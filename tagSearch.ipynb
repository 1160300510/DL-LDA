{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import re\n",
    "#连接数据库\n",
    "def connectDB():\n",
    "    # 打开数据库连接\n",
    "    db = pymysql.connect(\"localhost\", \"root\", \"Wangnima258\", \"stackoverflow\")\n",
    "    # print(\"连接上了...\")\n",
    "    return db\n",
    "#查询操作\n",
    "def queryDb(db, sql):\n",
    "    # 使用 cursor() 方法创建一个游标对象 cursor\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(sql)\n",
    "    # 获取所有记录列表\n",
    "    results = cursor.fetchone()\n",
    "    return results\n",
    "\"\"\"\n",
    "提取tag\n",
    "\"\"\"\n",
    "def tagPreprocess(tag):\n",
    "    # tag = '<c#><floating-point><type-conversion><double><decimal>'\n",
    "    p1 = re.compile(r'[<](.*?)[>]', re.S)  # 最小匹配\n",
    "    results = re.findall(p1, tag)\n",
    "    tags = []\n",
    "    for s in results:\n",
    "        tags.append(s)\n",
    "    # print(DE)\n",
    "    return tags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\"\"\"\n",
    "分别计算h1和h2，设阈值t1=0.1，t2=0.01，提取标签\n",
    "\"\"\"\n",
    "# def firstStep(csvpath):\n",
    "df = pd.read_csv('/Volumes/My Passport/stackoverflow数据集/nlp.csv')\n",
    "t = {}\n",
    "for index, row in df.iterrows():\n",
    "    s = row['Tags']\n",
    "    # print(s)\n",
    "    tags = tagPreprocess(s)\n",
    "    for tag in tags:\n",
    "        if tag not in t:\n",
    "            t[tag] = 1\n",
    "        else:\n",
    "            t[tag] += 1\n",
    "\n",
    "tag = list(t)\n",
    "a = list(t.values())\n",
    "b = []\n",
    "db = connectDB()\n",
    "for onetag in tag:\n",
    "    sql = \"select Count from Tags where TagName = \" + '\\\"'+ onetag + '\\\"'\n",
    "    result = queryDb(db, sql)\n",
    "    if(result is None):\n",
    "        bvalue = 0\n",
    "    else:\n",
    "        bvalue = result[0]\n",
    "    b.append(bvalue)\n",
    "db.close()\n",
    "frame = pd.DataFrame({'tag':tag,\n",
    "                      'a':a,\n",
    "                      'b':b,\n",
    "                      'c':len(df)})\n",
    "frame['h1'] = frame['a'].div(frame['b'])\n",
    "frame['h2'] = frame['a'].div(frame['c'])\n",
    "frame = frame.drop(frame[(frame.h1<0.1)].index)\n",
    "frame = frame.drop(frame[(frame.h2<0.01)].index)\n",
    "frame\n",
    "frame.to_csv('./nlp.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\"\"\"\n",
    "分别计算h1和h2，设阈值t1=0.1，t2=0.01，提取标签\n",
    "\"\"\"\n",
    "# def firstStep(csvpath):\n",
    "df = pd.read_csv('/Volumes/My Passport/stackoverflow数据集/cv.csv')\n",
    "t = {}\n",
    "for index, row in df.iterrows():\n",
    "    s = row['Tags']\n",
    "    # print(s)\n",
    "    tags = tagPreprocess(s)\n",
    "    for tag in tags:\n",
    "        if tag not in t:\n",
    "            t[tag] = 1\n",
    "        else:\n",
    "            t[tag] += 1\n",
    "\n",
    "tag = list(t)\n",
    "a = list(t.values())\n",
    "b = []\n",
    "db = connectDB()\n",
    "for onetag in tag:\n",
    "    sql = \"select Count from Tags where TagName = \" + '\\\"'+ onetag + '\\\"'\n",
    "    result = queryDb(db, sql)\n",
    "    if(result is None):\n",
    "        bvalue = 0\n",
    "    else:\n",
    "        bvalue = result[0]\n",
    "    b.append(bvalue)\n",
    "db.close()\n",
    "frame = pd.DataFrame({'tag':tag,\n",
    "                      'a':a,\n",
    "                      'b':b,\n",
    "                      'c':len(df)})\n",
    "frame['h1'] = frame['a'].div(frame['b'])\n",
    "frame['h2'] = frame['a'].div(frame['c'])\n",
    "frame = frame.drop(frame[(frame.h1<0.1)].index)\n",
    "frame = frame.drop(frame[(frame.h2<0.01)].index)\n",
    "frame\n",
    "frame.to_csv('./cv.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\"\"\"\n",
    "分别计算h1和h2，设阈值t1=0.1，t2=0.01，提取标签\n",
    "\"\"\"\n",
    "# def firstStep(csvpath):\n",
    "df = pd.read_csv('/Volumes/My Passport/stackoverflow数据集/speech-reg.csv')\n",
    "t = {}\n",
    "for index, row in df.iterrows():\n",
    "    s = row['Tags']\n",
    "    # print(s)\n",
    "    tags = tagPreprocess(s)\n",
    "    for tag in tags:\n",
    "        if tag not in t:\n",
    "            t[tag] = 1\n",
    "        else:\n",
    "            t[tag] += 1\n",
    "\n",
    "tag = list(t)\n",
    "a = list(t.values())\n",
    "b = []\n",
    "db = connectDB()\n",
    "for onetag in tag:\n",
    "    sql = \"select Count from Tags where TagName = \" + '\\\"'+ onetag + '\\\"'\n",
    "    result = queryDb(db, sql)\n",
    "    if(result is None):\n",
    "        bvalue = 0\n",
    "    else:\n",
    "        bvalue = result[0]\n",
    "    b.append(bvalue)\n",
    "db.close()\n",
    "frame = pd.DataFrame({'tag':tag,\n",
    "                      'a':a,\n",
    "                      'b':b,\n",
    "                      'c':len(df)})\n",
    "frame['h1'] = frame['a'].div(frame['b'])\n",
    "frame['h2'] = frame['a'].div(frame['c'])\n",
    "frame = frame.drop(frame[(frame.h1<0.1)].index)\n",
    "frame = frame.drop(frame[(frame.h2<0.01)].index)\n",
    "frame\n",
    "frame.to_csv('./speech-reg.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\"\"\"\n",
    "分别计算h1和h2，设阈值t1=0.1，t2=0.01，提取标签\n",
    "\"\"\"\n",
    "# def firstStep(csvpath):\n",
    "df = pd.read_csv('/Volumes/My Passport/stackoverflow数据集/opencv.csv')\n",
    "t = {}\n",
    "for index, row in df.iterrows():\n",
    "    s = row['Tags']\n",
    "    # print(s)\n",
    "    tags = tagPreprocess(s)\n",
    "    for tag in tags:\n",
    "        if tag not in t:\n",
    "            t[tag] = 1\n",
    "        else:\n",
    "            t[tag] += 1\n",
    "\n",
    "tag = list(t)\n",
    "a = list(t.values())\n",
    "b = []\n",
    "db = connectDB()\n",
    "for onetag in tag:\n",
    "    sql = \"select Count from Tags where TagName = \" + '\\\"'+ onetag + '\\\"'\n",
    "    result = queryDb(db, sql)\n",
    "    if(result is None):\n",
    "        bvalue = 0\n",
    "    else:\n",
    "        bvalue = result[0]\n",
    "    b.append(bvalue)\n",
    "db.close()\n",
    "frame = pd.DataFrame({'tag':tag,\n",
    "                      'a':a,\n",
    "                      'b':b,\n",
    "                      'c':len(df)})\n",
    "frame['h1'] = frame['a'].div(frame['b'])\n",
    "frame['h2'] = frame['a'].div(frame['c'])\n",
    "frame = frame.drop(frame[(frame.h1<0.1)].index)\n",
    "frame = frame.drop(frame[(frame.h2<0.01)].index)\n",
    "frame\n",
    "frame.to_csv('./opencv.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        Id  PostTypeId  AcceptedAnswerId  ParentId         CreationDate  \\\n1  8720410           1         8780172.0       NaN  2012-01-04 00:02:18   \n\n   DeletionDate  Score  ViewCount  \\\n1           NaN      2       1095   \n\n                                                Body  OwnerUserId  ...  \\\n1  <p>I was just kicking around the idea of break...      99923.0  ...   \n\n  LastEditDate     LastActivityDate                                     Title  \\\n1          NaN  2012-01-08 18:43:09  Compressing text using recursive N-Grams   \n\n                                   Tags AnswerCount CommentCount  \\\n1  <text><compression><storage><n-gram>           2            0   \n\n  FavoriteCount  ClosedDate  CommunityOwnedDate  ContentLicense  \n1           1.0         NaN                 NaN    CC BY-SA 3.0  \n\n[1 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>PostTypeId</th>\n      <th>AcceptedAnswerId</th>\n      <th>ParentId</th>\n      <th>CreationDate</th>\n      <th>DeletionDate</th>\n      <th>Score</th>\n      <th>ViewCount</th>\n      <th>Body</th>\n      <th>OwnerUserId</th>\n      <th>...</th>\n      <th>LastEditDate</th>\n      <th>LastActivityDate</th>\n      <th>Title</th>\n      <th>Tags</th>\n      <th>AnswerCount</th>\n      <th>CommentCount</th>\n      <th>FavoriteCount</th>\n      <th>ClosedDate</th>\n      <th>CommunityOwnedDate</th>\n      <th>ContentLicense</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>8720410</td>\n      <td>1</td>\n      <td>8780172.0</td>\n      <td>NaN</td>\n      <td>2012-01-04 00:02:18</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1095</td>\n      <td>&lt;p&gt;I was just kicking around the idea of break...</td>\n      <td>99923.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2012-01-08 18:43:09</td>\n      <td>Compressing text using recursive N-Grams</td>\n      <td>&lt;text&gt;&lt;compression&gt;&lt;storage&gt;&lt;n-gram&gt;</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import preprocess.pre as pre\n",
    "import re\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "#过滤代码片段\n",
    "def codefilter(htmlstr):\n",
    "    s = re.sub(r'<code>(\\n|.)*</code>', \"\",htmlstr)\n",
    "    return s\n",
    "\n",
    "df = pd.read_csv('data/nlp.csv')\n",
    "temp = df[df['Id'] == 8720410]\n",
    "temp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    <p>I was just kicking around the idea of break...\n",
      "Name: Body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = codefilter(str(temp['Body']))\n",
    "print(s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29417 entries, 0 to 29416\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Id                     29417 non-null  int64  \n",
      " 1   PostTypeId             29417 non-null  int64  \n",
      " 2   AcceptedAnswerId       11879 non-null  float64\n",
      " 3   ParentId               0 non-null      float64\n",
      " 4   CreationDate           29417 non-null  object \n",
      " 5   DeletionDate           0 non-null      float64\n",
      " 6   Score                  29417 non-null  int64  \n",
      " 7   ViewCount              29417 non-null  int64  \n",
      " 8   Body                   29417 non-null  object \n",
      " 9   OwnerUserId            29036 non-null  float64\n",
      " 10  OwnerDisplayName       420 non-null    object \n",
      " 11  LastEditorUserId       14881 non-null  float64\n",
      " 12  LastEditorDisplayName  187 non-null    object \n",
      " 13  LastEditDate           15053 non-null  object \n",
      " 14  LastActivityDate       29417 non-null  object \n",
      " 15  Title                  29417 non-null  object \n",
      " 16  Tags                   29417 non-null  object \n",
      " 17  AnswerCount            29417 non-null  int64  \n",
      " 18  CommentCount           29417 non-null  int64  \n",
      " 19  FavoriteCount          7792 non-null   float64\n",
      " 20  ClosedDate             1011 non-null   object \n",
      " 21  CommunityOwnedDate     2 non-null      object \n",
      " 22  ContentLicense         29417 non-null  object \n",
      "dtypes: float64(6), int64(6), object(11)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29417 entries, 0 to 29416\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Id                     29417 non-null  int64  \n",
      " 1   PostTypeId             29417 non-null  int64  \n",
      " 2   AcceptedAnswerId       11879 non-null  float64\n",
      " 3   ParentId               0 non-null      float64\n",
      " 4   CreationDate           29417 non-null  object \n",
      " 5   DeletionDate           0 non-null      float64\n",
      " 6   Score                  29417 non-null  int64  \n",
      " 7   ViewCount              29417 non-null  int64  \n",
      " 8   Body                   29417 non-null  object \n",
      " 9   OwnerUserId            29036 non-null  float64\n",
      " 10  OwnerDisplayName       420 non-null    object \n",
      " 11  LastEditorUserId       14881 non-null  float64\n",
      " 12  LastEditorDisplayName  187 non-null    object \n",
      " 13  LastEditDate           15053 non-null  object \n",
      " 14  LastActivityDate       29417 non-null  object \n",
      " 15  Title                  29417 non-null  object \n",
      " 16  Tags                   29417 non-null  object \n",
      " 17  AnswerCount            29417 non-null  int64  \n",
      " 18  CommentCount           29417 non-null  int64  \n",
      " 19  FavoriteCount          7792 non-null   float64\n",
      " 20  ClosedDate             1011 non-null   object \n",
      " 21  CommunityOwnedDate     2 non-null      object \n",
      " 22  ContentLicense         29417 non-null  object \n",
      "dtypes: float64(6), int64(6), object(11)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df['Body'] = df['Body'].astype(str)\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1 entries, 1 to 1\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Id                     1 non-null      int64  \n",
      " 1   PostTypeId             1 non-null      int64  \n",
      " 2   AcceptedAnswerId       1 non-null      float64\n",
      " 3   ParentId               0 non-null      float64\n",
      " 4   CreationDate           1 non-null      object \n",
      " 5   DeletionDate           0 non-null      float64\n",
      " 6   Score                  1 non-null      int64  \n",
      " 7   ViewCount              1 non-null      int64  \n",
      " 8   Body                   1 non-null      object \n",
      " 9   OwnerUserId            1 non-null      float64\n",
      " 10  OwnerDisplayName       0 non-null      object \n",
      " 11  LastEditorUserId       0 non-null      float64\n",
      " 12  LastEditorDisplayName  0 non-null      object \n",
      " 13  LastEditDate           0 non-null      object \n",
      " 14  LastActivityDate       1 non-null      object \n",
      " 15  Title                  1 non-null      object \n",
      " 16  Tags                   1 non-null      object \n",
      " 17  AnswerCount            1 non-null      int64  \n",
      " 18  CommentCount           1 non-null      int64  \n",
      " 19  FavoriteCount          1 non-null      float64\n",
      " 20  ClosedDate             0 non-null      object \n",
      " 21  CommunityOwnedDate     0 non-null      object \n",
      " 22  ContentLicense         1 non-null      object \n",
      "dtypes: float64(6), int64(6), object(11)\n",
      "memory usage: 272.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1 entries, 1 to 1\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Id                     1 non-null      int64  \n",
      " 1   PostTypeId             1 non-null      int64  \n",
      " 2   AcceptedAnswerId       1 non-null      float64\n",
      " 3   ParentId               0 non-null      float64\n",
      " 4   CreationDate           1 non-null      object \n",
      " 5   DeletionDate           0 non-null      float64\n",
      " 6   Score                  1 non-null      int64  \n",
      " 7   ViewCount              1 non-null      int64  \n",
      " 8   Body                   1 non-null      object \n",
      " 9   OwnerUserId            1 non-null      float64\n",
      " 10  OwnerDisplayName       0 non-null      object \n",
      " 11  LastEditorUserId       0 non-null      float64\n",
      " 12  LastEditorDisplayName  0 non-null      object \n",
      " 13  LastEditDate           0 non-null      object \n",
      " 14  LastActivityDate       1 non-null      object \n",
      " 15  Title                  1 non-null      object \n",
      " 16  Tags                   1 non-null      object \n",
      " 17  AnswerCount            1 non-null      int64  \n",
      " 18  CommentCount           1 non-null      int64  \n",
      " 19  FavoriteCount          1 non-null      float64\n",
      " 20  ClosedDate             0 non-null      object \n",
      " 21  CommunityOwnedDate     0 non-null      object \n",
      " 22  ContentLicense         1 non-null      object \n",
      "dtypes: float64(6), int64(6), object(11)\n",
      "memory usage: 272.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-f00d421bbdf2>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Body'] = temp['Body'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "temp['Body'] = temp['Body'].astype(str)\n",
    "temp.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<p>I was just kicking around the idea of breaking up a large group of text into a single integer by using recursive 2-Gram storage until there is only one value left.</p>\\n\\n<pre><code>table pair\\n{\\n    id\\n    first_parent_id (points to -&gt; this.id)\\n    second_parent_id (points to -&gt; this.id)\\n}\\n</code></pre>\\n\\n<p>For example, in the following code I have a 11 word sentence (twelve with the period). I could store each word pair in a database (\"this\" + \"is\" = ID #1) and then store each set of two wordpairs in the database (1 + 2 = ID #7), and repeat until I get down to only one word set left - which would be ID 12.</p>\\n\\n<pre><code>This is my group of words which I plan to compress.\\n---1---|--2-----|--3-----|-----4-|----5--|-------6-\\n-------7--------|--------8-------|-------9---------\\n----------------10---------------11----------------\\n------------------------12-------------------------\\n</code></pre>\\n\\n<p>Then using the number \"12\" we can work backwards (if we have the same dataset)</p>\\n\\n<pre><code>------------------------12-------------------------\\n----------------10---------------11----------------\\n-------7--------|--------8-------|-------9---------\\n---1---|--2-----|--3-----|-----4-|----5--|-------6-\\nThis is my group of words which I plan to compress.\\n</code></pre>\\n\\n<p>While this would take a tremendous amount of work to compress/uncompress each string - it seems like it might have a use in some kind of archive work where the contents need to be stored - but are never read except in rare cases where the uncompression process isn\\'t a problem. </p>\\n\\n<p>Am I thinking about this correctly? Would the possible number of word sequences just be too great to store like this? (Imagine a 500 word document).</p>\\n']\n"
     ]
    }
   ],
   "source": [
    "print(str(temp['Body'].values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<p>I was just kicking around the idea of breaking up a large group of text into a single integer by using recursive 2-Gram storage until there is only one value left.</p>\\n\\n<pre></pre>\\n\\n<p>While this would take a tremendous amount of work to compress/uncompress each string - it seems like it might have a use in some kind of archive work where the contents need to be stored - but are never read except in rare cases where the uncompression process isn\\'t a problem. </p>\\n\\n<p>Am I thinking about this correctly? Would the possible number of word sequences just be too great to store like this? (Imagine a 500 word document).</p>\\n']\n"
     ]
    }
   ],
   "source": [
    "s = codefilter(str(temp['Body'].values))\n",
    "print(s)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-fb4d7dd3",
   "language": "python",
   "display_name": "PyCharm (DL-LDA)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}