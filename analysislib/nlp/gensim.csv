,Unnamed: 0,Id,CreationDate,DeletionDate,Body,LastEditDate,LastActivityDate,Title,Tags,ClosedDate,CommunityOwnedDate,ContentLicense,nltk,spacy,gensim,stanford-nlp,scikit-learn
61,61,15670525,2013-03-27 22:12:52,,x csr matrix obtained using scikit tfidf vectorizer array plan create feature using lda however failed find initialize gensim corpus variable x csr matrix word want download corpus shown gensim documentation convert x dense matrix since would consume lot memory computer could hang short question following initialize gensim corpus given csr matrix sparse representing whole corpus use lda extract feature,2013-03-27 22:13:56,2013-03-28 23:27:52,initialize gensim corpus variable csr matrix,python scikit-learn document-classification lda gensim,,,CC BY-SA 3.0,False,False,True,False,True
221,221,9969599,2012-04-02 00:31:23,,trying retrieve list topic large corpus news article planning use gensim extract topic distribution document using lda want know format processed article required gensim implementation lda convert raw article format saw link using lda wikipedia dump found corpus processed state whose format wa mentioned anywhere,,2012-11-23 16:35:09,use gensim lda news article,machine-learning lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
300,300,13913142,2012-12-17 11:20:56,,trained lda model using gensim text corpus new text document text sparse vector ha inferred get word distribution corresponding topic example know top word topic number class gensim model ldamodel ldamodel ha method called show topic topic topn log false formatted true documentation say show randomly selected list topic way link print map inferred topic number word distribution,,2019-04-01 16:35:17,get topic number lda model gensim,python nlp lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
524,524,15016025,2013-02-22 02:47:42,,using wa able extract topic set document lsa access topic generated lda model printing code gave following error return code,,2019-08-28 04:07:15,print lda topic model gensim python,python nlp lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
568,568,15036048,2013-02-23 01:40:55,,tf idf model throw away term count transform corpus code output,,2013-03-14 07:35:48,tf idf model gensim throw away term count transform corpus,python nlp information-retrieval tf-idf gensim,,,CC BY-SA 3.0,False,False,True,False,False
600,600,15067734,2013-02-25 13:08:28,,using python train latent dirichlet allocation lda model small corpus sentence however time repeat process generates different topic doe lda parameter corpus generate different topic everytime stabilize topic generation using corpus http pastebin com wptkkvf list stopwords http pastebin com dqlcj code,,2020-03-12 20:09:37,lda model generates different topic everytime train corpus,python nlp lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
794,794,15184655,2013-03-03 10:20:55,,load lda transformed corpus python tried code output want load saved lda transformed corpus class using load tried using give output transformed corpus shown,2013-03-19 12:29:25,2014-04-02 22:34:32,gensim corpus class use load lda transformed corpus python,python nlp corpus lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
904,904,15260864,2013-03-07 00:24:44,,post responded thread getting totally screwy result trying print lsi topic gensim code print following console would like able print topic like er getting result like see note second item printed tuple idea came data txt text file several paragraph thought would fantastic adam,2017-05-23 12:11:05,2013-03-12 02:34:07,gensim topic printing error issue,python topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
971,971,9470479,2012-02-27 18:48:16,,document found net figured expression used determine term frequency inverse document frequency weight term corpus tf idf wt tf log n wa going implementation tf idf mentioned gensim example given documentation apparently doe follow standard implementation tf idf difference model note value used usually eigen value calculation doe eigen value come tf idf model,2012-03-20 11:28:36,2015-06-13 18:27:33,tf idf implemented gensim tool python,python tf-idf latent-semantic-indexing gensim,,,CC BY-SA 3.0,False,False,True,False,False
972,972,9470899,2012-02-27 19:20:44,,popular topic model latent dirichlet allocation lda used extract topic corpus return different topic different probability distribution dictionary word whereas latent semantic indexing lsi give topic distribution every iteration reality lda widely used extract topic doe lda maintain consistency return different topic distribution every time classification made consider simple example sample document taken represents document line represents document corpus lda model used generate topic document gensim used lda batch lda performed number topic chosen number pass original corpus batch lda performed topic generated pass batch lda performed original corpus topic generated case word distribution topic case fact word distribution never doe lda work effectively word distribution topic like lsi,2018-10-14 11:54:19,2019-05-22 10:12:59,doe lda give consistent result,nlp lda topic-modeling latent-semantic-indexing,,,CC BY-SA 3.0,False,False,True,False,False
983,983,16254207,2013-04-27 16:05:52,,apply lda latent dirichlet allocation get possible topic data base document collected use document rather corpus available like brown corpus english wikipedia training corpus refer page,2013-04-27 16:23:15,2017-11-07 15:56:26,use self made corpus training lda using gensim,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
985,985,16259652,2013-04-28 04:37:21,,corpus around document train data set topic modelling using lda whenever run program come across error even tried change value function always get error done,,2013-05-01 12:51:59,applying lda corpus training using gensim,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
995,995,16262016,2013-04-28 10:39:43,,trained corpus lda topic modelling using gensim going tutorial gensim website whole code output get know last output going help find possible topic please help,2013-04-28 10:48:48,2016-06-18 05:00:52,predict topic new query using trained lda model using gensim,python nlp lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
1064,1064,11471376,2012-07-13 13:22:10,,using gensim large scale topic modeling difficulty understanding determine predicted topic unseen non indexed document example million document converted vector lsa lda space want figure topic new document let call x according gensim documentation use doc x function convert x vector problem however variable topic return vector vector useful comparing x additional document allows find cosine similarity unable actually return specific word associated x missing something doe gensim capability thank edit larsmans ha answer wa able show topic using,2012-07-14 13:02:21,2014-05-17 16:43:02,finding topic unseen document via gensim,python nlp latent-semantic-indexing gensim,,,CC BY-SA 3.0,False,False,True,False,False
1075,1075,16309798,2013-04-30 22:10:04,,using gensim calculate similarity document reason line tfidf corpus return empty list sure though print dictionary get dictionary unique token print mmcorpus get mmcorpus document feature non zero entry tfidf corpus yield anyone diagnose problem thanks lot,,2013-04-30 22:10:04,calculating tf idf similarity document using gensim,python nlp similarity gensim,,,CC BY-SA 3.0,False,False,True,False,False
1163,1163,10559591,2012-05-11 23:00:15,,jep still playing around python decided try gensim tool find topic choosen word context wondered find word section text extract word together word spectic word word specific word save together extraction gensim could run seems hard find way extract word choosen word found played nltk tokenizing text word sentence wa easy get hold sentence still getting word sentence specific sentence seems hard figure confused may confusing show example soon finished blood rushed heart wa angry hear snow white wa yet living thought make something shall destroy completely thus saying made poisoned comb art understood disguising took form old widow went seven hill house seven dwarf knocking door called good ware sell day say word snow white want get part extracted heart wa angry hear snow white wa yet living thought word snow white also cool enough instead get sentence sentence snow white appeared done nltk easier mean whatever work best shall happy one two solution someone could help done gensim easier shall happy way fine want try see done atm head blank,,2018-07-02 09:45:34,extracting word plus section python,python nltk extraction gensim,,,CC BY-SA 3.0,True,False,True,False,False
1398,1398,16509883,2013-05-12 17:00:00,,first right way get topic distribution corpus lda wa performed issue occurs add alpha parameter lda try convert corpus sparse matrix follows conversion gensim corpus sparse matrix line get error get problem add alpha parameter complete traceback,,2013-12-04 22:25:18,gensim valueerror invalid shape alpha parameter,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
1454,1454,16553252,2013-05-14 21:35:04,,mac x mountain lion trying run script pycharm python installed installed canopy gensim understand could causing error getting show v installed entirety output following run script,,2013-05-15 01:44:50,gensim importerror pycharm module named scipy sparse,python scipy pycharm lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
1461,1461,12713797,2012-10-03 17:32:57,,looking compute similarity user text document using topic representation e document user represented vector topic e g neuroscience technology etc relevant topic user document goal compute similarity vector find similar user article recommended article tried use pearson correlation end taking much memory time reach k article vector length around k using numpy imagine better way inevitable single machine thank,2012-10-05 10:29:10,2013-02-25 12:18:03,topic based text user similarity,python numpy recommendation-engine topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
1572,1572,12763608,2012-10-06 20:31:45,,trying come topic based recommender system suggest relevant text document user trained latent semantic indexing model using gensim wikipedia corpus let easily transform document lsi topic distribution idea represent user way however course user history viewed article well rating article question represent user idea following represent user aggregation document viewed take account rating idea thanks,2012-10-06 20:50:44,2013-01-29 13:08:48,user profiling topic based recommender system,python machine-learning recommendation-engine latent-semantic-indexing topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
1580,1580,16645799,2013-05-20 08:51:42,,creating subset word corpus r answerer easily convert word cloud easily similar function python library take either raw word textfile corpus mmcorpus word cloud result look somewhat like,2017-05-23 12:10:24,2020-09-09 14:19:47,create word cloud corpus python,python nltk corpus gensim word-cloud,,,CC BY-SA 3.0,True,False,True,False,False
1586,1586,23176061,2014-04-19 21:58:42,,python code us sklearn gensim library tf idf lda latent dirichlet allocation want migrate google app engine use two library supported yet service already included google app engine use instead two library tf idf lda,,2014-04-30 04:33:58,tf idf lda google app engine,google-app-engine scikit-learn tf-idf lda gensim,,,CC BY-SA 3.0,False,False,True,False,True
1672,1672,17662916,2013-07-15 20:06:08,,module following code print distribution top word topic print full distribution word corpus,2015-08-15 04:25:46,2017-10-19 18:32:08,print full distribution word lda topic gensim,python lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
1681,1681,22079418,2014-02-27 20:18:06,,gensim dictionary object ha nice filtering function remove token appear fewer set amount document however looking remove token occur exactly corpus doe anyone know quick easy way,,2017-02-07 21:33:53,filter token occur exactly gensim dictionary,python-2.7 gensim,,,CC BY-SA 3.0,False,False,True,False,False
1703,1703,20953143,2014-01-06 15:21:46,,see following script snippet gensim tutorial page syntax word word python script,,2014-01-06 15:43:39,doe word word syntax mean python,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
1709,1709,20954805,2014-01-06 16:42:42,,big picture goal making lda model product review python using nltk gensim want run varying n gram problem everything great unigrams run bigram start get topic repeated information example topic might contain topic might contain human obviously conveying information obviously distinct bigram algorithmically determine similar enough translate occurrence one maybe one appears often corpus tried played around wordnet synset tree little luck turn adjective adjective satellite therefore return path similarity thought process wa following part speech tag sentence use po find correct synset compute similarity two synset threshold compute occurrence word replace least occurring word occurring word ideally though like algorithm determine similar corpus perhaps co occurring sense extended word part general english language appear corpus extended n gram maybe synonymous corpus similar suggestion algorithm suggestion get wordnet synset behave,,2014-01-07 10:13:49,nltk automatically translating similar word,python algorithm nltk wordnet gensim,,,CC BY-SA 3.0,True,False,True,False,False
1769,1769,23270933,2014-04-24 13:51:10,,using corpus document along dictionary around feature also model already prepared want find highest matching feature added document find best feature particular document running gensim similarity module feature document give u score feature want use later imagine costly process iterate index run iteration similarity need better way run gb memory system around iteration actually reason memory keep rising reallocating iteration surprisingly memory start rising around iteration memory issue solved better way finding highest scored feature particular document topic snippet code run memory edit memory issue wa resolved using memory profiler wa something else loop caused rise drastically let explain purpose detail imagine dealing various recipe recipe document item dictionary ingredient find six recipe thousand recipe trying achieve assign weight ingredient higher weighted ingredient important unique would best way achieve,2014-05-09 06:27:16,2014-05-09 06:27:16,use gensim scoring feature document also python memory issue,python memory-management dictionary nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
1773,1773,22121028,2014-03-01 22:08:11,,word vec model gensim trained document given sentence present sentence array e set trained model need update model sentence querying next time give result like printing log query similar new sentence positive give error indicates word cold part vocabulary trained thing right question update model give possible similarity given new sentence,,2019-09-25 01:49:40,update gensim word vec model,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
1777,1777,20984841,2014-01-08 00:30:08,,able run lda code gensim got top topic respective keywords would like go step see accurate lda algo seeing document cluster topic possible gensim lda basically would like something like python using gensim lda topicmodels see topic different document belong,2017-05-23 12:34:08,2020-08-28 21:15:20,topic distribution see document belong topic lda python,python nltk lda gensim,,,CC BY-SA 3.0,True,False,True,False,False
1780,1780,22129943,2014-03-02 16:04:53,,according gensim word vec use word vec model gensim package calculate similarity word e g however word vec model fails predict sentence similarity find lsi model sentence similarity gensim seem combined word vec model length corpus sentence long shorter word simple way achieve goal,2016-04-12 13:10:22,2020-01-08 06:38:49,calculate sentence similarity using word vec model gensim python,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
1904,1904,22196248,2014-03-05 11:20:51,,trying use model create lda model given corpus want update new corpus contains word seen first corpus try call get following error initialized lda model corpus consisting word see size bound wanted call update corpus many word fails get around want able update lda model new corpus new word possible,2014-03-05 11:41:42,2017-06-05 08:31:15,gensim lda model calling update corpus unseen word,lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
1939,1939,23348819,2014-04-28 18:41:57,,believe issue python doe play nicely character encoding column sql table show output column ha type ha encoding try make python play data getting following error gensim topic modeling library believe problem gensim requires unicode encoding change character encoding collation column database alternative solution thanks help,,2018-12-07 08:15:15,python mysqldb change string encoding,python mysql encoding collation gensim,,,CC BY-SA 3.0,False,False,True,False,False
1953,1953,17765509,2013-07-20 18:45:27,,using gensim tutorial find similarity text code two document one ha text another ha one commented use first document list everything go fine generates meaningful output use second document list text error occured reason behind error fix using bit machine,,2013-12-04 22:44:49,python gensim index array ha non integer dtype float,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
1957,1957,14468078,2013-01-22 21:11:09,,using gensim python toolkit build tf idf model document need create dictionary document first however found gensim doe use stemming creating dictionary corpus right,2013-01-22 21:12:28,2016-02-25 05:36:03,stemming used gensim creates dictionary tf idf model,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
2051,2051,22272370,2014-03-08 17:07:51,,trying train word vec model short phrase gram since sentence example short believe window size use atmost trying understand implication small window size quality learned model understand whether model ha learnt something meaningful tried training word vec model gram appears learnt model doe capture semantics etc well using following test evaluate accuracy model http code google com p word vec source browse trunk question word txt used gensim word vec train model snippet accuracy score using window size also tried running demo word accuracy sh script outlined window size get poor accuracy well however word vec site claim possible obtain accuracy task hence would like gain insight effect hyperparameters like window size affect quality learnt model,,2019-09-09 09:26:15,word vec effect window size used,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
2066,2066,22283396,2014-03-09 14:25:43,,trying get related document list document set doc using two algorithm testing gensim lsi gensim similarity give terrible result improve,,2015-10-16 07:03:51,document similarity gensim,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
2088,2088,22286488,2014-03-09 18:47:40,,hello gensim community working python sublime text need install gensim tried enthought doe support nltk need import gensim sublime text tried command line instruction success someone please tell get gensim st already scipy numpy installed tried following instruction radim rehurek webpage easy install pip install etc,,2014-03-10 07:18:28,python nltk gensim,python sublimetext2 nltk gensim,,,CC BY-SA 3.0,True,False,True,False,False
2104,2104,18840537,2013-09-17 02:50:55,,want get text training set natural language increase set automatically created text try mimic text content using bag word assumption sequence matter syntax matter want create text contains word pertinent general topic base right using latent dirichlet allocation classify document topic distribution average topic distribution set generate document topic distribution want know two thing better way train lda text domain set without tainting topic eg set want increase ha text politics train model kind text car fashion music classificates base politics text get topic distribution generates similar text distribution using python gensim,2013-09-17 03:03:36,2013-09-17 16:56:07,generate pertinent text,algorithm language-agnostic nlp probability-theory gensim,2014-04-24 05:58:27,,CC BY-SA 3.0,False,False,True,False,False
2158,2158,18867516,2013-09-18 08:39:47,,save serialized corpus try load give loading dictionary seems fine though anyone know resolve doe occur,,2013-12-04 22:15:34,resolve unpicklingerror loading gensim corpus python,python lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
2164,2164,23473844,2014-05-05 13:34:04,,problem statement several document k document need apply topic modelling find similar document analyze similar document find different q could anyone suggest topic modelling package achieve exploring mallet gensim python sure would best fit requirement help would highly appreciated,,2014-06-17 15:19:06,topic modelling finding similarity topic,topic-modeling gensim mallet,,,CC BY-SA 3.0,False,False,True,False,False
2213,2213,23509699,2014-05-07 05:48:16,,tried examine content bow corpus v lda bow corpus transformed lda model trained corpus say topic found following output doc n document bow corpus lda n transformation doc n lda model correct understanding output transformed document lda n topic document n belongs understanding see document like belong topic like doc belongs topic respective probability could please explain output lda n correct understanding output especially since another thread creator gensim mentioned document belongs one topic,2014-05-07 17:47:43,2018-05-16 10:20:33,understanding lda transformed corpus gensim,python nlp lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
2225,2225,22361438,2014-03-12 19:06:18,,bunch html document apply lda algorithm gensim stuck creating corpus understand design corpus collection html document example site show creation wikipedia compressed file xml bz anyone please guide apply lda bunch html document thanks advance,2014-03-12 20:49:18,2014-03-18 23:45:01,lda html document genism,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
2355,2355,22433884,2014-03-16 06:51:25,,got trained lda model want calculate similarity score two document corpus trained model studying gensim tutorial function still get head around somebody give hint thanks,,2020-06-10 12:47:30,python gensim calculate document similarity using lda model,python nlp lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
2381,2381,21313493,2014-01-23 16:09:48,,total document unique token length dictionary whenever run script get error check internet mentioned might related ram computer ha using window bit gb ram change make script please help,,2014-01-30 20:35:36,indexerror using gensim package lda topic modelling,python lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
2399,2399,18988886,2013-09-24 18:07:35,,library class convert matrix market format file python object sometimes necessary transpose matrix hence transposed parameter wa introduced however confused line http github com piskvorky gensim blob develop gensim matutils py inversion term document value id happens anyone familiar term document matrix information retrieval care enlighten,,2013-09-25 09:19:00,transposed parameter matrix market format gensim python,python matrix information-retrieval tf-idf gensim,,,CC BY-SA 3.0,False,False,True,False,False
2436,2436,22469506,2014-03-18 02:52:52,,trying model twitter stream data topic model gensim easy use solution impressive simplicity ha truly online implementation lsi lda changing content stream like twitter dynamic topic model ideal way even hack implementation even strategy using utilize gensim purpose python implementation derive preferably gensim independent preferring python since want get started asap optimum solution work please mention thanks,,2016-06-02 18:31:50,efficient python library dynamic topic model preferably extending gensim,python lda text-analysis topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
2531,2531,21403839,2014-01-28 11:04:12,,want cluster word based semantic similarity currently list document detected noun phrase want make cluster obtained noun within document unsupervisedly cluster semantically looked wordnet gensim library suggestion really help getting required cluster word based semantic similarity,2014-01-29 08:57:33,2014-01-30 20:25:14,unsupervised clustering word document semantically,python cluster-analysis semantics wordnet gensim,,,CC BY-SA 3.0,False,False,True,False,False
2565,2565,21440132,2014-01-29 18:57:53,,learning latent semantic analysis lsa able construct term document matrix find svd decomposition get topic decomposition example gensim,2014-01-30 20:48:42,2014-01-31 12:45:54,latent semantic analysis finding topic,algorithm svd gensim,,,CC BY-SA 3.0,False,False,True,False,False
2590,2590,23735576,2014-05-19 10:37:21,,trying train word vec model using italian wikipedia http dump wikimedia org itwiki latest itwiki latest page article xml bz however sure best preprocessing corpus model accepts list tokenized sentence first try use standard preprocessor extract article remove punctuation split word space tool sentence would correspond entire model sure impact fact model train model default parameter unfortunately training seems manage obtain meaningful similarity appropriate preprocessing wikipedia corpus task question broad please help pointing relevant tutorial article code first trial,2019-09-09 13:26:10,2019-09-09 13:26:10,gensim train word vec wikipedia preprocessing parameter,nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
2655,2655,18183810,2013-08-12 09:38:20,,wa curious gensim dictionary implementation following code looked inside file deerwester dict look like following code however yield question since see actual word inside dict file hexadecimal value stored kind super compressed format curious feel like consider using,2013-09-18 10:01:44,2013-09-18 10:01:44,gensim dictionary implementation,python nlp topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
2663,2663,21498633,2014-02-01 13:28:14,,trying classify email based subject line get lsi order train classifier getting tf idf trying get lsi model however doe processing write file code get output till tfidf complete program doe return anything lsi running subject line idea might going wrong much appreciated thanks logged data,2014-02-01 19:08:10,2014-06-02 19:47:02,python lsi using gensim working,python text-processing gensim,,,CC BY-SA 3.0,False,False,True,False,False
2682,2682,17310933,2013-06-26 03:13:39,,derived lda topic model using toy corpus follows found use small number topic derive model gensim yield full report topical distribution potential topic test document e g however use large number topic report longer complete seems topic probability le threshold observed specific omitted form output wondering behaviour due aesthetic consideration get distribution probability mass residual topic thank kind answer,,2015-09-18 12:22:05,document topical distribution gensim lda,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
2712,2712,20349958,2013-12-03 11:31:04,,trying understand gensim package python implement latent dirichlet allocation following define dataset removing stopwords create dictionary corpus define lda model print topic able understand much result providing probability occurrence word also meaning topic topic etc wa expecting something le like important keywords already checked gensim tutorial really help much thanks,2015-08-22 14:44:31,2019-03-22 16:08:29,understanding lda implementation using gensim,python topic-modeling gensim dirichlet,,,CC BY-SA 3.0,False,False,True,False,False
2745,2745,20362993,2013-12-03 22:25:56,,trying use module natural language processing library python doc say initialize model format doe expect input sentence raw text additional processing need post update tried load sentence get nothing,2013-12-03 23:33:41,2017-03-31 09:18:06,load sentence python gensim,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
2760,2760,22674660,2014-03-26 22:47:51,,get topic document lda doc print topic using lda print topic topic id equivalent way retrieve topic hdpmodel one way think using hdp lda create ldamodel straightforward way,,2014-05-11 02:23:58,get specific topic hdp,gensim,,,CC BY-SA 3.0,False,False,True,False,False
2762,2762,21552518,2014-02-04 12:25:15,,trying recycle scikit learn vectorizer object gensim topic model reason simple first already great deal vectorized data second prefer interface flexibility scikit learn vectorizers third even though topic modelling gensim fast computing dictionary relatively slow experience similar question asked especially bridging solution gensim function transforms scipy sparse matrix gensim corpus object however conversion doe make use attribute sklearn vectorizers hold mapping word feature id mapping necessary order print discriminant word topic gensim topic model described mapping word id integer word string aware fact gensim object much complex slower compute scikit simple python idea use gensim model example code,2017-05-23 12:26:26,2019-07-31 18:31:07,using scikit learn vectorizers vocabulary gensim,python scikit-learn topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,True
2783,2783,14705944,2013-02-05 11:01:37,,working tf idf model little confusion model implemented constructed model trying print model giving different value term following two term giving result following result curious know tf idf value term val val,2013-02-23 01:47:29,2013-12-04 22:09:11,little confusion tf idf model implemented gensim,python nlp tf-idf gensim,,,CC BY-SA 3.0,False,False,True,False,False
2810,2810,23853828,2014-05-25 09:23:37,,another thread ha similar question mine leaf reproducible code goal script question create process memory efficient possible tried write class take advantage gensims capability however running indexerror sure resolve creating document using used gensim tutorial placed tutorial example txt error received script resulting file thanks advance help topic modeling log,2017-05-23 12:08:50,2015-12-12 02:45:06,python indexerror using gensim lda topic modeling,python lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
2832,2832,17354417,2013-06-27 22:39:49,,last part code bash output wondering able save resulting topic generated readable format tried method always output something unreadable,2016-08-16 14:42:13,2018-08-02 19:00:42,gensim save lda model produced topic readable format csv txt etc,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
2875,2875,23877375,2014-05-26 20:35:36,,word vec seems mostly trained raw corpus data however lemmatization standard preprocessing many semantic similarity task wa wondering anybody experience lemmatizing corpus training word vec useful preprocessing step,2018-04-13 14:37:46,2019-04-16 06:55:47,word vec lemmatization corpus training,nlp word2vec gensim lemmatization,,,CC BY-SA 3.0,False,False,True,False,False
2926,2926,19315338,2013-10-11 09:58:14,,trying get started loading pretrained bin file google word vec site freebase vector skipgram bin gz gensim implementation word vec model load fine using creates run similar function cant find word vocabulary error code idea going wrong,2014-01-16 05:40:33,2015-06-10 16:16:26,working google word vec bin file gensim python,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
3036,3036,23971900,2014-05-31 15:49:27,,gensim tutorial run lad document feature non zero entry code simple meet value error gensim memory friendly happen get,2014-10-05 14:54:06,2014-10-05 14:54:06,handle valueerror array big gensim run lda,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
3143,3143,24430238,2014-06-26 12:13:15,,edit found interesting issue link show gensim us randomness training inference step suggested set fixed seed order get result every time however getting every topic probability want find every twitter user topic calculate similarity twitter user based similarity topic possibility calculate topic every user gensim calculate dictionary topic cluster every user topic general best way compare two twitter user based topic model extraction gensim code following returned topic probability user corpus using corpus list user word case use list user tweet get back calculated topic every tweet question doe following make sense training lda model several twitter user calculating topic every user every user corpus using lda model calculated provided example return topic distribution equal probability basically every line text corresponds different tweet calculate corpus give probability every tweet separately hand use like example user word corpus second case gensim return probability topic thus user getting topic distribution user text corpus list word list sentence list tweet regarding implementation qi jianshu weng twitterrank approach page say aggregate tweet published individual twitterer big document thus document corresponds twitterer ok confused document user tweet corpus contain,2017-05-23 11:44:06,2017-12-20 04:52:18,lda gensim implementation distance two different doc,python probability gensim,,,CC BY-SA 3.0,False,False,True,False,False
3256,3256,19474333,2013-10-20 05:46:31,,new python gensim currently working one tutorial http radimrehurek com gensim tut html two question line code file fully loaded memory dictionary start get built tutorial explicitly say monitor ram usage activity monitor python process hit gig gig file killed process midway strange assumed dictionary gig text file would much smaller someone clarify point recode line stuff line read want print screen see progress attempt work dictionary reinitialized every line realize n b question appreciate help patience,,2013-10-20 05:55:13,build dictionary without loading text,python dictionary gensim,,,CC BY-SA 3.0,False,False,True,False,False
3331,3331,19504898,2013-10-21 21:16:10,,used various version tfidf scikit learn model text data resulting data x format wanted experiment lda way reduce dimensionality sparse matrix simple way feed numpy sparse matrix x gensim lda model ignore scikit go way gensim tutorial outline like simplicity scikit vectorizers parameter,2018-12-09 05:04:37,2018-12-09 05:04:37,use scikit learn tfidf gensim lda,python scikit-learn text-mining lda,,,CC BY-SA 4.0,False,False,True,False,True
3372,3372,19522258,2013-10-22 15:34:33,,trying install gensim pip install setup install give error solve,,2013-10-22 15:54:18,install gensim,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
3390,3390,24126187,2014-06-09 18:08:45,,wa following instruction link http radimrehurek com tutorial mallet python however came across error tried train model please share thought might thanks,,2018-10-13 01:33:20,error implementing gensim ldamallet,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
3499,3499,24178843,2014-06-12 07:33:21,,use gensim build dictionary collection document document list token code question add new doc token dictionary update searched gensim document find solution,2020-01-30 18:07:54,2020-01-30 18:07:54,add token gensim dictionary,python gensim topic-modeling topicmodels,,,CC BY-SA 3.0,False,False,True,False,False
3548,3548,23032745,2014-04-12 15:59:46,,know training lda model gensim get topic unseen document document already used training mean way get topic document corpus wa used training without treating like new document,,2014-04-17 13:18:16,gensim get topic document seen document,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
3589,3589,19615951,2013-10-27 08:11:23,,experimenting lda topic modelling using gensim seem find topic model evaluation facility gensim could report perplexity topic model held evaluation text thus facilitates subsequent fine tuning lda parameter e g number topic would greatly appreciated anyone could shed light perform topic model evaluation gensim question ha also posted metaoptimize,2013-10-27 09:07:27,2013-11-04 05:03:29,topic model evaluation gensim,lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
3599,3599,24212368,2014-06-13 19:09:45,,working lda model gensim basically opening text file building dictionary running model open file use sample list list path file need use codecs open text different language updated python problem know close file using idea tried couple thing use regular loop following step use file get error ioerror errno many open file thinking could open number file time join close repeat also keeping file open bad thank,2014-06-13 19:10:52,2014-06-13 19:37:10,python closing bunch text file opened time list comprehension,python loops text gensim,,,CC BY-SA 3.0,False,False,True,False,False
3621,3621,25643004,2014-09-03 11:20:13,,trying install word vec window machine using python interpreter http github com danielfrg word vec tried downloading zip running python install unzipped directory running however instance return error seemed problem accessing bit googling managed add line word vec throw error honest even sure go also tried installing make setting path variable exe file install advice would greatly appreciated thanks update word vec module work package called seems work pretty well got great nlp functionality http radimrehurek com gensim,2017-10-22 03:26:12,2019-04-16 06:06:42,python word vec installing,python pip gnuwin32 word2vec,,,CC BY-SA 3.0,False,False,True,False,False
3653,3653,19652908,2013-10-29 08:15:26,,using lsimodel gensim modelling topic corpus mail able get word word score topic store file tried using print topic show topic return word score associated word also need topic score output log file want value variable like example log output need score variable method package get output please help,,2013-12-09 19:40:18,obtain topic score lsi model gensim,python gensim latent-semantic-indexing,,,CC BY-SA 3.0,False,False,True,False,False
3664,3664,24242287,2014-06-16 11:06:53,,doe gensim give u hierarchy topic write code calculate topic document output word topic want hierarchy topic code http gist github com anonymous e b f e c c output way get hierarchy topic,,2016-07-26 19:00:57,get hierarchy topic gensim,python scipy gensim,,,CC BY-SA 3.0,False,False,True,False,False
3832,3832,26812617,2014-11-08 01:13:02,,read doc next build corpus definition builddictionary buildcorpus stop word stuff call error logging information show get started crash get error message posted,,2014-12-03 00:50:48,index error running lda gensim,python lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
3869,3869,27615804,2014-12-23 07:21:19,,trying install gensim downloaded site installation using pip also working getting error seen question stackoverflow also wa mentioned question installed microsoft c compiler python window binary gensim install,2017-05-23 11:52:16,2014-12-31 14:07:59,difficulty installing gensim using source pip,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
3899,3899,27801403,2015-01-06 15:05:56,,trying run example code python lsi text clustering return error nd last command please let know wrong need update anything make work,,2015-01-06 15:05:56,lsi clustering using gensim python,python python-2.7 cluster-analysis gensim,,,CC BY-SA 3.0,False,False,True,False,False
3918,3918,27789298,2015-01-05 22:52:13,,posted issue github http github com piskvorky gensim issue however need help actually use compatibility numpy gensim ha tried passing none failing following corpus code work ipython notebook throw indexerrors,,2015-01-05 23:17:12,corpus dense requires two argument tutorial example us one,python numpy gensim,,,CC BY-SA 3.0,False,False,True,False,False
3932,3932,27632404,2014-12-24 06:17:47,,trying use gensim word vec unable train model based brown corpus code downloaded nltk data using getting error wrong,,2018-01-17 17:53:24,train gensim brown corpus,python gensim,,,CC BY-SA 3.0,True,False,True,False,False
3966,3966,27659985,2014-12-26 17:25:45,,trying following kaggle assignmnet using gensim package use word vec able create model store disk trying load file back getting error find similar question wa unable solve problem prog w v py trying generate model using code program take half hour generate model hence unable run many time debug,2017-03-02 17:58:03,2018-12-03 06:21:07,error utf codec decode byte x position invalid start byte,python character-encoding gensim word2vec kaggle,,,CC BY-SA 3.0,False,False,True,False,False
3974,3974,27957112,2015-01-15 05:04:05,,first question stack overflow dataframe panda like want extract pair column name data whose data index separate array want use gensim python library requires corpus form smart way apply gensim panda data,,2017-08-09 20:00:54,extract array column name data panda dataframe,python pandas gensim,,,CC BY-SA 3.0,False,False,True,False,False
3979,3979,25803267,2014-09-12 07:46:07,,situation numpy term document matrix example plugged matrix ldamodel method gensim working fine lad method term document matrix mentioned needed two intermediate matrix topic word array document topic array research purpose per document topic probability matrix p per topic word probability matrix p w question get array gensim function kindly help getting matrix,2014-09-12 22:24:29,2014-09-21 02:45:02,retrieve topic word array document topic array lda gensim,lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
4045,4045,24688116,2014-07-10 23:53:45,,using nlp task created corpus object want filter term low tf idf value running lda model looked documentation corpus class find way access term idea thank,2014-07-11 00:00:06,2018-11-01 03:30:20,filter word low tf idf corpus gensim,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
4067,4067,28034688,2015-01-19 22:35:40,,trying install gensim getting error displayed running anaconda python numpy window machine already window sdk say something deprecated numpy version seems odd running numpy also anaconda installation python though removed path order able run python cmd need work project python running return python go throwing undefined reference,,2015-12-22 13:37:31,gensim installing window python,python numpy windows-8.1 anaconda gensim,,,CC BY-SA 3.0,False,False,True,False,False
4076,4076,25829768,2014-09-14 03:21:13,,admit programmer charge deployment met big problem production environment loading corpus dictionary always fails error however code work fine test environment developer local environment make test server connect production database loading work mean database ok checked every setting file every directory file required path ok installed dependency frozen test environment unable find root cause may anyone give advice proceed troubleshooting,2014-09-14 03:41:48,2014-09-14 03:41:48,python corpus error reported loading dictionary nonetype object ha attribute doc bow,python django dictionary corpus gensim,,,CC BY-SA 3.0,False,False,True,False,False
4089,4089,26902048,2014-11-13 05:36:55,,know using scikit learn could use piece code could gensim,,2020-07-01 15:19:53,tokenize set document unigram bigram bagofwords using gensim,python-2.7 scikit-learn gensim,,,CC BY-SA 3.0,False,False,True,False,True
4154,4154,28155313,2015-01-26 17:22:32,,trying install using following command got following error message fix problem version ubuntu installed window vmware,2015-01-26 18:11:58,2016-02-02 02:54:34,problem installing gensim ubuntu,python ubuntu gensim,,,CC BY-SA 3.0,False,False,True,False,False
4288,4288,26977042,2014-11-17 16:19:21,,working project would like use latent dirichlet allocation order extract topic large amount article code also tried use ldamulticore different way every time got error idea thank advance,,2016-06-21 13:51:35,using latent dirichlet allocation gensim,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
4336,4336,28488714,2015-02-12 22:04:23,,using gensim topic modelling gotten point similarity query using lsi tf idf model get back set id similarity eg get text document related id case looked doc corpus dictionary index model seem find,2017-10-10 05:36:55,2017-10-10 06:28:46,retrieve string version document id gensim,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
4348,4348,28508548,2015-02-13 20:53:48,,trying use word vec project training get way could save,2018-11-14 13:42:47,2018-11-14 13:42:47,gensim word vec storing attribute syn norm,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
4358,4358,25915441,2014-09-18 14:28:04,,using gensim library apply lda set document using gensim apply lda corpus whatever term weight binary tf tf idf question term weighting used original lda understood correctly weight term frequency sure,,2014-09-21 03:20:12,term weighting original lda gensim,python lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
4391,4391,25936354,2014-09-19 14:32:16,,trying install window python try pip install sci end importerror similar yes installed work fine try import python managed install downloading executable installers one also tried using three work either something python installation idea thanks lot advance,,2014-09-19 14:32:16,python pip working scipy scikit learn gensim,windows-7 pip python-3.3 gensim,,,CC BY-SA 3.0,False,False,True,False,True
4438,4438,28677350,2015-02-23 15:34:17,,latent dirichlet allocation lda topic model find latent variable topic underlying bunch document using python gensim package two problem printed frequent word topic tried topic found distribution word flat meaning even frequent word ha probability topic similar meaning frequent word topic overlap lot topic share almost set word high frequency word guess problem probably due document document actually belong specific category example document introducing different online game case lda still work since document quite similar model based bag word may good way try could anyone give suggestion thank,2019-03-10 15:17:32,2019-03-10 15:17:32,using lda topic model distrubution topic word similar flat,python lda topic-modeling gensim,,,CC BY-SA 4.0,False,False,True,False,False
4459,4459,27032517,2014-11-20 05:40:50,,word vec open source tool google word provides vector float value exactly represent also paper paragraph vector anyone explain using word vec order obtain fixed length vector paragraph,2016-11-03 16:44:38,2018-07-30 07:18:51,doe vector word word vec represents,machine-learning nlp neural-network gensim,,,CC BY-SA 3.0,False,False,True,False,False
4530,4530,28823948,2015-03-03 04:10:03,,list doc trying get topic corresponding probability using already trained using code snippet getting document converting bow passing lda return topic also calculating mean probability topic document work fine pas bow one document loop document give following error unable find one please help p issue bow work fine give correct output edit list list inner list represents list word document whereas dictionary combined corpus topic model wa trained,2015-03-03 05:00:42,2015-03-06 01:23:16,error running trained topic model new document,python lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
4557,4557,26010645,2014-09-24 07:08:51,,code excerpt gensim word vec know two single word similarity calculated cosine distance two word set code seems use mean wordvec calculated two mean vector cosine distance know word vec foundation process,,2014-09-24 09:16:38,similarity beteween two bag word gensim word vec calculated way,nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
4567,4567,24816912,2014-07-18 03:47:19,,using gensim package implement lsi corpus goal find frequently occurring distinct topic appear corpus know number topic corpus estimate anywhere best approach setting number topic lsi search better look large number topic small number topic,,2014-11-10 06:34:11,number latent semantic indexing topic,topic-modeling gensim latent-semantic-indexing,,,CC BY-SA 3.0,False,False,True,False,False
4633,4633,27097779,2014-11-24 04:15:12,,new python trying implement topic modelling successful implementing lda pything using gensim able give label name topic name topic please help best way implement python lda output somewhat like please let know need code research student conference chi field work student hci group researcher research student ustars underrepresented participant researcher mathematics graduate mathematical conference student research conference field new participant chi robotics researcher student student robotics conference international interact new ph meet ieee u research flow field visualization challenge student project shape visual data research mathematics program june conference mathematician conference field mrc research student field hovering mechanism dpiv aerodynamic unsteady conference hummingbird research mathematics program flow mathematician conference field june visualization community student research ustars mathematics underrepresented program encouraging participant conference research conference program mathematics mathematician field conference area,,2014-11-24 04:57:07,naming lda topic python,python label lda,,,CC BY-SA 3.0,False,False,True,False,False
4635,4635,27104847,2014-11-24 12:26:04,,machine learning library requires dependency http scikit learn org stable install html user requires additional dependency http radimrehurek com gensim install html simply without dependency http github com alvations pywsd blob master setup py add,,2014-11-24 12:26:04,add scikit learn gensim library setup py,python installation scikit-learn gensim,,,CC BY-SA 3.0,False,False,True,False,True
4648,4648,28979559,2015-03-11 05:55:35,,written following code read corpus file followed done preprocessing step ir removing punctuation stopwords etc would like perform word count find frequent word used text used following code word doc however get following error suggestion,,2015-03-11 09:19:10,unhashable type list wordcount,python regex nltk word-count gensim,,,CC BY-SA 3.0,True,False,True,False,False
4652,4652,29083865,2015-03-16 18:03:10,,ultimate goal produce csv file containing labeled binary term vector document essence term document matrix using gensim produce file unlabeled term matrix essentially copying pasting code http radimrehurek com gensim tut html given list document called text convert vector numpy matrix use convert sparse numpy matrix full array finally output file produce matrix binomial vector know vector represents word accurate way matching word vector tried parsing dictionary creative list word would glue full matrix however doe work word id key matched appropriate vector assumption much simpler elegant approach possible time able find maybe someone help point something fundamental missed,,2015-06-09 01:06:23,word label document matrix gensim,python-2.7 numpy gensim,,,CC BY-SA 3.0,False,False,True,False,False
4659,4659,26031958,2014-09-25 06:23:31,,trying reproduce result graber et al showing lda used multilingual corpus probable term topic say top come single language paper reasonable sanity check perform imo difficulty using corpus used europarl corpus corpus composed bulgarian english concatenated bulgarian english corpus contains sentence line collection line bulgarian second collection english fit lda model topic contain english term top fourth mixed english bulgarian using default setting lda note removed stopwords sparse term think matter intuitively topic term bulgarian others term english,2014-09-29 19:10:22,2014-09-29 19:10:22,lda bi multi lingual corpus,lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
4733,4733,27139908,2014-11-26 01:35:41,,using gensim python package learn neural language model know provide training corpus learn model however already exist many precomputed word vector available text format e g http www nlp stanford edu project glove way initialize gensim word vec model make use precomputed vector rather learn vector scratch thanks,,2018-12-15 00:16:31,load precomputed vector gensim,python nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
4753,4753,27145452,2014-11-26 09:26:51,,lda model two method inference new document using existing model think difference two method,,2017-08-09 13:16:03,deference lda doc bow lda inference corpus,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
4755,4755,27147690,2014-11-26 11:14:04,,wondering whether either tfidf corpus used corpus used inference document using lda gensim example,,2014-12-03 00:30:07,use tfidf corpus corpus inference document using lda,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
4768,4768,24861239,2014-07-21 09:03:08,,using django search engine request made post server treat answer json format order fast need index file loaded beginning manage py runserver way access view called doe anyone know thanks advance,,2014-07-21 09:59:16,load file django manage py runserver,python django gensim,,,CC BY-SA 3.0,False,False,True,False,False
4777,4777,29259416,2015-03-25 15:08:27,,trying replicate tutorial mallet wrapper gensim http radimrehurek com tutorial mallet python fit model get error message use model infer topic distribution example distribution uniform output problem functioning wrapper mallet managed replicate mallet tutorial http programminghistorian org lesson topic modeling mallet,,2015-03-25 15:08:27,gensim ldamallet division error,python machine-learning topic-modeling gensim mallet,,,CC BY-SA 3.0,False,False,True,False,False
4829,4829,29372611,2015-03-31 15:36:52,,following code run lda analysis tweet try run script receive following log error message anyone got solution,,2017-04-21 12:29:17,error running lda tweet using gensim python,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
4852,4852,27177721,2014-11-27 19:37:11,,tf idf matrix already row term column document want train lda model given term document matrix first step seems using convert matrix corpus format construct parameter list term term row know format dictionary construct dictionary function like suggestion thank,,2014-12-09 12:15:19,training lda model gensim external tf idf matrix term list,python-3.x tf-idf lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
4867,4867,29369317,2015-03-31 13:01:20,,downloaded tweet amsterdam utf using twitter api python trying make dictionary lda using code part code part cause error always give error depending txt file choose input either expect reason character unknown utf smilies used tweet maybe googling tried replace code error message error message doe anyone solution thanks,,2015-03-31 13:15:27,tweet analysis python error making dictionary lda,python dictionary lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
4945,4945,29589795,2015-04-12 13:06:28,,file music txt science txt lke extract topic music science creating lda model file setting num topic output see science music present topic like use music txt create topic music lda model use science txt create topic science lda model combine lda model give lda model topic rd step possible like individual segregration topic lda model alternative,2015-04-12 17:11:30,2015-04-12 21:52:23,text processing assign topic document using lda,machine-learning nlp topic-modeling text-classification gensim,,,CC BY-SA 3.0,False,False,True,False,False
4949,4949,29591581,2015-04-12 16:14:54,,loading pre trained vector binary file generated word vec c code something like using vector generate vector representation sentence contain word may already existing vector example ha associated vector word yogurt try get make good sense want able take sentence word corresponding vector add representation aware post continue train c vector way train new model say word vector merge alternatively way test model contains word actually try retrieve least avoid keyerror,2017-05-23 12:17:44,2016-01-04 09:08:09,gensim word vec augment merge pre trained vector,python gensim keyerror word2vec,,,CC BY-SA 3.0,False,False,True,False,False
4971,4971,29561063,2015-04-10 12:09:07,,using lda categorize small document line categorizing topic technology politics art music etc etc using wikipedia download article category technology politics art etc etc training lda category wikipedia huge gb compressed computation take hour us huge space hard drive toolkit already provides ready made generic topic directly use categorization,,2015-04-10 20:40:38,ready made topic using lda categorize document,python nlp text-processing gensim,2015-04-26 22:51:36,,CC BY-SA 3.0,False,False,True,False,False
4990,4990,27220927,2014-12-01 02:40:15,,term document matrix numpy matrix format dictionary represent term document matrix way easily pas two gensim lda model pas somewhow gensim model ldamodel lda,,2014-12-09 12:12:32,passing term document matrix gensim lda model,python numpy machine-learning nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
4996,4996,29602038,2015-04-13 09:31:22,,package method computing similarity score pair sentence based wordnet research automatic summarization based wordnet need compute similarity score two sentence wa using nltk computing score every pair word iterated two sentence take lot time inefficient looking project library method already implement intelligently compute similarity score two sentence based wordnet addition found similar question python semantic similarity score string package named gensim look like want could help thank,2017-05-23 11:58:14,2015-04-13 09:31:22,python calculate similarity score two sentence based wordnet,python nltk wordnet,,,CC BY-SA 3.0,True,False,True,False,False
4998,4998,26145937,2014-10-01 16:20:48,,trying follow tutorial topic modelling latent dirichlet allocation lda book building machine learning system python gone far book first part topic modelling return error error vocab txt file doe exists switching directory supposed find following l download ap sh download wp sh preprocess wikidata sh look like ap data need downloaded separately mentioned book get doe anybody know solve issue thank,2014-10-01 16:42:36,2014-10-01 19:03:55,bleicorpus associated press dataset gensim io error,python enthought lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
5058,5058,29676413,2015-04-16 13:35:30,,using doc vec class gensim framework compute vectorial representation document corpus corpus contains short sentence even one word observed many sentence especially short one doc vec doe provide representation could someone explain reason,2015-04-20 19:49:30,2015-04-20 19:49:30,missing sentence doc vec representation,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5107,5107,29751328,2015-04-20 14:55:22,,trying implement topic tiling algorithm trained lda model algorithm need id assigned single word unseen document calculate frequent topic id given word assign mode word using gensim lib easy get topic word dist word given probability however get topic assigned single world meaning word topic dists please also note interested parsing topic word dist result gensim interested finding accurate way model assigns numerous topic individual word come unseen document thanks advance,,2016-05-16 23:53:36,lda gensim word topic id distribution instead topic word distribution,python lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
5108,5108,29837563,2015-04-24 02:13:02,,difference doc use however many people seem use,2015-04-27 03:41:47,2015-04-27 03:41:47,difference model ldamodel ldamodel model ldamodel,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
5142,5142,26202978,2014-10-05 13:27:25,,based previous question spark python use custom file format generator input rdd think able parse basically input sc textfile using library custom function particularly trying parse wikipedia dump using gensim framework already installed gensim master node worker node would like use gensim build function parsing wikipedia page inspired question list iterator tuples returned map pyspark code following source code extract page found http github com piskvorky gensim blob develop gensim corpus wikicorpus py based going seems work spark unfortunately run code getting following error log probably spark log tried without spark successfully problem somewhere combination spark gensim much understand error getting see file reading line gensim wikicorpus py edit added log spark edit gensim us documentation might cause problem actually expects file name file containing xml data rdd considered file containing xml data,2017-05-23 11:44:36,2015-04-06 18:51:43,spark python trying parse wikipedia using gensim,python apache-spark gensim wikimedia-dumps,,,CC BY-SA 3.0,False,False,True,False,False
5163,5163,29932784,2015-04-29 01:23:12,,new gensim package vector space model general unsure exactly lsa output give brief overview goal like enhance naive bayes classifier using topic modeling improve classification review positive negative great paper reading ha shaped idea left still somewhat confused implementation already got working code naive bayes currently using unigram bag word feature label either positive negative gensim code output suggestion general comment would appreciated,,2016-11-01 19:55:35,combining lsa lsi naive bayes document classification,document-classification gensim naivebayes latent-semantic-indexing latent-semantic-analysis,,,CC BY-SA 3.0,False,False,True,False,False
5166,5166,29939984,2015-04-29 09:44:22,,gensim optimized python port word vec see http radimrehurek com deep learning word vec gensim currently using vector http clic cimec unitn composes semantic vector html going rerun model training gensim wa noisy token model would like find equivalent parameter parameter used word context window pmi weighting compression k dimension gensim equivalence train word vec model pmi weight option gensim default min count used word vec another set parameter word vec word context window negative sample subsampling dimension negative sample parameter gensim parameter equivalence subsampling gensim,2015-04-29 11:03:36,2015-05-11 05:20:29,word vec gensim parameter equivalence,python nlp neural-network gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5180,5180,27291145,2014-12-04 10:05:22,,install gensim successfully many way freshman coding difficult understand following information thanks help,,2014-12-05 16:39:46,mistake installing gensim,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
5232,5232,27308118,2014-12-05 03:10:43,,list bag word two class say n item class item class b want use topic modeling gensim package lda python order train model class v class b meanwhile new topic modeling python doe anyone know mean merge bag class use gensim use bag item seperately thanks,,2014-12-05 17:06:21,topic modeling using gensim python,python machine-learning nlp lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
5266,5266,26251674,2014-10-08 07:45:48,,trying install gensim python library however facing dependency error isntalled schipy numpy throught canopy next step use pip install gensim order get gensim package however getting error message installed python got visual studio installed machine,2014-10-08 07:56:49,2014-10-08 08:22:32,installing gensim window,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
5277,5277,27324292,2014-12-05 20:39:00,,word vec site download googlenews vector negative bin gz bin file gb binary format useful tomas mikolov assures u fairly straightforward convert binary format text format though take disk space check code distance tool rather trivial read binary file unfortunately know enough c understand http word vec googlecode com svn trunk distance c supposedly gensim also tutorial found seem converting text way someone suggest modification c code instruction gensim emit text,2014-12-05 20:54:12,2017-05-04 08:30:48,convert word vec bin file text,python c gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5328,5328,30155506,2015-05-10 19:04:33,,gensim official tutorial explicitly state possible continue training loaded model aware according documentation possible continue training model wa loaded format even one generates model scratch try call method possible access newly created label instance supplied possible continue training doc vec model gensim new sentence achieved,,2018-03-18 21:56:13,continue training doc vec model,neural-network gensim,,,CC BY-SA 3.0,False,False,True,False,False
5379,5379,26286206,2014-10-09 19:12:16,,using gensim package topic modelling python trying train topic model using gensim train py module getting error run module could anyone please help figure issue,2014-10-09 19:18:07,2014-10-09 19:22:09,python ioerror errno file directory model dictionary dict,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
5393,5393,27354912,2014-12-08 09:26:26,,last part code wondering save corpus lda use,,2014-12-08 14:04:59,save trainset distribution trained lda model gensim,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
5408,5408,30323899,2015-05-19 11:07:34,,want use gensim library python code need execute code java following python code sent vec py code running fine standalone mode e executed need call function java code tried using jython error java code look like following error help appreciated thanks,,2020-05-28 20:05:25,using gensim python java jython,java python jython gensim,,,CC BY-SA 3.0,False,False,True,False,False
5417,5417,30301922,2015-05-18 11:24:45,,trained word vec model using corpus document gensim model training writing following piece code get raw feature vector word say view however get keyerror word probably exist key list key indexed word vec check key exit index trying get raw feature vector,,2018-07-21 10:21:50,check key exists word vec trained model,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5438,5438,26309463,2014-10-10 23:31:39,,working mini project classification text python idea simple corpus sentence respectively belonging j chirac mitterrand ex president french republic associated label goal build model predicts belong different sentence class label ha mitterand c chirac correctly program considered finally applied clustering algorithm dataset called naive bayes made prediction new data test problem evaluation performance system got low score although used several method increase stopwords bigram smoothing someone another idea suggestion improve performance system satisfied attach code following code chose stopliste deleted word important splitter produce corpus use bigram produce corpus test dataset edit performance system give value normally system effective give work file miller sentence declared gensim paste code long question method improve system performance used bigram smoothing,2015-06-12 15:36:31,2015-06-12 15:36:31,machine learning text classification,python algorithm machine-learning text-classification,,,CC BY-SA 3.0,False,False,True,False,False
5456,5456,30446268,2015-05-25 21:30:00,,many independent task read write gensim model gb size gensim topic modelling library built upon numpy decide parallelize first loading gensim model file pas parameter pool process run ran script two segment show runnable script please copy got stuck line occurred output wa error never occurred introduced gensim program gensim without multiprocessing also work think may related interoperation c code underlying gensim numpy blas wanted know reason error fix use gensim subprocessing alternative think would copied mac x using copy write strategy think related memory synchronization either line begin working printed e ha accessed code error passing sub process,2015-05-25 21:45:47,2015-05-25 21:45:47,systemerror sharing gensim numpy model multiprocessing,python numpy python-multiprocessing gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5489,5489,30488695,2015-05-27 16:53:24,,using doc vec model teh gensim framework represent corpus short document word creating vector vector representing word document want find similar item word document given item get memoryerror similarity computed ubuntu machine gb ram gb swap checked memory allocation htop observed never memory wa completely used also set unlimited maximum address space may locked memory python could someone explain reason memoryerror opinion available memory enough computation could memory limit python thanks advance,,2015-06-17 00:47:03,doc vec memoryerror,python memory gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5509,5509,30480027,2015-05-27 10:36:34,,trying use freebase word embeddings released google hard time getting word freebase name doe anyone know exist kind table map freebase representation word represent regard hedi,,2016-08-10 21:27:07,using freebase vector gensim,python freebase gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5546,5546,30563361,2015-05-31 22:25:55,,two question related usage gensim lda create model using one corpus save perhaps extend later another corpus training model possible lda used classify unseen document model need created including corpus online way see change fly fairly basic understanding lda used topic modeling simple corpus using lda gensim library please point conceptual inconsistency question thanks,,2017-03-20 07:40:50,latent dirichlet allocation using gensim one corpus,python lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
5551,5551,30573873,2015-06-01 12:46:10,,thinking training word vec huge large scale data tb size web crawl dump personally trained c implementation googlenews dump gb imac took hour train generate vector impressed speed try python implementation though read somewhere generating vector wiki dump gb vector length take day generate speed word vec need use distributed model type hardware need within day imac gb ram one faster gensim python c implemention see word vec implementation doe support gpu training,2015-06-02 07:40:20,2018-01-22 03:59:22,train word vec large datasets,python c machine-learning word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5558,5558,30628566,2015-06-03 19:07:00,,trained million word python want update trained model new data previous post source around web came know possible trying create multiple model dump want merge model dumping want use dumped result got previous post merging pretrained model word vec getting came know library named deepdist trying see experiment around possible solution one may kindly suggest using python window professional,2017-05-23 11:46:18,2015-06-03 19:54:42,averaging multiple model word vec gensim,python python-2.7 gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5569,5569,30633871,2015-06-04 02:18:16,,wish test scalability two implementation algorithm latent dirichlet allocation python gensim lda google search result talk scalability website web based application test scalability simple algorithm entire system best practice kept mind,2015-06-04 02:27:31,2015-06-04 03:01:21,scalability simple algorithm,python algorithm scalability lda,,,CC BY-SA 3.0,False,False,True,False,False
5577,5577,30583166,2015-06-01 20:58:47,,find n nearest word given word using gensim word vec implementation api referring skip gram maybe missed something read finding similar word finding odd one dl j method called equivalent gensim,,2016-12-02 16:22:05,gensim word vec finding nearest word given word,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5586,5586,30654526,2015-06-04 21:30:42,,relatively new working gensim lda started two week ago trouble trusting result following topic produced using paragraph document topic island world computer presidential post post tijuana vice tweet president info topic computer world post eurozone month tijuana island raise rate year topic quite seem right fact seem almost non sensical exactly read result also normal topic distribution exactly topic,,2015-06-05 01:10:59,lda generated topic,python machine-learning lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
5615,5615,30663755,2015-06-05 10:02:59,,new stackoverflow please forgive bad english using word vec school project want work domain specific corpus like physic textbook creating word vector using word vec standalone doe provide good result due lesser size corpus especially hurt want evaluate word may well outside vocabulary text book want textbook encode domain specific relationship semantic nearness quantum heisenberg especially close textbook eg may hold true background corpus handle generic word like need basic background model like one provided google word vec site way supplant background model using newer corpus training corpus etc doesnot work well attempt combine vector representation two corpus general specific could find search,2015-06-05 10:54:52,2015-06-05 14:53:48,biasing word vec towards special corpus,nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5641,5641,30718471,2015-06-08 20:27:31,,save output using following code,2016-01-07 17:15:14,2018-06-14 22:25:29,save gensim lda topic output csv along score,python-2.7 gensim,,,CC BY-SA 3.0,False,False,True,False,False
5657,5657,30742973,2015-06-09 21:15:31,,general bow corpus created yield document per format requires see however document lot word used extremely often wanted use tfidf balance something like want train lda train converges fine great new unseen document want project onto lda topic always need project new doc first e take original know apply first project onto doc little unclear whether model know previous transformation applied corpus,,2016-11-22 02:02:56,need transform unseen document projecting onto model topic,python tf-idf lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
5658,5658,30745184,2015-06-10 00:37:51,,wish know default number iteration gensim lda latent dirichlet allocation algorithm think documentation talk number iteration denoted parameter iteration initializing ldamodel thanks,2015-06-10 01:09:05,2017-12-12 00:14:42,gensim lda default number iteration,python topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
5673,5673,30770919,2015-06-11 03:13:23,,running gensim get error thought wa odd see file indeed ha adding trying run nameerror global name ifilter defined wa fixed changing module work perfectly guess question whether wa error specific system kind import python trick work,2015-06-11 03:42:18,2018-01-05 07:10:22,top topic gensim nameerror global name np defined,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
5682,5682,30804073,2015-06-12 13:15:54,,trying fit lda corpus lda c format got working hdp model seem make work lda gensim looking get topic probability vector document well probability distribution word topic hdp model work fine dat file ha corpus lda c format vocab file ha unique word lda implementation get proper vector seem find function give prior word distribution topic,2015-06-12 18:59:23,2016-03-03 13:19:01,fitting lda corpus lda c format gensim,lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
5705,5705,27470670,2014-12-14 15:13:43,,recently came across doc vec addition gensim use pre trained word vector e g found word vec original website doc vec doc vec getting word vector sentence us paragraph vector training thanks,2020-04-05 17:56:23,2020-04-05 17:56:23,use gensim doc vec pre trained word vector,python nlp gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
5731,5731,30851588,2015-06-15 17:42:10,,relatively new using gensim lda general problem right run lda corpus topic token weight info topic diff rho info topic sundayes nowe easter iniunctions eyther christ authoritie sir saint thinge info topic eu n ioseph pharohs pharoh iosephs lo egypt iacob ioseph beniamin info topic agreeable creede fourme conteined apostolike vicar sacrament contrarywise parson propitiatorie info topic yf suche lyke shoulde moste youre oure lyfe anye thinges info topic heau nly eu n heau n sweet peace eu ry constance constant doth oh info topic eu n ioseph pharohs pharoh vel iosephs heau n lo ac seu n info topic thou would love king sir doe thee never info topic quae vt qui ij non ad si vel atque cum info topic suspected supersticious squire parson ordinarie vsed english fortnight squire offender info topic ile e che much ti could oh neuer heart document running lda following code removing stopwords text token token text frequency token text text dictionary corpus dictionary text corpus dictionary doc bow text text text tfidf model tfidfmodel corpus tfidf corpus tfidf corpus lda model ldamodel tfidf corpus id word dictionary update every chunksize num topic pass lda tfidf corpus lda print topic sure wrong everytime run token weight might causing could correct,2015-06-15 22:00:02,2015-06-15 22:00:02,lda result error,machine-learning nlp lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,False
5738,5738,27477084,2014-12-15 03:51:47,,trying run gensim topic modeling example canopy express get following error sum line error get typeerror integer required seems ok regular python canopy ha issue seems canopy treat sum statement sure work around idea getting started python text analysis,,2014-12-15 04:47:30,gensim error canopy express,python-2.7 canopy gensim,,,CC BY-SA 3.0,False,False,True,False,False
5787,5787,30971935,2015-06-22 03:55:48,,seem one many people struggling install gensim window trawled countless forum error poster never appear match error hopefully someone point right direction running window server r standard bit installed mingw anaconda bit come python added file distutils cfg c user sam anaconda lib distutils content added c mingw bin environment variable install gensim using pip get error try run word vec get error uninstalled gensim tried install using mingw compiler give error exhausted option think find anyone could give advice would much appreciated,2015-06-22 04:01:21,2015-07-22 00:24:30,gensim mingw,python windows python-2.7 gensim,,,CC BY-SA 3.0,False,False,True,False,False
5805,5805,30973503,2015-06-22 06:41:44,,trying perform tfidf matrix would like use gensim work corpus therefore return list list varying length want matrix option somehow fill missing value list list convert corpus matrix choosing latter try convert count matrix tf idf weighted matrix get error copied function another script wa believe getting however imported function happening,2015-06-22 06:46:47,2015-06-22 16:47:29,attributeerror numpy ndarray object ha attribute,python numpy matrix gensim,,,CC BY-SA 3.0,False,False,True,False,False
5826,5826,31003021,2015-06-23 12:37:07,,trying run exactly code macbook pro ubuntu machine aws code look like us multinomialnb scikit learn macbook model training go well ubuntu machine getting like run training ubuntu machine able run screen try machine look exactly doe anyone ha idea possibly wrong edit list eg obtained using gensim framework first tokenizing text converting bow,2015-06-24 08:01:12,2015-06-24 08:01:12,valueerror setting array element sequence scikit learn,python ubuntu scikit-learn gensim,,,CC BY-SA 3.0,False,False,True,False,True
5838,5838,31011061,2015-06-23 18:48:58,,working gensim dictionary example print shown http radimrehurek com gensim tut html also access key value pair dictionary object however,,2017-11-02 17:32:24,access key value pair gensim dictionary,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
5873,5873,27533977,2014-12-17 20:09:12,,research purpose want large k set web page though interested text plan use gensim lda topic model commoncrawler seems like good place start sure could someone point way download k text file access easier downloading,,2014-12-17 21:42:53,download subset amazon commoncrawel text wet file needed,download lda gensim common-crawl,,,CC BY-SA 3.0,False,False,True,False,False
5887,5887,31062273,2015-06-25 23:06:57,,trying train word vec model using file k line one sentence per line think may represent special use case sentence arbitrary string rather dictionary word sentence line ha word word ha character character like also number training code simple thing thing work real quick k sentence ram steadily going run ram see pc ha started swapping training grind halt lot ram available gb us starting swap think openblas correctly linked numpy tell question expected machine got lot available ram like mine get ram train model smaller piece doe look like setup configured properly code inefficient thank advance,2015-06-25 23:17:58,2015-09-30 21:00:52,word vec training using gensim start swapping k sentence,python numpy blas gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5889,5889,31166218,2015-07-01 15:56:07,,trying use freebase along gensim word vec find similarity score vector two word using following code creating model based freebase code giving key error word giving use googlenews instead freebase work fine idea,,2015-07-01 19:33:54,unable find word using freebase word vec,python-2.7 freebase gensim google-news,,,CC BY-SA 3.0,False,False,True,False,False
5956,5956,31286574,2015-07-08 07:48:57,,studying word vec use word vec train text data occur overflowerror numpy message tell case machine x window python bit numpy scipy also bit,2015-07-10 08:13:35,2015-07-28 20:00:23,python word vec word vec overflowerror,python-3.x windows-7-x64 integer-overflow gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
5989,5989,31350481,2015-07-10 21:21:53,,like use gensim python wrapper dynamic topic model essentially topic modeling approach slice corpus date e year look topic evolve time however finding nothing online specifies timeslices formatted doe anyone example file preparation,,2020-07-27 06:50:07,gensim timeslice data format,python python-2.7 gensim,,,CC BY-SA 3.0,False,False,True,False,False
6015,6015,31321209,2015-07-09 14:57:45,,get document vector two text document using doc vec new would helpful someone could point right direction help tutorial using gensim get attributeerror list object ha attribute word whenever run,2018-12-15 19:33:57,2019-06-04 10:17:50,doc vec get document vector,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
6024,6024,31338082,2015-07-10 10:05:38,,want process wikipedia using final objective train word vec model working problem accented vowel spanish want normalize e u seem deaccent function gensim dwould like apply directly building corpus done working example,,2017-05-10 08:50:04,spanish wikipedia processing using gensim,python wikipedia gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6031,6031,31384947,2015-07-13 13:38:52,,trying install lib ubuntu using however got error like doe anyone know fix,,2015-07-14 08:08:47,getting unicodedecodeerror installing gensim ubuntu,ubuntu pip gensim,,,CC BY-SA 3.0,False,False,True,False,False
6061,6061,31512853,2015-07-20 09:21:39,,trying emulate streaming document update lsi additional document streamed find error code streaming document updating lsi model corpus get new new vec every iteration new vec yield different iteration error appears first iteration first line expected new vec rest expected output new vec,2015-07-20 19:58:18,2016-02-01 06:49:44,gensim valueerror failed create intent cache hide optional array must defined dimension got,python gensim latent-semantic-indexing,,,CC BY-SA 3.0,False,False,True,False,False
6068,6068,31425123,2015-07-15 08:22:03,,far know doc vec computes embeddings document word use word vector document vector estimate similarity word document document document word word remark would helpful,,2016-03-25 20:38:27,comparing word document,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6090,6090,31507399,2015-07-20 00:30:45,,try use word vec give error trying anything word seems encoding issue init word vec test bit error also tried load model make error loading,2015-07-20 00:46:56,2016-06-20 09:52:11,setting word vec keyerror word word vocabulary,python character-encoding gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6108,6108,31543542,2015-07-21 15:34:47,,using gensim hdp module set document number topic independent corpus length,,2020-10-17 18:56:09,hierarchical dirichlet process gensim topic number independent corpus size,python nlp lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
6115,6115,31524433,2015-07-20 19:08:05,,able reproduce word vec result using gensim result make sense gensim open source toolkit intended handling large text collection using efficient online algorithm including python implementation google word vec algorithm following online tutorial able reproduece result similar word positive woman king negative man supposed wenceslaus queen stead got u eleonore iv similar fast wa slow quick wa mitsumi insight code result gensim model import word vec import logging logging basicconfig format asctime levelname message level logging info sentence word vec text corpus tmp text model word vec word vec sentence size model similar positive woman king negative man topn u eleonore u iv model similar positive fast u slow u paced model similar positive quick topn u mitsumi,2020-06-20 09:12:55,2015-10-03 06:28:41,reproduce word vec result using gensim,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6116,6116,31524898,2015-07-20 19:35:07,,wanted know difference gensim word vec two similarity measure similar similar cosmul know first one work using cosine similarity word vector one us using multiplicative combination objective proposed omer levy yoav goldberg want know affect result one give semantic similarity etc eg result queen result u iraq,,2015-07-30 10:11:30,gensim word vec semantic similarity,python semantics similarity gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6163,6163,31742630,2015-07-31 09:24:14,,post question already answer use scikit method gensim like scikit vectorizers gensim seen whole pipeline used text classification try explain little bit situation want use gensim lda implemented method order proceed text classification one dataset consisted three part train k test k unlabeled data k trying learn latent topic space using unlabeled data transform train test set learned latent topic space currently using scikit learn implemented method order extract bow representation later transforming required input lda implementation end transforming train test set extracted latent topic space finally going back csr matrix order fit classifier obtain accuracy although seems everything fine performance classifier almost attaching part code order get additional help something obvious currently missing first post potential remark please hesitate inform,2017-05-23 11:45:52,2017-01-27 12:29:19,gensim lda text classification,python scikit-learn lda topic-modeling gensim,,,CC BY-SA 3.0,False,False,True,False,True
6179,6179,31685048,2015-07-28 19:05:06,,new web py python stack need use module web py application us gensim nltk library tried installing python window environment came across several error due issue numpy scipy installation window ended resolving error uninstalling python instead installing anaconda python successfully installed required gensim nltk library stage able see gensim nltk library resolving properly without error spyder pycharm however run application web py still complains gensim give error guess configure web py use anaconda python issue would resolved need know possible configure web py use anaconda python otherwise someone know way resolve gensim error web py kindly share thought help would highly appreciated,,2015-07-28 21:52:08,configure web py use anaconda python,python-2.7 web2py anaconda gensim,,,CC BY-SA 3.0,True,False,True,False,False
6181,6181,31687263,2015-07-28 21:17:27,,got bow vector wondering supervised dimensionality reduction algorithm sklearn gensim capable taking high dimensional supervised data projecting lower dimensional space preserve variance class actually trying find proper metric classification regression believe using dimensionality help know unsupervised method want keep label information along way,,2016-08-31 08:43:46,supervised dimensionality redunction topic model using sklearn gensim,python machine-learning gensim dimensionality-reduction,,,CC BY-SA 3.0,False,False,True,False,True
6203,6203,31728460,2015-07-30 15:48:51,,model want create model different dimension use doc vec model fast training train like doe ha effect,2015-07-30 16:00:45,2015-07-31 05:08:51,use word vec vocab one model another,python deep-learning gensim,,,CC BY-SA 3.0,False,False,True,False,False
6211,6211,31800674,2015-08-04 04:23:15,,first time use gensim package run lda model problem happened followed train save lda model local file lda model last night try usinfer topic distribution new unseen document run funciton error happend following source code could help,,2015-08-04 04:23:15,ldamulticore object ha attribute minimum probability,lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
6223,6223,31821821,2015-08-05 01:06:27,,background trying judge whether phrase semantically related word found corpus using gensim example corpus document pre tokenized code based gensim tutorial judge semantic relatendness phrase using cosine similarity string corpus problem seems query contains term found within dictionary phrase judged semantically similar corpus e g giraffe poop car murderer ha cosine similarity semantically unrelated sure solve issue code,2015-08-06 23:40:39,2015-08-14 14:18:21,semantic similarity phrase using gensim,python-3.x nltk gensim,,,CC BY-SA 3.0,True,False,True,False,False
6254,6254,31827623,2015-08-05 08:47:26,,gensim doc vec combine sentence vector make single vector paragraph realise train entire paragraph would obviously better train individual sentence context etc think advice normal use case also would retrieve sentence paragraph vector model,,2015-08-11 08:09:34,combining doc vec sentence paragraph vector,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6265,6265,31814825,2015-08-04 16:42:17,,currently working word vec model using gensim python want write function help find antonym synonym given word example antonym sad happy synonym upset enraged way word vec,,2019-08-28 14:29:27,obtain antonym word vec,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6283,6283,31870995,2015-08-07 06:23:30,,sorry enough reputation post image main problem tell need install c compiler reinstall gensim train slow fact really slow installed mingw visual studio added mingw environment variable path idea solve,2015-08-07 07:27:13,2020-04-22 06:46:57,gensim need c compiler,python compilation word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6318,6318,31996843,2015-08-13 19:28:39,,window winpython trying install gensim http www lfd uci edu gohlke pythonlibs gensim getting error,2015-08-13 21:29:00,2015-08-15 18:12:00,install gensim window,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
6332,6332,31975754,2015-08-12 21:30:08,,using lda algorithm gensim package find topic given text asked resulting topic include different word topic e g topic ha word monkey topic include word monkey list thought far run multiple time time add previous word stop word list since even sure algorithmically logically right thing b hope built way aware c large database take minute run lda time using multi core version question better way hope get help thanks,,2016-10-07 13:41:34,gensim lda generate topic different word topic,python algorithm api lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
6343,6343,32056080,2015-08-17 17:11:15,,trying use doc vec read file list sentence like want generate two file one unique word sentence another ha one corresponding vector per line vector output want output vector getting vocab fine code seem figure print individual sentence vector looked documentation found much help code look like far,2015-08-31 23:06:17,2015-08-31 23:06:17,using gensim doc vec produce sentence vector,python vector gensim,,,CC BY-SA 3.0,False,False,True,False,False
6365,6365,32101795,2015-08-19 17:17:41,,getting loading gensim model available word vec repository known issue,,2019-06-18 10:09:56,error loading word vec model gensim,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6406,6406,32201795,2015-08-25 10:38:47,,remove number output lda using gensim package info topic watch water strap analog resistance atm coloured timepiece classy output watch water strap etc,,2015-08-26 17:11:39,remove number symbol output lda using gensim package,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
6412,6412,32170261,2015-08-23 18:52:04,,new world word vec start use gensim implementation word vec use two naive sentence first document set vector get like however type another toy document set get following result new word vec according understanding two document set structurally identical result corresponding word getting different result algorithm always giving probalistic output document set small function used following,2015-08-23 18:57:54,2015-08-24 12:18:38,word vec probalistic output,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6424,6424,32150468,2015-08-21 23:01:24,,learning topic model set document working well wondering existing system actually generate new document topic word model ie say want new document topic gensim mallet tool actually produce new document given input topic choice choice roll kind problem say two topic tool take topic topic length nicely produce document like something along line want duplicate already exists,,2015-10-13 13:08:58,generating document lda topic model,modeling lda documents mallet generative,,,CC BY-SA 3.0,False,False,True,False,False
6433,6433,32321375,2015-08-31 23:25:19,,getting segmentation fault multiply scipy sparse matrix transpose searched internet could find answer help appreciated think memory issue since dimension small vec object created gensim information help also think overflow issue since range element pickle object http drive google com open id b djbsn xmvdmfyt mzzvfjovu,2015-08-31 23:37:02,2015-09-01 05:55:07,sparse matrix python segmentation fault,segmentation-fault scipy sparse-matrix gensim,,,CC BY-SA 3.0,False,False,True,False,False
6475,6475,32276734,2015-08-28 17:35:07,,trying run word vec skip gram model implemented gensim default window size corpus txt file iterator use look something like use punkt tokenizer us unsupervised algorithm detecting sentence boundary nltk package splitting text sentence however replace simple e considering sentence one line splitting word get time efficiency time faster using nltk parser code inside open look something like question important word vec algorithm fed sentence actual sentence something attempt punkt tokenizer sufficient word algorithm receive context surrounding word lie one line word may necessarily actual sentence case sentence spanning several line opposed context word word may sentence spanning several line also sort part doe window size play window size set example doe size sentence yielded sentence iterator cease play part window size decide context word case use instead trying detect actual sentence boundary using punkt tokenizer hope able describe issue sufficiently would really appreciate opinion pointer help regarding,,2017-01-31 10:01:11,relationship window size actual sentence length word vec,gensim word2vec,,,CC BY-SA 3.0,True,False,True,False,False
6481,6481,32313062,2015-08-31 13:58:08,,trying obtain optimal number topic lda model within gensim one method found calculate log likelihood model compare e g input parameter using latent dirichlet allocation hence looked calculating log likelihood lda model gensim came across following post estimate parameter latent dirichlet allocation model basically state update alpha method implement method decribed huang jonathan maximum likelihood estimation dirichlet distribution parameter still know obtain parameter using libary without changing code obtain log likelihood lda model gensim better way obtain optimal number topic gensim,,2020-10-15 11:48:55,best way obtain optimal number topic lda model using gensim,python text-mining lda gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
6487,6487,32251047,2015-08-27 13:42:51,,hell blocker trying use gensim doc vec import gensim model doc vec doc vec successfully train set tweet able pull document vector fine using model doc issue trying get vector representation new unseen document feed vector back classifier far know method exists doc vec however try call method get following attributeerror doc vec object ha attribute infer vector able use method described doc vec documentation http radimrehurek com gensim model doc vec html tried using different version gensim including version released doc vec http rare technology com doc vec tutorial latest version please help,2015-11-05 19:59:39,2015-11-05 19:59:39,gensim doc vec infer vector method missing,python machine-learning gensim,,,CC BY-SA 3.0,False,False,True,False,False
6534,6534,32476336,2015-09-09 09:51:02,,lda original output uni gram topic scuba water vapor diving topic dioxide plant green carbon required output bi gram topic topic scuba diving water vapor topic green plant carbon dioxide idea,2015-09-10 04:45:01,2018-11-13 02:02:23,abstract bigram topic instead unigrams using latent dirichlet allocation lda python gensim,nlp text-mining lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
6581,6581,32543235,2015-09-12 20:09:35,,running gensim topic modeling trying get code working know code work friend ran mac computer worked successfully run window computer code give also logging set second line also appear window computer something window need fix order gensim work,,2018-07-24 09:04:32,python gensim memory error,python windows gensim,,,CC BY-SA 3.0,False,False,True,False,False
6650,6650,32744732,2015-09-23 16:23:21,,learning doc vec gensim library able train model creating corpus document note particular document ha two tag namely labeled load model perform get perfect get tag similar labeled would like feedback loop training model give model new document would like know good bad model classification tagging adding document corpus would using doc vec know whether document labeled labeled actually similar one approach mind code random forest classifier function finally feedback process keep validation set tagged correctly feed tagged validation set classifier removing tag save result csv compare result another csv ha correct tag every mismatch add document labeled training set train model repeat validation set approach correct also incrementally train doc vec model let say initially trained doc vec model k tagged doc validation step need model trained k document train model beginning meaning need train model initial k tagged doc would really appreciate insight thanks,2015-09-23 19:44:26,2016-03-28 16:15:32,doc vec best practice feedback loop training model,nlp python-3.4 gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6689,6689,32794087,2015-09-26 05:48:31,,gensim ha document similarity feature inputted query document output similarity particular document document ha index used like approximate version supervised classification know gensim word vec us deep learning involved step,,2015-09-26 05:48:31,gensim document similarity used supervised classification,machine-learning nlp text-processing gensim,,,CC BY-SA 3.0,False,False,True,False,False
6702,6702,32826927,2015-09-28 15:46:29,,word vec model pyspark job summing individual word vector document getting strange discrepancy pyspark result normal result result spark result without spark give array intensity dimension order magnitude look th element computing vector locally give normal vector going wrong using spark doe mess answer communicating result master,,2015-09-28 15:46:29,discrepancy result spark using broadcasted varaibles,python apache-spark pyspark gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6705,6705,32812159,2015-09-27 19:48:10,,installed theano genesim pip install xxx user server side tried import python code error exception compilation failed return status usr bin ld find linclude collect ld returned exit status addition root permission make,,2015-09-27 19:48:10,find linclude server side,python compilation server theano gensim,,,CC BY-SA 3.0,False,False,True,False,False
6737,6737,32796485,2015-09-26 11:05:54,,model build data new sentence run time doe belong trained data set build predict vector sentence model handle unknown word sentence,2015-09-26 11:41:38,2015-09-27 03:59:29,building vector sentence doc vec untrained data set,python machine-learning nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6771,6771,32978429,2015-10-06 19:47:47,,data pipeline work perfectly fine put worker task however put worker dy unexpectedly exit code stage dependency code rather complex minimum example would difficult give gist matter following thing building dictionary text building corpus said text dictionary requires training lda model corpus dictionary requires reason step crash every time put one worker even already completed help would greatly appreciated edit example logging info trainlda task still two task require trainlda earlier task finished correctly substituted trainlda argument output would readable additional info statement put help u know happening deb,2015-10-07 23:03:14,2019-05-13 21:00:35,python luigi died unexpectedly exit code,python text-mining gensim luigi,,,CC BY-SA 3.0,False,False,True,False,False
6788,6788,33070598,2015-10-11 22:03:37,,getting error trying run word vec gensim library python using python window also attached complete stacktrace well read online say issue python x getting python,,2015-10-13 15:32:40,python int large convert c long python,python-2.7 python-3.x machine-learning word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6835,6835,33059671,2015-10-10 22:35:24,,started experiment word vec form gensim using tutorial provide http rare technology com word vec tutorial need need raw output vector write result get word array write get word computer using f,,2015-10-11 07:20:19,get word array word vec gensim,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
6878,6878,33200360,2015-10-18 16:31:42,,got acquainted gensim tried install performed step written page http radimrehurek com gensim install html could install installed python scipy numpy successfully window bit run setup py gensim run please help need gensim immediately tell installation step detail software need installed thanks,2015-10-18 16:43:35,2015-11-13 07:45:53,install gensim window,python numpy gensim,,,CC BY-SA 3.0,False,False,True,False,False
6919,6919,33229360,2015-10-20 06:20:23,,starting python task facing problem using gensim trying load file disk process split lowercase code list dictionary arr contains list word across file use gensim corpus dictionary process list however face error cant understand whats problem little guidance would appreciated,,2020-02-26 18:17:20,gensim typeerror doc bow expects array unicode token input single string,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
7022,7022,33596082,2015-11-08 16:20:09,,gensim word vec model computed python like however need use python try load result error suppose problem difference encoding python python also seems like gensim using pickle save load model way set encoding pickle option model load properly maybe use external tool convert model file recomputing python option take way much time,,2016-04-21 18:25:56,load gensim word vec computed python python,python python-3.x encoding gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
7034,7034,33525173,2015-11-04 15:05:25,,problem want convert list list dataframe setup following list lda document topic probability list list document tuple one five topic probability see earlier question posted stack overflow first element tuple represents topic number second element probability topic probability document note document like rd list five tuples topic probability gensim lda doe output probability topic le probability therefore example like document document le five tuples goal use loop create document topic probability matrix noted missing tuples topic zero need plugged get list figure use panda dataframe function produce final output df failed attempt problem referencing probmatrix receiving following error thank help bonus even better help one problem found gensim lda mentioned doe output probability le even example see earlier post example illustrative topic probability sum document however reality output look like looking instead putting zero unknown topic probability instead make remaining missing topic even probability topic probability document equal example would result probmatrix,2017-05-23 11:50:42,2015-11-05 15:37:54,python convert list list dataframe,python list pandas dataframe gensim,,,CC BY-SA 3.0,False,False,True,False,False
7041,7041,33615029,2015-11-09 17:46:45,,thanks reading taking time think respond using gensim wrapper mallet ldamallet py work like charm need get topic proportion corpus document know model alpha normalized plus alpha contains dirichlet parameter topic proportion correct help much appreciated,,2015-11-10 08:44:01,topic proportion corpus,lda gensim topic-modeling mallet,,,CC BY-SA 3.0,False,False,True,False,False
7056,7056,33638915,2015-11-10 20:24:43,,struggling create iterator query sqlalchemy tried far create table read everything could iterator get class created get iterator doe work overflow although specify break case wondering using generator need feed iterator gensim word vec unfortunately doe take generator thanks advance,2015-11-10 21:09:22,2015-11-11 10:52:51,result sqlachemy query iterator,python iterator sqlalchemy gensim,,,CC BY-SA 3.0,False,False,True,False,False
7093,7093,33702450,2015-11-13 21:59:05,,running anaconda python window installed gensim pyldavis topic modeling note installing pyldavis python window little tricky make sure using scikit bio appear compile window think workaround try reason outlined got pyldavis install however running seems problem import statement pyldavis installed folder return happening try run library call however folder file inside python try inside module import file within module gensim site package go fixing thanks,,2015-11-13 22:22:51,import gensim import file active module root site package folder,python python-2.7 gensim,,,CC BY-SA 3.0,False,False,True,False,False
7162,7162,33828304,2015-11-20 13:47:58,,applying tfidf text document get varied length n dimensional vector corresponding document output vector point represented mean say doe exist vector want apply k mean clustering vector vec vec scikit k mean clustering need vector equal dimension matrix format done,,2015-11-27 17:09:34,k mean clustering n dimensional vector,python scikit-learn k-means gensim,,,CC BY-SA 3.0,False,False,True,False,True
7171,7171,33789541,2015-11-18 20:16:25,,experimenting doc vec module sometime train model trained model output similar document given document follows work well give result way get result limit,,2015-11-19 18:59:15,limit gensim doc vec similar document result set,python-3.x gensim,,,CC BY-SA 3.0,False,False,True,False,False
7186,7186,33808746,2015-11-19 16:02:16,,gensim lda model working would like fit scikit naive bayes classifier similar scikit tfidftransformer shape tfidftransformer sparse numpy matrix post take scikit vectorizer feed gensim model want opposite something like would go assume matrix tfidftransformer fit transform matrix tfidf score word array document like case replace every word score feed matrix classifier really tell lot stuff going hood see edit wa able print first entry numpy array numpy array printed first entry got column left must tfidf score sure right assume wordids document id,2015-11-28 08:14:59,2015-11-28 08:14:59,fit gensim lda scikit naive bayes classifier,python scikit-learn gensim,,,CC BY-SA 3.0,False,False,True,False,True
7192,7192,34021351,2015-12-01 13:15:05,,problem trying import gensim python typing import gensim got following error traceback recent call last file line file library python site package gensim init py line gensim import parsing matutils interface corpus model similarity summarization importerror import name parsing also view init py contains following line bring model class directly package namespace save typing summarizer import summarize summarize corpus keywords import keywords idea solve problem highly appreciated using mac python thank,,2016-06-30 16:24:07,importing gensim mac,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
7197,7197,33929680,2015-11-26 02:31:03,,run gensim model machine core using get logging message say line later see another loging message say run top see python process spawned sleeping e one worker active machine ha core overwhelmed mean ldamulticore running parallel mode,2015-12-11 23:45:39,2016-08-25 12:07:26,gensim ldamulticore multiprocessing,python multiprocessing lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
7198,7198,25272500,2014-08-12 19:26:56,,try move gensim database though window explorer access new location get error say sharding error also know underlying sqlite gensim port sqlite django model,,2014-08-12 19:26:56,gensim sharding python moving database,python django gensim,,,CC BY-SA 3.0,False,False,True,False,False
7205,7205,33989826,2015-11-30 00:30:37,,know question ha asked already wa still able find solution would like use gensim custom data set still figuring format dataset ha look post input basically list list one big list containing list tokenized sentence nltk brown corpus thought input format use command however work little test set understand tried worked work understand work mock data even though ha data structure sentence brown corpus vocab brown sent beginning anyone please tell wrong,,2018-03-07 06:14:11,python gensim runtimeerror must first build vocabulary training model,python gensim word2vec,,,CC BY-SA 3.0,True,False,True,False,False
7215,7215,33976953,2015-11-28 22:05:32,,using gensim word vec library python using pre trained googlenews vector negative bin model word corpus word vector getting keyerror solve problem tried far loading per trained model build word vector training set using average value word vector tweet scale please tell possible add new word pre trained word vec model,2020-06-20 09:12:55,2020-06-17 08:32:24,add missing word vector googlenews vector negative bin pre trained model,python nlp gensim word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
7239,7239,34166369,2015-12-08 21:28:53,,generator function yield stuff trying pas get following error typeerror pas generator sentence argument try iterator generator kind iterator make iterator looking library code seems simply iterate sentence like work fine generator causing error,2015-12-08 21:32:25,2019-08-23 20:38:28,generator iterator,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
7255,7255,34075899,2015-12-03 20:52:29,,trying analyze wikipedia dump file using gensim script python library running command window cmd exe give error microsoft window version c microsoft corporation right reserved thought fix window gensim script ha installed,2015-12-03 21:13:13,2015-12-03 23:04:41,gensim script file directory,python cmd gensim,,,CC BY-SA 3.0,False,False,True,False,False
7261,7261,34057374,2015-12-03 03:28:22,,trying install gensim window python according gensim official installation tutorial gensim depends numpy scipy went download whl file numpy scipy installation used pip install gave error mean find designated module resolve,,2019-07-05 02:20:10,resolve error installing gensim,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
7265,7265,34153708,2015-12-08 10:39:55,,use next code train model procedure check result,,2015-12-08 11:00:02,word use train word vec model must model vocab,python gensim training-data word2vec,2015-12-08 13:09:54,,CC BY-SA 3.0,False,False,True,False,False
7293,7293,34249586,2015-12-13 09:15:04,,currently use gensim reproduce result example google provide problem accuracy test gensim match google result example accuracy capital common country google best result gensim different parameter set big gap code snippet train word vec accuracy using gensim code snippet google demo without change parameter accuracy comparison detail doe anyone could help,2015-12-13 10:04:51,2015-12-14 21:47:22,accuracy test word vec gensim,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
7320,7320,34207097,2015-12-10 16:35:27,,trying learn topic modelling using gensim python library tried many different tutorial including official one question get document wise topic distribution using gensim current output list topic keywords probability shown would like know possible list say document top topic particular document code following,,2017-04-27 14:12:17,print document wise topic gensim,python gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
7361,7361,34396300,2015-12-21 12:59:25,,installed gensim macbookpro yosemite using anconda installation wa working without error message tried run code tutorial appears error calling serialization complete error message downloaded tar file performed error occurred fix,,2016-01-03 21:48:17,gensim installation yosemite using anaconda,python python-2.7 anaconda gensim,,,CC BY-SA 3.0,False,False,True,False,False
7381,7381,34309428,2015-12-16 10:23:10,,created lda model using gensim wanted visualise using pyldavis library getting anyone help suggest alternative thanks advance,,2015-12-17 13:04:08,run pyldavis getting error importerror import name pcoa,python scikit-learn gensim skbio,,,CC BY-SA 3.0,False,False,True,False,True
7414,7414,34427678,2015-12-23 02:24:53,,use word vec module containing ton chinese character module wa trained coworkers using java saved bin file installed gensim try load module following error occurred tried load module python failed way load module gensim thanks,2015-12-30 10:59:30,2017-04-27 09:55:13,utf decode error loading word vec module,python nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
7433,7433,34540518,2015-12-31 03:14:20,,suppose possibly large corpus feature running lsi original data gensim need corpus train classifier using scikit learn however need first convert corpus numpy array corpus creation classifier trainer done two different script problem collection size expected grow stage already enough memory gb machine convert order work around problem converting one vector another time slow considered dumping corpus svmlight format scikit learn load would probably mean need load everything memory anyway efficiently convert gensim corpus numpy array scipy sparse matrix,,2015-12-31 04:00:02,convert gensim corpus numpy array scipy sparse matrix efficiently,python scikit-learn gensim,,,CC BY-SA 3.0,False,False,True,False,True
7440,7440,34384186,2015-12-20 18:14:30,,trying use gensim topic modelling print similarity query get id value instead actual string print string similarity query code using,,2015-12-20 18:14:30,gensim similarity query return id value vector string,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
7511,7511,34721984,2016-01-11 12:49:10,,trying word vec using gensim word vec library question remove stopwords input text based initial experimental result could see word like stopwords popping see anywhere referring stop word removal necessary word vec doe word vec supposed handle stop word even remove must pre processing thing like topic modeling almost must stopword removal,2016-01-12 06:25:02,2019-01-06 08:08:43,stopword removing using word vec,nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
7514,7514,34634367,2016-01-06 13:30:21,,fyi try import gensim module django view py server got stuck restful apis working response comment view py back normal problem debug django situation django version gensim version update import gensim django shell issue django,2016-01-06 15:42:22,2017-06-15 02:43:23,get stuck importing gensim django view py,python django gensim,,,CC BY-SA 3.0,False,False,True,False,False
7517,7517,34637242,2016-01-06 15:52:28,,wa reading experiment english wikipedia tutorial noticed many topic generated lsa lda contained multi word term clearly concatenated e g northamerica hockeyarchives could someone indicate take place looked gensim script make wiki gensim corpus wikicorpus genesis utils,,2016-01-06 15:52:28,doe gensim handle multi word term processing wikipedia corpus,nlp lda gensim topic-modeling lsa,,,CC BY-SA 3.0,False,False,True,False,False
7541,7541,34754547,2016-01-12 21:58:53,,using try save location sends error note exists another name tutorial correct way want achive following store corpus model like lda getting run,2016-01-15 06:07:39,2018-10-12 09:32:29,gensim saving corpus,amazon-s3 gensim,,,CC BY-SA 3.0,False,False,True,False,False
7549,7549,34831551,2016-01-16 20:05:51,,lda model generates different topic everytime train corpus setting lda model always initialized trained exactly way word vec model setting random seed constant would different run dataset produce model strangely already giving vector different instance true default random seed fixed default random seed number testing small dataset true random seed fixed different run data return vector link canonical code documentation would much appreciated,2017-05-23 12:18:32,2020-08-07 12:22:37,ensure gensim generate word vec model different run data,python random gensim word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
7551,7551,34765622,2016-01-13 11:34:03,,try load model anything always get figure wrong sure saving model incorrectly loading incorrectly,2016-01-13 12:08:47,2017-01-01 21:27:27,attributeerror projection object ha attribute u gensim python lsi,python-2.7 tf-idf gensim,,,CC BY-SA 3.0,False,False,True,False,False
7577,7577,34866830,2016-01-19 00:59:56,,using method get word similar given word afaik doe calculate cosine similarity given word word dictionary inspecting word score see word negative score list doe mean word ha opposite meaning given word also using cosine similarity doe get negative value cosine similarity varies two document,,2016-01-19 11:31:46,word vec similar function,text-mining gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
7597,7597,34898059,2016-01-20 10:55:02,,upgraded gensim facing issue inferencing doc vec code performing inference doc vec model training inference done using version code give result shown doc vec model training inference done using version code gave result like get document label instead number,2016-01-20 11:05:00,2016-01-28 21:42:29,doc vec inference gensim,gensim,,,CC BY-SA 3.0,False,False,True,False,False
7604,7604,34948650,2016-01-22 14:07:52,,using function gensim python convert document vector example usage interpret parameter know set length output vector doe mean instance increase difference,,2016-01-28 08:41:05,interpret size parameter doc vec function gensim,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
7641,7641,34923628,2016-01-21 12:18:15,,twitter corpus using build sentiment analysis application corpus ha k tweet hand labelled negative neutral positive represent text using gensim word vec pretrained vector word mapped dimension tweet add word vector get single dim vector thus every tweet mapped single vector dimension visualizing data using sne tsne python package see attached image red point negative tweet blue point neutral tweet green point positive tweet question plot clear separation boundary among data point assume also case original point dimension e point overlap sne graph also overlap original space vice versa,2016-01-21 12:34:10,2016-01-21 13:49:47,sne high dimension data visualisation,python machine-learning nlp scikit-learn data-analysis,,,CC BY-SA 3.0,False,False,True,False,True
7673,7673,35117491,2016-01-31 18:17:52,,using pre trained google news dataset getting word vector using gensim library python loading model converting training review sentence word vector word vec process get lot error word corpus model problem retrain already pre trained model e g googlenews vector negative bin order get word vector missing word following tried trained new model training sentence worked problem really small dataset le resource train large model second way looking extend already trained model googlenews vector negative bin possible good way use please help,2016-03-14 13:10:58,2016-10-24 11:03:12,possible train word vec model e g googlenews vector negative bin corpus sentence python,python nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
7705,7705,35121779,2016-02-01 01:33:53,,wa going website yesterday http rutumulkar com blog word vec author made use file script noticed specify location file wa wondering wa able run unable run way run file thank script follows question line author call put text file specify location text file python able detect,2016-05-17 17:25:49,2016-05-17 17:25:49,run gensim code need text file,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
7754,7754,35252743,2016-02-07 11:13:24,,trying clean text keeping alphabet number however text still contains character function one result get nutone central vacuum system ell ohio steel tandem natural synthetic turf sweeping system unique home design x su casa black surface mount outswing steel security door expanded metal screen unique home design x su casa black surface mount outswing steel security door expanded metal screen unique home design x su casa black surface mount outswing steel security door expanded metal screen mp global best x x acoustical recycled fiber underlayment film laminate wood mp global best x x acoustical recycled fiber underlayment film laminate wood grip rite x bright steel ring shank common nail lb pack error get,2016-02-07 12:16:23,2019-12-12 17:25:38,unicodedecodeerror cleaning text data,python regex beautifulsoup nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
7775,7775,35276944,2016-02-08 18:43:09,,building rnn model kera sentence word embeddings gensim initializing embedding layer glove vector since sequential model sentence variable length vector zero padded e g let say glove vector dimension zero index masked ignored get proper indexing word add extra column glove matrix dimension seems like unnecessary vector model estimate unless elegant way thanks,,2016-03-12 18:49:05,index embedding layer zero padding kera,deep-learning gensim keras,,,CC BY-SA 3.0,False,False,True,False,False
7812,7812,35372917,2016-02-12 22:01:00,,using gensim ldamulticore perform lda around small document around character given worker argument top show using process discussion around might slow reading corpus like gensim ldamulticore multiprocessing http github com piskvorky gensim issue us mmcorpus although corpus completely memory machine large ram gb loading corpus memory take around gb even ldamulticore using process created corpus able understand limiting factor,2017-05-23 12:25:52,2019-11-15 10:52:37,gensim ldamulticore multiprocessing properly using worker,python lda gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
7835,7835,35398153,2016-02-14 21:23:16,,hello stack overflow community following problem currently mining database support ticket would like use e g doc vec check similarity ticket however text contains huge string produced compiler command would clever use string single word model good practice doe anyone experience something like best thorsten,,2016-02-14 21:23:16,nlp compiler output system error message,python nlp nltk gensim,,,CC BY-SA 3.0,True,False,True,False,False
7846,7846,35470805,2016-02-18 00:56:37,,looking calculate similarity document using gensim python want way able restrict calculation subset corpus specifically document associated year want way computing similarity search document document value variable see instruction e g http radimrehurek com gensim simserver html associate additional variable document turn restrict similarity document indeed trying may feasible question thus possible way achieve use multiple corpus,,2017-04-07 20:09:15,restrict gensim similarity calculation subset corpus,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
7881,7881,35502363,2016-02-19 09:57:58,,new lda three question would like classify text tag lda first filter word used one user machine tag tag containing digit tag frequency le calculate amount topic elbow method get memory error third question amount topic suggested elbow method filtered tag overcome memory issue would need apply bigger datasets future use tf idf preprocessing step lda filter useless tag make sense think understand going exactly lda doe make sense validate topic quality lsi understand lsi method dimensionality reduction use apply k mean see cluster topic actually look like cluster honest really understand exactly visualising memory issue trying create matrix ha value every unique term term document get zero sparse matrix around unique term every document ha memory issue arise converting np array guess optimize matrix somehow following code took calculating percentage variance measure k mean idea question highly appreciated,2017-05-23 10:29:31,2016-02-19 09:57:58,necessary appropriate calculate tf idf preprocessing lda gensim,python tf-idf lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
7885,7885,35609171,2016-02-24 17:36:39,,today started writing script train lda model large corpus minimum sentence using gensim library current code using running script small corpus sentence realized need gb ram try run larger corpus fails memory issue problem obviously due fact loading corpus using command think way would need calling ldamodel method searched solution problem could find anything helpful would imagine common problem since mostly train model large corpus usually wikipedia document already solution idea issue solution,2016-02-24 18:53:38,2019-12-31 20:10:36,memory efficient lda training using gensim library,lda gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
7902,7902,35591567,2016-02-24 01:22:29,,believe question easy new python think blinding bit downloaded wikipedia dump explained preparing corpus http radimrehurek com gensim wiki html ran following line code line code taken link separate script done text analysis result text analysis number representing index particular article wikidocs corpus problem know print text article obvious thing try return error tried thing stuck thanks help,2016-02-24 01:37:59,2016-02-24 02:35:06,print wikipedia article title gensim wikicorpus,python nlp wikipedia gensim text-analysis,,,CC BY-SA 3.0,False,False,True,False,False
7904,7904,35596031,2016-02-24 07:39:48,,training word vec model using python gensim find number word model vocabulary,2019-02-26 18:28:30,2019-02-26 18:28:30,gensim word vec find number word vocabulary,python neural-network nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
7921,7921,35681403,2016-02-28 10:35:06,,trying find new concept corpus konkani language trained two model domain specific corpus newspaper corpus used gensim word vec train model however unable get term similar meaning close proximity vector space close word show relation synonym similarity good random word wrong,2017-03-21 21:25:35,2017-03-21 21:25:35,finding concept large corpus using word embeddings,gensim word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
7937,7937,35716121,2016-03-01 06:30:21,,preprocessing corpus wa planing extarct common phrase corpus tried using phrase model gensim tried code giving desired output code output come tried print vocab train data see bigram working test data going wrong,,2016-03-02 13:39:57,extract phrase corpus using gensim,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
7954,7954,35738391,2016-03-02 04:15:29,,using hdp hierarchical dirichilet process package gensim topic modelling software gensim hdp implementation expects user provide number topic advance documentation defines top level truncation level hdp determine number topic implementation hdp detect number topic help appreciated,2016-03-02 04:28:02,2016-03-02 13:17:04,hdp hierarchical dirichilet process detect number topic data,machine-learning data-mining gensim topic-modeling unsupervised-learning,,,CC BY-SA 3.0,False,False,True,False,False
7956,7956,35616088,2016-02-25 00:40:27,,looking link module thinking combine api train paragraph vector link actually provides following clean example model understanding distributing work gradient descent worker batch recombining updating master replace document vector trained word vector looked source code link following field model instance comparing source code gensim model word vec link following field went missing doc vec model model syn model syn neg think touch lockf vector seem used training done new data point come therefore code something like deepdist import deepdist gensim model doc vec import doc vec labeledsentence pyspark import sparkcontext sc sparkcontext assume dataset format char id followed doc content line per doc corpus sc textfile data set map lambda labeledsentence word split label def gradient model sentence executes worker syn doctag syn model syn copy model docvecs doctag syn copy previous weight model train sentence return syn model syn syn doctag syn model docvecs doctag syn doctag syn def descent model update executes master model syn update syn model docvecs doctag syn update doctag syn deepdist doc vec corpus collect dd dd train corpus gradient descent print dd model similar positive woman king negative man missing anything important example care model syn mean right model lockf locked matrix training ok use lambda labeledsentence word split label parse dataset assuming document one line prefixed padded digit id suggestion contribution appreciated write blog post summarize result mentioning contributor potentially help others train doc vec model scaled distributed system without spending much dev time trying solve solving thanks update apology get implement better option nowaday deepdist maintained awhile please read comment insist trying idea moment reminded proceeding risk also someone know deepdist still work please report back comment would help reader,2018-06-13 07:40:52,2019-03-03 20:34:51,doc vec pyspark gensim doc vec deepdist,apache-spark pyspark gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
7967,7967,35778075,2016-03-03 16:46:19,,use gensim package topic modelling idea understand topic flickr tag till using code document tag basically train lda document print probable word every topic correct train data part document use corpus lda lda corpus order apply trained model unseen document result different every time run model doe mean amount topic correct best way evaluate result,,2017-05-29 18:11:11,lda tag gensim,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
7972,7972,35721503,2016-03-01 11:20:22,,need train word vec representation tweet using gensim unlike tutorial code seen gensim data raw ha already preprocessed dictionary text document containing k word incl unknown token eol token tweet saved numpy matrix index dictionary simple example data format seen dict txt tweet unknown eol unsure handle index representation easy way convert list index list string e read word vec model however must inefficient gensim try look internal index used e g load data create word vec representation efficient manner using gensim,2016-03-12 19:02:16,2016-11-25 15:52:52,gensim word vec predefined dictionary word index data,python nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
7990,7990,35727272,2016-03-01 15:46:52,,tried install gensim word vec project stuck point like research realize sth wrong scipy tried upgrade since installed long time ago repetitively show error tried sudo install libblas dev still show error guess core problem essentially stuck long time could someone help please,,2016-03-01 15:46:52,upgrading scipy came across storing complete log pip log,python scipy gensim,,,CC BY-SA 3.0,False,False,True,False,False
8053,8053,35900953,2016-03-09 19:33:30,,trying run distributed lda example described http radimrehurek com gensim dist lda html created set document following tutorial http radimrehurek com gensim dist lsi html inflat ing corpus document repeating document suggests using python numpy keep getting following error ran distributed lsi example ran fine reason seem get lda work tried changing line usr lib python site package gensim model ldamodel py error went away got warning could someone explain done wrong change file correct running lda differently,,2018-04-11 09:04:08,trouble running gensim lda,python numpy lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
8072,8072,35914287,2016-03-10 10:48:09,,use ann predict word word input output word vector know get word output ann way gensim using,2016-03-10 11:12:33,2016-08-01 09:48:57,word vec get word vector,machine-learning gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8074,8074,35985851,2016-03-14 11:07:17,,installed gensim python library executed command executed without error tried import test gensim using command showed following error traceback recent call last file line gensim import test importerror import name test python site package gensim folder help would highly appreciated,2020-01-30 00:04:19,2020-01-30 00:04:19,gensim import test importing successfully,python python-3.4 gensim,,,CC BY-SA 4.0,False,False,True,False,False
8075,8075,35985951,2016-03-14 11:12:35,,using gensim library python using training word vector model recently wa looking initializing model weight pre trained word vec model googlenewdataset pretrained model struggling couple week searched gesim function help initialize weight model pre trained model weight mentioned know function thing please help,,2018-02-15 15:48:25,initialize new word vec model pre trained model weight,python gensim word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
8089,8089,35917500,2016-03-10 13:10:30,,playing around linan qiu example word vec implementation github final goal analyse bunch tweet problem facing idea extract positive negative polarity percentage implementation word vec code delivers accuracy rate presume must check predicted value po neg known value case entire txt filled either po neg approach would get predicted po neg rating per document case per review course simply add number rating mean divide po neg get percentage percentage would cover document file polarity could perhaps also calculated trying figure po neg first would anyone idea get predicted rating post vectorisation code rather similar cough standard used thank much,2016-03-10 13:51:35,2016-04-21 04:39:32,getting positive negative percentage word vec,python sentiment-analysis gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8099,8099,35981178,2016-03-14 06:49:59,,know word vec gensim compute similarity word want compute word similarity using tf idf lsa gensim note computing document similarity using lsa gensim easy http radimrehurek com gensim wiki html,2016-03-14 10:31:31,2016-03-14 10:31:31,compute word similarity using tf idf lsa gensim,python nlp tf-idf gensim lsa,,,CC BY-SA 3.0,False,False,True,False,False
8111,8111,36013137,2016-03-15 13:47:16,,objective find vector representation phrase code work partially bigram using word vec model provided gensim library problem word vec model seemingly automatic pruning bigram e tried adjusting various parameter seem affect pruning p aware bigram look need represented using underscore instead space e proper way call function would,,2016-03-16 11:49:08,gensim word vec unexpectedly pruning,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8117,8117,36013211,2016-03-15 13:50:36,,read kaggle word vec example http www kaggle com c word vec nlp tutorial detail part fun word vector understand come model vocabulary length different word vector length every cell word vector represent relation word vocabulary word ha relation word doe cell word vector represent really appreciate help,,2016-03-18 04:49:48,doe word vec vocabulary length different word vector length,machine-learning text-classification gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8119,8119,36014333,2016-03-15 14:37:41,,wa trying use gensim plain text extraction pdfs however encountered problem using library followed instruction website seemed work properly also downloaded python ide called pycharm trying quick example got error pycharm logging activation ha error line working ide hint word three word think maybe need something try link gensim reference library totally newbie python hope someone tell someone ha worked gensim may also help problem idea way using python project well,,2017-07-26 00:52:50,include gensim pycharm,python python-3.x ubuntu pycharm gensim,,,CC BY-SA 3.0,False,False,True,False,False
8122,8122,36113487,2016-03-20 12:09:37,,pc nvidia gpu installed openblas trying train word vector using gensim word vec implementation set number worker run top command see cpu usage showing doe mean one core utilised program doe show speed code snippet,2016-12-02 16:18:15,2016-12-02 16:18:28,word vector using gensim word vec implementation gpu doe show speed,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8127,8127,36032410,2016-03-16 10:04:50,,use pycharm install gensim package installment failed error message listed also use pip install also failed error message listed thank help sorry english pool,,2016-05-10 02:47:20,python install gensim mac,python macos python-2.7 pycharm gensim,,,CC BY-SA 3.0,False,False,True,False,False
8131,8131,36034454,2016-03-16 11:31:27,,using word vec gensim google pretrained vector trained google news noticed word vector access direct index lookup object unit vector however method non unit vector used instead normalised version used undocumented property contains unit vector larger vector scaled version unit vector given word similarity comparison word vec done cosine similarity obvious length non normalised vector mean although assume mean something since gensim expose rather exposing unit vector length non normalised word vec vector generated meaning calculation doe make sense use normalised vector use non normalised one,,2018-05-27 11:38:54,meaning doe length word vec vector,python nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8141,8141,36001230,2016-03-15 01:42:14,,know exists already implementation pv dbow paragraph vector python gensim interested knowing implement explanation official paper pv dbow follows another way ignore context word input force model predict word randomly sampled paragraph output reality mean iteration stochastic gradient descent sample text window sample random word text window form classification task given paragraph vector according paper word vector stored pv dbow said work similar skip gram word vec skip gram explained word vec parameter learning skip gram model word vector mapped hidden layer matrix performs mapping updated training pv dbow dimension hidden layer dimension one paragraph vector want multiply word vector sampled example paragraph vector size original representation word size vocabulary size x mapping performed get right size paragraph dimension x hidden layer mapping performed word vector stored assume word paragraph representation size hidden layer equation word vec parameter learning,2020-01-21 18:34:01,2020-01-21 18:34:01,doc vec pv dbow implemented,machine-learning nlp neural-network gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
8143,8143,36132650,2016-03-21 13:42:51,,large corpus text represented list text text text textn also list name text text name text name textn name turn data mallet corpus could possible use lda gensim,2016-03-21 14:26:16,2016-03-21 14:26:16,transform list text mallet corpus,python nlp lda gensim mallet,,,CC BY-SA 3.0,False,False,True,False,False
8170,8170,36019864,2016-03-15 19:00:34,,sometimes half hour running following script get segmentantion fault error info progress sentence processed word keeping word type segmentation fault using mint vm vmware workstation using word vec version gensim py linux x egg python coding utf import nltk import io import gensim logging import nltk logging basicconfig format asctime levelname message level logging info class mysentences object sentence mysentences home arie extracted model gensim model word vec sentence saw memory monitor look crash time every free tue mar mem buffer cache swap every free tue mar mem buffer cache swap,,2016-03-15 19:00:34,segmentation fault python gensim,python linux segmentation-fault virtual-machine word2vec,,,CC BY-SA 3.0,True,False,True,False,False
8199,8199,36160322,2016-03-22 16:43:32,,implementing tutorial gensim http rare technology com deep learning word vec gensim includes line sentence word vec text corpus tmp text however run program get error text doe exist looking code see text corpus method accepts argument type object instruction indicate passed http mattmahoney net dc text zip manually download file attempt pas resulting imbd uncompressed data set told permission denied doe anyone insight problem suppose downloaded imdb dataset wa suppose pointer code automatically,,2016-03-22 16:53:18,tmp text gensim,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
8208,8208,36256584,2016-03-28 05:35:38,,unable install python package always throw error package using used work gensim tried insttall unzip package go throw tried install ruamel yaml still work help failing solve update moving root sudo su worked,2016-03-30 09:10:58,2019-08-10 20:22:11,install python package gensim ubuntu,python pip gensim ruamel.yaml,,,CC BY-SA 3.0,False,False,True,False,False
8211,8211,36263594,2016-03-28 13:41:49,,using gensim ubuntu version word vec model consistent every time build model based exact sentence parameter still different presentation word code stole initial post also tried set seed fixed int didnt seem help also tried reinstall gensim also didnt help idea stabilize model,2016-03-28 15:17:46,2017-03-22 10:38:11,gensim word vec giving inconsistent result,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8222,8222,36223864,2016-03-25 16:25:17,,using doc vec corpus million title train corpus using following code everything seems train properly able infer vector using title similar encounter problem however try use vector seems though document missing final model e keyerror sent checked gensim forum stackoverflow suggestion could find wa ensure min count still issue,2016-03-25 16:26:08,2018-03-23 14:40:42,keyerror doc vec model even min count set training,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8246,8246,36250297,2016-03-27 17:20:41,,given data frame including item corresponding review text want map top frequent word resulting data frame like bag word vector highly preferred thanks lot edit tried ayhan answer successfully changed review text form denotes word id ha occurred time document like transfer vector like thank advance,2016-04-03 16:26:24,2016-04-03 16:48:13,map word data frame integer id python panda gensim,python pandas gensim,,,CC BY-SA 3.0,False,False,True,False,False
8250,8250,36192132,2016-03-24 02:14:38,,working project need apply topic modelling set document need create matrix dt matrix number document number topic dt ij contains number time word document di ha assigned topic tj far followed tut http rstudio pub static amazonaws com b c b db html new gensim far created document list preprocessed tokenized document used corpus dictionary create id term dictionary id word convert tokenized document document term matrix generated lda model get topic get matrix mentioned using matrix calculate similarity document topic sim b dt dt b,,2017-06-17 01:00:29,gensim lda create document topic matrix,python lda gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
8261,8261,36360367,2016-04-01 15:39:02,,new doc vec use case could get advice start save lot time data stream text data tweet continuously coming time clustering tweet wa thinking using doc vec reduce text content fixed size vector use compare document case text data getting accumulated time still used doc vec may learn model may could use large corpus wikipedia large newscorpus train doc vec model suggestion help thanks advance,,2016-04-05 00:37:56,doc vec used text data incrementally increasing,twitter text gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8290,8290,36324016,2016-03-31 04:13:04,,totally new python gensim trying use word vec gensim python window data csv contains k row text text either complete incomplete sentence including word may contain number facing error idea reason error help truly appreciated,,2016-04-01 04:51:41,error performing word vec python,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8293,8293,36328261,2016-03-31 08:39:37,,getting following error able figure gensim cant imported tried reimporting gensim creating virtual environment didnt work well new python please generous code output pip freeze also checked version io py exist,2016-03-31 09:13:59,2016-03-31 17:12:22,importerror import name bytesio eclipse,python lda gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
8296,8296,36371591,2016-04-02 09:37:58,,using window python installed nltk numpy scipy gensim using wheel file url http www lfd uci edu gohlke pythonlibs screenshot installed module running statement getting import error please help really need,2016-04-02 17:08:09,2016-04-02 17:08:09,nltk installation importerror dll load failed specified module could found,python installation scipy nltk gensim,,,CC BY-SA 3.0,True,False,True,False,False
8305,8305,36315770,2016-03-30 17:31:01,,may use word vec implementing part speech po tagging similar problem label sequencing feel may address problem clustering wa curious generally good lead discussion would nice python example preferably gensim learn may great may word vec implementation,,2016-03-30 17:31:01,word vec po tagging,machine-learning nlp nltk gensim word2vec,,,CC BY-SA 3.0,True,False,True,False,False
8315,8315,36397798,2016-04-04 08:29:35,,training sentence generally warning nature goal predict weather incoming sentence warning message gone sentiment analysis using doc vec according understanding considered newly arriving sentence predict positive negative according experience found output vector sentence dependent sentence well mean directly use model generate vector newly arriving sentence please anyone help thanks,,2016-04-05 21:33:51,possible use gensim doc vec classification,nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8336,8336,36509957,2016-04-08 21:55:54,,trying experiment gensim doc vec using following code far understand tutorial work however give attributeerror list object ha attribute word wrong help please thank using python gensim,2016-04-11 11:04:55,2016-04-14 08:23:41,gensim doc vec give attributeerror list object ha attribute word,python-3.x gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8341,8341,36535206,2016-04-10 20:30:12,,wa trying build entity resolution system entity various literature reference defined scope would consider ambiguity entity beyond entity category taking oxford oxford university different oxford place previous one first word organization entity second one entity location task construct one resolution algorithm would extract resolve entity working entity extractor first place second place try relate coreference found various literature like seminal work trying work decision tree based algorithm feature like distance pronoun j pronoun string match definite noun phrase demonstrative noun phrase number agreement feature semantic class agreement gender agreement proper name alias apposition etc algorithm seems nice one enities extracted hidden markov model hmm could work one entity recognition system hmm trying work coreference well entity resolution system wa trying feel instead using many feature use annotated corpus train directly hmm based tagger view solve relationship extraction like would wrong made experiment around word early result seem encouraging support one colleague trying insert semantic information like persuspol loccitus popersm etc person u politics location city u possessive person male tagset incorporate entity disambiguation one go feeling relationship extraction would much better please see new thought got good result naive bayes classifier also sentence predominately one set keywords marked one class one may suggest different approach please feel free suggest use python x window try use library like nltk scikit learn gensim panda numpy scipy etc thanks advance,2016-04-12 17:47:28,2016-04-12 21:58:08,name entity resolution algorithm,python algorithm machine-learning nlp,,,CC BY-SA 3.0,True,False,True,False,True
8361,8361,36374414,2016-04-02 14:18:38,,let make question clearer using python train word embedding model based understanding model training essence machine learning issue train neural network via prediction task example select parameter train skip gram model model trained predicting context word target word model well trained word vector obtained model understanding correct since fact machine learning process training goal perform well prediction task loss function training model supposed make loss low possible know model loss value given set parameter metric know understand model hope made question clear word want evaluate model output google test set http word vec googlecode com svn trunk question word txt want understand model simple machine learning problem training process would possible,2016-04-03 15:27:59,2016-04-03 15:27:59,python word vec understand trained model detail,python model gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8362,8362,36491071,2016-04-08 03:35:44,,text mining tool easy tutorial active community found popular sure one start,,2016-04-08 09:19:31,easy tutorial tool support text classification clustering topic modeling,weka text-mining gensim topic-modeling mallet,,,CC BY-SA 3.0,False,False,True,False,False
8377,8377,36462394,2016-04-06 21:08:55,,want use gensim convert wikipedia dump plain text using script use give error end doe anybody know going,2016-04-07 01:48:40,2017-05-26 12:09:03,convert wikipedia dump text using python gensim script make wiki,python wikipedia gensim,,,CC BY-SA 3.0,False,False,True,False,False
8421,8421,36578341,2016-04-12 15:54:13,,use similarity similarity gensim use similarity matrixsimilarity told myprogram work okay input content le line line go build index corpus tfidf,2018-06-05 12:18:54,2018-06-05 12:18:54,use similarity similarity gensim,python gensim cosine-similarity,,,CC BY-SA 3.0,False,False,True,False,False
8428,8428,36653882,2016-04-15 17:56:37,,trying find important word corpus based tf idf score following along example http radimrehurek com gensim tut html based tf idf score getting updated iteration example word computer based http radimrehurek com gensim tut html ha tf idf score doc doc word graph ha tf idf score doc doc doc currently getting final tf idf score word better way thanks advance,,2016-05-03 05:52:54,getting tf idf score word using gensim,python tf-idf gensim,,,CC BY-SA 3.0,False,False,True,False,False
8486,8486,36673316,2016-04-17 06:18:13,,generating topic yelp data set customer review using latent dirichlet allocation lda python gensim package generating token selecting word length review using allow u filter noisy word length le creating corpus document filtering word effect performance lda algorithm,2017-02-04 19:22:46,2019-04-12 23:37:18,latent dirichlet allocation lda performance limiting word size corpus document,python tokenize lda gensim corpus,,,CC BY-SA 3.0,False,False,True,False,False
8490,8490,36763582,2016-04-21 08:10:31,,looking efficient way creating similarity vector single sentence list sentence trivial way iterating list sentence detect similarity single sentence one sentence list solution slow looking faster way final goal detect really similar sentence list sentence one checking go next sentence solution right iv e tried put list sentence dictionary set improvement term time minor came across solution based linux package relevant,2016-04-21 08:29:00,2016-04-25 07:52:27,find similarity sentence list sentence,python nlp deep-learning gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8501,8501,36780138,2016-04-21 20:47:16,,trying learn understand doc vec following tutorial input list document e list list word code look like getting unicode error tried googling error good somebody please help understand going wrong thank,,2017-09-22 08:06:08,doc vec taggedlinedocument,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
8515,8515,36885223,2016-04-27 09:07:25,,trying use gensim topic classification already feature word multiple document following form also term frequency matrix sparse form dict wa trying train gensim lda get following error tutorial http radimrehurek com topic modeling tutorial topic modeling html seems like look okay sparse matrix form look bit different corpus tutorial corpus print next iter mm corpus think,,2016-04-27 09:07:25,create gensim corpus term frequency matrix collection string,nlp gensim corpus word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8529,8529,36757409,2016-04-21 00:13:12,,small experiment tweet input document train word vec input tweet find top similar word particular word concern run word vec time parameter inspect top similar word give set word weight also afaik word vec initializes random weight beginning giving output different run,,2016-04-21 06:24:59,word vec similar word return output different run,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8540,8540,36815038,2016-04-23 18:52:33,,ready go word vec model already trained serialized csv file like know load word vector model use train paragraph doc vec model doc vec tutorial say load model form idea actually mean c text format first place important load word vec model use doc vec training build vocabulary word vec model,2016-04-23 19:54:15,2016-07-29 02:38:08,load pre trained model gensim train doc vec,python gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
8548,8548,36790867,2016-04-22 10:08:03,,gensim documentation size defined window maximum distance current predicted word within sentence mean looking context go beyond sentence boundary right wa created document several thousand tweet selected word selected similar word using randomly shuffle tweet input document experiment without changing word vec parameter got different set similar word really understand happens gon na look sentence level information anyone explain edit added model parameter graph used model parameter graph draw graph wa ran word vec parameter original document shuffled document took top two bar word specific query word calculated jaccard similarity score two set word iter seems iteration increase lesser lesser similar word two set word got running word vec really understand happening going,2016-04-27 10:47:17,2016-04-27 10:47:17,gensim word vec changing input sentence order,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8558,8558,36909819,2016-04-28 08:55:36,,using sklearn cluster kmean python trying cluster data plot graph vector size code kmean computing pairwise distance mean create matrix pairwise distance x think due got memory error pl suggest scalable k mean clustering algorithm large dataset tool available purpose import program directly sklearn cluster kmean minibatchkmean directly import program thanks,,2016-04-28 08:55:36,k mean minibatchkmean python memory,python memory-management cluster-analysis k-means gensim,,,CC BY-SA 3.0,False,False,True,False,True
8566,8566,36913218,2016-04-28 11:26:14,,running lda using gensim getting strange result perplexity finding perplexity topic diff increase number topic increase expecting decline tried lot different number topic also played around alpha symmetric auto keep getting result document word document small lda work try increase amount training data running k increase number pass look like ha converged thanks,,2016-04-28 11:26:14,lda gensim strange value perplexity,lda,,,CC BY-SA 3.0,False,False,True,False,False
8598,8598,36940334,2016-04-29 13:59:32,,installed python library numpy scipy required successful installation gensim stated http radimrehurek com gensim install html used wheel file http www lfd uci edu gohlke pythonlibs installation window bit machine python running certain compatibility issue error command python setup py egg info failed error code c user appdata local temp pip build zxq k smart open occurs pip installation way installation git repo wa unsuccessful trying import git repo p,2016-04-29 14:05:08,2016-05-02 13:32:27,installation problem gensim library python http www lfd uci edu gohlke pythonlibs,python git numpy scipy gensim,,,CC BY-SA 3.0,False,False,True,False,False
8600,8600,36958388,2016-04-30 18:05:48,,would like use genism doc vec model classification task however seems like gensim implementation doc vec requires see document train test build vocabulary training model otherwise get keyerror want get document vector document wa present building vocabulary wonder understanding correct practice one doe access test data time training way update vocabulary test time able get document representation test document,,2016-05-28 19:27:46,getting paragraph representation unseen paragraph doc vec,classification gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
8623,8623,36900356,2016-04-27 20:35:46,,thought may discussed somehow find answer topic generated using gensim lsi customer survey question doe minus plus sign front word mean generated topic could generated determine might optimal number topic example maybe statistically third topic everything else trivial suggestion appreciated interest lower rate rate good service good service interest lower rate rate great easy reward use service like rate rate great high lower easy great easy rate rate use high,,2016-10-14 00:55:22,interpret gensim topic properly,gensim,,,CC BY-SA 3.0,False,False,True,False,False
8633,8633,37049640,2016-05-05 11:38:23,,want plot gensim word vec model kind word galaxy like http www anthonygarvan com wordgalaxy flashing single dot entering name search field pressing submit button fairly new python stuff actually understand curdoc documentation example http github com bokeh bokeh tree master example app movie code help thank ffodwindow,,2016-05-05 11:38:23,pointing single dot text input,python plot bokeh word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8636,8636,37053011,2016-05-05 14:17:52,,gensim word vec input list sentence however tensorflow word vec input list word concatenate sentence together way separate sentence constructing target word context word pair using following code http github com tensorflow tensorflow blob r tensorflow model embedding word vec py,,2017-07-09 18:12:28,tensorflow separate sentence running word vec model,tensorflow word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8659,8659,36989108,2016-05-02 18:25:11,,experimenting word vec gensim python implementation make model accesible website need flask defined form form py like view py look like execute run py go http localhost change input click submit button get answer default input doesnt send input thanks help sorry english ffodwindow,,2018-08-29 19:22:13,getting data wtforms,python input flask wtforms word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8677,8677,37101671,2016-05-08 15:42:48,,piece code print single sentence output something like need shuffle word training save model sure whether coding right way end exception would like ask shuffle word,2016-05-08 16:51:29,2016-05-09 08:34:03,shuffle word word vec,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8679,8679,37196520,2016-05-12 20:10:03,,sample sentence want run doc vec model end goal matrix size num sentence num feature using gensim package thought would give list array first array corresponding vector sentence second array corresponding vector sentence etc instead got length get get output desired matrix dimension example saw correct answer say bottom document id whose vector want make even confused seems say indexing matrix row document vector,2017-05-23 11:53:08,2017-01-18 19:47:34,understanding output doc vec gensim package,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8704,8704,37089933,2016-05-07 14:50:12,,im trying install gensim using pip getting post suggested running report successfully installed package however running gensim pip install command give first error idea might happening,2016-05-07 16:38:54,2017-05-09 07:13:31,error installing gensim could import setuptools required install source distribution,python pip gensim,,,CC BY-SA 3.0,False,False,True,False,False
8714,8714,37147955,2016-05-10 20:04:39,,updated version xcode run process completed without issue however try import gensim within python shell terminal bar bunch c output block execution error begin think ha something gensim looking header file somewhat loss help debugging would greatly appreciated,,2016-05-10 21:42:39,import gensim fails since updating xcode,python c++ xcode gensim,,,CC BY-SA 3.0,False,False,True,False,False
8723,8723,37190989,2016-05-12 15:12:23,,using gensim word vec package python know get vocabulary trained model get word count word vocabulary,,2018-11-09 12:35:49,get vocabulary word count gensim word vec,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8803,8803,37405958,2016-05-24 06:31:07,,would like find design parser find wikipedia xml dump unable find idea tried using wikiextractor unfortunately doe extract article based user defined category instead extract article contain keyword example xml file downloaded wikipedia article anarchism article found following category example part xml anarchism would like search wikipedia xml dump article contained particular category like example generate xml file clean xml file train using gensim word vec model please advice basic programming experience need python thank,2016-05-24 08:00:02,2016-05-24 08:00:02,searching article wikipedia xml dump based category,python wikipedia gensim,,,CC BY-SA 3.0,False,False,True,False,False
8812,8812,37350767,2016-05-20 15:49:17,,training word vec model gensim python relatively small dataset data consist short text entry different people two three sentence know small word vec dataset seen similar one work past reason train model feature impractically close one another instance part speech included lemmatize data training code also happens train without bigram transformer doe anybody idea distance close,,2016-05-20 15:49:17,gensim word vec distance close,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8819,8819,37335842,2016-05-19 23:49:10,,trained gensim model doc vec doc vec model v model doc vec sentence size window min count worker get document vector docvec v model docvecs get word vector trained model,,2018-08-14 03:07:06,get word vector gensim doc vec,gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
8852,8852,37461117,2016-05-26 12:39:01,,want try implement word vec vietnamase language confused pre trained vector tried use english language use google news vector negative bin gz gb pre trained vector work good vietnam language make data pre trained vector make pre trained vector google news vector negative bin gz try convert google news vector negative bin text format result change letter word form,,2016-08-15 10:03:26,make pre trained vector language word vec,c python-2.7 gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8892,8892,37593293,2016-06-02 13:28:33,,want calculate tf idf document using python panda first thought would need get word count row wrote simple function applied row lost know easy method calculate tf idf use graphlab want stick open source option sklearn gensim look overwhelming simplest solution get tf idf,2020-09-20 18:19:29,2020-09-20 18:19:29,get tfidf panda dataframe,python pandas scikit-learn tf-idf gensim,,,CC BY-SA 4.0,False,False,True,False,True
8896,8896,37487504,2016-05-27 15:40:47,,computed lda model retrieved topic looking way compute weight percentage topic corpus surprisingly find way far code look like far seen forum following however get error cluster two idea,2019-01-21 22:16:17,2019-01-21 22:16:17,computing weight lda topic document corpus,python lda gensim corpus,,,CC BY-SA 4.0,False,False,True,False,False
8907,8907,37539760,2016-05-31 07:43:15,,wa making corpus using command gb file making corpus adding dictionary give hence discarding new token maximum size anyway limit size dictionary,,2017-05-10 11:44:27,increase dictionary size gensim making corpus,python dictionary gensim,,,CC BY-SA 3.0,False,False,True,False,False
8943,8943,37570696,2016-06-01 13:50:52,,seem find probably knowledge statistic term problem want achieve something similar graph found bottom page lda lib pypi observe uniformity convergence line achieve gensim lda,,2017-08-19 20:48:27,monitor convergence gensim lda model,python lda gensim convergence,,,CC BY-SA 3.0,False,False,True,False,False
8984,8984,37745250,2016-06-10 09:55:13,,trying apply word vec model implemented library gensim python list sentence sentence list word instance let u implement two identical model realize model sometimes sometimes different depending value n instance n obtain n possible thank much,,2016-07-06 16:10:30,different model gensim word vec python,python nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
8989,8989,37763883,2016-06-11 12:45:03,,way get document vector unseen seen document doc vec gensim version example suppose trained model thousand get doc vector doc way get document vector unseen document composed vocabulary,,2016-07-01 18:32:48,get document vector doc vec gensim,python gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
8997,8997,37749777,2016-06-10 13:39:30,,anaconda pip installed tried find package following msg wa thrown powershell help would appreciated thanks conda work well machine even help pip would appreciated,,2016-06-18 04:35:57,install gensim version window machine,python pip conda gensim,,,CC BY-SA 3.0,False,False,True,False,False
9009,9009,37789724,2016-06-13 12:20:20,,aim user input string need compare input sentence sentence find maximum similarity either sentence current approach tokenize input sentence find synonym set token compare maximum similarity adding similarity token using nltk path similarity token token problem sentence short sentence long many token since sum individual similarity similarity sentence input always even token input match sentence one solution divide similarity sentence length sentence hence get similarity per token sentence approach aggressive industry standard approach,,2016-06-13 12:20:20,algorithm sentence matching calculating word similarity using nltk,machine-learning nlp nltk semantics gensim,,,CC BY-SA 3.0,True,False,True,False,False
9010,9010,37793118,2016-06-13 15:01:18,,downloaded pretrained glove vector file internet txt file unable load access easy load access word vector binary file using gensim know text file format thanks advance,,2020-07-03 05:05:04,load pretrained glove vector python,python-2.7 vector nlp,,,CC BY-SA 3.0,False,False,True,False,False
9018,9018,37696459,2016-06-08 07:53:53,,document b series document would like get new document showing difference two document b difference several definition one list word concept include b thinking using tf idf sentence b sure would relevant generate new document c b especially interested semantic difference document c,2016-06-08 14:16:33,2016-06-08 14:16:33,nlp get difference document,nlp scikit-learn stanford-nlp gensim spacy,,,CC BY-SA 3.0,False,True,True,True,True
9056,9056,37930925,2016-06-20 20:04:51,,using gensim train sentence size unique word training dataset number word model len model vocab though doe make sense reason seeing change model key every word training model word vec window min count,,2017-05-20 21:23:56,number vocabulary gensim much lower one training data,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
9065,9065,37935785,2016-06-21 04:47:58,,reading paper doc vec really get paragraph id trained tried implement sentiment analysis task gensim package succeeded without knowing exactly work paper said document vector trained like another word processed trained time word vec training contain message paragraph treated word sentence label one confusing matrix anybody explain process got totally messed please help thx,2016-06-21 04:53:29,2016-06-21 04:53:29,document vector paraghaph id doc vec,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9078,9078,37894390,2016-06-18 07:19:39,,using spark lda implementation shown example code want get consistent topic topic distribution training data training two machine would like output understand lda us random component training inference explained post look like consistent result achieved python gensim setting seed value manually tried spark still getting slight variance outputted topic distribution way get consistent topic distribution training set data,2017-05-23 10:29:01,2016-06-18 07:19:39,spark lda consistent topic distribution,scala apache-spark apache-spark-mllib lda,,,CC BY-SA 3.0,False,False,True,False,False
9094,9094,37861873,2016-06-16 14:18:52,,function parameter called understand dimension output vector capture content better however understand doe stand doe mean far doc vec lookup word predict next word doe mean thanks lot,,2016-07-29 02:42:25,doe size parameter gensim doc vec represent,gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9102,9102,37818426,2016-06-14 17:22:31,,using library possibility provide model word want find list similar word wonder possibility give system input model vector ask system return top similar word vector close given vector something similar need functionality bilingual setting model english german well english word need find similar german candidate want get vector english word english model query german model vector implemented c using original distance function word vec package need python order able integrate script know already method library similar library doe need implement,2016-12-17 05:20:11,2018-12-19 15:58:57,get similar word given vector word word,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
9133,9133,38098824,2016-06-29 11:56:19,,taking different document database check lda gensim kind latent topic document work pretty well would like save database every document probable topic sure best solution could example beginning extract unique id every document database together text column somehow process know end id belongs topic number may last part print document topic know connect back database comparison text column document assigning corresponding topic number would grateful comment,,2016-07-04 09:43:16,lda gensim update postgres database correct topic number every document,python postgresql lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
9135,9135,38054356,2016-06-27 12:45:42,,using want calculate similarity within list document library excellent handling amount data got document reduced timestamps got function compare however us cosine similarity wondering anyone ha attemted ha different solution,,2016-07-06 00:14:37,gensim custom similarity measure,python time similarity gensim,,,CC BY-SA 3.0,False,False,True,False,False
9157,9157,38062337,2016-06-27 20:05:11,,working doc vec word vec deep learning algorithm doc vec api description gensim description currently interested using method basically computes cosine similarity two set word interested way validating model performance function overall accurate realistic result model provide since performs deep learning know way knowing well doe perform technique look use data set ha result compare suggestion much appreciated thank,,2016-06-27 20:05:11,way validate performance doc vec word vec deep learning model,python deep-learning gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9161,9161,37818728,2016-06-14 17:39:48,,working latent semantic analysis lsa applied example http radimrehurek com gensim tut html includes term clustering topic find anything cluster document topic example say appears according lsi tree graph minor related word contribute direction first topic second topic practically concern word expected first five document strongly related second topic remaining four document first topic relate five document python code related topic find python code would appreciate help,,2017-04-21 07:00:20,cluster document topic using latent semantic analysis lsa,python cluster-analysis tf-idf lsa,,,CC BY-SA 3.0,False,False,True,False,False
9162,9162,37823014,2016-06-14 22:15:14,,trying categorize blog content using topic modeling using lda transformation find correlation b w topic say cricket sub topic sport topic however come know could achieved using hlda could one help implement hlda transformation python gensim package,,2016-07-26 18:43:49,implement hlda transformation find correlation topic gensim,python gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
9182,9182,38005590,2016-06-24 04:26:32,,installed anacoda python v gensim v using spyder ide following simple code got following error reinstalled gensim scipy numpy still issue,,2017-11-07 07:29:49,importerror import name corpus gensim,python-2.7 nltk lda gensim,,,CC BY-SA 3.0,True,False,True,False,False
9193,9193,38088351,2016-06-29 00:23:06,,want lda topic analysis huge corpus tried r python like seed special word model mean prior probability word associated topic want seed model searched function lda r gensim model ldamodel ldamodel python paremters hardly saw example code using thus idea input prior model anyone provide help thanks,,2016-11-30 20:09:11,seeding word lda model r python,python r lda seeding text-analysis,,,CC BY-SA 3.0,False,False,True,False,False
9222,9222,38200241,2016-07-05 09:50:01,,already trained doc vec model model ha n similarity similar function check similarity sentence however want know top topic model extract topic model thank,2016-07-05 10:23:03,2016-07-05 10:23:03,gensim extract topic trained doc vec model gensim,python-3.x gensim,,,CC BY-SA 3.0,False,False,True,False,False
9262,9262,38245739,2016-07-07 12:41:04,,used class extracting sentence file directory use sentence train word vec model dataset unlabeled want use class make doc vec model read doc vec reference page function get sentence parameter accept sentence variable return error problem correct type parameter update think unlabeled data problem seems doc vec need labeled data,2016-07-07 12:59:04,2018-10-16 18:48:56,gensim doc vec pas corpus sentence doc vec function,python text-mining gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9284,9284,38324328,2016-07-12 09:01:53,,reading modern post sentiment classification analysis taking imdb dataset example find get similar accuracy percentage using doc vec however far better result using simple tfidf vectoriser tri gram feature extraction think similar table mikolov paper thought using bigger data set would change ran experiment using breakdown mill training mill test unfortunately case tfidf vectoriser feature extraction method increased doc vec fell wa wondering expected others find tfidf superior doc vec even large corpus data cleaning simple tried using feature doc vec model whereas tfidf vectoriser ha max feature classification experimented linear method however found simple logistic regression ok,,2016-07-29 02:33:21,doc vec suited sentiment analysis,machine-learning sentiment-analysis gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9321,9321,38315158,2016-07-11 19:56:06,,goal convert record csv file array clean normalize read corpus dictionary use doc bow gensim perform sparsematrixsimiliarity query wa successful reading csv file first printed array call definition one sub category record number hit wall utf ascii error gensim ha strict utf setting several hour spent stack overflow researching trying apply utf encoders per python csv documentation read since python box unicode encoding using import csv package could use codecs package figured instead finding every line original definition line array decoding could take initial stab decoding right bat using codecs however code fails write anything definition array newbie imagine may using codecs wrong way closing wrong way total newbie apology error description learning go really appreciate feedback help perhaps going wrong way welcome education thank,,2016-07-11 19:56:06,empty array writing csv file python,python arrays encoding utf-8 gensim,,,CC BY-SA 3.0,False,False,True,False,False
9371,9371,38442161,2016-07-18 16:53:23,,official explanation natural ordering topic lda method show topic returned num topic self num topic subset topic therefore arbitrary may change two lda training run tends find top ten frequent topic corpus way achieve many thanks,,2018-07-23 11:23:30,print top ten topic using gensim,python lda gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
9385,9385,38556496,2016-07-24 20:31:38,,need experiment text file using gensim mac yosemite already installed want import facing error upgraded latest version python read problem may solved hacking code know way,2016-07-24 20:34:23,2016-11-17 06:41:10,gensim imported importerror module named queue,python-2.7 queue gensim,,,CC BY-SA 3.0,False,False,True,False,False
9387,9387,38343475,2016-07-13 05:42:34,,please help gb text want build word vec model using gensim slow try deepdist example code web wondering anyone seen kind error output run script,2016-07-13 06:23:01,2016-08-02 23:07:09,trying deepdict run gensim word vec pyspark,python pyspark gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
9414,9414,38484117,2016-07-20 14:31:00,,trained doc vec model python would like use python try load python get seems related pickle compatibility issue tried solve gensim saved file renamed well found calling load doe fail unicodedecodeerror inference provides meaningless result easily train using gensim python used model create derived data would run long complex pipeline make doc vec model compatible python,2016-07-22 06:59:00,2016-07-22 06:59:00,doc vec model python compatibility,python python-3.x pickle gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9463,9463,38507935,2016-07-21 15:09:39,,trained glove spanish article know load glove gensim use wa word vec model facing problem topic modelling keywords extraction news article also spanish wa wondering could use trained model could,,2016-07-22 22:00:11,use trained glove word vec model extract keywords article,nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
9466,9466,38665556,2016-07-29 18:40:54,,gensim word vec implementation compute word embeddings everything went quite fantastically far tell clustering word vector created hoping get semantic grouping next step would like look word rather vector contained cluster e vector embeddings would like find actual word vector represents get word vocab item calling word vector could find location explicitly matched wa complicated expected feel might missing obvious way help appreciated problem match word embedding vector created approach creating model code would like match index assigned word phase vector matrix outputted thus better way e g feeding vector model match word doe even get correct result code create word vector found question similar ha really answered,2020-06-20 09:12:55,2017-06-16 02:41:24,matching word vector gensim word vec model,python vector machine-learning gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
9467,9467,38682784,2016-07-31 09:55:43,,doe anyone idea give direction extract category article corpus thousand article sport news buisness etc work example article sport would like program know soccer basketball somthing else output somthing like soccer basketball,,2016-07-31 12:29:54,nlp extract category tag text,python nltk gensim,,,CC BY-SA 3.0,True,False,True,False,False
9490,9490,38620124,2016-07-27 18:00:35,,using gensim nlp task currently corpus includes empty document want rerun code although option would like remove document content document already saved tf idf corpus wa wondering wa way remove document empty figure document empty corpus file iterator type data structure ie list thanks cameron,,2016-07-27 19:44:51,removing document gensim,python python-2.7 nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
9537,9537,38852074,2016-08-09 13:23:48,,im pretty sure im using yield improperly following example see trying create corpus xlsx file im reading xlsx file line title summary content appending big string function adjust text need end return big list word ex end yield result get following error know error yield line different yield line worked looked like wa abit messy hard put functionallity changed see first example,2016-08-09 13:37:02,2016-08-09 14:16:54,python yield improperly usage,python parsing yield gensim,,,CC BY-SA 3.0,False,False,True,False,False
9539,9539,38852506,2016-08-09 13:43:38,,trying analyze news snippet order identify crisis period already downloaded news article past year available applying lda latent dirichlet allocation model dataset order identify country show sign economic crisis basing code blog post jordan barber http rstudio pub static amazonaws com b c b db html code far essentially identify number topic code checked using last line assign news article score indicates probability article related one topic manually make qualitative assessment whether given topic related crisis bit unfortunate would much rather tell algorithm whether article wa published crisis use additional piece information identify topic crisis year well non crisis year simply splitting dataset consider topic bad e crisis year work opinion would still need manually select topic would actually related crisis topic would show anyways sport news way adapt code incorporate information crisis v non crisis b automatically chose optimal number topic word optimize predictive power model thanks lot advance,,2016-08-10 10:13:05,stipulation good bad case lda model using gensim python,python python-2.7 lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
9541,9541,38630720,2016-07-28 08:16:09,,libbz dev installed however still getting following import error importing gensim,,2017-07-17 16:48:05,python import error module named bz,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
9551,9551,38772040,2016-08-04 15:50:35,,use gensim doc vec model train document vector printed representation word good found every epoch found updating printed representation document id every epoch different code know happening,,2016-09-27 04:30:48,doc vec gensim word embeddings updating epoch,nlp gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9570,9570,38739250,2016-08-03 09:11:31,,able install gensim window please help need gensim immediately tell installation step detail software need installed thanks,,2020-08-12 19:07:10,install gensim window,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
9621,9621,38985470,2016-08-16 22:27:47,,training two identical sentence document using checking vector sentence completely different doe neural network different random initialisation per sentence contain,2016-08-17 00:02:24,2016-09-07 22:03:16,doe gensim doc vec give different vector sentence,python neural-network gensim,,,CC BY-SA 3.0,False,False,True,False,False
9622,9622,38986235,2016-08-17 00:02:35,,lately playing around wikidump preprocessed trained word vec gensim doe anyone know one script within spacy would generate tokenization sentence recognition part speech tagging lemmatization dependency parsing named entity recognition able find clear documentation thank,2016-09-22 17:54:46,2019-05-03 11:08:30,spacy pipeline,python nlp spacy,,,CC BY-SA 3.0,False,True,True,False,False
9632,9632,39006270,2016-08-17 21:05:21,,given matrix want remember vaguely done must also module panda tried happy post code think example clear enough slow imagine must solved,,2016-08-17 22:19:33,convert set feature count matrix panda,python pandas gensim,,,CC BY-SA 3.0,False,False,True,False,False
9649,9649,38968353,2016-08-16 06:53:20,,want phrase doc vec use gensim phrase doc vec need tagged document train model tag phrase code,,2016-08-16 23:24:42,use doc vec phrase,python nlp gensim phrases doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9699,9699,39130456,2016-08-24 18:20:19,,running lot problem installing word vec within python keep getting standard error python find package looking competition repo agent python python gcc linux import word vec traceback recent call last file line importerror module named word vec everything found ha either someone else implementation word vec within python accessed gensim pip install python import flawlessly need set thing python thanks ben,2016-08-24 18:58:08,2016-08-24 18:58:08,implementing word vec python without gensim,python-3.x word2vec,,,CC BY-SA 3.0,False,False,True,False,False
9713,9713,39301199,2016-09-02 21:54:52,,working using cluster generate word vec model using gensim sentence medical journal stored json file trouble memory usage large task keep cumulative list sentence particular year generate word vec model year add sentence next year cumulative list generate save another model year based sentence particular cluster slow enough data large enough reading memory take day streaming json disk year model would taken forever solution wa load gb json memory python list permission use gb memory could get necessary trouble running memory read post way python implement free list returning memory think may part problem sure thinking free list might problem maybe numpy would better implementation large number element changed cumulative list sentence cumulative array sentence gensim requires sentence list word string ran small subset sentence used slightly memory unsure proceed anyone ha experience would happy help also anything else could changed would appreciate telling well full code,,2016-09-07 16:59:26,excessive memory usage large python list loaded gb json word vec,python numpy word2vec,,,CC BY-SA 3.0,False,False,True,False,False
9727,9727,39247496,2016-08-31 10:45:53,,wanted output log probability learning word doc vector gensim taken look implementation score function slow plain numpy version score function make use parameter learned hierarchical softmax training calculation log probability supposed sigmoid function word vec parameter learning explained equation doe gensim really calculate log probability score comparison purpose would calculated log probability follows equation used explodes value close zero general wrong,2016-08-31 11:03:21,2016-09-06 21:03:22,score cbow pair word vec gensim,python numpy probability gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
9729,9729,39252207,2016-08-31 14:21:26,,doc vec modelling trained model saved following file however new way label document want train model since word vector already obtained previous version way reuse model e g taking previous w v result initial vector training one know,2016-09-01 01:29:56,2016-09-07 07:42:51,gensim retrain doc vec model using previous word vec model,python gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9749,9749,39252860,2016-08-31 14:51:26,,trying understand pv dm implementation averaging gensim function return value error case averaging divided number input vector according explanation division number document case averaging input vector word vec parameter learning explained equation code,,2017-01-19 02:39:59,update document vector doc vec pv dm gensim,python numpy gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9757,9757,39294921,2016-09-02 14:33:13,,using according documentation ha parameter however getting error say without parameter function work expected workflow look like want know else happening result error message like able recreate result possible,2016-09-02 14:40:45,2016-09-02 15:01:40,ldamodel random state parameter recognized gensim,python-3.x numpy gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
9758,9758,39296592,2016-09-02 16:02:43,,like plot simple vector space graph similarity different word calculated using model given gensim find graphical example literature code follows simple vector space graph like place following word bank finance market property oil energy business economy easily calculate similarity pair word function thanks lot,,2017-02-22 11:11:00,graphical plot word similarity given word vec,python graph deep-learning gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
9781,9781,39275547,2016-09-01 15:27:12,,like analyze first deep learning model using python order first split corpus article sentence corpus built follows trying use function library first split corpus sentence recommendation cheer,,2016-09-01 17:29:38,tokenizing corpus composed article sentence python,python deep-learning gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
9798,9798,39489933,2016-09-14 12:00:31,,using gensim doc vec model trying cluster portion customer support conversation goal give support team auto response suggestion figure show sample conversation user question answered next conversation line making easy extract data conversation hello office located nyc suggested figure describes conversation question answer sync conversation hello office located nyc suggested figure describes conversation context answer built time classification purpose assuming line redundant conversation link free trial account suggested following data per conversation line simplified wrote line user agent text time stamp using following code train model q structure training data heuristic could applied order extract raw data,2016-09-15 20:44:37,2016-09-20 19:30:24,break conversation data pair context response,python text-mining doc2vec gensym,,,CC BY-SA 3.0,False,False,True,False,False
9850,9850,39615420,2016-09-21 11:33:05,,gensim give string input training doc vec model get error typeerror know handle uri repr uri referred question doc vec taggedlinedocument still doubt input format myfile txt token list list separate list line document string document doc machine learning subfield computer science evolved study pattern recognition doc arthur samuel defined machine learning field study give computer ability learn look like case simple text document line machine learning subfield computer science evolved study pattern recognition arthur samuel defined machine learning field study give computer ability learn case list list token document case list token document separate line running test data format sentence want predict doc vector like case case something else testsentence case string case list token,2017-12-20 11:55:30,2017-12-20 11:55:30,doc vec input format doc vec training infer vector python,python gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9851,9851,39615436,2016-09-21 11:33:45,,using lda model get different topic time want replicate set searched similar question google fix seed shown article work read find code use code still working,2016-09-21 11:55:49,2018-06-25 05:55:06,fails fix seed value lda model gensim,python numpy gensim,,,CC BY-SA 3.0,False,False,True,False,False
9855,9855,39549248,2016-09-17 16:40:54,,want use pre trained model know load python file model file mb downloaded http devmount github io germanwordembeddings,2017-11-29 04:56:30,2017-11-29 04:56:30,load pre trained word vec model file reuse,python file model word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
9863,9863,39657215,2016-09-23 09:24:33,,code python loaded binary model gensim python used init sims option make execution faster x take almost second load equivalent time find similar normal using init sims option took almost double time feeling might ram allocation issue,,2016-09-27 07:01:49,word vec using gensim google news dataset slow execution time,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
9865,9865,39580232,2016-09-19 18:57:36,,trained paragraph vector around paragraph word vector size need infer paragraph vector around sentence considered paragraph sentence around word corresponding earlier paragraph already trained using problem taking long doe take argument way speed process threading way using machine gb ram checked available core using come need answering multiple choice question also library model help task thanks advance time,2017-12-20 11:56:10,2020-05-31 17:48:15,doc vec infer vector document faster,python gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9872,9872,39552088,2016-09-17 21:54:26,,possible choose model gensim training word vec model,2020-10-13 21:33:47,2020-10-13 21:33:47,select skip gram cbow model training word vec gensim,nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
9874,9874,39558642,2016-09-18 14:20:48,,using word vec doc vec method provided gensim distributed version us blas atlas etc speedup detail however supporting gpu mode possible get gpu working using gensim,,2019-07-13 00:33:28,doe gensim library support gpu acceleration,optimization gpu gensim deeplearning4j,,,CC BY-SA 3.0,False,False,True,False,False
9903,9903,39570120,2016-09-19 09:49:46,,dealing topic modelling twitter define profile invidual twitter user using gensim module generate lda model question choosing good input data like generate topic assign specific user question input data using supervised method choosing user different category sport politics etc putting tweet model efficient effective would good method generating meaningful topic whole twitter,,2017-05-17 19:38:06,generating good lda model twitter python correct input data,python twitter lda gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
9906,9906,39738327,2016-09-28 04:54:24,,trying make apple siri like application python give vocal command question microphone determines text version inputted audio determines appropriate action take based meaning command question going using speech recognition library accept microphone input convert speech text via ibm watson speech text api main problem right define action app execute appropriate command given question asked know determine said command question denoting action let clarify mean example say action called multiple way somebody say hello another person case application hello hi howdy etcetera course want way saying hello classified action someone say hello hi howdy response action executed likely app saying hello back case first thought solve wa supply app common way say certain command question follow previous example would tell computer hello hi howdy meant thing action however method ha couple flaw first simply understand way saying hello hardcoded hey second response new command question start getting coded would become tedious entering way say certain phrase aforementioned problem started looking way calculate similarity group sentence single query eventually came across gensim library python looked found promising information complex process latent semantic indexing analysis lsi lsa tf idf however seemed like thing mainly comparing document large word count rely frequency certain term assuming true process really provide accurate result command question given app probably eight word average could completely wrong know little process also discovered wordnet work python using natural language toolkit nltk look like could useful sure finally guess real question would best solution problem mentioned use one method mentioned better way want know help would greatly appreciated thanks advance p sorry wordy explanation wanted sure wa clear p,,2016-09-28 09:38:24,siri like app calculating similarity query predefined set control phrase,python nlp nltk wordnet gensim,,,CC BY-SA 3.0,True,False,True,False,False
9917,9917,39781812,2016-09-30 00:09:37,,trying use gensim word vec implementation gensim warns c compiler training slower away verify gensim correctly using c compiler installed using anaconda python window,2016-10-12 02:57:51,2016-10-12 02:57:51,tell gensim word vec using c compiler,python compilation installation gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
9938,9938,39843584,2016-10-04 03:13:27,,trying compare implementation doc vec via tf gensims implementation seems atleast visually gensim one performing better ran following code train gensim model one tensorflow model question follows tf implementation doc vec correct basically supposed concatenating word vector document vector predict middle word certain context doe parameter gensim mean using two word either side predict middle one either side thing quite document smaller length insight gensim performing better model different implement considering effectively matrix factorisation problem tf model even getting answer infinite solution since rank deficient problem last question simply bonus gensim tf update check jupyter notebook model working tested still feel like gensim model performing better initial analysis,2017-09-17 04:12:13,2017-09-17 04:12:13,gensim doc vec v tensorflow doc vec,python tensorflow nlp gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
9946,9946,39806859,2016-10-01 12:55:42,,attempting build model attempt identify interest category topic supplied text example shop bridal wedding saree exhausting variety beautiful designer saree get great deal quality stitching free international delivery would resolve top level category like fashion wedding fashion acheive used latent dirichlet allocation lda topic model generates topic based word frequency set document got topic document find way map human understandable format topic sare intern get deal exhaust design free qualiti shop great topic sare beauti deliveri stitch varieti wed bridal great shop qualiti used script implement thing question map identified topic human readable category like fashion,2016-10-03 04:39:56,2018-02-01 20:44:56,identifying interest topic text,python nltk lda gensim nltk-trainer,,,CC BY-SA 3.0,True,False,True,False,False
9947,9947,39644667,2016-09-22 16:48:13,,like know whether rule set hyper parameter alpha theta lda model run lda model given library doubt specification hyper parameter red library documentation hyper parameter set number topic given model ha topic hyper parameter set common value running model news article describe economic activity reason expect document topic distribution theta high similar topic document topic word distribution alpha high well topic sharing many word common word exclusive topic reason given understanding hyper parameter correct correct specification value,,2018-05-11 07:54:50,rule set hyper parameter alpha theta lda model,lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
9998,9998,39969919,2016-10-11 03:07:18,,hoping assign document one topic using lda realise get distribution topic lda however see last line assign probable topic question run somewhat second time order get topic builtin gensim function give topic assignment vector directly especially since lda algorithm ha passed document might saved topic assignment,2020-04-20 03:31:54,2020-04-20 03:31:54,gensim lda topic assignment,gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
10019,10019,39948442,2016-10-09 20:56:26,,trying visualize lda topic python using pyldavis seem get right model ha vocab size k word million token taken train outside ipython notebook code wrote get following error hour running code high speed server gb ram someone help going wrong,,2016-10-12 12:30:24,pyldavis typeerror sort index object place use sort value instead,python visualization lda gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
10021,10021,39890544,2016-10-06 07:54:48,,dictionary object keep track vocabulary collection document aka corpus feed data object data ha fed memory e g read file object gensim dictionary class,,2016-10-06 07:54:48,read file object gensim dictionary class,python dictionary nlp gensim corpus,,,CC BY-SA 3.0,False,False,True,False,False
10028,10028,39973361,2016-10-11 08:36:47,,wa wondering changed gensim word vec model train small sample sentence setting size visualization distribution look follows look like dimension change polar something,,2016-10-11 08:36:47,gensim word vec dimension change,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10057,10057,39944487,2016-10-09 14:07:01,,structure dealing trained stored model like working fine far however want load model like getting doc vec ext py see inherit class stuff know problem tried still working properly load stored model important noticed even load module try load model file wa created still working giving error,2016-10-09 14:36:22,2016-10-09 18:17:26,pickle load importerror module named doc vec ext,python pickle gensim,,,CC BY-SA 3.0,False,False,True,False,False
10101,10101,40121204,2016-10-19 02:42:17,,want use google word vec googlenews vector negative bin downloaded http code google com archive p word vec load memory error occured process finished exit code interrupted signal sigsegv use ubuntu gtx gb ram gb fix,,2018-06-09 15:00:59,google word vec load error,gpu segmentation-fault gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10120,10120,40158051,2016-10-20 15:01:36,,sentence iterator using formally generator running like iterator doe stop looping file corpus folder indefinitively doe happen ordinary iteration like,2019-05-18 20:25:12,2019-05-18 20:25:12,gensim word vec iterator doe stop yield,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
10133,10133,40091380,2016-10-17 16:30:06,,using word vector text classification solution using word vector mainly address case synonym training set present actual use case simply using word vector getting good enough accuracy prediction anyone please suggest enhancement word vector order improve accuracy,,2016-10-18 01:48:37,enhancement text classification using word vector,machine-learning scikit-learn text-classification gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,True
10141,10141,40160526,2016-10-20 17:11:33,,wiki gensim corpus mmcorpus r c user public document python script wiki en vocab k mm tfidf gensim model tfidfmodel load r c user tfidf model corpus tfidf tfidf wiki step want able find individual word score many thanks advance,,2016-10-20 17:11:33,get tf idf score particular word gensim,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
10150,10150,40205725,2016-10-23 17:23:45,,trying use gensim generate lsi model along corpus lsi following tutorial start corpus dictionary generated list document small line document sample list provided gensim tutorial however pythos crash reach line generating lsi model see code along generated output code output printing generating lsi model crash suggestion thing tried changing python version python removing gensim installing github instead conda,2016-10-24 07:22:42,2016-11-04 16:05:48,gensim generating lsi model cause python ha stopped working,python python-3.x gensim latent-semantic-indexing latent-semantic-analysis,,,CC BY-SA 3.0,False,False,True,False,False
10163,10163,40247112,2016-10-25 18:27:34,,using lda model corpus learn topic covered using gensim package e g gensim model ldamodel ldamodel easily use version lda necessary question efficient way use parameterized model topic word topic id find retrieve new document contain topic concretely want scrape medium api find new article sample document relate topic contained original corpus blind search running lda new document may cumbersome new document contain topic course simply retrieve new document contain one n frequent word lda learned topic apply lda returned document confidence wondering sophisticated method give better confidence new sample article actually contain topic opposed coincidentally containing one two topic word looking topic tiling algorithm sure applicable,,2016-10-27 12:34:02,use topic model lda output match retrieve new topic document,text lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
10171,10171,40296765,2016-10-28 01:49:44,,preparing doc vec model using tweet tweet word array considered separate document labeled sent sent etc taggeddocs index enumerate cleaned tweet len non empty tweet sentence taggeddocument word gensim utils unicode split tag u sent format index taggeddocs append sentence build model model gensim model doc vec taggeddocs dm alpha size min alpha min count epoch range epoch print training epoch epoch model train taggeddocs model alpha decrease learning rate model min alpha model alpha fix learning rate decay wish find tweet similar given tweet say sent get label similar tweet sims model docvecs similar sent label score sims print label print sent sent sent sent sent sent sent sent sent sent given label get original tweet word sentence e g tweet word say sent query doc vec model,,2017-01-19 03:54:21,extract word used doc vec,python nlp gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10180,10180,40181943,2016-10-21 16:59:07,,trying get key well vector vector give vector give n dim vector better way create list word model order vector word would take long,2016-10-23 16:10:45,2017-04-15 09:13:11,get key value pair numpy ndarray gensim word vec,python performance gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10186,10186,40250057,2016-10-25 21:29:47,,wondering possible train spark word vec batch mode word possible update vocabulary list spark word vec model already trained application paragraph located multiple file use gensim even wondering similar thing spark word vec spark found rdd union multiple file otherwise train model inp inp word inp gone training batch mode update trained model new paragraph future,2016-10-25 21:41:36,2017-02-28 16:38:46,possible train spark word vec model batch mode,apache-spark word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10189,10189,40149951,2016-10-20 09:03:16,,follow tutorial everything fine preprocess train model want find similarity following code vector proper format doe anyone know fix issue,2019-03-18 19:57:59,2019-03-18 19:57:59,arabic persian language printed correctly screen,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
10202,10202,40230532,2016-10-25 02:41:08,,code training doc vec model let take look understand phrase used implementation bear let take look data look like first data point understanding id id document following ought give back docvector instead outputed trying get similar give following back trying understand doc vector saved id used part approach working something interesting following get back similar doc vector meaning,2018-12-15 19:48:33,2018-12-15 19:48:33,gensim doc vec document found id,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
10208,10208,40315446,2016-10-29 02:21:12,,trying implement doc vec gensim error enough documentation help web part working code txt file look like init model example print output error idea,2016-10-29 07:49:11,2016-10-30 10:08:23,python simple implementation doc vec,python gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10211,10211,40356631,2016-11-01 08:44:08,,set document want know topic distribution document different value number topic taken toy program question first used lda provided gensim giving test data training data get topic distribution doc training data getting uniform topic distribution always toy code used output checked example ended giving equiprobable result logfile generated e output logger say update training might converge tried increasing pass output still though related convergence also tried increasing topic,2017-05-23 11:46:16,2017-01-10 11:31:12,gensim lda module always getting uniform topical distribution predicting,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
10219,10219,40318719,2016-10-29 11:42:13,,made sample program getting topic distribution per document lda using gensim program printing anything change required,,2016-10-29 12:26:36,printing topic distribution lda using gensim,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
10241,10241,40326300,2016-10-30 05:32:50,,using gensim doc vec method read text file contains sentence per line read file dictionary key tokenized list term value sentence number code example output new file feed list gensim taggedlinedocument function example output question given tag id example get back original sentence,2016-10-30 05:37:52,2017-01-19 03:44:27,python gensim retrieve original sentence doc vec taggedlinedocument,python gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10252,10252,40379531,2016-11-02 12:04:37,,used three different way calculate matching resume job description anyone tell method best used nltk keyword extraction rake keywords keyphrase scoring applied cosine similarity scikit keywords extraction tf idf cosine similarity calculation gensim library lsa lsi model extract keywords calculate cosine similarity document query,2016-11-02 16:32:20,2017-08-27 16:49:24,best resume document matching,scikit-learn nltk information-retrieval tf-idf gensim,,,CC BY-SA 3.0,True,False,True,False,True
10254,10254,40436110,2016-11-05 08:12:51,,trying calculate similarity first used rake library extract keywords crawled job put keywords every job separate array combined array documentarray documentarray anger command assertiveness approachability adaptability authenticity aggressiveness analytical thinking molecular biology molecular biology molecular biology molecular biology molecular biology master english molecular biology islamabad islamabad district islamabad capital territory pakistan rawalpindi rawalpindi punjab pakistan competitive compensation assay design positive attitude regular basis motivate others meeting related improve state travel phd degree meeting abstract benefit package daily basis scientific paper application note querystr vitro biochemistry pcr western blotting neuroscience molecular biology cell biology immunohistochemistry microscopy animal model presentation immunoprecipitation cell biology master degree bachelor degree wrote following gensim code class gensim printing lsa score lda score match kindly let know wrong modify calculate correct cosine similarity lsa score lda score,2020-06-20 09:12:55,2016-11-05 11:25:48,rake gensim,python rake information-retrieval gensim cosine-similarity,,,CC BY-SA 3.0,False,False,True,False,False
10278,10278,40458742,2016-11-07 06:03:00,,word vec model two linear transforms take word vocab space hidden layer vector back vocab space vector usually vector discarded training wondering easy way accessing vector gensim python equivalently access matrix motivation would like implement idea presented recent paper dual embedding space model document ranking detail reference following word vec model input layer size v vocabulary size hidden layer size output layer size v two matrix w w usually word vec model keep w matrix returned training word vec model gensim get stuff like model potato access retain w likely quite computationally expensive really hoping built method gensim afraid code scratch would give good performance,2016-11-12 18:37:16,2018-09-04 00:23:44,gensim word vec accessing vector,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
10287,10287,40404411,2016-11-03 14:40:55,,test development use lambda together possible aws service create web service background use lda model constructed using gensim analyse text file exist goal use lambda event trigger automatically analyse text get uploaded bucket far tried create simple function lambda print log item property get uploaded bucket however analysis issue lda model required perform analysis extract object using key essentially calling however make data variable string need extract metadata loaded model object style first possible loading model file around mb memory lambda perform task second since task invoked repeatedly file logic tell find way store model persistent memory save fetch time possible efficient object passing elsewhere p perform analysis required parameter model wordid dict actual text need analysed help would much appreciated better fitting alternative would also really awesome thanks,,2016-11-03 14:40:55,use lambda load non string object perform computation,python amazon-web-services aws-lambda lda serverless-framework,,,CC BY-SA 3.0,False,False,True,False,False
10302,10302,40521982,2016-11-10 07:21:57,,referred website http radimrehurek com gensim tut html come across error unpicklingerror wa unhandled user code invalid load key clear error referred query included klepto package still error persists using anacoanda code,,2016-11-10 07:21:57,unpicklingerror wa unhandled user code invalid load key,python dictionary anaconda gensim corpus,,,CC BY-SA 3.0,False,False,True,False,False
10320,10320,40432558,2016-11-04 22:25:51,,topic modeling newspaper article implemented lda using gensim python want create word cloud topic using top word topic know print word save lda model way save top word topic use generating word cloud tried google could find anything relevant help appreciated,,2017-10-04 06:38:15,generate word cloud lda model python,python lda word-cloud,,,CC BY-SA 3.0,False,False,True,False,False
10327,10327,40524768,2016-11-10 10:04:40,,applied lda sklearn gensim checked perplexity held data getting negetive value perplexity gensim positive value perpleixy sklearn compare value sklearn perplexity gensim perplexity,,2016-11-15 17:52:49,perplexity comparision issue sklearn lda v gensim lda,python scikit-learn nlp lda gensim,,,CC BY-SA 3.0,False,False,True,False,True
10335,10335,40527326,2016-11-10 12:11:38,,would like extract data wikipedia summary page machine learning use data build word vec model gensim library first get wiki summary machine learning wikipedia api python create model problem print vocabulary key get list character rather list word following code use print vocabulary key wrong pasted full code,,2016-11-19 09:25:49,create word vec model data extracted wikipedia summary python,python wikipedia gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10349,10349,40413866,2016-11-04 01:18:02,,going thorugh paper http c stanford edu quocle paragraph vector pdf state theparagraph vector word vector averaged concatenated predict next word context experiment use concatenation method combine vector doe concatenation averaging work example paragraph contain word word also image stated paragraph token thought another word act memory remembers missing current context topic paragraph reason often call model distributed memory model paragraph vector pv dm paragraph token equal paragraph vector equal,2016-11-04 06:53:29,2017-01-19 03:42:06,doe gensim calculate doc vec paragraph vector,nlp vectorization gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10353,10353,40472070,2016-11-07 18:30:20,,trying understand relation word vec doc vec vector gensim implementation application tagging multiple document label topic training doc vec model corpus using dbow word order train word vector well able obtain similarity word document vector fashion doe make lot sense ex getting document label similar word doc vec model docvecs similar positive doc vec model management topn question however theoretical interpretation computing similarity word vec doc vec vector would safe assume trained corpus dimensionality word vector document vector always compared find similar word document label similar document label word suggestion idea welcome question question impact high low frequency word final word vec model worda wordb similar context particular doc label set document worda ha much higher frequency wordb would wordb higher similarity score corresponding doc label trying train multiple word vec model sampling corpus temporal fashion want know hypothesis word get frequent assuming context relatively stay similar similarity score document label would also increase wrong make assumption suggestion idea welcome thanks manish,,2017-01-19 03:35:24,word vector paragraph vector query,similarity gensim word2vec temporal doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10357,10357,40564790,2016-11-12 16:06:36,,trying gensim first time question trained lsi model corpus prepared document question get know new document similar model generated corpus document want know similarity document document corpus like matrixsimilarity doe rather know document similar topic model,,2017-07-09 08:13:30,doc vec gensim similarity document topic,python similarity gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10373,10373,40581010,2016-11-14 02:17:09,,want visualize word vec created gensim library tried sklearn seems need install developer version get tried installing developer version working machine possible modify code visualize word vec model tsne python,,2019-09-04 22:38:26,run tsne word vec created gensim,scikit-learn gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,True
10376,10376,40606524,2016-11-15 09:42:03,,want find n word greatest tfidf value document using gensim corpus compute tfidf value would like get tf idf given word document corpus looking corpus tfidf object see corpus part index array size size corpus find documentation help get tfidf word document corpus note answer question getting tf idf score word using gensim really solves problem give unique value word edit sample code tried success following code surely pythonic explain document doc corpus tfidf get something useful corpus tfidf clearly iterable define object obtained iteration subsequent question find source associated doc variable create separate question,2016-11-15 16:04:53,2016-11-15 16:04:53,access tfidf value gensim,python tf-idf gensim corpus,,,CC BY-SA 3.0,False,False,True,False,False
10411,10411,40651699,2016-11-17 09:55:53,,compute variance pre trained word embeddings trained word vec gensim need variance word vec model trained google google news corpus thanks,,2016-11-17 09:55:53,variance pre trained word embeddings trained word vec google news corpus,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10426,10426,40671057,2016-11-18 06:53:42,,trying run example use word vec gensim library python keep getting error code simple example note made sure gensim installed dependency,,2019-12-16 13:36:25,use error trying use gensim word vec,python-2.7 gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10438,10438,40659565,2016-11-17 16:02:21,,using gensim tfidfmodel model code want extract tf idf value word know corpus tfidf variable tried code like view word tf idf word like banana want find tf idf value access find word dictionary like dictionary token id banana get tf idf word corpus ha document feature non zero entry important get value word minimum time,,2016-11-17 16:02:21,gensim extracting tf idf value word corpus,python text tf-idf gensim,,,CC BY-SA 3.0,False,False,True,False,False
10444,10444,40727093,2016-11-21 18:33:30,,trained million tweet skipgram technique create word embeddings follows however continuously collecting tweet database example million tweet wan na update embeddings also considering newcoming tweet possible load previously trained model update weight embeddings maybe adding new word embeddings model need million tweet beginning take hour current parameter take longer bigger data one question possible retrieve sentence parameter directly database instead reading txt bz gz file data trained getting bigger would better bypassing text read write operation,,2016-11-21 18:33:30,gensim word vec updating word embeddings newcoming data,gensim word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
10448,10448,40637537,2016-11-16 16:41:03,,new topic modelling aim find key topic document planning use lda purpose lda number topic predefined believe document domain wa training corpus come give proper result alternative solution thought correct,,2017-05-05 21:48:42,dynamic number topic topic model,nlp lda gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
10454,10454,40643082,2016-11-16 21:55:53,,believe despite common issue many similar question especially stackoverflow main reason behind issue varies case case method named find code read list file extract doc file yield yield operation occurs end reading file another method named find code main aim method upload corpus obviously main reason behind using yield corpus large need read run method receive error erros occurs line reading similar problem came understand happens list misplaced tried uplate line question ended issue code uploadcorpus code readcorpus,2016-11-23 14:38:20,2016-11-23 14:38:20,python gensim typeerror coercing unicode need string buffer list found,python python-2.7 typeerror iterable gensim,,,CC BY-SA 3.0,False,False,True,False,False
10455,10455,40768132,2016-11-23 15:18:19,,already running python code document similarity server code run fine commandline however try run jupyter notebook get following error find code attributeerror traceback recent call last simserver queryindex national intergroup inc said plan file registration statement first got different error message solution wa install simserver library within jupyter notebook using command think missing library need downloaded relevant code jupyter notebook line issue occurs,2016-12-06 06:33:41,2016-12-06 06:33:41,python code running jupyter notebook,python jupyter-notebook attributeerror gensim,,,CC BY-SA 3.0,False,False,True,False,False
10464,10464,40622799,2016-11-16 01:53:49,,planning sentiment analysis customer review review multiple sentence using word vec certain question regarding train word vec model gensim using training data consider test data represent review classification representation take consideration order word important representing review sentiment analysis,,2016-12-14 18:57:03,sentiment analysis using word vec,python sentiment-analysis word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10467,10467,40660127,2016-11-17 16:28:43,,question related post document topical distribution gensim lda documentation gensim model ldamodel state minimum probability control filtering topic returned document bow however ldamodel corpus return possible topic probability even number set minimum probability difference two python gensim thank,2017-05-23 12:30:20,2017-09-13 13:08:12,gensim latent dirichlet allocation minimum probability v print topic,python lda gensim,,,CC BY-SA 3.0,False,False,True,False,False
10472,10472,40732313,2016-11-22 01:20:34,,trying install gensim google cloud instance using pip install gensim stacktrace trying import gensim linux version output lsb release output pip freeze anybody give pointer frustrating,,2019-05-10 12:47:24,gensim installation problem,python pip gensim,,,CC BY-SA 3.0,False,False,True,False,False
10497,10497,40596702,2016-11-14 19:49:05,,read following code learn doc vec model document defined text line two line clueweb en xx xxxxx end clueweb en xx xxxxx code got error wrote model docvecs clueweb en write model docvecs got result error got experience python gensim please tell solve problem,,2017-01-19 03:28:13,solve gensim keyerror try document vector,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10526,10526,40840731,2016-11-28 09:18:15,,getting error python trying compute lda smaller size corpus work fine case size corpus tried setting number topic reduced still give error valueerror compute lda empty collection term getting error line corpus giving term,2018-03-18 07:14:06,2018-03-18 07:14:06,valueerror compute lda empty collection term,python python-3.x gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
10570,10570,40865128,2016-11-29 11:46:08,,warning warning module file c python lib site package gensim utils py line warning warn detected window aliasing chunkize chunkize serial userwarning detected window aliasing chunkize chunkize serial,2016-12-01 09:12:47,2017-08-10 12:23:28,problem gensim install,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
10584,10584,40597319,2016-11-14 20:32:16,,training word vec model gensim using sentence csv file follows get following result b u h e n r v k w l result get word character program going wrong,2016-11-15 04:42:01,2017-05-28 07:15:52,gensim word vec online training,python gensim word2vec yield-keyword,,,CC BY-SA 3.0,False,False,True,False,False
10589,10589,40936197,2016-12-02 15:56:07,,want replace word gensim word vec model mapping example current model ha word map vector mapping rebuild model new mapping,2016-12-03 04:06:25,2016-12-03 18:02:20,rename gensim word vec word mapping,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10599,10599,40966014,2016-12-05 01:54:42,,found gensim ha bm ranking function however find tutorial use case one query document retrieved search engine use gensim bm ranking compare query document find similar one new gensim thanks query document document document document,,2019-05-27 04:12:23,use gensim bm ranking python,python ranking gensim,,,CC BY-SA 3.0,False,False,True,False,False
10604,10604,40890226,2016-11-30 13:55:30,,used gensim train word vec model would like query nearby term instead getting word closest direction want move particular direction distance within vector space retrieve nearest word essentially vector math terrible ie non existent especially many dimension model,,2017-03-27 09:36:54,move word vec vector space specific direction,python machine-learning gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10611,10611,40910578,2016-12-01 12:22:28,,trying build phrase model big corpus keep stumbling memory error first tried fit entire corpus big generator tried save model document none solution work however generic en bigram v generated saved wondering train phrase model per document find way merge thanks insight,,2017-10-10 13:08:24,merging two gensim phrase model,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
10623,10623,40986528,2016-12-06 01:52:52,,wa running multi label classification text data noticed tfidf outperformed lda large margin tfidf accuracy wa aorund lda wa around expected lda better,,2017-03-15 04:49:14,classification lda v tfidf,machine-learning gensim lda text-classification,,,CC BY-SA 3.0,False,False,True,False,False
10633,10633,41012760,2016-12-07 08:39:16,,using gensim construct lsi corpus apply query similarity following gensim tutorial tut tut n tut issue try calcualte query similarity shown code get result form docid simscore tuples need use docid retrive string representation document similar token id mapping googling could find anything useful code searching result sample,,2016-12-11 18:58:16,doc id mapping gensim,python similarity gensim,,,CC BY-SA 3.0,False,False,True,False,False
10652,10652,40924185,2016-12-02 03:14:53,,trying use lda module gensim following task train lda model one big document keep track latent topic given new unseen document predict probability distribution latent topic per tutorial http radimrehurek com gensim tut html seems possible document corpus wondering would possible unseen document thank,,2016-12-02 19:12:19,calculating topic distribution unseen document gensim,python nlp gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
10658,10658,41101424,2016-12-12 12:55:05,,using topic visualization library ldavis produce image principal component topic unveiled lda latent dirichlet allocation model like download image stuck help much appreciated,,2017-01-20 12:21:13,downloading image produced ldavis library,python ipython gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
10664,10664,41064594,2016-12-09 16:16:05,,need compare two string e g highly toughened steel unbreakable highly rugged steel name two product need find similar string also need check synonym sentence already tried using diff sequence matcher output pretty good wa trying look genism library worth consider small task anyone provide reproducible example using genism compare string,2016-12-09 17:28:24,2016-12-09 17:28:24,python based code compare similarity sentence,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
10679,10679,41182372,2016-12-16 10:33:16,,please help understanding difference work ultimate goal text classification using model classifier following blog question provide weblink good source get grasp work,2016-12-16 10:37:24,2017-01-19 02:59:31,difference gensim labeledsentence taggeddocument,gensim text-classification word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10686,10686,41162876,2016-12-15 11:19:11,,using gensim word vec package python would like retrieve weight matrix learn skip gram learning seems give first one sure get one idea would actually love find exhaustive documentation model accessible attribute official one doe seem precise instance syn described attribute,2017-12-21 15:21:25,2017-12-21 15:21:25,get weight matrix gensim word vec,python machine-learning nlp word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
10690,10690,41113211,2016-12-13 03:18:41,,using tensorflow build word vec model reference http github com tensorflow tensorflow blob master tensorflow example tutorial word vec word vec basic py l question find top n similar word certain word know gensim save load word vec model use model similar find want tensorflow even way save model tensorflow since find get embedding vector right,,2017-02-18 06:24:29,find similar word certain word tensorflow word vec like using model similar gensim,tensorflow word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10697,10697,41129933,2016-12-13 20:23:03,,trained word vec model geinsim dimension would like cut dimension simply drop last dimension easiest efficient way using python,,2020-03-14 22:47:51,gensim word vec model cut dimension,python python-3.x gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10715,10715,41223299,2016-12-19 13:07:29,,learning model library using follows input directory path ha sake simplicity file located file containing line getting following exception also statement could see iterator iterated directory time kind help would appreciated,,2017-01-19 02:52:01,gensim doc vec exception attributeerror str object ha attribute word,python neural-network gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10724,10724,41133844,2016-12-14 02:28:25,,using wiki corpus trained word input vocabulary test bit error keyerror word vocabulary word,2016-12-14 02:29:35,2019-01-28 18:34:40,keyerror word word vocabulary word vec,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10736,10736,41194588,2016-12-17 01:39:23,,trying install gensim ec redhat micro build rest api overall installation process really long shorten code replicate error getting shorter version sudo yum update ec update sudo yum install nano nano editor sudo yum install gcc c python devel atlas sse devel lapack devel various gensim related package sudo yum install httpd apache sudo yum install mod wsgi wsgi curl http bootstrap pypa io get pip py sudo python get pip py pip virtualenv p python tmp app tmp app bin activate virtual env virtual env setup added numpy scipy gensim pip install u force numpy pip install u force scipy pip install u force add simple file following code run python file py terminal macos get following error tmp ava app lib python site package gensim utils py userwarning pattern library installed lemmatization available warning warn pattern library installed lemmatization available handler could found logger gensim model doc vec idea error result error browser many thanks stephane,,2016-12-17 01:39:23,gensim ec installation issue,amazon-ec2 installation gensim,,,CC BY-SA 3.0,False,False,True,False,False
10763,10763,41273573,2016-12-21 23:23:28,,big data platform install anaconda ssh account platform open python interpreter terminal work fine import gensim library earlier installed library using see doe import library give warning pattern library however open jupyter notebook try import library give following sure library installed working jupyter please note show library ha gensim,2016-12-21 23:30:53,2019-10-27 13:33:37,gensim library recognized jupyter notebook,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
10813,10813,41326577,2016-12-26 04:56:52,,using python window linux get error unicodedecodeerror ascii codec decode byte xc position ordinal range error log following reloaded module lazylinker ext traceback recent call last checked found default decode method utf import sys sys getdefaultencoding utf read file also added decode utf add shepang line beginning declare utf really dont know python couldnt read file anybody help code,2016-12-26 05:45:33,2016-12-28 12:51:12,unicodedecodeerror ascii codec decode gensim python,encoding utf-8 python-3.5 gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10815,10815,41330637,2016-12-26 11:34:38,,may basic problem stuck since hour trying execute line code getting error import name phraser know get kind error phraser neither variable function gensim model phrase checked gensim homepage found class gensim model phrase phraser phrase model gensim latest module using python anaconda bit window,,2017-07-09 17:20:28,gensim import name phraser,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
10822,10822,41360580,2016-12-28 10:58:21,,trying read pretrained doc vec model however error appears reading process could anyone suggest deal error,,2017-05-15 23:02:46,gensim load pretrained doc vec model,python model gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10825,10825,41430565,2017-01-02 16:55:15,,writing first app python use word vec model simple code getting following error tried solving adding two line still getting error w v model wa trained english sentence edit full stack hint solve problem thanks advance,2017-01-02 17:25:53,2017-12-05 09:17:20,encoding issue python using w v,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10848,10848,41467115,2017-01-04 15:13:46,,extract embedding representation input data tensorflow documentation say use following accdg tf documentation nd parameter function tf nn embedding lookup tensor id id tensor type int int containing id looked params question given sentence say welcome world represent transform code transform sentence,2017-01-04 15:39:21,2017-01-04 16:58:49,using word vec pretrained vector generate id sentence input tf nn embedding lookup function tensorflow,python tensorflow gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10869,10869,41432760,2017-01-02 20:12:22,,want use gensim word vec input neural network question gensim model word vec get parameter size parameter used size trained output gensim word vec could see probability value seems word vector get distance cosinus word word word exactly thanks response,,2019-08-28 07:58:03,gensim word vec output,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10871,10871,41440633,2017-01-03 09:50:20,,want use big data train doc vec model want use pretrained model train new text expect train new one pretrained model code work,2017-01-03 10:52:18,2017-01-03 10:52:18,train new text gensim doc vec,gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10891,10891,41568556,2017-01-10 12:10:53,,currently working gensim doc vec model implement sentence similarity came across sample code william bert ha mentioned train model need provide background corpus code copied convenience provide corpus code thanks advance help,2017-01-10 12:44:19,2017-01-10 12:44:19,call corpus file python,python machine-learning gensim corpus doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10908,10908,41594324,2017-01-11 15:10:22,,problem statement classify product review class travel hotel car electronics food movie approaching problem famous problem feature set prepared using default model classification using onevsrest every class feed review following doc vec tutorial way model learns vector sentence resulting vector class given training testing accuracy classifier unseen data accuracy also sentence vector plotted graph resulted one dense cluster conclude graph data inseparable classifier gave accuracy also unseen data accuracy low evaluate validate result,,2017-01-11 15:10:22,classifier accuracy good believe,python pca gensim text-classification doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10945,10945,41689525,2017-01-17 05:18:53,,learning word vec glove model python going getting started gensim available compiled code step step idle getting error rectify get vector bin file thanks help advance,,2017-02-09 08:12:02,gensim getting started error file directory vector bin,python error-handling gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10946,10946,41690885,2017-01-17 07:05:39,,convolution example http github com fchollet kera blob master example imdb cnn py without word vec currently using gensim train word vec model want use word vec kera cnn document classifacation chinese text learned basic flow text classification cnn want test example step imagine use good cinese tokenized text set train word vec model tokenize sentence dataset word list dataset longest sentence ha word shortest le use method transform word list dataset word vec dataset transform every word every sencence vec trained model pad word vec dataset size zero array go cnn using convolution search long time find way step step parameter layer setting step hard understand,,2017-01-17 11:43:53,use word vec kera cnn text classification,neural-network deep-learning keras gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10954,10954,41628856,2017-01-13 06:46:13,,learning word vec glove model python going available compiled code step step idle getting error rectify thanks advance help,2017-01-13 07:24:05,2017-05-28 15:35:19,gensim getting started error file directory text,python python-3.x error-handling gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
10962,10962,41658568,2017-01-15 06:43:50,,installed gensim pip python installation get following warning c python lib site package gensim utils py userwarning detected window aliasing chunkize chunkize serial warning warn detected window aliasing chunkize chunkize serial rectify unable import word vec gensim model due warning following configuration python gensim numpy scipy pattern,2017-01-15 07:05:26,2018-10-19 18:01:51,chunkize warning installing gensim,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
10971,10971,41607976,2017-01-12 08:07:07,,using gensim want know efficient way know vocabulary size doc vec one crude way count total number word data huge gb efficient way,,2019-05-07 11:24:24,way get vocabulary size doc vec model,gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
10981,10981,41758755,2017-01-20 08:04:02,,currently going gensim tutorial corpus vector space right trying understand corpus streaming one document time compiled line code referring link python getting error already downloaded mycorpus txt still getting error store mycorpus txt file thanks help,,2017-01-20 08:04:02,gensim python filenotfounderror errno file directory mycorpus txt,python error-handling gensim corpus,,,CC BY-SA 3.0,False,False,True,False,False
10986,10986,41720864,2017-01-18 13:35:13,,research google also gensim support forum find good answer basically implementing online learning doc vec using gensim gensim keep throwing random error called segmentation please take look sample code error anyone explain solve thanks,,2017-01-19 00:21:24,gensim segmentation fault,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
11011,11011,41765951,2017-01-20 14:28:54,,applying lda method using gensim extract keywords document extract topic assign topic key word associated document would like id term key word instead term know extract list couple term id term frequency document see could use code extract id assign result code follows thank advance ask information needed,,2017-01-23 16:13:16,python lda get id keywords instead keywords gensim,python gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
11025,11025,41709318,2017-01-18 00:15:02,,picture distributed representation sentence document paper introducing doc vec using gensim implementation word vec doc vec great looking clarity issue given doc vec model impression averaged concatenated vector includes word embedding paragraph vector correct supposing one access bonus calculated paper say paragraph vector framework see figure every paragraph mapped unique vector represented column matrix every word also mapped unique vector represented column matrix w thanks lead,,2017-01-19 00:14:55,gensim docvecs,python nlp gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
11034,11034,41729287,2017-01-18 20:56:50,,using gensim topic modeling created corpus using trimmedtexttokens result removing stop word want filter term corpus list restricted constructed vocabulary idea thank,,2017-01-19 10:56:02,filter word corpus constrained vocabulary gensim,python nlp gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
11040,11040,41815880,2017-01-23 21:22:23,,analyzing corpus roughly raw word build model using gensim word vec embed vector using sklearn tsne cluster vector word vec tsne using sklearn dbscan tsne output look right layout word space seems reflect semantic meaning group misspelling clothes etc however trouble getting dbscan output meaningful result seems label almost everything group colored teal image increase epsilon group take everything screenshots epsilon epsilon epsilon almost everything group would expect instance group clothing word get clustered together unclustered eps would also expect order cluster opposed cluster able control size number cluster using epsilon question understanding use dbscan correctly another clustering algorithm might better choice know good clustering algorithm data safe assume model tuned pretty well given tsne look right technique use order isolate issue clustering know word vec model use dbscan something else code using perform dbscan,2018-06-06 14:20:29,2018-06-08 18:29:36,troubleshooting tip clustering word vec output dbscan,python machine-learning scikit-learn word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,True
11070,11070,41819761,2017-01-24 03:57:19,,doe anyone example data visualization lda model trained using pyspark library specifically using pyldavis seen lot example gensim library pyspark specifically wondering pas function get lda model code,2017-01-24 13:10:21,2019-06-11 13:48:08,pyldavis visualization pyspark generated lda model,python apache-spark pyspark lda,,,CC BY-SA 3.0,False,False,True,False,False
11086,11086,41936775,2017-01-30 13:10:29,,analysing text topic modelling using gensim pyldavis would like share result distant colleague without need install python required library way export interactive graph html j file could uploaded web server found something mentioned documentation idea implement http github com bmabey pyldavis blob master pyldavis display py,,2017-01-30 13:14:12,export pyldavis graph standalone webpage,python gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
11105,11105,41884796,2017-01-26 23:25:06,,would like determine given url input category list category e g programming health vegan food computer science math would like without download lot data deriving category already searched lot available starting information overload losing lot data nlp topic modeling found gensim library sure able conversion provide certain direction would really helpful,,2017-01-26 23:25:06,determine category given url,python text-classification,,,CC BY-SA 3.0,False,False,True,False,False
11107,11107,41888085,2017-01-27 06:28:06,,want create word embedding pretraining network add something top word vec cbow therefore trying implement word vec cbow first since new kera unable figure implement cbow initialization calculated vocabulary mapping word integer input yet implemented network list integer representing central word word context network specification shared layer take list integer give corresponding vector output mean context vector taken believe done using helpful anyone share small code snippet p wa looking word veckeras follow code also us gensim update want share embedding layer network embedding layer able take context word k current word well taking k word index input write custom lambda function needful also want add negative sampling network take embedding word dot product context vector someone provide example embedding layer shared node network,2017-01-27 10:36:46,2017-02-10 08:37:23,implement word vec cbow kera shared embedding layer negative sampling,keras embedding word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11131,11131,41960099,2017-01-31 14:31:00,,textual dataset trained w v model want use vector recive tf idf value word document data set right way tried followe tutorial gensim site expect something like fail since doe want make since bow way,,2017-01-31 15:03:34,get tf id w v gensim,python-3.x machine-learning nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11150,11150,42039964,2017-02-04 11:45:01,,running lubuntu machine installed getting work train ever trained one worker dreadfully slow said wa installed start maybe made mistake installed corrected forcing reinstall via effect still one worker machine setup master interface via work something like us us python way get interface cluster idea reason cant get gensim work cython execute gensim code cluster convenient fire jupyter also gensim,,2017-02-06 16:17:28,get cython gensim work pyspark,python python-3.x pyspark cython gensim,,,CC BY-SA 3.0,False,False,True,False,False
11177,11177,42119237,2017-02-08 16:58:43,,using gensim extract feature vector document downloaded pre trained model google named loaded model using following command purpose get feature vector document word easy get corresponding vector however know document could please help,,2019-12-17 09:43:27,load pre trained word vec model doc vec,machine-learning nlp gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
11178,11178,42096798,2017-02-07 18:01:16,,three numpy array saved disk format together totaling gb representing text count data large document set three array represent attribute sparse matrix want use distributed gensim lsimodel data specifically function provide corpus iterator underlying sparse matrix however want materialize whole matrix memory instead tell gensim underlying disk data gensim stream disk csc matrix needed distribute chunk worker process understand correctly distributed lsimodel example claim instead require materializing array csc matrix ahead time tried loading underlying array function construct materialized csc matrix pull data regardless,,2017-02-08 00:01:37,using gensim scipy corpus without materializing sparse matrix memory,python numpy scipy sparse-matrix gensim,,,CC BY-SA 3.0,False,False,True,False,False
11204,11204,41829323,2017-01-24 13:21:52,,list k word text file like g kdn c action standard air brush air dilution trying convert lower cased token using code subsequent processing gensim get following callback suggestion wrong correct would greatly appreciated thank,,2018-09-26 09:29:55,attributeerror list object ha attribute lower gensim,python string split gensim,,,CC BY-SA 3.0,False,False,True,False,False
11237,11237,42198720,2017-02-13 07:32:35,,word vec find similarity score similar word single word done however want find similarity score word phrase get keyerror word battery life vocabulary possible word vec,,2017-02-14 19:14:12,find similarity score two word phrase word vec,text-mining gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11259,11259,42186543,2017-02-12 10:38:17,,training word vec model tensorflow tutorial http github com tensorflow tensorflow blob master tensorflow example tutorial word vec word vec basic py training get embedding matrix would like save import trained model gensim load model gensim command generate file tensorflow thanks,2017-02-14 20:17:48,2017-12-24 15:07:14,training wordvec tensorflow importing gensim,python machine-learning tensorflow gensim,,,CC BY-SA 3.0,False,False,True,False,False
11269,11269,42109463,2017-02-08 09:39:19,,bit confused regarding aspect doc vec basically sure make sense following dataset short document belonging label label training document per label evaluation document would like predict label end using classifier train doc vec model training document label model trained reproject original training document well evaluation document one would like classify end model space using resulting matrix problem following run simple cross validation decent accuracy try classify evaluation document even using randomly sampled label super bad accuracy make question way approaching problem followed tutorial training document doe approach make sense especially reprojecting training document using,2017-02-08 12:59:02,2017-02-08 17:31:37,doc vec reprojecting training document model space,python classification gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
11274,11274,42131107,2017-02-09 07:59:52,,trained word vec model dataset using word vec gensim package dataset ha unique word model output vector matrix shape word vector associated rest able get dimensional vector every unique word,2017-02-10 16:09:23,2017-02-10 16:09:23,word vec model query,neural-network deep-learning gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11288,11288,42242521,2017-02-15 06:55:42,,playing around doc vec gensim analysing stackexchange dump analyze semantic similarity question identify duplicate tutorial doc vec tutorial seems describe input tagged sentence original paper doc vec paper claim method used infer fixed length vector paragraph document someone explain difference sentence document context would go inferring paragraph vector since question sometimes span multiple sentence thought training give sentence arising question tag would infer vector unseen question notebook doc vec notebook seems training vector train test doc someone explain rationale behind,,2017-02-16 03:49:52,doc vec differentiate sentence document,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
11306,11306,42212423,2017-02-13 19:54:33,,dataset several thousand row text target calculate tfidf score cosine similarity document using gensim python followed tutorial let say tfidf matrix similarity built new document come want query similar document existing dataset question way update tf idf matrix append new text doc original dataset recalculate whole thing,,2020-09-04 11:28:52,python tf idf fast way update tf idf matrix,python nlp tf-idf gensim cosine-similarity,,,CC BY-SA 3.0,False,False,True,False,False
11325,11325,42269313,2017-02-16 09:06:14,,first let extract tf idf score per term per document printing want find saliency importance word within corpus simple sum tf idf score across document divide number document e looking output could assume prominent word corpus mathematical interpretation sum tf idf score word across document,,2019-04-08 15:59:32,interpreting sum tf idf score word across document,python statistics nlp tf-idf gensim,,,CC BY-SA 3.0,False,False,True,False,False
11340,11340,42094180,2017-02-07 15:50:16,,tried several method loading google news word vec vector http code google com archive p word vec give also tried gz packed vector loading saving gensim new format file contains word word vector line tried load return correct way update load created file spacy use test txt file string line zip txt bzip test txt bz create spacy compatible binary file load spacy work however process googlenews txt get following error,2019-05-13 17:26:27,2019-05-13 17:26:27,spacy load google news word vec vector,python nlp word2vec spacy,,,CC BY-SA 3.0,False,True,True,False,False
11345,11345,42329766,2017-02-19 16:28:49,,currently working nlp python however corpus british american english realize realise thinking convert british american however find good tool package suggestion,,2018-11-26 14:43:40,python nlp british english v american english,python nlp nltk gensim linguistics,,,CC BY-SA 3.0,True,False,True,False,False
11354,11354,42363897,2017-02-21 09:49:33,,trying implement word vec model getting attribute error attributeerror type object word vec ha attribute load word vec format code please let know issue,2017-02-21 10:14:37,2017-03-17 09:34:24,attributeerror type object word vec ha attribute load word vec format,python nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11356,11356,42368713,2017-02-21 13:31:26,,using word vec gensim feeding sentence model following iterator everything working expected noticed performance varies lot depending type input single file input directory file directory file directory file understand decrease speed streaming operation identical opening file reading line line p tried core core behavior observed,2017-02-22 05:17:06,2017-03-04 11:22:47,performance data streaming file v directory file,python python-3.x io gensim,,,CC BY-SA 3.0,False,False,True,False,False
11370,11370,42289858,2017-02-17 05:09:35,,lda model document topic probability also need distribution word topic e topic word probability matrix way extract information thanks,,2017-02-17 16:49:05,extract topic word probability matrix gensim ldamodel,python gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
11373,11373,42316431,2017-02-18 14:30:56,,trying classify paragraph based sentiment training data thousand document convert vector space word analyzer ngram range almost million feature singular value decomposition svd reduce feature tried gensim sklearn svd feature work fine feature reduction till soon try feature throw memory error also used entire document thousand training data taken document essentially training matrix million want reduce way implement python implement spark mllib svd written java scala yes much faster system specification gb ram core processor ubuntu,2017-02-18 14:38:37,2017-02-18 16:29:06,svd using scikit learn gensim million feature,python scikit-learn gensim svd,,,CC BY-SA 3.0,False,False,True,False,True
11387,11387,42468394,2017-02-26 12:19:01,,using pycharm loading model trained word using word vec tried check similarity two word get error debug seems problem come line function word vec however clue getting thank much advance help,,2017-02-27 12:21:20,word vec similarity function working,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11394,11394,42408666,2017-02-23 06:36:51,,using gensim create word vec model sample file directory followed tutorial online read file directory process line line sample file ha line code give line time someone please explain happening detail suppose filename contains line like give happens time get list thrice instead total sentence return line time,2017-02-23 07:04:49,2017-02-23 07:30:00,python file iterator running multiple time,python python-2.7 iterator word2vec listiterator,,,CC BY-SA 3.0,False,False,True,False,False
11402,11402,42357678,2017-02-21 02:35:31,,word vec gensim update word vector fly doe work work fine however doe using website try emulate done hence use following script point however run using give following traceback,2017-02-22 21:26:23,2017-02-23 15:35:04,gensim word vec array dimension updating online word embedding,python numpy gensim,,,CC BY-SA 3.0,False,False,True,False,False
11403,11403,42359220,2017-02-21 05:13:49,,trying classify user input text two category using doc vec python following code train model classify input text problem able find method classify string newbie please ignore mistake link class reference http scikit learn org stable module generated sklearn linear model sgdclassifier html sklearn linear model sgdclassifier predict http radimrehurek com gensim model doc vec html,,2017-02-22 00:28:03,classify input text using doc vec logisticregression,python machine-learning logistic-regression text-classification doc2vec,,,CC BY-SA 3.0,False,False,True,False,True
11410,11410,42372346,2017-02-21 16:07:53,,code running memory question asked page wrote second code iterable memory changed code based explanation page familiar stream concept could solve error got code read file folder given path context file consist document name context two line instance clueweb en dove gif clipart pigeon clip art picture image hiox free bird india web icon clipart add stumble upon clueweb en google bookmark yahoo bookmark php script java script jsp script licensed script html tutorial cs tutorial first code second code consider part related db error traceback recent call last file home flashkar git doc vec annoy doc vec annoy knn testiterator py line model doc vec alldocs size window min count worker file home flashkar anaconda lib python site package gensim model doc vec py line init self build vocab document trim rule trim rule file home flashkar anaconda lib python site package gensim model word vec py line build vocab self scan vocab sentence progress per progress per trim rule trim rule initial survey file home flashkar anaconda lib python site package gensim model doc vec py line scan vocab document document enumerate document file home flashkar git doc vec annoy doc vec annoy knn testiterator py line iter yield labeledsentence token tpl indexerror list index range,2017-02-23 17:52:43,2017-02-23 17:52:43,build doc vec model useing iterable object,python iterator gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
11414,11414,42376652,2017-02-21 19:51:13,,tried three default option alpha gensim lda implementation wonder result sum topic probability document smaller number document corpus see example alpha symmetric yield sum topic probability however number topic could one tell reason unexpected result,2018-12-13 20:03:15,2019-03-23 23:30:44,gensim lda alpha parameter,gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
11415,11415,42381902,2017-02-22 03:00:46,,e g train word vec model using query similarity word find negative similarity score interpret negative score cosine similarity range upper bound lower bound function much written doc http radimrehurek com gensim model word vec html gensim model word vec word vec similarity looking python wrapper code much http github com rare technology gensim blob develop gensim model word vec py l possible please point code similarity function implemented,,2017-03-07 03:12:36,interpreting negative word vec similarity gensim,python nlp similarity gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11424,11424,42389748,2017-02-22 11:16:52,,okay specific question data structure required providing training data gensim python library particular must implicit understanding constitutes document data provided otherwise instance able find tf idf specific example wikipedia dump used tutorial library training purpose wikipedia dump provided xml give gensim understanding separate document understanding predicated nesing xml element,,2017-03-16 10:36:23,gensim data parsing,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
11430,11430,42382207,2017-02-22 03:32:50,,word vec object ha parameter explained doc class gensim model word vec word vec sentence none size alpha window min count max vocab size none sample seed worker min alpha sg h negative cbow mean hashfxn iter null word trim rule none sorted vocab batch word parameter used checking code http github com rare technology gensim blob develop gensim model word vec py l state concatenative l,,2017-02-22 07:02:14,null word parameter gensim word vec,python null deep-learning gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11433,11433,42529467,2017-03-01 10:38:55,,making sm categorizer want classify message different topic want use gensim anybody provide source tutorial help begin topic modelling using gensim,,2017-03-04 19:00:35,topic modelling using gensim,gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
11437,11437,42493143,2017-02-27 18:26:15,,wrote following code build doc vec model iteratively read page number token document need split token repeat label segment length token document try split token writing following code got error show token considered model test model following code got error got vector result school got error philadelphia philadelphia token index,,2017-03-10 04:21:24,word exist doc vec model document added iteratively model,gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
11456,11456,42514986,2017-02-28 17:18:24,,trying implement word vec cbow negative sampling kera following code found however get error merge part embedding layer tensor cbow dimension assume need reshape embedding find reshape functional api using tensorflow backend also someone point implementation cbow kera gensim free would love look thank edit error,2017-03-02 09:14:10,2017-03-02 09:14:10,product merge layer kera functionnal api word vec model,python nlp keras word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
11477,11477,42552733,2017-03-02 10:23:07,,trying load model contains spanish word using gensim python cli say try call load function still work,,2017-05-09 08:58:59,issue loading model spanish data,python-3.x gensim,,,CC BY-SA 3.0,False,False,True,False,False
11478,11478,42554289,2017-03-02 11:31:07,,want use output embedding word vec paper improving document ranking dual word embeddings know input vector syn output vector syn syn neg negative sampling calculated similar output vector got result range removing syn syn neg got another syn neg numpy vector already similar output want get output numpy array negative preserved training let know access pure syn syn neg code word vec module get output embedding,,2017-03-06 21:58:03,access output embedding output vector gensim word vec,python numpy gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11480,11480,42517435,2017-02-28 19:43:33,,using gensim implementation word vec following code snippet run python run expected final print word vocabulary however run python get error going gensim word vec compatible python,,2017-03-01 20:42:51,gensim word vec python missing vocab,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11485,11485,42502605,2017-02-28 07:26:00,,new deep learning want explore deep learning nlp went word embeddings tested gensim word vec also heard pre trained model confused difference pre trained model training model use result want apply kera want write formula theano tensorflow,2017-02-28 11:40:32,2017-02-28 11:40:32,difference pre trained word embedding training word embedding kera,python python-2.7 nlp deep-learning,,,CC BY-SA 3.0,False,False,True,False,False
11489,11489,42539384,2017-03-01 18:34:51,,could load doc vec model computer got following error load model computer use model therefore know model wa built correctly code error,2017-03-01 19:35:23,2017-03-01 20:19:32,got eoferror loading doc vec model,python-2.7 pickle gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
11497,11497,42399565,2017-02-22 18:33:14,,training word vec model using different data implement resulting model classifier compare result original pre trained word vec model need save model binary extension bin code sentence list short message last method save word vec format give error missing read documentation gensim forum repo github us almost configuration understand wrong tried switch skipgram cbow hierarchical softmax negative sampling result thank advance,,2018-12-26 20:37:42,save gensim word vec model binary format bin save word vec format,python attributes nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11513,11513,42459373,2017-02-25 17:38:06,,loading complete pre trained word vec model google time intensive tedious therefore wa wondering chance remove word certain frequency bring count e g k word found word vec method package determine word frequency save model sure vocab pre trained model saving find hint operation http github com rare technology gensim blob develop gensim model word vec py http github com rare technology gensim blob develop gensim model keyedvectors py select subset vocabulary pre trained word vec model,,2018-02-16 05:43:22,reduce google word vec model gensim,nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11542,11542,42697499,2017-03-09 14:08:15,,new python trying read parameter via console parameter path trained lda model gensim parameter number common word per topic want get return want print topic number common word per topic question get topic far gensim doc thanks,,2017-03-09 14:12:06,load computed lda model print common word per topic,python gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
11575,11575,42626287,2017-03-06 12:59:32,,downloaded wikipedia word vector loaded vector want train get error back question seems like keyedvectors ha train function want continue training vector personal sentence instead using wikipedia vector possible thanks advance jan,,2017-03-21 20:30:45,gensim keyedvectors train,python-3.x gensim,,,CC BY-SA 3.0,False,False,True,False,False
11617,11617,42746007,2017-03-12 09:58:26,,tried train incrementally word vec model produced gensim found vocabulary size increased word vec model weight updated need update vocabulary model size,,2017-03-16 03:30:54,incremental word vec model training gensim,python deep-learning gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11628,11628,42727181,2017-03-10 20:29:18,,trying load pretrained word vector google using following code getting error tell file c programdata anaconda lib site package gensim model keyedvectors py line load word vec format result syn zero vocab size vector size dtype datatype valueerror array big larger maximum possible size could anyone suggest possible solution thanks advance,,2017-04-02 06:25:34,valueerror array big loading googlenews vector negative,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
11631,11631,42673590,2017-03-08 14:11:29,,getting memory error use googlenews vector negative bin try train model gensim wikipedia dataset corpus gb gb ram system way bypass host cloud service like aws get better speed,2017-11-20 07:37:39,2019-01-14 10:21:20,gensim memory error using googlenews vector model,nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11637,11637,42781292,2017-03-14 08:43:26,,trying build document retrieval model return document ordered relevancy respect query search string trained doc vec model using model gensim dataset form panda dataset ha document stored string line code far part struggling finding document similar relevant query used realised considers query document update model return result tried using method get word along similarity score guess return want enter search string query get document id relevant along similarity score cosine etc get part done,2018-06-25 05:41:30,2018-06-25 05:41:30,doc vec get similar document,python nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
11649,11649,42752356,2017-03-12 19:55:27,,would like text analysis job description wa going use nltk build dictionary remove stopwords part want however addition single word frequency would like keep meaningful word group count well example job description containing machine learning want consider machine learning separately keep retain word group dictionary frequently occurs together efficient method think wont need go beyond word group containing word point stopword removal example dictionary would like,2017-03-12 20:09:01,2017-03-20 17:17:37,create dictionary word group,python nltk gensim,,,CC BY-SA 3.0,True,False,True,False,False
11650,11650,42753119,2017-03-12 21:03:02,,calling load like dist package gensim utils py line model ha split mb numpy array anyone help figuring issue,,2017-03-16 03:18:20,error loading pretrained vector gensim,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11661,11661,42789612,2017-03-14 15:07:04,,gensim lead unicode added suppress,,2017-03-19 05:11:58,gensim unicode python,python unicode gensim,,,CC BY-SA 3.0,False,False,True,False,False
11669,11669,42881749,2017-03-19 01:05:34,,issue running multicored lda gensim generating topic pas using worker get error initially thought might saving model looking error code still keep running least process quit anyone know prevent error occurring,2017-03-19 23:41:56,2017-03-19 23:41:56,gensim multicore lda overflow error,python-3.x python-multiprocessing multicore gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
11673,11673,42827175,2017-03-16 06:54:27,,kinda newbie native english trouble understanding think give word similar query word request training tell case use someone could explain difference short word please thanks,,2017-03-16 10:04:35,gensim difference word vec doc vec,nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
11700,11700,42851859,2017-03-17 07:41:18,,understand training lda model corpus size dictionary say topic k word dictionary vector size position vector probability word belongs particular topic right question given word probability word belongs topic k k could get value gensim lda model wa using method output probability topic eg want see prob fun could topic well,,2017-03-30 23:46:41,get topic word probability given word gensim lda,gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
11718,11718,42857000,2017-03-17 11:58:57,,list sentence first list contains different question second contains different statement little example want write program able classify type sentence create neural network train list guess must recurrent neural network transformed sentence array word vec vector want set kera recurrent neural network lstm layer know correctly write kera model problem update form sentence transforming word vec like vector ha dimension model see magic number question statement word vector length sure model wrong also getting error,2017-03-17 12:32:42,2017-03-17 12:32:42,classify sentence using word vec kera,keras recurrent-neural-network gensim word2vec keras-layer,,,CC BY-SA 3.0,False,False,True,False,False
11727,11727,42928438,2017-03-21 13:23:13,,know creation lda model probabilistic two model trained parameter corpus necessarily identical however wondering topic distribution document fed lda model also probabilistic lda model presented well two document doc doc want find cosine similarity two document lda space problem noticing run multiple iteration cosine similarity always identical even use saved lda model similarity extremely similar always bit time actual code hundred document converting topic distribution dense vector using numpy calculation matrix running rounding error numpy another bug code behavior expect using lda find topic distribution document edit going run simple cosine similarity different document using lda model plot spread result report back find ok result running cossine similarity document using lda model code result correct assume lda model infering topic distribution document iteration thus cosine similarity stochastic rather determanistic much variation sign training model long enough properly normalizing vector thanks thanks,2017-03-21 14:42:13,2017-12-18 10:06:07,topic distribution document lda space probabilistic,python numpy gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
11729,11729,42836992,2017-03-16 14:32:11,,installed python using anaconda gensim support python using pip got following error running gensim code causing error node vec porting python got error know python len map cause error doe mean gensim doe support python although pip website say support hidden setting anyone ha idea wrong thanks,2017-03-16 15:00:42,2017-08-01 17:42:32,gensim python typeerror object type map ha len,python python-3.x anaconda gensim,,,CC BY-SA 3.0,False,False,True,False,False
11732,11732,42986405,2017-03-23 20:30:58,,building chatbot need vectorize user input using word vec using pre trained model million word google googlenews vector negative load model using gensim problem take minute load model let user wait long speed load time thought putting million word corresponding vector mongodb database would certainly speed thing intuition tell good idea,2017-03-29 18:42:16,2019-10-17 10:36:30,speed gensim word vec model load time,deep-learning gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11745,11745,42913090,2017-03-20 20:12:19,,would like obtain identifiable list relevant document lda model using gensim e exactly op link http group google com forum topic gensim lhi mhondsy ha relevant answer sure get work apart parenthesis seems wrong place two main question id generated map document word something like throw lambda missing required positional argument doc reason error understood would unpacked needed correct supplied fix needed also look python map lambda method input still unenlightened far,2017-05-23 11:46:21,2017-03-20 20:40:49,gensim python mapping document id document sorted,python lambda gensim,,,CC BY-SA 3.0,False,False,True,False,False
11768,11768,43014259,2017-03-25 08:34:41,,working topic modelling script us gensim package create model based collection document preparing visualise model using pyldavis package run error,,2017-03-25 18:10:52,display formatter attribute error python,python error-handling lda,,,CC BY-SA 3.0,False,False,True,False,False
11776,11776,42879491,2017-03-18 20:29:11,,trying solve deep learning text classification problem vectorize text input word vec feed neural network downloaded google pre trained word vec model http github com top word vec api load using gensim try print specific word get one vector one word point bonus question load word vector google pre trained word vec model mongodb database column id word string vector float loading model bin txt file take minute,,2017-03-29 22:44:37,get single vector single word using word vec,python deep-learning word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11790,11790,42995073,2017-03-24 08:52:07,,gensim ha tutorial saying given document query string say document similar descending order http radimrehurek com gensim tut html also display topic associated entire model print lda topic model gensim python find topic associated given document query string ideally numeric similarity metric topic able find anything,2017-05-23 12:10:13,2017-06-08 00:41:39,displaying topic associated document query gensim,python nlp gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
11795,11795,43051902,2017-03-27 16:37:53,,trying create algorithm capable show top n document similar specific document used gensim doc vec code bellow sims var give tuples first element id doc second score problem id correspond document training data trying time make sense id training data see logic p code used create train corpus position aux array one array witch position int want id position description thanks advance,,2017-12-12 02:50:49,gensim docvecs similar return id dont exist,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
11808,11808,43070656,2017-03-28 13:16:37,,model trained use want train embeddings scratch tensorflow someone tell example code,,2017-03-28 19:45:55,use pretrained word vec model tensorflow,python tensorflow gensim word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
11828,11828,43019447,2017-03-25 17:15:18,,list sentence follow instruction tutorial make corpus want train lda model corpus extract topic keywords however receive error training wrong format corpus,,2017-03-28 15:46:18,gensim unable train lda model,nlp gensim lda corpus,,,CC BY-SA 3.0,False,False,True,False,False
11849,11849,42976912,2017-03-23 13:05:13,,reading article start train model problem author doe make clear like download text wikipedia page written article make list sentence example look like try train model list dictionary model consists letter example output wrong thanks advance,2017-03-24 06:57:36,2017-03-24 06:57:36,train word vec model wikipedia page using gensim,python nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11867,11867,43045295,2017-03-27 11:34:55,,set user content document per user containing tweet user planning use distributed vector representation size n user one way take pre trained wordvectors twitter data average get distributed vector user planning use doc vec better result quite sure understood dm model given distributed representation sentence document understand assigning one vector per paragraph predicting next word using backpropagating error update paragraph vector well word vector use predict paragraph vector new paragraph edit toy code gensim compute paragraph vector new document would appreciated,,2017-08-27 02:33:12,get paragraph vector new paragraph,machine-learning deep-learning word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
11875,11875,43065843,2017-03-28 09:32:41,,want make word vec gensim heard vocabulary corpus unicode converted unicode source code seems like work well however problem vocabulary key want make korean word vec use unicode example word mean apology english unicode try find word vec key error occur instead store separately reason solve,,2017-03-28 23:56:15,python gensim word vec vocabulary key,python unicode gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11877,11877,43098535,2017-03-29 15:57:20,,studied implementation gensim aware input vector output vector negative sampling know access similarity input output embeddings like question possible save output embeddings matrix final model example output output embeddings exactly code could access modify need order use output embeddings input classifier done previously brute force approach would like access output embeddings easily,2017-03-29 16:08:11,2017-03-30 02:52:55,saving output context embeddings word vec gensim implementation final model,python gensim word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
11887,11887,43080291,2017-03-28 21:29:10,,gensim hdp model topic modeling gensim model hdpmodel hdpmodel ha constructor take argument called documentation say number chunk model go larger number chunk supplied corpus training wrap around corpus since wa warned info log likelihood function ha decreasing figure may need multiple pass corpus converge lda model provides argument functionality train corpus multiple iteration difficulty figuring hdp map lda example let say corpus ha document need exactly order train say pass corpus suggestion many many thanks,,2018-11-02 07:36:01,gensim hdp topic model train multiple pass corpus,nlp gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
11904,11904,43213046,2017-04-04 16:41:20,,possible use gensim random projection train svm sklearn need use tfidf implementation better dealing large input want put random projection train svm also happy pas tfidf model generated use random projection make thing easier far found way get either model gensim sklearn tried using course work neither tfidfmodel rpmodel corpi clueless try next,,2018-03-12 20:41:17,use gensim random projection sklearn svm,scikit-learn tf-idf gensim,,,CC BY-SA 3.0,False,False,True,False,True
11907,11907,43158631,2017-04-01 15:25:04,,paper titled machine learning limit canny et al report substantial word vec processing speed improvement working bidmach library used paper find resource explains word vec implemented used within framework several script repo getw vdata sh getwv data ssc tried running building referenced file success tried modifying get run nothing error come back emailed author posted issue github repo gotten nothing back got somebody else trouble say got run much slower speed reported newer gpu hardware searched trying find anyone ha used library achieve speed luck multiple reference floating around point library fastest implementation cite number paper intel research reference reported number without running code gpu cite number reported original paper old reddit post pointing bidmach best op say tested bidmach yet post citing bidmach best op actually run library make claim many worth listing citing bidmach best fastest without example claim tested search similiar library gensim code required run find thousand result tutorial similar search bidmach code yield bidmach repo bidmach implementation certainly carry reputation best anyone tell use want run simple training process compare handful implementation hardware every implementation concept find either ha work original shell script test file provides actual instruction provides shell script test update author library ha added additional shell script get previously mentioned script running exactly mean work still total mystery understand get word vec training procedure run data edit bounty give bounty anywone explain use corpus text would great train model save ouput vector vocabulary file read omar levy hyperwords exactly original c implementation would argument also intel implementation doe cuda implementation etc great way generate something easily compared version update bounty expired without answer john canny ha updated script repo added file thus making possible run test script package repo however attempt run text corpus yield near accuracy hyperwords test running training process billion word benchmark repo script also yield well average accuracy hyperwords test either library never yielded accuracy test still missing something setup issue remains open github,2017-05-23 12:10:24,2017-04-11 18:52:27,anyone explain get bidmach word vec work,machine-learning nlp word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11914,11914,43045418,2017-03-27 11:40:25,,used python based gensim sample created project added code project running error pycharm console solve issue,,2017-07-11 02:40:16,gensim memory friendly corpus error,python-3.x gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
11918,11918,43171573,2017-04-02 17:55:28,,word vec us either model distributed representation word wa checking code gensim defined model used gensim,,2017-04-02 17:59:45,anyone tell model skipgram cbow used gensim,python nlp semantics gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11932,11932,43165724,2017-04-02 07:25:25,,used training similar word dataset post college community site dataset consists like example around data like make vector try train data via wonder whether possible make consider weight mean give weight certain data vector train data way word data vector ha strong relationship similarity example gave weight dataset word etc ha strong relation data vector word would possible sorry poor explanation native english speaker need detailed info please post comment,,2017-04-02 18:40:31,word vec possible train respect weight nlp,nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11934,11934,43166762,2017-04-02 09:29:02,,know reducing dimension word vector generate word embedding model huge amount data relation two doe use inside use,,2017-04-02 19:27:03,relation tsne word vec,nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11943,11943,43146077,2017-03-31 17:01:18,,trained doc vec gensim model doc vec model using line yield error attributeerror doc vec object ha attribute index word using gensim help,,2017-04-02 06:19:28,index word gensim doc vec raise attribute error,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
11944,11944,43146420,2017-03-31 17:24:05,,loading pretrained doc vec model using getting following error attributeerror module object ha attribute call class doe anyone know fix model wa trained gensim using gensim,2017-03-31 17:26:05,2017-03-31 22:22:24,gensim error loading pretrained doc vec model,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
11955,11955,43202548,2017-04-04 08:56:07,,im latest version loading trained vector file done using dosent requires instantiating new word vec object code broken use property alternative mean something better,,2017-09-04 10:02:10,gensim keydvectors dimension,python-3.x gensim,,,CC BY-SA 3.0,False,False,True,False,False
11963,11963,43186733,2017-04-03 14:03:06,,using phrase class want visualize vector space order word vec used sne worked perfectly trying phrase make sense word appear next irrelevant word suggestion visualize phrase output,,2017-04-12 18:20:55,visualize gensim phrase vector,data-visualization gensim word2vec phrases,,,CC BY-SA 3.0,False,False,True,False,False
11969,11969,43321492,2017-04-10 11:03:23,,use train word set database phrase phrase short total mb database train data using job getting lot time feel like efficient especially creating part took lot time space want improve speed training idea want get advice thanks,,2017-04-12 18:06:52,word vec way train model fastly,orm nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
11995,11995,43260074,2017-04-06 15:52:26,,need process topic lda output lda show topic num topic num word compare pyldavis graph topic number differently numbered way match,,2017-10-19 04:22:28,way match gensim lda output topic pyldavis graph,python-3.x gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
12019,12019,43343034,2017-04-11 10:13:58,,able create lda model save trying load model pas new document printing doc lda getting object however want get topic word associated method use wa referring,2017-04-12 06:41:49,2019-04-14 13:20:39,view interpret output lda model using gensim,python-3.x gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
12027,12027,43249717,2017-04-06 08:27:18,,want use word vec pyspark process data wa previously using google trained model python way load bin file doe make sense export data dictionary python file load thanks,2019-10-09 07:27:58,2019-10-09 07:27:58,pyspark load trained model word vec,python load pyspark gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
12068,12068,43444261,2017-04-17 02:14:36,,trying calculate similarity text using wmd tried use following code python using gensim however think returning right value python,2017-04-17 14:28:38,2019-10-30 04:23:51,word mover distance python,python python-3.x text nlp information-retrieval,,,CC BY-SA 3.0,False,False,True,False,False
12073,12073,43337242,2017-04-11 05:13:18,,want use word vec module containing ton indian character module wa trained facebook http github com facebookresearch fasttext blob master pretrained vector md using gujarati vector installed gensim try load module following error occurred tried load module python failed way load module gensim thanks,,2018-04-05 20:09:08,utf decode error loading word vec module,python utf-8 nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12092,12092,43393248,2017-04-13 13:09:52,,trying import downloaded model google using following code however run get error file path correct name model however get import correctly using guide suggestion thanks,2017-07-01 00:09:03,2017-07-01 00:09:03,gensim error importing word vec model,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12100,12100,43357247,2017-04-11 22:29:51,,ldamodel gensim ha two method despite use gensim tutorial notebook fully understand interpret output created self contained code show mean output make sense two probability add topic ha higher probability ha also higher probability assigned question probability add numerically topic ha higher probability ha also higher number assigned doe number mean use provide seemingly functionality ha meaningful output,2017-04-21 19:39:04,2017-07-18 18:48:52,get document topic get term topic gensim,python gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
12111,12111,43396677,2017-04-13 15:49:36,,executing function row row using loop work executing function using panda dataframe apply return valueerror operand could broadcast together shape panda dataframe apply work one thing easily explainable idea speed processing multiprocessing valueerror operand could broadcast together shape thank,2017-04-13 18:20:11,2017-04-13 18:40:18,panda dataframe apply valueerror operand could broadcast together shape,python-3.x pandas gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12138,12138,43524301,2017-04-20 15:48:51,,wa wondering possible update spacys default vocabulary trying run word vec corpus gensim load vector model since lot word corpus spacys default vocabulary make use imported vector easy way add missing type edit realize might problematic mix vector question import custom vocabulary spacy,2017-04-21 09:04:13,2017-05-08 04:27:02,update spacy vocabulary,python word2vec spacy,,,CC BY-SA 3.0,False,True,True,False,False
12142,12142,43505696,2017-04-19 20:43:08,,fitting hierarchical dirichlet process hdp topic model using python gensim package newsgroups dataset discover topic informative top word probability small using standard text pre processing includes tokenization stop word removal stemming wa thinking reducing dictionary size help generate meaningful topic way reducing dictionary size gensim,,2017-04-19 21:12:59,reduce dictionary size gensim,python dictionary gensim,,,CC BY-SA 3.0,False,False,True,False,False
12150,12150,43543762,2017-04-21 13:16:57,,using doc vec tag unique identifier document document ha different tag semantic meaning using tag find specific document calculate similarity tag influence result model tutorial talk parameter set false representation learned label tag tutorial somewhat dated guess parameter doe longer exist doe doc vec handle tag,2017-04-24 07:32:21,2017-05-16 05:30:47,doe doc vec learn representation tag,gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12155,12155,43476869,2017-04-18 15:53:34,,multiple document contain multiple sentence want use doc vec cluster e g k mean sentence vector using sklearn idea similar sentence grouped together several cluster however clear train every single document separately use clustering algorithm sentence vector could infer sentence vector doc vec without training every new sentence right snippet code basically right training every labeled sentence document however idea could done simpler way eventually sentence contain similar word clustered together printed point training every document separately doe clearly reveal logic within cluster hopefully someone steer right direction thanks,,2017-04-19 17:09:51,doc vec sentence clustering,python scikit-learn text-mining gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,True
12156,12156,43546165,2017-04-21 15:08:58,,installed gensim run test test run successfully however hit error find instance happening internet answer yet,,2017-04-21 15:08:58,gensim attributeerror get attribute fixedcorpusweight,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12209,12209,43633092,2017-04-26 11:37:02,,new deeplearning j want make sentence classifier using word vector input classifier wa using python vector model wa generated using gensim want use model new classifier possible use gensim word vec model deeplearning j word vec,2019-02-04 21:31:28,2019-02-04 21:31:28,possible use gensim word vec model deeplearning j word vec,java gensim word2vec deeplearning4j,,,CC BY-SA 4.0,False,False,True,False,False
12218,12218,43500996,2017-04-19 16:14:54,,want train word vec model english wikipedia using python gensim closely followed http group google com forum topic gensim mjwrdw ivxw work like resulting word vec model named entity split make model unusable specific application model need ha represent named entity single vector thats planned parse wikipedia article spacy merge entity like north carolina north carolina word vec would represent single vector far good spacy parsing ha part preprocessing originally recommended linked discussion using remove punctuation stop word number capitalization save article separate line resulting output file problem spacy ner really work preprocessed text since guess relies punctuation capitalization ner doe anyone know disable gensim preprocessing remove punctuation etc still par wikipedia article text directly compressed wikipedia dump doe someone know better way accomplish thanks advance,,2019-10-07 14:14:32,disabling gensim removal punctuation etc parsing wiki corpus,python nlp gensim word2vec spacy,,,CC BY-SA 3.0,False,True,True,False,False
12231,12231,43554048,2017-04-22 00:55:21,,load doc vec model pkl file get error please help error,,2017-05-15 22:54:31,doc vec object ha attribute wv,python nlp gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12233,12233,43540857,2017-04-21 10:53:43,,trying load file gensim line code however getting error help solve error,,2017-05-08 04:23:54,gensim trying load text file gensim,python-3.x jupyter-notebook gensim,,,CC BY-SA 3.0,False,False,True,False,False
12242,12242,43617836,2017-04-25 17:57:08,,trained latent dirichlet allocation lda model corpus document using gensim package python able retrieve following distribution topic one document distribution word topic however obtain distribution topic probability topic entire corpus example topic get distribution follows entire corpus one document topic topic topic help would appreciated thank,,2017-04-25 17:57:08,distribution topic lda using gensim,gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
12248,12248,43647749,2017-04-27 02:40:34,,already trained word vec model gensim model word vec mean acquire frequency word model,,2020-10-01 08:40:31,acquire word frequency word vec model,python word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12252,12252,43580272,2017-04-24 05:16:36,,went word vec tutorial wa able train given example data text corpus tutorial link tried test custom data model training input unicode string format python list min count also set since wa training input format tried check type input given tutorial receive format class gensim model word vec text corpus sure train custom data unicode string sentence list anyone please guide right direction example input u sentence start u dont u let u u treat u u like u garbage u sentence end train word vec understand tutorial example tutorial work,2017-04-24 06:05:32,2017-05-16 05:41:59,word vec model training input sentence tried sequence sentence tokenized word list,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12259,12259,43598212,2017-04-24 21:43:49,,looking way dinamically add pre trained word vector word vec gensim model pre trained word vec model txt word embedding need get word mover distance example via gensim model word vec wmdistance document specific corpus new document prevent need load whole vocabulary would want load subset pre trained model word found corpus new document ha word found corpus original model vocabulary add model considered computation want save ram possible thing would help way add word vector directly model way load gensim matrix another object could object ram append new word loading model need gensim know different implementation wmd get vector input would work though need python thanks advance,,2020-01-22 22:27:23,add word embedding word vec gensim model,python nlp word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12283,12283,43668207,2017-04-27 21:28:16,,unable understand print output code want print keyphrases tfidf score thank,,2017-05-03 09:34:11,print gensim dictionary corpus,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
12291,12291,43712401,2017-04-30 23:25:09,,function differs line avoid code duplication want create base class general form function inherit class function function see difference,2018-02-17 06:20:13,2018-02-17 06:20:13,refactor repeated code,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
12300,12300,43656999,2017-04-27 11:52:14,,unstructured data k document trying group document using unsupervised learning algorithm currently using lda latent dirichlet allocation gensim python ldamodel passed num topic hence whole k data falling topic group question assign new document topic approach taking calculate sum word score document per topic assign document topic highest score however giving good result better way get assign main keywords denote topic,2017-05-02 06:18:57,2017-09-13 12:49:51,lda assigning keywords topic,python-3.x cluster-analysis gensim lda unsupervised-learning,,,CC BY-SA 3.0,False,False,True,False,False
12311,12311,43772128,2017-05-04 00:51:45,,lda model trained mallet java three file generated mallet lda model allow run model file infer topic distribution new text would like implement python tool able infer topic distribution given new text based trained lda model want trained lda model python therefore wonder possible load trained mallet lda model gensim python lda package thanks answer comment,,2019-04-02 18:10:44,use gensim python lda package use trained lda model mallet,gensim lda mallet,,,CC BY-SA 3.0,False,False,True,False,False
12338,12338,43776572,2017-05-04 07:31:22,,trained doc vec corresponding word vec corpus using gensim want visualise word vec using sne word dot figure ha word also looked similar question sne word vec following code import gensim import gensim model g give figure dot word know dot representative word display word dot,2017-05-23 12:26:07,2020-09-05 20:07:36,visualise word vec generated gensim,scikit-learn data-visualization gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,True
12375,12375,43855348,2017-05-08 19:01:26,,getting following error training doc vec model jupyter notebook x error reproducible although specific thread occurs change current dataset although successfully trained model datasets,,2017-05-15 22:36:58,runtimeerror release unlocked lock training doc vec,gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12404,12404,43815130,2017-05-05 23:39:21,,exercise intro deep learning assignment us bag word represent tweet achieve played around tool came across following question represent tweet use word vec directly instead training tweet embedding vector use word vec use pre trained model ii train tensorflow architecture obtain embeddings word vec e dimension change due continuation previous bow model additional change due embeddings previously wa iii necessary obtain embeddings given data tweet training word vec scratch train data around k tweet using word vec gensim glove word vec preprocess stopping word,,2017-05-05 23:39:21,understanding word embeddings converting bag word tweet,tensorflow sentiment-analysis,,,CC BY-SA 3.0,False,False,True,False,False
12412,12412,43896195,2017-05-10 14:59:56,,trained lda algorithm corpus like getting sentence topic corresponds order make comparison algorithm find label tried code result quite bad find great deal topic maybe volume closer thanks help,,2017-05-11 07:37:11,gensim find topic sentence,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
12415,12415,43878332,2017-05-09 19:26:59,,saved gensim dictionary disk load attribute dict populated simple piece code save dictionary load loading jupyter notebook still work fine mapping token id doe work map id token fact populated thought,,2017-05-11 13:36:18,gensim saved dictionary ha id token,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
12423,12423,43918566,2017-05-11 14:37:58,,trying mimick n gram parameter countvectorizer gensim goal able use lda scikit gensim find similar bigram example find following bigram scikit abc computer binary unordered gensim survey graph minor attached code make comparison gensim scikit term bigram unigrams thanks help gensim model find unique token print unigram bigram print dictionary token id scikit unique token print scikit vocabulary print vocab,,2017-05-11 16:25:48,trying mimick scikit ngram gensim,python scikit-learn gensim,,,CC BY-SA 3.0,False,False,True,False,True
12434,12434,43881924,2017-05-10 00:49:37,,trained paragraph vector model gensim using considerable amount text data next test verified index sentence inferred vector computed cosine similarity wa low opposite expected someone tell something wrong please thanks,2018-11-28 10:43:05,2018-11-28 10:43:05,inconsistent similarity betwen inferred trained vector doc vec,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12447,12447,43868822,2017-05-09 11:39:10,,order use latent semantic indexation method gensim want begin small classique example like question get corpus iterator wiki en tfidf mm must download somewhere searched internet find anything help please,,2017-05-09 13:48:09,latent semantic indexation gensim,gensim wikidata latent-semantic-indexing bz2 latent-semantic-analysis,,,CC BY-SA 3.0,False,False,True,False,False
12453,12453,43922531,2017-05-11 17:55:58,,order make clear would like get feedback whether following code gensim usage right thank advance valuable time,,2017-05-14 06:10:59,id word token id usage confusion gensim,python python-2.7 python-3.x gensim,,,CC BY-SA 3.0,False,False,True,False,False
12459,12459,43904029,2017-05-10 23:09:25,,want analyze vector looking pattern stuff use svm complete classification task class b task supervised know may sound odd homework result really need know extract coded vector document using trained model interpret doe word vec code using gensim word vec,2017-05-11 03:25:59,2017-05-15 10:16:43,extract vocabulary vector gensim word vec,python machine-learning gensim word2vec text-classification,,,CC BY-SA 3.0,False,False,True,False,False
12460,12460,43942790,2017-05-12 16:48:23,,executing following line code available http radimrehurek com gensim wiki html downloaded wikipedia corpus generated required file wiki en wordids txt one file file available following location execute code mentioned get following error even though file available required location get error place file location determine right location,,2017-05-14 05:59:53,gensim file found error,python python-3.x gensim,,,CC BY-SA 3.0,False,False,True,False,False
12470,12470,43850721,2017-05-08 14:49:35,,file thought wa gensim dictionary file apparently one created merging dictionary however try call doc bow like get error file home rnczf desktop file patent sim newpython parse xml patentsall embedded pftaps allfiles py line iter yield self diction doc bow attributeerror vocabtransform object ha attribute doc bow,,2017-05-08 14:49:35,calling merged dictionary gensim,nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
12485,12485,44000997,2017-05-16 12:06:17,,trying run gensim wmd similarity faster typically doc example corpus best matched document great however function take extremely long time thought breaking corpus part end part max score similar problem even though output something give good similar query corpus even though get max similarity part something wrong,2017-05-19 18:22:16,2017-06-24 12:46:43,python gensim make wmd similarity run faster multiprocessing,python multithreading multiprocessing gensim,,,CC BY-SA 3.0,False,False,True,False,False
12500,12500,43985180,2017-05-15 17:07:37,,loading wiki fasttext model gensim library take six minute aware way cache model looking way speedup initial model loading specific api granted wiki fasttext large model however load model many language,,2017-05-16 12:36:24,way load wiki fasttext model faster load word vec format,nlp stanford-nlp gensim fasttext,,,CC BY-SA 3.0,False,False,True,True,False
12521,12521,44022180,2017-05-17 10:23:45,,trying load binary file using get error file file py line model gensim model word vec load ammendment vector model bin file home hp anaconda lib python site package gensim model word vec py line load model super word vec cl load args kwargs file home hp anaconda lib python site package gensim utils py line load obj unpickle fname file home hp anaconda lib python site package gensim utils py line unpickle return pickle load f encoding latin pickle unpicklingerror could find mark googled unable figure error coming please let know information required,2017-05-17 11:27:13,2017-05-18 01:56:16,unpickling error using word vec load,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12524,12524,44026369,2017-05-17 13:31:21,,wanted parallelize word vec execution gensim well let describe step done installed c compiler using mingw set env variable path downloaded tar gz file gensim installed gensim cmd command python setup py install gensim got installed without error python version gensim fast version result python gensim fast version screenshot n b using version window python version gensim version scipy version,2017-05-17 19:38:52,2017-05-24 11:27:10,parallelize execution word vec using gensim,python cython gensim,,,CC BY-SA 3.0,False,False,True,False,False
12526,12526,44060759,2017-05-19 03:08:01,,used gensim ldamodel topic extraction customer review follows return unigrams topic like looking ngrams came across sklearn latentdirichletallocation us tfidf vectorizer follows specify range ngrams vectorizer possible gensim lda model well sorry new using model know much,2017-05-19 05:05:27,2018-10-30 16:08:39,implement latent dirichlet allocation give bigram trigram topic instead unigrams,python scikit-learn nlp gensim lda,,,CC BY-SA 3.0,False,False,True,False,True
12535,12535,44005974,2017-05-16 15:44:16,,suppose filter list word want use next word vec model load construct keyedvectors contain filtered word list tried make given word get following error thank,,2017-05-16 18:39:57,speed gensim word vec model filtering word,word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12547,12547,44045881,2017-05-18 10:57:39,,trying load pre trained word vecs found http github com mmihaltz word vec googlenews vector used following command throw error,2017-05-18 18:26:04,2020-09-26 12:29:49,failed load bin gz pre trained word vecx,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12558,12558,44050492,2017-05-18 14:23:39,,new gensim wa reading experiment english wikipedia understand creates model topic word try relate company list phrase cluster manually filtering script us damerau levenshtein distance formula actually data elasticsearch use fuzzyness search score understand matching considered example cluster let say clustered fuzzy search elasticsearch match similar elasticsearch us damerau levenshtein distance formula script considers put cluster already validated validation done manually question gensim useful cluster word using wikipedia database dictionary also find pre trained vector done facebook know use problem tried load one file python script wa first experiment wa still know start little neural network topic related word semantics clue thanks advance,2017-05-19 07:50:36,2017-05-24 11:17:36,word clustering gensim,python neural-network cluster-analysis gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
12564,12564,44143441,2017-05-23 19:26:36,,using w v server googlenews code word vec http server running http rare technology com word vec tutorial bonus app changed loaded file file vector trained original c version word vec load file seems load without problem test http service let say got empty result execution time put except part related method case got idea might happens note use python installed gensim using pip gave gensim,,2017-05-23 23:21:57,code gensim word vec http service keyedvectors attribute error,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12566,12566,44101714,2017-05-21 20:56:02,,trying determine similarity set document one method using cosine similarity result tf idf tried use sklearn gensim implementation give similar result implementation result different matrix analyzing noticed implementation different one studied came across sklearn gensim use raw count tf apply l norm resulting vector side implementation found normalize term count like question difference implementation give better result end clustering purpose edit question clearer difference normalizing end result v normalizing term count beggining,2017-05-21 21:12:53,2017-05-23 14:26:36,sklearn gensim tf idf implementation,scikit-learn tf-idf gensim,,,CC BY-SA 3.0,False,False,True,False,True
12572,12572,44090503,2017-05-20 20:26:35,,might actually dumb question figure script gensim model word vec working thing using stanford sentiment analysis databank dataset review trying build word vec using gensim script problem script run give huge similarity every pair word addition word sentence built vocabulary must something obviously wrong figure thank help,2017-05-23 10:28:57,2017-06-09 13:22:44,gensim word vec poor training performance,python-3.x dataset text-mining gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12591,12591,44146401,2017-05-23 23:03:42,,title pretty much say test code raise following error truncated since irrelevant stack info fine super go run exact command cmd exe cygwin error code run fine even test return code echo cygwin return help much appreciated,,2019-08-07 02:59:23,gensim ldamallet raising calledprocesserror running mallet command line run error,python subprocess gensim lda mallet,,,CC BY-SA 3.0,False,False,True,False,False
12602,12602,44011706,2017-05-16 21:15:43,,read page understand different model built based following code know dbow word training doc vector faster first model second model,,2017-05-17 01:07:38,different doc vec model dbow word set,gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12604,12604,44163836,2017-05-24 16:24:45,,trained doc vec model using train default setting worked wondering infer vector combine across input word average individual word vector add wondering misunderstanding,,2017-05-25 07:34:35,doe doc vec infer vector combine across word,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12607,12607,44169631,2017-05-24 22:42:20,,trying use gensim summarizer keywords extract important keywords summarizing content however getting following error traceback checked version gensim using anaconda distribution installed gensim using help would greatly help thanks,,2017-05-26 16:51:40,getting import error using gensim summeraization,python-2.7 gensim,,,CC BY-SA 3.0,False,False,True,False,False
12608,12608,44051051,2017-05-18 14:48:50,,using gensim version trained two separate word embeddings using text parameter training calculating pearsons correlation word occurrence frequency vector length one model trained using loaded using trained using loaded using understand word vec algorithm non deterministic result vary however difference correlation two model quite drastic method using instance,,2017-05-18 15:11:01,gensim save word vec format v model save,python nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12614,12614,44150201,2017-05-24 06:06:14,,question concern proper training model unique really specific use word vec model see word vec detail working identifying noun adjective relationship within word embeddings e g nice car sentence data set given word embeddings corpus noun adjective labeled trying design technique find proper vector connects nice car course trying connect pair word technique would relationship supervised approach taken moment try work towards designing unsupervised method understand trying explain problem obviously know word vec need trained large amount data learn proper embeddings accurately possible afraid give data data set labelled sentence afraid give data train e g latest wikipedia dump data set learn better vector extra data influence positioning word word relationship biased extra training data e g also nice apple extra training data positioning word nice could compromised hopefully make sense making bad assumption dilemma bad vector enough training data good vector compromised vector positioning word embeddings would proper way train much training data possible billion word labelled data set sentence thank kindly time let know anything explained doe make sense,,2017-05-24 11:04:27,train word vec model properly special purpose,vector deep-learning gensim word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
12658,12658,44158856,2017-05-24 12:47:53,,implemented finding similar document based particular document using lda model using gensim next thing want multiple document get similar document based multiple document provided input implemented lda using link sample code single query another doc implement,,2018-05-26 13:07:15,calculate document similarity using one query,python gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
12664,12664,44249358,2017-05-29 19:32:17,,would like find outlier dataset using lda order specify outlier case planning use bound perplexity value new unseen document trained model sort value ascending order check whether outlier issue could get bound perplex value individual doc model throw typeerror int object subscriptable error would appreciate help solve case case attaching code thanks advance,,2017-06-02 17:30:23,get bound perplexity value new unseen document trained model,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
12669,12669,44233296,2017-05-29 00:37:15,,trying use gensim ver get cosine similarity document relatively simple problem retrieving vector document cosine similarity try retrieve document label gave training get key error example tell key however print see thing like appears every document saving sentence document name underscore number either training incorrectly b understand retrieve doc vector anyone help train doc vec us class got class web tutorial http medium com klintcho doc vec tutorial using gensim ab ac help get around doc vec weird data formatting requirement completely understand honest doe look like class written adding sentence tutorial seems still retrieve document vector giving filename wrong,,2017-05-29 06:57:08,problem accessing docvectors gensim,gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12673,12673,44213766,2017-05-27 06:32:19,,purpose build something like q bot generate sentence according input sentence user use pre trained word vec gensim input model word chinese think matter word vec first turned sentence array shape sample n time step word dim time step equal length sequence sequence already done zero padding thus length fixed next build simple seq seq model like said simple attention layer feed last output current input decoder loss value wa negative training afterward use training data prediction turn output vector back sentence however word sentence something weird changed loss function mse seems improved little bit least loss negative think correct way solve figure value word vec dimension order use categorical crossentropy need normalization word vector training use softmax activation function output layer prediction convert normalized vector back origin called denormalized turn sentence fine method use normalized change loss function layer deal unbound value new nn kera way solve thanks,,2017-05-27 06:32:19,use word vec seq seq model kera,nlp deep-learning keras word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12741,12741,44352552,2017-06-04 09:22:06,,dataframe like try create dictionary corpus comment term face error message,,2019-01-07 23:51:29,typeerror doc bow expects array unicode token input single string using gensim corpus dictionary,python dictionary gensim,,,CC BY-SA 3.0,False,False,True,False,False
12743,12743,44371835,2017-06-05 15:00:06,,want import word vecters created tensorflow utilize gensim method tried method following exactly way training wordvec tensorflow importing gensim example word word save file load kwarg binary false error like raised solve problem,,2017-06-05 17:41:28,importing word vector tensorflow gensim,python tensorflow gensim word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
12760,12760,44282320,2017-05-31 10:30:49,,want use gensim train word vec model python gensim numpy mkl scipy run code cause error attributeerror module gensim ha attribute model make error due named file gensim py thank burhankhalid,2018-04-15 07:55:44,2019-07-24 04:50:31,solve error module gensim ha attribute model,python python-3.x gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12762,12762,44315325,2017-06-01 19:09:36,,blackbox lda model output word topic distribution like follows proceed calculate perplexity looking gensim lda code found use variational lower bound method access internal topic parameter calculate blackbox model access dump initial parameter alpha beta,,2017-06-01 19:09:36,given word topic distribution calculate perplexity,text-mining evaluation lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
12772,12772,44301061,2017-06-01 07:23:07,,set document also title topic based want categorize document preference use lda gensim way feed list topic topic modeling algorithm,,2017-10-29 14:37:35,lda lsi topic modelling gensim predefined list topic,gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
12773,12773,44306123,2017-06-01 11:20:24,,sentiment prediction based document vector work pretty well example show http github com rare technology gensim blob develop doc notebook doc vec imdb ipynb http linanqiu github io word vec sentiment wonder pattern vector making possible thought similarity vector making somehow possible gensim similarity measure rely cosine similarity therefore tried following randomly initialised fix compare vector get cosine similarity compare vector vector training test set use similarity label train set estimate logistic regression model evaluate model test set look like train test array contain document vector train test label label either notice document vector obtained genism doc vec well trained predicting test set right directly used input logistic regression turn approach doe work predicting test set question information vector making prediction based vector work similarity vector approach simply possible capture similarity vector correct,2017-06-01 20:06:53,2017-06-02 01:06:04,information document vector make sentiment prediction work,machine-learning sentiment-analysis gensim feature-selection doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12774,12774,44338377,2017-06-02 22:41:55,,trying unsuccefully install python package gensim first followed direction including updating trying install entered got following error massage tried install using anaconda described got tried install directly git got similar error tried work way around using wa able install gensim package newly created folder even though default python python conclusion understood probably python wa compiled ssl support fix may able win long battle understand fix plus understand insists installed python manual say package also compatible python,,2017-06-06 13:35:50,install gensim ubuntu anaconda,ubuntu ssl anaconda gensim python-3.6,,,CC BY-SA 3.0,False,False,True,False,False
12785,12785,44323816,2017-06-02 08:05:15,,word vec model loading python script consumes gb ram impossible use way use model without loading complete model ram,,2017-06-02 08:30:22,word vec reduce ram consumption loading model,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12796,12796,44345576,2017-06-03 15:29:31,,calculated document similarity using doc vec docvecs similarity gensim would either expect cosine similarity lie range gensim used absolute value cosine similarity metric roughly half negative doe however seeing similarity negative rare le pairwise similarity set document almost similarity positive,,2017-06-05 14:51:37,almost cosine similarity positive word document vector gensim doc vec,python gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12799,12799,44497215,2017-06-12 10:29:01,,training model corpus many short sentence sentence ha frequency indicates time occurs total corpus implement follow see choose repeat time way data small work data grows frequency large cost much memory machine afford count frequency every record instead repeat time way save memory corpus something like,2017-06-12 10:42:51,2017-06-12 18:46:45,count frequency gensim doc vec,python gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12805,12805,44386503,2017-06-06 09:39:09,,working word vec model using gensim python found result word theme synonym part result find synonym word based work done reply appreciated,,2017-06-12 03:44:45,find synonym based word vec,word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12819,12819,44461656,2017-06-09 15:32:12,,setup follows python version numpy version scipy version gensim version gcc compiler version system window bit get following error setup make run time far slow training model gensim feel problem package version using installed install numpy using install scipy using install gensim using reason setup try install scipy using get error install scipy via also try install gensim using installs version tried get error numpy scipy work fine independently import script import fine use functionality however used gensim clearly problem know would anyone able advise possible fix ideally would like keep latest version package possible thank advance note gensim work fine fast version gensim version installed version dependency,2017-06-09 16:01:30,2017-10-10 10:02:38,gensim slow version gensim model doc vec used,python numpy scipy pip gensim,,,CC BY-SA 3.0,False,False,True,False,False
12822,12822,44439291,2017-06-08 15:01:24,,gensim word vec keyedvectors model speed purpose would like parallelize program run spark environment however far aware spark rdds work collection iterables think could actually see performance boost simply putting keyedvectors model rdd explored storing model broadcast variable far large partitioning using rdd look like best option wanted boost program performance converting model parallel collection spark would go,,2017-06-08 15:01:24,parallelizing gensim keyedvectors model spark,apache-spark pyspark rdd gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12826,12826,44443675,2017-06-08 19:02:46,,using pre trained doc vec bow model ap news following compute vec text getting different vector representation text happening aviod want vector returned give exactly text tried following post doe seem help,,2020-01-07 17:52:06,removing randomization vector initialization doc vec,python random gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12833,12833,44516295,2017-06-13 08:37:05,,one tf idf example isi paper trying validate code example get different result code know reason term document matrix paper tf idf matrix paper tf idf matrix code tried another code like get appropriate answer,,2017-06-14 06:03:49,tf idf calculation using gensim,python tf-idf gensim,,,CC BY-SA 3.0,False,False,True,False,False
12862,12862,44449132,2017-06-09 04:05:11,,made doc vec file training data using gensim model processing getting error running code model doc vec load sentiment v getting keyerror test po want know wrong,,2017-06-12 03:25:59,getting error using gensim model python,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12869,12869,44506950,2017-06-12 19:05:05,,trying pull python english wikipedia corpus http dump wikimedia org enwiki latest enwiki latest page article xml bz perform deep learning using gensim gb got sitting large ec machine aws load run jupyter notebook basically hung trying load watching memory consumption loading extremely slowly hour gb way speed,2017-06-12 19:06:23,2017-06-22 09:48:08,speed loading xml bz file memory,python deep-learning gensim,,,CC BY-SA 3.0,False,False,True,False,False
12874,12874,44471602,2017-06-10 09:14:02,,problem deploying python module heroku based python requirement txt file module trouble uploading konlpy gensim already installed module virtual environment also set buildpack gensim konlpy error log trying deploying word vec heroku thank,,2018-02-16 13:57:06,deploy python module heroku,python-2.7 heroku word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12882,12882,44490739,2017-06-12 02:46:16,,trying run program using gensim library python version whenever ran program came across statement understand meaning behind gensim selecting slow version want fastest version need,2017-06-12 03:04:24,2017-10-10 10:06:35,using gensim show slow version gensim model doc vec used,python python-3.x gensim,,,CC BY-SA 3.0,False,False,True,False,False
12901,12901,44432464,2017-06-08 09:55:47,,code getting error info loading doc vec object c user desktop sentiment v info loading wv recursively c user desktop sentiment v wv mmap none info setting ignored attribute syn norm none info loading docvecs recursively c user desktop sentiment v docvecs mmap none info setting ignored attribute cum table none info loaded c user desktop sentiment v please input train po count train neg count classifier c user appdata local continuum anaconda lib site package ipython core interactiveshell py userwarning exit use exit quit ctrl warn exit use exit quit ctrl stacklevel exception ha occurred use tb see full traceback systemexit,,2017-06-08 09:55:47,getting system exit error modelling test data,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12910,12910,44581914,2017-06-16 06:07:00,,building nlp chat application python using library model hard coded document given set training example testing model throwing user question finding similar document first step case test question exact copy document training example result similarity since exactly improve accuracy specific way training document missing something,2017-06-16 06:23:46,2017-06-16 18:36:40,improve cosine similarity two document sentence doc vec model,python nlp gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12921,12921,44553278,2017-06-14 19:34:58,,planning use multi layer perceptron classifier scikit learn purpose output gender word shall represented one hot encoding like male female female one input word vector word vector ha dimension feature part speech tag singularity plurality state question use word vector array feature mlpclassifier,,2017-06-14 22:26:18,use word vector returned word vec feature,python scikit-learn neural-network gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,True
12927,12927,44605649,2017-06-17 14:15:59,,recently interested nlp would like build search engine product recommendation actually always wondering search engine google amazon built take amazon product example could access word information one product applying package could easily compare similarity different product make recommendation another question feel vague build search engine product example feel pain would like search medicine online like type whose searching result include sound like keyword extraction tagging question done nlp know corpus contain single word like typed either could get searched could come idea directly call python javascript calculate similarity input word browser based server make recommendation kind able still prefer build big list keywords backends stored datasets database directly visualized web page search engine thanks,,2017-06-18 15:47:35,natural language processing keywords building search engine,nlp nltk search-engine gensim corpus,,,CC BY-SA 3.0,True,False,True,False,False
12928,12928,44606735,2017-06-17 16:17:55,,want extract topic article test article http julien danjou info blog announcing scaling python aticle python scalling tried lsi lda time lda seems work better output stable course first three five keywords seem hit target python book project think project useful topic drop stopwords list scaling scalable openstack keywords list stable topic list stopwords list might improve result scalable maintain different list different domain question better solution improve algorithm lda model demo code code lsi test result test result,,2017-06-22 09:39:25,improve topic model gensim,python gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
12938,12938,44571617,2017-06-15 15:36:38,,sometimes return probability topic fine sometimes return probability topic add one seems depends document generally return topic probability add le returning relevant topic way force return probability maybe missing something find documentation method parameter,,2020-04-27 16:51:03,probability returned gensim get document topic method add one,text-mining gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
12955,12955,44610300,2017-06-17 23:20:19,,list title trying use gensim find closest related title code running tokenization tokenize title sentence tokenized sent variable tokenizes header wrong,2017-06-17 23:51:46,2017-06-17 23:51:46,unable tokenize sentence using gensim nltk python,python pandas nltk tokenize gensim,,,CC BY-SA 3.0,True,False,True,False,False
12959,12959,44613624,2017-06-18 09:32:35,,train model use infer vector get vector successfully save model load error appears follows whole code,2017-06-18 09:34:38,2017-06-20 20:09:07,save gensim doc vec model,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
12973,12973,44710644,2017-06-22 23:06:43,,trained word vec model using gensim package saved following name got log message info model wa getting trained saved tried load model using got following error also file feature minwords context show fix attribute error also tried following google forum resulted another error model trained utf encoded sentence sure throwing error info use mac roman encoding order access using panda dataframe since text dataframe ha utf training model saved particular feature separate csv file encoding utf later accessed particular column help appreciable,2017-06-23 02:31:07,2017-06-23 07:37:30,word vec saved model utf encoded sentence input word vec model utf encoded,python-3.x utf-8 nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12982,12982,44693241,2017-06-22 07:44:56,,file contains million word vector think sure file loaded following line written want download vector word give externally list called code run code freeze system loading whole binary file searching word yes get around issue think get following warning use package suppress error give guess mean program able search word binary file solve,2017-06-22 08:13:53,2017-06-22 09:01:44,extract word vector google pre trained model word vec,python file-handling gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
12996,12996,44732303,2017-06-24 02:56:11,,trying build docker application us python gensim library version installed via pip requirement txt file however docker seems trouble installing numpy scipy gensim googled error message found user experienced problem environment many solution seem work docker following error message using image version package,,2017-06-30 12:28:01,docker unable install numpy scipy gensim,python numpy docker scipy gensim,,,CC BY-SA 3.0,False,False,True,False,False
13010,13010,44698910,2017-06-22 12:02:19,,building nlp chat application using doc vec technique python using package already done tokenizing stemming want remove stop word test work better training set well question user throw code way remove stop word directly get new set vocab without stop word,,2017-06-22 21:05:31,remove stop word document gensim,python nlp gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13012,13012,44657908,2017-06-20 16:01:51,,expert nlp related model may missing simple point please bear obtained topic corresponding keywords topic want first cluster document based topic want see document belongs topic next given new document need find document cluster belongs think need pas new document lda model used obtain topic use generated topic measure similarity previously obtained topic however sure work example new document short document know work help extremely useful thank btw using python gensim package lda algorithm,,2017-06-20 16:01:51,deciding document cluster new document belong,python-2.7 nltk gensim,,,CC BY-SA 3.0,True,False,True,False,False
13034,13034,44787568,2017-06-27 18:37:50,,trying determine optimum number topic lda model using log perplexity python graphing log perplexity range topic determining minimum perplexity however graph obtained ha negative value log perplexity positive value,,2017-06-27 18:37:50,determining log perplexity using ldamulticore optimum number topic,python-2.7 gensim lda topic-modeling perplexity,,,CC BY-SA 3.0,False,False,True,False,False
13038,13038,44831480,2017-06-29 17:25:57,,using model order calculate similarity two word training model mb wikipedia text gave good result similarity score related pair word problem using model add phrase similarity score drop nearly zero exact word result phrase model probably mean using phraser model correctly code trying pharser model alone look like worked fine cause behavior trying figure solution according gojomo answer tried create using iterator tried train model word vec training log training two similarity calculation produce zero seems iterator working well checked using gojomo trick working may problem,2017-07-01 15:06:56,2017-07-01 15:57:13,word vec gensim calculating similarity word working using phrase,python deep-learning gensim word2vec phrases,,,CC BY-SA 3.0,False,False,True,False,False
13052,13052,44849368,2017-06-30 14:56:28,,multiple text file trying find way identify similar body text file consist average sized paragraph top also data could used lables data go root neural network saimese network wa one option another possibility wa wondering wa using something doc vec order process paragraph removal stopwords attempting find similar file text based upon cosine doc vec wa wondering method outlined generally compare term result produce doc vec robust accurate enough consider viable option also may overlooking good method,,2017-07-10 23:59:22,training network find similar body text,nlp nltk gensim spacy doc2vec,,,CC BY-SA 3.0,True,True,True,False,False
13056,13056,44871728,2017-07-02 14:14:36,,used gensim package python load pre trained google word vec dataset want use k mean find meaningful cluster word vector find representative word cluster thinking use word whose corresponding vector closest centroid cluster represent cluster know whether good idea experiment give good result example code like output code category word vehicle fruit animal output see k mean correctly clustered word category representative word derived using centroid method good class want see animal give rabbit class want see vehicle return car help suggestion finding good representative word cluster highly appreciated,2017-07-02 14:21:18,2017-07-03 11:38:53,find meaningful word represent k mean cluster derived word vec vector,python k-means gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13071,13071,44781047,2017-06-27 13:04:51,,following english wikipedia gensim tutorial http radimrehurek com gensim wiki html latent dirichlet allocation explains tf idf used training least lsa clear lda expected apply tf idf transformer new document instead end tut suggests simply input bag word doe lda require bag word vector,,2018-08-20 10:01:09,necessary apply tf idf new document gensim lda model,gensim,,,CC BY-SA 3.0,False,False,True,False,False
13108,13108,44763743,2017-06-26 15:55:56,,thousand document associated tag information however also many document without tag want train model document tag apply trained classifier untagged document classifier suggest appropriate tag untagged document done quite lot research seem supervised implementation document tag classification know nltk gensim word vec library useful problem coding project python help would greatly appreciated,,2017-06-26 18:01:56,supervised tag suggestion document,python machine-learning nlp text-classification,,,CC BY-SA 3.0,True,False,True,False,False
13110,13110,44910999,2017-07-04 16:54:25,,fairly new nlp embedding world used gensim word vec model tensorflow vector representation question training gensim word vec model take tokenize sentence tensorflow take long list word doe differ training quality impact also doe tensorflow cater need skip gram data list word sentence referring tensorflow tutorial found link http www tensorflow org tutorial word vec pardon understanding domain wrong would appreciate understanding cleared thank guidance help,,2017-07-04 16:54:25,doe gensim word vec differ tensorflow vector representation,vector tensorflow nlp gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
13168,13168,44993240,2017-07-09 05:19:44,,use train data train model use generate vector given document trained data different value cosine wa small distance wa saved model wa generated reasonable ah find error use string u instead string correct way cosine distance,2017-07-09 06:15:57,2017-07-09 16:15:45,use infer vector gensim doc vec,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13171,13171,44944249,2017-07-06 08:58:52,,trying install package python getting following error find anything regarding error please suggest,,2020-03-03 05:08:50,pip install pyemd error,python nlp pip gensim,,,CC BY-SA 3.0,False,False,True,False,False
13172,13172,44957082,2017-07-06 19:10:13,,spacy built method creating vector representation performed nlp corpus used similarity cosine similarity map document similar however unsure method spacy us create vector representation knowledge thinking probably word vec skip gram negative sampling however would like sure,,2017-07-07 10:37:54,doe spacy use create vector representation,python nlp gensim word2vec spacy,,,CC BY-SA 3.0,False,True,True,False,False
13182,13182,44964380,2017-07-07 06:56:08,,corpus built wikimedia dump file stored sentence txt sentence say try extract word vector always one two word missed training despite included list trained upon get keyerror way improve training miss word frequently proof doe happen word tokenizer well return list sentence corpus stored inside sentence txt see check word inside list tokenized sentence present list feed word vec trainer yet training vocabulary,2017-07-08 22:14:19,2017-07-10 19:51:19,gensim loss word token training,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13186,13186,45037860,2017-07-11 14:46:45,,gensim doc vec trying load google pre trained word vector instead using object trained labeled doc infer vector document anyone know use doc vec google pretrained word vector tried post http mccormickml com google pretrained word vec model python doe work load object perhaps different gensim version,2018-10-23 23:51:20,2018-10-23 23:51:20,gensim doc vec google pretrained vector,gensim,,,CC BY-SA 4.0,False,False,True,False,False
13193,13193,44983315,2017-07-08 06:40:33,,applied lda gensim package corpus get probability term problem get term without probability code output example like want idea thanks advance,,2017-07-09 08:40:50,get topic term lda,python-3.x gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
13209,13209,44929582,2017-07-05 14:50:39,,using window installed python gensim using pip install gensim try import gensim python console get following error seen similar error stackoverflow seem trick thank help,,2017-10-07 14:54:53,gensim importerror dll load failed specified module could found,python windows installation gensim,,,CC BY-SA 3.0,False,False,True,False,False
13226,13226,45007902,2017-07-10 09:05:57,,want know loss w v model upgrade latest version still use argument miss something,,2017-07-13 20:10:12,word vec object ha attribute compute loss,gensim,,,CC BY-SA 3.0,False,False,True,False,False
13235,13235,45046058,2017-07-11 23:34:25,,new doc vec wish classify set text using confused taggeddocument taggedlinedocument difference two taggedlinedocument collection taggeddocuments directory containing file generate feature vector create new file line contains text file directory,,2017-07-12 01:36:48,difference taggeddocument taggedlinedocument gensim work file directory,nlp gensim word2vec text-classification doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13249,13249,45159693,2017-07-18 06:59:03,,trying make word vec model gensim persian language ha space character delimiter use python problem encounter wa gave text file input return model consists character separately instead word also gave input list word recommended python gensim word vec vocabulary key work think consider sequence word sentence correct preprocessing input consist collapse multiple whitespaces single one tokenize splitting whitespace remove word le character long remove stop word gave text word vec gave result correctly need python choice limited use gensim also tried load model made word vec source gensim get error need create word vec model gensim code,2019-07-07 05:05:36,2019-07-07 05:05:36,word vec model consist character instead word,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
13257,13257,45069715,2017-07-13 00:47:01,,loaded word vec model using google news dataset want get word vec representation list sentence wish cluster going documentation found sure looking way get word vec representation list sentence pretrained model right none link searched anything lead would appreciated,,2017-07-13 06:12:44,loading pretrained word vec model get word vec representation new sentence,cluster-analysis gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13259,13259,45070186,2017-07-13 01:49:54,,trying ask user input company name example microsoft able predict computer software industry around name industry name english company name tried training word vec model using gensim based company name averaged word vector feeding sklearn logistic regression terrible result question ha anyone tried kind task googling short text classification show result classifying short sentence instead pure name anyone tried mind sharing keywords research paper regarding task would better brief description company instead using name much would help word vec model rather using company name,2017-07-18 16:11:45,2017-07-18 16:11:45,machine learning classify company name industry,python machine-learning text-classification multilabel-classification,2017-07-18 16:14:09,,CC BY-SA 3.0,False,False,True,False,True
13270,13270,45091817,2017-07-13 22:20:01,,array containing vector vector respectively vector array tfidf value using gensim example trying build item user matrix sorting user similar item loop method cost lot time finish handle efficiently help appreciable expected output,,2017-07-13 22:24:34,python get cosine similarity matrix efficiently,python numpy gensim cosine-similarity,,,CC BY-SA 3.0,False,False,True,False,False
13272,13272,45164340,2017-07-18 10:36:34,,new gensim word vec wa trying use word vec build word vector raw html file first convert html file txt file first question train word vec model everything fine want test accuracy model produced error sample file file actually begin many know space open vim look like problem second question also text classification biomedical paper file wa given raw html file either japanese english ascii conversion stop word cleaning still many html code left file try clean file restrict character za z found medical term like protein something get properly cleaned well suggestion clean file,,2017-07-18 16:46:33,gensim word vec error valueerror missing section header line,python html nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13277,13277,45125798,2017-07-16 06:35:56,,two directory want read text file label know via thought would work taggeddocument string label work apparently code error get,2018-12-15 19:32:14,2019-07-22 20:13:46,use taggeddocument gensim,python nltk gensim word2vec doc2vec,,,CC BY-SA 4.0,True,False,True,False,False
13288,13288,45186094,2017-07-19 09:16:06,,want use word vec web server production two different variant fetch two sentence web compare real time testing local machine ha gb ram scenario w v load w v model already read solution reducing vocabulary size small size would like use vocabulary new workarounds handle way initially load small portion vocabulary first minute parallel keep loading whole vocabulary,2017-07-20 08:28:14,2018-06-04 20:45:33,make word vec model loading time memory use efficient,python nlp nltk gensim word2vec,,,CC BY-SA 3.0,True,False,True,False,False
13303,13303,45170589,2017-07-18 15:05:37,,training word vec cope word end sentence use exact word beginning another sentence context word center word end last sentence,,2017-07-18 16:48:58,word vec deal end sentence,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13316,13316,45193550,2017-07-19 14:26:08,,recently updated conda environment python python environment made project using gensim wich worked perfectly update using library generates multiple error guy know happens gensim explicitly say python supported used code list package installed,2017-07-20 07:27:28,2017-07-20 08:02:28,gensim error updating python version conda,python-3.x conda gensim,,,CC BY-SA 3.0,False,False,True,False,False
13328,13328,45195169,2017-07-19 15:37:04,,trying run doc vec library gensim package problem training saving model model file rather large gb tried using line change anything also tried change max vocab size decrease space wa luck somebody help matter,,2017-07-19 17:48:30,gensim doc vec generating huge file model,python semantics gensim word2vec doc2vec,2017-07-19 20:34:04,,CC BY-SA 3.0,False,False,True,False,False
13340,13340,45243316,2017-07-21 17:19:59,,document similarity corpus using doc vec outputting good similarity wa wondering could topic model doc vec giving increase accuracy model order get better similarity,,2017-07-21 23:46:52,create topic model lda output doc vec model,nlp gensim lda topic-modeling doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13345,13345,45108291,2017-07-14 17:05:14,,would like use embeddings made w v order obtain likely substitute word given context surrounding word rather supplying individual word example sentence would like go park tomorrow school want find candidate similar park typically would leverage similarity function gensim model obtain semantically similar word however could give similar word verb park instead noun park wa way query model give surrounding word context provide better candidate,,2017-07-15 01:55:41,python word vec context similarity using surrounding word,python gensim word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
13350,13350,45152693,2017-07-17 20:01:01,,panda series around k line one text per line wanted extract output array line trained w v testing data set using following code error received doe kill ipython session solve,2017-07-17 20:20:33,2017-07-17 20:20:33,gensim word vec start new thread,python multithreading gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13352,13352,45154833,2017-07-17 22:50:11,,know skip gram model learns vector representation element based long sequence element context model ha commonly applied natural language concatenating giant collection text document often concatenated single long line text distinction new document begin end end much issue nlp percentage model training instance involving overlapping document small percentage total number instance education data overlap much higher shorter sequence high number user formerly document nlp also problem behavioral datasets education problem manifest inspecting learned vector finding model ha determined many student first encountered element similar student last encountered element bi product wrapping line input gensim instance spanning end one student sequence beginning another identify code overlapping occurs prohibit overlap happening training gensim,,2017-07-17 23:24:20,prevent overlapping word vec,python nlp gensim word2vec,2017-07-18 08:55:16,,CC BY-SA 3.0,False,False,True,False,False
13384,13384,45310409,2017-07-25 17:51:48,,need use gensim get vector representation word figure best thing use would word vec module pre trained english wikipedia corpus doe anyone know download install use gensim create vector,,2017-12-14 04:26:24,using word vec model pre trained wikipedia,wikipedia gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13385,13385,45310925,2017-07-25 18:21:31,,train lda model want get full topic distribution every document particular case want document topic contributing distribution want able access topic contribution output lda adhering strictly mathematics lda however gensim output topic exceed certain threshold shown example try show topic contribute document tried solution link however doe work still get output produce output e topic per document question change threshold access full topic distribution document access full topic distribution matter insignificant contribution topic document reason want full distribution perform kl similarity search document distribution thanks advance,,2018-10-19 13:42:25,get complete topic distribution document using gensim lda,python gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
13388,13388,45234310,2017-07-21 09:40:29,,training model like model like data comparable parameter using model classification task found simply averaging summing embeddings document performs considerably better using vector also tried much iteration make difference tip idea improve result update created fact data training data contains document word average vocabulary size word data classification task much smaller average word average also tried split training data line train model like almost result data natural language please keep mind,2017-07-22 13:14:19,2017-07-22 13:14:19,doc vec worse mean sum word vec vector,python machine-learning gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13395,13395,45276029,2017-07-24 08:47:11,,according gensim model word vec api reference compute loss valid keyword however get error say update word vec class github doe compute loss keyword local library doe see gensim documentation library deviate found file conda repository date however uninstalling gensim conda change anything still work apparently source github distributed library different tutorial seems assume code github end update followed downloaded tutorial notebook word vec input first cell training loss computation headline get error word vec class initializer input output gensim installed via conda new new clone gensim repository tutorial notebook using bit python window anaconda tried search others encounter successful know reason fix apparently source github distributed library different tutorial seems assume code github also previously posted question official mailing list,2017-07-25 10:44:31,2017-07-31 09:04:15,gensim word vec recognize compute loss keyword,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13399,13399,45346233,2017-07-27 09:10:01,,wonder similarity work gensim different shard created doe increase performance looking top n similar document generally documentation internal structure gensim,2017-07-27 12:56:46,2017-07-27 17:32:34,gensim similarity doe work,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
13400,13400,45346418,2017-07-27 09:17:59,,trying generate word vector using pyspark using gensim see word closest word using pyspark generate word vector space model pyspark equivalent gensim background need store word synonym model map use later finding sentiment tweet reuse word vector model map function pyspark model belongs spark context error pasted want pyspark word vec version instead gensim provides better synonym certain test word alternative solution also welcome,2018-01-19 22:51:23,2019-12-09 10:46:40,obtain word list pyspark word vec model,apache-spark nlp pyspark apache-spark-mllib word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13413,13413,45289256,2017-07-24 20:13:05,,big dataset trying run word vec model vocabulary constantly lowered tried different setup constructor still dataset consists machine log previously ran tfidf model dataset know sure k unique word use different dataset gensim problem definately know problem dataset know exactly sample per gensim documentation leave full vocabulary ha anyone problem datasets edit code output first line see word like cli system license etc included vocabulary info logging full dataset,2017-07-27 17:34:09,2020-01-13 15:05:14,gensim always trimming vocabulary,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
13416,13416,45352522,2017-07-27 13:39:51,,trying install gensim python ubuntu tried easy install getting error could someone help identifying going wrong easy install thank,2017-07-27 15:52:51,2017-07-28 14:40:22,issue installing gensim ubuntu,python python-2.7 gensim,,,CC BY-SA 3.0,False,False,True,False,False
13419,13419,45280020,2017-07-24 11:56:23,,generated word vec model using gensim huge corpus need cluster vocabulary using k mean clustering need cosine distance matrix word word size matrix number word x number word feature matrix word feature size matrix number word x number feature feature matrix tried use x model wv got object type gensim model keyedvectors keyedvectors much smaller expected feature matrix way use object directly generate k mean clustering,2017-07-24 20:03:44,2017-07-24 20:03:44,getting distance matrix feature matrix word vec model,python k-means gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13430,13430,45317151,2017-07-26 03:54:12,,relative new world latent dirichlet allocation able generate lda model following wikipedia tutorial able generate lda model document step try understand use previus generated model classify unseen document saving lda wiki model loading model new doc txt turn document id term dictionary converted tokenized document document term matrix run receive gensim interface transformedcorpus object x f ecfa extract topic already tried return topic relationed new document mistake miss understanding something run new model using dictionary corpus created receive correct topic point use model correctly use wiki model thank,2017-07-26 04:32:02,2019-04-29 21:15:29,gensim interface transformedcorpus use,gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
13434,13434,45425070,2017-07-31 20:50:44,,might naive question ask tokenized corpus trained gensim word vec model code cluster similar word using pca visualize cluster similar word problem forming big cluster seen image pca scatter plot code three question one article enough clear segregation cluster model trained huge corpus want predict similar word new article visualize e word article predicting form cluster way highly appreciate suggestion thank,2017-07-31 20:55:50,2017-08-01 17:55:29,python clustering similar word based word vec,python nlp cluster-analysis word2vec topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
13448,13448,45427552,2017-08-01 01:22:30,,hi file present bbc folder like sub folder inside bbc folder contains text file code help accessing file inside folder want access file subfolder getting following error kindly suggest change code,,2017-08-01 18:07:56,read file present subfolder,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13459,13459,45357552,2017-07-27 17:38:00,,new tensorflow also document similarity topic modeling therefore apologize question make complete sense limited understanding topic modelling done using algorithm lsa lda etc seen code using gensim lsa time train high large set document mind consequently cpu ram resource heavy tensorflow seem native lsa lda implementation would appreciate opinion would lda implemented using tensorflow better performance implemented using gensim could someone tell tensorflow primitive look document similarity rather lda sorry question vague cover sufficient information give proper response new domain would appreciate direction someone could point thank time regard jeetu,,2018-07-07 19:35:15,document similarity using tensorflow,tensorflow topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
13465,13465,45467699,2017-08-02 17:46:00,,using gensim doc vec model generate feature vector code using explained problem code wondering mistake parameter set update wa playing tag parameter taggeddocument changed mixture text number like doc doc see different number count generated vector still number feature vector expected,2017-08-02 22:06:59,2017-08-03 01:29:10,gensim doc vec model generates limited number vector,python nlp gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13471,13471,45419049,2017-07-31 14:48:32,,doc vec wikipedia tutorial http github com rare technology gensim blob master doc notebook doc vec wikipedia ipynb output original paper set vocabulary size seems similar size vocabulary set min count size vocab seems rather arbitrary see mentioning doc,,2017-07-31 19:47:46,doc vec scale vocab memory vocab divided obtain vocabulary size,gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13489,13489,45380351,2017-07-28 18:42:22,,suppose generated latent dirichlet allocation model using basic command question would classify new document say corpus trying use following command obtain distribution first document get following error confused regarding class object suggestion find information tutorial welcome,,2017-10-16 16:29:18,infer topic distribution new unseen document lda gensim,python lda,,,CC BY-SA 3.0,False,False,True,False,False
13499,13499,45454433,2017-08-02 07:38:26,,new doc vec hope one help issue asked number people issue nobody know solution wanto cluster doc vec result k mean please see code getting error,2017-08-02 09:09:16,2017-08-02 09:09:16,gensim doc vec model clustering k mean,python k-means gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13502,13502,45420466,2017-07-31 15:59:08,,trained word vec model using python gensim library tokenized list vocab size giving model try get similarity score one word list get keyerror word buy vocabulary guy suggest wrong way check model used train pca sne order visualize similar word forming topic thank,,2018-07-16 05:46:34,gensim keyerror word vocabulary,python nlp gensim word2vec topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
13504,13504,45424420,2017-07-31 20:04:41,,related getting string version document id gensim implementing document similarity retrieving similarity object index similarity score new document would like trace index back original document corpus based answer question look like built way achieve df feed corpus look like building model tweaking dataframes tutorial http www oreilly com learning compare document similarity using python run following new document get max similarity score index similarity object function unpacking tuple separate df column index similarity object doe match index original dataframe would carry original dataframe index similarity object would carry field original dataframe object similarity object understand keep separate mapping similarity object index original dataframe index doe mapping look like desired result,2017-07-31 20:19:49,2017-07-31 20:19:49,maintain dataframe index gensim,python python-3.x pandas indexing gensim,,,CC BY-SA 3.0,False,False,True,False,False
13508,13508,45476932,2017-08-03 06:54:34,,want use lda latent dirichlet allocation model nlp purpose train model wikipedia corpus take hour wiki corpus gb check tutorial rather place download built lda model use directly gensim,2017-08-04 03:31:18,2017-08-05 15:52:03,download trained lda model gensim,nlp gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
13517,13517,45404027,2017-07-30 19:48:11,,trying run demo gensim distributed lsi find yet whenever run code get error checked similar issue stackoverflow usually caused misuse library however using pyro directly using distributed lsi introduced gensim room mistake side believe code really simple find,,2017-08-05 10:33:07,attributeerror module pyro ha attribute expose running gensim distributed lsi,python-2.7 gensim latent-semantic-indexing pyro4,,,CC BY-SA 3.0,False,False,True,False,False
13523,13523,45458493,2017-08-02 10:37:59,,creating word vector gensim plain english text file imdb movie rating training saving model trying load back get unicodedecodeerror utf codec decode byte x position exception see tried different combination encoding parameter including iso latin also different combination binary true false nothing help exception matter parameter used wrong make loading vector work exception,2017-08-02 11:16:33,2017-08-02 15:48:40,gensim word vector encoding problem,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
13530,13530,45571295,2017-08-08 14:38:45,,using word embeddings finding similarity two sentence using word vec also get similarity measure one sentence english one dutch though good started wondering possible compute similarity two sentence two different language without explicit translation especially language similarity englis dutch,2017-08-08 15:08:50,2020-05-16 10:58:05,semantic similarity across multiple language,nlp nltk gensim word2vec,,,CC BY-SA 3.0,True,False,True,False,False
13534,13534,45572515,2017-08-08 15:34:42,,trying read large log file sixty thousand line memory want apply word vec algorithm implemented gensim tried number solution none seems working help would appreciated code code,2017-08-09 06:27:49,2017-08-09 06:27:49,reading large file memory word vec conversion,python word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13535,13535,45573181,2017-08-08 16:08:35,,using gensim excellent library compute similarity query corpus using lsi however distinct feeling result could better trying figure whether adjust corpus order improve result certain amount control split document original data ha lot short document mean length word document exist document word long logical way concatenate several document one problem know whether worth extent find material addressing question regarding size corpus size vocabulary assume end day size document bounded size vocabulary sure still general guideline could help decision considered document short long assume latter function former could easily constant value doe anyone experience anyone point direction paper blog post research address question much appreciated edited add regarding strategy grouping document document text message sent two party potential grouping based also take consideration time message sent meaning could group message sent b within certain hour certain day simply group message two also decide minimum maximum number message grouped together exactly question know ideal length,2017-08-08 17:29:40,2017-08-09 10:25:32,optimal document size lsi similarity model,gensim lsa,,,CC BY-SA 3.0,False,False,True,False,False
13536,13536,45459496,2017-08-02 11:23:27,,based article http nadbordrozd github io blog text classification word vec trying implement gensim word vec model pretrained vector glove text classification task however would like featureselection also text data tried multiple sequence pipeline get fast memory error point transform part tfidfembeddingvectorizer replace tfidfembeddingvectorizer class regular tfidfvectorizer work properly way could combine selectfrommodel w vec pipeline,,2017-11-15 07:20:33,combining w vec feature selection pipeline,python-3.x gensim text-classification feature-selection,,,CC BY-SA 3.0,False,False,True,False,False
13542,13542,45444304,2017-08-01 17:29:52,,using gensim lda implementation create document topic model distribution model trained want extract distribution matrix size n n number document corpus number topic row therefore would represent document column would represent topic distribution already available model variable e g represents simple example document topic list list tuples list document first element tuple topic id second element topic contribution document done far problem dataset k document topic creating matrix using approach take minute ultimately want create matrix feed function calculates document similarity comparing first row document matrix row document way directly feed learned model value function would great would save time creating redundant matrix efficient way create matrix reference document comparison function matrix fed,2017-08-01 17:56:21,2017-08-01 17:56:21,extract lda model value distribution matrix efficiently,python matrix gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
13550,13550,45499558,2017-08-04 06:22:59,,install gensim pkg cython continusly show warning doe anybody know using python pycharm linux mint userwarning c extension loaded word vec training slow install c compiler reinstall gensim fast training warning warn c extension loaded word vec training slow also show line create load model slow version gensim model doc vec used,,2017-08-04 11:28:20,c extension loaded word vec,python python-3.x gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13552,13552,45502464,2017-08-04 08:59:17,,using wmd calculate similarity scale sentence example reference http markroxor github io gensim static notebook wmd tutorial html however also wmd based similarity method reference http markroxor github io gensim static notebook wmd tutorial html difference two except obvious one distance another similarity update exactly except different representation http github com rare technology gensim blob develop gensim similarity docsim py,2017-08-07 10:03:44,2017-08-07 16:59:10,difference wmd word mover distance wmd based similarity,nlp nltk gensim word2vec word-embedding,,,CC BY-SA 3.0,True,False,True,False,False
13559,13559,45444964,2017-08-01 18:12:40,,struggling understand use parameter gensim documentation dimensionality vector far knowledge go word vec creates vector probability closeness word sentence word suppose size doe create vector dimension greater anyone please brief optimal value size thank,,2017-08-02 06:28:45,python size parameter gensim word vec model class,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13571,13571,45478607,2017-08-03 08:19:04,,would like use gensim implemented word vec list context word pair input instead sentence originally thought entering manually created context word pair sentence would equivalent entering raw sentence setting window parameter two approach yield different result doe gensim word vec calculate context word pair sentence enter manually created pair input function,,2017-08-03 17:02:20,using gensim word vec custom word context pair,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
13579,13579,45565389,2017-08-08 10:05:15,,looking various semantic similarity method word vec word mover distance wmd fasttext fasttext better word vec semantic similarity concerned wmd word vec almost similar result wa wondering alternative ha outperformed word vec model semantic accuracy use case finding word embeddings two sentence use cosine similarity find similarity,2017-08-08 12:22:25,2017-08-08 17:52:23,semantic similarity method outperforms word vec approach semantic accuracy,nlp nltk gensim word2vec fasttext,,,CC BY-SA 3.0,True,False,True,False,False
13622,13622,45696948,2017-08-15 16:12:28,,class wrapping various object required calculating lsi similarity want add function class allow adding document corpus updating model accordingly found two thing clear originally create lsi model one parameter function receives updating model tell use updated dictionary actually unnecessary make difference update index look documentation use class class add document index see functionality understood correctly better input corpus contains dense vector doe using lsi model change update index conversely complexity creating index insignificant create new index updated corpus follows code thanks,,2018-09-27 18:44:12,adding document gensim model,python-3.x gensim lsa,,,CC BY-SA 3.0,False,False,True,False,False
13643,13643,45647333,2017-08-12 06:41:01,,trained word vector like normally would cleaned text hand line sentence token separated space issue vector return array value numpy infs already retrained vector time know causing,,2017-08-12 06:41:01,word vector return value infinite infinite,python numpy gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13644,13644,45647439,2017-08-12 06:53:55,,built word vecmodel using gensim library python want evaluate word embedding follows related b c related c b equal example embedding vector arithmetic india rupee japan equal embedding yen used built function gensim like predict output word similar get desired result kindly help evaluating model per criterion,2017-08-12 07:40:49,2017-08-12 17:24:18,evaluating word vec model finding linear algebraic structure word,nlp word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
13645,13645,45569142,2017-08-08 13:03:45,,want compare word vec fasttext model based comparison tutorial http github com jayantj gensim blob fast text notebook doc notebook word vec fasttext comparison ipynb according semantic accuracy fasttext model increase set max length char n gram zero fasttext start behave almost like word vec ignores ngrams however find formation set parameter loading fasttext model idea,,2017-08-08 17:59:02,setting max length char n gram fasttext,nlp nltk gensim word2vec fasttext,,,CC BY-SA 3.0,True,False,True,False,False
13650,13650,45720880,2017-08-16 18:46:24,,gensim lsi model want persist mongodb specifically want persist following gensim dictionary id word gensim corpus lsi model matrixsimilarity index know object saved file figure save data mongodb specifically using pymongo gathered need anything like gridfs file relatively small case want save single document separately thanks,,2017-08-16 18:46:24,persisting gensim lsi model mongodb,mongodb python-3.x pymongo gensim,,,CC BY-SA 3.0,False,False,True,False,False
13663,13663,45685055,2017-08-15 00:54:35,,code return something like running new text model collocation found however use following stemmer everything work supposed dtype returned stemmer list string problem idea happens thanks platform linux aws x debian stretch sid python version,2017-08-15 06:29:19,2017-08-15 06:29:19,gensim model phrase phrase doe work input come nltk stemmed token,python nltk gensim spacy,,,CC BY-SA 3.0,True,True,True,False,False
13675,13675,45687700,2017-08-15 06:44:54,,use python library train word vec model call function like get cosine similarity apple banana local machine find function document model built code simple way achieve goal,,2017-08-15 06:44:54,compute cosine similarity two word word vec model pyspark,python pyspark word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
13682,13682,45758225,2017-08-18 13:45:36,,using gensim ldamulticore extract topic work perfectly fine jupyter ipython notebook run command prompt loop run indefinitely execution arrives ldamulticore function execution start first please help novice importing required package,2017-08-18 13:59:12,2018-08-24 08:04:50,gensim ldamulticore running command prompt,python nlp multicore gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
13699,13699,45711628,2017-08-16 10:53:19,,currently working lda logarithm python want covert topic list top word topic tried code got different output want output following format got output code edit resulted non expected output,2017-08-16 14:26:45,2017-08-16 18:05:16,convert topic list top word topic lda python,python gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
13727,13727,45825532,2017-08-22 19:28:32,,training word vec model using gensim k browser useragent dictionary size depending word frequency limit looking embedding vector similarity see algorithm ha converged code unfortunately even epoch sign convergence embedding vector example plot embedding first dimension ipad embedding vector v number epoch embedding ipad v number epoch looked many blog paper seems nobody trained word vec beyond epoch missing,,2017-08-23 06:29:04,embedded vector converge gensim,python gensim convergence word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
13729,13729,45802490,2017-08-21 17:11:02,,topic modelling linguistics paper using gensim phrase identify frequent collocation want able mark term support cleft one single word since specific linguistic terminology however make gensim model taking stopwords collocation found since contain stopwords make model taking stopwords stopwords including identifies whole lot irrelevant collocation way manually add phrase recognised collocation gensim phrase thanks,,2017-08-21 22:53:20,manually add collocation gensim phraser,gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
13761,13761,45783781,2017-08-20 15:25:44,,trying save gensim doc vec model model trained document vector vocabulary around word getting pickel error top show program us around gb ram also think since need train model new document required saving parameter necessary memoryerror,,2017-08-20 15:25:44,pickel error storing doc vec gensim model,nlp pickle gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13778,13778,45860212,2017-08-24 11:16:59,,pre trained continuous bag word word vec model load type task could perform evaluate,,2017-08-24 11:16:59,load evaluate pretrained word vec model trained cbow algorithm,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13782,13782,45810954,2017-08-22 07:03:01,,created two model using gensim word vec want merge two model way get union two model eg model one ha following vocabulary model two ha following vocabulary want use two model create new model following vocabulary,2017-08-22 08:20:23,2017-10-12 12:46:28,create model using trained model,machine-learning nlp deep-learning gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13783,13783,45813264,2017-08-22 09:02:54,,training word vector particular text corpus using fast text fasttext provides necessary mechanic option training word vector looked tsne vector amazing notice gensim ha wrapper fasttext good accessing vector task many text corpus need use trained vector new corpus use trained vector new discovered corpus fasttext doesnot provide function donot see package achieves may lost see google forum gensim provides intersect word vec format understand find usage tutorial another question open similar answer apart gensim way train model like,,2017-08-22 09:02:54,train word vec pretrained vector,nlp gensim word2vec fasttext,,,CC BY-SA 3.0,False,False,True,False,False
13786,13786,45847370,2017-08-23 18:52:07,,two approach one run really fine warning produce warning understand difference generator iterators passing iterators verified printing command multiple time print thing fine still sure warning empty iterator second case missing something,2017-08-23 19:22:05,2017-08-23 20:00:37,issue gensim model phrase,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
13790,13790,45906577,2017-08-27 15:29:57,,show output ldamodel learnt gensim show unicode character u unicode character chinese persian character make appear character,2017-08-27 15:35:14,2017-08-27 15:35:14,make output print topic show unicode character,python python-2.7 unicode nltk gensim,,,CC BY-SA 3.0,True,False,True,False,False
13798,13798,45960671,2017-08-30 12:38:55,,using calculating similarity reference sentence sentence according source code return following code inefficient two way use case reference sentence repeatedly calculating time distance function distance function called multiple user different point repeat whole process sentence computationally expensive comparison take around second therefore would like isolate two task final calculation distance preparation input distance matrix distance matrix depends least input preparation isolated final matrix calculation initial plan create three customized function possible function go customized version idea solution deal problem better way,2017-08-31 00:48:11,2018-12-30 06:14:30,optimizing gensim word mover distance function speed wmdistance,python nlp nltk gensim word2vec,,,CC BY-SA 3.0,True,False,True,False,False
13814,13814,45943832,2017-08-29 16:13:47,,trying train doc vec model using gensim unique document label vocab size around unique word gb ram linux machine azure run build vocab iterator par file throw memory error listed code memory usage per top someone please tell much expected memory better option adding swap space slow process add memory cost cluster might eventually equivalent vector gensim store memory flag missing memory efficient usage,2017-08-30 05:23:15,2017-08-30 05:23:15,gensim doc vec finalize vocab memory error,python nlp gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13824,13824,45926917,2017-08-28 20:31:20,,working document comparison engine search engine currently using follows comparing result would like simplest term possible multi dimensional document document ha multiple dimension rather document example also able weight result example title body etc question way within gensim need create separate document meta item document example comparing meta item title body tag separate document combining weight fact using document key id sure good job explaining please let know improve question thank,,2017-08-28 23:59:21,multi dimensional document gensim,python machine-learning tensorflow gensim tf-idf,,,CC BY-SA 3.0,False,False,True,False,False
13827,13827,45876711,2017-08-25 07:51:09,,using word vec million abstract dataset billion word find similar document use class trying retrieve best match using calculation spends time building dictionary piece log doe part dependent query way calculation edit training scoring phase code training saving disk loading scoring,2017-08-28 12:24:02,2017-08-29 00:50:55,gensim word vec wmd similarity dictionary,python nlp word gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13844,13844,45948533,2017-08-29 21:22:30,,gensim implement function called doesnt match return outlier word list function called wordvector object model wv doesnt match breakfast cereal dinner lunch split cereal documentation specifying function really work computation background anyone know,,2017-08-30 00:12:00,gensim doesnt match function working,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13846,13846,46001910,2017-09-01 14:01:30,,lda topic model narrative report natural language research project using gensim python several smallish corpus doc know tiny like compare know beyond looking lda model instance pyldaviz academic background c still bit new nlp good way compare topic across corpus topic model instance possible estimate much two lda model overlap way ass topic similarity several corpus thanks advance help,,2017-09-06 16:52:59,best way compare several corpus natural language,python nlp nltk lda topic-modeling,,,CC BY-SA 3.0,True,False,True,False,False
13855,13855,45917969,2017-08-28 11:31:30,,using doc vec convert top tweet follower vector representation say v v using vector representation k mean cluster see cluster dominated value say v v v question doe v v etc represents deduce specific column cluster specific keywords document,,2019-04-19 21:35:02,intrepret cluster result using doc vec,python scikit-learn cluster-analysis gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,True
13857,13857,46064892,2017-09-06 00:00:34,,trying learn skip gram model within word vec however confused basic concept start current understanding model motivated example using python gensim go corpus three sentence determine vocabulary following paper tomas mikolov others basic skip gram formulation defines p w j w using softmax function v w v w input output vector representation w w number word vocabulary understanding skip gram model involves two matrix call vector representation input center word vector representation output context word assuming vector dimension size called genism x matrix x matrix start training procedure matrix filled random value yes might want calculate probability word dog appears context cat exp question understanding algorithm correct thus far using genism train model data using array given vector dog input matrix output matrix way view matrix final model doe thought closer since data would indicate word cat unlikely occur context word cat,2017-09-06 00:31:04,2017-09-06 01:59:37,word vec training procedure clarification,gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13863,13863,46047506,2017-09-05 05:23:46,,applied doc vec convert document vector used vector clustering figured nearest similar document centroid cluster need find dominant important term document figure characteristic cluster question way figure dominat simlar term word document doc vec using python gensim package doc vec implementaton,,2018-05-23 20:53:55,find similar term word document doc vec,python cluster-analysis gensim word2vec doc2vec,2017-09-06 23:04:01,,CC BY-SA 3.0,False,False,True,False,False
13873,13873,46065514,2017-09-06 01:35:34,,trying get probable sequence word using gensim word vec model found pretrained model provides file code trying get probability sentence model running code getting error anyone help figure solve problem general want use pretrained model get probability sequence word appearing together,,2017-09-06 17:42:38,getting probability text given word embedding model gensim word vec model,python nlp gensim word2vec language-model,,,CC BY-SA 3.0,False,False,True,False,False
13874,13874,46065773,2017-09-06 02:12:56,,word vec training get two weight matrix input hidden weight matrix hidden output weight matrix people use input hidden weight matrix word vector row corresponds word namely word vector come confusion people use input hidden weight matrix word vector instead hidden output weight matrix add softmax activation function hidden layer rather output layer thus preventing time consuming plus clarifying remark intuition word vector obtained like appreciated,,2020-10-17 12:31:19,use input hidden weight matrix word vector instead hidden output weight matrix,nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13912,13912,46146241,2017-09-10 22:45:20,,code comparing much book car dinosaur fence similar like car bird using cosine similarity technique two sentence effectively word common car however run code get similar doe make sense someone suggest improve code get reasonable number,,2017-09-11 01:30:24,text similarity gensim cosine similarity,python gensim cosine-similarity,,,CC BY-SA 3.0,False,False,True,False,False
13913,13913,46147013,2017-09-11 01:14:35,,want extract bigram trigram given sentence code work fine bigram capture new york machine learning ad bigram however get following error try insert trigram please let know correct code following example documentation gensim,2017-09-27 04:11:06,2018-07-30 13:45:23,error getting trigram using gensim phrase,python nlp data-mining text-mining gensim,,,CC BY-SA 3.0,False,False,True,False,False
13915,13915,46148182,2017-09-11 04:28:12,,want get bigram trigram example sentence mentioned code work fine bigram however doe capture trigram data e g human computer interaction mentioned place sentence approach mentioned code using phrase gensim approach even tried use phraser phrase work please help fix issue getting trigram following example documentation gensim,2017-09-11 07:33:33,2017-09-11 15:19:31,issue getting trigram using gensim,python data-mining text-mining word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
13923,13923,46013294,2017-09-02 11:26:06,,reading doc vec command gensim page curious command intersect word vec format understanding command let inject vector value pretrained word vec model doc vec model train doc vec model using pretrained word vec value rather generating word vector value document corpus result get accurate doc vec model using pretrained w v value wa generated much larger corpus data compared relatively small document corpus understanding command correct even close,,2017-09-03 20:54:19,gensim doc vec intersect word vec format command,nlp gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13926,13926,46168239,2017-09-12 05:00:47,,trying solve problem sentence comparison using naive approach summing word vector comparing result goal match people interest dataset consists name short sentence describing hobby batch fairly small hundred people wanted give try digging doc vec prepare data cleaning completely removing stop word tokenizing lemmatizing use pre trained model word vector return adequate result finding similarity test word also tried summing sentence word find similarity original model match make sense similarity would around general sense phrase sentence matching trying following create empty model build vocab name person id training summ sentence word vector store result model corresponding id understand expecting much accuracy sne print show clustering whatsoever finding similarity method also fails find match wondering anyone ha idea go wrong approach valid,,2017-09-12 18:22:55,sentence matching gensim word vec manually populated model work,python nlp gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13928,13928,46072991,2017-09-06 10:32:37,,doe word vec create vector word trained two word vec model using two different file commoncrawl website getting word vector given word model actually created multiple word vec model using different text file commoncrawl website want check model better among select best model model getting word vector different model sorry question clear,,2017-09-06 17:32:11,doe word embedding word vector work created,neural-network nlp deep-learning gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13932,13932,46129335,2017-09-09 09:49:15,,currently using uni gram word vec model follows however miss important bigram trigram dataset hence want capture important bigram trigram etc dataset input word vec model new wordvec struggling please help,2017-09-10 18:49:11,2019-05-09 06:01:54,get bigram trigram word vec gensim,python tokenize word2vec gensim n-gram,,,CC BY-SA 3.0,False,False,True,False,False
13940,13940,46086858,2017-09-07 02:16:18,,new word vec gensim want build word vec model text extracted wikipedia machine learning find similar word machine learning current code follows however vocab get one character output please help get similar word using using model similar,2017-09-07 02:26:59,2017-09-07 02:34:23,word vec gensim using model similar,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13947,13947,46168600,2017-09-12 05:33:26,,trying import gensim following code got following error installed gensim python use genssim word vec,,2020-07-22 22:03:11,gensim error module named gensim,python linux gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
13950,13950,46173339,2017-09-12 09:55:39,,problem installing gensim module installed numpy scipy dependent module successfully wa getting error installing gensim tried solution given python pip install give command python setup py egg info failed error code none worked error,,2018-03-19 11:32:54,unable install gensim python,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
13953,13953,46083322,2017-09-06 19:52:17,,possible train doc vec model single document ha multiple tag example movie review case document ha unique tag uid multiple categorical tag access vector training example would proper syntax call,,2017-09-08 05:41:33,multiple tag single document doc vec taggeddocument,python nlp gensim word2vec doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13963,13963,46157805,2017-09-11 14:12:49,,created doc vec model size dimension understand reading dimension feature model identify dimension exactly,,2017-09-11 17:51:30,identify dimension doc vec model,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
13964,13964,46157937,2017-09-11 14:19:26,,running gensim word vec code corpus resume stopwords removed identify similar context word corpus list pre defined keywords despite several iteration input parameter stopword removal etc similar context word making sense term distance context eg correlation matrix occurs window several time yet matrix doesnt fall similar result correlation following detail system code gensim running python anaconda training resume sentence average word per sentence word post stopwords removal code lost result random anyway check accuracy word vec also alternative word vec similar function read glove wa able install package information regard would helpful,,2017-09-11 17:59:21,word vec similar function giving senseless result training,python-2.7 gensim word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
13980,13980,46137572,2017-09-10 05:27:14,,trying get bigram sentence using phrase gensim follows even though catch new york new york doe catch machine learning machine learning however example shown gensim website able catch word machine learning machine learning please let know get machine learning bigram example,,2017-09-11 01:13:28,error extracting phrase using gensim,python data-mining text-mining word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
13983,13983,46141998,2017-09-10 14:51:35,,trying install gensim using following command got following error message installed numpy scipy fix problem,2017-09-10 15:15:35,2017-09-10 15:21:15,install gensim error ubuntu,python ubuntu gensim,,,CC BY-SA 3.0,False,False,True,False,False
14000,14000,46197493,2017-09-13 12:22:52,,im currently trying implement convolutional lstm network using kera instead using kera embedding layer used gensim doc vec embeddings created input data preprocessing data label load doc vec model infer data create input vector infer vector function creates document embeddings based doc vec model created reshape data building model get error,2017-09-13 12:28:03,2017-09-13 13:04:51,using gensim doc vec kera conv valueerror,python machine-learning keras gensim,,,CC BY-SA 3.0,False,False,True,False,False
14001,14001,46201029,2017-09-13 15:09:18,,according wmd paper inspired word vec model use word vec vector space moving document towards document context earth mover distance metric paper understand concept paper however understand wmd us word vec embedding space code gensim someone explain simple way doe calculate word vector different way understand code word vec embedding matrix used wmd fucntion gensim,2017-09-15 09:47:58,2017-09-15 09:47:58,word mover distance wmd us word vec embedding space,nlp nltk gensim word2vec word-embedding,,,CC BY-SA 3.0,True,False,True,False,False
14006,14006,46238185,2017-09-15 11:09:31,,little new doc vec algorithm using gensim implementation python following gensim tutorial gensim doc vec tutorial imdb sentiment dataset built vocab trained doc vec model stored disc using creates following four file directory load model back using filename used save e use model create vector document get error going wrong note tokenize function returning list word using nltk wordpunct tokenizer,,2017-09-15 11:09:31,typeerror using infer vector gensim doc vec model loaded memory,python gensim doc2vec,,,CC BY-SA 3.0,True,False,True,False,False
14029,14029,46125018,2017-09-08 21:55:58,,trying understand sample code http www tensorflow org tutorial recurrent find http github com tensorflow model blob master tutorial rnn ptb ptb word lm py using tensorflow summarized think key part question biggest question use produced model actually generate next word suggestion given first word sentence concretely imagine flow like get head around code commented line would sub question use random uninitialized untrained word embedding use softmax doe hidden layer match dimension input e dimension word vec embeddings bring pre trained word vec model instead uninitialized one asking one question suspect connected connected gap understanding wa expecting see wa loading existing word vec set word embeddings e g using gensim convert word input corpus representation loading sentence afterwards lstm would spit vector dimension would try find similar word e g using gensim using softmax saving u relatively slow call btw pre existing word vec part question using pre trained word vec lstm word generation similar however answer currently looking hoping plain english explanation switch light plug whatever gap understanding use pre trained word vec lstm language model another similar question update predicting next word using language model tensorflow example predicting next word using lstm ptb model tensorflow example similar question however neither show code actually take first word sentence print prediction next word tried pasting code nd question http stackoverflow com come github branch get either run without error think may earlier version tensorflow another update yet another question asking basically thing predicting next word lstm model tensorflow example link predicting next word using language model tensorflow example answer quite looking case still clear trying write high level function called previously built lstm loaded disk string open might return pod might call open pod return bay example character rnn using mxnet function shown near end http github com zackchase mxnet straight dope blob master chapter recurrent neural network simple rnn ipynb call training also call training sentence want,2017-09-13 13:35:00,2018-06-08 18:27:52,use lstm tutorial code predict next word sentence,python tensorflow lstm word2vec word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
14030,14030,46270606,2017-09-18 02:00:01,,trying calculate cosine similarity value time calculation cost min code necessary using gensim package get tf idf value similarity calculation someone please give advice guidance speed time,2017-09-18 02:06:24,2019-10-24 11:26:04,speed time calculate cosine similarity using nested loop python,python gensim cosine-similarity,,,CC BY-SA 3.0,False,False,True,False,False
14034,14034,46297740,2017-09-19 10:10:57,,dataframe index word column float number word embedding vector would like convert dataframe object gensim model object use method specially search similar word within subset preferred way thanks,,2017-09-19 12:17:40,turn embeddings loaded panda dataframe gensim model,python pandas gensim,,,CC BY-SA 3.0,False,False,True,False,False
14041,14041,46244286,2017-09-15 16:48:47,,currently using word vec model trained google news corpus since trained news need updated vector also add new word vocabulary based news coming suppose new corpus news train fine tune update google news word vec model done using gensim done using fasttext,,2019-05-02 15:11:14,fine tuning pre trained word vec google news,python gensim word2vec google-news fasttext,,,CC BY-SA 3.0,False,False,True,False,False
14049,14049,46258266,2017-09-16 20:42:10,,trying q recipe shown corpus keep getting returned even though checked doe seem reading document correctly code text file using test,,2017-09-16 22:23:05,gensim iterating multiple document,gensim,,,CC BY-SA 3.0,False,False,True,False,False
14061,14061,46326173,2017-09-20 15:30:07,,new topic modelling latent dirichlet allocation trouble understanding apply concept dataset whether correct approach small number literary text novel would like extract general topic using lda using module python along feature test split original text chunk word converted chunk document term matrix ran algorithm code although think matter question however result completely different example seen topic full meaningless word found source document e g said like example quite understand happens happen example seen get lda model find distinctive topic le overlap matter filtering common word first adjust many time model run number original text small,,2017-09-20 17:42:59,understanding lda topic modelling much topic overlap,python nlp gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
14076,14076,46362028,2017-09-22 10:02:21,,using ptvs v write python code write import gensim library start debugging using f debugger take around min load library move next line fix problem b start without debug ctrl f fast load code write pause execution attach debugger continue,2017-09-22 10:07:51,2017-09-28 14:37:27,python tool visual studio debugging slow importing gensim package,python visual-studio gensim ptvs,,,CC BY-SA 3.0,False,False,True,False,False
14078,14078,46379763,2017-09-23 12:49:41,,document term matrix nine document running code getting error executing pyldavis display function typeerror object type complex json serializable someone guide could reason,2017-09-23 16:43:41,2018-11-21 07:42:59,typeerror object type complex json serializable using pyldavis display function,json gensim serializable,,,CC BY-SA 3.0,False,False,True,False,False
14083,14083,46282473,2017-09-18 14:58:51,,try run lda model n pas lda object get coherence showing error typeerror diags take least argument given code,2018-07-17 14:16:38,2019-08-14 18:09:19,error identify coherence value lda model,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
14104,14104,46421771,2017-09-26 08:47:19,,want make word vec model n gram usual found phrase class gensim model phrase find phrase want possible use phrase corpus use result model word vec train function first something like exactly like sample code gensim documentation model ha created without good result evaluation warning searched found http group google com forum topic gensim xwq fpmfsi changed code get error want know wrong code,,2017-10-02 07:08:45,text processing word vec training phrase detection bigram model,python text-processing gensim word2vec python-textprocessing,,,CC BY-SA 3.0,False,False,True,False,False
14124,14124,46441876,2017-09-27 07:27:33,,building word vec model follows however output get model vocabulary single character follows getting bigram trigram correctly hence confused make code wrong please let know problem,2017-09-27 07:37:28,2017-09-27 07:49:52,get single letter vocabulary gensim word vec,python gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
14130,14130,46368720,2017-09-22 15:55:37,,typeerror tfidfmodel object callable compute tfidf matrix doc initializing started document paragraph sentence spacy tokenizing everything created dictionary k unique token corpus list list tuples ready create tfidf matrix later lda w v matricies ml however initializing tfidf model corpus calculation idf get following error message trying see tfidf doc typeerror tfidfmodel object callable able create model using differnt corpus four doc comprised sentence confirm expected corpus fomat list list tuples doc word count word count doc word count word count,,2017-09-24 05:55:14,tfidif model creation typeerror gensim,python nlp gensim tf-idf language-features,,,CC BY-SA 3.0,False,True,True,False,False
14147,14147,46505573,2017-09-30 18:01:30,,recently started play dataset quora question pair challenge quora question pair challenge dataset basic stuff like visualizing data bit cleaning lematization stop word reomval punctuation removal etc also generated embeddings question pair using word vec model gensim package bit confused fit model enable make prediction help regard welcome code written,,2017-09-30 18:01:30,working text quora pair kaggle challenge,python-3.x machine-learning nlp,,,CC BY-SA 3.0,False,False,True,False,False
14167,14167,46433778,2017-09-26 18:51:02,,working code using gensim tough time troubleshooting valueerror within code finally wa able zip googlenews vector negative bin gz file could implement model also tried gzip result unsuccessful error code occurs last line would like know done fix error workarounds finally website could reference thank respectfully assistance,,2019-12-02 11:05:08,import googlenews vector negative bin,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
14168,14168,46435220,2017-09-26 20:25:36,,generated tf idf model document using following code work well problem try calculate similarity score using linear kernel memory usage blow seems like take much memory comparison row csr mil row csr output x mil ndarray justy fyi x csr matrix gb memory computer ha tried looking gensim replace find great example thought missing,,2017-09-26 21:49:09,calculating similarity tfidf matrix predicted vector cause memory overflow,python scikit-learn gensim tf-idf csr,,,CC BY-SA 3.0,False,False,True,False,True
14179,14179,46308283,2017-09-19 19:21:35,,using python gensim package word vec want run model tokenize word word phrase document used nltk regextoknizer get single word token document tokenizer document get also word phrase example document green apple word phrase green apple etc,2017-09-20 04:36:35,2017-12-29 19:13:58,python tokenizer word phrase word vec model,python nltk tokenize,,,CC BY-SA 3.0,True,False,True,False,False
14185,14185,46455511,2017-09-27 19:08:58,,trying use pyspark identify good number topic dataset e g tweet several way exist task see example question though value reported pyspark logperplexity loglikelihood function accompanying pyspark ml clustering lda understanding say increase topic count see perplexity decrease log likelihood value increase see behavior gensim using model parameter pyspark however increase topic value returned log perplexity increase log likelihood decrease result seem counter understanding value mean missing fundamental aspect pyspark lda model help would greatly appreciated included copy jupyter notebook using run test see result http www c umd edu cbuntain findtopick pyspark regex html thanks advance,2017-09-28 16:42:59,2017-09-28 16:42:59,optimizing perplexity log likelihood topic count pyspark lda,apache-spark pyspark lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
14205,14205,46574720,2017-10-04 21:48:23,,using lda gensim perform topic modeling know convert raw text data corpus get topic get topic label add back topic result raw document code last code show distribution topic document question convert numeric variable topic weight document desired output dataframe see dataframe topic column name weight value also link topic variable back raw document movie review,2017-10-04 21:49:23,2020-04-23 22:01:18,python gensim lda add topic document getting topic,python gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
14210,14210,46536132,2017-10-03 01:58:24,,built lda model using gensim want get topic word get word topic probability id word tried print topic show topic function gensim get clean word code used tried show topic gave output topic id access word information thanks advance,,2019-09-24 11:44:26,access topic word gensim,python nlp gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
14213,14213,46605194,2017-10-06 11:58:12,,implemented lda python want label topic whichever got lda,,2018-05-16 00:59:41,label topic automatically applying lda,python nltk gensim lda topic-modeling,,,CC BY-SA 3.0,True,False,True,False,False
14221,14221,46647945,2017-10-09 13:41:42,,word vec model lot word vector access word vector output proper vector representation want replace word vector boy following error thrown fashion workaround manipulate word vector manually model trained possible platform except gensim,,2017-10-09 23:49:48,manually change vector dimension word gensim word vec,python vector gensim word2vec vector-space,,,CC BY-SA 3.0,False,False,True,False,False
14223,14223,46609507,2017-10-06 15:50:21,,trying build embedding corpus using python gensim word vec implementation catch wish embedding unigrams bigram corpus way embed space unigrams bigram,,2018-10-18 05:58:39,mixed unigram bigram word vec embedding,python text-mining gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
14243,14243,46576437,2017-10-05 01:17:40,,dataframe look like month column ha value range want build model text data based number month trying get output save txt file open file find contains one line want get text file named per index one contain line code wrong thanks advance,,2017-10-05 03:16:10,write output data text file iteratively,python string pandas encoding gensim,,,CC BY-SA 3.0,False,False,True,False,False
14247,14247,46610746,2017-10-06 17:10:48,,use filter like eliminate punctuation check performance gensim word vec got seems punctuation eliminated,2017-10-06 17:16:06,2017-10-06 17:16:06,gensim kera preprocessing text eliminate punctuation using text word sequence function,python nlp keras word2vec,,,CC BY-SA 3.0,False,False,True,False,False
14249,14249,46612949,2017-10-06 19:45:38,,currently tb text data build gensim word vec model almost taking day complete want build model tb text data might take month create model need minimise execution time way use multiple big system create model please suggest way help reducing execution time fyi data use smart open module stream data,,2018-03-09 06:31:00,build word vec model distributed way,nlp deep-learning distributed-computing gensim word2vec,,,CC BY-SA 3.0,False,False,True,False,False
14251,14251,46684810,2017-10-11 09:37:55,,doe gensim corpus dictionary term frequency saved possible get document frequency word e many document particular word occur function remove n th frequent token filter remove n frequent token appear document pruning shrink resulting gap word id note due gap shrinking word may different word id call function function removing n th frequent based document frequency term frequency latter way access term frequency word object,,2020-02-04 22:14:16,doe gensim corpus dictionary term frequency saved,python dictionary frequency gensim tf-idf,,,CC BY-SA 3.0,False,False,True,False,False
14258,14258,46630171,2017-10-08 10:41:59,,try build word rnn equivalent char rnn net generate next word sentence input use pre trained word vec dim vector hidden layer size main problem output layer designed char rnn output vocabulary size number unique char vector char probability distribution softmax generating next char simply sampling form distribution using word vec word vocabulary k approach feasible output generates dim vector find nearest similar word use gensim similar vector function could provide good easy understand python tensorflow implementation link github publication found similar question answer question,2018-01-14 12:48:55,2018-01-14 12:48:55,design output layer word rnn model use word vec embedding,python tensorflow neural-network recurrent-neural-network word2vec,,,CC BY-SA 3.0,False,False,True,False,False
14263,14263,46674609,2017-10-10 19:37:00,,im trying understand doc vec use solve scenario want label sentence tag using taggedsentences word tag im unsure understanding correct basically need happen totally mark create taggeddocuments build model train model done expect execute animal tree get update infer get elephant room doc vec need accomplish scenario go back bed proper think im trying achieve life help greatly appreciated,2017-10-11 07:49:36,2017-10-11 07:49:36,gensim doc vec sentence tagging,python machine-learning data-science gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14265,14265,46704738,2017-10-12 08:20:21,,using gensim library word vec want train model text example unrelated example cat brown time created following input model however wondering whether model assumes brown context tried find answer api could find,2017-10-12 08:35:52,2017-10-12 10:16:26,gensim different context,machine-learning nlp word2vec,,,CC BY-SA 3.0,False,False,True,False,False
14270,14270,46656290,2017-10-09 23:06:46,,set word n gram need calculate tf idf value word corpus look follows currently getting tf idf value n gram using sklearn follows however interested gensim forall example came across gensim us unigrams iwant bigram trigram well calculated word want calculate word hence please help find two thing gensim,,2017-10-11 04:48:41,calculate tf idf gensim vocabulary,python gensim tf-idf,,,CC BY-SA 3.0,False,False,True,False,True
14280,14280,46559980,2017-10-04 08:09:53,,trying get doc vec function work python following code work far understand rank function error get zero list e g document putting doe list seems similar function doe work model train data document build vocab tagged documentation mainly used gensim dokumentation torturial hope one help additional info need please let know best niels,2017-10-04 08:17:03,2017-10-04 21:56:56,applying similar function gensim doc vec,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14291,14291,46731926,2017-10-13 14:13:15,,playing gensim wordvec try build model using term large medical thesaurus sentence million term multiword term treat sentence hope see term like breast cancer breast tumor etc able conclude cancer tumor somewhat similar run experiment track similar term like using different number iteration seems result correlate expect considering word pair like wound lesion thorax lung cancer tumor etc going iteration tendency even small one word pair similar number iteration grows result appear pretty random even getting worse specifically loop iteration train w v model word pair check rank nd word list say lung similar word returned w v first word say thorax sum build average average rank growing decreasing meaning training proceeds vector lung thorax move away expect gensim detect clean synonym also perhaps million term sentence enough still puzzled effect doe anyone suspicion added comment feedback came thanks detailed feedback gojomo checked many issue yes thesaurus term sentence come right format e g breast cancer yes mio term multiword clear word term provide context ample evidence multiword term example gave clinic cancer lung occur many hundred term often many thousand find odd even word frequent really good similar word suggested ask code http www dropbox com fo fazl frj ut w vexperiment py dl expects called python name model skos xml file large thesaurus like snomed python w vexperiment py snomed w v model skos skos code see create new model new experiment different number iteration effect one run pollutes wrong learning rate etc set min count still model get better often worse number iteration grows even better one iteration give strange result test word,2017-10-15 14:29:28,2017-10-15 14:29:28,gensim quality word vec model seems correlate num iteration training,python word2vec,,,CC BY-SA 3.0,False,False,True,False,False
14319,14319,46769705,2017-10-16 11:53:39,,way load doc vec model saved using gensim deeplearning j paragraphvectors gensim model valid able load using gensim problem call wordvectorserializer readparagraphvectors model java throw exception upon debugging code noticed deeplearning j expects zip file multiple txt file single json file inside way convert gensim model zip expected deeplearning j dedicated method dl j api find using example javadoc,,2017-10-16 11:53:39,doc vec gensim deeplearning j,java python gensim deeplearning4j doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14321,14321,46697503,2017-10-11 21:02:23,,found successful weighting theme adding word vector seems work sentence comparison case add additional information sentence act noise get decrease way deal additional information comparing using word vector know subset text provide better match upd edited code make clear case doe called smooth inverse frequency weighting word vector glove model word vec well etc added weight w word frequency use word inverse tfidf score e coefficient typically taken e approach taking tfidf score weight instead fraction give almost similar result also played normalization etc wanted vectorize sentence example overload question think doe depend add word vector using weighting theme problem comparison work best sentence approximately number meaning word aware another approach distance sentence text computed using sum mean minimal pairwise word distance e g obama speaks medium illinois president greets press chicago approach doe take account adjective change meaning noun significantly etc le incorporated vector model word like adjective good bad nice etc become noise match two text contribute zero low distance thus decreasing distance sentence text played bit doc vec model seems wa gensim doc vec implementation embedding case matching short query much bigger amount text unsatisfactory result,2017-10-13 13:06:51,2017-10-13 20:06:35,possible search part text using word embeddings,gensim word2vec word-embedding doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14322,14322,46701173,2017-10-12 03:59:07,,created word vector using distributed word vec algorithm word corresponding vector build gensim word vec model using word vector,,2017-10-12 09:33:25,create gensim word vec model using pre trained word vector,nlp gensim word2vec text-analysis word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
14324,14324,46807010,2017-10-18 09:33:27,,new doc vec wa initially trying understand doc vec mentioned code us gensim want get trained model document vector two document however would like know benefit retraining model several epoch gensim using parameter train seperate please let know change following code train model epoch also interested knowing multiple training iteration needed word vec model well,2017-10-18 09:47:15,2018-05-17 13:23:11,doc vec training iteration,python deep-learning word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14353,14353,46889727,2017-10-23 12:44:40,,working recurrent language model learn word embeddings used initialize language model using gensim word vec model training word vec model hold two vector word vocabulary word embedding row input hidden matrix context embedding column hidden output matrix outlined post least three common way combine two embedding vector summing context word vector word summing averaging concatenating context word vector however find proper paper report best strategy question common solution whether sum average concatenate vector doe best way depend entirely task question strategy best word level language model combine vector use original word embeddings word e contained weight matrix input hidden neuron related unanswered question word vec summing concatenate inside outside vector use input hidden weight matrix word vector instead hidden output weight matrix,2017-10-24 07:38:32,2020-04-10 02:42:38,word vec best add concatenate average word vector,python word2vec gensim word-embedding language-model,,,CC BY-SA 3.0,False,False,True,False,False
14360,14360,46754881,2017-10-15 12:10:44,,use python rc get following message executing python script gensim already installed command give following list imported keyedvectors gensim model another script worked suggestion thanks reply,,2017-10-15 12:38:53,python import gensim window,python python-3.x pip gensim,,,CC BY-SA 3.0,False,False,True,False,False
14377,14377,46762366,2017-10-16 03:06:11,,load keyedvectors model word frequency seems like word index miss something,,2017-10-16 23:18:30,gensim keyedvectors object word count,gensim,,,CC BY-SA 3.0,False,False,True,False,False
14393,14393,46796227,2017-10-17 17:51:12,,trying create custom version word vec want able define word meet certain criterion stay always window either cbow skip gram create new pyx file based word vec inner pyx source code instance modify skip gram training find modification compilation cython code c succeeds still new fast version used checked ipython import new pyx pyximport failed finding numpy core h file user pyxbld temp macosx x pyrex numpy,2017-10-17 17:58:15,2017-10-17 17:58:15,gensim word vec customized,python cython word2vec,,,CC BY-SA 3.0,False,False,True,False,False
14400,14400,46786311,2017-10-17 08:59:39,,doe anyone know function use want use pre trained doc vec model website http github com jhlau doc vec know use laod word vector pre trained word vec model similar function load pre trained doc vec model well gensim thanks lot,,2019-02-09 04:39:17,load pre trained doc vec model use vector,python numpy gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14408,14408,46899062,2017-10-23 21:48:12,,want train word vec model tokenized file size mb trying run python code call function file get know word vec need lot space still think problem see estimated memory model mb computer ha gb ram yet monitoring process code run show occupies memory get killed post advise tried increase min count decrease size even ridiculous value min count size process stop also tried make python exception oom process get killed memoryerror instead killing going use recent laptop ubuntu gb ram nvidia gtx run python anaconda gensim doe nt better gensim,2017-10-23 21:59:42,2017-10-24 05:04:45,gensim word vec us much memory,python-3.x memory word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
14410,14410,46914400,2017-10-24 15:25:38,,want construct word embeddings document using glove know obtain vector embeddings single word unigrams follows example text document want obtain vector embeddings bigram example new york instead new york machine learning instead machine learning possible glove yes,,2017-10-25 13:01:55,n gram glove,nlp stanford-nlp data-mining gensim word-embedding,,,CC BY-SA 3.0,False,False,True,True,False
14411,14411,46914513,2017-10-24 15:31:58,,using list unique label form train doc vec model somehow split label symbol output following initial list tagged document document ha unique label code model training following therefore index document like get thing pas data constructor instead building vocabulary happening thanks,,2017-10-24 18:39:14,doc vec model split document tag symbol,python-3.x gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14412,14412,46915589,2017-10-24 16:27:57,,trying summarise text using gensim python want exactly sentence summary seem option done following workaround however code giving two sentence furthermore incrementally increase still nothing happens help would appreciated,2018-01-09 14:25:05,2018-04-04 13:20:15,nlp get exact number sentence text summary using gensim,nlp text-processing gensim,,,CC BY-SA 3.0,False,False,True,False,False
14418,14418,46860197,2017-10-21 04:58:22,,current doc vec code follows also word vec code interested using dm dbow doc vec skip gram cbow word vec gensim found mentioned sentence produce word vector deep learning via word vec skip gram cbow model using either hierarchical softmax negative sampling thus confused either use hierarchical softmax negative sampling please let know difference two method also interested knowing parameter need changed use hierarchical softmax negative sampling respect dm dbow skip gram cbow p application recommendation system,,2017-10-23 01:25:42,doc vec word vec negative sampling,python nlp word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14432,14432,46885454,2017-10-23 09:00:26,,tried follow documentation nbviewer jupyter org github skipgram modern nlp python blob master executable modern nlp python ipynb following code snippet get run change following last line print dataframe give error get head around keep return nonetype object line look like term index tracking get help input welcome best niels,2017-10-23 09:36:02,2017-10-23 09:47:57,create dataframe word vector data term row label,python-3.x pandas word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
14437,14437,46917675,2017-10-24 18:33:27,,downloaded dump wikipedia file gb downloaded format load file python convert article plain text file inorder perform lda wa following instruction fromm http radimrehurek com gensim wiki html data loading python mentioned,2017-10-24 18:35:53,2017-10-24 19:12:38,load wikipedia dump,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
14450,14450,46888984,2017-10-23 12:07:55,,code found test py run correctly importing test py test py file line creates ldamulticore model seems stuck added example code illustrate problem solution test py test py terminal output terminal output running test py,,2017-10-23 12:07:55,gensim model ldamulticore executing imported trough file,python machine-learning gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
14454,14454,46960119,2017-10-26 17:11:55,,want load pre trained word embeddings google news error showing fix want list word word embeddings average sentence embedding,,2018-02-01 00:19:28,load pre trained word embeddings,python encoding word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
14457,14457,47018088,2017-10-30 14:44:50,,using gensim word vec built cbow model bunch litigation file representation word vector named entity recognition problem want known evaluate representation word use datasets like wordsim nltk online datasets google work built model specific domain dataset file evaluate word vec representation word vector want word belonging similar context closer vector space ensure build model started using technique called odd one eg created dataset validating using word training word vec started evaluating taking three word similar context odd word context accuracy model method really help evaluating w v model better way want go word similarity measure need reference score human assessed evaluate model technique please suggest idea technique,2017-10-30 15:34:04,2017-10-30 16:01:24,evaluate word vec build specific context file,machine-learning nltk word2vec gensim feature-engineering,,,CC BY-SA 3.0,True,False,True,False,False
14469,14469,47037276,2017-10-31 14:01:09,,want optimize gensim run doc vec window c compiler installed gensim following instruction http radimrehurek com gensim install html however page http radimrehurek com gensim model doc vec html saying c compiler needed installing gensim make sure c compiler installing gensim use optimized compiled doc vec training x speedup blog something using pip blas tutorial http github com rare technology gensim blob develop doc notebook doc vec lee ipynb saying time train blas library used take second blas library used take minute use blas value time seems like install blas optimization idea blas little complex blas installation guide window blas library install running gensim window install blas library automatically linked python code running gensim doc vec something link doc vec code,2020-06-20 09:12:55,2017-11-01 16:21:32,optimizing gensim c compilier blas window,python-2.7 word2vec gensim blas doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14476,14476,46998858,2017-10-29 09:56:08,,trying install gensim using giving error please help installing gensim googled able find solution,,2020-01-21 11:01:35,importerror module named py compat,python python-2.7 importerror gensim,,,CC BY-SA 3.0,False,False,True,False,False
14482,14482,46985320,2017-10-28 01:08:17,,trying use pre trained model add additional vocabulary csv file column sentence get following error existing model fr train line missing attributeerror traceback recent call last usr local lib python dist package gensim model word vec py train self sentence total example total word epoch start alpha end alpha word count queue factor report delay compute loss called model cached iter value supplied epoch value self model trimmed post training raise runtimeerror parameter training discarded using model trimmed post training method fast version attributeerror word vec object ha attribute model trimmed post training,,2017-10-28 07:06:33,gensim word vec online training attributeerror word vec object ha attribute model trimmed post training,nlp word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
14493,14493,47060859,2017-11-01 17:51:04,,corpus file wa made using function gensim lost dictionary file way get dictionary file something corpus file using gensim,2017-11-02 11:08:36,2017-11-02 11:08:36,corpus file wa made doc bow function gensim lost dictionary file get dictionary file back,machine-learning nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
14499,14499,47022246,2017-10-30 18:46:21,,tried import gensim module window end error c python lib site package gensim py win amd egg gensim utils py userwarning detected window aliasing chunkize chunkize serial warning warn detected window aliasing chunkize chunkize serial possibility overcome warning,2018-06-12 21:46:39,2018-06-12 21:46:39,warning message importing gensim module window,python nlp warnings semantics gensim,,,CC BY-SA 4.0,False,False,True,False,False
14501,14501,47025885,2017-10-30 23:48:37,,doe gensim option equivalent training step tensorflow word vec example word vec basic default value doe gensim use gensim parameter related training step tensorflow script includes section tensorflow example perform sne embeddings plot matplotlib plot look reasonable number step high using small corpus email one way look reasonable number clustered together would like attain apparent level quality using gensim,2017-12-26 20:20:36,2017-12-26 20:20:36,gensim equivalent training step,python tensorflow nlp word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
14511,14511,46970376,2017-10-27 08:11:23,,using gensim wrapper obtain wordrank embeddings following tutorial follows however getting following error wondering made wrong everything look correct please help moreover want know way saving model correct saw gensim offer method advantage using without directly using original wordrank model,2017-10-27 08:29:47,2018-09-24 00:07:54,issue gensim wordrank embeddings,python nlp gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
14517,14517,47028943,2017-10-31 06:12:27,,running code gensim word vec throwing word vocabulary error let know solution output use print list,2017-10-31 06:23:23,2017-10-31 06:46:53,gensim keyerror word quick vocabulary,python-3.x word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
14526,14526,47080842,2017-11-02 17:03:00,,im using jython working fine need install gensim doe library work jython thank,2017-11-02 18:30:07,2017-12-08 01:58:13,gensim jython,gensim jython-2.7,,,CC BY-SA 3.0,False,False,True,False,False
14557,14557,47163477,2017-11-07 16:59:29,,trying build word level language model tensorflow input batch word id shape target input shifted one time step left word target next word sequence model receives word embeddings input word embeddings pre trained using gensim word vec manually checked word embeddings read correctly correspond right word id although tried lot thing model improving even training epoch full training set accuracy remains tried without success removing dropout first goal get rid underfitting different vocabulary size using gradient clipping using gradient clipping changing initialization weight data shuffling different optimizer rsmprop adam gradient descent larger smaller model hidden layer hidden unit different batch size different learning rate different loss function sparse softmax cross entropy logits tf contrib seq seq sequence loss refeeding refeeding final state lstm training beginning loss accuracy improving also model adapting prediction epoch full training set loss accuracy stay constant also model prediction changing anymore get stuck example show development loss accuracy input sequence epoch nothing changing anymore working week already know try anymore would super grateful tip idea important part code,2017-11-08 07:31:46,2017-11-08 07:31:46,language modeling model loss accuracy improving model underfitting,python tensorflow nlp language-model,,,CC BY-SA 3.0,False,False,True,False,False
14569,14569,47105869,2017-11-03 23:47:34,,code error installed properly really clue going wrong encountered,2017-11-04 08:27:33,2019-06-05 08:34:51,getting error install pyemd even though installed,python installation word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
14585,14585,47148615,2017-11-07 01:36:06,,first time using doc vec trying classify work author trained model labeled sentence paragraph string specified length word list word paragraph tag author name case two author tried accessing docvecs attribute trained model contains two element corresponding two tag trained model trying get doc vec numpy representation paragraph fed training use training data later thanks,,2017-11-08 05:37:06,getting numpy vector trained doc vec model document,python-3.x nlp gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14603,14603,47155414,2017-11-07 10:21:23,,obtain word vector code e g want identify word represents word vector wor vec genism tried using code however work please help,,2017-11-08 05:32:32,given word vector get word word vec,python word2vec gensim word-embedding doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14605,14605,47157286,2017-11-07 11:51:49,,using following python code generate similarity matrix word vector vocabulary size dimensionality however understand dimensionality vocabulary size please let know wrong code moreover want know order vocabulary used calculate similarity matrix obtain please help,,2019-04-29 14:10:11,get similarity matrix word vec python gensim,python word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
14612,14612,47117569,2017-11-05 02:21:00,,doc use read word vec model genism index word mapping e g derive inverted mapping word index based,2020-02-08 05:09:00,2020-02-08 05:09:00,get word index gensim,gensim,,,CC BY-SA 4.0,False,False,True,False,False
14625,14625,47235153,2017-11-11 06:39:27,,execute code instead getting sim model pkl get two file sim model pkl index npy sim model pkl behavior,2017-11-13 16:24:06,2017-11-13 16:24:06,suffix added extra model file save,python-2.7 gensim,,,CC BY-SA 3.0,False,False,True,False,False
14626,14626,47171777,2017-11-08 04:47:30,,set document vector generated using gensim doc vec k vector dimension wish cluster similar document want generate n n similarity matrix run clustering algorithm tried instruction link http github com rare technology gensim issue using gensim similarity output k record wa k matrix dont understand output k k missing something,,2017-11-08 07:45:16,doc vec clustering n n similarity document,cluster-analysis gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14627,14627,47173538,2017-11-08 07:07:15,,try create word vec model skipgram negative sampling received file output follows worried happens previous test example word vec received one model npy file please help,2017-11-13 16:24:46,2017-11-13 16:24:46,multiple model file created gensim word vec,python word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
14632,14632,47134108,2017-11-06 09:54:21,,new nlp subject working turkish hard find proper corpus read lot found http radimrehurek com gensim wiki html preparing corpus tell use wikipedia data even use give stem word structure language agglutinative language aim put text category result must like text related subject subject subject thought try without corpus first wanted ask idea possible utopic also need category word related someone show path go great drifting inside topic thanks,2017-11-06 23:51:01,2018-04-06 14:57:46,work language without explicit token e g turkish,python nlp,,,CC BY-SA 3.0,False,False,True,False,False
14633,14633,47138149,2017-11-06 13:30:44,,lda code generates topic say standard way norm used link generated topic document eg doc topic doc topic topic etc one way think string search geenrated key word topic doc generic way practice followed ex lda code http github com manhcompany lda blob master lda py,,2018-06-04 17:07:20,link back topic generated lda model actual document,machine-learning nlp gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
14655,14655,47270934,2017-11-13 18:16:27,,trying classify set text document using multiple set feature using sklearn feature union combine different feature fitting single model one feature includes word embeddings using gensim word vec order include transformer estimator already available sklearn attempting wrap word vec result custom transformer class return vector average however come time fit model receive error understand error variable word csr matrix need iterable list question modify transformer class data use word embeddings feature feed featureunion first post please gentle,2017-11-14 12:18:48,2018-05-15 23:28:15,custom transformer featureunion word vec,python scikit-learn nlp pipeline word2vec,,,CC BY-SA 3.0,False,False,True,False,True
14685,14685,47332205,2017-11-16 14:28:15,,using gensim doc vec however check get output real output recipe recipe use get output real value recipe test dictionary please let know happens,2017-11-18 03:59:46,2017-11-18 03:59:46,issue doc vec tag gensim,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14693,14693,47319033,2017-11-15 23:25:04,,trained topic model using symmetric alpha lda distibution see quite understand gensim allows lowering alpha parameter allow document mixture fewer topic,,2017-11-15 23:46:08,adjust alpha parameter gensim ldamodel,python alpha gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
14701,14701,47353341,2017-11-17 14:48:50,,calculating tf idf follows however want identify important word corpus using word ha highest value please let know,2017-11-17 14:54:45,2017-11-18 00:35:33,get important word corpus using tf idf gensim,python gensim tf-idf,,,CC BY-SA 3.0,False,False,True,False,False
14707,14707,47300015,2017-11-15 05:28:44,,using gensim calculate tf idf score corpus mentioned current code follows however get error p code wrong happy different code please help calculate tf idf value current corpus moreover want get term ha highest tf idf score corpus please help,2017-11-15 08:13:48,2017-11-15 08:13:48,issue calculating tf idf gensim,python gensim tf-idf,,,CC BY-SA 3.0,False,False,True,False,False
14708,14708,47300490,2017-11-15 06:09:06,,know obtain document vector given tag doc vec using document vector either recipe tag start newspaper tag start ingredient tag start want retrieve document vector recipe pattern recipe document e g recipe recipe interested knowing possible obtain multiple document vector using pattern e g tag starting please help,2017-11-15 06:27:25,2017-11-15 17:42:38,obtain document vector doc vec gensim,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14721,14721,47325484,2017-11-16 09:04:42,,assignment something like task estimate lda model parameter corpus find list topic significant word topic pass autograder fine next task find topic distribution new doc attempt follows however simply return also see doc statement infer topic distribution new unseen document doc lda lda doc bow success either help appreciated,,2017-11-16 20:27:33,topic distristribution gensim ldamodel trained countvectorizer,python-3.x gensim topic-modeling countvectorizer,,,CC BY-SA 3.0,False,False,True,False,False
14723,14723,47303842,2017-11-15 09:36:41,,use model infer vector compute vector differ order document result different call infer vector executed call infer vector twice result follows know happen link result,2017-11-15 10:04:22,2019-08-02 17:09:11,gensim doc vec order sentence affect doc vec vector,gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14737,14737,47325820,2017-11-16 09:23:24,,using gensim load fasttext file follows however confused need load file perform command like etc file important perform cosine similarity matching please help,2017-11-16 11:05:13,2018-06-18 13:03:33,fasttext gensim,python word2vec gensim fasttext,,,CC BY-SA 3.0,False,False,True,False,False
14760,14760,47381841,2017-11-19 20:47:53,,building chat bot every message user sends need converted vector ml related work using pre trained word vec model word vec model wa created using gensim library saved disk mb file used django python web application every time new message received api request function load word vec model us object generate vector message need happen real time basis worried every time new message received application load instance word vec model would cause memory problem many request coming time multiple instance word vec model present ram time handle memory efficiently doe use much memory,2017-11-21 04:04:07,2017-11-21 04:04:07,handling large number request use ml model,django memory-management machine-learning word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
14761,14761,47386166,2017-11-20 06:28:05,,given doc vec model using gensim wa trained million document million document wa trained also given idea order document trained folder supposed use test data find top match training set code use output get get know document doe document id refer access document trained data set job id,,2018-04-20 18:54:21,access document detail doc vec similarity score gensim model,python gensim doc2vec sentence-similarity,,,CC BY-SA 3.0,False,False,True,False,False
14772,14772,47365480,2017-11-18 11:25:19,,new glove successfully ran demo sh given website running demo got several file created etc documentation anything describes file need use use find similar word hence please help find similar word given word glove using cosine similarity e g like gensim word vec please help,,2017-11-21 08:54:23,get similar word using glove,nlp stanford-nlp word-embedding,,,CC BY-SA 3.0,False,False,True,True,False
14773,14773,47366918,2017-11-18 14:00:21,,k document user description using doc vec model wanted ask would best fit model configuration contextual search document want enter free text query get best similar result query query including unique word important example need english speaker current configuration getting really good result example find description speaker inside english one german speaker better configuration example,,2017-11-18 14:00:21,doc vec configuration,python similarity word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14784,14784,47424335,2017-11-21 23:19:15,,trained lda model using gensim impression lda reduces data two lower level matrix ref http www analyticsvidhya com blog beginner guide topic modeling python seem figure access term topic matrix reference could find gensim documentation get topic attribute however format provides make sense easy enough apply transformation retrieve document topic matrix like hoping similarly functional method generate topic term matrix ideally output look like thought whether possible,,2018-02-28 09:55:23,access term topic matrix generated gensim lda,python gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
14785,14785,47441798,2017-11-22 18:40:07,,trying use gensim glove instead word vec make shape glove compatible gensim use using following line code however last line code give following error tried open glove first writing csv file open specifying encoding utf also tried several thing mentioned error keep coming back doe anyone know solution,2019-04-09 17:12:23,2019-04-09 17:12:23,doe using gensim glove continue give utf unicodedecodeerror,python-3.x utf-8 gensim,,,CC BY-SA 4.0,False,False,True,False,False
14801,14801,47427986,2017-11-22 06:15:32,,followed example link ran following script process latest english wikipedia article http radimrehurek com gensim wiki html python gensim script make wiki result running script hour mm txt file want train word vec model example found start bz file train word vec model using mm file input instead raw bz file link show train lda model someone pls share syntax http radimrehurek com gensim wiki html thanks,,2017-11-22 06:15:32,wikipedia word vec,gensim,,,CC BY-SA 3.0,False,False,True,False,False
14811,14811,47507091,2017-11-27 09:01:16,,two different word vector model created using word vec algorithm issue facing word first model second model want create third model two different word vector model use word vector model without loosing meaning context word vector,2017-11-27 16:01:44,2017-11-27 16:01:44,creating wordvector model combining word model,machine-learning nlp word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
14822,14822,47598369,2017-12-01 17:19:25,,found question provides evidence sentence order probably matter effect also result different random initialization want process reddit comment dump project string extracted json would unsorted belong different subreddits topic want mess context doe neighbor sentence matter gensim word vec recover whole comment tree structure simply extract bag sentence train model,,2017-12-01 18:44:09,doe word vec realization gensim go beyond sentence level examining context,word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
14827,14827,47598646,2017-12-01 17:36:25,,many different way tf idf calculated want know formula used gensim lsa model going source code obvious document term matrix created probably memory optimization one lsa paper read cell document term matrix log frequency word document divided entropy word however seems unusual formulation tf idf familiar form tf idf also notice question implemented gensim however see importing therefore assume ha implementation tf idf,,2017-12-14 03:00:16,formula tf idf doe lsa model gensim use,gensim tf-idf latent-semantic-indexing latent-semantic-analysis,,,CC BY-SA 3.0,False,False,True,False,False
14848,14848,47563821,2017-11-29 23:58:19,,code used generate word vec use train naive bayes classifier able generate word vec use similarity function successfully next step would want use word vec train naive bayes classifier currently code given error trying slit data test training convert word vec model array used training data importing library import numpy np import matplotlib pyplot plt import panda pd import gensim,2017-12-16 12:52:51,2017-12-16 12:52:51,use word vec train classifier,python word2vec naivebayes,,,CC BY-SA 3.0,False,False,True,False,False
14860,14860,47604717,2017-12-02 04:50:50,,using save method gensim phrase class store model future use update version gensim problem loading model back example get following error loading model gensim wa made better way ensure forward compatibility,,2017-12-02 05:18:39,save gensim model ensuring forward compatibility,python machine-learning nlp data-science gensim,,,CC BY-SA 3.0,False,False,True,False,False
14868,14868,47624644,2017-12-03 23:53:47,,understand word present gensim model vocabulary training give following true understand specifically running model learn embeddings every word list sentence find word model vocabulary get embeddings wrong thanks edit helped solve problem,2017-12-04 04:11:43,2017-12-04 04:11:43,gensim model keyerror,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
14884,14884,47533772,2017-11-28 14:18:29,,would like call copy object using module requires multiple copy require much ram gb ram tried evaluate query pair took hour first round may round coming looking threading solution understand python ha issue suggestion,,2017-11-30 20:26:22,gensim word vec doc vec multi threading parallel query,python multithreading word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
14887,14887,47681257,2017-12-06 18:37:35,,http radimrehurek com gensim model lsimodel html gensim model lsimodel lsimodel save function ha prototype like understand pas however document explain could anyone help thanks,,2018-07-17 02:26:53,call gensim lsimodel save,gensim,,,CC BY-SA 3.0,False,False,True,False,False
14914,14914,47610985,2017-12-02 18:13:02,,trying learn dynamic topic modeling capture semantic change word data scrapped pubmed wa able get data form xml wa able extract abstract text date information saved csv format part data format obtained year month day abstracttext planning using gensim lda model never really done topic modeling need help guiding process one step time question csv preferred format feed gensim lda dynamic modeling time aspect data captured used model better way organize data csv file use bodytext instead abstract hope learn lot thanks advance,2017-12-03 10:25:43,2019-02-16 21:36:36,setup data dynamic topic modelling,python text-mining gensim topic-modeling pubmed,,,CC BY-SA 3.0,False,False,True,False,False
14917,14917,47666699,2017-12-06 04:16:35,,background vector sample data vector ha category name place color name objective train model take new input string predict category belongs example new input purple able predict color correct category new input calgary predict place correct category approach research came across word vec library ha similarity mostsimilarity function use one brute force approach thought following take new input calculate similarity word vector take average instance input pink calculate similarity word vector name take average vector also vector give highest similarity average would correct vector input belong issue given limited knowledge nlp machine learning sure best approach hence looking help suggestion better approach solve problem open suggestion also please point mistake may made new machine learning nlp world,2017-12-11 22:23:36,2018-05-14 16:43:38,using word vec classify word category,python machine-learning nlp word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
14939,14939,47725012,2017-12-09 03:25:02,,solved seems referencing touse variable doe work acceptable file path input changing true path fixed problem relatively new python biting chew understand keep getting error code simple operation closed file yet know file closed file error derived corpus mmcorpus serialize statement shown block code error,2017-12-10 15:54:55,2017-12-10 15:54:55,gensim valueerror operation closed file,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
14964,14964,47785599,2017-12-13 04:41:03,,reading paper distributed representation word phrase compositionality interesting really curious relationship parameter negative final performance personally think final performance may become better increase negative value negative sample using make comparison get better result theoretical course performance become better point right,,2017-12-13 19:09:08,negative affect model performance gensim,nlp word2vec,,,CC BY-SA 3.0,False,False,True,False,False
15002,15002,47775557,2017-12-12 14:56:40,,existing gensim doc vec model trying iterative update training set extension model take new document perform preproecssing normal load original model update vocabulary retrain update training set panda dataframe appending new data reset index however try use infer vector updated model result quality poor suggesting index model training set dataframe longer match compare non updated training set dataframe using updated model result fine though obviously missing new document anyway updated want able make frequent update model without full retrain model,,2017-12-13 18:04:31,updating training document gensim doc vec model,gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15005,15005,47735393,2017-12-10 02:49:16,,using gensim phrase identify important n gram text follows however detects uninteresting n gram etc particularly interested detecting concept text etc way stop phrase detecting uninteresting n gram mentioned example,,2017-12-11 02:37:00,gensim phrase usage filter n gram,python nlp word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15009,15009,47812930,2017-12-14 12:02:09,,would like know scientific explanation word vec model like cbow perform poorly small data tested retrained model time dataset scientific reason improvement performance data size increased increase word count increase data,2017-12-14 12:03:51,2017-12-14 18:09:56,scientific explanation word vec model perform poorly small data,word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15027,15027,47827130,2017-12-15 06:44:04,,trying textual analysis bunch textual document document preprocessing removing unnecessary word stopwords ha sentence determined nlkt sentence tokenizer sentence ha word average job find hidden theme document thought topic modeling however decide data enough obtain meaningful result via lda anything else also divide text different document document roughly x word enough consider sentence document document word average much like tweet suggestion would helpful thanks advance,,2017-12-17 06:18:40,suggestion lda,python-3.x nlp gensim text-analysis,,,CC BY-SA 3.0,False,False,True,False,False
15061,15061,47929028,2017-12-21 16:27:43,,trying doc vec row sentence code interpret result length vector size length doe make sense know something wrong understanding output doc vec gensim package mention length docvec determined size clear,,2018-01-05 19:42:01,doc vec model docvecs length,python nlp gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15063,15063,47838719,2017-12-15 19:25:11,,loaded google news vector dataset word represented point vector want use neural network classification one word seems big reduce vector say without compromising quality,,2018-07-29 14:14:05,reducing word vec dimension google news vector dataset,python-3.x gensim,,,CC BY-SA 3.0,False,False,True,False,False
15068,15068,47799657,2017-12-13 18:13:04,,task assign tag descriptive word document post list available tag working doc vec available gensim read doc vec used document tagging could get suitable parameter value task till tested changing value parameter named size window result getting nonsense also changing value parameter find trend result e value result got little bit improved value result fall anyone suggest suitable parameter value task found size defines size feature vector large enough training data rest parameter getting sure,,2017-12-14 05:08:30,parameter value doc vec document tagging gensim,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15071,15071,47890052,2017-12-19 15:20:20,,tried apply doc vec row sentence code getting poor result implementation change made apart wa suggested tutorial wa change line,2017-12-21 05:02:27,2017-12-21 05:02:27,improving gensim doc vec result,python nlp gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15077,15077,47859739,2017-12-17 21:40:27,,using gensim analyze document similarity large corpus document ha title specifically unique id string along content text looking several tutorial top modeling indexing retrieval wikipedia still clear get interpretable result getting building lsi model querying index search vector see top n similar document index similarity score lookup title document example code would lookup title example document came back similar result previous part tutorial function yielded tuple title token want,,2017-12-19 16:25:28,gensim document similarity get document title similar result,python nlp similarity gensim lsa,,,CC BY-SA 3.0,False,False,True,False,False
15079,15079,47930809,2017-12-21 18:34:44,,doc vec model cluster vector cluster resulting vector implement clustering model,,2018-02-12 13:29:33,doc vec clustering resulting vector,python nlp gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15086,15086,47873938,2017-12-18 17:57:17,,trained word vec model tensorflow save session outputted file wa thinking implementing knn method retrieving nearest word saw answer using gensim save tensorflow word vec model first,2017-12-19 19:23:35,2018-07-28 13:12:50,save tensorflow word vec text binary file later use knn output,machine-learning tensorflow nlp word2vec embedding,,,CC BY-SA 3.0,False,False,True,False,False
15094,15094,47914953,2017-12-20 21:59:54,,please university project called automatic generation ocl constraint supervisor asked choose tool list tool natural language processing apache opennlp deeplearning j chatscript delph dkpro core general architecture text engineering gate gensim linguastream mallet software project modular audio recognition framework montylingua natural language toolkit spacy uima would easiest implement one would suitable future work else proposition,2017-12-21 01:24:20,2017-12-21 07:21:26,natural language processing tool generating ocl,nltk opennlp deeplearning4j ocl dkpro-core,2020-06-21 16:38:11,,CC BY-SA 3.0,True,True,True,False,False
15101,15101,47882600,2017-12-19 08:16:30,,class several method input input trained model object gensims tfidf model function panda dataframe text document one document per row use output input problem class return list tuples incorrect whereas return numpy array length entry cosine similarity row work fine independent function outside class going wrong gensim model object used self inside class help would much appreciated,2017-12-19 08:35:06,2017-12-19 08:35:06,using self class gensim tfidf,python class gensim tf-idf,,,CC BY-SA 3.0,False,False,True,False,False
15109,15109,47893976,2017-12-19 19:30:31,,code used preprocess text apply text rank followed gensim textrank tutorial please help method get better result text data column csv row row sentence output get line different line paragraph text summary word keywords output paragraph text summary control number keywords displayed,,2018-07-18 09:44:25,gensim text rank,python nlp gensim summarization,,,CC BY-SA 3.0,False,False,True,False,False
15111,15111,47898159,2017-12-20 02:57:57,,trying build word vec similarity dictionary wa able build one dictionary similarity populated correctly missing anything code input sample data text code result expected output similarity sheungwan wanchai chaiwan guessing skipgrams working properly fix,2017-12-20 15:56:38,2017-12-20 15:56:38,skip gram word vec working properly,scikit-learn neural-network word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,True
15128,15128,47901979,2017-12-20 08:47:26,,using doc vec model gensim python library every time feed model sentence data set parameter seed doc vec fixed number model give different vector model built test purpose need determined result every time gave unchanged input data searched lot doe find way keep gensim result unchanged anything wrong way use thanks replying advance code,2017-12-20 13:38:00,2017-12-21 05:08:19,gensim doc vec give non determined result,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
15129,15129,47974626,2017-12-26 06:19:39,,recently installed gensim glove mac trying get word embedding textual data however trouble finding right function come across method get similarity metric two word train glove object data present library use obtain embeddings word dataset library python thanks,,2018-01-03 06:35:30,getting word embeddings dataset using training data glove,python macos nlp,,,CC BY-SA 3.0,False,False,True,False,False
15134,15134,47978579,2017-12-26 12:20:35,,using following function load word vec model however getting following error try genism version using version please let know making wrong tried remove call class give following error please help,2017-12-28 03:49:45,2017-12-28 03:49:45,error loading word vec model,word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15147,15147,47959639,2017-12-24 09:58:48,,set embeddings trained neural network ha nothing gensim word vec want use embeddings initial weight see continue training requires gensim modle input also seems accept gensim model case gensim model start text file word vec format embeddings start transfer learning word vec text file,,2017-12-24 15:02:56,gensim word vec transfer learning non gensim model,python word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15153,15153,47905576,2017-12-20 11:59:12,,created document vector large corpus using gensim doc vec using gensim infer vector using document vector create document vector another sample corpus way pas entire dataframe infer vector get output vector line dataframe,,2017-12-21 13:11:43,use gensim doc vec infer vector large dataframe,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15155,15155,48017343,2017-12-29 04:18:46,,word vec model wa trained huge corpus using model neural network application came across quite vocabulary word need find word embeddings vocabulary word googling found facebook ha recently released fasttext library question convert existing word vec model keyedvectors fasttext model,,2018-05-17 09:53:40,convert gensim word vec model fasttext model,nlp word2vec gensim word-embedding fasttext,,,CC BY-SA 3.0,False,False,True,False,False
15158,15158,47998685,2017-12-27 21:10:25,,tried generating topic using gensim record trying visualize topic get validation error print topic model training fails using pyldavis got error trying running pyldavis,,2019-09-11 03:06:52,pyldavis validation error trying visualize topic,python nlp lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
15165,15165,48051767,2018-01-01 17:30:03,,trying built predictive model using address data transformed address data bigram model using gensim phrase facing issue transforming address data corresponding bigram attaching separate column used countvectorization code gensim bigram phrase model sample input column dataframe expected output new data passing gensim phrase model able replace corresponding address respective bigram gensim phrase model iteratively expected output replace old address newly generated bigram phrase pas countvectorizer help appreciated,2018-01-02 03:04:35,2018-01-02 03:04:35,creating bigram phrase column panda using gensim attaching dataframe,pandas nlp word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
15182,15182,48073718,2018-01-03 08:28:06,,created word vec dictionary using gensim want replace text corpus root word way replace text data corpus root word eg building root word similarity dictionary want replace similar word building similarity orginal text corpus sample data column dataframe similarity dictionary,2018-01-03 17:43:41,2018-01-17 13:15:33,word replacement text corpus using word vec similarity dictionary panda dataframe,python pandas string-matching word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15196,15196,48096066,2018-01-04 13:09:28,,trying use pre trained word embeddings taking account phrase popular pre trained embeddings like separate embeddings phrase well unigrams e g embeddings two unigrams naive word tokenization dictionary look ignore bigram embedding gensim provides nice phrase model given text sequence learn compact phrase e g instead two unigrams done aggregating comparing count statistic unigrams bigram possible use pre trained embeddings without estimating count statistic elsewhere possible use pre trained embeddings without estimating count statistic elsewhere efficient way use bigram imagine way using loop believe ugly ugly code,,2018-01-04 13:09:28,using gensim phraser pre trained vector,python machine-learning gensim phrase,,,CC BY-SA 3.0,False,False,True,False,False
15206,15206,48059145,2018-01-02 10:19:07,,using gensim library train doc vec model experimenting different datasets training fairly confused ideal training data size doc vec model sharing understanding please feel free correct suggest change training general purpose dataset want use model trained general purpose dataset specific use case need train lot data training context related dataset want train data context use case usually training data size smaller size number word used training case general note stop training ml model error graph reach elbow point training help significantly decreasing error ha study done direction doc vec model training stopped reaching elbow,,2018-01-03 15:40:45,much data actually required train doc vec model,neural-network gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15212,15212,48060401,2018-01-02 11:46:40,,output creating word vec model gb corpus got file output word vec model word vec model syn neg npy word vec model wv syn npy used first file training smaller corpus treat last file loading model load first one run query usual,2018-01-02 11:49:25,2018-01-03 15:30:29,syn neg syn created output,word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15217,15217,48009532,2017-12-28 14:47:23,,generated word vector corpus facing vocabulary issue many word generate word vector oov word fly using existing word embedding,,2019-05-08 14:45:29,word embedding oov word,machine-learning nlp word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15223,15223,48044670,2017-12-31 17:55:45,,trying get started using excellent tutorial trying use code sample added method remove punctuation stopwords etc trouble method called training iteration understand call global method messing sure get past problem code,,2018-01-03 16:00:15,doc vec gensim issue shuffling sentence epoch,python word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15228,15228,48115965,2018-01-05 14:50:58,,want compute cosine similarity lda topic fact gensim function matutils cossim dont know parameter vector use function snap code,2018-05-23 08:51:56,2018-05-23 08:51:56,cosine similarity lda topic,python nlp gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
15238,15238,48064378,2018-01-02 16:20:45,,pyspark dataframe corpus k unique row doc contains sentence text processing dimension vectorized representation row doc nlp process remove punctuation regex udf word stemming nltk snowball udf pyspark tokenizer word vec ml feature word vec vectorsize windowsize understand implementation us skipgram model create embeddings word based full corpus used question doe implementation go vector word corpus vector document row process gensim doc vec implementation simply concatenates word vector doc together doe gensim calculate doc vec paragraph vector doe cut vector specified size doe use first word average wa unable find information sourcecode http spark apache org doc api python module pyspark ml feature html word vec help reference material look super appreciated,,2019-03-28 02:48:39,doe pyspark calculate doc vec word vec word embeddings,apache-spark nlp pyspark word2vec doc2vec,,,CC BY-SA 3.0,True,False,True,False,False
15239,15239,48137617,2018-01-07 13:31:36,,word vec model trained twitter imported gensim using would like use function similar one show similar word want restrict result word start hashtag somebody please give explain accomplish,2018-01-07 16:24:38,2018-01-07 16:24:38,gensim word vec similar filtering prefix,python machine-learning nlp word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15246,15246,48082018,2018-01-03 17:11:12,,word vec dictionary give top similar word given word want pas list word similarity need calculated file list input similarity word checked word vec dictionary similar word input word list must found written dataframe shown format want create dataframe two column word similar word output dataframe help appreciated,2018-01-03 17:58:41,2018-01-03 17:58:41,create dataframe top close word particular word list dictionary panda,python string pandas word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15250,15250,48049619,2018-01-01 12:22:42,,trying solve nlp problem dict word like input phone easily use operator get description phone data key problem input something like phone phone want input phone get word like know word vec use nlp module provide solution like second issue give word dog get word like puppy kitty dog dog etc tried something like giving synonym returning instead wanted,2018-01-01 14:14:28,2018-01-01 14:14:28,get similar word related one word,python nlp nltk gensim spacy,,,CC BY-SA 3.0,True,True,True,False,False
15263,15263,48089141,2018-01-04 05:24:03,,word vec dictionary ha list similar word given word example want create dataframe containing root similar word similarity currently able write similar word corresponding root word current output expected output similar word similarity done,2018-01-04 06:05:32,2018-01-04 06:05:32,write word similarity specific word dictionary dataframe panda,python string pandas word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15276,15276,48090426,2018-01-04 07:15:54,,training using got error code use python gensim version help must something really missing,2018-06-09 04:56:25,2018-06-09 04:56:25,attributeerror list object ha attribute word python gensim module,python machine-learning nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
15282,15282,48164954,2018-01-09 09:25:03,,dataset document separated different year objective train embedding model year data time word appearing different year similar vector representation like word compute vector year year something around way accomplish example train model year initial value word trained already year modify vector randomness new word corpus,2018-01-09 17:36:21,2018-01-09 17:36:21,gensim word embedding training initial value,machine-learning nlp word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
15318,15318,48205412,2018-01-11 10:56:23,,gensim word vec allows u train model using text far know creates interim nx v n number relevant concept v vector size user specified matrix store information later used create wordspace access work particular data structure,,2018-01-11 10:56:23,access interim model created cbow gensim word vec,python word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15323,15323,48281026,2018-01-16 12:14:07,,want cluster dimensional word vec vector custom gensim model determine whether use clustering find topic related word hope attach quite distant still related word overall size model normalization vector e memory gb tried scikit dbscan implementation github seem consume ram processing crash time gb ram gb swap metric euclidean convert cosine distance threshold co eps sqrt optimization applied problem know number cluster want determine setting threshold closely related word let dbscan seems working small subset pas computation full data algorithm workaround python help edit distance matrix seem size float byte kb mb gb tb tb impossible precompute edit currently trying elki make cluster data toy subset properly,2018-01-16 16:12:23,2019-02-18 11:32:29,fixed ram dbscan another clustering algorithm without predefined number cluster,python optimization cluster-analysis gensim,,,CC BY-SA 3.0,False,False,True,False,False
15324,15324,48234595,2018-01-12 22:00:38,,working app using gensim know recommended approach trying port however sure equivalent method method better put obtain document vector entire document using model write annoy model,2018-01-14 11:27:02,2018-01-14 11:27:02,gensim doc vec infer vector equivalent keyedvector,machine-learning nlp word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15344,15344,48313840,2018-01-18 04:25:36,,want train doc vec model gensim corpus large method train every batch sentence corpus example iterately load corpus train model reload another batch corpus know api method hint,,2018-01-18 22:47:38,training gensim doc vec occures memory error,word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15349,15349,48297322,2018-01-17 09:10:02,,context preparing large input array use machine learning algorithm using word embeddings using gensim word vec represent word sentence vector input calling word vec model sentence word length list float problem iterate sentence apply word embedding function forming new array new word embedded representation word length vector float got million sentence encode hit around million row mark gb ram get maxed way avoid happening read generator help memory efficiency first solution used numpy array changed list help memory efficiency still complete task would use cloud service achieve magic applied code able laptop gb ram code help appreciated,,2018-01-17 09:10:02,large python list maxing memory word vec,python memory memory-management machine-learning word2vec,,,CC BY-SA 3.0,False,False,True,False,False
15350,15350,48298619,2018-01-17 10:17:33,,use lda package model topic large set text document simplified example removed cleaning step lemmatization biograms etc code happy result far struggle write code predict new text find reference lda documentation save loading predict option add new text set fit expensive way know gensim somehow result gensim model le impressive stick initial lda model appreciate suggestion code,2018-01-17 10:28:06,2018-03-16 06:05:23,predict new text using python latent dirichlet allocation lda model,python predict lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
15351,15351,48225845,2018-01-12 11:56:34,,following problem english language code generates successful word embeddings gensim similar phrase close considering cosine distance angle response time error measurement relation user perceived response time error measurement small thus similar phrase set however use phrase portuguese work code follows question additional set gensim generate proper word embeddings portuguese language gensim doe support language,2018-01-12 12:11:19,2019-11-22 19:38:39,generate word embeddings portuguese using gensim,python nlp nltk gensim,,,CC BY-SA 3.0,True,False,True,False,False
15354,15354,48263122,2018-01-15 12:32:11,,want get vector word every iter e g would like use model model want get dimensional vector learned every iteration want show continuous learning content html,2018-01-15 16:01:58,2018-01-15 16:01:58,get vector training iter word vec,python-3.x nlp word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
15357,15357,48267720,2018-01-15 17:10:08,,use case collection upvoted document downvoted document using order set result search using gensim doc vec able run query word fetch matching word would able fetch matching keywords given vector fetched vector sum doc vector,,2018-01-15 17:58:30,doc vec way fetch closest matching term given vector,word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15372,15372,48253833,2018-01-14 20:25:59,,need print topic word one word contains number get topic name like happy string word happy show happi show happi want print word,2018-01-15 06:03:10,2018-02-05 00:08:46,print topic name using lda python,python-3.x nltk gensim lda stemming,,,CC BY-SA 3.0,True,False,True,False,False
15373,15373,48358161,2018-01-20 16:03:38,,direct efficient method getting topic probability data gensim interface transformedcorpus object numpy array alternatively panda dataframe row method,,2018-06-21 21:39:43,efficient transformation gensim transformedcorpus data array,python numpy gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
15389,15389,48290403,2018-01-16 21:51:28,,working node vec using small dataset code work well soon try run code large dataset code crash error process finished exit code interrupted signal sigabrt line giving error using pycharm python idea happening could found post could solve problem,,2019-12-31 01:25:35,process finished exit code interrupted signal sigabrt,python pycharm word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15400,15400,48402364,2018-01-23 12:57:48,,trying extract document vector feed regression model prediction fed around labelled sentence doc vec training however wa able retrieve vector using model docvecs snapshot labelled sentence used trained doc vec model code used train doc vec model dimension document vector part code mess update adding comment sophros appear made mistake creating taggeddocument prior training resulted mil document appearing document courtesy irene li tutorial doc vec made slightly edit class used generate taggeddocument mistake wa fixed made change appear index taggeddocument must form list taggeddocument work properly detail please refer answer gojomo,2018-01-24 06:38:06,2018-01-25 00:31:16,extracting vector doc vec,gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15401,15401,48362530,2018-01-21 00:31:48,,trying follow official doc vec gensim tutorial mentioned http github com rare technology gensim blob develop doc notebook doc vec lee ipynb modified code line determine best matching document given query everytime run get completely different resultset new code iin line notebook everytime run piece code get different set document matching query prevent forest fire difference stark doe seem match doc vec suitable match querying information extraction bug,,2019-11-21 04:10:08,doc vec infer vector keep giving different result everytime particular trained model,nlp word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15407,15407,48307812,2018-01-17 18:34:23,,trying use google word vec model http code google com archive p word vec http drive google com file b xkcwpi kdynlnuttlss pqmm edit usp sharing based google news python load model using gensim package specially class http radimrehurek com gensim model keyedvectors html use method problem named entity example would compare measure roger federer michael jordan federer jordan want tokenize single named entity many named entity got error pre trained word vec model used measure distance named entity,,2018-01-17 18:34:23,named entity recognition cosine similarity,python nlp word2vec named-entity-recognition,,,CC BY-SA 3.0,False,False,True,False,False
15420,15420,48455703,2018-01-26 04:12:40,,using gensim train word vec know word similarity deteremined word replace make sense sentence word similarity used extract relationship entity example bunch interview document interview interviewee always say name manager wanted extract name manager interview transcript could get list human name document using nlp name similar word manager using word vec likely manager doe thought process make sense word vec would ml solution problem input word embeddings sequence sequence model,,2018-01-26 18:30:59,word vec used information extraction,machine-learning word2vec gensim rnn information-extraction,,,CC BY-SA 3.0,False,False,True,False,False
15421,15421,48371824,2018-01-21 21:19:23,,following code relevant part shown code run lambda aws work fine model small think reason decent size model mb get following error first file exists secondly seems main model file loaded validate access existence file added work fine printing help,2018-01-22 12:02:42,2018-01-23 12:38:54,gensim loading doe work,amazon-web-services amazon-s3 aws-lambda gensim,,,CC BY-SA 3.0,False,False,True,False,False
15426,15426,48507404,2018-01-29 18:05:36,,came across stackoverflow post word count doc vec model vocabulary wonder another method retrieve word frequency maybe elegant way via gensim library e output word frequency txt file,,2018-01-30 21:37:18,gensim retrieving word frequency doc vec vocabulary,dictionary word2vec gensim doc2vec vocabulary,,,CC BY-SA 3.0,False,False,True,False,False
15428,15428,48403942,2018-01-23 14:18:59,,trying create gensim corpus save arbitrary hdfs regular f path using pyspark running zeppelin notebook hadoop cluster minimal example lead error although path exists running following work however find checked kind path required working pyspark,2018-01-24 09:05:34,2018-01-24 13:55:53,serialize gensim corpus pyspark using apache zeppelin notebook,hadoop serialization pyspark gensim apache-zeppelin,,,CC BY-SA 3.0,False,False,True,False,False
15457,15457,48411780,2018-01-23 22:19:37,,little background project copy identifier text e g need find right match given text input within corpus however wa able achieve somewhat using gensim similarity lda lsi model update index new document idea keep training model live stage step followed querytext guardiola moved lionel messi role come deep think aguero drop back deeper position often note code layman index created using create dictionary create corpus create lda model update existing dictionary model index update existing dictionary update existing lda model update existing similarity index warning update seems worked let run similarity query text however failed error really appreciate helping looking forward awesome reply,2018-02-02 12:04:15,2018-02-02 12:04:15,gensim similarity add document live training,python nlp similarity gensim,,,CC BY-SA 3.0,False,False,True,False,False
15488,15488,48479915,2018-01-27 19:50:24,,using example gensim word vec similar method training embedding vector wa wonder good ratio preferred ratio embedding dimension vocabulary size also doe change data coming along still topic would one chose good window size training embedding vector asking training network real life language dictionary rather sentence would describe relationship process file process example sentence text corpus would look like sm exe irp mj create systemdrive window system ntdll dll desiredaccess execute traverse synchronize disposition open option attribute n sharemode read allocationsize n openresult opened may imagine variation numberous question still remains fine tune hyperparameters best way embedding space fit also enough meaningful feature word thanks gabriel,2018-01-28 12:15:42,2019-03-29 07:33:54,preferred ratio vocabulary size embedding dimension,machine-learning keras nltk word-embedding nltk-trainer,,,CC BY-SA 3.0,True,False,True,False,False
15493,15493,48438304,2018-01-25 08:12:47,,run sourcecode twe model need compile c extension python installed microsoft visual c compiler python cython first need run twe train py second twe gensim model wor vec py thrid haved compiled twe gensim model word vec inner pyx setup py using command python setup py install complied word vec inner pyx appears follow error checked pyx file wa compiled correctly also installed cython conclusion import train sentence sg train sentence cbow fast version train sentence topic gensim model word vec inner gensim addons model word vec inner appears problem compiled pyx file correctly two directionarys anyone help problem haved troubled several day please help thank,,2018-05-19 08:52:26,link fatal error lnk open file c user hp pyxbld lib win gensim model word vec inner pyd,c python-2.7 cython word2vec cythonize,,,CC BY-SA 3.0,False,False,True,False,False
15509,15509,48590383,2018-02-02 20:25:44,,would like apply graph vec code dataset however figure properly format input data understand input data format example available github page author network dataset ha integer node binary label dataframe three column appreciate anyone point right direction graph vec github http github com mldroid graph vec tf graph vec arxiv http arxiv org pdf pdf,2018-02-02 20:39:09,2018-05-16 10:18:05,graph vec input data format,python-3.x tensorflow graph word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15523,15523,48443999,2018-01-25 13:28:06,,trying continue training existing model got error last line attributeerror word vec object ha attribute compute loss post said caused using earlier version gensim tried add loading existing model train give attributeerror output model train model trained new sentence solve problem,2019-10-24 13:23:11,2019-10-24 13:23:11,gensim word vec continue training existing model attributeerror word vec object ha attribute compute loss,python nlp word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
15524,15524,48444393,2018-01-25 13:45:10,,recently came across following problem applying topic model bunch parsed pdf file discovered content reference unfortunately also count model e word within reference appear tokenized list word known best practice solve problem thought search strategy python code automatically remove content last mention reference bibliography would go first random mention reference bibliography within full text parser might capture true full content input pdf different journal thus different page structure,,2018-01-30 04:42:47,nlp challenge automatically removing bibliography reference,nlp gensim topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
15545,15545,48559764,2018-02-01 09:52:09,,say title would like load pre tranined model using gensim possibile example fasttext say http radimrehurek com gensim model wrapper fasttext html word vec say possibile continue traning model pretranind end know glove point library something load pre tranined model continue traning sentence case load pretranined model neural network continue traning vector maybe using get kera embedding,,2018-02-01 09:52:09,nlu fasttext glove word vec load pre trained model add new word vocabulary,neural-network nlp word2vec gensim fasttext,,,CC BY-SA 3.0,False,False,True,False,False
15556,15556,48674084,2018-02-07 22:08:08,,using gensim lda topic modeling getting result like topic word word word word topic word word word word topic word word word word however using mallet lda doe produce duplicate word across topic document word train lda get rid word appearing across multiple topic,,2018-04-10 09:21:58,word appearing across topic lda,python gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
15560,15560,48562396,2018-02-01 12:06:32,,new nlp trying extract summary paragraph using gensim python facing problem short paragraph giving warning given give summary short paragraph code python giving warning follows output printing summary label actual summary short paragraph missing something library,,2018-02-01 13:18:46,text summarization gensim short paragraph,python python-3.x gensim,,,CC BY-SA 3.0,False,False,True,False,False
15566,15566,48614304,2018-02-05 00:14:38,,trying build gensim word vec model using external vocabulary know gensim ha internal vocabulary generator however control problem code simply getting c anaconda envs workflow lib site package gensim model word vec py runtimewarning overflow encountered int scalar retain pct retain total max original total,,2018-02-05 00:14:38,gensim build vocab freq overflow error,python nlp overflow gensim vocabulary,,,CC BY-SA 3.0,False,False,True,False,False
15572,15572,48635364,2018-02-06 04:09:16,,read lot example regarding doc vec find answer like real example want build model doc vec train ml model get vector raw string exact trained doc vec model need predict ml model size logical vector,,2018-02-06 22:20:19,load doc vec model get new sentence vector test,nlp word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15589,15589,48606331,2018-02-04 08:50:48,,new natural language processing list blog title example real data get point title want use lda python generate topic title assuming already cleaned tokenised text using nltk package removed stopwords end proceed convert text bag word corpus data look like model creation make use model generate list topic example eat visit etc title understand output might contain probability would like string together text,,2018-02-05 01:33:41,generate topic list title using lda python,python nlp nltk gensim lda,,,CC BY-SA 3.0,True,False,True,False,False
15595,15595,48690415,2018-02-08 16:35:04,,attempting load pre trained vector gensim model retrained new data understanding retraining however way find load vector creates object usually attribute model object doe method need retrain vector get vector actual model,2018-02-08 20:20:43,2018-02-08 20:20:43,load vector gensim word vec model keyedvectors,machine-learning nlp word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
15601,15601,48661163,2018-02-07 10:16:11,,want get similarity one document document use gensim program run correctly step exit segmentation fault code run normally get sims get sims using get following info program received signal sigsegv segmentation fault x fffd csr tocsc n row n col ap x eb aj x fc ec ax x bp xa f bi x f ee bx x f f scipy sparse sparsetools csr h scipy sparse sparsetools csr h,2018-02-08 06:30:03,2018-02-09 05:36:37,gensim similarity sparsematrixsimilarity get segmentation fault,python c++ segmentation-fault gensim,,,CC BY-SA 3.0,False,False,True,False,False
15617,15617,48623214,2018-02-05 13:01:28,,document processed got matrix exported file import environment run clustering getting error elki setting used,2018-02-06 09:42:32,2018-02-09 09:25:14,elki kmeans clustering task failed error high dimensional data,cluster-analysis k-means gensim doc2vec elki,,,CC BY-SA 3.0,False,False,True,False,False
15622,15622,48683025,2018-02-08 10:18:25,,question regarding concatenating two doc vec model followed official gensim imdb example implemented example data concatenating two model pv dm pv dbow outlined original paper wondered concatenated model appears dim like two input model dim input shape correct expected number dimension,,2018-02-08 13:21:14,concatenating two doc vec model vector dimension doubled,machine-learning concatenation word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15627,15627,48703067,2018-02-09 09:53:11,,build vocab extend old vocabulary example idea use doc vec train model build vocabulary datasets want extend need use build vocab use put gensim doc vec example,2020-01-28 20:23:07,2020-01-28 20:23:07,use build vocab gensim,nlp word2vec gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
15628,15628,48705138,2018-02-09 11:47:28,,noticed adding document gensim dictionary execution time jump reaching million word code quick example loop int add number dictionary iteraion get following output reaching million word reason doe anyone know bypass problem using dictionary big corpus tokenize bigram expecting dictionary million row many thanks,2018-02-09 12:10:13,2018-02-09 12:36:39,adding document gensim dictionary get slow reaching million word,python dictionary nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
15633,15633,48644212,2018-02-06 13:27:58,,trying save lda output dictionary word probability key value save dictionary json know achieve simply try save json kind binary format code tried far,2018-02-06 16:17:37,2018-02-06 16:17:37,make dictionary lda output save json,python json python-3.x gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
15637,15637,48717970,2018-02-10 06:32:46,,trying implement something similar http arxiv org pdf pdf using awesome gensim library however trouble improving quality result compare collaborative filtering two model one built apache spark one using gensim word vec grouplens million rating dataset apache spark model hosted aws http sparkmovierecommender u east elasticbeanstalk com running gensim model local however compare result see superior result cf model time like example similar searched movie affinity towards marvel movie e g search thor movie get result gensim captain america first avenger x men first class rise planet ape iron man x men origin wolverine green lantern super tron legacy transformer dark moon cf captain america first avenger iron man thor dark world iron man avenger x men first class iron man star trek captain america winter soldier model configuration far tried playing window min count size parameter much improvement help regard appreciated,2018-02-10 06:49:55,2018-02-14 01:53:07,gensim word vec recommender accuracy improvement,word2vec gensim recommendation-engine,,,CC BY-SA 3.0,False,False,True,False,False
15646,15646,48733918,2018-02-11 16:49:51,,trouble similar method gensim doc vec model run similar get similarity first tagged document based tag always code topn used topn len document still get similarity first document tagged document instantiate model train model problem think output length document training model sure returning similarity first document side question anyone experience better use word vec doc vec input document short word document thanks help,,2018-02-12 03:46:40,gensim doc vec similar,python nlp deep-learning gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15670,15670,48743444,2018-02-12 09:46:17,,doe term frequency saved doc use formula prob attribute tfidfmodel object following code getting seem find term frequency stored term frequency saved reason since already stored compute weight anyways way retrieve term frequency somehow fitting process,,2018-06-20 10:33:04,doe gensim model tfidfmodel term frequency saved,python nlp counter gensim tf-idf,,,CC BY-SA 3.0,False,False,True,False,False
15695,15695,48842866,2018-02-17 15:28:11,,using gensim python shown within image line getting following error,2018-02-17 18:52:31,2018-05-08 15:25:45,gensim model doc vec ha attribute labeledsentence,python-3.x sublimetext3 sentiment-analysis gensim,,,CC BY-SA 3.0,False,False,True,False,False
15704,15704,48749858,2018-02-12 15:27:30,,want train word vec using gensim large corpus data information co occurence two word data ha format word tab context word tab number e g danger meaning danger co occured time window size corpus line doe word vec gensim take input searched gensim tutorial havn seen example like thanks lot help li,,2018-02-14 01:40:34,use word context count pair input gensim word vec,word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15724,15724,48821863,2018-02-16 07:21:15,,already doc vec model trained train data want use doc vec test data want add test data vocabulary existing model vocabulary mean update vocabulary model,,2018-02-16 23:25:57,add new vocabulary existing doc vec model,word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15730,15730,48808989,2018-02-15 13:56:11,,size gb data size mb running code training process completion output model come mb,2018-02-17 15:17:34,2018-02-17 15:17:34,way retrain pretrained googlenews vector negative bin model data,python word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15733,15733,48898325,2018-02-21 04:45:14,,trying train new labelled document taggeddocument pre trained model pretrained model trained model document unique id label index instance good good good total size trained data want train pre trained model new document unique id label index instance bad bad bad total size trained data train wa successful without error problem whenever try use similar suggests similar document labelled good expect labelled bad train altogether beginning give answer expected infers newly given document similar either labelled good bad however practice work one trained altogether beginning continuing train working properly make mistake,2018-02-21 04:51:02,2018-02-21 19:08:43,gensim doc vec train document pre trained model,gensim doc2vec pre-trained-model resuming-training,,,CC BY-SA 3.0,False,False,True,False,False
15735,15735,48917449,2018-02-21 23:52:20,,converting w v file tsv file code result error added original open file piece counteract opposite issue tried adding vector row vector row encode utf work remedy,,2018-02-22 00:09:13,typeerror byte like object required str converting gensim tensorboard,python python-3.x typeerror gensim,,,CC BY-SA 3.0,False,False,True,False,False
15786,15786,48941648,2018-02-23 05:26:07,,given model e g possible remove word w v vocabulary e g similarity word deleting see word popping e g remove word completely word vec model gensim updated answer vumaasha comment could give detail want delete word let say universe word word corpus learn dense relation word want generate similar word come subset domain specific word possible generate enough filter word let say space specific domain small might looking word ranked th similar inefficient would better word totally removed word vector word return word outside specific domain,2018-02-23 06:17:40,2019-08-14 03:55:22,remove word completely word vec model gensim,python dictionary word2vec gensim del,,,CC BY-SA 3.0,False,False,True,False,False
15792,15792,49021389,2018-02-28 03:14:02,,used gensim fit doc vec model tagged document length training data target get doc vector training doc vector found model docvecs example training data length pre treatment tagged doc fit doc vec model get final model result tried datasets length got result question use model docvecs get full vector without using designed provide training docvecs,2018-02-28 13:39:00,2018-02-28 13:39:00,doc vec docvecs gensim doc vec model,machine-learning nlp word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15797,15797,48928739,2018-02-22 13:33:38,,set document df transforming document vector save model convert w v file tsv file finally overwrite metadata tsv file meaningful point two tsv file one contains vector contains metadata vector got point following tutorial http nbviewer jupyter org github rare technology gensim blob f c ff c f c dcf c doc notebook tensorboard visualization ipynb training doc vec model would like embed model tsv file local tensorboard tried code ran without error type go localhost location look like folder structure look like click choose file tensorboard projector choose note tensor tsv file say graph visualization failed graph empty make sure graph passed tf summary filewriter graph defined get tsv file show projector tsne pca visualization like tutorial linked earlier update tried adding two line added file also gave tensorboard tab however error fetching metadata tsv exist also looking log log instead log dismiss error click load choose note metadata tsv nothing happens,2018-02-22 13:58:37,2018-02-22 13:58:37,embedding gensim doc vec tensorboard,python tensorflow gensim tensorboard doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15802,15802,48962171,2018-02-24 11:10:57,,tried follow wasted lot time ending nothing useful want train model corpus mb corpus txt file downloaded file provided link compiled using editing demo sh file changed leave unchanged output wa cooccurrence bin cooccurrence shuf bin text corpus txt vector txt used file load model python,2020-01-27 06:21:12,2020-06-09 16:10:08,train glove algorithm corpus,nlp stanford-nlp gensim word2vec glove,,,CC BY-SA 4.0,False,False,True,True,False
15820,15820,48999199,2018-02-27 00:19:17,,bit new gensim right trying solve problem involves using doc vec embeddings kera able find existing implementation doc vec kera far see example found far everyone us gensim get document embeddings trained doc vec model gensim need export embeddings weight genim kera somehow really clear see supposedly give word vec embedding weight according unclear export document embeddings advise know general get embeddings document directly gensim model want fine tune embedding layer kera later since doc embeddings used part larger task hence might fine tuned bit,,2020-01-06 09:54:11,export gensim doc vec embeddings separate file use kera embedding layer later,keras gensim word-embedding doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15833,15833,48949166,2018-02-23 13:40:21,,using train model document assigned particular people million document people care people care specific group people say anywhere people interested could change day day never need look full population end goal resulting vector people interested currently training model time document assigned specific people train model million document train model document assigned people interested important train million document would get vector people interested,,2018-02-23 13:54:25,gensim doc vec training,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15835,15835,48968688,2018-02-24 23:25:23,,trained doc vec model five million document document tagged unique id idno loading model accessing specific subset vector based idno first load df database look like load model access three vector df create necessary file run load say point dimension loading enter chrome developer tool get error working wa set rather accessing specific vector pushing array happening,,2018-03-16 20:23:05,tensorboard uncaughttypeerror read property length undefined,python tensorflow gensim tensorboard,,,CC BY-SA 3.0,False,False,True,False,False
15839,15839,48934154,2018-02-22 17:53:38,,two different corpus want train model thought could something like would right,,2018-02-22 18:17:06,build vocaburay twice gensim word vec doc vec,python word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15847,15847,48914436,2018-02-21 19:59:24,,large sparse word embedding matrix trained sklearn tfidf ha nothing gensim word vec similar gensim word vec transfer learning non gensim model turn embeddings loaded panda dataframe gensim model however given matrix sparse would like store memore efficiently reload gensim keyedvecotrs create keyedvectors instance without saving sparse matrix directly save gensim word vec object thanks follow end successfully way however make xsparse word embedding matrix dense sure efficient way thanks answer,2018-02-21 21:01:13,2018-02-21 21:01:13,efficiently transform sparse word embedding matrix gensim keyedvectors object,python sparse-matrix word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,True
15854,15854,48990935,2018-02-26 14:36:55,,list word python programme need iterate list find semantically similar word put another list trying using gensim word vec could find proper solution implemeted need help iterate list word variable sentence find semantically similar word save another list,2018-02-27 10:44:10,2018-02-27 10:44:10,find semantic similarity using gensim word vec python,python machine-learning nlp word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
15870,15870,48953871,2018-02-23 18:08:41,,three document df document converted corpus tag typical practice semantically meaningless ints corpus used train model resulting vector model accessed like would tie original df resulting vector document trained vector identified one want query set vector author example want return set vector jane would think basic idea identify int tag correspond jane something like access would identify tag though meaningful model tagged document join back original df,2018-02-23 19:01:44,2018-02-23 19:49:19,gensim doc vec access vector document author,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15882,15882,49048758,2018-03-01 11:29:00,,text classification plan use word vec word embeddings pas conv layer text classification dataframe contains text corresponding label sentiment used gensim module used word vec algorithm generate word embedding model code used plan use cnn use word embedding model use word embedding model cnn input plan use something like obviously hyper parameter somebody help point right direction thanks advance,2018-03-01 15:16:15,2018-03-05 08:48:56,word vec conv text classification confusion,python keras conv-neural-network word2vec multiclass-classification,,,CC BY-SA 3.0,False,False,True,False,False
15883,15883,48994062,2018-02-26 17:37:19,,achieved far model read person need save model plain text use certain software requires model way tried following get know pas specific parameter,,2018-02-26 18:01:22,way save gensim doc vec model plain text txt,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15887,15887,48998064,2018-02-26 22:22:03,,text look follows error getting typeerror doc bow expects array unicode token input single string tried transform text list word avail also tried transform unicode avail python expert trying analyse text next step would check often token appears document called text using ipython notebook,2018-02-28 14:21:24,2018-02-28 14:21:24,gensim typeerror doc bow expects array unicode token input single string trying create mapping dictionary,ipython nltk,,,CC BY-SA 3.0,True,False,True,False,False
15889,15889,49088689,2018-03-03 20:05:07,,doe anyone know load tsv file embeddings generated starspace gensim gensim documentation seems use word vec lot find pertinent answer thanks amulya,2018-03-04 06:13:37,2018-06-30 13:48:21,load embeddings tsv file generated starspace,gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
15903,15903,49142365,2018-03-07 00:46:23,,built gensim doc vec model let call doc vec want find relevant word given document according doc vec model example document java tag doc java ask similar document get document programming language topic related java document model work well want find relevant word doc java follow solution closed question find similar term word document doc vec give seemingly random word word java even among first similar word also tried like change anything find similar word given document,2018-03-07 00:56:19,2018-03-19 18:35:21,get similar word document gensim doc vec,word2vec gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15943,15943,49128847,2018-03-06 10:41:27,,suppose data trained sentence stream try bigram model test data check output suppose want add custom bigram like mayor bigram model output contain suggestion configure bigram model,,2018-03-06 10:41:27,configure bigram model gensim include custom bigram,python-3.x gensim,,,CC BY-SA 3.0,False,False,True,False,False
15965,15965,49205736,2018-03-10 05:37:03,,application comparing similarity one document document want find similar document gensim done efficiently using matrixsimilarity method spacy documentation example comparing multiple document however many document loop efficient implementation someone could please suggest efficient way compare one document others spacy would much appreciated believe may involve using pipeline sure use note example documentation seems issue idea get around issue also welcome,2018-03-10 14:43:52,2018-03-11 09:37:22,spacy efficiently compare similarity one document others,performance gensim spacy,,,CC BY-SA 3.0,False,True,True,False,False
15978,15978,49155392,2018-03-07 15:19:24,,train doc vec using gensim doc vec python corpus k document ha hundred word infer document vector using document similar trained document vector would expect would least somewhat similar cosine distance trained inferred vector first document see really similar similarity terrible even document used training even begin try infer unseen document training configuration inferring note side document always preprocessed way checked list token go training inferring also played parameter around bit result similar suggestion would something like try increasing decreasing training parameter likely tried maybe come across correct parameter though thanks suggestion make work better edit willing able use available python implementation paragraph vector doc vec one know another achieve better result edit minimal working example,2018-03-08 16:41:54,2018-03-08 16:41:54,gensim doc vec inferred vector similar,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
15992,15992,49229336,2018-03-12 06:34:35,,trying train word embeddings word vec dataset using gensim library alp list list containing token individual sentence corpus get following error whenever try train w v model please help,,2018-03-12 09:21:16,trouble running gensim word vec,word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
16010,16010,49210010,2018-03-10 14:10:15,,want add new word trained gensim word vec model using new text dataset however want preserve old word embeddings add new word dataset existing model mean simple retraining old model new text dataset option readjust vector previous word embeddings also new text dataset give suggestion regarding task would like something like gensim doc vec infer feature feed model text input give vector output thanks,,2019-09-03 20:53:51,infer new word vector gensim word vec model,neural-network word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
16036,16036,49230376,2018-03-12 07:50:42,,trained model preprocessed corpus forget save preprocessed data wa form list list possible recover data trained model,2018-03-18 22:14:54,2018-03-18 22:14:54,possible extract bow gensim lda model,dataset gensim,,,CC BY-SA 3.0,False,False,True,False,False
16043,16043,49183643,2018-03-08 22:36:26,,working large dataset yelp review machine learning research project gensim ha worked well far however build vocabulary document index appear collected key dictionary certainly case script made tagging document building vocabulary training model saving model loading model length tag using building vocabulary user id necessarily unique thousand user also tag appear single character expected wrong,,2018-03-09 01:16:54,gensim docvecs doctags incorrect index,python gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
16050,16050,49202413,2018-03-09 21:29:55,,set environment anaconda running gensim working great today updated gensim package environment get following error terminal window jupyter notebook kernel dy restarted try import gensim say module found figure start went wrong writing code week everything ha hunky dory updated clue code never executed image find complete terminal output failed session,,2018-05-15 22:06:17,updated environment anaconda kernel dy code never executed,python-3.x image kernel anaconda gensim,,,CC BY-SA 3.0,False,False,True,False,False
16097,16097,49274321,2018-03-14 09:43:55,,using word vec word embeddings want project word w axis represent similarity word w two given word w w way see word w similiar like image best way,2018-03-14 13:13:09,2018-03-14 13:13:09,project word axis similarity word,vector data-visualization word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
16109,16109,49262453,2018-03-13 17:35:03,,possible leverage pretrained model e g glove use train corpus example helpful,,2018-03-13 17:35:03,use pretrained model train current corpus,nlp word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
16118,16118,49279990,2018-03-14 14:14:05,,trying use gensim ironpython installing package seems impossible tried ironpython following command doe anyone know possible use gensim package ironpython otherwise switch part net application cpython gensim working thanks advance,2018-03-14 14:18:10,2018-03-14 14:18:10,install gensim ironpython,c# python pip ironpython gensim,,,CC BY-SA 3.0,False,False,True,False,False
16127,16127,49313542,2018-03-16 05:05:14,,trained lda model url containing article particular topic python predict new corpus based trained model,2018-03-16 05:16:29,2019-12-08 13:31:52,predict new corpus using trained lda model,python-3.6 gensim lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
16133,16133,49414962,2018-03-21 19:23:05,,attempting train encoding text using gensim run text iteration document word long gensim training frequent word summed training loss iteration reduces time said plotted clear training ended early training would reduce loss however load back saved model run training training appears start scratch initial training error reduces back saving model saved model appears least partially trained word vector similarity seem somewhat reasonable want train encoding working note initially training encoding time ie improve loss start end reducing initial alpha min alpha extended period doe help either initial training run,,2018-03-21 19:23:05,gensim resume training starting training scratch,gensim,,,CC BY-SA 3.0,False,False,True,False,False
16164,16164,49380138,2018-03-20 09:11:53,,made word embedding code want calculate similarity two word see neighbour difference one use,2018-05-30 10:51:19,2018-05-30 10:51:19,word vec python similarity,python similarity word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
16165,16165,49380258,2018-03-20 09:17:00,,tried text clustering using lda giving distinct cluster code problem overlapping element cluster tend present cluster also tried increase threshold manually however giving issue,2018-03-21 11:17:54,2018-03-21 11:17:54,inefficiency topic modelling text clustering,python cluster-analysis gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
16171,16171,49402113,2018-03-21 09:08:39,,first harry potter book txt format created two new txt file first occurrencies replaced second occurrencies replaced concatenated text create one long text used input word vec code possible give different output neighbour completely different output four print,2018-03-21 09:21:47,2018-03-21 09:51:06,gensim word vec similar different result python,python string word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
16201,16201,49478142,2018-03-25 16:30:27,,trained saved model doc vec colab model saved folder accessible drive see output move two file shared directory notebook problem facing two gensim creates two file saving model one load try load file able load model getting error suggestion,,2018-03-26 05:24:35,load saved doc vec model colab,python gensim google-colaboratory doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
16204,16204,49384123,2018-03-20 12:22:12,,changed code word vec py receive error line arrow pointed understand operand concatenating int str within str method using anaconda environment thats matter python,,2018-09-07 07:12:05,gensim word vec unsupported operand type int str,python word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
16214,16214,49428431,2018-03-22 12:13:42,,using gensim word vec return similar text corpus matching query text instance relevant line code start thing simple function run instance passed multiprocessor batch multiprocessing script actually happens run run batch fine batch account text processed set text looping get th batch text appears simply stop processing doe fail quit crash anything visually look like still running cpu activity go back progress bar stop moving visually inspected text processed set nothing looked weird ran get similar given text function text isolation outside multiprocessing function completed fine anyway reiterate always happens batch doe anyone insight familiar multiprocessing work thanks,,2018-03-22 14:48:08,multiprocessing batch suddenly halt python,python multiprocessing word2vec,,,CC BY-SA 3.0,False,False,True,False,False
16217,16217,49388929,2018-03-20 16:02:47,,new stackoverflow python please bear trying run latent dirichlet analysis text corpus gensim package python using pycharm editor prepared corpus r exported csv file using r command creates following csv structure though much longer already preprocessed text try following essential python code based gensim tutorial perform simple lda analysis get following error code code exit python venv lib site package setuptools py egg pkg resource vendor pyparsing py deprecationwarning invalid escape sequence python venv lib site package setuptools py egg pkg resource vendor pyparsing py deprecationwarning invalid escape sequence python venv lib site package setuptools py egg pkg resource vendor pyparsing py deprecationwarning invalid escape sequence g python venv lib site package pyldavis prepare py deprecationwarning ix deprecated please use loc label based indexing iloc positional indexing find solution honest neither clue exactly problem come spent hour making sure encoding csv utf exported r imported python correctly wrong else could look cheer,2020-06-20 09:12:55,2018-03-21 09:33:25,python lda gensim deprecationwarning invalid escape sequence,r python-3.x export-to-csv gensim deprecation-warning,,,CC BY-SA 3.0,False,False,True,False,False
16222,16222,49429971,2018-03-22 13:29:27,,new gensim trying load given pre trained word vec model file xxxx model wv bigger one xxxx model wv syn npy call following line get following error solve error,2018-03-22 15:07:41,2020-09-15 01:42:30,load word vec gensim without getting attributeerror,python word2vec gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
16224,16224,49431270,2018-03-22 14:29:51,,building python gensim word vec model way see doc word matrix input see something like illustrated human readable looking scipy matrix indexed transformed word word matrix see co occurences something like already implemented something like word word co occurrence matrix using countvectorizer work well however already using gensim pipeline speed code simplicity matter use case,,2018-03-31 14:54:35,word co occurrence matrix gensim,python nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
16238,16238,49410113,2018-03-21 15:16:47,,following code made sure extension name correct however still get error outputted seen see another person asked similar question stack overflow read answer help failed load bin gz pre trained word vecx suggestion fix input output,,2020-06-19 12:49:05,oserror gzipped file b python,python word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
16245,16245,49339461,2018-03-17 16:53:25,,want word embedding using lda represent document corpus vector dimension show one detected topic lda model know suggestion appreciated use python gensim library lda,,2018-03-17 16:53:25,using lda word embedding,machine-learning gensim lda topic-modeling word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
16258,16258,49391597,2018-03-20 18:22:22,,command model similar positive france topn give top similar word france however would like know method output similar word similarity threshold given word method like following model similar positive france threshold,2018-03-21 00:59:14,2019-11-26 12:43:27,applying word vec find word similarity threshold,word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
16271,16271,49470302,2018-03-24 21:49:25,,want build model classification news specific categorize imagine put selected train paper specific label category word vec training generate model wonder doe possible try small example build vocab gensim keep telling word exist vocab confuse wonder anyone idea know build beginning dataset help maybe documentation good read doc http radimrehurek com gensim model word vec html follow like keep telling loop exist vocabulary word vec build,,2018-03-24 21:49:25,documentation topic classification using word vec,python classification text-mining word2vec,,,CC BY-SA 3.0,False,False,True,False,False
16272,16272,49471037,2018-03-24 23:30:57,,training word vec model corpus querying model work fine running experiment need call model different condition save model condition query model condition save output query csv file say analysis condition studied gensim documentation searched around figure asked gensim folk said since result similar python object save pickle save txt csv whatever format want sound great clue start code could help fill blank even something simple research expand,2018-03-25 01:41:40,2020-07-30 09:51:14,save result word vec model query csv file,python csv word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
16293,16293,49564330,2018-03-29 20:15:54,,currently working document applying gensim lda training part process seems take forever get model tried use multicore function well seems working ran whole almost day still get lda model checked feature data code read question gensim ldamulticore multiprocessing still get solution config check blas sure installed proper one one thing struggled use command apt get install package mac installed xcode still give error poor understanding use shardedcorpus python dictionary corpus help appreciated slept day figure problem thanks,,2018-03-30 14:28:54,extremely slow lda training model large corpus python gensim,python machine-learning multiprocessing gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
16307,16307,49514111,2018-03-27 13:24:37,,trained lda model using gensim library using extract topic vector document using following code call follows exact piece code wa working wa using python updated system python x throwing following error wrong,2018-03-27 13:39:46,2018-03-28 06:58:53,typeerror supported instance float nonetype,python gensim lda,,,CC BY-SA 3.0,False,False,True,False,False
16312,16312,49526981,2018-03-28 05:48:00,,using gibberish review data train doc vec model gensim face error st taggeddocument take argument unable pas field nd argument resort simple character order proceed nd reach near end code loop get following error valueerror must specify either total example total word proper job parameter updationand progress calculation usual value total example model corpus count,,2018-03-30 11:22:15,doc vec gensim using csv,python nlp data-science gensim,,,CC BY-SA 3.0,False,False,True,False,False
16316,16316,49350340,2018-03-18 16:37:29,,currently working project trying create sentiment analysis news article german news outlet rougly article different site using word vec current approach dumping article text file one per news outlet feeding resulting text corpus model one per news outlet word vector using data set positive negative german word weight indicating sentiment create sentiment score word article using similarity function gensim word vec provides creating average score number news article included training data problem sure word select analysis could either use every word article maybe filter relevant word create score think valid good approach maybe idea better approach would,,2018-03-18 16:37:29,sentiment analysis news article using word vec,python sentiment-analysis word2vec,,,CC BY-SA 3.0,False,False,True,False,False
16327,16327,49527668,2018-03-28 06:36:26,,converting list text document corpus dictionary converting bag word model using find index value particular word dictionary using way find word stored dictionary particular index,,2018-03-31 09:14:46,understanding word stored dictionary gensim corpus using gensim corpus dictionary text,python gensim corpus,,,CC BY-SA 3.0,False,False,True,False,False
16331,16331,49585674,2018-03-31 08:07:33,,need little help diagnosing problem experiencing text vector process actually trying apply doc vec word embedding obtain vector classification task run code get error ha quite difficult figure pretty new code output running model tried extract vector output get anything wrong,2018-03-31 08:07:59,2018-03-31 16:39:21,tag text seen training corpus invalid,python python-3.x gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
16338,16338,49532089,2018-03-28 10:27:08,,using gensim lda topic modeling work data wa pretreated people gave two thing mmcorpus file imported function dictionary file imported function created lda model successfully adjusted superparameter alpha drew visualized chart like wa confused several tall bar found strange word like interestingly letter b seen appears man gave data said letter b may generated automatically converted data byte type know erase b neither delete b mmcorpus file dictionary file please,,2018-04-12 16:47:54,remove word lda analysis gensim,python text-mining gensim lda stop-words,,,CC BY-SA 3.0,False,False,True,False,False
16354,16354,49643974,2018-04-04 06:10:35,,want perform text classification using word vec got vector word output perform classification product non product,,2020-10-03 09:56:02,text classification using word vec,python-3.x word2vec gensim text-classification,,,CC BY-SA 3.0,False,False,True,False,False
16358,16358,49628691,2018-04-03 11:15:01,,trying load already trained word vec model downloaded using following code suggested aforementioned website try execute code get following error suppose due fact model ha probably trained previous version gensim would prefer avoid retrain solve problem thanks,,2018-04-03 11:15:01,gensim word vec object ha attribute vector size loading file,python-3.x word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
16366,16366,49681525,2018-04-05 21:06:37,,around document trained using gensim doc vec class need docvecs model perform kmeans clstering maximum docvecs able get idea get code snippet,,2018-04-06 08:57:47,get docvecs model,python k-means gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
16376,16376,49631758,2018-04-03 13:47:23,,struggling doc vec see wrong text file sentence want know given sentence closest sentence find file code model creation test purpose file test matter parameter training obviously tell similar sentence th one sent sent know index work sentence label form result missing try sentence like dog sent really get low number run time row load get result either thanks help,2018-04-03 13:57:17,2018-04-03 17:22:25,gensim doc vec similar method working expected,python nlp gensim doc2vec sentence-similarity,,,CC BY-SA 3.0,False,False,True,False,False
16405,16405,49635325,2018-04-03 16:50:21,,would like tag list document pas document input read documentation understood exactly parameter tried get error,,2018-04-03 17:10:18,properly tag list documenta gensim taggeddocument,nlp gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
16410,16410,49676060,2018-04-05 15:21:59,,creating chatbot need word vec file binary format loading bin file getting type error,2018-04-05 15:39:30,2018-04-06 12:53:58,unpicklingerror invalid load key,python-3.x word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
16427,16427,49710537,2018-04-07 18:21:06,,want load pre trained word vec embedding gensim pytorch embedding layer question get embedding weight loaded gensim pytorch embedding layer thanks advance,2018-08-10 12:26:52,2020-04-03 08:18:38,pytorch gensim load pre trained word embeddings,python neural-network pytorch gensim embedding,,,CC BY-SA 3.0,False,False,True,False,False
16432,16432,49784513,2018-04-11 21:09:56,,looked suggestion everyone say break string token split function ha done already still seems error give error output token variable seems like please help,,2018-04-11 21:09:56,typeerror doc bow expects array unicode token input single string,python tokenize gensim corpus,2018-04-13 09:56:11,,CC BY-SA 3.0,False,False,True,False,False
16470,16470,49699065,2018-04-06 18:33:14,,recieving following error calling gensim model word vec corpus object iteratable corpus defined like subclass xmldataset contains static method instance xmldataset passed corpus could issue edit dictionary updated like gensim called dataset iterate corpus print element get output needed train model like,2018-04-11 23:15:49,2018-04-11 23:15:49,gensim typeerror concatenate tuple str tuple,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
16471,16471,49767270,2018-04-11 05:37:30,,niche corpus k doc want test near duplicate document similar meaning across think article event covered different news organisation tried gensim word vec give terrible similarity score within corpus tried spacy give k document similarity tested spacy similar document wa mostly useless relevant code using gensim found decent approach preprocessing similarity score still quite low ha anyone faced problem resource suggestion could useful,2018-04-11 05:44:36,2018-04-12 17:09:17,document similarity spacy v word vec,python-3.x nlp gensim spacy,,,CC BY-SA 3.0,False,True,True,False,False
16473,16473,49768453,2018-04-11 06:58:06,,name employee saved text file processed file compared name already exist checked using similar method found return totally unrelated name even exact name exist corpus correctly train data return closely matching name,,2018-04-11 09:46:18,using model compare name surname,machine-learning gensim,,,CC BY-SA 3.0,False,False,True,False,False
16478,16478,49829787,2018-04-14 09:10:00,,created model mongodb db news tagged document mongo collection id created model using model code output id related aa b eeb proplem,,2018-04-14 23:14:25,gensim model return id related input doc vec,word2vec gensim cosine-similarity doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
16490,16490,49811018,2018-04-13 06:56:51,,two separate data set one resume demand using gensim doc vec created model able query similar word data set need merge two model one query resume demand attain similarity matching data set plain txt file two resume demand separated please find implementation suggestion would highly appreciated thanks,2018-04-13 09:06:24,2018-04-13 09:06:24,matching two separate document using gensim doc vec,gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
16502,16502,49847602,2018-04-15 22:59:31,,wa wondering limited google word vec vocabulary google word vec link http drive google com file b xkcwpi kdynlnuttlss pqmm edit usp sharing vocabulary list unique word corpus feel embedding matrix word vocabulary addition would like flexibility word doe exist google word vec filled zero thanks,,2018-04-16 09:24:37,adjust google word vec loaded gensim vocabulary create embedding vector,python word2vec gensim embedding,,,CC BY-SA 3.0,False,False,True,False,False
16509,16509,49867648,2018-04-16 23:29:15,,trying use gensim phrase library identify phrase text used following get error latest gensim package idea recognizing common term parameter,,2018-04-17 00:04:43,genism phrase library accepting common term,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
16517,16517,49750112,2018-04-10 09:30:19,,text file precomputed word vector following format example line every word extra float place trying load gensim keyedvectors ultimately would like compute cosine similarity find similar word etc unfortunately worked gensim documentation quite clear tried following found however give following error first word text file suspect loading function expecting something find information would highly appreciate pointer information solution problem thanks,,2018-04-10 09:40:47,gensim load precomputed word vector text file,python python-3.x nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
16527,16527,49761033,2018-04-10 18:53:50,,seem getting correct result last step array result keep coming back empty trying follow tutorial compare set note http www oreilly com learning compare document similarity using python far output seems right continue output get output,,2018-04-17 12:19:20,gensim similarity docsim similarity return empty queried,python-3.x nltk jupyter-notebook gensim,,,CC BY-SA 3.0,True,False,True,False,False
16541,16541,49891527,2018-04-18 05:02:29,,wa trouble similar call fasttext model understanding fasttext able obtain result word vocabulary getting vocabulary error even prior saving loading call wa perfectly fine code juypter return far good save model load exact similar call model loaded result idea wrong,,2018-07-23 13:47:21,gensim fasttext keyerror word vocabulary,gensim fasttext,,,CC BY-SA 3.0,False,False,True,False,False
16549,16549,49800622,2018-04-12 15:36:01,,running latest version python upon trying import gensim like get following error tried updating python package dependency nothing seems working thought,,2019-02-28 18:37:08,python importerror import name config trying import gensim,python jupyter boto gensim,,,CC BY-SA 3.0,False,False,True,False,False
16556,16556,49926774,2018-04-19 17:19:54,,using python trying repeat code implemented video moment http youtu bkeqzjt f piece code typeerror slice index must integer none index method happening fix get output w v like video,2018-04-19 17:56:53,2018-04-19 18:06:58,gensim word vec model wv index word typeerror slice index must integer none index method enumerate,python-3.x word2vec gensim tensorboard enumerate,,,CC BY-SA 3.0,False,False,True,False,False
16558,16558,49929066,2018-04-19 19:44:29,,looking good approach using python library tackle following problem dataset column ha product description value column messy would lot word related product want know row product would need tag description sentence main topic example following unit shoe green sport tennis import oversea plastic would like tag something like shoe sport looking build approach semantic tagging sentence part speech tagging assume labeled tagged data training help would appreciated,,2018-04-20 07:03:35,clear approach assigning semantic tag sentence short document python,python-2.7 nlp nltk gensim semantic-analysis,,,CC BY-SA 3.0,True,False,True,False,False
16583,16583,49929170,2018-04-19 19:52:08,,following line work fine following line generates error error wa working converting glove word vec format glove word vec,,2018-04-19 19:52:08,import gensim v import gensim test utils,python gensim word-embedding,,,CC BY-SA 3.0,False,False,True,False,False
16604,16604,50009030,2018-04-24 18:58:29,,correct way use gensim phrase preprocess string together way little contrived result part code wa taken extract phrase corpus using gensim,2020-09-24 08:09:27,2020-09-24 08:09:27,correct way using phrase preprocess string gensim,python python-3.x nlp gensim,,,CC BY-SA 3.0,False,False,True,False,False
16607,16607,49919642,2018-04-19 11:10:45,,error screen import nltk importerror import name raise unorderable type already checked show error import nltk already reinstalled nltk using pip install nltk upgrade try command line level nltk command like nltk download still throw error unable resolve checked dist package python ha nltk checked trying import package dist package like gensim work python version ipython shell version,2018-04-19 12:54:41,2018-04-19 12:54:41,error importing nltk,python import nltk,,,CC BY-SA 3.0,True,False,True,False,False
16631,16631,50033595,2018-04-26 01:39:21,,trying understand lda used text retrieval currently using gensim ldamodel model implementing lda http radimrehurek com gensim model ldamodel html managed identify k topic used word understand lda probabilistic distribution topic word distributed within topic document much make sense said understand use ldamodel retrieve document relevant string input search query eg negative effect birth control tried inferring topic distribution search query finding similarity topic distribution search query topic distribution corpus using gensim similarity matrixsimilarity compute cosine similarity like performance really good figure finding topic distribution search query meaningful usually topic search query know else could implement ldamodel gensim advice would really appreciated new topic modeling maybe missing something glaringly obvious thanks,,2019-09-02 08:41:32,use gensim lda conduct text retrieval query,gensim information-retrieval lda topic-modeling,,,CC BY-SA 3.0,False,False,True,False,False
16634,16634,50046643,2018-04-26 15:18:50,,like use reticulate package run gensim r sure fully understand syntax reticulate get work default function setting fails try pas argument word vec gensim pre trained model include large file pick fav pre trained model think issue providing additional args python function edit figured look like r python communication handle number expected work,2018-04-26 16:40:55,2018-04-27 15:15:56,run python gensim function r reticulate,python r gensim reticulate,,,CC BY-SA 3.0,False,False,True,False,False
16635,16635,50048484,2018-04-26 17:03:20,,trying join list appended sentence large string text object use input gensim summarize module however try say input sentence le run split text see multiple sentence count sentence instead total sentence together variable r string type object would like concatenate sentence together one large string read gensim summarize module sample code sample output example input want summarize gensim summarizer number underneath string represent count sentence ending period,2018-04-26 21:17:03,2018-04-27 13:31:50,joining sentence list python,python regex list join gensim,,,CC BY-SA 3.0,False,False,True,False,False
16638,16638,49962749,2018-04-22 05:18:53,,trying train doc vec model using gensim library million sentence variable length tutorial eg http github com rare technology gensim blob develop doc notebook doc vec lee ipynb step actual training process part ha running hour without update step necessary training process could step taking long since linear pas data using gensim version python,,2018-04-26 06:33:49,gensim build vocab taking long,python-3.x nlp word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
16661,16661,50038347,2018-04-26 08:31:46,,learning doc vec library got stuck following question gensim doc vec distinguish sentence positive negative context example sentence love machine learning sentence b love machine learning train sentence b doc vec find cosine similarity vector model able distinguish sentence give cosine similarity le negative model represent sentence close vector space give cosine similarity close mostly word except negative word also train sentence try infer sentence b vector close vector space would request nlp community doc vec expert helping understanding thanks advance,2018-04-26 08:39:38,2018-04-26 16:49:05,gensim doc vec distinguish sentence positive negative context,python nlp gensim doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
16669,16669,49984763,2018-04-23 15:30:02,,apologise advance reproduce dataset working going describe step hope someone familiar whole process trying use lda gensim extract topic list text document build list list cleaned token text like initiate model like print topic term important make sense seems working fine struggle plot document cluster using bokeh really need bokeh compare plot different model know reduce dimensionality try using countvectorizer sne get error definitely something wrong countvectorizer could anyone help,2018-04-23 16:42:25,2018-04-23 16:42:25,plot cluster lda gensim bokeh,python-3.x vectorization gensim dimensionality-reduction,,,CC BY-SA 3.0,False,False,True,False,False
16671,16671,50038358,2018-04-26 08:32:17,,best way visualize word vec model using tensorflow embedding projector way export word vec model vector format embedding projector expects built function tensorflow thanks,,2019-05-07 18:07:39,visualize word vec model using embedding projector,tensorflow nlp data-visualization word2vec gensim,,,CC BY-SA 3.0,False,False,True,False,False
16674,16674,50084316,2018-04-29 07:25:27,,trying install gensim package python using pip using work start downloading get following error help would appreciated,2018-04-29 08:02:00,2018-04-30 06:29:21,error downloading gensim package python,python gensim,,,CC BY-SA 3.0,False,False,True,False,False
16685,16685,50089525,2018-04-29 17:42:20,,training document embeddings million sentence using parallel processing gensim creating model training following code epoch logging information show training get stuck waiting worker thread note logging information say epoch training loop stuck several hour similar output previous run logging stopped,2018-05-02 18:30:17,2018-11-07 01:46:56,gensim worker thread stuck,python nlp word2vec gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
16689,16689,50146901,2018-05-03 04:19:39,,code like corpus file ha processd list token linesentence gensim like get error token vocabulary others get word vector know reason,,2018-06-24 17:26:21,keyerror word vocabulary use gensim word vec process chinese token,python nlp word2vec gensim keyerror,,,CC BY-SA 4.0,False,False,True,False,False
16706,16706,50076131,2018-04-28 11:39:03,,trying check semantic syntactic performance doc vec model doesnt seem function since model deprecated doc vec deep learning paragraph vec say ha deprecated since version gensim package give error message though work word vec model well way get done apart impossible,,2018-04-28 20:04:37,semantic syntactic performance doc vec model,python-3.x word-embedding doc2vec,,,CC BY-SA 3.0,False,False,True,False,False
16730,16730,50117021,2018-05-01 13:06:14,,new fasttext library efficient learning word representation sentence classification trying generate word vector huge data set single process taking significantly long time let put question clearly option use speedup single fasttext process way generate word vector parallel fasttext process implementation workaround available solve problem read caffe implementation available unable find thanks,2018-05-01 17:04:42,2018-05-01 17:04:42,way use fasttext word representation process parallel,nlp word2vec gensim fasttext caffe2,,,CC BY-SA 3.0,False,False,True,False,False
16758,16758,50191231,2018-05-05 15:44:52,,loaded pre trained word vec model gensim toolkit would like find synonym word given context intelligent bright person,2018-11-15 22:04:04,2018-11-15 22:04:04,find synonym word multi word paraphrase using gensim toolkit,python nlp word2vec gensim word-sense-disambiguation,,,CC BY-SA 4.0,False,False,True,False,False
16768,16768,50118868,2018-05-01 15:04:33,,running lda code appears statement user user anaconda lib python site package gensim model ldamodel py runtimewarning overflow encountered exp expelogthetad np exp elogthetad lda model function used follow may know solution,,2018-12-10 23:20:54,runtimewarning overflow encountered exp lda,python lda,,,CC BY-SA 3.0,False,False,True,False,False
16774,16774,50212449,2018-05-07 10:50:07,,try map sentence vector order make sentence comparable test gensim doc vec model downloaded sklearn newsgroup dataset trained model order compare two sentence use model infer vector wondering two call using sentence delivers different vector output training epoch training epoch training epoch training epoch training epoch training epoch training epoch training epoch training epoch training epoch set alpha min alpha get consistent vector feel fine feel good model give vector every epoch doe seem learn anything training epoch training epoch training epoch training epoch training epoch training epoch training epoch training epoch training epoch training epoch question even possibility specify learning rate inference would expect model changed training inference specify alpha inference doe distance two vector change different epoch,2020-06-20 09:12:55,2018-05-07 18:20:02,gensim doc vec doe infer vector use alpha,gensim embedding sentence doc2vec,,,CC BY-SA 4.0,False,False,True,False,True
16776,16776,50213754,2018-05-07 12:01:11,,working something using gensim gensim var usually mean object first use save index file load default save index shard file like index file becoming larger automatically seperate shard like load shard file load one file btw try find answer gensim doc failed,,2019-11-04 15:50:00,load index shard gensim similarity similarity,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
16779,16779,50195948,2018-05-06 03:17:06,,word vec currently trying perform text classification text corpus order decided perform help order code sentence basically class handle file get vocabulary model ha created line output sample dictionary vocabulary contains word string object want able query index particular word order make training data like represents index word within vocabulary label represents class corpus solution experimenting utility give nice dictionary word corpus vocabulary one created function mentioned,,2018-05-07 06:36:10,trying get key particular word word vec vocabulary,python dictionary nlp word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
16782,16782,50227208,2018-05-08 06:26:16,,using http github com dav word vec built word vec embedding use output python gensim word vec vectorsfile txt vocabuloryfile txt corpus txt please,,2018-05-08 06:26:16,converting word vec embedding c python gensim word vec,python c tensorflow word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
16791,16791,50161445,2018-05-03 18:11:44,,trained fasttext model gensim want use encode sentence specifically want use feature native fasttext save model gensim correct binary format understood native fasttext using fasttext gensim python essence need inverse load binary data given gensim fasttext doc,2018-05-04 04:41:01,2018-05-05 15:43:05,load gensim fasttext model native fasttext,gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
16800,16800,50198409,2018-05-06 09:55:21,,working sentiment analysis amazon food review trying apply word vec review visualise using sne wa easily able visualise using bag word representation using following code also code work feed w v model model type gensim model word vec word vec obtained model using following code,,2019-12-07 16:44:20,apply sne word vec model,python-3.x machine-learning deep-learning nltk amazon-machine-learning,,,CC BY-SA 4.0,True,False,True,False,False
16801,16801,50214899,2018-05-07 13:02:05,,facing following error trying update gensim ldamodel indexerror index bound axis size checked people issue thread using dictionary beginning end wa error big dataset loading chunk chunk using pickle load building dictionary way iteratively thanks piece code built whole dataset training model fashion iteratively way also tried updating dictionary every chunk e right last piece code finally tried setting allow update argument doc bow true nothing work fyi size final dictionary k size dictionary built first chunk k error occurs second iteration pass else condition calling update method error raised line called called called anyone idea fix happening thank advance,,2020-06-24 07:55:06,indexerror trying update gensim ldamodel,python-3.x gensim lda topic-modeling index-error,,,CC BY-SA 4.0,False,False,True,False,False
16834,16834,50253681,2018-05-09 12:40:01,,working word embedding project using amazon sagemaker purpose blazingtext algorithm amazon sagemaker produced fast result option see facility get prediction model weight output consists vector file generate model way get model vector file need predict new word thanks advance,2018-05-09 12:44:23,2019-09-10 08:52:20,amazon sagemaker blazingtext,amazon-web-services nlp word2vec gensim amazon-sagemaker,,,CC BY-SA 4.0,False,False,True,False,False
16841,16841,50275623,2018-05-10 14:44:57,,wa confused result similar similar vector gensim word veckeyedvectors supposed calculate cosine similarity way however running one word give identical result example model similar obama similar vector model obama give equation give give noticable difference cosine distance word queen monarch etc wondering thanks,,2018-05-10 16:32:01,difference similar similar vector gensim word vec,nlp word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
16854,16854,50237247,2018-05-08 15:28:24,,get error load google pre trained word vec train doc vec model data part code got error doc vec object ha attribute intersect word vec format help error get google model http amazonaws com dl j distribution googlenews vector negative bin gz gensim latest version think,2018-05-08 17:53:42,2018-05-08 17:53:42,gensim doc vec object ha attribute intersect word vec format load google pre trained word vec model,word2vec gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
16859,16859,50278744,2018-05-10 17:52:21,,currently following script help find best model doc vec model work like first train model based given parameter test classifier finally output best model classifier hope data example data data csv downloaded http pastebin com takyp note data ha structure make ideal classifier accuracy script following question regarding script combine avoid three post code snippet purpose possibly remove part somehow tried unsuccessfully add classifier others gridsearch workflow pipeline could train test data split added code current script train full dataset,2019-01-31 19:00:03,2019-01-31 19:00:03,pipeline gridsearch doc vec,scikit-learn pipeline gensim grid-search,,,CC BY-SA 4.0,False,False,True,False,True
16861,16861,50328915,2018-05-14 11:13:01,,wan na use lda gensim topic modeling thousand document therefore using csv file input format term document matrix currently occurs error running following code error following using module correctly mistake thanks advance,,2018-05-21 06:07:51,csv input gensim lda via corpus csvcorpus,python-3.x csv gensim lda corpus,,,CC BY-SA 4.0,False,False,True,False,False
16878,16878,50370240,2018-05-16 11:53:32,,got hold google word vec model quite new concept trying extract main feature paragraph using following method getting following error say paragraph checked word vocabulary keyerror word republic ghana country west africa border c te ivoire also known ivory coast west burkina faso north togo east gulf guinea south word ghana mean warrior king jackson john g introduction african civilization page wa source name guinea via french guinoye used refer west african coast gulf guinea vocabulary aware function expects single array would like know translated extract one main feature word display main concept paragraph using word vec model modified modified code pas word array method getting following error traceback recent call last file home manuelanayantarajeyaraj pycharmprojects chatbotword vec new approach py line print model wv similar positive word array topn file home manuelanayantarajeyaraj usr myproject project lib python site package gensim model keyedvectors py line similar word weight positive negative valueerror many value unpack expected modified implementation suggestion regard much appreciated,2018-05-18 05:54:39,2018-05-21 04:44:34,extract main feature paragraph using word vec,python word2vec feature-extraction,,,CC BY-SA 4.0,False,False,True,False,False
16885,16885,50352777,2018-05-15 14:27:28,,want train lstm model tensorflow text data input get doc vec paragraph text pas lstm layer get valueerror inconsistency shape rank searched stackoverflow similar question tutorial solve error idea error traceback recent call last file writernn py line output final state tf nn dynamic rnn cell embed initial state initial state file myven lib python site package tensorflow python ops rnn py line dynamic rnn dtype dtype file myven lib python site package tensorflow python ops rnn py line dynamic rnn loop input flat input file myven lib python site package tensorflow python ops rnn py line input flat input file myven lib python site package tensorflow python framework tensor shape py line rank least raise valueerror shape must rank least self rank valueerror shape must rank least code got error output final state tf nn dynamic rnn cell input initial state initial state line error described doc vec model trained gensim convert sentence vector value tried change input shape label shape also get error really know really thank could answer question,2018-05-15 14:32:58,2018-05-15 20:01:46,shape valueerror lstm network using tensorflow,python tensorflow nlp lstm doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
16891,16891,50373248,2018-05-16 14:11:43,,trying generate word vec vector panda data frame transformed token used word vec gensim model transform dataframe df equivalent,2018-05-16 21:40:34,2018-06-07 07:52:42,generate word vec vector python,python neural-network nlp text-mining word2vec,,,CC BY-SA 4.0,False,False,True,False,False
16892,16892,50373381,2018-05-16 14:17:03,,using keywords summarization keywords py file getting set tag matter value choose po tagger nn jj nn jj expected result giving po filter nn noun come tag however tag like started looking also coming output similarly difference output irresepective po filter nn po filter nn jj po filter jj correct way using po filter reflect appropriate output actual result student muslim american ramadan month started community place spirituality car white trump looking president black student muslim american ramadan month started community place spirituality car trump white president looking black student muslim american ramadan month started community place spirituality car white trump looking president black,,2018-05-16 14:17:03,correct way use po tagger option gensim keywords extraction,keyword gensim pos-tagger summarization,,,CC BY-SA 4.0,False,False,True,False,False
16893,16893,50264369,2018-05-10 01:53:40,,n number document upon submission new document user goal inform possible duplication existing document like stackoverflow suggests question may already answer system new document uploaded every minute mostly topic chance duplication current implementation includes gensim doc vec model trained document tagged unique document id infer vector new document find similar doc id reason behind choosing doc vec model wanted take advantage semantics improve result far know doe support online training might schedule cron something periodically update model scheduling cron disadvantageous document come burst user may upload duplicate model yet trained new data also given huge amount data training time higher would like know case handled big company better alternative better algorithm problem,,2018-05-10 04:45:59,document similarity production environment,python machine-learning nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
16898,16898,50340657,2018-05-15 00:12:49,,possible plot pyldavis mallet implementation lda trouble lda model use mallet get code,,2019-01-31 23:28:37,pyldavis mallet lda implementation ldamallet object ha attribute inference,gensim topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
16907,16907,50390455,2018-05-17 11:35:16,,extracted sentence gb english wikipedia dump want train doc vec model based sentence unfortunately gb ram get memoryerror trying train even set min count gensim tell would need gb ram think increasing min count would good idea resulting model would good guess anyways try see memory sufficient possibility train large model limited ram current code maybe obvious mistake using completely wrong could also try reducing vector size think result much worse result paper use vector,,2018-05-17 17:04:50,gensim doc vec memoryerror training english wikipedia,python out-of-memory gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
16908,16908,50390582,2018-05-17 11:41:46,,reading doc vec documentation gensim get bit confused option example constructor doc vec ha parameter iter iter int number iteration epoch corpus doe train method also similar parameter called epoch epoch int number iteration epoch corpus difference one paragraph doc avoid common mistake around model ability multiple training pass explicit epoch argument must provided common recommended case train called model cached iter value supplied epoch value really understand constructor need iter parameter exactly provided edit saw also possibility specify corpus directly constructor rather calling train separately think case iter would used otherwise epoch correct difference specifying corpus constructor calling train manually would one choose one edit although mentioned doc iter depreciated parameter doc vec wa renamed epoch consistent parameter train training seems work although struggle memoryerrors,2018-05-17 14:04:15,2018-05-17 17:13:01,gensim doc vec difference iter v epoch,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
16922,16922,50413059,2018-05-18 14:02:29,,want use dynamic topic modeling blei et al http www c columbia edu blei paper bleilafferty pdf large corpus nearly patent document doe anybody ha experience using dtm gensim package identified two model model ldaseqmodel dynamic topic modeling python link model wrapper dtmmodel dynamic topic model dtm link one use used one better better word one prefer,,2019-04-14 12:42:47,dynamic topic modeling gensim code,python-3.x gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
16926,16926,50306710,2018-05-12 13:22:37,,running gensim linux suse start python program startup get c extension loaded training slow install c compiler reinstall gensim fast training gcc installed doe anyone know,2018-05-12 17:56:14,2018-05-12 17:56:14,gensim c extension loaded training slow,pip word2vec gensim opensuse suse,,,CC BY-SA 4.0,False,False,True,False,False
16932,16932,50361783,2018-05-16 02:49:54,,corpus sentence may contain marked compound word example example sentence followed another awesome paragraph want get embedding vector token compound word example sentence followed another awesome paragraph example sentence awesome paragraph gensim library use,2018-05-16 07:40:09,2018-05-16 07:40:09,vector representation token compound word,python machine-learning word2vec gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
16933,16933,50362506,2018-05-16 04:32:06,,using get vector word please see code file content ha line content line trained doc vec got model problem although content line doc vec gave different vector dont know happened thought vector would explain want make vector word case,2018-05-16 20:08:46,2018-05-16 21:06:02,doc vec give different vector text,python nlp word2vec gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
16940,16940,50413300,2018-05-18 14:15:17,,currently trying implement neural network us doc vec vector us work machine allows use tensorflow requirement need model transform sentence paragraph vector know gensim implementation experience gensim implementation apparently doe use tensorflow backend latter link however doe work without hour day debugging seems would helpful link recommendation,2018-06-06 08:23:35,2018-06-06 08:23:35,document vector method doc vec rely tensorflow backend,python tensorflow nlp word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
16950,16950,50396111,2018-05-17 16:13:44,,load word vec format file want calculate similarity vector know issue mean mean thank,,2018-05-17 17:16:41,cosine similarity word vec,scikit-learn nlp word2vec gensim cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,True
16956,16956,50438428,2018-05-20 19:03:03,,struggling understand usage doc vec trained toy model set document using sample code saw googling next want find document model considers closest match document training data say document sample document searched fair bit confused interpret similar doc want answer question document training data closely match document sample document map similar doc output back training data understand array tuples second half tuple must probability etc,,2018-05-21 14:39:32,doc vec get similar document,python machine-learning gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
16958,16958,50492676,2018-05-23 15:50:18,,seen question ask none answer yet thought might well try using gensim word vec model create vector exported text tried importing tensorflow live model embedding projector one problem work told tensor improperly formatted beginner thought would ask people experience possible solution equivalent code creates model save vector print result nice pretty tab delimited file value dimension understand figure wrong way put tensorflow documentation regarding pretty scarce far tell one idea ha presented implementing appropriate tensorflow code know code import file live demo edit new problem object vector non iterable gensim apparently decided make data structure non compatible trying ok done thanks help,2018-05-24 19:06:32,2020-03-11 14:31:33,visualize gensim word vec embeddings tensorboard projector,python tensorflow gensim tensorboard word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
16964,16964,50366293,2018-05-16 08:49:11,,working project classify customer feedback bucket based topic feedback comment need classify sentence one topic among list pre defined topic example keep getting error message every time log ha tagged login topic make screen colorful ha tagged improvement topic topic specific product context lda seem work correct wrong detects topic general sense like sport politics technology etc need detect specific topic mentioned also labelled data training comment supervised learning approach look like option tried far trained gensim model google news corpus gb cleaning sentence removing stop word punctuation mark etc finding topic among set topic word closest tag word topic idea sentence might contain word closer topic referring picking topic maximum number word sentence mapped example word sentence mapped login topic word sentence mapped improvement topic tagging sentence login topic clash count multiple topic return topic maximum count topic list approach giving fair result good enough best approach tackle problem,2018-05-16 08:54:57,2020-10-06 14:42:33,classify sentence one pre defined topic bucket using unsupervised approach,python machine-learning nlp gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
16966,16966,50326147,2018-05-14 08:38:13,,wa experimenting nlp wa working sarcasm detection meanwhile put code sarcasmextractor py giving following error code topic py overall code found overall code,2018-05-14 13:38:07,2018-05-14 13:38:07,attributeerror ldamodel object ha attribute minimum phi value,python tensorflow nlp gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
16969,16969,50477192,2018-05-22 22:16:44,,persisted word vec model binary file trying load serverless api adapted blog using basis work fine locally calling file error ioerror errno file directory punct xec xd xaf xa x,,2018-09-25 12:29:21,loading word vec binary model gensim fails,python amazon-s3 gensim serverless,,,CC BY-SA 4.0,False,False,True,False,False
16974,16974,50478046,2018-05-23 00:02:54,,using gensim library loading pre trained word vector googlenews dataset dataset contains word vector dimension want load googlenews dataset receive memory error tried code without memory error know receive error checked lot site solving issue cant understand code loading googlenews error received anybody help thanks,,2020-04-17 06:08:03,memory error using gensim loading word vec,python word2vec gensim word-embedding google-news,,,CC BY-SA 4.0,False,False,True,False,False
16999,16999,50463415,2018-05-22 08:45:36,,lda corpus document topic number result five vector word word associate weight degree importance like word common document want know calculate similarity vector calculate cosine similarity similarity measure programming scratch wa thinking might easier way help would appreciated thank advance spending time programming python gensim library open library know someone else ha asked similar question cosine similarity lda topic becasue get answer ask,2020-06-20 09:12:55,2018-05-22 12:59:01,calculating similarity two vector,python-3.x nlp gensim lda spacy,,,CC BY-SA 4.0,False,True,True,False,False
17008,17008,50535278,2018-05-25 18:51:58,,trying replicate mikolov work pv dm pv dbow say algorithm used order get better result reason trying train model give document tag sne using gensim doc vec get document tag concatenated structure appear document tag joint model still treating model separate entity see variable explorer also using gensim anyone help way get document tag concatenated new entity individual one,2018-05-25 19:18:07,2018-05-28 00:57:50,gensim doc vec getting doc tag concatenated model,python model gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17013,17013,50516951,2018-05-24 19:36:38,,team ha given task looking document see useful rebranded updated company branding guideline take u forever figured would least try summarize document gensim extract keywords write file name summary keywords csv latest jupyter notebook using python kernel python newbie done past looping directory issue time hour memory utilization start creeping around gb stay hour return normally fluctuationg mb hour two later memory jump back stay seem process file left running hour new python familiar debug sure loop type file encoding issue corrupt file two general help would extremely greatful code started basic logging looking log file every often memory usage ha spiked seems like document processed taking extremely long time noticed log info root manufacturing automotive competitive assessment english letter pptx parsed info gensim corpus dictionary adding document dictionary unique token info gensim corpus dictionary adding document dictionary unique token pictur slide titl automot manufactur info gensim corpus dictionary adding document dictionary unique token pictur slide titl automot manufactur info gensim corpus dictionary adding document dictionary unique token pictur slide titl automot manufactur info gensim corpus dictionary adding document dictionary unique token pictur slide titl automot manufactur info gensim corpus dictionary adding document dictionary unique token pictur slide titl automot manufactur info gensim corpus dictionary adding document dictionary unique token pictur slide titl automot manufactur info gensim corpus dictionary built dictionary unique token pictur slide titl automot manufactur document total corpus position could cause increased memory usage creating multiple dictionary file look like creates one dictionary file,2018-05-25 02:22:05,2018-05-25 02:22:05,python extracting text summarize multiple file type directory tika gensim,python-3.x jupyter-notebook gensim apache-tika,,,CC BY-SA 4.0,False,False,True,False,False
17015,17015,50521304,2018-05-25 03:57:03,,trying cluster description using lsi dataset long clustering based vector obtained model instead using similarity matrix requires much memory pick sample matrix generated correspond square precludes use md however running model looking vector getting different vector length description length num topic argument model description present length happening way correct,2018-05-25 05:48:20,2019-05-27 15:30:46,get different length vector using gensim lsi model,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
17017,17017,50447523,2018-05-21 11:06:45,,c programmer new python working python form visual studio already written program c text processing task need accomplish work python provides advanced function dealing natural language processing specifically need pas parameter c application python application passed parameter used instead inline following python snippet another issue handled casting different data type want import shown c used parameter returned function python idea please help solve issue,2020-10-02 05:07:21,2020-10-02 05:07:21,passing parameter c application python application using gensim visual studio,c# python visual-studio-2017 parameter-passing gensim,,,CC BY-SA 4.0,False,False,True,False,False
17026,17026,50408740,2018-05-18 10:00:20,,following code think getting vector wrong way example vector two document identical output ha like first word line name file follows corresponding vector file need save vector way use external software,,2018-05-18 20:49:12,gensim doc vec gettting different vector document identical,python gensim word-embedding doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17030,17030,50555303,2018-05-27 18:35:54,,put following command anaconda prompt python stop working show following error message deal problem,2020-05-05 14:57:44,2020-05-05 14:57:44,install gensim anaconda prompt,python machine-learning nlp anaconda conda,,,CC BY-SA 4.0,False,False,True,False,False
17031,17031,50557993,2018-05-28 01:17:01,,python code want find way fill value manually already list list tfidfs document corpus calculated using specific equation use fill instead recalculating using calculation want use value passed lsi lda model,2020-10-07 02:56:40,2020-10-07 02:56:40,set value tfidf model gensim manually,python gensim tf-idf,,,CC BY-SA 4.0,False,False,True,False,False
17034,17034,50466643,2018-05-22 11:32:20,,trained word vec model gensim trying load model spacy first need save disk try load init model spacy unable figure exactly,,2020-05-07 09:09:20,spacy use word vec model created gensim,model word2vec gensim spacy,,,CC BY-SA 4.0,False,True,True,False,False
17046,17046,50598129,2018-05-30 06:54:18,,using tf idf computation manually use instead look like remove non salient word tf idf model evident maybe log base seem different log maybe normalization going looking http radimrehurek com gensim model tfidfmodel html gensim model tfidfmodel tfidfmodel scheme difference would output different value clear doc default value default smartirs gensim tfidfmodel default parameter caused difference natively implemented tf idf gensim,2018-05-30 07:04:34,2019-01-04 05:36:44,default smartirs gensim tfidfmodel,python nlp gensim information-retrieval tf-idf,,,CC BY-SA 4.0,False,False,True,False,False
17048,17048,50573054,2018-05-28 20:25:36,,full description starting work word embedding found great amount information understand far train word vector use previously trained one google wikipedia available english language useful since working text brazilian portuguese therefore went hunt pre trained word vector portuguese ended finding hirosan list pretrained word embeddings led kyubyong wordvectors learned ramus al rfou polyglot downloading unsuccessfully trying simply load word vector short description load pre trained word vector trying wordvectors polyglot downloads kyubyong pre trained word vector format word vector portuguese polyglot pre trained word vector portuguese loading attempt kyubyong wordvectors first attempt using gensim suggested hirosan error returned zip downloaded also contains file return similar error polyglot first attempt following al rfous instruction error returned second attempt using polyglot word embedding load function first install polyglot via pip import error returned extra information using python macos high sierra solution kyubyong wordvectors pointed aneesh joshi correct way load kyubyong model calling native load function word vec even though grateful aneesh joshi solution polyglot seems better model working portuguese idea one,2018-05-29 16:28:57,2020-04-19 12:57:13,unicodedecodeerror error loading word vec,python word2vec gensim python-unicode polyglot,,,CC BY-SA 4.0,False,False,True,False,False
17052,17052,50579266,2018-05-29 08:02:10,,according original paper distributed representation sentence document inference unseen paragraph done training inference stage get paragraph vector new paragraph never seen adding column gradient descending holding w u b fixed inference stage done gensim doc vec model attempt infer paragraph whose sentence case pre pad inferring vector special null word symbol length sentence paragraph bigger window size,,2018-05-30 18:24:55,doe doc vec gensim infer vector need window size padded sentence,gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17059,17059,50635465,2018-06-01 02:53:05,,word vec model trained three output created model model wv syn model syn neg couple question regarding model output essentially different model look want access trained result thanks advance,2018-06-01 22:23:26,2018-06-01 22:23:26,word vec model output type,word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
17071,17071,50655405,2018-06-02 09:26:26,,question related gensim like know whether recommended necessary use pickle saving loading model multiple model find script github either see variant variant appears pickle function embedded http github com rare technology gensim blob develop gensim utils py def save try pickle dump self fname handle protocol pickle protocol goal question would glad learn whether need pickle better memory management case better loading model file thank,2018-06-04 16:38:42,2018-06-12 15:27:28,gensim pickle,memory model pickle gensim,,,CC BY-SA 4.0,False,False,True,False,False
17080,17080,50658576,2018-06-02 15:47:53,,trying execute parallel machine learning algorithm use multiprocessing slower without wild guess serialization model use slowing whole process question initialize pool worker initial state need serialize deserialize every single call model current code line marked point data serialized call least mb data serialized avoid serialization,,2018-06-02 16:52:37,initialize pool python multiprocessing worker shared state,python scikit-learn nlp data-science gensim,,,CC BY-SA 4.0,False,False,True,False,True
17083,17083,50583937,2018-05-29 12:03:00,,paper topic word document embeddings word vec doc vec mention used stanford corenlp framework tokenize lemmatize po tag input word sentence corpus lemmatized po tagged stanford corenlp manning et al token wa replaced lemma po tag http www ep liu se ecp ecp pdf pre processing tokenise lowercase word using stanford corenlp http arxiv org pdf pdf question doe first paper apply po tagging would token replaced something like whole thing used train model tag used filter token example gensims wikicorpus applies lemmatization per default keep type part speech verb noun etc get rid rest recommended way quote second paper seems like split word lowercase also first tried used wikicorpus opinion give better result document embeddings po type contribute meaning sentence right original doc vec paper find detail pre processing,,2018-05-29 12:03:00,nlp pre processing doc vec word vec,nlp stanford-nlp word2vec gensim doc2vec,,,CC BY-SA 4.0,False,False,True,True,False
17087,17087,50618993,2018-05-31 07:31:41,,want get word embeddings word corpus decide use pretrained word vector googlenews gensim library corpus contains word googlenews word missing word want use arithmatic mean n similar word goggolenews word first load googlenews check word receive error possible large dataset word true also common word like adding missing word word vec model first want get index word googlenews missing word used index calculate mean embedding vector similar word missing word add news embeddings word vec model un consistency print missing embed empty missing word check found lot missing word question missing embed empty missing word possible googlenews word like append new embeddings word vec model used build vocab syn thanks,,2018-12-30 05:36:09,add new word googlenews gensim,python word2vec gensim google-news,,,CC BY-SA 4.0,False,False,True,False,False
17095,17095,50530747,2018-05-25 13:50:44,,gensim doc vec implementation return tag cosine similarity document similar query document want actual document tag way directly without searching document associated tag returned also documentation seem find documentation half gensim class,,2018-05-28 00:31:24,gensim doc vec similar equivalent get full document,python-3.x nlp text-mining gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17096,17096,50531181,2018-05-25 14:13:42,,trying cluster document word vec numpy run fit fit transform get error exception thread thread traceback recent call last file c user lperona appdata local continuum anaconda lib threading py line bootstrap inner self run file c user lperona appdata local continuum anaconda lib threading py line run self target self args self kwargs file c user lperona appdata local continuum anaconda lib site package gensim model base vec py line worker loop tally raw tally self train job data iterable job parameter thread private mem file c user lperona appdata local continuum anaconda lib site package gensim model word vec py line train job tally train batch cbow self sentence alpha work neu self compute loss file gensim model word vec inner pyx line gensim model word vec inner train batch cbow valueerror truth value array one element ambiguous use x train numpy array string doe anyone know solution thank,,2018-08-29 13:30:06,fit method gensim sklearn api w vmodel w vtransformer throw error inputed dimensional array string,python arrays python-3.6 word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,True
17102,17102,50567108,2018-05-28 13:00:20,,trying generate summary large text file using gensim summarizer getting memory error facing issue since sometime help would really appreciated feel free ask detail length document error messsage tried looking error internet find workable solution,2018-05-29 15:37:08,2018-05-29 15:37:08,gensim summarizer throw memoryerror solution,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
17103,17103,50569110,2018-05-28 14:59:16,,tried creating simple doc vec model end empty vocabulary debugging saw inside build vocab function dictionary actually created vocabulary scan vocab function deleted following vocabulary prepare vocab function deeply function cause problem doe somebody understand problem,,2018-05-28 15:33:57,gensim doc vec trim delete vocabulary,python gensim doc2vec vocabulary,,,CC BY-SA 4.0,False,False,True,False,False
17108,17108,50643196,2018-06-01 12:13:08,,training model using however seem find method compute loss iteration logging purpose look ha method allows print training loss alternative simply impossible,,2018-06-01 12:13:08,gensim fasttext compute training loss,python nlp word2vec gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
17112,17112,50645331,2018-06-01 14:10:11,,trying use pyldavis display result non negative matrix factorization approached topic model model built using sklearn nmf scaling transformation required feed pyldavis prepare way topic term dists parameter take value component nmf doc topic dists result transform method nmf model applied tf idf matrix vocab gensim corpus dictionary computed dataset used build tf idf matrix term frequency come sum along axis count matrix also built dictionary part code raise one deprecation warning follows c user vde anaconda lib site package pyldavis prepare py deprecationwarning ix deprecated please use loc label based indexing iloc positional indexing apart also get three runtime warning seen people getting similar error issue solution doe correspond problem help would much appreciated hesitate ask detail,,2018-06-01 14:10:11,pyldavis object type valuesview json serializable,python json serialization visualization topic-modeling,,,CC BY-SA 4.0,False,False,True,False,True
17124,17124,50607378,2018-05-30 14:34:49,,currently trying evaluate topic model gensim topiccoherencemodel output negative value correct anybody provide formula something u mass work,,2019-01-24 20:29:36,negative value evaluate gensim lda topic coherence,python-3.x gensim evaluation topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
17130,17130,50627026,2018-05-31 14:45:48,,want generate topic topic matrix order find similar topic generate internal cluster function gensim lda save generated data csv topic topic distance case hellinger distance cell code working,,2018-06-06 13:47:24,topic similarity one model csv matrix,python-3.x export-to-csv gensim,,,CC BY-SA 4.0,False,False,True,False,False
17135,17135,50697092,2018-06-05 09:48:50,,trying get text punctuation important consider latter doc vec model however wikicorpus retrieve text searching web found page page gensim github issue section wa question someone answer wa subclass wikicorpus answered piskvorky luckily page wa code representing suggested subclass solution code wa provided rhazegh link page stackoverflow title disabling gensim removal punctuation etc parsing wiki corpus however clear answer wa provided wa treated context spacy link decided use code provided page current code mywikicorpus py used another code pan yang link code initiate wikicorpus object retrieve text change current code initiating mywikicorpus instead wikicorpus code process wiki py command line ran process wiki py code got text corpus last line command prompt info finished saved article read file python checked first article wa without punctuation example anarchism political philosophy advocate self governed society based voluntary institution often described stateless society although several author defined specifically institution based non hierarchical free association anarchism hold state undesirable unnecessary harmful opposition state central anarchism specifically entail opposing authority hierarchical two relevant question wish help please thing wrong reported pipeline regardless pipeline opened gensim wikicorpus python code wikicorpus py wanted edit line add remove update possible get result punctuation many thanks time reading long post best wish ghaliamus,,2019-03-14 17:13:40,get wikipedia corpus text punctuation using gensim wikicorpus,python nlp gensim doc2vec,,,CC BY-SA 4.0,False,True,True,False,False
17145,17145,50679537,2018-06-04 11:27:52,,try evaluate dynamic topic model model generated gensim wrapper possible function like perplexity topic coherence equal normal topic modeling,,2019-04-23 23:39:07,evaluation dynamic topic model,gensim evaluation lda,,,CC BY-SA 4.0,False,False,True,False,False
17147,17147,50684894,2018-06-04 16:21:57,,trained doc vec model following tutorial document http github com abtpst doc vec blob master traindoc vec py however try find similar document given document result similarity higher see code output docvecs similarity return docvecs similar return similarity two document see code output output true true library system version linux amd x debian python default jan numpy scipy gensim fast version,2020-06-20 09:12:55,2018-06-04 16:21:57,doc vec similar method return similarity score higher,python python-3.x gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17148,17148,50685212,2018-06-04 16:43:47,,using gensim create word vector based corpus like following wa wondering possible start somehow avoid word index would like vocabulary start index need operation keep index get little confusing thanks help,,2018-06-04 19:59:31,gensim word vec start vocabulary index different,python word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
17164,17164,50737844,2018-06-07 09:33:45,,try get ldamallet gensim working get following error c appdata local temp eb f state mallet gz found code num topic extremely small test go sentence ha problem regular gensim ldamodel thanks,,2018-07-03 15:21:25,mallet gensim file found,gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
17166,17166,50742031,2018-06-07 13:05:47,,hi wa using gensim topic modelling wa using mallet wa executing code unzipped mallet c drive shown also set environment command code wa executing give error like please help,2018-06-07 13:43:06,2020-05-21 18:31:34,python topic modelling error mallet,python-3.x topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
17179,17179,50651861,2018-06-01 22:50:23,,trying use scikit learn pipeline give jupyter notebook instead seek trained model fix,2018-06-02 00:25:21,2018-06-02 05:37:18,using gensim word vec scikit learn pipeline,python scikit-learn word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,True
17184,17184,50723303,2018-06-06 14:46:50,,say training gensim word vec model min count documentation learns u min count doe ignores word total frequency lower effect min count context let say sentence frequent word min count infrequent word min count annotated f f f f test sentence f f shown made word frequently used word demonstration purpose remove infrequent word get completely different context word vec trained example sentence would would training sentence word vec moreover lot infrequent word word originally far away placed within context correct interpretation word vec assuming many infrequent word dataset set lower min count threshold,,2018-06-06 21:48:04,word vec min count applied,python word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
17186,17186,50723841,2018-06-06 15:11:38,,would need find something like opposite return array word similar one given input need find sort center list word function gensim tool could help example given center would maybe depending corpus model wa trained,2018-06-11 06:05:15,2018-06-11 06:05:15,find closest word set word,python nlp word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
17189,17189,50709355,2018-06-05 21:41:04,,using model pycontractions library determinate machine learning best option expand contraction ambiguous meaning like size model large around gb think gb large model use purpose probably never use word representation model way reduce size extracting subset word representation useful purpose,2018-06-06 00:31:30,2018-06-06 01:48:32,small model google news word vec model,machine-learning models word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
17205,17205,50692739,2018-06-05 05:38:40,,training document gensim doc vec two type input whole english wikipedia article wikipedia text considered one document doc vec training total around million article document document related project manually prepared collected website around document document size around sentence want use model infer sentence size word request clarification approach method training document size document approx sentence inferring new sentence correct train sentence document infer new sentence,,2018-06-05 21:18:42,doc vec useful training document inferring sentence,python gensim training-data doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17216,17216,50783082,2018-06-10 11:13:35,,already built skip gram model using gensim word vec know get similarity score two word e g want know similars since skip gram ha trained context word suppose way get frequent context word shared another example following sentence like get word frequent context notice appear returned frequent context way,,2018-06-13 14:16:21,get frequent context two word word vec,machine-learning nlp word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
17229,17229,50825058,2018-06-12 20:05:08,,trying load pretrained word vec model using gensim although model tagged every word ha tag tell part speech word represents example anyone point load model ask model big right work try keyedvectors load,,2018-06-18 01:35:55,gensim deal model word tag,load gensim corpus,,,CC BY-SA 4.0,False,False,True,False,False
17236,17236,50860649,2018-06-14 15:07:58,,using google word vec wondering get top word predicted skipgram model trained using hierarchical softmax given input word instance using negative sampling one simply multiply input word embedding input matrix vector output matrix take one top value however hierarchical softmax multiple output vector correspond input word due use huffman tree compute likelihood value probability output word given input word case,,2018-06-15 02:37:32,predict word using trained skipgram model,python c++ nlp word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
17239,17239,50805556,2018-06-11 20:30:01,,using perform lda understand parameter find explanation documentation someone ha experience working would love detail parameter signify specifically understand working corpus document roughly around page unfortunately share snapshot data confidentiality reason currently set solely based example saw sure generalizable data,2018-06-12 07:15:02,2018-06-12 07:48:19,understanding parameter gensim lda model,python parameters gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
17250,17250,50828314,2018-06-13 02:33:19,,using gensim load pre trained fasttext model downloaded english wikipedia trained model fasttext website code wrote load pre trained model try check following phrase exists vocal rare chance would pre trained model phrase internal executive present vocabulary still word vector corresponding confusion fastext creates vector character ngrams word word internal create vector character ngrams including full word final word vector word sum character ngrams however still able give vector word even whole sentence fastext vector word ngram vector seeing phrase clearly two word,2018-06-14 06:40:43,2019-03-29 22:36:40,doe gensim fasttext pre trained model get vector vocabulary word,python nlp gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
17261,17261,50752533,2018-06-08 02:31:19,,trying fit word vec model according documentation gensim word vec need call using yet asking tried calling function ha worked also fitted word vec model without needing call something wrong code help greatly appreciated also using macos sierra much support online using gensim mac,,2018-06-08 13:32:16,gensim word vec must first build vocabulary training model,python nlp word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
17271,17271,50848942,2018-06-14 02:53:16,,gensim example whenever execute show different result believe gensim work well result result look simiar human computer interaction thanks,,2019-01-17 03:49:27,different result executing gensim example,python document similarity gensim cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,False
17273,17273,50849640,2018-06-14 04:30:20,,following tutorial result getting ha coefficient data set ha ha two column tweet ingestion date copied code exactly made substitution like tweet prepreocessor thought doe original file need target target name column like tutorial,2018-06-14 13:56:42,2018-08-22 18:06:02,gensim coefficient nan,python machine-learning gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
17278,17278,50866996,2018-06-14 22:53:55,,using python package gensim clustering first created dictionary tokenizing lemmatizing sentence given text using dictionary created corpus using following code understand corpus would contain id word along frequency document wish know frequency given word whole corpus find top term corpus wondering method available return frequency term entire corpus,2018-06-15 07:15:23,2018-06-15 07:15:23,top term corpus gensim,python gensim counting corpus,,,CC BY-SA 4.0,False,False,True,False,False
17310,17310,50839808,2018-06-13 14:30:54,,tried load googlenews vector negative bin try predict output word method tested three way every failed code error way shown first first used line error second tried error third model gensim model word vec load googlenews vector negative bin print model wv predict output word king man topn error pickle unpicklingerror invalid load key read document http radimrehurek com gensim model word vec html still idea namespace predict output word would anybody help thanks,,2018-06-13 17:11:22,load googlenews vector negative bin predict output word,word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17325,17325,50857544,2018-06-14 12:26:38,,possibility evaluate dynamic model ldaseqmodel like normal lda model value perplexity topic coherence know value printed logging info another method would save logging info text file search evaluation value simulation method code evaluate ldaseqmodel doesnt exist possible save logging info text file code generate ldaseqmodel,,2019-04-14 11:46:07,evaluation ldaseqmodel gensim,python-3.x gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
17327,17327,50887821,2018-06-16 12:15:56,,using hdbscan algorithm create cluster document create vector matrix word using tf idf algorithm want use glove searched post could understand use algorithm also read gensim understand could use implement could see implementation used along text clustering could use place,,2018-06-16 18:24:29,use glove generate vector matrix,python vectorization tf-idf hdbscan,,,CC BY-SA 4.0,False,False,True,False,False
17339,17339,50910287,2018-06-18 13:08:57,,using gensim load fasttext pre trained word embedding give memory error way load,2018-06-18 13:16:13,2018-06-18 22:20:29,loading fasttext pre trained german word embedding vec file throwing memory error,nlp gensim word-embedding fasttext,,,CC BY-SA 4.0,False,False,True,False,False
17342,17342,50945820,2018-06-20 10:17:47,,using deeplearning j java library build paragraph vector model doc vec dimension using text file ha around million line size file mb train model calculate paragraph vector give reasonably good result problem try save model writing disk wordvectorserializer writeparagraphvectors dl j method take around gb space around gb use native java serializer thinking may model size big much data model size gb reasonable text data mb comment also welcome people used doc vec paragraph vector library language thank,2018-06-21 00:14:16,2018-06-21 00:14:16,paragraph vector doc vec model size,nlp gensim word-embedding doc2vec deeplearning4j,,,CC BY-SA 4.0,False,False,True,False,False
17359,17359,50895571,2018-06-17 10:01:56,,hi using gensim word vec word embedding python getting error like importerror import name utils thank,,2019-05-15 13:44:59,python module gensim error import name utils,python pip gensim word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
17366,17366,50933591,2018-06-19 17:06:00,,using gensim vector space model creating dictionary corpus gensim calculated term frequency inverse document frequency tfidf using following line corpus tfidf contain list list term id corresponding tfidf separated tfidf id using following line want use k mean clustering want perform cosine similarity tfidf matrix problem gensim doe produce square matrix run following line generates error wonder get square matrix gensim calculate similarity document vector space model also convert tfidf matrix case list list numpy array comment much appreciated dumydist cosine similarity tfidfmtx,2018-06-19 17:27:54,2019-04-15 15:25:36,perform kmean clustering gensim tfidf value,numpy k-means gensim tf-idf corpus,,,CC BY-SA 4.0,False,False,True,False,False
17372,17372,50859540,2018-06-14 14:10:47,,using gensim tdidf model like like apply threshold remove term appear frequently max df infrequently min df know scikit countvectorizer allows seem find set threshold gensim tfidf could someone please help,,2018-06-22 18:14:32,way set min df max df gensim tfidf model,gensim tf-idf,,,CC BY-SA 4.0,False,False,True,False,False
17381,17381,50937881,2018-06-19 22:39:53,,interested final w w also known w w variation two matrix learning using gensim implementation compared sklearn gensim api well organized mind hence open moving tf need given getting access value would possible easier know hack main code question whether already function variable,2019-05-26 11:04:37,2019-05-26 11:04:37,get weight update word vec,tensorflow gensim word2vec,2019-05-26 11:04:40,,CC BY-SA 4.0,False,False,True,False,True
17382,17382,50992153,2018-06-22 16:29:52,,running gensim doc vec ubuntu doc vec reject input error attributeerror list object ha attribute word tried already question many variation result document brown tagged sent adding hash function corpus txt file utilize often possible,,2018-06-22 18:49:34,doc vec input format,gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17387,17387,50914729,2018-06-18 17:32:32,,large pretrained word vec model gensim want use pretrained word vector embedding layer kera model problem embedding size enormous need word vector know word occure input want get rid reduce size embedding layer way keep desired wordvectors including coresponding index based whitelist word,2018-06-18 20:40:39,2019-04-17 11:15:04,gensim word vec select minor set word vector pretrained model,python keras word2vec gensim word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
17389,17389,50919655,2018-06-19 01:59:24,,wondering number feature number unique token rather case differ one v info adding document dictionary unique token info built dictionary unique token document total corpus position info collecting document frequency info progress processing document info calculating idf weight document feature matrix non zero,2020-06-20 09:12:55,2018-06-19 02:09:44,gensim tfidf number unique token v number feature,gensim,,,CC BY-SA 4.0,False,False,True,False,False
17390,17390,50953272,2018-06-20 16:45:07,,use gensim find jaccard index vector corpus,,2018-06-21 04:30:48,jaccard index python corpus using gensim,python-2.7 nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
17409,17409,51014463,2018-06-24 22:25:09,,effect assigning label bunch sentence doc vec collection document want learn vector using gensim file classification task file refers collection document given id several way labeling mind want know would difference best take document assign label tag train repeat others take document assign label tag tokenize document sentence assign label tag train full document individual sentence repeat others example ignore sentence tokenized similar also assign unique label sentence along full document ha sentence tag along example also additional categorical tag assigning would best approach,,2018-06-25 00:27:46,hierarchical training doc vec would assigning label sentence document work,python nlp word2vec gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17415,17415,50960914,2018-06-21 05:24:02,,forming gensim lda model got dictionary data using following command frequent token manually removed token remaining token would directly related topic want generate form corpus document new dictionary formed type dict form use train lda model,,2018-06-21 05:43:25,form corpus document lda model dictionary type dict,python dictionary gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
17416,17416,51105753,2018-06-29 16:10:47,,use gensim library create word vec model contains function understand follows example model trained sentence anarchism doe offer fixed body doctrine single particular world view instead fluxing flowing philosophy use situation could get predict correct word omitted word doctrine right way please explain function detail,2018-06-29 18:49:25,2018-07-02 10:02:17,gensim function predict output word,python tensorflow nlp word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
17433,17433,51030698,2018-06-25 19:33:43,,using gensim create bag word model want perform normalization found documentation http radimrehurek com gensim model normmodel html confused implement given code conversation list tokenized document essentially list list element document corpus sparse matrix believe document ha non zero frequency term corresponding count last line doe work try input following get type error message int object iterable however documentation say pas corpus confused would appreciate help thanks,2018-06-25 19:48:52,2018-06-25 19:48:52,normalizing bag word data gensim,python normalization gensim corpus term-document-matrix,,,CC BY-SA 4.0,False,False,True,False,False
17440,17440,51150702,2018-07-03 09:10:04,,trying find dissimilarity two document using gensim far obtained similarity score way know dissimilarity score dissimilar feature two document evaluate,2019-09-02 12:18:27,2019-09-02 12:18:27,dissimilar feature two document,nlp nltk gensim cosine-similarity,,,CC BY-SA 4.0,True,False,True,False,False
17453,17453,51168444,2018-07-04 07:49:20,,check previous post link seems work case pre trained word vec model panda dataframe keywords want add vector keyword corresponding column use throw error update keyword work use still giving error update new word word vec vocabulary get vector expected output,2018-07-06 06:47:36,2018-07-26 08:52:18,get vector word present word vec vocabulary,python-3.x pandas word2vec gensim text-classification,,,CC BY-SA 4.0,False,False,True,False,False
17460,17460,51132848,2018-07-02 09:25:08,,pre trained doc vec model large data set like wikipedia similar,2019-05-07 01:32:54,2019-05-07 01:32:54,pre trained doc vec model,gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17461,17461,51133162,2018-07-02 09:40:22,,trained w v model big corpus want update smaller one new sentence new word first big training took default parameter alpha lin decay want use update doc understand initial final learning rate used update training one side also use lin decay strong already existing word appeared lot first big corpus heavily changed side new word added model build vocab sentence update true low learning rate small question default behaviour api new sentence regarding learning rate choose learning rate order take account issue old new word aside question use time model train sentence second time update vector,2018-07-02 09:46:27,2018-07-02 15:17:31,word vec gensim update learning rate,python machine-learning word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
17465,17465,51092771,2018-06-29 00:30:12,,ha suggested initializing topic model using cluster word lead higher quality model robust consistent inference talking initializing optimizer setting prior code illustrate want create ldamodel object pas corpus next assign property object corresponding probability drawing word topic matrix construction fit corpus thanks help,2018-06-30 20:28:56,2018-06-30 23:08:24,initialize gensim lda topic model,python gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
17471,17471,51061171,2018-06-27 11:04:52,,want create model predict word missing sentence sentence ha whole need filled dataset consists sentence shortest sentence length longest sentence length vocabulary size dataset would make huge difference model either onehot encoding pre trained word vec gensim model use pre trained weight kera embedding layer would sense freezing trainable layer make difference regarding accuracy case tried representation seems difference regarding accuracy test data highest accuracy achieved wa correctly predicted right track wrong approach task machine slow make experiment parameter hard time consuming would grateful advice tip,,2018-06-27 12:06:27,lstm sentence completion word vec,keras deep-learning lstm prediction word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17481,17481,51135118,2018-07-02 11:26:43,,regarding word vec gensim suppose already trained model big corpus want update new word new sentence update word already vector possible freeze vector word update chosen word like new word calling maybe trick thanks,,2018-07-02 15:25:39,gensim word vec freeze wordvectors update others,python word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
17487,17487,51042031,2018-06-26 11:39:53,,company ha lot data issue stored database want create search engine people check issue previously dealt use rd party api sensitive data want keep house right approach following clean data use doc vec represent issue vector find closest issue using distance metric problem result useful problem data one liner issue description spelling mistake stack trace thing right approch switch something else right testing k data thanks help,,2018-06-26 11:39:53,trying make search engine issue,machine-learning word2vec gensim information-retrieval doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17494,17494,51082572,2018-06-28 12:09:46,,wa working amazon sentiment classification dataset predict sentiment based review given however wa experimenting method one normal layer kera architecture next one wa trying code unable understand difference b w using using along want know math behind working kera layer working gone post understand kera embedding layer work want understand gradient descent backpropagation also combination p code given skipped part,,2018-06-28 12:09:46,gradient descent backpropagation difference b w embedding layer kera word vec gensim,python keras nlp deep-learning word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17495,17495,51062519,2018-06-27 12:12:53,,used gensim text summarizing python want summarized output stored different column dataframe used code error coming line code state typeerror expected string byte like object store processed text panda dataframe,2018-06-27 12:14:34,2018-06-27 14:39:59,storing processed text panda dataframe,python loops gensim,,,CC BY-SA 4.0,False,False,True,False,False
17506,17506,51157395,2018-07-03 14:44:59,,word document want transform bag word representation mean word known however call result empty list possible explanation document single word assigned topic reason seeing,,2018-12-24 05:44:44,get document topic return empty list topic,gensim,,,CC BY-SA 4.0,False,False,True,False,False
17510,17510,51160354,2018-07-03 17:47:44,,used gensim create bag word model although much longer reality format outputted creating bag word document term matrix tokenized text using gensim sparse matrix representation understand library represent document term matrix similar fashion well document term matrix non sparse meaning zero entry well know since dimension num document num term multiplying two give term co occurrence ultimately want get top n co occurrence get top n term pair occur together text would achieve attached gensim creating bow model another library like sklearn easily open would appreciate advice help code problem thanks,,2018-07-04 18:40:37,computing top n word pair co occurrence document term matrix,python matrix scikit-learn gensim text-analysis,,,CC BY-SA 4.0,False,False,True,False,True
17513,17513,51142294,2018-07-02 19:01:57,,following documentation well link machine learning gensim tutorial complete loss happening tokenizing lemmatizing sentence put sentence phraser created dictionary inserted right variable model sampling code sample token list look like completely made list topic getting nan discovered nan gained nan send nan discovered nan gained nan send continues time topic weight nan could issue,2018-07-02 19:18:52,2019-07-26 03:52:30,gensim ldamodel error nan topic,python pandas nlp gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
17520,17520,51269058,2018-07-10 15:26:20,,gensim model take input list list inner list containing individual token word sentence understand used quantify context word within text using vector currently dealing corpus text ha already split individual token longer contains obvious sentence format punctuation ha removed wa wondering input model say simply split corpus sentence uniform length token per sentence example would good way inputting data model essentially wondering format input sentence list list affect output word vec,2018-07-10 17:59:54,2018-07-10 17:59:54,use proxy sentence cleaned data,python nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
17524,17524,51180848,2018-07-04 21:18:46,,started learn gensim word vec doc vec work similarity score actually work really well experiment however wanted optimize key word based search algorithm comparing single word getting similar piece text best way considered averaging word vector word text maybe remove fill stop word first comparing search word really intuition would best way,,2018-07-05 21:00:30,get similiarity word document gensim,python search gensim word2vec doc2vec,2018-07-07 11:50:00,,CC BY-SA 4.0,False,False,True,False,False
17536,17536,51252324,2018-07-09 18:57:07,,trying use gensim doc vec create model trained set document set label label created manually need put program trained far list list sentence list label corresponding sentence need use doc vec specifically tried far getting error line googled say put labeled sentence object sure work predefined label doe anyone know put pre defined label doc vec thanks advance,,2018-07-10 03:30:43,doc vec gensim supervised data predefined label,python gensim supervised-learning doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17542,17542,51233632,2018-07-08 15:46:00,,problem going completely head training word vec model using gensim provided data multiple language e english hindi trying find word closest man getting problem english word tried find similarity meaning hindi english word accuracy better accuracy hindi corpus ha made translating english one hence word appear similar context hence close,2018-07-10 10:20:52,2020-05-16 10:43:50,word vec gensim multiple language,python nlp artificial-intelligence word2vec gensim,,,CC BY-SA 4.0,False,False,True,False,False
17552,17552,51311240,2018-07-12 17:16:40,,using word vec skip gram model tensorflow wrote code obtain word embeddings document set final embeddings numpy ndarray format obtain similar document need use wmd word mover distance algorithm much knowledge gensim gensim similarity wmdsimilarity requires embeddings keyedvectors data type seems like implement wmd code tight deadline give much time writing code wmd scratch,,2018-07-15 18:03:37,use wmdsimilarity function provided gensim along word embeddings numpy ndarray data type,python-3.6 gensim word2vec numpy-ndarray wmd,,,CC BY-SA 4.0,False,False,True,False,False
17570,17570,51292498,2018-07-11 18:59:38,,dataframe column also pretrained word vec model using gensim get dimension vector word using question want assign dimension vector column name v v corresponding keyword ii word present word vocabulary want assign vector array corresponding word otherwise give example word present vocab would like far done far got array vector im getting put column name treat missing word,,2018-07-16 13:17:20,add word vector column panda dataframe,python-3.x pandas gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17575,17575,51275484,2018-07-11 00:09:17,,intend deploy trained model production since keep code base need upload cloud refer runtime using kubernetes relatively new stepwise understanding solve build persistent volume trained model size around mb mount persistent volume pod single container keep pod running refer model python script via pod tried referring documentation pv luck also tried move model pv via kubectl cp success idea resolve help would appreciated,,2018-07-11 00:09:17,trained model kubernetes,machine-learning kubernetes nlp gensim persistent-volumes,,,CC BY-SA 4.0,False,False,True,False,False
17579,17579,51330246,2018-07-13 17:35:01,,training multiple word vec model gensim word vec parameter dimension trained slightly different data want compare change data affected vector representation word every time train model vector representation word wildly different similarity among word remain similar whole vector space seems rotated way rotate word vec representation way word occupy position vector space least close possible thanks advance,,2018-07-13 18:09:20,rotate word vec onto another word vec,gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
17603,17603,51222901,2018-07-07 11:47:14,,trained model using package gb text data preprocessed using following code snippet every time train model size kb seems right tried generating vector trained model say following code used training word vec model please help resolving issue,2018-07-07 12:54:32,2018-07-07 14:09:46,word vec model size small recognizing word,python python-3.x word2vec gensim word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
17606,17606,51281241,2018-07-11 08:56:14,,using gensim executed following code simplified day code finished however saving experienced noticed npy file generated intermediate result use rerun entire process,,2018-07-11 21:39:18,gensim word vec model trained saved,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17617,17617,51265111,2018-07-10 12:23:27,,attempting compare tagged document consisting list word individual tag list tag code follows issue running feed back keyerror word otherword vocabulary want get similarity taggeddocument tag question need change code check correctly give back similarity value n b replaced actual word placeholder,,2019-11-09 02:30:16,gensim n similarity word vocabulary,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
17638,17638,51287590,2018-07-11 14:05:07,,wanted write code find similarity two sentence ended writing code using nltk gensim used tokenization gensim similarity similarity work serving purpose work fine introduce last line code throw error find answer anywhere internet please help figure problem,,2018-07-11 16:04:10,use gensim similarity similarity find similarity two sentence,python python-3.x nltk gensim corpus,,,CC BY-SA 4.0,True,False,True,False,False
17644,17644,51376241,2018-07-17 08:05:51,,trained v large text corpus received file bun final model ha saved wa enough free space available disk way resave model using file shorter time training time thank advance,2018-07-17 08:35:03,2018-07-17 17:55:06,gensim doc vec trained saved,model save gensim word-embedding doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17656,17656,51245689,2018-07-09 12:32:10,,trying understand parameter function parameter function following code snippet manually set loop iteration required passing epoch parameter doc vec enough also different epoch also weight updated,,2018-07-10 03:37:44,doe epoch mean doc vec train manually run iteration,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17670,17670,51414910,2018-07-19 05:24:32,,hey guy pretrained binary file want train corpus approach tried tried extract txt file bin file use word vec file time loading trained corpus saved model model performing badly word pre trained bin file used intersect word vec format command script used approach model perform well word pre trained file corpus,,2018-07-24 04:33:49,train pretrained binary file corpus using gensim,nlp models gensim corpus,,,CC BY-SA 4.0,False,False,True,False,False
17684,17684,51418154,2018-07-19 08:45:36,,training doc vec using callback trying see alpha decreasing training time using code training see alpha changing time callback see alpha possible check alpha decreasing really decreasing training one question benefit core training doc vec see core loaded,2018-07-20 14:08:41,2018-07-20 14:08:41,check via callback alpha decreasing load core training,callback gensim multicore word-embedding doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17693,17693,51438277,2018-07-20 08:28:02,,trying train doc vec word embedding preprocessed paragraph removed punctuation carried tokenization po tag chunking get error attributeerror tree object ha attribute word run doc vec model done correct thank,,2018-07-20 09:24:53,attributeerror tree object ha attribute word doc vec error,model nltk gensim attributeerror doc2vec,,,CC BY-SA 4.0,True,False,True,False,False
17694,17694,51438425,2018-07-20 08:36:25,,currently trying classify text class able reach precision score using majority voting svm multinomial nb random forest knn wanted try increase little precision using word embeddings thus getting le dimension sample use gensim word vec create model nltk list stop word tokenizer model seems fine get satisfying result use similarity word use class get mean representation sample finally build common sklearn pipeline let sklearn perform gridsearchcv data issue get random precision score around maybe dimensionality reduction always able increase precision think understand something something wrong idea going wrong thank advance,2018-07-20 13:05:31,2018-07-20 13:05:31,word embedding decreasing classification precision,scikit-learn nlp nltk gensim text-classification,,,CC BY-SA 4.0,True,False,True,False,True
17712,17712,51457515,2018-07-21 15:29:33,,several table different column name mapped etl total around table attribute set massive column mapping follows see column name mapped different name across different table trying solve following problem given two schema want find match attribute name wa wondering way leverage gensim solve problem similar source word google example challenge facing dataset use train model also wondering another approach solve problem,2018-07-21 19:34:41,2018-07-21 20:27:38,attribute mapping using machine learning,machine-learning database-design gensim,,,CC BY-SA 4.0,False,False,True,False,False
17722,17722,51481553,2018-07-23 14:43:44,,trying use fasttext french pre trained binary model downloaded official fasttext github page need model word vector approximate misspelled vocabulary word however try load said model using get following error surprising work fine try load english binary model running python gensim idea work french vector welcome,2020-06-20 09:12:55,2018-11-19 15:21:51,error loading fasttext french pre trained model gensim,python gensim pre-trained-model fasttext french,,,CC BY-SA 4.0,False,False,True,False,False
17733,17733,51388707,2018-07-17 19:14:21,,anaconda installed host recently installed several package data science use import fine except gensim getting intel mkl fatal error load libmkl avx libmkl def getting python shell sound like duplicate weird part import tensorflow seaborn importing gensim getting error gensim imported would also like know dependency package latest version numpy looked various solution proposed installing package uninstalling would like know reason actually,,2018-09-07 06:11:24,intel mkl fatal error trying import gensim package,python tensorflow anaconda seaborn gensim,,,CC BY-SA 4.0,False,False,True,False,False
17736,17736,51426107,2018-07-19 15:07:55,,trying build tf idf model score bigram well unigrams using gensim build gensim dictionary use dictionary create bag word representation corpus use build model step build dictionary look like list unigrams bigram like however provide list algorithm reduces token bigram e g way generate dictionary gensim includes bigram,,2019-01-28 05:47:48,build gensim dictionary includes bigram,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
17756,17756,51429975,2018-07-19 18:53:50,,try use get used get sklearn api w vmodel scikit learn wrapper word vec model could find advice install,,2018-07-19 18:56:28,module named gensim sklearn api,python scikit-learn gensim,,,CC BY-SA 4.0,False,False,True,False,True
17758,17758,51430560,2018-07-19 19:36:06,,getting irregular behavior lda topic model program right seems like file save lda model creates really sure code snippet albeit going take time could write code reproducible since really trying load certain file created beforehand put sraightforwardly clue permission denied try save lda model particular location right even original directory location giving permission denied error message seeming like directory could use work odd behavior really find asks talk error context found post people getting error message actually tried storing location exist really question first got error actually started wonder wa another lda topic model named topic model wa stored subdirectory started wonder name wa potential cause changed see could change result nothing working even really figure solution applies situation especially since right reproducible code work someone tell error message mean doe come maybe start,,2018-07-20 21:41:25,gensim lda permission denied try save model,python text-mining gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
17764,17764,51514825,2018-07-25 08:57:25,,need generate word vec array dictionary word dictionary look something like loop go line check word exists model yes store vector array otherwise check next word line none word present gensim model nothing array initialised zero however word exist pre trained model raise exception keyerror word galeocerdo cuvieri vocabulary ideal loop also ha exception order bypass error raised starting code,,2018-07-25 09:47:44,word vec dictionary word,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17767,17767,51520031,2018-07-25 13:23:54,,familiar tfidf vectorizer however gensim seems like tfidf treated model like lda lsi others case tfidf used vectorize input lda model example link documentation http radimrehurek com gensim tut html,,2019-10-21 07:53:31,tfidf seen model gensim,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
17768,17768,51520655,2018-07-25 13:52:14,,trying download gensim pretrained word vec model behind proxy receive error urllib error urlerror urlopen error errno getaddrinfo failed following code already set proxy using successfully downloading package using pip way add proxy gensim,,2018-07-25 13:52:14,downloading gensim model behind proxy,python python-3.x gensim http-proxy,,,CC BY-SA 4.0,False,False,True,False,False
17773,17773,51449841,2018-07-20 20:22:20,,would like use gensim library unfortunately install via pip due company firewall advice thank advance help suggestion provide,,2018-07-20 20:34:18,install gensim without pip firewall issue,python installation firewall gensim,,,CC BY-SA 4.0,False,False,True,False,False
17790,17790,51523248,2018-07-25 16:00:06,,trained doc vec model million record want find similar sentence new sentence put data getting bad result sample data passing data done preprocessing includes stop word removal special character numeric value removal lowercase data also performed step testing process code used training well new gensim doc vec followed example training model please correct used wrong parameter testing side testing passed sentence present training data model doe give related document similar document example got lootmela tempered glass guard micromax canvas juice similar sentence nokia pewter black gb gb ram sentence similarity score please forgive question formatting good,2018-07-25 16:38:36,2018-07-25 17:20:43,doc vec inaccurate cosine similarity,python machine-learning gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17794,17794,51560126,2018-07-27 14:30:30,,gensim pretrained model wa trying find similar word using let say word named politics done give output list word thing put inside function used get error something wrong edit append blank array name word e present array name done working,2020-06-20 09:12:55,2018-07-27 15:01:41,python loop working inside user defined function,python python-3.x function gensim cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,False
17802,17802,51602111,2018-07-30 20:52:57,,two pretrained word embeddings one pretrained stanford trained different set vocabulary reduce oov like add word appear file appear file file easily load save file gensim,2018-07-30 21:20:32,2018-07-30 22:53:27,adding additional word word vec glove maybe using gensim,nlp gensim word2vec glove,,,CC BY-SA 4.0,False,False,True,False,False
17803,17803,51492778,2018-07-24 07:23:46,,trying build translation network using embedding rnn trained gensim word vec model learning word association pretty well however get head around properly add layer kera model inverse embedding output another question answered default word vec input string e g get vector representation word however believe layer returned word vec get kera embedding take one hot tokenized input instead string input documentation provides explanation appropriate input figure obtain one hot tokenized vector vocabulary ha correspondence embedding layer input elaboration currently workaround apply embedding outside kera feeding network detriment set embedding non trainable anyway far noticed memory use extremely inefficient like gb even declaring kera model collection word long sentence load padded input weight outside model maybe generator help following code input padded word long word vec embedding ha dimension probably lot mistake due repeated experimentation trying make embedding work suggestion welcome throw error try fit model text following excerpt rajmak demonstrating use tokenizer convert word input kera embedding kera embedding layer obtained gensim word vec word vec get kera embedding train embeddings false method constructed like shown null word embeddings indicate number word found pre trained vector case google news could possibly unique word brand context explicitly created using however use embedding matrix already constructed fixed know word index tokenizer coerced match corresponding word kera embedding input proper way use word vec get kera embedding kera,,2018-07-25 16:28:24,properly use get kera embedding gensim word vec,python keras gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
17805,17805,51634656,2018-08-01 13:31:40,,trying filter token frequency using filter extreme function gensim http radimrehurek com gensim corpus dictionary html specifically interested filtering word occur le frequent document frequent document first print statement give second print statement give however following first print statement give expected second give add number total word however come sum exceeds number word corpus doe make sense since filter cover non overlapping word based explanation documentation idea would really appreciate input thanks,2018-08-01 15:58:23,2020-07-05 09:59:51,filtering token frequency using filter extreme gensim,python dictionary text-processing gensim corpus,,,CC BY-SA 4.0,False,False,True,False,False
17808,17808,51512064,2018-07-25 06:20:00,,dataframe like saved save word vec format using gensim txt file using panda read file picture delete first row make index txt file http drive google com file n hpsmvmjwc w atyqqmdmwhrlf view usp sharing,2018-07-25 08:49:10,2018-07-25 08:49:10,delete first column take index panda,python pandas dataframe nlp word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17822,17822,51547315,2018-07-26 20:49:50,,issue similar one discussed gensim word vec updating word embeddings newcoming data following code save model text gensim bin code add data saved model loading model load fine however try call model wv similarity function get following error keyerror word eft vocabulary missing something,,2018-07-26 21:30:41,gensim word vec update model data,gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
17823,17823,51514060,2018-07-25 08:18:11,,word vec dataframe like saved save word vec format using gensim txt file using panda read file picture delete first word make index want dataframe like one hot encoding vector dataframe txt file http drive google com file n hpsmvmjwc w atyqqmdmwhrlf view usp sharing,2018-07-25 08:47:59,2018-07-25 08:50:22,remove first word take word index like one hot encode vector panda,pandas dataframe word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17825,17825,51655597,2018-08-02 14:03:27,,using sklearn decomposition latentdirichletallocation module explore corpus document number iteration training adjusting model e adding stopwords synonym varying number topic fairly happy familiar distilled topic next step would like apply trained model new corpus possible apply fitted model new set document determine topic distribution know possible within gensim library train model subsequently apply trained model new corpus http radimrehurek com gensim model ldamodel html doe one using scikit learn application lda,2018-08-02 14:27:56,2018-08-02 15:38:18,sklearn latentdirichletallocation topic inference new corpus,python scikit-learn lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,True
17849,17849,51566257,2018-07-27 22:21:48,,working project using gensim word vec total freshman field actually already got model way get similarity rank word another word example top similar word word girl lady woman function use enter lady return enter woman return thanks,,2020-08-31 19:00:35,return rank word gensim word vec,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17858,17858,51527411,2018-07-25 20:47:34,,document sentence using gensim doc vec train model training work fine smaller data set say record however training full dataset process dy mostly resetting layer weight stage sometimes dy suspecting memory issue gb ram core indeed memory issue way train model batch reading documentation seems train useful case new document new vocabulary case document suggestion,,2018-07-26 21:25:17,gensim doc vec training crash killed error,gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17891,17891,51593971,2018-07-30 12:27:15,,want label document tag mapped id attribute database id example also like document example reason able build vocabulary although unique id tag higher value doe matter gensim writes tag log solve problem want start map higher number uselessly used compute time also tried tag string document taggeddocument word blabla request tag doe work either inspecting gensim code get solution,,2018-07-30 16:57:10,gensim tagging document big number,python gensim topic-modeling doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17892,17892,51594165,2018-07-30 12:38:19,,cbow word vec scheme look like extract matrix wi wo found field gensim w v model make assumption wi wo code give matrix zero element mb dataset matrix also contain zero element log gensim log,2018-08-01 14:55:47,2018-08-01 14:55:47,extract matrix wi wo gensim word vec,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17899,17899,51616074,2018-07-31 14:41:18,,following related question solution created docker container load googlenews vector negative keyedvector inside docker container load memory also another docker container provides rest api load model observe fully loaded container take gb memory gunicorn worker take gb memory however expect process share memory keyedvector take gb shared container someone tried achieve succeed edit tried following code snippet indeed share memory across different container problem share memory edit studying gensim source code see called open memmaped file following code sample share memory across multiple container,2018-08-06 13:38:04,2018-08-07 08:49:54,sharing memory gensim keyedvectors object docker container,python mmap gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17902,17902,51680023,2018-08-03 20:59:43,,call document getting error yield hunch may numpy gensim version compatibility using python numpy gensim full error,2018-08-03 21:25:34,2018-08-06 15:20:10,gensim calling docvecs similar yield error,python numpy gensim,,,CC BY-SA 4.0,False,False,True,False,False
17906,17906,51632344,2018-08-01 11:39:43,,around pair sentence pair consists two sentence one causing high ctr one low want create mechanism auto produce sentence optimized high ctr iterating pair get vector using spacy nlp sentence take vector difference sent vector sent vector mean pair using numpy mean difference vector hand want add given text get new sentence idea obtain gensim similar work single word thanks,,2018-08-01 11:39:43,spacy gensim creating similar sentence,gensim spacy,,,CC BY-SA 4.0,False,True,True,False,False
17940,17940,51736907,2018-08-07 23:54:22,,trying use word vec supervised classification labelled class data containing sentence label would like train word vec model use word vec possibly random forest classifier order figure class unseen sentence tried far wondering need go order include label go along sentence tell model label sentence belongs able load model separate file classify unseen data category based supervised learning help appreciated,,2018-08-07 23:54:22,using word vec supervised classification,python gensim word2vec supervised-learning,,,CC BY-SA 4.0,False,False,True,False,False
17942,17942,51742332,2018-08-08 08:45:59,,trained word vec model using gensim want randomly select vector find corresponding word best,2018-08-08 09:29:37,2018-08-09 05:34:34,randomly select vector gensim word vec,python-3.x nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
17947,17947,51650896,2018-08-02 10:07:38,,trying compute accuracy word vec model code get following error c user appdata local program python python lib site package gensim matutils py futurewarning conversion second argument issubdtype deprecated future treated np issubdtype vec dtype np int nothing happens anyone know fix,2018-08-02 11:31:21,2018-08-02 11:31:21,futurewarning error calculating accuracy word vec model,python numpy nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17948,17948,51651934,2018-08-02 10:57:51,,trying allow user enter search term find top article matching search process comparing result performance variety method gensim word vec doc vec nearest neighbour etc successfully created code leverage standard similarity function spacy however loop massive list document appending similarity score panda df take long method return top similar document without loop panda append reason method return sensible top document compared others joy word embeddings,2018-08-02 11:05:56,2020-03-31 15:53:55,python spacy similarity without loop,python python-3.x machine-learning similarity spacy,,,CC BY-SA 4.0,False,True,True,False,False
17950,17950,51798248,2018-08-11 09:18:16,,trained doc vec model order simple binary classification task would also love see word sentence weigh term contributing meaning given text far luck finding anything relevant helpful idea could implement feature switch doc vec conventional method like tf idf,,2019-09-03 21:04:39,find decisive sentence word document via doc vec,python nlp gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
17959,17959,51785296,2018-08-10 11:14:48,,trying load saved gensim lda mallet testing new query original corpus dictionary everything seems fine first load executing code afterward error pop java io filenotfoundexception tmp f corpus mallet file directory java io fileinputstream open native method java io fileinputstream open fileinputstream java java io fileinputstream fileinputstream java cc mallet type instancelist load instancelist java cc mallet classify tui csv vector main csv vector java exception thread main java lang illegalargumentexception read instancelist file tmp f corpus mallet cc mallet type instancelist load instancelist java cc mallet classify tui csv vector main csv vector java traceback recent call last file topic modeling py line topic get label text id word first ldamallet file topic modeling py line get label row enumerate lda ques vec file home user sjha anaconda envs conda env lib python site package gensim model wrapper ldamallet py line getitem self convert input bow infer true file home user sjha anaconda envs conda env lib python site package gensim model wrapper ldamallet py line convert input check output args cmd shell true file home user sjha anaconda envs conda env lib python site package gensim utils py line check output raise error subprocess calledprocesserror command home user sjha project topic modeling mallet bin mallet import file preserve case keep sequence remove stopwords token regex input tmp f corpus txt output tmp f corpus mallet infer use pipe tmp f corpus mallet returned non zero exit status content directory also seems like file get modified every time load model could possible error source kind bug gensim mallet wrapper,,2019-07-09 20:43:17,gensim mallet bug fails load saved model,python gensim lda topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
17963,17963,51762199,2018-08-09 08:27:39,,help correct way accomplish task,2018-08-09 09:06:56,2018-08-09 17:29:16,add vocabulary pretrained word vec model,machine-learning nlp data-mining gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17967,17967,51800210,2018-08-11 13:40:14,,training word vec model using gensim word vec well known wikipedia dump provided tobias schnabel following link http www c cornell edu schnabts eval index html gb would like understand many epoch run model training model converged added following code however see model converging undersatnd loss function result reducing stay quite constant around,,2018-08-11 17:30:11,gensim word vec model converged,gensim word2vec loss-function,,,CC BY-SA 4.0,False,False,True,False,False
17971,17971,51707594,2018-08-06 12:24:26,,try integrate gensim kera model first text preprocessing convert text token sequence convert word gensim word index padding value build model apparently problem padding value default value gensim word vec use non existing value fails following error message right way use padding gensim word vec would appreciate help,2018-08-06 12:46:37,2018-08-06 12:46:37,use padding value get kera embedding,keras gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
17976,17976,51747613,2018-08-08 13:09:31,,given got word vec model gensim want get rank similarity word example let say word desk similar word desk table chair book pencil want create function f desk book since book rd similar word desk doe exists efficient way,2018-08-08 17:54:18,2018-08-08 17:54:18,word vec get rank similarity,python python-3.x nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17997,17997,51791964,2018-08-10 18:11:40,,implementating word vec python facing unexpected scenario related depreciation question exactly depreciation warning respect similar word vec gensim python currently getting following issue deprecationwarning call deprecated method removed use self wv similar instead model similar hamlet futurewarning conversion second argument issubdtype deprecated future treated np issubdtype vec dtype np int please help curb issue help appreciated code tried follows,2020-09-29 09:45:14,2020-09-29 09:45:14,deprecationwarning gensim similar,python python-3.x gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
17998,17998,51792916,2018-08-10 19:23:44,,started learning word embeddings gensim tried code article visualisation say need pca convert high dimensional vector low dimension parameter size word vec method set size equal rather using pca tried compare graph one size size got different result confused size depicts size vector affect got used size got used size,,2018-08-10 20:23:23,parameter size mean gensim model word vec sentence size,python nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
18006,18006,51754634,2018-08-08 19:54:03,,currently running lda dataset dataset consists approximately k document document approximately long wikipedia article ran lda topic fine topic coefficient turn nan tried every combination numpy gensim version two different computer get result absolutely idea solve problem please let know info need since asked code snippet line lda changed number worker normally used,2018-08-11 14:50:05,2018-08-11 14:50:05,gensim lda coefficient nan topic,python gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
18033,18033,51900688,2018-08-17 17:54:43,,spacy ha great parsing capacity api intuitive part way spacy api fine tune word embedding model particular would like keep spacy token give vector possible thing come across train embeddings using gensim know load embeddings spacy gensim load back spacy http www shanelynn ie word embeddings python spacy gensim help first part training spacy token help appreciated,2018-09-14 21:23:59,2018-09-14 21:23:59,fine tune spacy word embeddings,python-3.x gensim spacy,,,CC BY-SA 4.0,False,True,True,False,False
18034,18034,51903087,2018-08-17 21:27:50,,made annoyindexer running similar query find nearest neighbour vector dimensional vector space code wondering returned value distance taken away divided surely largest smallest distance messed,,2018-08-17 22:12:21,understanding similar method annoyindexer gensim similarity index,python nlp gensim word2vec annoy,,,CC BY-SA 4.0,False,False,True,False,False
18058,18058,51945520,2018-08-21 09:23:24,,hello community member present implementing word vec algorithm firstly extracted data sentence break split sentence token word remove punctuation mark store token single list list basically contain word calculated frequency word computed occurrence term frequency result list next trying load model using gensim however facing problem problem code snippet whatever tried follows note using python window suggested use sentence split token apply build train model question apply corpus single list containing word specified word also using list e word training model,2018-08-21 09:25:28,2018-08-21 17:22:36,word vocabulary corpus word shown single list gensim library,python-3.x nltk gensim word2vec nltk-book,,,CC BY-SA 4.0,True,False,True,False,False
18120,18120,51985536,2018-08-23 12:11:20,,using gensim doc vec implementation thousand document tagged four label training doc vec model list taggeddocuments however sure infer tag document wa seen training see infer vector method return embedding vector get likely label idea would infer vector every label calculate cosine similarity vector vector new document want classify way go get vector four label,2018-08-23 12:18:34,2018-08-23 19:11:05,gensim doc vec infer label,python nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
18122,18122,51988701,2018-08-23 14:56:05,,trying implement word vector model set word given using code however getting error,2019-01-25 12:43:36,2019-01-25 12:43:36,implementing word vector model using gensim,python-3.x machine-learning gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
18123,18123,51851193,2018-08-14 23:55:08,,seen post say average word vector perform better task doc vector learned pv dbow relationship document vector average sum word vector say vector approximately equal average sum word vector thanks,,2018-08-15 03:59:17,doc vector learned pv dbow equivalent average sum word vector contained doc,machine-learning nlp gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
18124,18124,51854220,2018-08-15 06:56:45,,trained gensim word vec model let say certain vector want find word represents best way meaning specific vector want get word,2018-08-15 07:23:55,2020-09-17 00:34:34,word vec find word specific vector,python-3.x nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18130,18130,52038651,2018-08-27 11:48:18,,cause loss increase epoch code used training output loss epoch wrong language arabian input dociter list token,2019-12-19 00:06:53,2019-12-19 00:06:53,loss doe decrease training word vec gensim,python gensim word2vec loss,,,CC BY-SA 4.0,False,False,True,False,False
18132,18132,51956153,2018-08-21 20:21:09,,used code http datascienceplus com evaluation topic modeling topic coherence find topic coherence dataset tried code number topic got new value running example number topic got following value running first run number topic coherence score cv coherence score uma second run number topic coherence score cv coherence score uma reason unstable case trust library highest coherence value changed well,2019-04-14 22:09:30,2019-04-14 22:09:30,gensim lda coherence value reproducible run,gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
18133,18133,51958011,2018-08-21 23:30:50,,use case hr department provide free text set plain text ask come salience score based job description relevance consists skill required minimum qualification wa considering doc vec bit confused train model collate job description create corpus querying profile text give incorrect result moreover job requisition transient nature profile might match expired requisition since job description exclusive shall create trained model job better framework please advise please see code,2018-08-27 18:48:07,2018-08-27 18:48:07,using doc vec find salience score resume based job description,nlp gensim doc2vec information-extraction,,,CC BY-SA 4.0,False,False,True,False,False
18142,18142,52080365,2018-08-29 14:47:33,,downloaded fasttext model use follows would like continue training model adapt domain checking fasttext github gensim documentation seems like currently feasible appart using person proposed modification yet merged missing something,,2019-07-08 02:55:06,continue training fasttext model,python gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
18150,18150,52061585,2018-08-28 15:33:05,,trying train model training get small vocabulary length containing alphabet letter could get right vocabulary update tried got wrong vocabulary size,2018-08-29 01:37:35,2018-08-29 01:37:35,wrong length gensim word vec vocabulary,nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18158,18158,52102961,2018-08-30 18:01:55,,question around measuring calculating topic coherence lda model built scikit learn topic coherence useful metric measuring human interpretability given lda topic model gensim coherencemodel allows topic coherence calculated given lda model several variant included interested leveraging scikit learn lda rather gensim lda ease use documentation note would like avoid using gensim scikit learn wrapper e actually leverage sklearn lda research seemingly scikit learn equivalent gensim coherencemodel way either feed scikit learn lda model gensim coherencemodel pipeline either manually converting scikit learn model gensim format scikit learn gensim wrapper seen wrapper way around generate topic coherence manually calculate topic coherence scikit learn lda model countvectorizer tfidf matrix done quite bit research implementation use case online seen solution lead documented equation scientific literature anyone ha knowledge similar implementation could point right direction creating manual method would great thank side note understand perplexity log likelihood available scikit learn performance measurement predictive read,2018-08-30 19:49:03,2019-04-14 15:45:50,lda topic model performance topic coherence implementation scikit learn,scikit-learn nlp gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,True
18171,18171,52009779,2018-08-24 18:11:54,,found explicit usage sentence whether contain old corpus,2018-08-24 20:59:18,2018-08-24 21:10:06,necessary mix old corpus new corpus updating word vec model,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18183,18183,52139386,2018-09-02 17:21:53,,code list article dataset raw ha article run code face error keyerror u word business vocabulary original code work great data set http github com derekgreene topic model tutorial could help error,2018-09-02 19:15:44,2018-09-02 19:15:44,gensim raise keyerror word vocabulary word,python nlp gensim word2vec topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
18208,18208,52012579,2018-08-24 22:49:37,,instead construct one single document mycorpus txt frame dictionary multiple document one going mb file size file please aware trying construct dictionary without loading text memory via gensim,,2018-08-26 22:51:07,gensim contruct dictionary without loading text memory gensim,python bigdata gensim,,,CC BY-SA 4.0,False,False,True,False,False
18222,18222,52144567,2018-09-03 06:56:40,,large corpus word extracted document corpus word might mean eg command order mean apple apply doe mean would like merge similar word say command order command tried use word vec check semantic similarity word ouputs good similarity apple apply since four character word try using wup similarity give good similarity score word matching synonym whose result impressive could best approach reduce semantically similar word get rid redundant data merge similar data,,2018-09-03 09:01:12,reduce semantically similar word,python-2.7 gensim word2vec text-analysis redundancy,,,CC BY-SA 4.0,False,False,True,False,False
18233,18233,52125136,2018-09-01 05:26:57,,followed step gensim python http radimrehurek com gensim wiki html train wikipedia lda model want compare arbitary article cnn com example trained data need next suppose article txt file,2018-09-01 05:53:43,2018-09-02 16:50:53,training lda wikipedia corpus tag arbitary article,python nltk gensim,,,CC BY-SA 4.0,True,False,True,False,False
18235,18235,52126539,2018-09-01 08:53:27,,trained word vec gensim kera want use make matrix sentence using word embedding storing matrix sentence space memory inefficient want make embedding layer kera achieve used layer lstm tell detail p different question using gensim word vec training instead kera,2018-09-01 09:25:02,2019-08-06 11:30:57,using pretrained gensim word vec embedding kera,python keras gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
18247,18247,52072855,2018-08-29 08:26:50,,found warning follows remove warning,2018-08-29 08:31:29,2019-04-11 07:36:17,remove gensim warning use word vec gensim matutils py,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18250,18250,52077016,2018-08-29 12:04:58,,created lda model text file using gensim package python want get topic distribution learned model method gensim ldamodel class solution get topic distribution model example use coherence model find model best cohrence value subject number topic range getting best model use get document topic method thanks kenhbs get topic distribution document used creating model best ha topic use get document topic get le value document distribution question best lda model topic using coherence model document get document topic return fewer topic document topic small distribution le e,2018-09-03 10:35:00,2019-12-31 11:21:32,extracting topic distribution gensim lda model,gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
18273,18273,52220514,2018-09-07 10:24:05,,would like pas vector input model vector type example run code get error read post issue due different data type input array case data type update code,2018-09-07 10:39:47,2018-09-07 15:29:15,typeerror ufunc add contain loop signature matching type dtype,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18292,18292,52184439,2018-09-05 11:49:19,,k file combined total million word wanted topic modelling using gensim similar tutorial lda requires one tokenize document word create word frequency dictionary file read panda dataframe content column ha text following create list text image dataframe attached however running memory error large word count also tried tokenvectorizer python got memory error handle tokenizing really long document way processed lda analysis gb desktop matter edit since python wa unable store really large list actually rewrote code read file originally stored html convert text create text vector append list sent lda code worked,2018-09-06 12:24:38,2018-09-06 12:24:38,handling memory error dealing really large number word million lda analysis,python out-of-memory gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
18294,18294,52116717,2018-08-31 13:38:43,,used lda corpus entry got good result inserting line corpus relaunching lda quite different topic however line represent corpus normally result change looked something sensitivity stability lda model seen pretty sensitive parameter level doe anyone know anything script first result list topic topic order mail received back always share refund answer topic cancel order wish possible wish would wish advance error item deceived topic keep current informed delivery order informed product inform face number topic faulty wooden box present box side level painting defect box add line corpus topic change topic big top metal big size damaged product chandelier canape support topic receipt ordered article product miss well order send back topic faulty wooden box present box side level painting defect box topic order payment amount spend transfer made pay bank come well understand algorithm sensitive stability change much add line,2020-06-20 09:12:55,2018-08-31 15:37:39,sensitivity stability lda model,python scikit-learn gensim lda,,,CC BY-SA 4.0,False,False,True,False,True
18304,18304,52131011,2018-09-01 18:23:27,,want understand work reference tell setup py file mention anything else doe flag executes setup py file step involved also see project using command like doe mean value placeholder defined somewhere folder name specific write find example usage reference,,2018-09-01 18:23:27,pip installing dependency using pip install e,python-3.x pip gensim,,,CC BY-SA 4.0,False,False,True,False,False
18325,18325,52252119,2018-09-10 06:22:37,,skip gram word vec training sample obtained follows word give next pair training etc every word cbow w v use reverse approach word get pair difference skip gram word vec cbow w v training gensim library specify target word training cbow mode case pair word used,,2018-09-10 19:24:58,difference skip gram word vec cbow w v training gensim library,python machine-learning nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18332,18332,52170784,2018-09-04 16:47:18,,gone thread specified lda memory proportional numberofterms numberoftopics case two datasets dataset k document around k term easily able run topic dataset b around million document k term got filtering able run till topic throw memory exception wanted understand number term topic matter memory number document causing problem quick workaround avoid note know corpus wrapped around iteratable specified memory efficient lda training using gensim library let assume already loaded corpus memory restriction keeping input data different format run different platform different algorithm point able run lesser number topic loading whole corpus memory workaround help run number topic example wa thinking adjusting chunksize might help work,,2018-09-04 16:47:18,lda gensim oom exception large corpus,python gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
18333,18333,52171195,2018-09-04 17:17:04,,two way load pretrained word embeddings compiled c python self trained embeddings python loaded go load word dictionary way would pretrained embeddings third party error since doe method load,,2018-09-04 17:46:25,gensim self trained embedding load,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
18337,18337,52286330,2018-09-12 01:44:58,,working gensim library train data file using doc vec trying test similarity one file using method always get result almost difference logic file similarity result inaccurate code training model output result file txt file txt file txt file txt file txt file txt wrong could improve accuracy result,,2018-09-12 17:23:05,inaccurate similarity result doc vec using gensim library,python nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
18353,18353,52364632,2018-09-17 09:30:43,,according http code google com archive p word vec wa recently shown word vector capture many linguistic regularity example vector operation vector paris vector france vector italy result vector close vector rome vector king vector man vector woman close vector queen try simple demo running demo analogy sh try supplied demo script please note input hint demo suggest problem unable reproduce behavior open word vector try compute vector example word analogy actually reproduce,2018-09-17 09:39:55,2018-09-17 20:09:53,operation behind word analogy word vec,python gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
18373,18373,52277384,2018-09-11 13:43:28,,build two word embedding word vec model using save word vec word vec using command two different corpus two corpus somewhat similar similar mean related like part part book suppose top word term frequency occurrence two corpus word let say compute degree similarity extracted top word say two word vec model doe work case efficiently want know much degree similarity doe word related two different generated model idea deeply appreciated,2018-09-11 16:11:07,2018-09-12 01:15:31,calculation cosine similarity single word different word vec model,python-3.x gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
18383,18383,52297260,2018-09-12 14:12:38,,pycharm find gensim listed anaconda list anaconda list see gensim doe exist project interpreter using paython version problem library problem gensim installation anyone ha advice appreciate thanks,2018-09-12 14:31:18,2018-09-12 14:31:18,gensim recognized pycharm,python python-3.x pycharm gensim,,,CC BY-SA 4.0,False,False,True,False,False
18406,18406,52425323,2018-09-20 12:36:04,,checked unsupervised clsutering gensim fasttext sklearn find documentation cluster text data using unsupervised learn without mentioning number cluster identified example sklearn kmneans clustering provide n cluster case text automatically identify number cluster cluster text reference article link much appreciated,2018-09-21 10:37:41,2018-09-21 10:37:41,unsupervised clustering technique identify number cluster,tensorflow scikit-learn gensim unsupervised-learning fasttext,,,CC BY-SA 4.0,False,False,True,False,True
18421,18421,52391572,2018-09-18 17:11:22,,trying use text corpus file one sentence line extarct word co occurrence order use later traitement extract word statistical co occurrence large corpus file using gensim use later,2018-09-18 21:20:35,2018-09-18 21:20:35,gensim extract word co occurrence,python nlp gensim word2vec corpus,,,CC BY-SA 4.0,False,False,True,False,False
18424,18424,52397065,2018-09-19 02:14:15,,would like load file extension name gensim normal code would would like auto open file bin example bin file news bin file bin guess bin long load extension thank,,2018-09-19 02:29:22,load file extension name,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18431,18431,52415929,2018-09-20 00:42:39,,wish use variable like model ha trained certain sentence gensim example use gensim word vec train sentence find vector another function save variable called model create another function get vector word return code follow way pas variable function def gen named model function def name tried use self working wanted call variable dont want build another extra function link,,2018-09-20 01:09:28,possible call variable another function another function,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
18433,18433,52379317,2018-09-18 05:07:41,,would like ask word vec currently trying build program check embedding vector sentence time also build feature extraction using sci kit learn extract lemma lemma lemma sentence understanding feature extraction lemma lemma lemma word embedding vector embedded character achieved using gensim word vec tried explanation sentence pen word token sentence example feature extraction pen lemma lemma lemma lemma lemma lemma pen try extract feature using one hot produce word embedding word vec pen pen tokenized word vec gensim produced matrix example using window size produced floating integer number explanation purpose original data vary depending sentence dummy data explain question understanding word vec correct yes difference feature extraction word vec curious whether use word vec get feature extraction embedding since understanding word vec find embedding word feature hopefully someone could help,,2018-09-18 17:52:20,word vec word sentence feature well,word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18449,18449,52401067,2018-09-19 08:06:31,,able extract topic lda model using gensim print topic displaying topic number word default want show word one topic tried change still getting word per topic change default behavior code printing topic,,2018-09-19 09:01:46,change default number word lda,python python-3.x nlp lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
18450,18450,52402693,2018-09-19 09:34:49,,generate non english french spanish italian word embedding english word embedding best way generate high quality word embedding non english word word may include samsung galaxy,,2018-10-17 14:21:49,non english word embedding english word embedding,tensorflow nlp gensim word-embedding chainer,,,CC BY-SA 4.0,False,False,True,False,False
18451,18451,52525990,2018-09-26 21:02:56,,new deep learning trying make basic lstm network word embedding feature written following code model unable run error getting searching found people used compress feature dense layer unable fix issue explaining kindly let know dimension work upon request x training dimension issue providing code clear confusion think following code giving numpy array initializing way objective use gensim pretrained model lstm comment,2018-09-27 07:27:23,2018-09-27 09:40:08,lstm network pre trained word embedding gensim,python machine-learning deep-learning lstm word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
18458,18458,52486070,2018-09-24 19:26:58,,using following code get ordered list user post however also getting vector use find nearest neighbour like th place list mistake code issue gensim becuase vector neighbour edit doc vec model training code,2018-09-25 03:55:50,2018-09-25 03:55:50,gensim similar doc vec give vector output,nlp data-mining gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
18460,18460,52488877,2018-09-25 00:10:37,,using gensim doc vec would find distance many thanks,,2018-09-25 01:11:51,finding distance doctag infer vector gensim doc vec,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
18462,18462,52469352,2018-09-23 19:04:52,,edit asking spent hour experimenting package feel though gotten nowhere pretty new python done randomforestclassifier model successfully organization model production neural net beyond current comprehension working text classification problem python sample row taken job posting one column string sentence one column job posting came gunning promotion work thought would neat opportunity learn neural network going data scientist type role fascinates sample one job duty job posting document job posting one job posting could multiple duty nearly identical every job posting identical abstracted duty ultimately assume cluster duty job posting essentially desired output classify row regardless job posting came think document column relevant n cluster expect label cluster cleaned sample removing punctuation stopwords dataframe package experimented far kera doc vec word vec nltk soundex way cluster sample unsupervised without training data need upload corpus train doe corpus default classification label simplest willing sacrifice accuracy get n cluster sample go content cluster determine label cluster post processing vaguely directional guidance would really help,2018-09-23 19:20:06,2018-09-23 19:55:41,python nlp neural network text clustering,python tensorflow keras nltk gensim,,,CC BY-SA 4.0,True,False,True,False,False
18488,18488,52460163,2018-09-22 19:31:45,,using pre trained model google word embedding kind string give model receive array full zero need pad sentence need array zero embed padding maybe create array zero instead model,,2018-09-22 19:31:45,pad token google news word vec pre trained model,python gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
18498,18498,52514911,2018-09-26 09:54:01,,gensim installed system summarization gensim want find similarity sentence showing error sample code given downloaded google news vector error traceback recent call last file home abhi desktop chiir clustering summarization idea final version sentence embedding py line model gensim model keyedvectors load word vec format data googlenews vector negative bin gz binary true nameerror name gensim defined,,2019-01-27 07:04:25,nameerror name gensim defined doc vec similarity,similarity gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
18540,18540,52584376,2018-10-01 03:56:34,,able build model using built lee background corpus try compare using similar method get error tried list inferred vector still getting error typeerror numpy float object iterable trying compare dummy text corpus find entry already exist data file update instead list inferred vector need use inferred vector ha solved problem ever time run code get different similar document possible sometimes get list list keep changing everytime run code even change model matter fact first line training corpus similar line word changed surprisingly document id nowhere top list,2018-10-01 04:36:58,2018-10-01 05:42:01,compare document using similar method,nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
18564,18564,52752804,2018-10-11 05:28:03,,trying load fasttext file use word embedding first time also tried described http datascience stackexchange com question load fasttext pretrained model gensim still result downloaded bin file kaggle http www kaggle com kambarakun fasttext pretrained word vector english still issue want use bin file vec file take le time,2018-10-11 14:24:10,2018-10-11 14:24:10,fasttext unicodedecode issue,python machine-learning word2vec fasttext,,,CC BY-SA 4.0,False,False,True,False,False
18574,18574,52734146,2018-10-10 06:43:12,,working nlp application corpus text file would like create word vector using gensim word vec algorithm training testing split trained model appropriate set would like ass accuracy model testing set surfed internet documentation accuracy assessment could find method allowed doe anyone know function doe accuracy analysis way processed test data wa extracted sentence text file test folder turned giant list sentence used function though wa right one turn gave error typeerror know handle uri went idea fix last part please help thanks advance,,2019-07-29 09:11:07,word vec gensim accuracy analysis,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18579,18579,52693004,2018-10-07 21:18:10,,sample document hand coded certain type content like find similar document already hand coded using gensim doc vec quite figure best way code look like figure right way go forward something doc vec end like ranked list document first one similar document thanks help might spent lot time reading gensim help document various tutorial floating around able figure edit use code get document similar short sentence way modify instead get document similar coded document love learn,2018-10-07 21:30:30,2018-10-22 19:04:54,doc vec similarity coded document unseen document,python nlp gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
18586,18586,52618479,2018-10-03 01:28:32,,would like print vector word using gensim word vec code however list comprehensive method wont work also tried still dont work could anyone please tell print every word vector without using loop way want line print part still clear please let know,,2018-10-03 01:39:31,loop element print word vec vector based element,python printing word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18596,18596,52757683,2018-10-11 10:20:39,,hello word vec model generated using word vec java implementation dl j saved calling output zip file contains bunch txt file successfully load use model dl j using trying read model python using get following error also tried binary true get result extract model generated dl j get following file way read model python,,2018-10-11 18:15:45,loading dl j trained word vec model gensim,python gensim word2vec dl4j,,,CC BY-SA 4.0,False,False,True,False,False
18606,18606,52724444,2018-10-09 15:22:01,,new ml field trying hand creating model predict semantic similarity two sentence using following approach using word vec model gensim package vectorise word present sentence question calculate average vector word every sentence document next calculate cosine similarity two average vector reference stackoverflow question calculate sentence similarity using word vec model gensim python help needed following challenge want create model would predict semantic similarity two sentence quite sure model would best suited problem next importantly train model create matrix row contain two sentence sen sen would vectorise calculate cosine similarity per mentioned approach training data x train avg vector sen sen cosine similarity value train prediction set binary value similar cosine similarity otherwise quite confused whether approach correct put proper approach form working codebase internet material available online teacher learn ml thus requesting guidance help clearing gap understanding help coming good working model problem,,2020-02-07 11:42:14,need help creating appropriate model predict semantic similarity two sentence,python machine-learning nlp data-modeling word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18616,18616,52707075,2018-10-08 17:07:49,,training doc vec model multiple tag includes typical doc id tag also contains label tag category trying graph result get doc distribution using largevis able color different tag problem vector model return exceed number training observation making difficult align original tag vector training model parameter idea whether additional observation shift order vector whether appended end want avoid using string tag doc id preparing code use much larger dataset found explanation google group http group google com forum topic gensim odvqkwuadl explained using multiple tag per doc result type output however able find way avoid correct forum documentation,,2018-10-08 18:37:04,align graph multiple tag doc vec returning item doctag syn training data,python machine-learning nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
18617,18617,52686366,2018-10-07 07:28:40,,train save gensim word vec model one enviroment work perfectly another get error attributeerror get attribute word veckeyedvectors module gensim model keyedvectors c user anaconda new envs isp env lib site package gensim model keyedvectors py guess might package version issue figure idea thanks,,2020-06-05 17:46:41,get attribute word veckeyedvectors,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18626,18626,52645618,2018-10-04 11:31:10,,trained word vec model huge corpus using gensim tried find gender bias word vec model neutralizing bias specific professional word referred following link gender de biasing http datascience enthusiast com dl operation word vector html de biasing neutralizing word new vector specific word returned possible take new vector existing word retrain previous model please let know technique thanks regard aimc,,2018-10-04 11:31:10,retrain existing word vec model new word vector,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18631,18631,52743468,2018-10-10 15:13:01,,trying train gensim sgns model process measure loss calculating however noticed change worker thread get different loss keeping parameter especially keep worker thread get really high loss increase thread get le loss instance,,2018-10-10 17:38:48,effect increase worker thread gensim word vec,multithreading gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18640,18640,52762875,2018-10-11 14:42:14,,trying keep output topic modeling stable using mallet library gensim however found mallet set random seed see parameter gensim set,,2019-04-19 21:08:20,set random seed topic model using mallet gensim,python gensim topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
18646,18646,52725193,2018-10-09 16:08:38,,research found gensim ha script convert glove word vec glove wrod vec looking opposite simple way convert using gensim library,2018-10-09 18:40:03,2018-10-19 11:53:53,convert word vec glove format,python nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
18651,18651,52876014,2018-10-18 14:12:45,,trying find best hyperparameters trained doc vec gensim model take document input create document embeddings train data consists text document label e x found question related trying solution proposed supervised model none unsupervised like mine code training doc vec model need suggestion proceed find best hyperparameters trained model using gridsearch suggestion technique help much appreciated,2018-10-18 14:35:55,2018-10-23 08:00:51,gridsearch doc vec model built using gensim,machine-learning gensim grid-search doc2vec hyperparameters,,,CC BY-SA 4.0,False,False,True,False,False
18665,18665,52817087,2018-10-15 12:44:07,,gensim example github http github com rare technology gensim blob develop doc notebook doc vec wikipedia ipynb provides example end find simalarities phrase keywords like lady gaga machine learning however looking find similarity actual document plain text file could done suppose text file located local laptop txt format,2018-10-15 13:26:00,2018-10-16 02:11:40,document similarity doc vec,python nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
18683,18683,52895284,2018-10-19 15:13:31,,using gensim lda topic modelling need get topic distribution corpus individual document let say document belongs different category let say doc category training lda model overall document want see dominant topic category following image illustrates dataset aim far think two approach sure either sane happy know better way first approach concatenate document category one large document large document hence document able retrieve topic distribution another approach might getting topic distribution document without concatenating document hence category document topic distribution get dominant topic category may sum probability topic get highest scored topic sure approach right would suggest,,2018-10-21 17:50:12,overall topic distribution corpus individual document,nlp data-science gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
18687,18687,52861807,2018-10-17 18:55:52,,trying make model gensim library using python spyder also want incorporate wiki corpus code shown getting following error code wa github link http github com lasseregin gensim word vec model blob master train py suspect something simple sort could please advise,2018-10-17 19:02:29,2018-11-01 18:41:05,gensim doc vec exception attributeerror str object ha attribute decode,python python-3.x gensim,,,CC BY-SA 4.0,False,False,True,False,False
18691,18691,52914701,2018-10-21 11:14:26,,try get started gensim library goal pretty simple want use keywords extraction provided gensim german text unfortunately failing hard gensim come keywords extraction build build textrank result look good english text seems work german simple installed gensim via pypi used box well ai product usually driven model guess gensim come english model word vec model german available github page stuck find way summarization module gensim provides keywords function looking work external model basic question load german model get keywords german text thanks,,2018-10-21 13:10:32,gensim keywords load german model,nlp keyword gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18694,18694,52919299,2018-10-21 19:57:40,,messing around gensim got print top topic popular noun associated topic wa done using example topic distribution clustering using lda working document case difficulty getting last two cluster work keep receiving list index range error completely clueless change could make fix cluster method attempted using else condition gave incorrect first cluster spot commented exactly going wrong,,2018-10-21 19:57:40,topic distribution problem clustering document using lda,python nltk gensim lda,,,CC BY-SA 4.0,True,False,True,False,False
18696,18696,52785462,2018-10-12 18:48:56,,implementing python facing unexpected scenario related lead nonetype object subscriptable error screenshot full stack trace follows exactly issue gensim python code tried note model work perfectly comment line shown code,2018-10-13 08:44:10,2018-10-13 08:44:10,gensim error nonetype object subscriptable training fasttext,python python-3.x nltk gensim fasttext,,,CC BY-SA 4.0,True,False,True,False,False
18702,18702,52840791,2018-10-16 17:16:54,,installed gensim window command conda install c anaconda gensim environment py trying run python script using import statement error idea done,,2018-10-17 11:23:40,importerror module named gensim,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
18703,18703,52842474,2018-10-16 19:11:06,,trying build doc vec model using gensim sklearn perform sentiment analysis short sentence like comment tweet review etc downloaded amazon product review data set twitter sentiment analysis data set imbd movie review data set combined category positive negative neutral next trinaed gensim doc vec model data obtain input vector classifying neural net used sklearn linearreggression model predict test data three data set unfortunately result good expected tutorial seem focus one specific task classify amazon review twitter sentiment manage find anything general purpose one share thought,,2018-10-16 21:35:58,data set doc vec general sentiment analysis,dataset artificial-intelligence gensim sentiment-analysis doc2vec,,,CC BY-SA 4.0,False,False,True,False,True
18704,18704,52845345,2018-10-16 23:35:08,,trying implement following code however keep getting error calledprocesserror command c mallet bin mallet import file preserve case keep sequence remove stopwords token regex input c user joshua appdata local temp corpus txt output c user joshua appdata local temp corpus mallet returned non zero exit status previously wa able execute code laptop directory yet doe execute pc currently running python could someone please let know wrong,,2019-04-02 17:54:16,lda mallet calledprocesserror,python-3.x gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
18714,18714,52827465,2018-10-16 03:14:54,,using lda corpus arxiv abstract category stats ml problem lot overlap topic whether pick topic every topic ha distribution word like model algorithm problem topic considered differentiable many prominently feature term using pyldavis wa instructive distribution topic turn actual nature topic emerges ml medical application question could uncover distinctive term course training lda model without pyldavis also doe performance opposed interpret ability model improve get ignore common non discriminating term several idea try would like guidance filtering common term dictionary think helped bit sure right approach tweaking parameter goal ultimately take new document word coloring based word relate topic also offer document similar input document pretty new first question totally base something please let know thank,,2018-10-16 03:14:54,limit lda topic term distinct,python gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
18746,18746,52938047,2018-10-22 21:32:25,,hope good day trying instantiate doc vec model implementing following code however return following error c user joshua anaconda lib site package gensim model base vec py userwarning c extension loaded training slow install c compiler reinstall gensim fast training tried resolve installing microsoft visual c compiler noted http wiki python org moin windowscompilers however doe seem help also tried uninstall install gensim wa advised userwarning also help suggestion unfamiliar using c compiler maybe missing something look like work refer line notebook http github com susanli nlp python blob master text classification model selection ipynb thank advance,2020-06-20 09:12:55,2019-05-03 22:55:14,doc vec c compiler user warning,python-3.x visual-c++ nlp anaconda doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
18757,18757,53037373,2018-10-29 00:39:53,,ran code output wa supposed since occurs two document removed however case missing something,2018-10-29 00:50:53,2018-10-29 00:57:02,misunderstanding use filter extreme gensim,python python-2.7 gensim,,,CC BY-SA 4.0,False,False,True,False,False
18763,18763,52979374,2018-10-24 23:42:34,,k word embeddings created using gensim originally containing dimension trying visualize within tensorboard projector failed far problem tensorboard seems freeze computing pca first left page open hour imagining wa much calculated nothing happened point started try test different scenario case needed wa time wa trying rush thing following list testing far failed spot computing pca plotted point dimension retrained gensim model could reduce dimensionality reduced tried plotting point e two dimensional point using tensorflow find last saved tensor flow session would mind trying still beginner therefore used couple tutorial get started used sud harsan work far help much appreciated thanks update found someone else dealing problem tried solution provided change anything b thought could something installation therefore tried uninstalling tensorflow installing back luck proceeded create new environment dedicated tensorflow also work c assuming wa something wrong code ran tensorflow basic embedding tutorial check could open projector result guess still go past calculating pca visit online projector example load perfectly help would appreciated thanks,2018-11-02 20:03:05,2019-01-22 19:38:28,tensorboard projector compute pca endlessly,tensorflow pca gensim tensorboard,,,CC BY-SA 4.0,False,False,True,False,False
18770,18770,52893017,2018-10-19 13:08:32,,beginner large body txt file want train doc vec model however trouble importing data python usable way import data used however get list work seem find import text file way used nltk doc vec anywhere tutorial help would greatly appreciated thank,2018-10-19 13:21:41,2018-10-19 16:03:37,gensim doc vec getting txt file taggeddocuments,python gensim doc2vec,,,CC BY-SA 4.0,True,False,True,False,False
18782,18782,52941179,2018-10-23 04:28:28,,using python gensim create word vec million sentence however train model getting three file output extension bin trainables syn neg npy bin wv vector npy addition bin went answer provided multiple model file created gensim word vec give reasoning happens however would like know way convert file normal single bin file,,2018-10-23 09:52:50,gensim creates file extension bin trainables syn neg npy bin wv vector npy addition bin,python-2.7 gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18784,18784,52947708,2018-10-23 11:17:20,,making use hdp implementation gensim infer topic dataset question regarding truncation level way infer appropriate truncation level noticed final number topic dependent value truncation level selected,2018-10-23 13:32:21,2018-10-23 13:32:21,hierarchical dirichlet process inferring truncation level,lda topic-modeling dirichlet hdp,,,CC BY-SA 4.0,False,False,True,False,False
18786,18786,52982761,2018-10-25 06:33:39,,want train word vec fasttext get vector specific dataset model take input file like prepare data word vec run doe word vec model take inter sentence similaarity account e prepare corpus sentence wise,,2018-10-28 23:51:00,prepare data word vec gensim fasttext,python machine-learning gensim word2vec fasttext,,,CC BY-SA 4.0,False,False,True,False,False
18797,18797,53004827,2018-10-26 08:42:37,,understand treat paragraph id new word doc vec dm approach left figure training training output context word model trained suppose want get embedding given new document feed word network average get embedding another way feed gensim trying understand work,,2019-04-06 12:39:48,doc vec prediction average word paragraph id new paragraph,nlp word2vec word-embedding doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
18817,18817,52989568,2018-10-25 12:42:57,,little bit confused comment alpha documentation lda gensim regular gensim ldamodel say one set alpha asymmetric gensim us fixed normalized asymmetric prior topicno topicno num topic right called asymmetric symmetric case see http radimrehurek com gensim model ldamodel html whats default number alpha used mallet far know one choose value http radimrehurek com gensim model wrapper ldamallet html,,2018-10-25 12:42:57,lda gensim mallet documentation alpha,gensim lda mallet dirichlet,,,CC BY-SA 4.0,False,False,True,False,False
18820,18820,53030121,2018-10-28 09:37:13,,using google app engine standard flex enviroment python need load pre trained model gensim word vec kera lstm need load since slow take around second keep faster access several hour best fastest way thanks,,2018-10-28 13:48:45,load file google app engine standard enviroment,python google-app-engine keras gensim google-app-engine-python,,,CC BY-SA 4.0,False,False,True,False,False
18846,18846,53015716,2018-10-26 20:13:05,,pretty new topic modeling gensim still trying understand many concept trying run gensim lda model corpus contains around tweet created streaming corpus id word dictionary using gensim using num topic chunk size loading tweet time using gensim numpy link corpus id word dictionary http drive google com drive folder frj gjbidqp vc syojrvcqpcesdyoya usp sharing know wrong solve topic diff first hit inf nan start getting topic please help code error receiving,,2018-10-28 23:48:08,gensim lda model topic diff resulting nan,python python-3.x numpy gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
18872,18872,53142322,2018-11-04 15:23:48,,tried reproduce tutorial local machine get used gensim fasttext functionality fasttext gensim library correctly installed calling train method gensim fasttext wrapper get following error note rwxr xr x right fasttext executable help appreciated fix,,2019-11-05 08:32:16,gensim fasttext wrapper return permission error model training,file-permissions gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
18901,18901,53076731,2018-10-31 05:15:59,,trying get score likelihood search query term single document text paragraph score tell much text talking query term tried failed need value likelihood search term text data incorrectly,2019-03-07 15:20:52,2019-03-07 15:20:52,text similarity score using single query single document gensim,python gensim tf-idf,,,CC BY-SA 4.0,False,False,True,False,False
18905,18905,53183341,2018-11-07 03:51:37,,trouble converting fast fasttext vector back word python code take vector especially arbitrary vector proper dimension spit word,,2018-11-07 04:06:36,converting fasttext vector word,python nlp data-science gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
18909,18909,53187257,2018-11-07 10:05:24,,pretty new mysql gensim word vec still learning use working personal project data got web scrapping hard coded used instagram account get hashtag data several post data instagram hashtags trying use data code part working really sure wa trying use method see work trying want use data hashtags got scrapping instagram website value thank,2018-11-07 12:55:55,2018-11-07 13:15:24,use scrapped data website word vec gensim,python mysql gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18913,18913,53159443,2018-11-05 17:38:13,,list sentence want perform action two sentence time al sentence example tried receive following error besides error maybe better way,2018-11-05 17:45:28,2018-11-05 17:45:28,nested loop list dynamically create variable,python python-3.x for-loop gensim,,,CC BY-SA 4.0,False,False,True,False,False
18914,18914,53160763,2018-11-05 19:16:19,,working text classification use case text basically content legal document example company annual report w etc different category document total therefore document per category dataset consists row column st column consisting text nd column target built basic model using tf idf textual feature used multinomial naive bayes svc linear sgd multilayer perceptron random forest model giving f score approx wanted see creating word embedding help improve accuracy trained word vector using gensim word vec fit word vector ml model getting score small dataset lot category problem reason something missing,2018-11-05 20:02:46,2019-06-04 18:37:54,word embeddings perform poorly text classification,nlp word2vec text-classification word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
18928,18928,53130024,2018-11-03 09:26:21,,trying train library facing issue setting path corpus code error filenotfounderror errno file directory nltk data corpus brown checked brown corpus data present path know one another way train gensim word vec nltk brown corpus follows want know method work feel free drop thought,,2018-11-03 09:26:21,trouble training gensim word vec nltk brown corpus,python nltk gensim word2vec,,,CC BY-SA 4.0,True,False,True,False,False
18930,18930,53130738,2018-11-03 11:10:38,,running code python latest gensim library jupyter http github com rare technology gensim blob develop doc notebook doc vec wikipedia ipynb,2018-11-04 03:31:10,2018-11-05 14:09:27,gensim example typeerror str int error,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
18939,18939,53192902,2018-11-07 15:46:16,,using online lda perform topic modeling task using core code based paper original online lda paper hoffman blei bach online learning latent dirichlet allocation nip code available http github com blei lab onlineldavb using train set document code generates lambda file output use generate topic http github com wellecks online lda python printtopics py sure use find topic new test data similar model get document topic gensim please help resolve confusion,2018-11-09 05:01:25,2018-11-09 11:04:01,using online lda predict test data,python algorithm lda topic-modeling dirichlet,,,CC BY-SA 4.0,False,False,True,False,False
18958,18958,53247197,2018-11-11 08:57:45,,want measure similarity sentence use sklearn euclidean distance measure semantic similarity sentence read cosine similarity also someone explain difference measure best approach use,,2018-11-14 13:07:54,doe euclidean distance measure semantic similarity,scikit-learn gensim euclidean-distance cosine-similarity sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,True
18968,18968,53195906,2018-11-07 18:49:45,,working project using word vec gensim part code moment getting error file stored output result data got web scrapping really sure need fix thank advance,2018-11-07 19:07:52,2018-11-07 19:07:52,getting init got unexpected keyword argument document error python working word vec gensim,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18972,18972,53227410,2018-11-09 14:16:51,,import gensim load google pre trained word vec model output print weight embedding layer kera currently printing empty list,2018-11-09 14:29:10,2018-11-09 14:29:10,print weight kera embedding,keras gensim,,,CC BY-SA 4.0,False,False,True,False,False
18980,18980,53249919,2018-11-11 14:54:07,,want get cosine similarity sentence tested doc vec gensim trained sentence given code want train model using text document one sentence per line use document sentence,,2018-11-11 15:33:01,import document sentence train doc vec model,python gensim cosine-similarity doc2vec sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
18985,18985,53281744,2018-11-13 13:10:21,,supposed exercise python glove give problem supposed find similar word norway war peace glove wiki gigaword package run code say word vocabulary guessing kind formatting know use,,2018-11-13 13:25:11,glove similar multiple word,python nlp gensim glove,,,CC BY-SA 4.0,False,False,True,False,False
18988,18988,53265028,2018-11-12 15:12:41,,code convert word vector code output possible encode array vector word yes implement python,2018-11-13 06:17:04,2018-11-13 06:17:04,python data encoding vector word,python machine-learning nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
18997,18997,53301916,2018-11-14 13:56:33,,know gensims model one access embedding matrix attribute also seem work glove model recently loaded think also seen somewhere previously found doc string wondering logic behind embedding matrix would generally doe stand,2018-11-14 19:21:24,2018-11-16 07:12:51,python gensim meaning syn syn norm,python deep-learning nlp gensim word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
19003,19003,53320951,2018-11-15 13:50:25,,trying perform ldatransformer using gensim api want get topic word using following code print topic word received error method use extract word model,,2018-11-15 13:50:25,display topic word using sklearn api gensim,python-3.x scikit-learn gensim lda,,,CC BY-SA 4.0,False,False,True,False,True
19014,19014,53232894,2018-11-09 20:32:30,,folk searched google different type paper blog tutorial etc found anything helpful would appreciate anyone help please note asking code step step rather idea blog paper tutorial problem statement like sentiment analysis used identifying positive negative tone sentence want find whether sentence forward looking future outlook statement want use bag word approach sum number forward looking word phrase going forward near future year etc sure word vec doc vec used please enlighten thanks,,2018-11-10 07:39:21,unsupervised sentiment analysis using doc vec,nlp gensim word2vec sentiment-analysis doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19017,19017,53343027,2018-11-16 17:52:59,,trying use word vec gensim get warning running c user user pycharmprojects firsttest venv lib site package gensim utils py userwarning detected window aliasing chunkize chunkize serial warning warn detected window aliasing chunkize chunkize serial c user user pycharmprojects firsttest venv lib site package gensim model base vec py userwarning c extension loaded training slow install c compiler reinstall gensim fast training c extension loaded training slow installed configure path mingw gcc ada bin mingw gcc fortran bin mingw gcc g bin mingw gcc objc bin sure compiler tested c script know use fast version gensim run script window python thank,,2019-04-22 18:27:40,gensim window c extension loaded training slow,python pip gensim,,,CC BY-SA 4.0,False,False,True,False,False
19035,19035,53286476,2018-11-13 17:24:55,,using glove gensim word vec module use return similarity score entity return way return semantic relationship two entity example given word result relationship something like output desired output,2018-11-13 18:27:15,2018-11-14 10:17:13,way get relationship glove word vec,relationship semantic-web gensim word2vec glove,,,CC BY-SA 4.0,False,False,True,False,False
19050,19050,53313575,2018-11-15 06:23:52,,new python need construct lda project preprocessing step code want get topic distribution doc document get probability topic distribution use output appear get topic distribution doc,2018-11-15 06:45:12,2018-11-15 08:41:01,get document topic distribution document gensim lda,python-3.x gensim lda topic-modeling probability-distribution,,,CC BY-SA 4.0,False,False,True,False,False
19052,19052,53406593,2018-11-21 06:46:19,,trying run simple lda model gensim getting following error tried seem work really sure error thrown suggestion edit restarting anaconda spyder fixed issue,2018-11-21 22:07:55,2018-11-21 22:07:55,attributeerror gensim running lda model,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
19057,19057,53353978,2018-11-17 17:57:54,,new using word embedding want know project model tensorflow wa looking tensorflow website accepts tsv file vector metadata know generate required tsv file tried looking find solution regrading try saving model tsv file format need transformation help appreciated saved model following file load need use word vec model word vec model wv vector npy,,2018-11-17 18:44:41,project word vec model tensorflow,tensorflow gensim word2vec tensorboard,,,CC BY-SA 4.0,False,False,True,False,False
19072,19072,53368915,2018-11-19 05:41:32,,tiny step doc vec training process take word neighbor within certain length called window size neighbor summed averaged concated question window exceed boundary certain doc like neighbor summed averaged concated simply discarded nlp work doc dataset quite short appeciate idea,,2018-11-19 17:18:14,genisim doc vec short doc processed,machine-learning nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19098,19098,53376459,2018-11-19 14:11:13,,model based trained multiple document would like use model infer vector another document want use corpus comparison look similar sentence one introduce us new document vector instead trained corpus currently using compute vector one sentence new document use function list vector obtain ha would like know way compute vector new document allow use function compute similarity one sentence new document sentence introduce individually case implementation gensim allows compute cosine similarity vector new gensim nlp open suggestion provide complete code since project university main part problem pre processing data train model try compute vector new document way try compute similarity new document vector input phrase,2018-11-19 14:28:52,2018-11-20 13:33:34,gensim doc vec model compute similarity corpus obtained using pre trained doc vec model,python nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19110,19110,53430997,2018-11-22 12:26:22,,dataframe containing description would like cluster description based meaning usign challenge document embed row equal dimension vector first training word vector using however bit confused replace full sentence document vector equal dimension workaround repacing word row vector applying pca dimentinality reduction bring vector similar dimension better way though could say something like,,2018-11-23 09:16:07,sentence embed gensim word vec embedding vector,python-3.x gensim word2vec word-embedding doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19121,19121,53417171,2018-11-21 17:02:37,,use gensim lda topic modelling find topic document check similarity document comparing received topic vector document given different number matching topic comparison vector cosine similarity incorrect vector length required related code output vector see vector ha different length possible perform cosine similarity would like output idea tnx,,2018-11-21 19:02:42,fixed size topic vector gensim lda topic modelling finding similar text,python gensim lda topic-modeling cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,False
19127,19127,53503049,2018-11-27 15:34:45,,already trained gensim doc vec model finding similar document unknown one need find similarity value two unknown document training data referenced doc id code vec vec successfully initialized value size vector size looking gensim api example could find method work expecting taggeddocument compare feature vector value value closer text similar,2018-11-27 18:07:13,2020-02-19 16:12:55,measure similarity two document using doc vec,python machine-learning nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19136,19136,53467414,2018-11-25 12:25:40,,trying calculate similarity two document comprised thousand sentence baseline would calculating cosine similarity using bow however want capture semantic difference document hence built word embedding calculated document similarity generating document vector simply averaging word vector document measure cosine similarity document vector however since size input document rather big result get using method similar simple bow cosine similarity two question q found gensim module offer soft cosine similarity hard time understanding difference method used think may mechanism calculate similarity million pair document q found doc vec gensim would appropriate purpose recognized training doc vec requires ram gb size entire document gb would way train model small part like gb entire corpus use model calculate pairwise similarity entire corpus yes would desirable train set size tutorial follow,,2019-01-09 18:30:41,python calculating similarity two document using word vec doc vec,python similarity gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19148,19148,53473868,2018-11-26 01:58:55,,time series dataset therefore time period trained word vec model realigned model however try load aligned word vec model follows get mentioned error error way resolve error attached sample trained word vec model give error testing purpose link http drive google com file ibbugeaubr xznylkzgpt xoesw bo view usp sharing edit mention log program,2018-11-30 04:00:39,2018-11-30 04:00:39,load aligned word vec model gensim,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19151,19151,53493465,2018-11-27 05:46:53,,based article text implemented topic modeling article wa properly categorized dominant topic wa determined want create dataframe show topic percentage article python want data frame look like x row would code based following site http machinelearningplus com nlp topic modeling gensim python see probability list topic every single article,2018-11-28 05:13:36,2018-11-28 05:13:36,construct dataframe lda python,python dataframe lda,,,CC BY-SA 4.0,False,False,True,False,False
19161,19161,53570547,2018-12-01 11:59:55,,using python django ide pycharm imported gensim project however seems like django doe recognize version gensim numpy scipy python following error,2019-05-21 02:39:06,2019-05-21 02:39:06,django recognize gensim,python django numpy pycharm gensim,,,CC BY-SA 4.0,False,False,True,False,False
19174,19174,53449019,2018-11-23 15:06:20,,questioon cossim usage fragment big fuction get following exception please help explain exception mean,2018-11-23 15:07:23,2019-01-29 00:40:18,use cosssim gensim,python python-2.7 gensim,,,CC BY-SA 4.0,False,False,True,False,False
19188,19188,53575141,2018-12-01 21:18:40,,hello new word vec wa trying simple program read file get vec word something wrong tokenization process word vec take account letter word instance file contains hello first trial get error hello vocab use letter h work,2018-12-01 21:24:08,2018-12-02 19:45:46,trying use word vec file working,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19200,19200,53534262,2018-11-29 07:58:10,,use three txt file lda project try separate three txt file two way difference among process document number lda model create rubbish result relatively good result use model train document difference two model document number everything else lda create different result two model,,2018-12-02 05:57:03,document number affect result gensim lda,python-3.x text-mining gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
19206,19206,53587960,2018-12-03 05:29:29,,assume word dictionary fa understand word embedding word vec method aim represent word dictionary vector element represents similarity word remaining word dictionary correct say dimension vector size word vec vector gensim python modify value size parameter word vec let say size case doe size mean extract output vector denoted x x x x x x represent case,,2018-12-03 20:47:17,meaning size word vec vector gensim library,python gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
19226,19226,53536021,2018-11-29 09:45:04,,currently using custom corpus wields tagged document looking source code brown corpus see read directory handle tagging document tested see improvement training speed,,2018-11-29 12:58:10,use taggedbrowncorpus training gensim doc vec,python gensim corpus doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19237,19237,53628382,2018-12-05 08:51:11,,way find similar doc like word vec like know use infer vector feed similar one want feed many positive negative example word vec way thanks,,2018-12-07 01:07:31,find similarity doc vec like word vec,python nlp gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19245,19245,53610331,2018-12-04 10:03:24,,got problem online updating word vec model document build model document update new word need update vocabulary model general know gensim code new word e x wrong solve problem,,2018-12-04 10:33:13,online updating word vec,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19272,19272,53613789,2018-12-04 13:12:53,,study author found word vec generates two kind embeddings http arxiv org ab well easily get using syn attribute gensim word vec case gensim fasttext syn exists concept fasttext sub word based possible get vector word output matrix matching index know way around calculate vector using output matrix,,2018-12-05 01:14:12,get vector output matrix fasttext,word2vec word-embedding fasttext,,,CC BY-SA 4.0,False,False,True,False,False
19278,19278,53616003,2018-12-04 15:15:05,,train doc vec model training part save model work want add sentence vocabulary model e x update model work jupiter urgently shut answer use way word vec model work problem,,2018-12-04 20:25:41,doc vec online training,python python-3.x nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19283,19283,53648464,2018-12-06 09:43:24,,using relaxed word mover distance package compute distance document identify similar document target document word vector compiled using available pacakage python length document vary one word word document duplicated corpus assume distance duplicated short value across different pair document however observe distance identical pair vary close le relevant document even concluded closer identical pair command use follows problem model,2018-12-06 10:16:37,2018-12-06 10:16:37,relaxed word mover distance r,python r gensim wmd text2vec,,,CC BY-SA 4.0,False,False,True,False,False
19293,19293,53618906,2018-12-04 17:59:28,,trying apply word vec model implemented library gensim python window machine list sentence sentence list word input model performing preprocessing computed result obtaining similar word given input word using followed editor getting different result source code executed two editor result need choose specifying screenshot result obtained running code spyder sublime text input word need obtain similar word really confused choose result basis also started learning word vec recently suggestion appreciated result obtained spyder result obtained using sublime text,2018-12-05 10:39:46,2018-12-05 10:39:46,different result gensim word vec model two editor source code environment platform,python python-3.x gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19307,19307,53621737,2018-12-04 21:31:56,,possible retrieve n frequent word gensim model understand frequency count therefore use method need produce list n frequent word model edit tried following initial guess wa use code implement count method sure represents frequent word,2020-03-05 20:56:33,2020-03-05 20:56:33,gensim word vec retrieve n frequent word,gensim,,,CC BY-SA 4.0,False,False,True,False,False
19312,19312,53694381,2018-12-09 16:36:00,,want learn bigram corpus using gensim print bigram learned seen example doe help appreciated,2018-12-09 16:43:54,2020-02-13 20:34:21,print bigram learned gensim,python gensim n-gram topic-modeling phrase,,,CC BY-SA 4.0,False,False,True,False,False
19318,19318,53767024,2018-12-13 17:17:43,,recently switched gensim main reason wa optimized training process stream training data directly file thus avoiding gil performance penalty used trin doc vec classifying document quite well draw back trained cpu utilized new way cpu utilized model performing poorly according documentation use train method also use epoch count iteration also min aplpha aplha value touched configuration doc vec look issue new set configuration something wrong new version gensim p using corpus case also tried epoch count also smaller number like luck edit first model wa iteration epoch second wa epoch second model make epoch made perform even better since wa longer managing alpha second issue popped providing file line document doc id always corresponding line manage figure could causing seems work fine small corpus find wrong update answer final configuration corpus size gb look like,2019-01-08 17:27:59,2019-01-08 17:27:59,gensim doc vec file stream training worse performance,nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19325,19325,53748921,2018-12-12 18:07:38,,question topic modeling via python gensim library run following code work well come related topic want see topic per document listed csv file shuffle example st topic nd document nd topic st document rd rd one run code shuffle fix get topic per document linked topic directly id author document could listed st column code step step loading data processing step printing topic topic,2018-12-12 22:33:55,2018-12-12 22:33:55,topic modeling gensim python getting topic model according fixed id linked data,python-3.x gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
19331,19331,53455834,2018-11-24 06:43:55,,want predict score sentence text written test method part main method received error error traceback recent call last file home mahsa anaconda envs pytorch env lib python unittest case py line testpartexecutor yield file home mahsa anaconda envs pytorch env lib python unittest case py line run testmethod file home mahsa anaconda envs pytorch env lib python site package nose case py line runtest self test self arg exception test missing required positional argument sent begin captured logging gensim model doc vec debug fast version gensim model doc vec used summa preprocessing cleaner info pattern package found tag filter available english gensim utils info loading keyedvectors object home mahsa pycharmprojects pytorch env project thesis proj glove saved gensim utils info loading syn home mahsa pycharmprojects pytorch env project thesis proj glove saved syn npy mmap none gensim utils info setting ignored attribute syn norm none gensim utils info loaded home mahsa pycharmprojects pytorch env project thesis proj glove saved end captured logging e error mahsa rnn sent classification test traceback recent call last file home mahsa anaconda envs pytorch env lib python site package nose case py line runtest self test self arg typeerror test missing required positional argument sent begin captured logging gensim model doc vec debug fast version gensim model doc vec used summa preprocessing cleaner info pattern package found tag filter available english gensim utils info loading keyedvectors object home mahsa pycharmprojects pytorch env project thesis proj glove saved gensim utils info loading syn home mahsa pycharmprojects pytorch env project thesis proj glove saved syn npy mmap none gensim utils info setting ignored attribute syn norm none gensim utils info loaded home mahsa pycharmprojects pytorch env project thesis proj glove saved end captured logging ran test failed error think test ha argument sent correct error,2018-11-24 09:19:29,2018-11-24 09:19:29,typeerror test missing required positional argument,python pycharm pytest text-mining nose,,,CC BY-SA 4.0,False,False,True,False,False
19344,19344,53788106,2018-12-14 23:21:10,,gensim model like frequency token document automatically evaluated also define tf idf model access tf idf statistic token document however clue count memory friendly number document given word arise sure use value tf idf document frequency evaluate however would like evaluate directly counting process instance first document would like get somenthing like since token arises twice document second,2018-12-14 23:46:59,2018-12-15 10:06:36,gensim python simple way get number time given token arise document,nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
19345,19345,53728556,2018-12-11 16:36:43,,would like train model gensim using news text electronic newspaper pdf format best way extract text pdf file process text ready training sample code,,2018-12-12 08:20:55,extracting text pdf file building model gensim,python-3.x nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
19355,19355,53697450,2018-12-09 22:47:38,,version python tried execute code still error traceback recent call last file c user tmdgu desktop nlp master nlp master ontology construction py line binary true file e program file python python lib site package gensim model word vec py line load word vec format raise deprecationwarning deprecated use gensim model keyedvectors load word vec format instead deprecationwarning deprecated use gensim model keyedvectors load word vec format instead fix code path data wrong,2018-12-10 01:58:24,2018-12-10 21:55:36,error word vec googlenews vector negative bin,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19375,19375,53742400,2018-12-12 11:49:30,,couple year ago previous developer team wrote following python code calling word vec passing training file location output file worked linux asked get running window machine bearing mind know next python installed gensim guessing implement word vec know rewrite code use library rather executable doesnt seem possible compile window box could someone help update code please,2018-12-12 14:06:48,2018-12-19 12:54:14,run word vec window using gensim,python python-3.x gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19380,19380,53852041,2018-12-19 13:15:16,,using lda topic modelling unfortunately data heavily skewed document different category would like category equally contribute lda topic however category ha varying number document one category example hold entire document several category hold document would best approach assign weight category equally contribute topic run lda without topic largely based category hold document corpus exploring sampling would prefer solution directly assigns weight lda,,2018-12-19 13:15:16,assign weight certain document within corpus lda gensim,python-3.x nlp gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
19382,19382,53852871,2018-12-19 14:03:18,,using gensim doc vec train model use infer vector infer vector new document compare similarity document model however reusing document different result way way accurately evaluate similar document search network mention infer vector ha random characteristic time new text vector produced different way solve problem,2018-12-19 16:04:58,2018-12-19 17:05:09,improve reproducibility doc vec cosine similarity,python-3.x nlp gensim similarity doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19394,19394,53837088,2018-12-18 16:15:30,,used gensim build word vec embedding corpus currently converting padded input sentence word vector using gensim model vector used input model drawback using word vector directly without kera embedding layer also currently adding additional one hot encoded tag input token concatenating word vector doe approach make sense,,2018-12-20 15:29:05,embedding v inserting word vector directly input layer,keras deep-learning nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19396,19396,53839662,2018-12-18 19:15:56,,implementing word vec gensim corpus nested list collection tokenized word sentence sentence form sentence list total word token getting meaningful result term similarity two word using model wv similarity chosen value size window min count iter alpha lemmatized word input model vocabulary result incurred default alpha value size window dimension meaningless based used data computing similarity value however higher value alpha give meaningful result term inducing meaningful similarity score two word however calculate top n similar word meaningless doe need change entire parameter used initial training process still unable reveal exact reason model behaves good higher alpha value computing similarity two word used corpus whereas meaningless computing top n similar word score input word case doe diverging towards optimal solution check idea case deeply appreciated note using python window machine anaconda prompt giving input model file tried example sentence list follows scientist time comet activity sublimation carbon dioxide nears ice system inconsistent age system year size collision intelligence system example application filter image motion channel estimation equalization example application filter system nested list list list lemmatized tokenized word preprocessed raw data save file giving input computing lemmatizing token used popular wordnet lemmatizer need word embedding model calculate similarity two word computing similar word given input word getting meaningful score method whereas calculating word word say shown getting desired result guessing model getting diverged global minimum use high alpha value confused dimension size window inducing meaningful result rule regarding compute size window suggestion appreciated size total sentence word specified question result getting without setting alpha edit recent comment result word vec vocab size alpha similarity meaningless le term accuracy getting setting alpha seems meaningful word domain explanation word domain comparing data two domain word get confused word word set injected character start end distinguish two different domain top word along score whereas top word set cosine similarity value word set two different data,2018-12-19 23:37:32,2018-12-19 23:37:32,diverging issue word vec gensim using high alpha value,python-3.x gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
19406,19406,53815402,2018-12-17 12:36:39,,want know effect value alpha gensim word embedding model know alpha default value form radim blog change bit higher value e effect doe allowed change however changed experiment large sized data window min count iter worker result pretty much meaningful word vec model however using fasttext model result bit scattered mean le related unpredictable high low similarity score imprecise result data two popular model different precision doe value play crucial role building model suggestion appreciated,2018-12-17 12:49:10,2018-12-17 18:47:42,value alpha gensim word embedding word vec fasttext model,python-3.x gensim word2vec word-embedding fasttext,,,CC BY-SA 4.0,False,False,True,False,False
19408,19408,53821303,2018-12-17 18:44:42,,working newsgroup dataset using python using countvectorizer using gensim api augmented term frequency tried fitting getting error code running code get error using getnz end like get error,2019-01-19 08:49:08,2019-01-19 08:49:08,augmented frequency newsgroup dataset typeerror int object iterable,python scikit-learn nlp gensim,,,CC BY-SA 4.0,False,False,True,False,True
19418,19418,53765598,2018-12-13 15:54:49,,trained gensim w v model k sentence around k word want calculate perplexity best way k word check proper amount data thanks,,2018-12-13 16:00:59,calculate perplexity word vec model,python nlp gensim word2vec language-model,,,CC BY-SA 4.0,False,False,True,False,False
19434,19434,53791972,2018-12-15 11:34:03,,pair word semantic type word trying compute relatedness measure two word using semantic type example word king type man word queen type woman use gensim word vector similar get queen king man woman however looking similarity measure vector represented king man woman queen looking solution way calculate vector representative king man woman calculating similarity two vector using vector value gensim way calculate simple mean projection weight vector e king man woman,2018-12-15 11:44:35,2018-12-15 20:37:47,similarity measure using vector gensim,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19438,19438,53796806,2018-12-15 20:04:58,,using gensim doc vec learn feature news article successfully train document however struggle retrieve document vector model processing example code directly taken gensim documentation correctly train without error try use directly iterate like get error reason fix thanks advance,,2018-12-15 20:18:28,gensim doc vec keyerror tag seen training corpus invalid,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19449,19449,53862627,2018-12-20 04:59:23,,word vec model using pre trained googlenews vector negative bin model work fine get similarity two word example want use list element instead word example suppose list name tag first two element first row culture friendship tag culture tag friendship use following code give error tag list error,2018-12-20 05:16:46,2018-12-20 05:17:38,use list word vec similarity,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19455,19455,53930617,2018-12-26 10:16:48,,list co occurences want train word vec model customized loss function best way approach possible set gensim word vec model function example implementation kera must define everything totally scratch thanks,,2018-12-26 10:16:48,customizg loss function word vec,keras nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
19465,19465,53800830,2018-12-16 09:10:49,,code look like define preprocess function using gensim use function appears encode csv file byte like object avoid kind error,2018-12-16 09:13:56,2019-07-11 06:14:19,avoid decoding str need byte like object error panda,python python-3.x pandas gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
19489,19489,53885591,2018-12-21 13:28:12,,convert pretrained fasttext vector gensim model need predict output word method import gensim gensim model import word vec gensim model wrapper import fasttext model wiki gensim model keyedvectors load word vec format wiki ru vec model word vec sentence model wiki typeerror traceback recent call last model word vec sentence model wiki train model corpus anaconda envs pym lib python site package gensim model word vec py init self sentence corpus file size alpha window min count max vocab size sample seed worker min alpha sg h negative n exponent cbow mean hashfxn iter null word trim rule sorted vocab batch word compute loss callback max final vocab callback callback batch word batch word trim rule trim rule sg sg alpha alpha window window seed seed h h negative negative cbow mean cbow mean min alpha min alpha compute loss compute loss fast version fast version def train epoch self corpus file thread id offset cython vocab thread private mem cur epoch anaconda envs pym lib python site package gensim model base vec py init self sentence corpus file worker vector size epoch callback batch word trim rule sg alpha window seed h negative n exponent cbow mean min alpha compute loss fast version kwargs raise typeerror pas generator sentence argument try iterator self build vocab sentence sentence corpus file corpus file trim rule trim rule self train sentence sentence corpus file corpus file total example self corpus count anaconda envs pym lib python site package gensim model base vec py build vocab self sentence corpus file update progress per keep raw vocab trim rule kwargs total word corpus count self vocabulary scan vocab sentence sentence corpus file corpus file progress per progress per trim rule trim rule self corpus count corpus count self corpus total word total word anaconda envs pym lib python site package gensim model word vec py scan vocab self sentence corpus file progress per worker trim rule sentence linesentence corpus file total word corpus count self scan vocab sentence progress per trim rule logger info anaconda envs pym lib python site package gensim model word vec py scan vocab self sentence progress per trim rule vocab defaultdict int checked string type sentence sentence enumerate sentence checked string type isinstance sentence string type anaconda envs pym lib python site package gensim model keyedvectors py getitem self entity return self get vector entity return vstack self get vector entity entity entity def contains self entity typeerror int object iterable,2018-12-21 13:35:41,2018-12-21 14:16:01,convert pretrained fasttext vector gensim model,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19495,19495,53901258,2018-12-23 04:44:30,,using gensim topic modeling training lda model call get document topic new document get topic distribution however document return value empty list code idea could gone wrong,,2018-12-26 23:08:24,get document topic return empty list,python gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
19505,19505,53867257,2018-12-20 10:53:37,,word vec model want change adding additional data beside occurrence word example category predefined po etc thought two way concat metadata word word desk coded desk furniture noun better way opinion create new loss function function co occurrence word co occurrence category co occurrence po etc question better way create new loss function optimize word vec pas parameter gensim word vec need build new word vec model scratch,,2018-12-20 10:53:37,adding metadata word word vec,nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
19507,19507,53971240,2018-12-29 16:22:00,,pre trained word embedding vector different norm want normalize vector model loop iterates word normalizes vector model u huge take much time doe gensim include way faster find thanks,,2018-12-29 18:29:15,normalize vector gensim model,nlp gensim word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
19510,19510,53941291,2018-12-27 07:24:25,,pretrained model english language wikipedia available http wikipedia vec github io wikipedia vec pretrained difference case english wikipedia doe parameter mean training window iteration negative,,2018-12-27 08:45:12,wikipedia model training parameter,machine-learning nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
19538,19538,53929657,2018-12-26 08:53:22,,hi using gensim find similarity document make tf idf document calculate cosine similarity new document calculate similarity document previous document using index tfidf vec way tf idf update new word doe consider similarity calculation solution update tf idf quickly without recalculating whole matrix best solution problem,2019-01-12 10:55:25,2020-08-08 20:50:54,updating tf idf using gensim,python gensim similarity tf-idf,,,CC BY-SA 4.0,False,False,True,False,False
19543,19543,53998446,2019-01-01 19:47:37,,following reproducible script used compute accuracy word vec classifier wrapper gensim problem script work essentially always first word change simply substituted script return valueerror reshape array size shape solve issue e classifier work one word input edit apparently w v wrapper work variable length train input compared v working v version,2019-01-02 09:13:48,2019-01-02 09:36:36,w vtransformer work one word input,scikit-learn gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,True
19550,19550,53955958,2018-12-28 09:02:04,,get frequent context word pretrained fasttext model example word football corpus get list context word try use satisfied,2018-12-28 09:37:09,2019-02-26 21:25:21,get list context word gensim,python gensim word2vec fasttext,,,CC BY-SA 4.0,False,False,True,False,False
19552,19552,53963743,2018-12-28 20:02:24,,generated pyspark word vec model like data used train model relevant important right format successfully yield object need convert model gensim word vec model would go,,2018-12-29 06:51:33,convert pyspark ml word vec model gensim word vec model,pyspark gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19560,19560,53968214,2018-12-29 09:09:09,,working review dataset problem fetch important number time feature reviewed positive negative feature specific product review ex positive great mileage good looking spacious etc negative poor power bad performance software problem etc thing extract best worst thing product used gensim doc vec find top positive negative sentence result good get similar sentence structure similar feather hold,2018-12-29 10:15:35,2018-12-30 06:41:19,feature extraction nlp,python machine-learning nlp doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19578,19578,54089804,2019-01-08 10:26:54,,following code used preprocess text custom lemmatizer function question speed lemmatization process improved large corpus document currently take two hour function seems main bottleneck gensim function quite fast thanks help,,2019-01-08 17:55:53,improving speed preprocessing,gensim lemmatization,,,CC BY-SA 4.0,False,False,True,False,False
19581,19581,54003616,2019-01-02 09:03:17,,use following gensim wrapper train word vector model however try access trained model e output error attributeerror w vtransformer object ha attribute wv somehow access vocabulary model parameter possible wrapper,2019-01-02 09:52:17,2019-01-02 22:37:36,accessing model gensim wrapper,model wrapper gensim,,,CC BY-SA 4.0,False,False,True,False,False
19586,19586,54005055,2019-01-02 10:54:48,,came across error trying apply cross validation paragraph vector model keyerror experimented replacing also tried raw input data instead pre processed text suspect something must wrong format cross validation compared function pipeline work fine also noted worked doe anyone spot mistake,,2019-01-02 11:04:00,cross validation paragraph vector model,scikit-learn transform cross-validation gensim,,,CC BY-SA 4.0,False,False,True,False,True
19595,19595,54078386,2019-01-07 16:40:36,,downloaded google pretrained word embeddings binary file googlenews vector negative bin gz want able filter embedding based vocabulary first tried loading bin file keyedvector object creating dictionary us vocabulary along another vocabulary filter however take long time take long time run sure efficient solution filter step first,2019-01-07 16:45:58,2019-01-07 17:16:25,filtering word embeddings word vec,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
19599,19599,53989210,2018-12-31 15:52:48,,running code run perfectly fine first time show following error restart kernel spyder using ubuntu,2018-12-31 17:35:23,2019-06-25 10:53:49,fix relative import error python gensim summarization,python gensim summarization,,,CC BY-SA 4.0,False,False,True,False,False
19602,19602,54131612,2019-01-10 15:11:13,,struggling implement fasttext fttransformer pipeline iterates different vectorizers particular get cross validation score following code used keyerror ngrams word machine learning useful branding sometimes absent model problem solved sidenote pipeline work fine simply apply defining pipeline instead two fit shown seems like fttransformer integrate well given vectorizers,,2019-01-10 16:45:52,fasttext get cross validation,scikit-learn cross-validation gensim,,,CC BY-SA 4.0,False,False,True,False,True
19606,19606,54060506,2019-01-06 10:11:56,,following script used lemmatize given input column text question print progress lemmatization progress,2019-01-08 10:35:11,2019-01-08 10:35:11,show progress lemmatization,gensim lemmatization,,,CC BY-SA 4.0,False,False,True,False,False
19631,19631,54063448,2019-01-06 16:15:09,,using gensim lda topic modelling using panda dataframe processing getting error typeerror decoding str need byte like object series found need process data using panda input data like one row code,2019-01-08 14:41:07,2020-08-29 02:03:32,error data processing gensim lda using panda dataframe,python pandas dataframe gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
19636,19636,54085239,2019-01-08 04:31:48,,trying convert keyedvector word vec object tsv file code would loop embeddings save tsv file,,2019-01-28 23:48:28,converting keyedvector tsv file,python-3.x gensim,,,CC BY-SA 4.0,False,False,True,False,False
19658,19658,54187308,2019-01-14 18:38:17,,installed gensim python call gensim got error someone help,2019-01-14 21:11:44,2019-01-14 21:11:44,gensim installation python,python-3.5 gensim,,,CC BY-SA 4.0,False,False,True,False,False
19673,19673,54213078,2019-01-16 08:37:46,,large language corpus use sklearn tfidf vectorizer gensim doc vec compute language model total corpus ha document realized jupyter notebook stop computing cross certain threshold guess memory full applying grid search cross validation step even following example script already stop doc vec point way stream line document instead loading full data memory another way make memory efficient read article topic could discover included pipeline example,2019-01-31 19:06:12,2019-01-31 19:06:12,streaming corpus vectorizer pipeline,scikit-learn streaming gensim corpus,,,CC BY-SA 4.0,False,False,True,False,True
19687,19687,54196106,2019-01-15 09:35:24,,call numpy scipy gensim python linux following error,2019-01-15 11:49:44,2019-01-17 01:27:20,error calling numpy scipy gensim python,python python-3.x numpy scipy gensim,,,CC BY-SA 4.0,False,False,True,False,False
19695,19695,54165109,2019-01-13 00:26:23,,vectorizing word different corpus gensim getting result making rethink word vec function understanding wa word vec wa deterministic position word vector space would change training training cat running dog running two sentence corpus value running stem seems necessarily fixed however found value indeed doe vary across model word keep changing vector space train model difference always hugely meaningful indicate existence random process missing,2019-01-13 00:33:25,2019-01-14 20:43:08,stochastic aspect word vec,nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19697,19697,54228660,2019-01-17 03:37:37,,using cosine similarity function gensim module similarity sparsematrixsimilarity want get similarity index document method attribute index know stored len self tfidf vector sim index shape sim index toarray shape also guess sim index,,2019-07-10 02:29:13,stored similarity sparsematrixsimilarity index,gensim cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,False
19709,19709,54287822,2019-01-21 10:21:29,,want extract potential sentence news article part article summary upon spending time found achieved two way extractive summarization extracting sentence text clubbing abstractive summarization internal language representation generate human like summary reference rare technology com followed abigailsee get point summarization pointer generator network summarization wa producing good result pre trained model wa abstractive problem extractive summarizers looked far pyteaser pytextrank gensim based supervised learning naive bayes classifier tf idf po tagging sentence ranking based keyword frequency position etc require training thing tried far extract potential summary sentence get sentence article label summary sentence others clean text apply stop word filter vectorize text corpus using tokenizer vocabulary size pad sequence average length sentence build sqequential kera model train giving low accuracy think model suitable positive negative sentence rather summary non summary sentence classification guidance approach solve problem would appreciated,2019-01-22 02:04:01,2019-01-22 16:41:14,supervised extractive text summarization,python keras nlp nltk text-extraction,,,CC BY-SA 4.0,True,False,True,False,False
19713,19713,54215456,2019-01-16 10:52:02,,problem im using glove pre trained model vector retrain model specific domain say car training want find similar word within domain got word domain corpus believe glove vector expect something like leg room car spacious feature mentioned domain corpus exclude glove vector similar vector thanks,2019-01-17 07:01:51,2019-01-17 07:01:51,gensim pretrained model similarity,python vector nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19720,19720,54202117,2019-01-15 15:38:25,,two version python python python install gensim go python install following comand install python,2020-05-07 03:08:30,2020-05-07 03:08:30,install gensim python,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
19721,19721,54186233,2019-01-14 17:15:22,,generating doc vec embedding panda dataframe following guidance provided given document vector v try infer similar document document vector v concatenateddocvecs model get following error course use simple model infer similar document produced vector embeddings size concatenated vector get list similar document document vector concatenateddocvecs model,2019-01-14 17:22:07,2019-01-15 00:28:37,doc vec infer similar vector concatenateddocvecs,python gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19739,19739,54289583,2019-01-21 12:03:10,,trying train word vec model using gensim line using training text list list string representing word corpus using ha sentence word unique word training word present model model word specified max vocab size missing training word thanks,2019-01-21 16:35:51,2019-01-22 08:41:49,missing word training word vec model,nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19755,19755,54277363,2019-01-20 14:18:14,,trained word vec model english asian language sinhala later phase going use trained model get sentence similarity order detect plagiarism sinhala document please explain measure accuracy trained model university student previous knowledge thing,,2019-01-22 05:20:40,measure accuracy word vec model trained another language,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19757,19757,54279792,2019-01-20 12:49:14,,recently implementing algorithm paper using master work come across problem regarding time taking perform operation get detail want add data set comprehends roughly kk entry data point two list tuples get framework annoy calculates cosine similarity vector every vector dataset final format like algorithm two list name first value tuple two different cosine similarity sum cosine list order array get top n highest cosine value issue taking long actual code implementation following make code faster tried using thread sure make faster getting list problem concatenation sorting thanks english native language sorry misspelling,,2019-01-22 05:38:56,speedup adding two big vector tuples,machine-learning python gensim,,,CC BY-SA 4.0,False,False,True,False,False
19762,19762,54348402,2019-01-24 14:01:22,,creating document vector trained fasttext model computer gensim fasttext far know option create document vector better known paragraph vector pv therefore calculated manually taking average sum word available document task alone take much time want append several numerical feature calculated pv millionen doc take minute create thought process could improved splitting work onto several core computer multiprocessing library python work right certain extent problem solve getting stage since using jupyter notebook execute code place method seperate python script able use mulitprocessing jupyter notebook code available jupyter notebook import module helper ha method create document vector helper py computer core thread however make code work core using core always result error caused using memory ram think caused copy object process seems way create shared memory process access dataframe iterating access text data method called process us dataframe fasttext model object read create pv append value dataframe could merge text dataframe feature dataframe however would still need share least fasttext model object question would possible read several question regarding problem stackoverflow make much maybe need use something different pool,,2019-01-24 14:01:22,shared memory several read object multiprocessing pool,python multiprocessing jupyter-notebook shared-memory gensim,,,CC BY-SA 4.0,False,False,True,False,False
19768,19768,54243797,2019-01-17 20:27:57,,using gensim create word vec model trained large text corpus model based stackexchange data dump also model trained corpus derived english wikipedia assume vocabulary term model model created parameter word vec way combine add vector two separate model create single new model ha word vector would resulted combined corpus initially trained data reason want want able generate model specific corpus process new corpus later want able add information existing model rather combine corpus retrain everything scratch e want avoid reprocessing every corpus time want add information model builtin function gensim elsewhere allow combine model like adding information existing model instead retraining,,2020-05-16 11:17:12,combining adding vector different word vec model,python gensim word2vec training-data corpus,,,CC BY-SA 4.0,False,False,True,False,False
19769,19769,54385850,2019-01-27 07:05:34,,imported package need need run ldamallet model import like run code got error occurred thought imported thing need lda model ran well tried use mallet problem,2019-01-27 07:16:56,2019-01-27 07:16:56,nameerror name gensim defined,python gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
19776,19776,54339299,2019-01-24 04:19:44,,ton text data multiple web page product interested sell customer tried using pre trained fasttext word embedding trained wikipedia give good result classification task probably text data website contains lot technical detail different text data wikipedia would like kind transfer learning word embedding keeping pretrained fasttext word embedding base train custom word embedding web page using kera initialize custom word embedding fasttext pre trained embedding train initialization really help giving better word embedding would prefer solution using kera training word embedding know embedding ha trainable true option sure use framework due recommend kera gensim,2019-01-24 08:53:36,2019-01-24 15:45:52,train custom word embedding web page,python tensorflow keras deep-learning nlp,,,CC BY-SA 4.0,False,False,True,False,False
19807,19807,54431187,2019-01-29 23:28:46,,running following python script large dataset around item currently execution unacceptably slow would probably take month finish least exaggeration obviously would like run faster added comment belong highlight think bottleneck written database function imported help appreciated,,2019-01-30 00:51:24,gensim lda multicore python script run much slow,python mysql gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
19812,19812,54262583,2019-01-18 23:09:39,,loaded pretrained word vec embeddings python dictionary form example element dictionary would like load model gensim similar library find euclidean distance embeddings understand pretrained embeddings typically come bin file loaded gensim dictionary form would load vector model,2019-01-21 12:32:32,2019-11-09 06:41:57,load word vec dictionary gensim,nlp gensim word2vec spacy word-embedding,,,CC BY-SA 4.0,False,True,True,False,False
19818,19818,54432791,2019-01-30 03:02:01,,running ldamulticore python gensim library script seem create one thread error creating lda model like actually asked another question script full script found gensim lda multicore python script run much slow relevant running centos server let know include information help appreciated,,2019-01-30 07:19:06,gensim ldamulticore throwing exception,python gensim multicore lda,,,CC BY-SA 4.0,False,False,True,False,False
19822,19822,54395916,2019-01-28 05:18:12,,using gensim python library work small corpus around press article time let say interested creating cluster article relating news corpus article tokenized detected collocation stemmed fed little dictionary around k token passed though tfidf model finally used tfidf corpus build lsi model corpus help document similarity function gensim wa able get good result wa curious made coherence checking lsi always get value around could seem pretty weak wa wondering interpret coherence value doe value make sense need similarity document index index query full document corpus edit tried different thing text preprocessing splitting document real sentence feeding phrase class generating bigram trigram removing accent case wa able get coherence value around least guess help finding efficient way process raw data,2019-01-30 03:41:31,2019-01-30 03:41:31,good value lsi topic coherence,python gensim topic-modeling latent-semantic-indexing,,,CC BY-SA 4.0,False,False,True,False,False
19835,19835,54362442,2019-01-25 09:34:43,,goal read line inside file replace special character like french character normal character e c work python documentation gensim example work simple sentence like deaccent line read file time get aec code file contains would like get aec,,2019-01-25 19:33:53,use properly deaccent method gensim,python string gensim,,,CC BY-SA 4.0,False,False,True,False,False
19840,19840,54318701,2019-01-23 01:15:31,,like create big gensim dictionary french language try getting better result topic detection similarity text thing like planned use wikipedia dump process following way extract article frwiki yyyymmdd page article xml bz done tokenize article basically converting text lowercase removing stop word non word character done train phrase model article detect collocation stem resulting token article feed dictionary new corpus one stemmed collocated tokenized article per line large size corpus store anything memory access corpus via smart open appears gensim phrase model consuming much ram complete third step sample code way complete operation without freezing computer train phrase model subset corpus,,2019-01-23 05:03:32,train phrase model huge corpus article wikipedia,python nltk gensim collocation,,,CC BY-SA 4.0,True,False,True,False,False
19852,19852,54400712,2019-01-28 11:10:47,,found many similar question none answer problem someone help two legal document need find contextually meaning approach thought use something lstm wherever see get people one two sentence compare want lot doc find similar get head around begin task,,2019-02-04 19:10:42,find semantically similar paragraph two different text file two document,nlp gensim recurrent-neural-network,,,CC BY-SA 4.0,False,False,True,False,False
19857,19857,54422810,2019-01-29 14:03:15,,pretty new gensim trying train first model using word vec model see parameter pretty straightforward easy understand however know track loss model see progress also would like able get embeddings epoch also show prediction also get logical epoch better train iter time save loss embeddings epoch sound efficient much show code still posting,,2019-01-29 14:43:54,tracking loss embeddings gensim word vec model,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19873,19873,54472367,2019-02-01 03:14:39,,tried saving word vec model trained gensim like try get post full traceback help,,2019-02-01 04:08:23,load saved gensim word vec model,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
19875,19875,54476634,2019-02-01 09:34:42,,trying feed sentence list sequentially gensim model word vec generates typeerror token object iterable,,2019-02-01 10:57:26,word vec error token object iterable,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19883,19883,54492390,2019-02-02 11:00:22,,find anything default value parameter gensim fasttext original facebook fasttext implementation,2019-02-02 13:24:38,2019-02-03 06:58:06,default gensim fasttext,gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
19891,19891,54323245,2019-01-23 08:49:50,,trying load saved word vec model file loading throw error reshape array size shape created word vec model initialising word random vector feeding list list vocabulary word gensim running model new title grp panda df synon title str average np array shape column replacing vector pre computed vector value dimension model work well called notebook loading different notebook throwing error thought numpy array dimension case dimension vector please help edit saving using also using able save apparently loading using error error,2019-01-24 05:54:24,2019-01-24 05:54:24,unable load saved gensim model reshape array size shape,python-3.x numpy gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19924,19924,54587140,2019-02-08 06:35:50,,working nlp problem goal able pas data sklearn algos used word vec via python gensim library underlying problem trying solve binary classification series tweet modifying code git repo part code relating tokenization part use gensim sklearn api try vectorize tweet result following error seems part issue gensim expecting fed one word time instead getting entire tweet x train type list first three element list update order remedy tried following produce following error honest one blow mind common word like vocabulary beyond also wondering tweet stray letter throwing error imagine weird jumble letter often pas word cause similar issue,2019-02-08 08:26:08,2019-02-08 08:26:08,parsing list tweet order utlize gensim word vec,python nlp gensim word2vec topic-modeling,,,CC BY-SA 4.0,False,False,True,False,True
19931,19931,54626897,2019-02-11 08:56:14,,got question gensim word vec documentation help example block text sentence like time new sentence like detect situation course word dictionary solution tried find similar word see next word ok otherwise find word mean top answer list get word work thought word sentence training quite similar coordinate top list word word wrong checked solution trained corpus text situation word top list word explanation near word quite similar coordinate word contextual proximity quite similar coordinate second solution using doesnt match take list word report one word furthest average word yes case answer word detect word answer word example explore top word word word see word list sentence word word word normal detect,2019-02-11 09:12:33,2019-02-11 13:32:57,word vec work python,python python-3.x machine-learning nlp word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19936,19936,54554922,2019-02-06 13:36:46,,python created word vec model using gensim library saved local disk want upload file bucket successfully created word vec model using gensim uploading bucket get error link suggest encoding avoiding error applicable word vec vector model created type encoding way could upload file code upload file bucket tried uploading wav file bucket wa sucessful code issue,,2019-02-06 13:36:46,uploading word vec model aws give error,python amazon-web-services amazon-s3 word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19941,19941,54568930,2019-02-07 08:15:14,,im writing script take website url downloads using beautiful soup us gensim summarization summarize text keep getting valueerror input must one sentence even thought text ha one sentence first section script work downloads text cant get second part summarize text create txt file summarized text script run whatever folder py file located,,2019-02-07 09:12:34,fix valueerror input must one sentence error,python-3.x beautifulsoup gensim,,,CC BY-SA 4.0,False,False,True,False,False
19946,19946,54521323,2019-02-04 17:28:50,,protein sequence want doc vec goal one vector sentence sequence sentence sequence class label unique many document share label first tried doc vec gave vector number unique label decided multiple tag get vector sentence ended vector sentence explanation might gone wrong screenshot data screenshot corpus screenshot data,2019-02-04 18:45:41,2019-02-04 19:40:49,get vector document size gensim doc vec,python tags gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
19951,19951,54537417,2019-02-05 15:09:35,,trying rewrite algorithm basically take input text file compare different document result similarity want print output unmatched word output new textile unmatched word code hello force input checked raw document print rank matched document word force matched second document ouput give rank second document hello raw document want print unmatched word hello matched want print unmatched input word wa matched raw document,2019-02-06 08:35:32,2019-02-06 08:35:32,find print unmatched dissimilar word document dataset,python dictionary nltk gensim nltk-trainer,,,CC BY-SA 4.0,True,False,True,False,False
19960,19960,54592261,2019-02-08 12:14:45,,got problem question word vec understand let train model corpus text way corpus gb size let take one line text calculate vector line line vector sum word vector smth like let calculate length vector standard library need word vec yes converting word vector contextual proximity near word found word close meaning similar coordinate want waiting take line text add word dictionary typical line calculate length vector get quite different value calculate vector line without adding uncharacteristic word line dictionary fact value vector adding word quite similar moreover practically getting result understand right line coordinate word quite contextual proximity new word rather different coordinate affect result vector length line new word e x w v model setting problem get necessary result,2019-02-08 12:28:05,2019-02-08 13:46:29,python gensim wrod vec word similarity,python python-3.x machine-learning nlp word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19966,19966,54559615,2019-02-06 17:44:35,,start training word vec model presented warning consider setting layer size multiple greater performance sound neat find reference argument similar documentation increase layer size determine good value,,2019-02-06 18:24:41,layer size gensim word vec,python python-3.x nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19968,19968,54627037,2019-02-11 09:05:05,,trying rewrite algorithm basically take input text file compare different document result similarity want print output unmatched word output new textile unmatched word code hello force input checked raw document print rank matched document word force matched second document ouput give rank second document hello raw document want print unmatched word hello matched want print unmatched input word wa matched raw document,,2019-02-11 14:27:55,find print unmatched dissimilar word document,python scikit-learn nltk gensim,,,CC BY-SA 4.0,True,False,True,False,True
19976,19976,54580260,2019-02-07 18:48:10,,unsure use similar method gensim word vec let say want test tried true example man stand king woman stand x find x thought could method result getting think true documentation read find top n similar word positive word contribute positively towards similarity negative word negatively method computes cosine similarity simple mean projection weight vector given word vector word model method corresponds word analogy distance script original word vec implementation assume take positive example negative example try find point vector space close possible positive vector far away possible negative one correct additionally method allows u map relation two point another point get result cf man king woman x example,,2019-02-07 20:17:27,understanding gensim word vec similar,python python-3.x nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
19992,19992,54684338,2019-02-14 06:23:03,,running tfidf model python return output give pattern value exact word example chose word aaa every different value even though exact,2019-02-14 09:22:21,2019-02-14 19:37:48,tfidf oucomes different exact word,python pandas gensim tf-idf corpus,,,CC BY-SA 4.0,False,False,True,False,False
19994,19994,54684552,2019-02-14 06:42:33,,training lda model gensim lda model converted model gensim mallet via function provided wrapper conversion topic word distribution quite different mallet version return rare topic word distribution conversion output gensim original implementation see wa bug around issue ha fixed previous version gensim using gensim,,2020-03-18 18:26:39,issue topic word distribution malletmodel ldamodel gensim,gensim lda topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
20008,20008,54673964,2019-02-13 15:37:30,,dataframe ha text column splitting dataframe two part based value another column one part indexed gensim similarity model part fed model find indexed text similar involves couple search function enumerate item indexed part toy data fast real data much slow using code example tried converting operation dask dataframes avail well python multiprocessing would make function efficient possible vectorize function,2019-02-13 16:02:56,2019-02-14 06:29:37,make python gensim search function efficient,python python-3.x pandas gensim,,,CC BY-SA 4.0,False,False,True,False,False
20022,20022,54655604,2019-02-12 17:28:57,,would like use pre trained embeddings neural network architecture pre trained embeddings trained gensim found informative answer indicates load pre trained model like seems work correctly also question quite understand feed layer utilise feed token segmented sentence need mapping instance token index found access token vector simply something like doe mean rnn architecture simply load token batch sequence instance doe seem work assuming need convert token index final word vec model true found get index word using word vec model input embedding layer provide tensor sequence sentence consist sequence word example use dummy dataloader cf example dummy rnn welcome,2019-02-12 19:32:26,2019-02-13 08:31:38,expected input torch embedding layer pre trained vector gensim,vector pytorch gensim word2vec recurrent-neural-network,,,CC BY-SA 4.0,False,False,True,False,False
20026,20026,54709178,2019-02-15 12:15:36,,list million sentence contains word running gensim word vec every word taking simple average sentence problem use min count lot word vocab solve intersect vocab array contains word every sentence least one element left intersection return simple average otherwise return vector zero issue calculating every average take long time run whole dataset even splitting multiple thread would like get better solution could run faster running ec r xlarge instance already tried switching doc vec wa way faster result good word vec simple average suggestion different algorithm technique purpose sentence embedding could solve problem would love read,,2019-06-27 05:07:56,handle word word vec vocab optimally,python numpy optimization gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20040,20040,54644228,2019-02-12 06:43:41,,use gensim predict output word function tried word vec load word vec format googlenews vector negative bin binary true wa deprecated well,,2019-02-12 07:51:24,gensim predict output word function syntax,gensim,,,CC BY-SA 4.0,False,False,True,False,False
20047,20047,54675013,2019-02-13 16:27:23,,corpus text preprocessing data vectorized text using gensim word vec understand exactly wrong base took discussion good tutorial predict next word code source code input line sentence want take line take word line predict word using word word predict word end line tutorial time predicts fix length word take first word use generate next second parameter give length sentence tutorial help every time getting output predicted sequence word random opinion length wrong fix,2019-02-15 08:23:57,2019-02-17 05:05:32,pre trained word vec lstm predict next word sentence,python machine-learning keras nlp lstm,,,CC BY-SA 4.0,False,False,True,False,False
20053,20053,54697748,2019-02-14 19:26:53,,need remove invalid word vocab gensim model keyedvectors word veckeyedvectors tried remove using print word disappeared run using word word deleted still appearing similar delete word way affect bring,2019-02-14 19:40:27,2019-04-18 07:55:12,way remove word keyedvectors vocab,gensim word2vec embedding glove,,,CC BY-SA 4.0,False,False,True,False,False
20058,20058,54717449,2019-02-15 21:43:21,,using spacy part topic modelling solution situation need map derived word vector closest similar word vocabulary word vector see gensim ha function wordembeddingskeyedvectors similar vector calculate wa wondering spacy ha something like map vector word within vocabulary nlp vocab,2020-10-14 11:47:10,2020-10-14 11:47:10,mapping word vector similar closest word using spacy,nlp spacy word2vec word-embedding,,,CC BY-SA 4.0,False,True,True,False,False
20064,20064,54736839,2019-02-17 19:29:56,,trained model trying get prediction use return next tried know text number return vector representation way get text label model loading train dataset take lot time try find another way,,2019-02-17 22:16:00,doc vec get text label,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20074,20074,54754669,2019-02-18 20:11:40,,try train model get sentence similarity case name organization use train model get result return strange result test already tried use example train data got similarity example get next result understand get example train data improve result model,2019-02-19 06:31:54,2019-02-20 00:55:19,doc vec strange result model docvecs similar,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20085,20085,54722074,2019-02-16 10:24:22,,trying perform sentiment analysis twitter data using deep learning rnn know various deep learning library like tf kera gensim etc wanted know possible perform deep learning using corenlp library http github com charlescc deep learning sentiment analysis person try compare gensim tensorflow core nlp deep learning barely documentation understand run file dependecies required please help,2019-02-18 04:59:21,2019-02-18 05:31:39,apart kera spacy use stanford core nlp deep learning,deep-learning nlp stanford-nlp lstm,,,CC BY-SA 4.0,False,True,True,True,False
20113,20113,54823225,2019-02-22 08:49:26,,trained lda model cluster topic according knowledge every topic outputted certain probabiliy adding run code getting topic please help lda output top keywords highest prob topic health medical patient cancer hospital said treatment doctor care drug addition probability lda output,,2019-02-28 00:19:49,gensim lda giving output topic id probability adding,machine-learning nlp gensim topic-modeling unsupervised-learning,,,CC BY-SA 4.0,False,False,True,False,False
20126,20126,54842129,2019-02-23 13:29:22,,learning nlp text classification via book text analytics python required several module installed virtual environment use anaconda env created blank env python installed required panda numpy nltk gensim sklearn install pattern first problem install pattern via conda conflict pattern mkl random impossible remove mkl random related package gensim numpy scikit learn etc know find suitable conda installation pattern accepted case installed pattern using pip installation wa successful okay package conda pip time second problem think connected first one downloaded book example code http github com dipanjans text analytics python tree master old first edition source code ch text classification added bracket python x print function run classification py program raised exception understand happening exception raised installation pip problem wrong deprecated code book possible install pattern conda necessary package thank advance,,2019-12-05 09:00:28,pattern module issue nlp learning,python design-patterns pip nlp anaconda,,,CC BY-SA 4.0,True,False,True,False,True
20136,20136,54863236,2019-02-25 09:40:00,,trying extract indonesia title wiki title dump text file using word vec gensim python wiki dump contains title language also symbol code getting error searched online could succeed help appreciated,,2019-02-25 18:56:44,typeerror sequence item expected byte like object str found,gensim word2vec python-3.7,,,CC BY-SA 4.0,False,False,True,False,False
20155,20155,54924835,2019-02-28 11:37:28,,new sagemaker running test measure performance ntm lda aws compared lda mallet native gensim lda model wanting inspect trained model sagemaker look stuff like word highest contribution topic also get measure model coherence able successfully get word highest contribution topic ntm sagemaker downloading output file untarring unzipping expose file params symbol json meta json however try process lda untarred output file unzipped maybe missing something something different lda compared ntm able find documentation also anyone found simple way calculate model coherence assistance would greatly appreciated,,2020-02-17 10:35:04,sagemaker lda topic model access params trained model also simple way capture coherence,python lda amazon-sagemaker,,,CC BY-SA 4.0,False,False,True,False,False
20166,20166,54888490,2019-02-26 15:05:38,,print log file stout loss epoch training phase using gensim word vec model tried saw loss printing,,2019-10-23 04:08:03,gensim word vec print log loss,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20170,20170,54623849,2019-02-11 04:08:38,,similarity score genism similar word function wa reading genism similar word function http radimrehurek com gensim model keyedvectors html similar word function return sequence word similarity definition similarity calculated,,2019-02-11 07:39:27,similarity score gensim similar word function,gensim,,,CC BY-SA 4.0,False,False,True,False,False
20171,20171,54623993,2019-02-11 04:31:22,,following following gensim tutorial transform word vec model tensor link tutorial http radimrehurek com gensim script word vec tensor html specifically ran following command however get following error command use save model mentioned following link http github com rare technology gensim issue use command get following error wondering made mistake syntax commads please let know resolve issue happy provide detail needed,2019-02-11 04:38:09,2020-06-30 20:57:28,use word vec tensor gensim,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20177,20177,54870236,2019-02-25 16:03:52,,tried load gensim code often work fine today get following exception im using python gensim solve problem,,2019-02-25 20:03:46,exception calling gensim,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
20193,20193,54929726,2019-02-28 16:02:09,,new word vec trying cluster word based similarity start using nltk separate sentence using resulting list sentence input word vec however print vocab bunch letter number symbol rather word specific example one letter gensim model keyedvectors vocab object x ab l,2019-02-28 17:57:20,2019-02-28 17:57:20,word vec vocab result letter symbol,python python-3.x tokenize gensim word2vec,,,CC BY-SA 4.0,True,False,True,False,False
20209,20209,54839158,2019-02-23 07:09:09,,trained word embeddings saved npz format trying load keyedvectors format make error load numpy array gensim keyedvectors format really need need use function like similar vector value model py tensorflow saving py main py got also tried got,,2019-02-25 21:18:57,load numpy array gensim keyedvector format,python numpy tensorflow gensim embedding,,,CC BY-SA 4.0,False,False,True,False,False
20236,20236,54878715,2019-02-26 05:02:26,,getting error trying get coherence score topic modelling gensim package error seem syntax related get error googled problem quite bit find problem come fix thanks,,2019-02-26 05:02:26,error coherence score gensim package,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
20243,20243,54950481,2019-03-01 18:39:02,,googled issue find reliable solution source give log v log v time complexity word vec model following parameter vocabulary equal word unique word,2020-07-25 19:07:00,2020-07-25 20:30:20,word vec time complexity,python time-complexity big-o gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20250,20250,54972481,2019-03-03 18:52:54,,working gensim wmdsimilarity followed tutorial pre trained model took second output found implementation calculating wmd word mover distance sure using pre trained w v,2019-03-04 07:10:03,2019-03-04 07:10:03,way calculate gensim wmdsimilarity faster,nlp gensim word2vec sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
20266,20266,54911712,2019-02-27 17:56:52,,may seem like odd question new thought ask anyway want use google news model various different file laptop mean running line different jupyter notebook model word vec keyedvectors load word vec format googlenews vector negative bin binary true doe eat storage noticed storage filling exponentially reason le memory would otherwise close previous notebook running next storage ha gone gb one day thing done computer run google news model similar restarting closing notebook helped big file laptop idea thanks,2019-02-28 11:37:21,2019-02-28 11:37:21,doe google news word vec model take storage every time run,python nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
20290,20290,55028281,2019-03-06 16:50:55,,using loading german file order get vector representation vocabulary word phrase far work fine achieve good result overall familiar clearly model provide vector representation every possible ngram combination ran confusing least issue give quick example model provides representation phrase want get representation get mentioned model obviously ha representation shorter phrase extended one even return representation removed space mio eur mean statement error simply true first example show know ngrams someone explain understand understanding ngrams wrong code thanks advance amos,2019-03-10 00:04:23,2019-03-10 06:12:20,fasttext representation short phrase longer phrase containing short one,python nlp gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
20305,20305,55016629,2019-03-06 06:07:27,,downloaded pretrained word vector file bin facebook http fasttext cc doc en crawl vector html however tried use model happens make error weird thing operates well use old version bin file http fasttext cc doc en pretrained vector html wrong file fix must use bin file need n gram prevent oov solution like use vec file help thank much,,2019-08-10 18:12:36,facebook fasttext bin model unicodedecodeerror,python facebook utf-8 gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
20337,20337,55084361,2019-03-10 04:13:39,,similar enough run,,2019-03-10 06:20:59,access w w matrix gensim word vec negative sampling setting,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
20348,20348,54917218,2019-02-28 01:53:58,,small python pipeline one class clean lemmatizes data return list list string e pas list another class pass data gensim dictionary following code however throw exception code new python checked debug method bowlist list list str,,2019-02-28 02:44:23,python gensim attributeerror list object ha attribute,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
20360,20360,55075312,2019-03-09 08:10:46,,code read review excel file rev column make list list xp like use list model give error typeerror float object iterable know problem thanks got typeerror float object iterable,2019-03-09 08:56:24,2019-03-09 22:49:31,train word vec model using gensim,python-3.x gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20362,20362,55018426,2019-03-06 08:17:24,,recently trained fasttext word embedding sentiment get representation english word however today trial run fasttext module couple chinese word instance output hence really want know fasttext module trained sentiment could thank,,2019-03-07 15:57:35,fasttext word embedding could generate representation word another language,python gensim word-embedding fasttext natural-language-processing,,,CC BY-SA 4.0,False,False,True,False,False
20366,20366,55086734,2019-03-10 10:31:00,,large txt file mg like wan na train word vec model model using file give ram problem dont know feed txt file word vec model code know code ha problem know,2019-03-10 10:37:09,2019-03-10 19:00:33,train gensim word vec using large txt file,python-3.x gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20386,20386,55091094,2019-03-10 18:43:37,,project use python library gensim topic modeling extraction text try load trained ldamallet model classify new unseen text first part loading model sure last line convert ldamallet ldamodel wa way get result second part preparing new data classify result look something like matter text use array result changing,2019-03-10 18:56:35,2019-03-10 18:56:35,correct way load ldamallet model gensim classify unseen document,python gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
20401,20401,55002455,2019-03-05 12:04:24,,may know version lda mallet wrapper ha random seed parameter included code tried version mallet getting typeerror unexpected keyword argument downloading ldamallet py github replacing mallet script bin folder thanks typeerror init got unexpected keyword argument random seed update order random seed parameter work download ldamallet py file github paste python gensim model directory change required mallet wrapper,2019-03-05 17:06:23,2019-03-05 17:06:23,setting random seed lda mallet implementation replicability result,python lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
20417,20417,55169721,2019-03-14 18:30:43,,way infer multiple document time preserve random state model using gensim doc vec function infer vector defined doc word list str document vector representation inferred could find opther option infer multiple document time,,2019-03-15 02:15:17,preserve random state doc vec mode document want infer infering document time,gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20441,20441,55095368,2019-03-11 04:47:00,,running code gensim word vec throwing word vocabulary error let know solution file file txt code output,2019-03-11 04:53:40,2019-03-12 09:15:30,gensim keyerror word good vocabulary,python-3.x gensim,,,CC BY-SA 4.0,False,False,True,False,False
20450,20450,55121095,2019-03-12 12:06:41,,new dl nlp recently started using pre trained fasttext embedding model cc en bin gensim would like able calculate vector vocabulary word splitting word n gram looking vector every n gram could find way export n gram vector part model realize hashed perhaps way necessarily using gensim get insight appreciated,,2019-05-12 20:55:17,fasttext way export ngrams,export gensim n-gram fasttext oov,,,CC BY-SA 4.0,False,False,True,False,False
20456,20456,55230344,2019-03-18 21:32:53,,building lda python using gensim struggling increase number word printed per topic default like topic word advice would greatly appreciated,2019-04-12 22:23:37,2019-04-12 22:23:37,add word per topic lda,python windows gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
20486,20486,55103288,2019-03-11 13:47:51,,obtain specific doc vector value tag like possible index like last case must know matching,,2019-03-11 15:44:16,correct way get doc vector value,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20487,20487,55248396,2019-03-19 19:08:35,,thanks stopping quick question appending stop word select word show data set wa hopping could add gensims stop word list seen lot example using nltk wa hoping would way gensim post code,,2019-03-19 21:15:52,add stop word gensim,python windows nlp gensim stop-words,,,CC BY-SA 4.0,True,False,True,False,False
20496,20496,55238328,2019-03-19 10:07:17,,trying implement embedding layer using gensim word vec loaded data using panda data text type come word vec part keep getting error idea fix much information internet also error related first line shown code finally note cleaned data removed every integer thank edit function problem happens p develop one,2019-03-21 20:19:11,2019-03-21 20:19:11,gensim word vec error embedding layer error,python machine-learning keras gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20509,20509,55288724,2019-03-21 20:24:44,,getting error trying access gensims mallet jupyter notebook specified file mallet folder notebook cant seem access tried routing c drive still get error please help,2019-04-01 16:12:19,2020-04-02 12:06:08,gensim mallet calledprocesserror returned non zero exit status,python windows jupyter-notebook gensim mallet,,,CC BY-SA 4.0,False,False,True,False,False
20525,20525,55309197,2019-03-22 23:51:46,,dataset observation sample following goal predict job sector row based job title firstly apply preprocessing column following however result getting accuracy make lot suspicious especially using instead classifier getting accuracy therefore guess must something wrong apply fix simply dataset relatively small advanced method word embeddings etc require way data,2019-03-25 09:32:48,2019-09-10 14:38:20,doc vec classification poor result,python classification gensim text-classification doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20533,20533,55278701,2019-03-21 10:47:33,,topic modelling harvard library book title subject use gensim mallet wrapper model mallet lda try get coherence perplexity value see good model perplexity fails calculate exception get error use gensim built lda model instead mallet corpus hold document length word averaging document short related part code perplexity coherence score lda gave score without problem model bag word mallet coherence score ask perplexity value get warning nan value app app py lib python site package gensim model ldamodel py runtimewarning invalid value encountered multiply score np sum self eta lambda elogbeta perplexity nan app app py lib python site package gensim model ldamodel py runtimewarning invalid value encountered subtract score np sum gammaln lambda gammaln self eta realize gensim specific question requires deeper knowledge function gensim model wrapper ldamallet malletmodel ldamodel ldamallet hence would appreciate comment warning gensim domain,2019-03-22 15:15:54,2019-07-02 10:16:19,gensim topic modeling mallet perplexity,python gensim topic-modeling mallet perplexity,,,CC BY-SA 4.0,False,False,True,False,False
20535,20535,55291657,2019-03-22 01:38:09,,trained lda model corpus using gensim topic distribution document compare similar two document topic would like summary measure example following topic distribution two document totally topic brevity show first topic largest probability topic order mean topic ha probability doc calculate euclidean cosine distance two vector using summary measure say example doc similar doc doc doc doc similar doc doc topically thank,2019-03-22 13:56:35,2019-04-14 17:15:23,compare topical similarity two document python gensim topic distribution,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
20547,20547,55331731,2019-03-25 05:32:41,,tried load bin embedding file using gensim got error tried method provided gensim rectify error method method method gave error unicodedecodeerror utf codec decode byte xbc position invalid start byte method method gave error unpicklingerror invalid load key xbc,2019-03-25 15:04:06,2019-03-25 15:04:06,error loading bin embedding file using gensim package,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20557,20557,55335354,2019-03-25 10:07:38,,using doc vec basic way far limited success able find similar document however often get lot false positive primary goal build classification algorithm user requirement help user requirement analysis search know really large enough dataset question like help train one set document build vector another go tuning model specifically selecting right number dimension vector space create hierarchical clustering word vector one model create separate word document classification model ground truth unsupervised learning tuning measure quality result finally recommended online resource might cover calling train vector document word document ha column tagged cell row hope achieve set document vector help finding similar user requirement free text hierarchical clustering build navigation existing requirement,2019-03-25 10:54:21,2019-03-25 15:57:29,doc vec beyond beginner guidance,python dataframe gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20565,20565,55262684,2019-03-20 14:06:52,,working sparse matrix abruptly kill kernel exit code happened working gensim us sparse matrix format failure happens multiplying matrix another matrix even using matrix sum matrix wa created using scipy,,2019-03-21 08:03:20,sparse matrix cause segmentation fault exit code,scipy segmentation-fault sparse-matrix gensim exit-code,,,CC BY-SA 4.0,False,False,True,False,False
20567,20567,55263867,2019-03-20 14:58:16,,training using predicting using test corpus like work fine understand prediction actually done using trained model code,2019-07-02 21:43:57,2019-07-02 21:43:57,doe lda latent dirichlet allocation inference gensim work new data,python gensim lda topic-modeling inference,,,CC BY-SA 4.0,False,False,True,False,False
20580,20580,55298609,2019-03-22 11:26:20,,experiencing problem using pre trained fasttext bin model retreived http fasttext cc doc en crawl vector html checking similar vocabulary word return sensible response however checking similar vocabulary word differs one character return gibberish question ha something model using wrong way,,2019-03-22 11:44:46,pretrained fasttext model return gibberish vocabulary word,python gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
20612,20612,55302607,2019-03-22 15:08:47,,using pre trained doc vec model try find similar document sample document give unsupported operand type error give following error,,2019-03-25 03:05:16,gensim doc vec similar give unsupported operand type error,machine-learning nlp gensim word-embedding doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20622,20622,55341145,2019-03-25 15:23:22,,class ha method use prelearned model wa saved class class analogue method get instance gensim model keyedvectors know something another,,2020-03-27 20:44:56,predict output word keyedvectors word vec,python python-3.x gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20629,20629,55424127,2019-03-29 19:10:45,,data set contains search query term id user typed searched query want get user embedding user vec sort thing learn type thing user search previously merged query user id tokenized tagged using tagged function tried using learn embedding kept getting memory error time run want time kera know input data want output show matrix number user dimension embedding,2019-03-29 19:58:37,2019-07-11 14:09:26,input data set doc vec kera train,keras out-of-memory gensim word-embedding doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20631,20631,55373509,2019-03-27 09:15:34,,trying implement python score trained skip gram model pair word figure error integer slice ellipsis numpy newaxis integer boolean array valid index code tried,2019-03-27 10:05:44,2019-03-27 21:01:50,using word vec score sg pair raise python error integer integer boolean array valid index,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20632,20632,55376622,2019-03-27 11:56:23,,trying train doc vec model corpus six novel need build corpus tagged document novel txt file already preprocessed read python using method appears try tag novel using taggeddocument form gensim novel get one tag corpus tagged document ha six element enough train doc vec model suggested split novel sentence assign sentence one tag id sentence one tag id book belongs however trouble since know structure code wa first code e one using novel format however mean corpus tagged document ha six element model ha enough element train instance try apply method target book get completely wrong result sum need help assign sentence book already split book sentence one tag id sentence one tag id book belongs using taggeddocument build corpus train model thanks attention,2019-03-27 14:18:02,2019-03-27 14:18:02,doc vec corpus novel assign sentence novel one tag id sentence one tag id book,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20635,20635,55384167,2019-03-27 18:24:15,,getting repeated line summarizer output using genism python summarizing text document remove duplicate line output summarizer output coming repeated content keep unique line output summarizer input file follows,,2019-03-27 19:09:42,gensim summarization returning repeated line summary text document,python nlp gensim summarization summarize,,,CC BY-SA 4.0,False,False,True,False,False
20648,20648,55343781,2019-03-25 17:49:12,,text file million row wanted convert word vector later compare vector search keyword see text closer search keyword dilemma training file seen word vec form paragraph word ha contextual meaning within file file independent contains different keywords row question whether possible create word embedding using text file best approach searching matching search keyword million text file structure expected result file,2019-03-26 07:47:49,2019-03-26 09:15:17,convert list word text file word vector,python machine-learning nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20651,20651,55304262,2019-03-22 16:44:49,,would like tokenize list string according self defined dictionary list string look like self defined dictionary expected result vitamin c juice organic supplement current code error message got however want simply tokenize vitamin c instead want tokenize based existing word say,,2019-03-25 21:32:33,tokenize string based self defined dictionary,python nlp nltk tokenize gensim,,,CC BY-SA 4.0,True,False,True,False,False
20656,20656,55428777,2019-03-30 06:23:48,,pre trained word vec model like evaluate using corpus way could get raw training loss given model dump file corpus memory,,2019-03-30 21:27:20,get word vec training loss gensim pretrained model,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20669,20669,55485908,2019-04-03 01:52:55,,getting calledprocesserror non zero exit status error run gensim ldamallet model full corpus million document interestingly enough run exact code testing corpus document code run perfectly fine since working fine small corpus inclined think code fine sure else would could cause error tried editing mallet bat file suggested avail also double checked path issue given work smaller corpus full traceback error,,2019-04-12 23:14:50,python gensim ldamallet calledprocesserror large corpus run fine small corpus,python gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
20670,20670,55487124,2019-04-03 04:32:52,,following tutorial http github com rare technology gensim blob develop doc notebook doc vec wikipedia ipynb get part get following error scan vocab doe anyone know fix thanks,,2019-04-03 16:31:38,gensim attribute error trying use pre scan doc vec object,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
20681,20681,55393311,2019-03-28 08:44:39,,gensim us text streaming minimize memory requirement cost performance due endless disk io trick fly copy complete file disk one disk io temporary memory file like keep code recoding list structure great way debugging functionality expected result much faster code background question original code http github com skipgram modern nlp python blob master executable modern nlp python ipynb example code taken phrase modelling section calculating unigrams review unigrams go crucial routine unigrams calculated line requires patience h familiar iterables understand correctly first read actual file disc variable list data process strategy problem obviously line review file reading,2019-04-01 19:38:14,2019-04-01 19:38:14,text streaming gensim,inputstream gensim,,,CC BY-SA 4.0,False,False,True,False,False
20705,20705,55476594,2019-04-02 13:54:58,,trying implement latent dirichlet allocation lda using python gensim also referring lda code website still clear lda python code could someone know lda explain lucid manner according code given also uploading lda formula image wikipedia case lda used analyze collection text document,2019-04-02 14:46:00,2019-04-12 23:29:32,clear python code lda algorithm,python-3.x lda,,,CC BY-SA 4.0,False,False,True,False,False
20709,20709,55545188,2019-04-06 01:53:21,,classic example determining similarity distance word mover distance example http markroxor github io gensim static notebook wmd tutorial html word vec model googlenews vector negative bin obama speaks medium illinois president greets press chicago orange favorite fruit calculated wmd distance distance distance understand similar threshold value vmd distance decide two sentence actually contain almost information maybe case sentence value large reality sentence different decision need made example question sample correct answer student answer addition answer gojomo let postpone identification automatic understanding logic later let consider case two sentence enumeration object property action one object positive way need evaluate similar content two sentence,2019-04-08 04:31:12,2019-04-08 04:31:12,decision text sentence equivalent content,word2vec similarity wmd,,,CC BY-SA 4.0,False,False,True,False,False
20711,20711,55490182,2019-04-03 08:13:51,,user barry anaconda lib python site package gensim model ldaseqmodel py runtimewarning divide zero encountered double scalar convergence np fabs bound old bound old bound hey guy using dynamic topic model gensim package topic analysis following tutorial http github com rare technology gensim blob develop doc notebook ldaseqmodel ipynb however always got unexpected error anyone give guidance really puzzled even thought tried different dataset generating corpus dictionary error like user barry anaconda lib python site package gensim model ldaseqmodel py runtimewarning divide zero encountered double scalar convergence np fabs bound old bound old bound,,2019-04-12 17:43:51,gensim model ldaseqmodel py runtimewarning divide zero encountered double scalar,gensim,,,CC BY-SA 4.0,False,False,True,False,False
20734,20734,55478104,2019-04-02 15:12:48,,downloaded full wikipedia archive gb running thise line code code seem getting past ha running hour understand target file massive wa wondering could tell working expected time complete,,2019-04-02 17:20:24,tell wikicorpus gensim working,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
20740,20740,55622251,2019-04-10 22:40:43,,corenlp determine whether common noun opposed proper noun proper name refers person box need train model task go first looking coreference resolution rather building block coreference definition depends context whereas trying evaluate whether word isolation subset person human example naive attempt use gensim spacy pre trained word vector failed rank engineer two word found following list corenlp promising would work task would access python wrapper thank,,2019-04-11 19:44:51,corenlp tell whether noun refers person,nlp stanford-nlp pycorenlp,,,CC BY-SA 4.0,False,True,True,True,False
20752,20752,55492888,2019-04-03 10:25:59,,working document similarity problem document retrieve vector word pre trained word embedding model average get document vector end dictionary say dict map document collection vector want feed dictionary gensim document get document dict closer could,,2019-04-12 14:26:42,get similar word custom input dictionary word vector gensim,python gensim cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,False
20771,20771,55660598,2019-04-12 23:25:57,,trained doc vec model wikipedia corpus using gensim wish retrieve vector different document wa wondering text processing wikicorpus function used train model e g removed punctuation made text lower case removed stop word etc important wish perform text processing document inferring vector greater consistency accuracy model,,2019-04-13 21:03:07,text processing doe wikicorpus perform gensim,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20781,20781,55592142,2019-04-09 11:46:29,,understand word vector involved training process gensim doc vec dbow mode know disabled default happens set understanding dbow context word predicted directly paragraph vector parameter model dimensional paragraph vector plus parameter classifier multiple source hint possible dbow mode co train word doc vector instance section empirical evaluation doc vec practical insight document embedding generation answer use gensim doc vec pre trained word vector done clarification would much appreciated note dm paragraph vector averaged concatenated word vector predict target word case clear word vector trained simultaneously document vector parameter vocab size word vector space dim,2019-04-10 12:47:23,2019-04-10 12:47:23,word vector co trained paragraph vector doc vec dbow,gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20784,20784,55629368,2019-04-11 09:40:00,,using word embeddings model fasttext via gensim library expand term search basically user write operating system goal expand term similar term like window ubuntu software model work well time ha come improve model external information external information mean oov vocabulary term term good context following example wrote user writes operating system would like expand query general term term built fasttext model window ubuntu software term represent organization company like microsoft apple complete query term operating system query operating system software window io microsoft apple problem company inside corpus present much context link microsoft operating system example extract piece inside corpus read started working microsoft november friend john see contextualize microsoft word good context indeed small recap corpus company term poor context big database company description need would like include company fasttext model set manually word context cloud related term idea,,2019-04-11 13:56:53,add oov term word embeddings model,python machine-learning nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
20789,20789,55612157,2019-04-10 12:05:32,,using spacy want add custom entity model created model word vec gensim using python spacy init model en c myproject gcmodel v gcword vec txt wanted run training custom entity data followed example given documentation run break nlp update call error model wa passed command line ha loaded front wrong thanks,,2019-04-10 12:05:32,spacy model update ner existing model failure,model spacy ner,,,CC BY-SA 4.0,False,True,True,False,False
20808,20808,55665180,2019-04-13 11:57:31,,gensim trained doc vec model document either single word two three word would best way calculate similarity word document standard cosine similarity document better approach comparing small string document first thought could get cosine similarity word word string every word document taking average dont know effective would,2019-04-13 12:54:14,2019-04-13 21:48:53,calculate similarity word couple word compared document using doc vec model,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20835,20835,55649311,2019-04-12 10:10:07,,function input list tokenized sentence assume contains word output would like get however actual output getting adjust code get output,,2019-04-12 10:32:24,return actual token rather empty variable tokenizing,python apply tokenize gensim,,,CC BY-SA 4.0,False,False,True,False,False
20838,20838,55612440,2019-04-10 12:21:27,,trying add pretrained vector training model using fasttext getting error code written python fasttext thought fasttext could add pre trained vector supervised training model typeerror supervised got unexpected keyword argument pretrainedvectors,2019-04-10 12:30:34,2019-04-10 12:30:34,fasttext error typeerror supervised got unexpected keyword argument pretrainedvectors,python gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
20857,20857,55705634,2019-04-16 10:07:28,,training multiple word vec model corpus study variation learned word vector using tutorial reference http rare technology com word vec tutorial suggested default gensim model word vec iterate corpus least twice initialization training iterating number epoch specified since always using corpus want save time initializing providing initialization input successive model done current setting mysentences defined similarly tutorial made slight change order corpus sentence would shuffled initialization,,2019-04-16 21:05:01,speed gensim word vec initialization pre proccessed corpus,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
20870,20870,55520565,2019-04-04 16:07:48,,background given corpus want train implementation word wec gensim want understand final similarity token dependent frequency b corpus context preserved agnostic example may ideal using elaborate problem statement suppose word used different context within corpus b used different context question change frequency corpus ensuring context lost e still used least context original corpus similarity snd b going new distribution across context lead appreciated,2019-04-04 16:14:09,2019-04-04 17:21:20,semantic similarity word b dependency frequency b corpus,python nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
20887,20887,55692700,2019-04-15 15:36:47,,possible apply sentence level lda model using gensim proposed bao datta paper distinct feature make one topic per sentence assumption p different sentence level method typically allow sentence include multiple topic straightforward method treat sentence document apply lda model collection sentence rather document p think reasonable assume one sentence deal one topic thank,2019-04-15 19:36:21,2019-04-15 19:36:21,apply sentence level lda model using gensim,python nlp gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
20889,20889,55764137,2019-04-19 15:25:32,,word list like want load pre trained glove word vector word glove file large fast way tried iterated line file see word list add dict true method little slow also tried loaded whole file instead vector need want method like set word list load,,2019-04-21 01:31:11,load part glove vector gensim,python gensim word-embedding glove,,,CC BY-SA 4.0,False,False,True,False,False
20905,20905,55693826,2019-04-15 16:45:59,,pretrained word embedding using wang vec http github com wlin wang vec loaded python gensim tried get vector word vocabulary obviously get thought adding item vocabulary map oov vocabulary word let say since vocabulary format would simply add item searched item vocabulary output wa something like way add token vocabulary pretrained word embedding loaded gensim avoid keyerror looked gensim doc found http radimrehurek com gensim model word vec html gensim model word vec word vec build vocab seems work update parameter,2019-04-15 18:25:40,2019-04-16 04:57:35,manage keyerror gensim pretrained word vec model,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
20906,20906,55694532,2019-04-15 17:34:08,,trying show learning progress ldamodel every sample found web throw exception throw code found throw currently mostly interested monitoring learning progress eyeball eta would proper way setting callback,,2019-08-26 20:46:28,log epoch gensim ldamodel,python python-3.x gensim,,,CC BY-SA 4.0,False,False,True,False,False
20907,20907,55710967,2019-04-16 14:48:12,,let say trying compute average distance word document using distance compute cosine similarity two document using n similarity however let say new document contain word original model doe gensim deal reading documentation find gensim doe unfound word would prefer gensim count towards average case distance simply return anything something easily delete later compute mean using numpy case n similarity gensim course ha asking document word program classify instance contain unknown word name brand etc want taken consideration classification want know preprocess every document trying classify,,2020-03-19 17:54:08,dealing new word gensim found model,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
20941,20941,55751027,2019-04-18 17:25:33,,word vec file standard format huge item also vocabulary file row word file ha k row want load embeddings word vec file want embeddings word vocabulary file efficient implementation gensim,,2019-04-19 03:36:17,load word vec txt file vocabulary constraint,gensim,,,CC BY-SA 4.0,False,False,True,False,False
20956,20956,55774197,2019-04-20 13:54:20,,facing gensim training problem using word vec model wv vocab getting word trained corpus word one initialization instruction fact many time trying code even official site example work tried saving model many spot code even tried saving reloading corpus alongside train instruction first print statement give right second supposed give len vocab hello world,,2019-04-21 01:27:02,gensim word vec training provided document,python-3.x gensim google-colaboratory,,,CC BY-SA 4.0,False,False,True,False,False
20964,20964,55754594,2019-04-18 22:47:31,,would like use gensim scikit pipeline update corpus created list lemmatized token involves transforming gensim corpus numpy array like seems work sklearn lda run read result need read actual term gensim dict otherwise stuck meaningless feature number however result following code clearly meaningless example result anyone tell wrong,2019-04-19 05:29:32,2019-04-19 05:29:32,python using gensim scikit pipeline,python scikit-learn gensim,,,CC BY-SA 4.0,False,False,True,False,True
20967,20967,55755962,2019-04-19 02:46:54,,trying build fake news classifier quite new field column title en ha title fake news another column called title en target label agreed disagreed unrelated title news column title en agrees disagrees unrelated first column tried calculating basic cosine similarity two title converting word sentence vector ha resulted cosine similarity score need lot improvement synonym semantic relationship ha considered,,2019-04-19 11:29:36,train model result similarity score two news title,nlp classification gensim cosine-similarity sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
20971,20971,55756841,2019-04-19 05:02:37,,struggling training wikipedia dump doc vec model experienced setting server local machine question due ram requires training couldnt find pre trained model except outdated copy python,,2019-04-21 01:12:19,find pretrained doc vec model wikipedia large article dataset like google news,python nlp gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
20976,20976,55738632,2019-04-18 03:14:30,,example already transformed word number one hot coding want use however popped error think directly input one hot coding wonder doe python module satisfy need want input one hot coding vector raw sentence directly word vec model thank much,2019-04-18 03:50:48,2019-04-18 15:30:06,input one hot coding vector raw sentence directly python module word vec word vec,python gensim word2vec one-hot-encoding,,,CC BY-SA 4.0,False,False,True,False,False
20982,20982,55789477,2019-04-22 05:19:09,,used gensim ldamallet topic modelling way predict sample paragraph get topic model using pretrained model use text get topic pretrained model please help,,2019-04-23 23:48:08,predict test data gensim topic modelling,python jupyter-notebook gensim topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
20986,20986,55812580,2019-04-23 13:38:57,,running gensim python window tried installing visual studio mingw tdm gcc uninstalled reinstalled gensim installation also uninstalling reinstalling cython regardless able run c extension stuck slower numpy code sure trouble lie run idea proceed make progress,,2019-05-06 12:04:23,making gensim fast version work window python,python-3.x gensim,,,CC BY-SA 4.0,False,False,True,False,False
20987,20987,55813659,2019-04-23 14:37:45,,hava panda dataframe ha one column conversational data preprocessed following way make one dimensional used well look follows case used however case got error modify data get typeerror given similar question asked considered gensim typeerror doc bow expects array unicode token input single string based first answer tried solution got error second answer someone say input need token already hold furthermore based typeerror doc bow expects array unicode token input single string using gensim corpus dictionary used approach described doe work either,,2019-04-24 15:42:21,input series list consisting different token gensim dictionary,python dictionary nlp typeerror gensim,,,CC BY-SA 4.0,False,False,True,False,False
21010,21010,55815556,2019-04-23 16:23:02,,lda show number word topic default want increase number tried topn num word keywords giving error change default behaviour error,2019-04-25 18:33:33,2019-04-25 18:33:33,change default number word ldamulticore,python gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
21019,21019,55816686,2019-04-23 17:38:56,,thanks stopping wa trying get help graph showing blank following tutorial http www machinelearningplus com nlp topic modeling gensim python build graph coherence score different number topic using ldamallet code data wish looked like pls help,,2019-08-09 23:05:16,coherence graph blank coherence value nan,python graph nan lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
21023,21023,55884548,2019-04-27 20:18:21,,training txt file full text txt contains document trained model wish use similarity method word sentence however since first time using gensim unable get solution want look similarity word try mentioned get error question check similarity entire document read lot question around like one looked documentation still sure wrong,,2020-08-15 12:37:22,gensim doc vec word vocabulary,python nlp gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21025,21025,55923298,2019-04-30 14:37:51,,newbie trying understand model generates simple example output size model defaulted doe item size array represent example first element,2019-05-01 19:36:36,2019-05-01 19:36:36,understanding gensim model inference output,nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
21034,21034,55886735,2019-04-28 03:19:12,,creating seq seq model tensorflow kera input output sentence something like chatbot translator run get array sentence tried thing input well still get error target array array internal array list number mapped word sentence target batch get error look like tried everything use made sentence using following done everything saving bin retrieving using get error enc input dec input target enc input tf placeholder tf float none none n input thanks,2019-04-28 10:12:47,2019-04-28 10:12:47,getting valueerror setting array element sequence passing gensim word vec feed dict,tensorflow word2vec seq2seq,,,CC BY-SA 4.0,False,False,True,False,False
21040,21040,55924378,2019-04-30 15:36:33,,trying train doc vec model using training data finding similarity every document test data specific document test data using trained doc vec model however unable determine currently using however function find similarity every document training data specific document test data tried manually comparing inferred vector specific document test data inferred vector every document test data using return vector dictionary,,2019-04-30 19:40:10,doc vec finding document similarity test data,python machine-learning gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21043,21043,55872853,2019-04-26 18:02:10,,using gensim fasttext word vector return similar word code return problem sole sun english return series word dot like sole sole ecc problem similar return meaningless word edit tried english word vector word sun return impossible reproduce result like relatedwords org,2019-04-26 18:26:57,2019-04-26 21:23:49,gensim similar fasttext word vector return useless meaningless word,gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
21051,21051,55874253,2019-04-26 19:59:51,,trying get word vec work python however dataset large easily fit memory loading via iterator zip file however run get error code doe show dd type string contains correct preprocessed string length somewhere word,2019-04-27 02:04:23,2019-04-27 02:10:47,python gensim word vec give typeerror typeerror object type generator ha len custom dataclass,python machine-learning nlp gensim training-data,,,CC BY-SA 4.0,False,False,True,False,False
21056,21056,55892073,2019-04-28 16:04:49,,want get bigram symbol letter word example word done dog want able find bigram tried using gensim phrase work code expected output nothing output wrong thank,,2019-04-28 17:29:45,gensim phrase find bigram,python gensim phrase,,,CC BY-SA 4.0,False,False,True,False,False
21070,21070,55939511,2019-05-01 16:37:26,,trained gensim doc vec model default word vec training dm get word vector global model model wv vector documentation say word leaf example vector depending document context appear bit confused model wv vector word leaf example vector document used train model may contradictory understand documentation get word vector particular document,,2019-05-01 19:17:18,word vector whole doc vec model v word vector particular document,gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21074,21074,55978013,2019-05-03 23:01:20,,using library node vec based gensim word vec model encode node embedding space want fit word vec object get warning c user lenovo anaconda lib site package gensim model base vec py userwarning c extension loaded training slow install c compiler reinstall gensim fast training one help fix issue please,2019-05-04 04:08:30,2019-10-25 07:18:00,fix c extension loaded training slow install c compiler reinstall gensim fast training,python-3.x jupyter-notebook anaconda gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21089,21089,55936182,2019-05-01 12:19:34,,installed gensim module mac passing following command terminal already many module panda numpy installed able import jupyter notebook without issue importing gensim checked path module installed terminal module able import panda well gensim case get output library framework python framework version lib python site package anyone tell could issue case,2019-05-01 12:28:34,2019-05-01 12:28:34,unable import gensim module ha definitely installed,python python-3.x machine-learning jupyter-notebook gensim,,,CC BY-SA 4.0,False,False,True,False,False
21121,21121,56021542,2019-05-07 11:24:55,,actually working gensim library want get similarity probabilites top similarity provided model trained use get top similar doc looking get probilities top analysis thanks help,2019-05-07 11:48:01,2019-05-07 22:52:14,get similar document doc vec,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21126,21126,56059927,2019-05-09 12:54:42,,trying topic modeling gensim mallet link locate mallet path try assign gensim get error subprocess calledprocesserror returned non zero exit status get prompted update java done hint solve,,2019-08-07 03:03:35,subprocess calledprocesserror trying run mallet gensim,python-3.x subprocess lda topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
21128,21128,55951158,2019-05-02 11:10:59,,understanding batch vanilla gradient descent make one parameter update training data stochastic gradient descent sgd allows update parameter training sample helping model converge faster cost high fluctuation function loss batch vanilla gradient descent set sgd set mini batch gradient descent set usually doe gensim apply sgd mini batch gradient descent seems equivalent want sure setting gensim model equivalent applying sgd,,2019-05-02 17:30:23,gensim word vec apply stochastic gradient descent,nlp gensim word2vec gradient-descent stochastic,,,CC BY-SA 4.0,False,False,True,False,False
21143,21143,56063312,2019-05-09 15:54:42,,trained lda model using framework saved file however model wa saved extra separate file prefix name original file model result four file question whether loading model file automatically load extra separate file whether load file separately e line code load everything load model along extra,2019-05-10 09:01:02,2019-05-10 09:01:02,load gensim ldamodel ha seperate file,python machine-learning gensim topic-modeling,2019-05-10 09:15:22,,CC BY-SA 4.0,False,False,True,False,False
21147,21147,56023167,2019-05-07 12:57:37,,word vec model gensim model keyedvectors load word vec format googlenews vector negative bin gz binary true contains word uppercase produce new model one word word lowercased word would vector source model,,2019-05-08 00:48:03,produce new word vec model existing one,word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21160,21160,56076298,2019-05-10 10:59:45,,trained doc vec paragraph embeddings text document using module python package normally document tagged unique id yielding unique output representation follows see link detail however also tag group document tag order train class representation query number output representation following command question follows trained model class document yielding document vector want map document vector corresponding class tag establish vector associated tag,2019-05-13 09:16:55,2019-05-13 09:16:55,mapping doc vec paragraph representation class tag post training,python gensim word2vec text-classification doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21161,21161,56076714,2019-05-10 11:24:57,,model trained word vec work well would like plot list word entered list written function reused code found get following error message vector added arr valueerror input array must number dimension,,2019-05-13 15:39:16,gensim plot list word word vec model,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21168,21168,56027806,2019-05-07 17:34:08,,thanks stopping directional question built latent dirichlet allocation using gensims mallet wrapper trained model olddataset csv measured coherence using pas newdataset csv topic allocation need guidance might able predict accurately pre trained model allocating newdataset csv coherence score check accuracy pre trained model allocated data set like way track occurrence historical topic detect emergence new topic without training model like say topic olddataset csv whiskey tango foxtrot assign newdataset csv whiskey tango foxtrot accurate allocation might whiskey tango alpha keep running model might miss new topic exists numeric score would measure closely topic adhere newdataset csv would huge time saver thanks stack always save,,2019-05-17 19:45:20,lda detect new emerging topic,python windows machine-learning gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
21171,21171,56045317,2019-05-08 16:36:29,,lsi model stored model getting stored model pkl model pkl projection however try load model loading failing trying look projection file npy idea would happening,,2020-04-03 11:18:36,lsi model fails load model,scikit-learn gensim latent-semantic-indexing,,,CC BY-SA 4.0,False,False,True,False,True
21178,21178,56097390,2019-05-12 08:22:33,,trying implement word vector supervised learning predict sentiment document news article word vec represents word corresponding real number create vector based occurance word document data preprocessing follows applying countvectorizor give word count passed tf idf give word frequency classifier multinomial naive bay applied grid searchcv used tune best model classification clf fit used train model clf predict used predict sentiment sentence passed model give classification report like want apply word vector embedding please suggest implement word vector embedding naive svm http github com akanshajainn sentiment analysis twitter word vec kera http www bonaccorso eu twitter sentiment analysis gensim word vec kera convolutional network,,2019-05-12 08:22:33,apply word vector algorithm naive svm intead tf idf count vectorizor,keras scikit-learn neural-network word2vec supervised-learning,,,CC BY-SA 4.0,False,False,True,False,True
21196,21196,56033651,2019-05-08 04:40:58,,currently working python train word vec model using sentence provide save load model get word embedding every word sentence used train model however get following error keyerror word n chicago bear vocabulary whereas one sentence provided training follows hence would like know word missing vocabulary despite trained word sentence corpus training word vec model corpus sample sentence sentence txt line file containing exactly word stop word saving model tried load different python file within directory saved shown loading saved model bin however end following error way get word embedding every word trained sentence corpus using method suggestion regard much appreciated,,2019-05-08 05:11:44,word missing trained word vec model vocabulary,python tensorflow nltk gensim word2vec,,,CC BY-SA 4.0,True,False,True,False,False
21220,21220,56105853,2019-05-13 04:44:50,,textual data want discover topic ha used trained doc vec large corpus wikipedia inconsistency result better approach discover topic,,2019-05-15 06:22:20,detect topic arbitrary text file data knowing number topic beforehand,python nltk gensim word2vec lda,,,CC BY-SA 4.0,True,False,True,False,False
21221,21221,56106821,2019-05-13 06:29:31,,currently learning gensim doc model python see similarity sentence created model return input word obviously exists training dataset find similar word sentence doe automatically skip word important define sentence simply bug something appreciated could way cover appearing word dataset thanks,,2019-05-13 17:16:54,gensim doc vec model learn word,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21237,21237,56213690,2019-05-20 02:34:12,,new natural language processing found interesting tutorial describes topic modeling available data tutorial source code code provide topic modeling using lda generates k number topic question find document belongs topic cluster like example shown figure wondering something like publish date text aba belongs topic cluster already read post still get answer also tried matlab text analytic toolbox figure yet would great provide help,2019-05-22 18:27:53,2019-05-22 18:27:53,find document belong cluster,python gensim lda topic-modeling natural-language-processing,,,CC BY-SA 4.0,False,False,True,False,False
21245,21245,56128701,2019-05-14 10:47:33,,ndarray word corresponding vector size per word example want create word vec model done saw keyedvectors take file array,,2019-07-28 01:22:04,python gensim create word vec model vector ndarray,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21248,21248,56130065,2019-05-14 12:06:29,,working sentence similarity algorithm following use case given new sentence want retrieve n similar sentence given set using gensim v trained word vec doc vec model result latter outperform word vec trouble performing efficient query doc vec model model us distributed bag word implementation dm used infer similarity using built method wa possible started training data one want query say want find similar sentence among subset training dataset quick fix wa comparing vector new sentence every vector set using cosine similarity obviously doe scale compute load embeddings make lot comparison successfully use word mover distance word vec doc vec get better result doc vec using cosine similarity efficiently query new document set using pv dbow doc vec model method class similarity looking similar approach wmd doc vec cosine similarity,2019-05-15 10:33:15,2019-05-20 18:34:31,perform efficient query gensim doc vec,python gensim similarity doc2vec sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
21249,21249,56082233,2019-05-10 17:23:33,,code output like get value loss function step visualize,,2020-05-19 16:21:26,gensim doc vec get value loss function step,nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21258,21258,56177411,2019-05-16 22:35:37,,assume wikipedia pre trained word vec model train additional corpus small scentences imagine way limit vector search trained corpus example simply find closest word given vector matter part wikipedia corpus trained vocabulary hand word search concept exists tried train based small corpus scratch somewhat work expected course could much powerful assigned vector come pre trained set,,2019-05-20 22:00:37,word vec limit similar vector result trained corpus,nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21278,21278,56148576,2019-05-15 11:44:23,,try run get following error code specifically make work furthermore question error ha asked time however answer seems specific particular case see change code work someone elaborate meaning problem,,2020-04-13 05:10:23,calledprocesserror returned non zero exit status,python gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
21282,21282,56167224,2019-05-16 11:12:27,,really accept every hint following problem want obtain embedding dataset write solution hopefully problem part consider working annotated corpus disambiguate word given sentence thanks wordnet synset id call tag example dataset starting given embedding dimension call n would like build embedding like embedding thought generate corpus word vec starting text sentence replace respective word contain underscore replaced space lemma underscore since every single word annotated simple preprocessing performed remove stopwords punctuation end something like following example corpus example since interested annotated word also generated predefined vocabulary use word vec vocabulary file contains row entry like vocabulary example defined corpus vocabulary used word vec toolkit terminal emulation output problem number word corpus number word predefined vocabulary file even tried python gensim course output think problem word vec consider word format underscore know solve problem hint appreciated thank advance,2020-06-20 09:12:55,2019-05-16 19:36:33,use word vec build sense embedding,python gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
21287,21287,56150678,2019-05-15 13:33:38,,looking solution use something like using want find similar sentence list sentence using nlp tried use e g http spacy io api doc similarity one one loop take long time go deeper would like put sentence graph like find sentence cluster idea,,2019-05-15 13:33:38,use spacy find similar sentence doc,gensim similarity spacy doc2vec sentence-similarity,,,CC BY-SA 4.0,False,True,True,False,False
21295,21295,56236404,2019-05-21 10:33:38,,according doc wikipedia mmap allows process share chunk ram model loaded like take gb ram model loaded like take gb ram observing drastic decrease ram consumption loading multiple model simultaneously work expected model share gm memory,,2019-05-21 18:54:24,mmap flag reduces memory consumption single word vec instance,ram gensim mmap word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21307,21307,56170250,2019-05-16 13:55:25,,window using python anaconda whenever run get error trace back linesentence class last return seen error change error parameter error ignore change line ontology corpus lst file sample problem working afraid result flawed due encoding error ignored solution would approach fine,2019-05-16 15:28:48,2019-05-16 18:18:23,gensim sentence ontology corpus unicode error,python unicode gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21356,21356,56243568,2019-05-21 17:28:54,,goal import gensim python window using python checked running window command prompt installed gensim running checked installation running saw line ran command enter interactive python mode still window command prompt ran line got following output also tried got following output suggestion install gensim window python test gensim,,2020-09-21 16:47:50,modulenotfounderror module named gensim,python python-3.x pip python-import gensim,,,CC BY-SA 4.0,False,False,True,False,False
21367,21367,56292749,2019-05-24 12:30:44,,want tokenize text want add phrase would recognized single token example possible gensim library possible use,2019-05-27 08:42:23,2019-05-27 08:42:23,specify additional token tokenizator,python nlp token tokenize gensim,,,CC BY-SA 4.0,False,False,True,False,False
21369,21369,56367510,2019-05-29 19:45:41,,arabic dialect text classification used word vec train model got far predict new text dialect also looked around found code give error run load trained word vec model note actually another code post wanted use word vec neural network code neural network know make feature got word vec input neural net label output possible connect word vec deep neural net,2019-05-31 23:20:34,2019-05-31 23:20:34,predict word vec,python gensim word2vec text-classification,,,CC BY-SA 4.0,False,False,True,False,False
21370,21370,56369258,2019-05-29 22:17:35,,gensim word vec trained lack vector word although word yuval input model lack vector cause,,2019-05-30 07:03:25,gensim word vec lack vector input word,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21402,21402,56251839,2019-05-22 07:51:27,,edit train corpus spark dataframe built step load parquet format created feed class give gensim lib iterator train corpus end edit wish train gensim doc vec model million news text document model definition first step getting vocabulary end minute logging info end process train model iterator class train corpus last training log never finish remaining thread first time encounter problem even much smaller train corpus usually relaunch entire process vocabulary setting model training go save time wish calculate vocabulary getting place previously succesfully calculated one try train model way save vocab part model load train model directly train corpus,2019-05-23 07:14:11,2019-05-23 07:14:11,way save load vocabulary gensim doc vec model,python pyspark gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21409,21409,56339518,2019-05-28 09:52:26,,using gensim perform cosine similarity bunch document getting segmentation fault could please help resolve issue error trace code,,2019-06-13 08:38:24,getting segmentation fault running gensim cosine similarity function bunch document,python-3.x gensim,,,CC BY-SA 4.0,False,False,True,False,False
21411,21411,56408849,2019-06-01 17:16:13,,used gensim lda topic modeling get associated topic corpus want get top document representing topic document highest probability topic want save csv file format column topic id topic word probability word topic top document topic tried get document topic think best approach task topic lda model get document topic corpus minimum probability per word topic false sure get top document best represent topic add csv file expected result csv file format column topic id topic word probability word top document topic,,2020-03-26 14:18:28,applying gensim lda topic modeling get document highest probability topic save csv file,python csv gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
21435,21435,56444845,2019-06-04 13:23:49,,lately research purpose unsupervised clustering huge text database firstly tried bag word several clustering algorithm gave good result trying step doc vec representation seems working load prepared model work instead training doesnt prove result tried train model k text around word similarity score proposed gensim like working much worse bag word model much worse mean identical almost identical text similarity score compatible text dont connection think decided use model pre trained doc vec model use pretrained model might connection word sorry somewhat long preambula question plug someone provide idea using loaded gensim model http github com jhlau doc vec convert dataset text vector length data preprocesssed stemmed punctuation lowercase nlst corpus stopwords deliver list dataframe file needed code question pas data pretrained model help would appreciated upd output make feel bad train document use medium paper examination medium habit one week must chart daily use medium radio television newspaper magazine film video etc wake radio alarm listen traffic report commuting get news watch sport soap opera watch tv use internet work home read book see movie use data collect journal basis analysis examining information using u gratification model discussed textbook u gratification article provided perhaps carrying small notebook day inputting material evening help stay organized smartphone use note app track medium need turn diary trust tell tell immediately paper whether actually kept one begin medium diary soon possible order give ample time complete journal write paper completed diary need write page paper use medium functional analysis theory say something best understood understanding used u gratification model provides framework individual use medium basis analysis especially category discussed posted dominick article apply concept medium usage expected le medium use cognitive social utility affiliation withdrawal must draw conclusion use analyzing habit within framework idea discussed text article concept must clearly included articulated paper common mistake student make assignment tell medium habit fail analyze habit within context u gratification model must include idea paper similar document use medium paper examination medium habit one week must chart daily use medium radio television newspaper magazine film video etc wake radio alarm listen traffic report commuting get news watch sport soap opera watch tv use internet work home read book see movie use data collect journal basis analysis examining information using u gratification model discussed textbook u gratification article provided perhaps carrying small notebook day inputting material evening help stay organized smartphone use note app track medium need turn diary trust tell tell immediately paper whether actually kept one begin medium diary soon possible order give ample time complete journal write paper completed diary need write page paper use medium functional analysis theory say something best understood understanding used u gratification model provides framework individual use medium basis analysis especially category discussed posted dominick article apply concept medium usage expected le medium use cognitive social utility affiliation withdrawal must draw conclusion use analyzing habit within framework idea discussed text article concept must clearly included articulated paper common mistake student make assignment tell medium habit fail analyze habit within context u gratification model must include idea paper look perfectly ok looking output train document photography garry winogrand would like paper life work garry winogrand famous street photographer also influenced street photography aim towards thoughtful imaginative treatment detail referencescite research material academic essay university level similar document tang dynasty write page essay tang dynasty essay discus buddhism tang dynasty name artifact tang dynasty discus history put heading paragraph information tang dynasty discussed essay show u score similarity two exactly text similar system two like super distinct almost make problematic anything data get similar document use,2019-06-05 08:44:56,2019-06-05 08:44:56,way use pretrained doc vec model evaluate document dataset,python numpy gensim,,,CC BY-SA 4.0,False,False,True,False,False
21442,21442,56363181,2019-05-29 14:41:44,,training ldamallet model python saving also saving training dictionary use create corpus unseen document later perform every action e train model save trained model load saved model infer unseen corpus within console everything work fine however want use trained model different console computer passed prefix training look temp file created model following file created model trained corpus mallet corpus txt doctopics txt inferencer mallet state mallet gz topickeys txt load saved model different console infer unseen corpus created using saved dictionary see temp file created produce following error odd reason load saved model console console wa trained infer unseen corpus like corpus txt updated two new temp file created corpus mallet infer doctopics txt infer idea might issue tried using ldamodel instead ldamallet ldamodel work fine irrespective whether perform whole task console different console snippet code using expectation use function training data save optimum model dictionary saved use function load saved model dictionary create corpus unseen text run model get desired topic modeling output,2019-05-30 13:07:25,2020-08-26 06:51:50,saved gensim ldamallet model working different console,python gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
21446,21446,56309232,2019-05-25 22:30:18,,training phrase model identify bigram large corpus using gensim reload model get following error typeerror float object subscriptable code save model also training like one reload model cain moment using following case get error shown idea tip solve,,2019-05-25 22:30:18,typeerror float object subscriptable reloading gensim model,python nlp save gensim,,,CC BY-SA 4.0,False,False,True,False,False
21450,21450,56341586,2019-05-28 11:48:09,,trying perform topic modelling databricks using gesim wrapper mallet already running code local system sample code already work local system trying execute databricks instance exit following error please note already imported necessary mallet file mentioned directory path exist assuming problem something setting env variable inside databricks unable figure help would much appreciated,2019-05-28 11:51:38,2019-05-28 11:51:38,unable perform topic modelling databricks gensim mallet,python gensim databricks lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
21453,21453,56408959,2019-06-01 17:31:23,,already trained word vec model gensim library example model contains vector word new york however also want train vector word new york transform new york new york train new vector model finally want combine vector vector word new york new york one vector representation word new york save new vector value model try assign new vector model gensim allow assign new value vector model,,2019-06-02 01:06:49,create new vector model gensim,python vector gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21454,21454,56412272,2019-06-02 04:51:47,,use gensim doc vec package train doc vec embeddings would expect two model trained identical parameter data would close value doc vec vector however experience true doc vec trained pv dbow without training word embedding dbow word pv dm pv dbow dbow word e every case word embedding trained along doc vec doc vec embedding vector identically trained model fairly different code update tried suggested gojomo compare difference vector unfortunately even worse second update time finally understood gojomo thing look fine,2019-06-03 17:20:17,2019-06-03 17:20:17,discrepancy gensim doc vec embedding vector,gensim word-embedding doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21467,21467,56431471,2019-06-03 16:44:56,,training word vec model word belongs specific class want embeddings learn difference word within class want learn difference class achieved negative sampling word class target word gensim word vec specify number word negative sample using parameter mention option modify filter sampling function method achieve update consider class like language word different language training data sentence document contains mostly word language sometimes language want embeddings word similar meaning together irrespective language word different language occur together frequently word language embeddings basically group word language together wanted try negative sampling target word word language learns distinguish word within language,2019-06-04 07:44:59,2019-06-04 07:44:59,specify condition negative sampling gensim word vec,gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
21473,21473,56418817,2019-06-02 20:43:08,,following blog trying train doc vec wikipedia corpus using gensim http markroxor github io gensim static notebook doc vec wikipedia html notice output extremely case sensitive example change case input think lower case everything train model however shown link first read input directly suggestion lower case wiki document way used small file size test whether error running code hence reason infer vector sensitive case maybe problem minimum use actual wiki dataset,2019-06-12 00:33:39,2019-06-12 00:33:39,train wiki doc vec wiki case insensitive feature,python-3.x mediawiki gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21474,21474,56418980,2019-06-02 21:11:50,,suppose seq seq model want embedding layer model based research three way train word embedding separately data set download pre trained word embedding use weight embedding weight word data set need embedding layer load weight already trained word word data set create embedding layer set trainable true embedding also embedding trained based task create embedding layer load already trained weight set trainable false case weight get updated please correct im wrong used want know interpretation output code output consider two sequence wa thinking use word embedding lstm transform word sequence embedding expected see vector embedding word vec gensim appreciate someone shed light getting lost thanks,2019-06-02 21:29:54,2019-06-02 23:11:55,word embedding lstm sequence,tensorflow keras lstm gensim word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
21484,21484,56346717,2019-05-28 16:40:18,,would like see similarity list using list like would like see similarity expecting output like,2020-06-19 14:16:10,2020-06-19 14:16:10,calculate text similarity list using countvectorizer tfidfvectorizer,python scikit-learn gensim countvectorizer tfidfvectorizer,,,CC BY-SA 4.0,False,False,True,False,True
21487,21487,56316146,2019-05-26 18:08:18,,trying gauge impact part speech information word vec embeddings obtaining expected result expected po included word vec embeddings perform better machine translation task actually performing worse creating two set embedding corpus using gensim one normal word vec changing token word po gauging difference performance using embeddings seq seq machine translation task evaluating two approach bleu training word vec po embeddings spacy benchmark machine translation model kera tensorflow bleu word vec po approach consistently score word vec point normal word vec embeddings doe anyone know might happening gap reasoning expectation,,2019-05-29 02:03:26,word vec po producing expected result,keras nlp word2vec word-embedding seq2seq,,,CC BY-SA 4.0,False,True,True,False,False
21489,21489,56316903,2019-05-26 19:53:31,,interested calculating similarity vector however similarity ha number many question concerning tf idf cosine similarity indicating value lie wikipedia case information retrieval cosine similarity two document range since term frequency using tf idf weight negative angle two term frequency vector greater peculiarity wish calculate similarity two vector two different word vec model model aligned though fact represent word vector space calculate similarity word word like similarity metric range scientifically sound way map range intuitively would think something like okay sure whether good practice respect actual meaning cosine similarity similarity metric advised reason trying get value data transferred colleague use feature machine learning system expects value intuition wa take absolute value seems worse alternative map opposite identical considering actual meaning cosine similarity though might wrong taking absolute value good approach well,2019-05-28 09:32:48,2019-08-22 08:51:51,cosine similarity,python scikit-learn gensim similarity cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,True
21493,21493,56508631,2019-06-08 17:25:40,,trying create w v model generate train test data used model question generate test data done creating w v model train data,,2019-06-09 18:46:13,creating train test data word vec model,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21495,21495,56421404,2019-06-03 05:05:14,,understanding really doe sample project follows using feature follows want identify outlier document using trained model using document dataset question straight away use document vector code detect outlier need reduce dimensionality vector applying happy provide detail needed,2019-06-03 06:11:28,2019-06-03 06:11:28,use document vector isolationforest sklearn,python scikit-learn gensim outliers doc2vec,,,CC BY-SA 4.0,False,False,True,False,True
21501,21501,56468865,2019-06-05 22:29:49,,relatively new nlp trying create word embeddings trained personal corpus doc trying implement following code create wordembedings sentence list sentence since pas thousand thousand sentence need iterator found solution creator gensim doe work create iterator know get list sentence every document second related question aiming compare document similarity particular corpus always better create scratch word embeddings document particular corpus using glovec word vec amount doc around cheer pre,,2019-06-05 22:29:49,sentence iterator pas gensim language model,python nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
21516,21516,56438104,2019-06-04 05:59:47,,recently started experimenting pre trained word embeddings enhance performance lstm model nlp task case looked google word vec based online tutorial first downloaded word vec used python package query embeddings using following code however noticing many common word found model started wonder something wa awry tried searching embedding repo shown found went tensorflow embedding projector loaded word vec model searched wa question happening wa version word vec downloaded complete gensim unable load word memory therefore omitting,,2019-06-04 17:01:09,word vec word found gensim show tensorflow embedding projector,python-3.x deep-learning nlp word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
21526,21526,56323377,2019-05-27 09:34:45,,trying find similarity document using doc vec gensim train around k document around string type tag tag consists unique word contains sort document model trained using distributed memory method tried dm dbow well dm give better result similarity score compared dbow understood concept dm v dbow know method good similarity measure two document first question method best perform well similarity give similarity score using word vector give similarity score using doc vector doc doc tag index doctags doc doc contains word kind sentence wv n similarity docvecs similarity unseen doc provide different similarity score type document docvecs similarity unseen doc give little bit good result compared wv n similarity wv n similarity sometimes also give good result question difference docvecs similarity unseen doc wv n similarity use docvecs similarity unseen doc find similarity score unseen data might silly question asked docvecs similarity unseen doc provides similarity score tag actual word belonging tag sure please correct wrong convert cosine similarity score probability thanks,2019-05-29 08:04:10,2019-05-29 08:04:10,method dm dbow work well document similarity using doc vec,python-3.x gensim similarity doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21541,21541,56443667,2019-06-04 12:13:17,,importerror import name mean absolute difference tried uninstalling installing,,2020-05-04 15:40:01,error importing gensim package colab,python importerror gensim,,,CC BY-SA 4.0,False,False,True,False,False
21542,21542,56326458,2019-05-27 12:49:24,,trying implement piece code using guidedlda understand format text data need work tutorial code uploads dataset module whereas extracted text data panda dataframe created corpus dictionary using gensim still unable make functional could help explain structure text data sparse array dataset used lda model document term matrix think utilised guidedlda module originally followed tutorial run lda analysis text data http www machinelearningplus com nlp topic modeling gensim python wanting improve wanted use seed topic tailor found tutorial http medium freecodecamp org changed unsupervised lda semi supervised guidedlda e f guidedlda ha giving many error match structure dataset used tried changing corpus array get shape made x corpus structure corpus bow model used dictvectorized tutorial code found http medium freecodecamp org changed unsupervised lda semi supervised guidedlda e f n top word print topic format join topic word code x corpus id word attributeerror list object ha attribute shape x np array corpus x shape shape small tutorial code shape sum receive error print topic format str join topic word typeerror sequence item expected str instance numpy int found also encountered error attempt turn corpus text data kind sparse array resembles document term matrix used tutorial code including valueerror enough value unpack expected got typeerror cast array data dtype float dtype int according rule safe,,2019-05-27 12:49:24,create document term matrix panda nested list,python-3.x pandas scikit-learn nlp lda,,,CC BY-SA 4.0,False,False,True,False,True
21552,21552,56478384,2019-06-06 13:14:00,,doc vec creating vocabulary ha possibility put minimum occurence word document included vocabulary parameter possible exclude word appear far often parameter know one way preprocessing step manually deleting word counting would nice know maybe built method give space testing many thanks answer,2019-06-06 17:23:24,2019-06-06 17:34:37,put maximum vocabulary frequency doc vec,python gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21555,21555,56483468,2019-06-06 18:51:00,,trying use gensim doc vec word vec since pv dm approach generate word vec doc vec time thought pv dm right model use created model using specifying pv dm question following true word vec model get trained along doc vec call doc vec object seems like property contains word vec available even training static version word vec also created dbow model noticed also contains also static version word vec mentioned previous question,2019-06-06 19:47:10,2019-06-06 23:41:25,word vec mapping coming dbow doc vec gensim implementation,gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21565,21565,56605373,2019-06-14 21:32:01,,question two fold select ideal value get vocabulary size dynamically per row intend set ideal size data look like following example one row one column row row etc based post python size parameter gensim word vec model class parameter le equal vocabulary size trying dynamically assign size following get vocabulary size create second model set value current vocab value current row intended right way right size small vocabulary text,,2019-06-15 15:33:06,dynamically assign right size word vec,python python-3.x nltk gensim word2vec,,,CC BY-SA 4.0,True,False,True,False,False
21572,21572,56551612,2019-06-11 21:01:09,,asking question lazy researcher want try random crazy idea quickly without spending ton time reinventing wheel completely understand intended use case test number hypothesis would love generate target context tuples differently instead default sliding window generate negative sample target random context tuples based rule instead random nce draw example get parse tree sentence use parent child relationship generate tuples non linear window somebody already tried nlp research community hand coded ofc also get antonym dictionary lookup generate negative sample addition random one sure may help faster convergence private member function something start override achieve,,2019-06-12 05:53:39,gensim manual generation training tuples target context label,python nlp gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21573,21573,56456051,2019-06-05 07:36:06,,get following deprecation warning saving loading gensim word embedding http github com rare technology smart open blob master readme rst migrating new open function understand following note page save open model instead use python gensim smart open think get warning using gensim python smart open,,2019-06-06 00:16:02,gensim save load model deprecation warning,gensim,,,CC BY-SA 4.0,False,False,True,False,False
21585,21585,56394227,2019-05-31 11:25:49,,using word feature additional input nmt model used gensim create pretrained embedding feature concated word embedding vector question use named entity tag word feature concate named entity tag one hot vector word embedding vector main idea come paper example word embedding vector po tag named entity tag final embedding vector,,2019-05-31 11:25:49,use one hot vector named entity tag concate word embedding improve neural machine translation,nlp machine-translation,,,CC BY-SA 4.0,False,False,True,False,False
21594,21594,56553753,2019-06-12 02:07:03,,using doc vec analysis paragraph wish get deterministic vector representation train data based official documentation seems need set parameter seed worker well pythonhashseed environment variable python therefore wrote script follows problem within run doe produce deterministic result run whole script give different result problem environment variable setting missing something else python,2019-06-12 02:12:08,2019-06-12 16:47:48,get deterministic train result doc vec,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21598,21598,56605777,2019-06-14 22:24:15,,would like compare two document semantically generate similarity score following doc wikipedia compare expect see higher score world world similar context would training doc vec model world testing two doc model good approach thermo thermodynamics principally based set four law universally valid applied system fall within constraint implied various theoretical description thermodynamics law may expressed seemingly differing form prominent formulation following zeroth law thermodynamics two system thermal equilibrium third also thermal equilibrium statement implies thermal equilibrium equivalence relation set thermodynamic system consideration world world war often abbreviated wwi ww also known first world war great war wa global war originating europe lasted july november contemporaneously described war end war led mobilisation million military personnel including million european making one largest war history also one deadliest conflict history estimated nine million combatant seven million civilian death direct result war resulting genocide influenza pandemic caused another million death worldwide june gavrilo princip bosnian serb yugoslav nationalist assassinated austro hungarian heir archduke franz ferdinand sarajevo leading july crisis world world war ii often abbreviated wwii ww also known second world war wa global war lasted vast majority world country including great power eventually formed two opposing military alliance ally axis state total war emerged directly involving million people country major participant threw entire economic industrial scientific capability behind war effort blurring distinction civilian military resource world war ii wa deadliest conflict human history marked million fatality civilian soviet union china,,2019-06-15 15:18:24,generate similarity score two document,gensim word2vec similarity cosine-similarity doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21613,21613,56591149,2019-06-14 03:52:24,,wanted see simply set new weight gensim word vec without training get news group data set scikit learn sklearn datasets import fetch newsgroups trained instance word vec token tokenized data set created new instance word vec without training set embeddings new word vec equal first one function work expected e g however similar work missing disclaimer posted question datascience stackexchange got response hoping better luck,,2019-06-14 16:06:36,copying embeddings gensim word vec,gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,True
21630,21630,56625109,2019-06-17 05:20:10,,trained gensim wordtovec text corpus converted doctovec used cosine similarity find similarity document need suggest similar document suppose among top suggestion particular document manually find similar feedback incorporated retraining model,,2019-06-17 18:04:39,incorporating feedback retrain wordtovec finding document similarity,machine-learning deep-learning gensim cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,False
21635,21635,56593904,2019-06-14 07:59:36,,using word vec using doesnt match function showing warning anyone help venv lib python site package gensim model keyedvectors py futurewarning array stack must passed sequence type list tuple support non sequence iterables generator deprecated numpy raise error future vector vstack self word vec word use norm true word used word astype real code,,2019-06-14 08:53:50,word vec doesnt match function throw numpy warning,python numpy word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21651,21651,56563339,2019-06-12 13:24:12,,tried use download network reliable downloaded github put use load model received error like attributeerror module word vec google news ha attribute load data code,2019-06-12 13:36:59,2020-03-16 15:50:49,module word vec google news ha attribute load data,python-3.x gensim,,,CC BY-SA 4.0,False,False,True,False,False
21653,21653,56577964,2019-06-13 09:58:31,,problem description unable run gensims distributed lsi due step code corpus reproduce log trace version,2019-06-13 10:11:39,2019-06-13 10:11:39,unable run gensims distributed lsi,python python-3.6 gensim latent-semantic-indexing pyro4,,,CC BY-SA 4.0,False,False,True,False,False
21654,21654,56579523,2019-06-13 11:33:16,,want retrain pre trained word embeddings python using gensim pre trained embeddings want use google word vec file googlenews vector negative bin following gensim word vec tutorial possible resume training model generated c tool load word vec format still use querying similarity information vital training vocab tree missing therefore use keyedvectors training model tutorial suggests use http rare technology com word vec tutorial however try get error message find way convert binary google new file text file properly even sure whether would solve problem doe anyone solution problem know different way retrain pre trained word embeddings,,2019-06-13 17:06:51,retraining pre trained word embeddings python using gensim,python-3.x gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21656,21656,56582711,2019-06-13 14:25:26,,already built doc vec model using around file looking way find string representation given vector id might similar word vec index entity able get vector using model n wondering whether way get sort string representation well,,2019-06-13 16:48:03,python doc vec get document vector id,python nlp gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21660,21660,56599306,2019-06-14 13:33:49,,want use word embeddings order get handy dandy cosine similarity value creating model checking similarity word data give model tell word vocabulary find similarity word description data look follows angle make joint stronger also provide consistent straight corner simpson strongtie offer wide variety angle various size thickness handle lightduty job project structural connection needed bent skewed match project outdoor project moisture present use zmax zinccoated connector provide extra resistance corrosion look z end model numberversatile connector various connection home repair projectsstronger angled nailing screw fastening alonehelp ensure joint consistently straight strongdimensions x x inmade gauge steelgalvanized extra corrosion resistanceinstall common nail x strongdrive sd screw note already tried give data separate sentence instead separate word,2019-06-14 13:38:37,2019-06-14 13:39:52,word vocabulary training gensim word vec model,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21667,21667,56686830,2019-06-20 13:16:11,,trying get embeddings list node word vec try build vocabulary find word vec take list list node treat single digit eg becomes already tried number single entry see wether formatting problem went buil vocab freq instead build vocab also produce error object type int ha len code following want get embedding eg number thanks help edit managed fix anybody else specific problem format list mentioned etc cant change old list runtime least didnt work way could create new list runtime,2019-06-20 18:00:38,2019-06-21 04:22:47,add number one digit word vec vocabulary,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21685,21685,56667348,2019-06-19 12:11:57,,basically installed gensim python importing pycharm got error importerror dll load failed valid win application want use word vec model gensim due error stuck change python version need help get gensim imported version python using pycharm import gensim gensim model import word vec,,2019-07-08 12:30:10,gensim import error importerror dll load failed valid win application,python winapi dll pycharm gensim,,,CC BY-SA 4.0,False,False,True,False,False
21688,21688,56638258,2019-06-17 20:08:47,,stanford c n course know gensim provides fantastic method play around embedding data similar wa trying find equivalent kera embedding layer possible box kera wa wrapper top,2020-01-16 22:32:43,2020-01-16 22:32:43,find similar word kera word embedding layer,keras word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
21701,21701,56639993,2019-06-17 23:26:44,,according gensim page wordembeddingkeyedvectors add new key value pair new word vector incrementally however initializing wordembeddingkeyedvectors pre trained vector tag adding new unseen model inferred word vector method could longer used expect output list vector tag similar input tag output indexerror index bound axis size,2019-06-17 23:35:48,2019-06-18 22:25:15,add new word vector gensim model keyedvectors calculate similar,python gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21708,21708,56707416,2019-06-21 16:39:13,,code take forever execute probably due large size dictionary way make faster e g cropping visualized data,,2019-08-19 07:35:49,pyldavis prepare slow,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
21733,21733,56712365,2019-06-22 03:33:15,,new lda calculating coherence score lda model using gensim coherencemodel take extremely long time run however training part relatively fast reasonable time wonder data size long text way speed process thanks code exactly tutorial,2019-06-22 13:17:12,2019-06-29 17:23:46,slow calculating coherence score lda using gensim,nlp gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
21740,21740,56641954,2019-06-18 04:53:03,,trying convert token sentence integer giving float give want positive integer,,2019-06-18 08:12:52,converting string token integer,python python-3.x nltk gensim word2vec,,,CC BY-SA 4.0,True,False,True,False,False
21759,21759,56715394,2019-06-22 12:17:33,,trying use english wikipedia dump http dump wikimedia org enwiki latest enwiki latest page article xml bz pre trained word vec model using get download something,,2019-06-24 03:50:04,use wikipedia dump gensim model,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21775,21775,56791240,2019-06-27 12:39:57,,structured dataset column text topic someone ha already conducted word embedding topic modeling row text assigned topic number would like create new data frame topic number top key word represent topic done usually start scratch run lda model use object created lda find keywords per topic said starting mid point supervisor gave throwing data structure look like would plan create bag word groupby topic count word keywords function group column option know gensim nltk,,2019-06-27 15:40:06,extract key word topic,python nlp nltk gensim,,,CC BY-SA 4.0,True,False,True,False,False
21794,21794,56793969,2019-06-27 15:05:26,,different lda model text different topic stored one list want save list model disk however sure work treat list lda model gensim website found following code however work separate lda model list multiple model best way save list model,,2019-07-05 18:02:20,save list gensim lda model,python list save gensim,,,CC BY-SA 4.0,False,False,True,False,False
21808,21808,56779011,2019-06-26 18:26:37,,use ldavis library visualize lda topic work fine get error download saved model file sagemaker local computer know doe happen doe relate sagemaker run local saved model local run ldaviz library work fine keyerror traceback recent call last appdata local continuum anaconda lib site package pyldavis gensim py prepare topic model corpus dictionary doc topic dist kwargs see kwargs opts fp merge extract data topic model corpus dictionary doc topic dist kwargs return vi prepare opts appdata local continuum anaconda lib site package pyldavis gensim py extract data topic model corpus dictionary doc topic dists gamma topic model inference corpus else gamma topic model inference corpus doc topic dists gamma gamma sum axis none else appdata local continuum anaconda lib site package gensim model ldamodel py inference self chunk collect sstats phinorm normalizer todo treat zero explicitly instead adding epsilon eps dtype eps self dtype phinorm np dot expelogthetad expelogbetad eps keyerror dtype float,,2019-12-23 18:05:23,fix keyerror dtype float ldaviz,python lda amazon-sagemaker,,,CC BY-SA 4.0,False,False,True,False,False
21812,21812,56796761,2019-06-27 18:22:26,,thanks stopping question dynamic topic model path path dynamic topic model binary something need install download install download thanks,,2019-06-29 17:39:10,dynamic topic model path,python nlp gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
21818,21818,56897173,2019-07-05 05:48:32,,list document first belongs document e list index remaining belings document e list index movie start e g tv series document tag start e g use movie tv series dataset build model follows want get nearest along cosine similarity know function gensim provides however result include movie well intension possible gensim assume document vector creating order document list provide happy provide detail needed,2019-07-05 10:52:25,2019-07-05 17:46:46,identify doc vec instance seperately gensim python,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
21820,21820,56757166,2019-06-25 15:11:35,,receive error trying upload pre trained word vec file compiled fasttext using gensim file ha vec extension found http word embeddings corola vec zip tried far option keyedvectors gensim model option fasttext wrapper error option unicodedecodeerror utf codec decode byte x b position invalid start byte deprecation error option deprecationwarning deprecated use gensim model keyedvectors load word vec format instead need correct method successfully upload word vec file using gensim thank,,2019-06-26 09:55:10,word vec error received uploading pre trained word vec file using gensim,python nlp gensim word2vec fasttext,,,CC BY-SA 4.0,False,False,True,False,False
21841,21841,56883959,2019-07-04 08:45:50,,data set consisting faculty id feedback student regarding respective faculty multiple comment faculty therefore comment regarding faculty present form list want apply gensim summarization comment column data set generate summary faculty performance according student feedback trial tried summarize feedback corresponding first faculty id distinct comment sentence particular feedback still gensim throw error valueerror input must one sentence valueerror input must one sentence change shold make summarizer read sentenses summarizes,2019-07-04 08:46:32,2019-07-05 08:58:07,columnwise summarize multiple sentence present list using gensim summarizer,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
21847,21847,56833365,2019-07-01 09:44:01,,quite post specific issue wa unable solve problem experimenting lda newgroup corpus sklearn gensim implementation described literature perplexity usually decrease higher amount topic different result already experimented different parameter general perplexity increase test set decrease train set increasing amount topic could indicate model overfitting training set similar pattern occur using text data set also research specifically using data set experienced decrease perplexity e g ng perplexity experimented sklearn gensim gensim mallet wrapper package show different perplexity value expected since lda randomly initalized different inference algorithm common pattern perplexity doe increase every package contradicts many paper literature small sample code expect perplexity decrease getting following output k train perplexity test perplexity k train perplexity test perplexity k train perplexity test perplexity edit running fold cross validation step size averaging perplexity per fold following plot created seems perplexity training set decrease topic slightly increase going higher topic number perplexity test set constantly increase almost lineary difference perplexity calculation sklearn gensim implementation research publishing decrease perplexity,2019-07-02 10:22:21,2019-07-02 10:22:21,perplexity increase number topic,python scikit-learn lda topic-modeling perplexity,,,CC BY-SA 4.0,False,False,True,False,True
21867,21867,56835032,2019-07-01 11:39:01,,would like find bigram large corpus text format corpus loaded memory line big load chunk kb want go piece piece corpus find bigram use gensim phrase phraser function training model constantly loses state thus tried save reload model megabyte read free memory still loses state code suggestion thank,,2019-07-01 17:25:24,detect bigram collection large text dataset,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21888,21888,56837259,2019-07-01 14:15:05,,install gensim elastic beanstalk environment python get error gensim need python run wa problem mid day deployment today made project code change nothing related elastic beanstalk requirement setting time succesfully running version another identical environment mean pip python version required dependency tried lowering gensim requirement gensim officially support python get error edit managed make thing work installing gensim redeploying gensim still know cause issue solution really solution still interested insight,2019-07-03 11:34:07,2019-07-03 11:34:07,install gensim python,amazon-web-services pip amazon-elastic-beanstalk gensim,,,CC BY-SA 4.0,False,False,True,False,False
21899,21899,56681210,2019-06-20 07:38:02,,intro currently trying use dask concert gensim nlp document computation running issue converting corpus taggeddocument tried many different way wrangle problem list attempt attempt dealing problem met slightly different woe first initial given data desired output error number generator allowed typeerror could serialize object type generator found way getting around still using generator fix would great work perfectly fine regular panda error number first element partition one bit dumb function iterate know give desired format return first row partition error number function call hang cpu near tell refactoring return outside loop function hang build memory dask client cpu utilization go task computed keep mind calling function way panda solution list comp time tested solution panda solution solution chug along pretty much hour however enough memory juggle thing done conclusion feel super lost right list thread looked admit really new dask spent much time feel like fool errand dask bag generator processing text dask speed panda apply using dask parallelize apply panda dataframes making use core one machine python dask dataframe support trivially parallelizable row apply map partition simple dask map partition example doc,2020-06-20 09:12:55,2019-06-21 18:31:48,convert column dask dataframe taggeddocument doc vec,python dask gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21903,21903,56889408,2019-07-04 13:49:34,,starting get familiar word vec struggeling problem coudln find something similar want use gensims word vec imported pdf document book import used pypdf stored whole book list furthermore used gensims simple preprocess order preprocess data worked far got following output tried use word vec output wa like expected also word text list character tried find relation word e g schottky diode got error message none word included vocabulary first thought wa import wrong got result textract instead pypdf doe someone know problem thanks help appendix importing book content text number input len listdir path,,2019-07-05 17:53:21,gensim word vec vocabulary unclear output,python python-3.x text-mining gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21905,21905,56908407,2019-07-05 19:33:03,,target numpy array shape set candidate array also shape array word vec representation word trying find candidate word similar target word using vector representation best way find candidate word similar target word one way sum absolute value element wise difference target word candidate word select candidate word lowest overall absolute difference example yet seems clunky potentially wrong better way edit include example vector,2019-07-05 19:53:49,2019-07-05 19:57:52,comparing numpy array similarity,python numpy gensim,,,CC BY-SA 4.0,False,False,True,False,False
21906,21906,56909294,2019-07-05 21:14:14,,intro currently using gensim combination panda numpy run document nlp computation like build lda seqential model track topic change time running error corpus format trying figure set time slice dynamic topic model using ldaseqmodel requires integer time slice data csv converted array tuples called bow corpus desired output print one topic allocation time slice entered topic two time slice get three topic printed twice showing topic evolved time tried function bow corpus array tuples tried every version integer input time slice produce error premise wa time slice would represent number indicies row document time slice example data ha million row wanted two time slice would order data time enter integer cutoff like time slice input produce error error solution tried going back documentation looking format common corpus used example format bow corpus also tried running code documentation see worked also produced error sure problem code anymore hope also tried messing file format manually dividing csv csvs containing time slice creating iterated corpus work considered converting row csv txt file creating corpus like david beil doe sound pointlessly tedious already iterated corpus,2019-08-01 17:11:48,2019-08-13 10:23:20,set time slice dynamic topic model,python-3.x nlp gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
21914,21914,56976941,2019-07-10 18:50:07,,working text data moment put data term document matrix calculated tf term frequency tf idf term frequency inverse document frequency matrix look like column document name rownames word filled tf tf idf score using package much current analysis take started playing around library python clear word embeddings tf tf idf hopeing use word vec doc vec obtain matrix similar currently calculate cosine similarity document one output model basically document want calculate cosine similarity rank cosine similarity score,,2019-07-10 20:33:51,obtain word vec doc vec matrix calculate cosine similarity,python gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21919,21919,56961877,2019-07-10 00:11:50,,running code google platform compute engine vm get error imported library first time run import boto error message would modulenotfounderror module named urllib ran different error message came attributeerror module boto ha attribute plugin tried installing google compute engine work also tried different version boto failed well,2019-07-10 11:14:47,2019-07-12 21:56:05,python attributeerror module boto ha attribute plugin,google-cloud-platform boto gensim,,,CC BY-SA 4.0,False,False,True,False,False
21922,21922,56910538,2019-07-06 01:11:46,,trying install gensim specific conda env python window machine tried different way based suggestion elsewhere summarized time show successfully installed present env try import jupyter notebook get error note closed relaunched anaconda jupyter install summary attempt install command detail install command output seen,2019-07-06 03:34:32,2019-07-09 21:59:49,gensim installed anaconda env import jupyter notebook,python jupyter-notebook anaconda conda gensim,,,CC BY-SA 4.0,False,False,True,False,False
21943,21943,56874230,2019-07-03 16:09:41,,binary word vec file using load function get word gensim function calculate return difference vector use two vector get difference vector also trying use difference vector feature document classification calculating diff vector word class right approach example class word want calculate diff vector,2019-07-03 16:23:51,2019-07-05 18:01:15,calculate difference vector word vec,python gensim word2vec calculation document-classification,,,CC BY-SA 4.0,False,False,True,False,False
21944,21944,56999139,2019-07-12 01:29:56,,trying build doc vec model le k sentence use model find similar sentence model new sentence trained gensim doc vec model using corpus k sentence model extend tell new sentence similar sentence corpus problem may happen word new sentence exist corpus mean word embedding happens prediction result good far know trained doc vec model doe matrix doc vector well matrix word vector thinking load set pre trained word vector contains large number word train model get doc vector doe make sense possible gensim another way,2019-07-12 02:24:39,2019-07-13 03:33:51,way load pre trained word vector training doc vec model,gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
21946,21946,57033566,2019-07-15 05:14:25,,would like train word embeddings fastext however following tutorial manage properly far tried however try look vocabulary word get even word present sentence passing fast text model also check similar word return getting character correct way using gensim fasttext wrapper,,2020-08-04 13:29:14,train word embedding representation gensim fasttext wrapper,machine-learning nlp gensim word-embedding fasttext,,,CC BY-SA 4.0,False,False,True,False,False
21954,21954,56816261,2019-06-29 08:50:28,,new nlp find similarity sentence also print score word also implement gensim word vec model try code two sentence,,2019-06-29 17:02:13,find score sentence similarity using word vec,nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
21958,21958,56965668,2019-07-10 07:38:49,,working nlp project moment one task compare similar two news article title already trained doc vec model using english wikipeida article gensim library want compare similarity new text inferring vector wiki doc vec model one method tried gensim docvecs similarity unseen doc function however result really intuitive may know way get similarity score better performance maybe part code wrong training doc vec model comparing similarity output similarity score seem good code training please let know training error caused inaccuracy inferring unseen doc,2019-07-11 02:35:10,2019-07-11 02:35:10,get sentence text similarity new corpus wiki doc vec model,python gensim cosine-similarity doc2vec sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
21963,21963,56968915,2019-07-10 10:37:59,,gensims word vec api trained model initialized model max final vocab saved model using model save give one model file one model trainables syn neg npy one model wv vector npy file need train model fine using kv variable shown want use top n n case vocabulary item instead entire vocabulary way even attempt cutting vocabulary could find wa load model though vocabulary still ha length want reduce vocabulary model model wv retaining working model retraining option,,2019-07-10 12:16:06,gensim word vec reduce vocab size existing model,gensim word2vec vocabulary,,,CC BY-SA 4.0,False,False,True,False,False
21969,21969,56984758,2019-07-11 08:25:54,,used gensim word vec model applied list document well word embedding getting created want know word vec performing well list document metric measure understand word vec ha really worked well document corpus try different embedding code used gensim,2019-07-11 08:27:42,2019-07-11 21:51:28,check performance word embedding,python word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
21977,21977,57020405,2019-07-13 15:17:54,,getting import error try import gensim panda numpy django view py work fine shell import view py installed library virtual environment,2019-07-14 11:26:16,2019-07-14 11:26:16,trying import gensim panda numpy django project getting import error,django pandas numpy gensim,,,CC BY-SA 4.0,False,False,True,False,False
22009,22009,57060692,2019-07-16 15:25:27,,created word vec model using gensim using document calculation vector array obtained punching code new vector array want devectorize new vector array text done python,,2019-07-16 15:25:27,devectorize vector array nx text using pre trained model word vec using gensim,python nlp artificial-intelligence gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22023,22023,57079642,2019-07-17 15:39:01,,reading tutorial gensim doc understand correct way generating new embeddings trained model far trained gensim fast text embeddings like let say want get embeddings vector associated sentence get trained previously,,2019-07-17 18:22:00,training word embedding gensim fasttext wrapper embed new sentence,machine-learning nlp gensim embedding,,,CC BY-SA 4.0,False,False,True,False,False
22029,22029,57097233,2019-07-18 14:44:39,,want compare similarity two string calculate wmd distance word vec model doc vec model gensim could understand doe wmd work doc vec model doe wmd still take word embeddings word doc vec model doe word vec model difference word vec model doc vec model calculate wmd distance example wmd distance calculated model different understand wmd work generally two sentence figure work doc vec model would appreciate someone help understand,,2019-07-18 17:56:12,wmdistance word vec model doc vec model gensim,gensim,,,CC BY-SA 4.0,False,False,True,False,False
22045,22045,57100323,2019-07-18 18:03:42,,data data generated r use package port python problem python code r code python code note special function call r data changed using python data supposed process document print say say know going wrong function data data frame row unique book text book one cell want process cell,2019-07-18 18:06:23,2019-07-18 18:08:53,number texted processed function process document,python r gensim,,,CC BY-SA 4.0,False,False,True,False,False
22047,22047,57102264,2019-07-18 20:33:38,,assume number picture let say picture annotated people pic might beach vacation relax sand sun trained word vec domain specific content vector word represent want create one final vector representing picture one vector represents annotation beach vacation relax sand sun let assume vector represented dimension add first dimension dimension vector nd dimension vector etc thankful comment might help tried sure right way also tried doc vec guess problematic word order annotation irrelevant relevant doc vec,,2019-07-22 18:25:27,calculate vector word vec,gensim,,,CC BY-SA 4.0,False,False,True,False,False
22068,22068,57138453,2019-07-22 02:17:04,,using doc vec model follows construct document vector seen gensim doc vec also includes word vector suppose word vector created word question possible get nearest word vector gensim python happy provide detail needed,2019-07-22 05:35:59,2019-07-22 18:42:34,get nearest document word gensim python,python gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
22070,22070,57157137,2019-07-23 05:20:00,,loaded gensim continuous skipgram model built google news vocabulary size however getting error message two random word trying get similarity loading model also tried binary file instead file work either also similarity score tried using unicode character parameter work either pretty sure huge corpus word sure getting result also tried common word military car etc error message,2019-07-23 05:28:21,2019-07-23 05:28:21,raise keyerror word vocabulary word gensim model,python gensim word2vec similarity,,,CC BY-SA 4.0,False,False,True,False,False
22071,22071,57157390,2019-07-23 05:44:44,,large corpus million document gb csv want create tf idf vector feature engineering data large load memory working google colab gpu gb ram imagine way process data chunk combine tf idf end sure proceed code far removing stopwords punctuation lemmatizing wordnetlemmatizer stemming snowballstemmer english read chunk time avoid memory error probably save result disk delete object memory processing next set chunk point process combine multiple tf idf,,2019-07-23 05:44:44,nlp combining multiple tf idf matrix,python scikit-learn gensim tf-idf tfidfvectorizer,,,CC BY-SA 4.0,False,False,True,False,True
22081,22081,57090689,2019-07-18 08:56:50,,two list say list list b text want find similar text list b text list want using bag word later cosine similarity created dictionary using gensim obtained occurences word text list b convert vector cosine similarity,,2019-07-18 08:56:50,create one hot vector find similarity text gensim doc bow implementation,nlp gensim cosine-similarity one-hot-encoding,,,CC BY-SA 4.0,False,False,True,False,False
22095,22095,57125117,2019-07-20 13:17:11,,document using gensim embed document code follows would like get document related topic deep learning e document mainly content related deep learning possible doc vec model gensim happy provide detail needed,,2019-07-20 18:56:36,get document vector given topic gensim,python gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
22099,22099,57107945,2019-07-19 07:53:23,,trying load pytorch struct getting valueerror could convert string float b x x x x x k xba x x x tried post robodasha without success goal build vocabulary loaded embedding using suggestion,2019-10-04 16:25:34,2019-10-04 16:26:24,building dictionary googlenews vector negative bin return valueerror could convert string float,python pytorch gensim,,,CC BY-SA 4.0,False,False,True,False,False
22110,22110,57125757,2019-07-20 14:44:18,,need process large number file building model txt file bit messy need remove newlines read sentence loaded string txt file tokenize sentence using word vec model thing cant read file line line cause sentence end one line therefore use split file sentence cant figure convert list string list list sub list contains sentence passing thourgh generator actually need save sentence new file one sentence per line pas generator well code look like goal load file tokenize sentence split sentence word load file etc input sentence word vec model,,2019-07-20 17:16:02,training word vec model streaming data file tokenize sentence,python streaming nltk gensim word2vec,,,CC BY-SA 4.0,True,False,True,False,False
22112,22112,57198286,2019-07-25 09:11:09,,created word embeddings word vec using dataset used gensim module create word embeddings want evaluate word embeddings used wordsim dataset evaluate word embeddings following code show result evaluation code result interprete result please help interprete result,2019-07-25 09:37:42,2019-07-25 11:07:01,interepretation word vec evaluation result,word2vec evaluation word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
22116,22116,57179502,2019-07-24 09:23:30,,need run multiple word vec period time example running word vec every month reduce computing workload would like run word vec data wa accumulated last month problem stem fact processing require embeddings model ran previous month know also reading post individual word vec model run different sample representative sample overarching corpus obtaining word embeddings comparable possible similar problem analysing network data evolves time effectively kind graph vec analysing node behaviour yet wondering comparable embeddings achieved using pca follows model create node embeddings length x model run pca node embeddings retain x principal component whereby whitening enabled transform individual node embeddings corresponding pca coordinate since individual sample used train individual model share high proportion node existing one tend stay new one likely added following append pca transformed embeddings one database nodeid calculate mean pca transformed embedding would work pca transformation embeddings model ensures resulting embeddings measure thing example first principal component pca capture kind information etc sure,2019-07-24 09:30:29,2019-07-24 19:14:06,principal component different word vec model measuring thing,math gensim word2vec fasttext,,,CC BY-SA 4.0,False,False,True,False,False
22133,22133,57200067,2019-07-25 10:41:26,,code load file strip sentence remove stopwords return token far good include statement simple example see stopwords removed run sentence word vec model model still creates wordvector stopwords like error code run return similar word word removed cry loud gensim function take set stopwords remove,,2019-07-25 17:20:22,code remove stopwords word vec still creates wordvector stopword,python nltk gensim stop-words,,,CC BY-SA 4.0,True,False,True,False,False
22136,22136,57148357,2019-07-22 14:38:05,,building vocabulary table using doc vec error attributeerror module gensim utils ha attribute smart open solve notebook databricks platform running python past tried running code local jupyter notebook error occurred also searched http radimrehurek com gensim model doc vec html could find anything related smart open ran line separately first line worked fine second say attributeerror module gensim utils ha attribute smart open,2019-07-22 18:14:14,2020-07-25 14:49:35,attributeerror module gensim utils ha attribute smart open,python gensim databricks doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
22157,22157,57189149,2019-07-24 18:26:00,,try compare text form text file concerning content e g got text animal want analyze text animal discus looking analysis output like read lot latent dirichlet allocation word probability topic text classification completely unsupervised approach seemed fit set document trying implement lda stuff python understood prepare data tokenizing lemmatizing stemming get next step generate training data topic animal could implement also seen tutorial manipulating topic via know could use favor grateful advice lead right direction thanks,2019-07-24 20:22:56,2019-07-29 12:34:35,implement statistical thematic comparison text via text mining,python text-mining gensim text-classification lda,,,CC BY-SA 4.0,False,False,True,False,False
22176,22176,57244699,2019-07-28 20:25:02,,trying learn word vec using code load google pre trained word vec model python unsure turn list ate apple list vector ie get vector model,,2019-07-28 22:46:18,turn list word list vector using pre trained word vec model google,python-3.x gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22198,22198,57297194,2019-07-31 18:49:40,,new nlp gensim currently trying solve nlp problem gensim word vec module current understanding word vec result vector matrix entry however trying simple one result vector ha entry greater sure part wrong could anyone give suggestion please used gensim utils simple preprocess generate list list token list look like believe correct input format gensim word vec expect output vector containing probability e actually turned following see vector,2019-07-31 18:55:19,2019-07-31 22:12:07,gensim word vec entry greater,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22201,22201,57298877,2019-07-31 21:10:19,,want python getting error already tried using using local window window server multiple reinstallments diffenent version package e g traceback recent call last file c user administrator document github contract criterion identifier aws schnelltest py line import gensim file c user administrator appdata local program python python lib site package gensim init py line gensim import parsing corpus matutils interface model similarity summarization utils noqa f file c user administrator appdata local program python python lib site package gensim parsing init py line preprocessing import remove stopwords strip punctuation strip punctuation noqa f file c user administrator appdata local program python python lib site package gensim parsing preprocessing py line gensim import utils file c user administrator appdata local program python python lib site package gensim utils py line import scipy sparse file c user administrator appdata local program python python lib site package scipy sparse init py line csr import file c user administrator appdata local program python python lib site package scipy sparse csr py line sparsetools import csr tocsc csr tobsr csr count block importerror dll load failed specified module could found p c user administrator document github contract criterion identifier aws c user administrator appdata local program python python python exe c user administrator document github contract criterion identifier aws schnelltest py traceback recent call last file c user administrator document github contract criterion identifier aws schnelltest py line import gensim file c user administrator appdata local program python python lib site package gensim init py line gensim import parsing corpus matutils interface model similarity summarization utils noqa f file c user administrator appdata local program python python lib site package gensim parsing init py line preprocessing import remove stopwords strip punctuation strip punctuation noqa f file c user administrator appdata local program python python lib site package gensim parsing preprocessing py line gensim import utils file c user administrator appdata local program python python lib site package gensim utils py line import scipy sparse file c user administrator appdata local program python python lib site package scipy sparse init py line csr import file c user administrator appdata local program python python lib site package scipy sparse csr py line sparsetools import csr tocsc csr tobsr csr count block importerror dll load failed specified module could found,2019-07-31 21:22:23,2019-07-31 22:18:52,install gensim run package python,python machine-learning pip gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22204,22204,57264086,2019-07-30 03:56:34,,set string tokenizing sending string model say token e g ate pizza etc generating matrix possible convert generated token embeddings vector sending model library following max feature size token vector e input length also sure getting job done right way convert token embeddings vector ideally want covert embeddings vector sending model,,2019-07-30 19:32:43,combine token embeddings vector,python tokenize gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
22210,22210,57335044,2019-08-03 02:26:38,,trying understand use tensorflow train word embeddings without preset label tensorflow tutorial http www tensorflow org beta tutorial text word embeddings show train word embeddings using pre structured dataset label however wonder train tensorflow embeddings non labeled text similar done gensim word vec,,2019-09-01 03:05:09,word embeddings tensorflow,nlp gensim word2vec word-embedding tensorflow2.0,,,CC BY-SA 4.0,False,False,True,False,False
22213,22213,57316991,2019-08-01 21:07:17,,result whereas give different answer one expect expect return thing misunderstanding vector math performed vector,,2019-08-01 22:02:28,passing positive negative parameter gensim similar function return vector math result,nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22258,22258,57373626,2019-08-06 10:05:48,,around k document word k document document similar document known document serve test data trying find similar document datasets using gensim doc vec paper distributed representation sentence document say combination pv dm pv dbow often work consistently better imdb therefore recommended would like combine vector two method find cosine similarity train document select top least cosine distance effective method combine vector method adding averaging method combining vector normalise vector find cosine distance,,2019-08-06 20:22:26,combine vector generated pv dm pv dbow method doc vec,python nlp gensim doc2vec sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
22274,22274,57283636,2019-07-31 05:14:40,,around k document word k document document similar document known document serve test data present removing document using remaining document training doc vec extract vector train test data test data document find cosine distance train document select top least cosine distance similar document marked present top take accurate accuracy accurate record total number record way find similar document using doc vec similiar method calculate accuracy using formula two accuracy match epoch one increase decrease using code given http medium com scaleabout gentle introduction doc vec db e c cce e training doc vec would like know tune hyperparameters get making accuracy using mentioned formula use cosine distance find similar document shall use gensim similar function,,2019-07-31 21:58:09,effectively tune hyper parameter gensim doc vec achieve maximum accuracy document similarity problem,python nlp gensim doc2vec sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
22276,22276,57391090,2019-08-07 09:24:38,,distributed online lda implemented spark mllib gensim would like choose one project present already hadoop system running worker node could someone experience give recommendation point pro con e g difficulty cluster setup speed modelling process etc thanks,2019-08-07 12:02:36,2019-08-07 12:02:36,comparison distributed online lda implemented pyspark gensim,pyspark nlp apache-spark-mllib gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
22294,22294,57412511,2019-08-08 12:23:40,,wa trying use gensim import googelnews pretrained model english word sampled one stored txt file per line context corpus could use model similar get similar word phrase actually file loaded python pickle method used gensim built function directly cluster english word future since train save load model beginning,2019-08-08 14:28:21,2019-08-08 18:06:42,gensim built model load function python pickle load file,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22299,22299,57391750,2019-08-07 09:59:35,,k text document tweet newspaper article represented vector obtained doc vec model want use regressor multiple linear regression predict continuous value output case uk consumer confidence index code run since forever wrong imported data excel splitted x train x dev data composed preprocessed text cci continuous value since fitting never completed wonder whether using wrong input however error message shown code simply run forever wrong thank much help,2019-08-07 11:01:20,2019-08-07 12:29:43,use sklearn linear regression doc vec input,scikit-learn linear-regression gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,True
22348,22348,57226900,2019-07-26 20:54:44,,quite long text document describing behaviour different animal want extract text specific animal figured done example document descibes different animal want alorithm output information input file related lion lion described discussed several different place document selective extraction text related lion doe anyone know edit input output input text file e g document txt key word e g lion output example lion large feline traditionally depicted king jungle big cat roamed africa asia europe male generally larger female distinctive mane hair around head asiatic lion eat large animal well goat nilgai chital sambhar buffalo female gestation period around four month give birth young away others hide cub first six week life,2019-07-26 21:04:42,2019-07-28 01:30:55,selective text extraction python based certain topic keywords,python nlp nltk gensim pythonanywhere,,,CC BY-SA 4.0,True,False,True,False,False
22356,22356,57457214,2019-08-12 07:35:16,,using lda gensim topic modeling data ha document want separate topic word document gensim giving topic entire set document together get individual doc output getting,,2019-08-12 10:53:42,print document wise topic gensim,python nltk gensim lda topic-modeling,,,CC BY-SA 4.0,True,False,True,False,False
22373,22373,57461705,2019-08-12 12:59:41,,trained fasttext sen vec word vec model news collection csv file news one line like got trained model happily get vector line csv file like fasttext like gensim get vector array line csv file like like,2019-08-12 17:29:56,2019-08-12 17:52:26,get doc vec sen vec trained vector readable csv txt format linewise,python arrays vector word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22374,22374,57528271,2019-08-16 16:41:01,,would like import pre trained dictionary binary format vectorizing text able import vector initialize blank spacy nlp object get word associated index set vector nlp object able get stage without problem however wa wondering save nlp object load spacy vectorize new text efficiently possible,,2019-09-08 06:17:21,import word vec vector binary format spacy,python nlp gensim spacy,,,CC BY-SA 4.0,False,True,True,False,False
22378,22378,57475889,2019-08-13 10:30:07,,found wa failure used gensim googlenews pre trained model cluster phrase like knitting knit loom loom knitting weaving loom rainbow loom home decoration accessory loom knit knitting loom advised googlenews model doe phrase phrase little specific googlenews model corpus train new model phrase considering turn bert could bert expected thank,,2019-08-13 11:30:49,could use bert cluster phrase pre trained model,tensorflow nlp pytorch gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22392,22392,57496250,2019-08-14 14:00:39,,pretty new doc vec made small research found couple thing story trying learn using doc vec million document first tried small model document checked result infer vector first document found similar indeed first document cosine similarity measure found good even though tried enter new document completely different word received high score measure similarity however put aside tried go build full model million document point problem began result wa complete nonsense received similar function result similarity completely different new document checked tried tune parameter result yet tried also remove randomness small big model however still got different vector tried use get latest training loss epoch order see loss change epoch code know code bit awkward used follow loss error receive tried looking model auto complete found indeed function found something similar name training loss give error anyone give idea thanks advance,,2019-08-14 18:26:04,doc vec object ha attribute get latest training loss,python gensim doc2vec glove,,,CC BY-SA 4.0,False,False,True,False,False
22395,22395,57443879,2019-08-10 16:33:19,,training doc vec model french wikipedia code based notebook http github com rare technology gensim blob develop doc notebook doc vec wikipedia ipynb actually training phase know vectorize new sentence use model infer vector example sentence case make processing wikicorpus method doe explained http radimrehurek com gensim corpus wikicorpus html thanks,2019-08-10 16:40:01,2019-08-12 03:10:32,new sentence doc vec model trained wikicorpus,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
22415,22415,57532018,2019-08-16 23:07:02,,using core virtual cpu g memory training doc vec gensim usage cpu always around whatever modify number core two picture showed percentage cpu usage pointed cpu used efficiently edit tried use parameter corpus file instead document resolved problem need adjust code convert x w v file x w v directly,2020-06-20 09:12:55,2019-08-17 00:06:53,efficiently use multi core cpu training doc vec gensim,gensim,,,CC BY-SA 4.0,False,False,True,False,False
22432,22432,57551270,2019-08-19 06:11:43,,using gensim utils preprocess text nlp library make call numpy return inter alia error message already tried fixing path bash profile case wa case competing python installation using venvs also uninstalled additional virtual env extension could potentially cause conflict pyenv reinstalled package new env updated essentially followed instruction nothing succeeded,2019-10-07 16:57:39,2019-10-07 16:57:39,numpy image found importing gensim python,numpy scipy anaconda gensim,,,CC BY-SA 4.0,False,False,True,False,False
22438,22438,57426745,2019-08-09 09:01:22,,want exactly cluster word phrase e g knitting knit loom loom knitting weaving loom rainbow loom home decoration accessory loom knit knitting loom corpus word phrase could use pre trained model like one googlenews wikipedia realise trying use gensim load googlenews pre trained model get phrase similarity told googlenews model includes vector phrase word find could get word similarity phrase similarity fails error message phrase vocabulary please advise thank,2019-08-10 14:28:00,2019-08-10 14:28:00,cluster word phrase pre trained model gensim,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22468,22468,57626276,2019-08-23 12:22:52,,trying find similarity score two document containing around record using two method python tfidf scikit learn word vec gensim google pre trained vector example doc click bill tab doc click chap tab first method give score second method give score example doc see following requirement doc see following requirement first method give score second method give score anyone tell example word vec giving though different example word vec giving though difference,,2019-08-23 13:33:33,tfidf v word vec,python machine-learning data-science word2vec tf-idf,,,CC BY-SA 4.0,False,False,True,False,True
22487,22487,57543403,2019-08-18 09:53:41,,problem reading json dump created wikipedia dump using gensim trying follow instruction given link read wiki dump create json file http radimrehurek com gensim script segment wiki html code failing code running given please help understand whats wrong code running code window machine using anaconda,,2019-08-18 09:53:41,read json file created gensim wikipedia dump,json gensim wikipedia,,,CC BY-SA 4.0,False,False,True,False,False
22489,22489,57630389,2019-08-23 16:57:30,,trained lda model pc saved locally using model save command load model output topic pycharm try load model jupiter notebook get error anyone encounter problem fix full error output,,2019-08-23 17:35:44,load pre trained lda model jupiter notebook,pycharm jupyter-notebook gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
22493,22493,57617061,2019-08-22 21:05:49,,building program assigns multiple label tag textual description using scikit learn onevsrestclassifier xgbclassifier classify vectorized textual description using gensim word vec vectorize text however try fit classifier vectorized data get following error indexerror tuple index range code error happens last line try fit classifier shape x shape shape xtrain shape ytrain,2019-08-22 21:23:11,2019-08-23 22:07:35,sklearn classifier trained gensim word vec data,python machine-learning scikit-learn gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,True
22500,22500,57652804,2019-08-26 06:31:05,,trained model gensim wan na evaluate model simlexx give error code error tried give keyerror please help solve problem,2019-08-27 04:15:31,2019-12-20 11:20:18,evaluating word vec model using simlex,python-3.x gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22505,22505,57599259,2019-08-21 21:14:47,,building multilabel text classification program trying use onevsrestclassifier xgbclassifier classify text initially used sklearn tf idf vectorization vectorize text worked without error using gensim word vec vectorize text feed vectorized data onevsrestclassifier xgbclassifier however get following error line split test training data typeerror singleton array array dtype object considered valid collection tried converting vectorized data feature array np array seemed work code variable list string textual description trying classify,2019-08-21 21:36:39,2019-08-22 15:59:03,sklearn gensim use gensim word vec embedding sklearn text classification,python machine-learning scikit-learn gensim,,,CC BY-SA 4.0,False,False,True,False,True
22522,22522,57579009,2019-08-20 17:44:10,,following code run give cosine distance two word model wv distance word word find euclidean distance two word using gensim word vec implementation,,2019-08-20 18:01:59,change code find euclidean distance cosine word word vec impementation,python gensim word2vec similarity euclidean-distance,,,CC BY-SA 4.0,False,False,True,False,False
22531,22531,57605476,2019-08-22 08:49:25,,building program assigns multiple label tag textual description using gensim doc vec vectorize text description however print length doc vec model vector return number different tag number description word return vector representing tag document inevitable lead valueerror try splitting data using sklearn valueerror found input variable inconsistent number sample code variable dimension array length,2019-08-22 11:58:16,2019-08-23 08:33:22,gensim doc vec le vector generated expected,python machine-learning scikit-learn gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,True
22541,22541,57672901,2019-08-27 10:39:27,,wanted successfully run ldaseq model huge corpus finally want extract topic getting error memory step ldaseq model huge token want truncate resolve memory issue window sp python v f c b mar msc v bit amd numpy scipy gensim fast version expected result shown documentation need topic term topic doc matrix finally,2019-08-27 11:39:20,2020-01-17 12:01:40,memory issue gensim topic modeling,gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
22561,22561,57728181,2019-08-30 13:59:02,,new word vec trained text file via word vec feature extraction look word trained found single character instead word miss anyone help try feed token instead raw text model,,2019-08-30 15:40:08,get single character learned vocabulary word vec genism output,nlp gensim word2vec feature-extraction text-classification,,,CC BY-SA 4.0,False,False,True,False,False
22562,22562,57729538,2019-08-30 15:28:23,,wanted fix topic include word e g topic cloud computing hybrid cloud topic smartphone mobile across blog http scignconsulting com guided lda attempt setting prior eta found large collection document seed word getting downranked final topic actually including original seed word hypothesis happening believe alpha probability topic given document would also need set otherwise probability seeded topic low seedwords may matter much ha anyone experience pointer avoid seed word ignored,,2020-01-03 15:51:47,guided lda gensim fixed eta,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
22563,22563,57729961,2019-08-30 15:59:38,,set document fit pre defined category successfully trained model document question novel document calculate closely new document line trained model current solution wa unable find convenience method documentation,,2019-08-31 09:25:08,gensim doc vec used compare novel document trained model,python python-3.x nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
22564,22564,57730631,2019-08-30 16:57:26,,documentation bit unclear save fasttext model disk specify path argument tried failed error example documentation furthermore save model text format like done word vec model edit trying suggestion make file first keep kgetting error run code typeerror file must write attribute,2019-08-30 19:33:31,2019-08-30 19:33:31,save fasttext model binary text format,gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
22568,22568,57688029,2019-08-28 08:26:15,,trying process large corpus preprocess string return error shown run without error,2019-08-28 08:27:50,2020-04-23 08:07:00,issue character encoding processing text,python encoding gensim,,,CC BY-SA 4.0,False,False,True,False,False
22570,22570,57695150,2019-08-28 14:53:10,,want train part corpus first based embeddings train whole corpus achieve gensim skipgram found api pas initial embeddings want thing like,,2019-08-28 17:41:32,use pretrained embedding gensim skipgram model,python machine-learning gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22578,22578,57525190,2019-08-16 13:04:12,,text classification plan use word vec word embeddings used gensim module word vec training tried several option getting error word xyz vocabulary able find mistake text processing please help solve issue definig corpus word vec model using created word embeddings downstream classification task classification model two priority want classify using folllowing network classification getting error please help solve thank,2019-09-11 11:36:05,2019-09-11 11:36:05,text classification word vec,python-3.x word2vec text-classification,,,CC BY-SA 4.0,False,False,True,False,False
22591,22591,57752992,2019-09-02 07:33:40,,created lda model using gensim first iterated num topic range based pyldavis plot chose n final lda model trained model want know use model doc used training also new unseen document assign topic using code getting error error message,,2019-09-08 22:51:53,unable classify topic using lda trained model,python nlp lda,,,CC BY-SA 4.0,False,False,True,False,False
22593,22593,57755481,2019-09-02 10:37:09,,update training gensim fasttext model command model build vocab think key attributeerror fasttext object ha attribute syn neg please give suggestion thanks lot load pre trained model pretrained vector make sure train model print load fasttext pretrain model pretrained model fasttext gensim load pretrained model file load token article wan na update convert token list list sent token df token value tolist use build vocab pretrain model state update true pretrained model build vocab sent update true traceback recent call last file c user marcus pycharmprojects diva cws fasttext pretrain py line pretrained model build vocab sent update true file c user marcus desktop diva cws lib site package gensim model deprecated word vec py line build vocab self finalize vocab update update build table array file c user marcus desktop diva cws lib site package gensim model deprecated word vec py line finalize vocab self update weight file c user marcus desktop diva cws lib site package gensim model deprecated word vec py line update weight self syn neg vstack self syn neg zero gained vocab self layer size dtype real attributeerror fasttext object ha attribute syn neg,,2019-09-20 10:52:09,bug fasttext build vocab,python gensim word-embedding fasttext incremental-build,,,CC BY-SA 4.0,False,False,True,False,False
22596,22596,57697374,2019-08-28 17:27:28,,gensim trained model use get list word closest vector space example spacy per documentation give similarity token specified string combing doc searching figure gensim type way listing similar word preloaded model either way,,2020-10-03 05:35:16,list similar word spacy pretrained model,python spacy,,,CC BY-SA 4.0,False,True,True,False,False
22601,22601,57757356,2019-09-02 12:57:55,,test sentence define skill perform equipment maintenance set diploma different diploma description needed skill paragraph per diploma problem consists finding diploma closest test sentence term semantic similarity thought creating doc vec model multi class class per diploma order transform diploma feature vector infer vector test sentence calculate cosine similarity feature vector yet one sample diploma still work split sentence diploma text order obtain several sample diploma,,2019-09-03 20:21:06,doe doc vec work multi class problem sample per class,nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
22624,22624,57760664,2019-09-02 17:11:25,,trying get unique word topic using gensim line help generate model repeated word two different topic would like different word per topic,2019-09-02 17:11:46,2020-04-23 01:57:03,get unique word per topic lda,python gensim word lda,,,CC BY-SA 4.0,False,False,True,False,False
22626,22626,57762713,2019-09-02 21:11:33,,two list would like compute cosine similarity two list way cosine similarity first sub list list sublists list measured thing second sub list list sub list list etc goal create len list len list matrix entry matrix cosine similarity score currently done following way however like implement matrix multiplication loop two question way sort element wise matrix multiplication generate required matrix would efficient faster using current method matrix multiplication hope question wa clear enough please let know clarify even,2019-09-02 23:02:38,2019-09-02 23:49:10,perform matrix multiplication cosine similarity function,python-3.x numpy gensim word2vec cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,False
22638,22638,57795240,2019-09-04 20:26:48,,work understand thing correctly model entirely defined word topic distribution obtained wondering possible create model specifying distribution notably order use gensim function topic prediction,,2019-09-04 20:26:48,create gensim model specifying word topic distribution,gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
22639,22639,57796091,2019-09-04 21:56:09,,part assignment asked topic modeling using lda visualize word come top topic shown screenshot however even searching lot able find helpful resource would help achieve goal resource text visualization pointed towards word cloud goal use word cloud visualization required lda topic visulization help greatly appreciated,2020-06-20 09:12:55,2019-09-11 10:08:56,visualize result lda topic modelling shown,matplotlib plotly seaborn gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
22646,22646,57834425,2019-09-07 14:05:51,,trying apply doc vec tutorial instead testing random test corpus document testing entire test corpus modified following line code error,,2019-09-07 14:38:33,testing model doc vec test corpus,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
22648,22648,57903695,2019-09-12 09:28:22,,want use read version gensim fasttext embedding save ram compared full model loading keyvectors version get following error fetching vector error occurs using word vocabulary e g lawyerxy instead lawyer full model return vector assumption keyedvectors offer fasttext vacabulary function key feature usecase limitation given documentation http radimrehurek com gensim model word vec html anyone prove assumption name fix allow vector lawyerxy etc,,2019-09-12 15:59:50,gensim fasttext keyedvector vocab,gensim word-embedding fasttext,,,CC BY-SA 4.0,False,False,True,False,False
22675,22675,57943303,2019-09-15 10:36:08,,trying compare glove fasttext bert elmo basis similarity word using pre trained model wiki glove fasttext pretrained model could easily used gensim word vec python doe elmo bert model,2019-09-16 07:25:33,2019-09-20 12:32:52,get similarity score word using pre trained bert elmo,nlp gensim word2vec word-embedding elmo,,,CC BY-SA 4.0,False,False,True,False,False
22679,22679,57804554,2019-09-05 11:32:05,,running dockerfile ubuntu base image follows python installed machine still getting error follows specific version gensim need download different error,,2019-09-05 12:09:15,unable install gensim python ubuntu,python docker ubuntu gensim,,,CC BY-SA 4.0,False,False,True,False,False
22689,22689,57839264,2019-09-08 04:47:17,,using gensim train word vec model passing one sentence time gensim model word vec method corpus gradually train model whole corpus confused value iter parameter sure whether iterates passed sentence n time whole corpus tried checking documentation gensim state definition follows iter int optional number iteration epoch corpus confused passing whole corpus single sentence iteration line code train model look like data represents single sentence passed time generator suppose corpus sentence x variable variable model receives data x variable first data variable nd iteration clarify question whether iter train model iterating though x variable time variable time iterating though x variable variable whole corpus time,2019-09-08 04:52:37,2019-09-08 22:06:27,doe iter parameter gensim model word vec method iterate whole corpus sentence passed time,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22691,22691,57856393,2019-09-09 14:47:55,,like calculate word mover distance universal sentence encoder tensorflow hub embedding tried example spacy wmd relax load en model spacy find another way feed embeddings gensim seems accepts file file know someone ha written bert token embeddings based pytorch generalized model tf hub approach transfer pretrained model tf hub spacy format word vec format,,2020-06-29 16:54:38,load pretrained model tf hub calculate word mover distance wmd gensim spacy,tensorflow nlp gensim spacy tensorflow-hub,,,CC BY-SA 4.0,False,True,True,False,False
22695,22695,57894052,2019-09-11 17:23:26,,switched window development ubuntu installing libaries using pip got runtime warning numpy ufunc size changed using following version project pycharm professional lastest version spacy numpy blis thinc gensim uninstalled everything installed spacy last uninstalled numpy put version various trick see get install correct version doe anyone know resolve issue actual version numpy thinc blis used case,,2019-09-11 17:23:26,spacy numpy ufunc size changed may indicate binary incompatibility,python-3.x numpy spacy,,,CC BY-SA 4.0,False,True,True,False,False
22696,22696,57895899,2019-09-11 19:49:13,,attempting use gensim mallet wrapper run following code thrown following error exhaustive online search found many proposed solution unfortunately resolve issue since first error message doe print entire path believe space cause issue unfortunately company requires use directory change name way escape space order run code,,2019-09-18 23:22:48,pas file path containing space gensim lda mallet wrapper,python bash gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
22697,22697,57896070,2019-09-11 20:04:04,,given heavily cleaned input format word vec returning alongside obvious result super specific vector appears occurring document hard time believing appear five time using following code create model wrong getting useless vector,2019-09-11 20:19:27,2019-09-11 22:35:47,gensim word vec returning awkward vector,python python-3.x gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22704,22704,57946734,2019-09-15 17:51:58,,code want detects hill eye output,,2019-09-17 04:20:40,find bigram using gensim,python-3.x gensim phrase,,,CC BY-SA 4.0,False,False,True,False,False
22748,22748,57939471,2019-09-14 21:41:55,,would like build application foreign language learning something based creating deck flashcard word ordering add voice pronounciation sample add image etc something similar anki app want use c language net platform make wish make desktop mobile app maybe also website considered question exactly technology type project use mean make desktop app using net framework wpf xamarin mobile app somehow synchronize would like synchronize desktop mobile apps together someone us desktop version install mobile app could access whole previous deck setting maybe consider creating account also wonder net core thanks would make app cross platfrom know correctly plan another thing would like use python libaries exactly mean gensim generally topic modeling maybe also tool neural network general would like embed python thing c code sumarizing aim create desktop mobile app using net net framework net core somehow make synchronization connection like additional feature use python topic modelling neural network tool enrich whole app thing would recommend something way properly good approach topic start till wa using mainly wpf win form also entity framework ado net never used net core think time get know future suppose,2019-09-14 21:48:07,2019-09-14 21:50:23,properly synchronize desktop mobile app net,c# .net .net-core project topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
22760,22760,57921755,2019-09-13 10:19:32,,would like investigate tf idf score particular word document depends number document idf based unfortunately list result receive vary length yet number word document fixed get tf idf result word document regardless number modeling document use gensim library calculate tf idf ratio approach far good would like compare result result obtained smaller number document based model built order following somebody explain number result decreasing example number unique token first document model trained fewer document number token suddenly drop etc yet document contains fixed number token included result include maybe something wrong grateful help,2019-09-13 10:39:38,2019-09-13 10:39:38,evaluation tf idf effectiveness gensim result list incomplete,python keyword gensim tf-idf,,,CC BY-SA 4.0,False,False,True,False,False
22777,22777,57969707,2019-09-17 07:53:15,,gensim word vec python want get list cosine similarity price read document gensim word vec document describes function want whole list similarity price others,2019-09-17 19:05:43,2019-09-17 19:08:20,python word vec get list similarity rank price model,python gensim word2vec similarity cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,False
22781,22781,57961188,2019-09-16 16:45:21,,would like take word book example get vector representation call v find word whose vector representation within ball radius r v e v v r real number r know gensim ha function allows state number top vector return quite need surely use brute force search get answer slow,,2019-09-17 01:53:18,gensim find vector word ball radius r,python gensim word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
22823,22823,58045181,2019-09-22 00:41:48,,medium sized dataset encrypted comment corresponding label either positive negative wonder best way treat missing comment given missing comment rate toy example dataset applying extensive data cleaning step using gensim preprocess string removing stopwords building customized list stopwords goal fit classifier predict sentiment given encrypted comment,2019-09-22 00:54:00,2019-09-22 00:54:00,treating missing value sentiment analysis,python pandas nlp,,,CC BY-SA 4.0,False,False,True,False,False
22849,22849,58069421,2019-09-23 20:00:29,,pre trained word vec bin file using skipgram file pretty big vector dimension gb thinking method make file size smaller bin file contains vector punctuation stop word want know option decrease file size word vec safe delete punctuation stop word row would effective way,,2019-09-24 02:20:48,gensim word vec extremely big method make file size smaller,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22853,22853,58034474,2019-09-20 19:56:48,,trying modify example post applies tf idf reason line retuning empty list dictionary empty feeding dic non empty list part finding reason fails,,2019-09-23 07:07:49,sentence return empty dictionary gensim corpus,python nlp gensim spacy,,,CC BY-SA 4.0,False,True,True,False,False
22854,22854,58099559,2019-09-25 13:28:56,,imagine fasttext model trained thanks wikipedia article like explained official website would possible train another corpus scientific document could add new pertinent link word especially scientific one summarize would need classic link exist english word coming wikipedia would like enhance model new document specific sector way yes way maybe ponderate training relation coming custom document would important final wish compute cosine similarity document scientific better result thought adding scientific document,2019-09-25 13:29:36,2019-09-25 21:42:46,training model multiple corpus,python artificial-intelligence gensim training-data fasttext,,,CC BY-SA 4.0,False,False,True,False,False
22857,22857,58069724,2019-09-23 20:24:45,,wonder deploy doc vec model production create word vector input feature classifier specific let say doc vec model trained corpus follows dumped pickle file word vector used train classifier random forest predict movie sentiment suppose production document entailing totally new vocabulary said among one present training doc vec model wonder tackle case side note aware updating training document gensim doc vec model gensim retrain doc vec model using previous word vec model however would appreciate light shed matter,2019-09-24 12:46:09,2019-09-24 12:46:09,use doc vec model production,python nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
22863,22863,58123189,2019-09-26 19:01:59,,extracting word embeddings vector word vec model using model wv range value element vector seem find information documentation,2019-09-26 20:31:05,2019-09-26 22:07:46,range vector value gensim model,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22865,22865,58123369,2019-09-26 19:15:52,,given list predefined term formed one two even three word problem count ocurrences set document free vocabulary ie much many word document term need recognized form desired output first doc ha two term interest second ha formed three word term needed accounted word length could easily order document alphabetically remove repeted term set intersect term size word counting repeated word searched result term length thing get tricky using gensim form bag word detect index using new phrase e g count seend idxs considering index sequential would mean single term ha seen suggestion,2019-09-27 05:38:00,2019-09-27 05:38:00,identify term list unseen document,python nlp information-retrieval,,,CC BY-SA 4.0,False,False,True,False,False
22874,22874,58053916,2019-09-22 22:42:31,,running anaconda python apply gensim v use attribute format fix problem error comment,2019-09-22 22:44:18,2019-09-22 23:26:23,gensim model word vec ha attribute keyedvectors,python word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22886,22886,58074914,2019-09-24 07:13:10,,code make model error file c programdata anaconda lib site package gensim model word vec py line init fast version fast version help,2019-09-24 07:26:18,2019-09-24 07:26:18,utf codec decode byte xe position word vec gensim,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22900,22900,58182293,2019-10-01 09:53:47,,hosting word vec model gensim aws lambda using python boto gensim line function py file load model directly model loading line getting mysterious error without much detail cloud watch see print message til got key inclusive get right time delay two message please way get detailed error info background detail wa able download model tmp authorize retrieve model file went space file gb tmp mb switched directly loading model gensim getting mysterious error running function python lambda local work without issue probably narrow issue gensim smart open aws lambda would appreciate hint thanks,2019-12-03 18:09:35,2019-12-03 18:09:35,aws lambda boto gensim model module initialization error exit,python amazon-web-services aws-lambda gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22903,22903,58055415,2019-09-23 03:47:51,,trying use bio vec medical word embedding project using gensim downloaded biowordvec pubmed mimiciii bin web however unable load error message invalid literal int base x understand invalid character bin file able load however sure correct able open bin file edit anything someone help code using,2019-09-23 12:49:49,2020-01-15 16:45:01,load bio vec gensim,python-3.x nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
22921,22921,58134062,2019-09-27 11:54:40,,training skipgram model using gensim word vec would like exit training reaching number epoch passed parameter based specific accuracy test different set data order avoid overfitting model way gensim interrupt train word vec callback function,2020-02-12 15:51:03,2020-02-12 15:51:03,break word vec training callback function,python callback gensim word2vec early-stopping,,,CC BY-SA 4.0,False,False,True,False,False
22924,22924,58186670,2019-10-01 14:12:27,,building word vec model category recommendation dataset consisting sentence total word distinct one build model basically like tried find right number epoch model like find result counterintuitive understand increasing number epoch could lead lower performance seems misunderstanding function since observe result function way better epoch epoch epoch insight behaves like would think increasing number epoch would sure positive effect training loss,2019-10-02 08:09:53,2019-10-02 08:09:53,gensim word vec model getting worse increasing number epoch,python machine-learning nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22944,22944,58238043,2019-10-04 14:08:54,,creating fasttext model using gensim want load running error seemingly related callback code used create model callback defined aside type model identical process word vec worked without issue however open another file try load model greeted error get vocabulary load create embedding layer kera model relevant happening jupyterlab,2019-10-04 16:02:37,2019-10-04 16:08:37,loading gensim fasttext model callback fails,python callback gensim jupyter-lab fasttext,,,CC BY-SA 4.0,False,False,True,False,False
22953,22953,58171114,2019-09-30 15:36:53,,trying implement topic detection function hdpmodel gensim choose hdpmodel since model doe require know priori number topic detect really cool problem method generate topic print topic receives argument indicate number topic doc say num topic param optional indicate number topic selected passing value result topic retrieved significance set retrieves topic try defining parameter calling print topic default number topic always returned topic retrieve possible event supposed main contribution hdp thanks,,2019-09-30 15:36:53,get possible topic gensim hdpmodel,gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
22962,22962,58153359,2019-09-29 07:57:23,,created dictionary document topic probability gensim lda model iteration dictionary even exact code produce slightly different value note code copied pasted another jupyter cell first time produce second run produce third,,2019-09-29 08:06:02,different run iteration produce different result,python pandas loops gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
22963,22963,58155131,2019-09-29 12:16:48,,wondering step execute corpus pre process style like google massive pre trained word vec model http mccormickml com google pretrained word vec model python according website following bigram trigram removal stop word common one like removal number without surrounding letter source detail step also e g remove punctuation lowercase letter stem lemmatize,,2019-09-29 12:16:48,pre process text match google pre trained word vec model,nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
22970,22970,58190771,2019-10-01 18:59:58,,code error even tried importing gensim model word vec tried every possibility get done someone help thanks advance,,2019-10-02 01:26:36,word vec object ha attribute generate training data,nltk word2vec,,,CC BY-SA 4.0,True,False,True,False,False
22974,22974,58206571,2019-10-02 17:39:01,,hi trying find similar sentence using doc vec able find actual sentence matching trained sentence code link code give vector number get actual sentence matched training data eg case expecting result love building chatbots,,2020-07-22 06:25:31,doc vec find similar sentence,python nlp gensim doc2vec sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
22980,22980,58195364,2019-10-02 04:49:30,,text classification using gensim doc vec using two data set testing one stack exchange data set reddit data set trying classify post one subreddit stackexchange site particular subject using post unrelated subreddit stackexchange site negative example using data set k post train model testing set k divided positive example negative use infer vector similar function classify entry positive negative training model pre process data remove word symbol link etc leaving significant word train model code used train model method working get result would like know different way training achieve better result currently training many model different epoch vector size using infer vector similar function see vector score returned similar entry greater certain number way improve upon aspect training model also aiming get better result trained another model way larger data set k entry used model data set produced similar worse result model trained smaller data set thought training data would improved result made worse doe anyone know reason also test created new bigger test set k entry even worse original test set data test set although unique type data used original test set yet produce worse result may reason,2019-10-03 02:21:03,2019-10-03 02:21:03,text classification model using doc vec gensim,python machine-learning gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
22983,22983,58245826,2019-10-05 06:08:32,,already pretrained word vec gensim kera want use word vector word get pretrained word vec combined word po tag feature encode one hot vector kera think use embedding matrix want make embedding layer kera achieve used layer lstm tell detail,,2019-12-01 03:21:55,combine po tag feature associated word vector word get pretrained gensim word vec use embedding layer kera,python-3.x keras gensim,,,CC BY-SA 4.0,False,False,True,False,False
22986,22986,58248337,2019-10-05 12:34:15,,tried un installing installing jupyter notebook also separately installed pycharm tried working using still show error doe install gensim properly also installed virtual studio vc library support library visual studio time usage simple library good understanding using pip easy conda installing library updating still working scipy sklearn working properly,2019-10-06 00:45:56,2019-10-06 00:45:56,getting error using nltk library python even updating nltk python,python python-3.x nltk,,,CC BY-SA 4.0,True,False,True,False,True
22988,22988,58109056,2019-09-26 03:10:57,,got python dictionary stored vector file pickle method bert service google pretrained model like key phrase value phrase vector bert woman cloth idea get phrase similarity vector file bert service model gensim word vec since later equipped similarity method would please give advice get phrase keywords similarity cluster python pickle dictionary vector file maybe better idea cluster keywords bert service following code show get vector phrase keywords,,2019-09-26 06:19:34,cluster keywords get keywords similarity vector,nlp word2vec similarity cosine-similarity sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
22992,22992,58278111,2019-10-07 22:52:36,,tf estimator us feature column input layer one initializing randomly default behaviour would like pre train embeddings gensim transfer learned embeddings tf model accepts initializer argument expects callable created using however function expects saved tf checkpoint trained embeddings gensim question save gensim word vector numpy array tensor tf checkpoint format use initialize embedding column,2019-10-14 01:27:12,2019-10-14 01:27:12,importing pre trained embeddings tensorflow embedding feature column,tensorflow gensim word2vec transfer-learning,,,CC BY-SA 4.0,False,False,True,False,False
23005,23005,58253405,2019-10-06 00:41:33,,trying use dimension wikipedia word vec model analyze document using introspection found vector representation word dimension numpy ndarray however whenever try create ndarray find nearest word get value error tell looking around online indeed maximum supported number dimension ndarray give gensim able output dimension ndarray example code output goal would compute average vector word corpus format used find nearby word model alternative suggestion effect welcome,,2019-10-06 22:13:12,gensim word vec model output dimension ndarray maximum number ndarray dimension,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
23019,23019,58301450,2019-10-09 09:49:46,,want able see value word vec model small corpus want see exactly happens step particular corpus section code want see exactly,,2019-10-09 19:53:26,view word vec model,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
23041,23041,58286505,2019-10-08 12:36:41,,newbie python ml found nice script http www machinelearningplus com nlp topic modeling visualization present result lda model get attributed topic document lda changed able use lsi well original code order use lsi changed correct way lsi based probability perc contrib interpret number apart script since lsi doe get document topic function use see topic highest score,,2019-10-08 12:36:41,get topic score attributed document gensim lsi,python gensim topic-modeling latent-semantic-indexing,,,CC BY-SA 4.0,False,False,True,False,False
23111,23111,58397381,2019-10-15 14:48:54,,would like create lda model e instance gensim model ldamodel returning pre determined topic word distribution reason would like leverage gensim pyldavis etc display result topic word distribution obtain algorithm possible show incomplete code find ml community intimidating wa hoping achieve initializing eta lda model setting iteration attempt shown resulting topic topic gensim doc eta float np array str optional priori belief word probability edit calling reset model state seems work sure make theoretically sense however topic distribution given document trained think keeping topic constant,2019-10-28 11:03:17,2019-10-28 11:03:17,initialize gensim lda model pre determined prior,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
23156,23156,58393090,2019-10-15 10:58:26,,two list list word example hello world len list b contains pre trained vector corresponding vector dimension want convert two list gensim word vec model format order load model later,2019-10-15 12:48:05,2019-10-15 18:18:29,save gensim word vec file,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
23173,23173,58493250,2019-10-21 19:54:03,,trying code lda mallet model ran couple month ago ran fine longer post subject solution yet helped anyone figure wrong code solution fix problem first two cell run fine third break say return non zero exit status,,2019-10-21 20:24:11,lda mallet returned non zero exit status,python gensim mallet,,,CC BY-SA 4.0,False,False,True,False,False
23214,23214,58497442,2019-10-22 05:10:55,,trying use doc vec text classification based document subject example want classify document sport document want first training doc vec model training data use classification model logistic regression classify text positive negative seen various example online employ different method unclear detail using certain method method best text classification firstly using example better train model using document related sport document subject thinking wa training sport document could classify document based document similarity although wouldnt produce vector non sport document use train next model also feel like training model document would need huge amount document represent everything sport get good classification secondly feature actually used train logistic regression model training model document assume would track document using index sort train logistic regression model using vector class label correct thirdly seen various us taggeddocument unique id put document also shared id used represent class eg sport non sport read shared id mean model ha single vector representing class using unique id provides unique vector document correct assuming need unique labeled vector training logistic regression model point using shared id wouldnt provide terrible classification result anyone help question generally best way text classification using doc vec vector would greatly appreciated,,2019-10-22 17:56:30,best training method binary text classification using doc vec gensim,machine-learning gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
23221,23221,58545704,2019-10-24 16:39:34,,running gensim anaconda distribution python laptop prepared term document matrix vocabulary file done past getting valueerror message try run lsimodel function corpus read tutorial documentation figure missing anyone provide insight thanks advance copy paste qtconsole terminal info pattern package found tag filter available english info loading corpus file nameoffile txt info using serial lsi version node info updating model new document valueerror invalid format file nameoffile txt full error message,,2019-10-24 16:39:34,gensim valueerror invalid format file running lsimodel function blei corpus,python python-2.7 nlp anaconda gensim,,,CC BY-SA 4.0,False,False,True,False,False
23230,23230,58407649,2019-10-16 07:10:25,,trying load one fasttext pre trained model ha form bin file size bin file gb gb ram gb swap file unfortunately model start loading occupies almost gb break following error observing system monitor see ram swap fully occupied think break memory trying load file using gensim wrapper fasttext question following way fit model current memory system possible reduce size model tried quantization using following code getting following error would really appreciate help,,2019-10-16 15:37:48,fasttext bin file fit memory even though enough ram,python gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
23254,23254,58451218,2019-10-18 12:44:40,,list sentence want cluster sentence similarity using wmd word mover distance using word vec model gensim create embeddings word clustering algorithm know nltk sklearn use number vector input need give sentence array list embeddings word think use nltk clustering method custom distance function want use wmd custom function wmd function gensim us list string input prebuild wmd function us embeddings string input clustering kmeans something else handle list string input wmd custom distance function thanks,,2020-09-08 17:27:47,use wmd function gensim sentence clustering,python gensim word2vec,,,CC BY-SA 4.0,True,False,True,False,True
23289,23289,58540089,2019-10-24 11:12:40,,failed use callback save model according official document http radimrehurek com gensim model callback html attributeerror pickle local object train model shf,,2019-10-24 16:27:42,pickle error save doc vec model attributeerror,python-3.x gensim,,,CC BY-SA 4.0,False,False,True,False,False
23293,23293,58412763,2019-10-16 11:58:44,,anybody tell default value used,2019-10-21 11:32:35,2019-10-21 11:32:35,default value doc vec alpha min alpha,python scikit-learn gensim doc2vec hyperparameters,,,CC BY-SA 4.0,False,False,True,False,True
23311,23311,58556924,2019-10-25 10:37:05,,new nlp word embeddings still need learn many concept within topic pointer would appreciated question related think may development since question asked facebook muse provides aligned supervised word embeddings language used calculate word similarity across different language far understand embeddings provided muse satisfy requirement coordinate space compatibilty seems possible load embeddings library gensim wonder possible load multiple language word embeddings gensim library type similarity measure might fit use case use loaded word embeddings calculate cross lingual similarity score phrase instead word e g pnv german v trasporto pubblico locale italian english term public transport open implementation library language embeddings though may need time learn topic thank advance,2019-10-25 10:43:30,2020-09-21 14:40:30,calculate cross lingual phrase similarity using e g muse gensim,python nlp multilingual gensim word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
23324,23324,58619716,2019-10-30 06:28:27,,data ha million row training gensim similarity model making multiple sav file model sav model sav model sav problem loading loading one sub part instead sub part hence performing horribly prediction parameter option working per gensim documentation per gensim documentation http radimrehurek com gensim similarity docsim html saving file handle giving following params worked model save fname handle separately none model load filepath mmap r even tried pickle sav file pickle st shard e model sav compressing sub part gz file compress one shard sub part also give sort pickle error expected result give matching document corpus give model sav file mentioned loading doe even execute shard checked result shard question use sub file gensim model predict similarity test document without looping every sub file individually presenting union result,,2019-11-04 17:31:33,saving loading multiple shard made gensim similarity model,python model gensim,,,CC BY-SA 4.0,False,False,True,False,False
23332,23332,58522356,2019-10-23 11:57:18,,using anaconda enviroment python gensim basically data dataframe tha ti separated test training set structure x test xtrain dataframe format already preprocessed code use creating model everything work fine effectively use get topic problem come try compare similarity new document corpus code using last two line get error idea solve trying debug hour believe followed code many people use fot getting similarity thing tried solve using work error code wa obtained replace lda model corpus corpus index model vec index new doc freq vector similarity matrixsimilarity work believe doe give proper result doe model information fact work tell ha something data type print lda model corpus get idea mean though,2019-10-24 06:51:40,2019-11-10 14:47:41,error many value unpack trying get similiraties gensim using lda model,python gensim similarity recommendation-engine lda,,,CC BY-SA 4.0,False,False,True,False,False
23334,23334,58635642,2019-10-31 01:07:27,,training doc vec corpus file huge want know get value total word edit right,2019-10-31 01:16:47,2019-10-31 22:08:43,total word must provided alongside corpus file argument,gensim,,,CC BY-SA 4.0,False,False,True,False,False
23359,23359,58610689,2019-10-29 15:35:10,,produced glove vector using code provided http github com stanfordnlp glove blob master demo sh using corpus bin file txt file vector trying import file gensim work like word vec vector tried changing load using binary format text file format ended getting pickling error tried ignoring unicode error work still got unicode error code right error message keep getting pickling error wa something like unpickling error using word vec load text file format,2019-10-30 17:07:07,2019-10-30 17:07:07,importing glove vector gensim unicodedecodeerror utf codec decode byte xe position invalid continuation byte,python gensim word2vec glove,,,CC BY-SA 4.0,False,False,True,False,False
23370,23370,58574772,2019-10-26 21:12:45,,getting error try install make work workaround full error stacktrace p using packaging tool,2019-10-26 21:21:36,2019-10-27 18:03:04,unable install gensim python,python-3.x scipy gensim pipenv python-3.8,,,CC BY-SA 4.0,False,False,True,False,False
23391,23391,58710000,2019-11-05 11:04:03,,want get list similar word since spacy built support want convert spacy model gensim word vec get list similar word tried use method time consuming doe save model text file hence able use following method,2019-11-05 11:15:35,2019-11-05 16:11:16,way load spacy trained model gensim,python-3.x nlp gensim spacy similarity,,,CC BY-SA 4.0,False,True,True,False,False
23397,23397,58682909,2019-11-03 17:43:49,,working way lda model text analysis heard mallet implementation best however seems generate poor result compare gensim version think may something wrong anyone explain discrepancy give following plausible inference topic however thing work differently mallet implementation little difference topic model infers seems making elementary blunder possibly specifying relevant model parameter correct way however baffled might grateful advice,2019-11-03 20:50:00,2019-11-03 20:50:00,doe mallet lda give poor result gensim version,python nlp gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
23409,23409,58712856,2019-11-05 13:55:28,,let say word vec model trained word vec model vocabulary word oov word occurs compute vector vec using compute vec oov word method want add append oov word corresponding vector vec already trained model word vec model already checked link answer question combining adding vector different word vec model http datascience stackexchange com question train existing word vec gensim model new word http radimrehurek com gensim model keyedvectors html gensim model keyedvectors basekeyedvectors add,,2019-11-06 09:32:33,add word vector manually word vec gensim,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
23425,23425,58714746,2019-11-05 15:40:56,,got question following simple gensim tutorial gensim website tried got following error doe anyone know reason message know model wv file thank advance,,2019-11-05 17:11:31,gensim errno file directory model wv,python model gensim,,,CC BY-SA 4.0,False,False,True,False,False
23431,23431,58685936,2019-11-04 00:41:06,,gensim solve equation king woman man queen line pas output interpolation like would awesome pas two dissimilar word like rain mouse see word need added subtracted transform one gensim tool,,2019-11-04 00:41:06,use gensim keyedvectors find connecting word two given word,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
23445,23445,58749620,2019-11-07 13:19:46,,lot example lda mallet topic modelling however non show add dominant topic percent contribution topic keywords original dataframe let assume dataset code dataset code tried something like work,2019-11-07 13:35:59,2020-07-27 06:39:56,return dominant topic percent contribution topic keywords original model,python gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
23455,23455,58730230,2019-11-06 12:30:19,,used gimsm lsa per tutorial http www datacamp com community tutorial discovering hidden topic python got following output running list text doe london indicate,2019-11-06 16:58:20,2019-11-06 16:58:20,doe score indicate topic modelling,python nlp gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
23485,23485,58735585,2019-11-06 17:28:04,,research fasttext pre trained model need word frequency analysis doe vec bin file provided fasttext website contain info word frequency yes get using load word vec format load model tried using model wv vocab word count give word frequency rank original word frequency,2019-11-06 19:54:03,2019-11-06 19:54:03,gensim chance get word frequency word vec format,python-3.6 gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
23491,23491,58786596,2019-11-10 07:30:53,,struggling following problem downloaded pre trained word embedding model spanish million word dimensional word vector spanish loaded successfully even managed undertake couple experiment similar word basic analogy spanish b c try following raise error already checked word actually word embedding also eliminated possibility encoding error based research type error produced token word supposed wrapped list however know apply specific problem besides block code code used deep learning cookbook chapter word vecmath complete script thank support,,2019-11-10 19:14:34,using spanish pretrained model gensim cause raise keyerror word vocabulary word,python deep-learning gensim word-embedding keyerror,,,CC BY-SA 4.0,False,False,True,False,False
23493,23493,58754450,2019-11-07 17:50:21,,using gensim train skip gram word vec model dataset ha million sentence vocabulary size would like see model accuracy iteration used callback function see score returned value updated iteration wa set tried change value ha effect model wa initialized callback class something like printed every epoch value never changed wa expecting value updated iteration make sense new machine learning word vec thanks lot help,,2019-11-08 14:15:28,similar word improve iteration,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
23500,23500,58816895,2019-11-12 10:38:53,,trying train doc vec model using gensim dataset using newsgroups dataset included sklearn datasets module used example gensim documentation create model checked every line code seems working line initializes model get type error http scikit learn org datasets twenty newsgroups html,,2019-11-12 10:47:20,type error trying create doc vec model gensim,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,True
23503,23503,58718429,2019-11-05 19:47:10,,ran following error msg validationerror row distribution topic term dists sum,,2019-11-05 19:47:10,fix pyldavis gensim error msg dictionary,python jupyter-notebook gensim,,,CC BY-SA 4.0,False,False,True,False,False
23506,23506,58723979,2019-11-06 06:04:50,,ran gensim train doc vec corpus need extract vector document input data logical regression spark,,2019-11-06 17:21:39,recall doc vec spark input vector logical regression machine learning,apache-spark gensim,,,CC BY-SA 4.0,False,False,True,False,False
23510,23510,58789484,2019-11-10 14:13:54,,trying lemmatize document following code lemmatization work produce byte string therefore next part code produce cant concan byte str error changed token str given code output code given using python bit code best regard,2019-11-10 21:15:46,2019-11-10 21:15:46,gensim lemmatization remove postag b,gensim lemmatization,,,CC BY-SA 4.0,False,False,True,False,False
23515,23515,58771410,2019-11-08 17:40:47,,looking test datasets optimize word vec model found good one gensim gensim test test data question word txt doe anyone know similar datasets thank,,2019-11-12 19:37:54,question pair ground truth datasets word vec model testing,machine-learning nlp word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
23522,23522,58666699,2019-11-01 22:45:31,,using implementation module order construct word embeddings sentence plain text file despite word defined vocabulary getting error tried apply given answer similar question work hence posted question code,,2019-11-01 23:27:33,word vec keyerror word x vocabulary,gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
23523,23523,58666807,2019-11-01 23:02:35,,using implementation module despite getting reason program throw exception code end output,,2019-11-01 23:34:16,fasttext throw exception without reason,python-3.x gensim word-embedding fasttext,,,CC BY-SA 4.0,False,False,True,False,False
23527,23527,58804099,2019-11-11 15:18:43,,going gensim source noticed utility function clear punctuation except word starting underscore reason,,2019-11-11 18:15:07,doe gensim ignore underscore preprocessing,nltk gensim,,,CC BY-SA 4.0,True,False,True,False,False
23548,23548,58793692,2019-11-10 22:56:49,,using latent dirichlet allocation gensim sklearn python use topic distribution document associated classification let say movie review labeled positive negative use supervised learning algorithm classify unseen document resource work people done recommend take look break problem let suppose corpus document movie review document labeled either positive negative positive negative review using latent dirichlet allocation topic modeling like generate topic model corpus document associated distribution topic using topic distribution classification positive negative like train supervised machine learning algorithm like neural network decision tree classify future movie review seen model either positive negative,,2019-11-10 22:56:49,topic modeling use topic distribution document associated classification use supervised learning algorithm,python scikit-learn gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,True
23551,23551,58836322,2019-11-13 11:40:57,,trying implement semantic search retrieve similar document dataset unstructured french document document categorized template word per document using doc vec using gensim find paragraph embeddings dimension window dataset converting search query maximum word vector dimension comparing cosine distance find document close search query getting good result please suggest strategy semantic search wa trying reduce number word dataset rake keyword extraction,2019-11-13 15:46:33,2019-11-25 20:17:33,language representation huge document word query based retrieval,search nlp gensim cosine-similarity doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
23553,23553,58839049,2019-11-13 14:12:14,,keyword list lowercase let say list text lowercase let say need transform text right checking keywords text replace keywords complexity n really slow long text keywords case wa trying use phraser manage build one keywords could someone suggest optimized way,2019-11-13 22:18:55,2019-11-14 19:27:32,python connect composed keywords text,python data-science gensim,,,CC BY-SA 4.0,False,False,True,False,False
23571,23571,58822292,2019-11-12 15:56:58,,context exists severals question train using streamed data anyhow question deal issue streaming use multiple worker since array split thread hence wanted create generator providing functionality gensim result look like result error typeerror unhashable type list since would work yield single splitted document assume gensims wrap generator within extra list case would look like hence batch would also wrapped resulting something like list list list processed gensim question stream pas batch order use multiple worker change code accordingly,2020-01-09 22:18:00,2020-07-17 23:38:48,batch train word vec gensim support multiple worker,python nlp batch-processing gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
23584,23584,58797101,2019-11-11 07:24:27,,trying store data global variable inside redis queue rq worker data remains pre loaded e need loaded every rq job specifically working word vec vector loading using gensim keyedvectors app python flask running linux server containerized using docker goal reduce processing time keeping handful large vector file loaded memory time first tried storing global variable flask gunicorn worker load vector eats lot ram need one worker store particular vector file told one solution set number rq worker holding vector global variable control worker get vector file loaded far rq worker py app py docker stack yml redacted bunch stuff docker provide detail relevant generally work except rq worker seems load w v scratch time get new job defeat whole purpose keep vector stored w v global variable need reloaded time missing something set differently told might possible use mmap load vector file global variable rq worker sits sure would work keyedvectors advice would much appreciated,,2019-11-11 18:46:45,store gensim keyedvectors object global variable inside redis queue worker,docker flask redis gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
23596,23596,58671002,2019-11-02 12:14:43,,around row csv file getting memory error statement could please advise extract value similarity object without getting memory error,2019-11-15 06:37:10,2019-11-15 06:37:10,memory error similarity matrix large number row gensim,gensim,,,CC BY-SA 4.0,False,False,True,False,False
23610,23610,58895222,2019-11-16 21:05:11,,topic modeling corpus english th century correspondence using lda using topic coherence well silhouette score evaluate topic use gensim coherence highest ever gotten wa score model tested even topic make sense qualitative evaluation even extensive pre processing hyperparameter comparison basically accepted best get order write reading topic coherence understood pipeline model human judgement one thing seen find clear info though based exclusively calculation made corpus based external data well like trained external corpus might nothing domain use instead,,2020-01-14 04:03:32,topic coherence gensim coherencemodel calculated based exclusively corpus external data well,data-science topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
23612,23612,58876630,2019-11-15 12:01:11,,trying export fasttext model created gensim binary file doc unclear achieve done far doe seems like best solution since later want load model using get infinite loop loading created function get completed around second,,2020-05-15 20:50:12,export fasttext model created gensim binary file,python nlp gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
23645,23645,58965192,2019-11-20 23:55:57,,document like compute tf idf matrix gensim like document get tf idf like want tf idf vector document include word tf idf value e include every word mentioned corpus gensim maybe library compute tf idf matrix fashion although like gensim need able handle large data set e g achieved result sci kit small data set sci kit ha memory problem large data set,,2019-11-22 20:13:49,include word corpus gensim tf idf,python nlp gensim text-classification tf-idf,,,CC BY-SA 4.0,False,False,True,False,False
23647,23647,58869364,2019-11-15 02:10:01,,dataset million question want compare tf idf vector retrieve similar pair question according gensim documentation also special syntax need similarity document index index e query indexed document special syntax us faster batch query internally ideal v pairwise similarity however since million document numpy array length million large store memory way get similar pair question,2020-06-20 09:12:55,2019-11-15 05:52:46,gensim similarity large dataset million,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
23651,23651,58930298,2019-11-19 09:10:59,,building machine learning model process document extract key information need use word embedding ocred output several different option embedding google word vec stanford facebook fasttext main concern oov word ocr output lot misspelled word example want embeddings output embedding embdding e missed ocr certain level similarity care much associated contextual information chose facebook fasttext give embeddings oov word well concern size embeddings vector size fasttext model length way reduce size returned word vector thinking using pca dimensionality reduction technique given size word vector time consuming task,2019-11-20 00:49:26,2020-04-30 18:02:23,reducing size facebook fasttext word vec,data-science gensim word2vec dimensionality-reduction fasttext,,,CC BY-SA 4.0,False,False,True,False,False
23655,23655,58883173,2019-11-15 19:03:56,,want create topic model data provided jstor e g http www jstor org dfr sample datasets however copyright allow full text access instead request list unigrams followed frequency document supplied plain e g easy convert bag word vector however found example gensim lda model built fulltext would possible pas vector instead,2019-11-17 14:55:29,2020-01-14 04:19:55,creating lda model using gensim bag word vector,vector lda topic-modeling jstor,,,CC BY-SA 4.0,False,False,True,False,False
23658,23658,58886579,2019-11-16 01:04:05,,use gensim cbow training corpus get similar word set input word example given set input word david mary married infer output word like wedding husband wife couple etc,,2019-11-16 01:07:40,find similar word set input word cbow gensim,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
23674,23674,58871071,2019-11-15 05:51:44,,trying find similarity document e document document using doc vec gensim keyedvectors py finding similarity score score negative document document result nltk word tokenize doe negative score mean try find similarity two tokenized document p trained model document page page word document,2019-11-15 14:34:24,2019-11-15 14:34:24,getting negative score model docvecs similarity unseen doc document document,python nlp nltk gensim,,,CC BY-SA 4.0,True,False,True,False,False
23689,23689,58938729,2019-11-19 16:28:32,,run code day without output also without error something didnt get topic gensim model bag word created dataset consist document,2019-11-19 17:18:43,2019-11-19 17:18:43,extremely slow lda training model using python gensim library,python pandas gensim,,,CC BY-SA 4.0,False,False,True,False,False
23701,23701,58986684,2019-11-22 02:38:46,,clustering certain corpus obtaining result group sentence together obtaining tf idf checking similarity weight certain threshold value gensim model problem despite putting high threshold value sentence similar topic opposite polarity get clustered together example similarity weight obtained like like method library alternative model differentiate polarity effectively assigning low similarity opposite vector output like dont like separate cluster p pardon conceptual error rather new nlp thank advance,2019-11-25 07:08:49,2019-11-25 07:08:49,text representation differentiate string similar topic opposite polarity,nlp cluster-analysis gensim similarity,,,CC BY-SA 4.0,False,False,True,False,False
23715,23715,58975407,2019-11-21 12:44:46,,good day fellow human methodological question confused deep research tiny amount time question arises following problem need apply semi supervised unsupervised clustering document document classified multi label approximately document classified number unsupervised document could become next day main idea applying semi supervised clustering based label hand alternatively going fully unsupervised soft clustering thought creating embeddings whole document lie confusion library best task guess utmost importance need lie context whole document far know bert fasttext provide context dependent word embedding whole document embedding hand gensim doc vec context agnostic right think saw way train sentence embeddings bert via huggingface api wa wondering whether could useful consider whole document single sentence suggestion probably exposing utter ignorance confusion matter brain melted thank much time viva edit answer gojomo document average word original task wa multi label text classification e document n label number label n highly imbalanced labeled document far due several issue asked document provider give also unlabeled data reach order k used fasttext classification mode result obviously atrocious also run k nn doc vec document embedding result obviously still atrocious wa going use biomedical bert based model like biobert scibert produce ner tagging trained domain specific datasets document later apply classifier unlabeled document disposal wanted adventure semi supervised classification unsupervised clustering explore possibility say master thesis,2019-11-21 21:27:00,2019-11-21 21:27:00,nlp best document embedding library,nlp document gensim embedding bert-language-model,,,CC BY-SA 4.0,False,False,True,False,False
23731,23731,59009670,2019-11-23 16:19:38,,trying reimplement wor vec pytorch implemented subsamping according code original paper however trying understand subsampling implemented gensim looked source code manage grasp reconnects original paper thanks lot advance,,2019-11-25 19:42:23,doe gensim implement subsampling word vec,gensim word2vec subsampling,,,CC BY-SA 4.0,False,False,True,False,False
23732,23732,59024220,2019-11-25 01:48:29,,beginner nlp first time topic modeling wa able generate model however produce coherence metric converting term document matrix new gensim format df sparse matrix gensim corpus model finally attempted get coherence score using coherence model error dictionary id token may initialized standard gensim corpus dictionary setattr dictionary id token v k k v dictionary token id item attributeerror dict object ha attribute id token,,2019-11-25 09:07:15,error computing coherence score attributeerror dict object ha attribute id token,python scipy nlp gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
23747,23747,58993767,2019-11-22 11:54:50,,make gensim lda model use pre determined topic distribution determining topic new doc ex return possible return distribution eta e,,2020-01-14 03:47:38,initialize gensim lda model pre determined topic distribution,python gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
23762,23762,58961983,2019-11-20 19:30:20,,gensim documentation say save trained model disk later load back either continue training new training document transform new document would like dictionary corpus tf idf model however documentation seems say possible without explaining save thing load back using pickle know right,2019-11-20 19:38:13,2020-04-29 20:17:51,save model dictionary corpus disk gensim load,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
23788,23788,59079173,2019-11-27 22:16:11,,training gensim doc vec model couple day epoch running smoothly got last epoch suddenly stopped logging anything new last message logged wa info gensim model base vec epoch progress example word qsize qsize line code save model epoch saved anything idea could issue,,2019-11-27 22:16:11,gensim doc vec training stalled,python gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
23799,23799,58999509,2019-11-22 18:01:00,,way map generated topic lda list document identify topic belongs interested clustering document using unsupervised learning segregating appropriate cluster example topic running lda model best hyperparameter return number topic already defined withe pre trained lda model new sentence document user input waiting guy good solution p using gensim nlp,,2019-11-25 15:49:10,map topic document topic modeling done lda,nlp gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
23846,23846,59067555,2019-11-27 10:01:20,,getting keyerror running code python completed code error getting doe anyone know might happen think ha vtransformer running code getting error trying select one column dataframe throw error created pipeline used one column still getting error x train look detail x train,2019-11-28 22:44:34,2019-11-30 18:00:47,python keyerror using vtransformer,python dataframe pipeline gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
23856,23856,59050644,2019-11-26 12:07:13,,trying train word vec model wikipedia text data using following code minute program running getting following error error message,2019-11-26 12:20:08,2019-11-26 17:40:21,memoryerror unable allocate array shape data type float using word vec python,python multiprocessing python-multiprocessing gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
23877,23877,59056631,2019-11-26 17:42:33,,tf idf vocabulary already get gensim tfidfvectorizer specific metric method drop tail tf idf vocabulary mean tail zipf diagram visualize would like see accuracy change drop number word vocabulary instance vocabulary ha word,2019-11-26 17:49:00,2019-11-27 11:39:51,specific metric method drop tail tf idf vocabulary,python machine-learning nlp data-science tf-idf,,,CC BY-SA 4.0,False,False,True,False,False
23878,23878,59120553,2019-11-30 21:47:57,,problem solve given sentence return intent behind think chatbot reduced example dataset intent left dict stripped sentence spacy tokenized word using word vec algorithm provided gensim library resulted use word vec model googlenews vector negative bin list sentence sentence list word sentence sentence word sentence list must size word padding remaining zero word list ha element word vec dimension following tutorial transformed tensordataset moment confused use word vec probably wasting time believe embeddings layer lstm configuration composed importing word vec model weight using enough pytorch saying doe accept embeddings index int type edit found importing weight matrix gensim word vec straightforward one ha import word index table well soon fix issue post,2019-12-01 00:45:34,2019-12-01 10:31:35,use gensim pytorch create intent classifier lstm nn,python pytorch lstm word2vec torch,,,CC BY-SA 4.0,False,True,True,False,False
23891,23891,59093325,2019-11-28 16:46:19,,trying annotate vocabulary corpus trained word vec model corpus grouped word related based score key first word key remaining word list tuple word score respect key example coffee key value know coffee releated latte green tea espresso starbucks data would like label word latte cohypo green tea cohypo espresso hypo starbucks related tim horton related cohypo http en wiktionary org wiki cohyponym hypo http en wiktionary org wiki hyponyme related word repeated morpho morphological variant example computer computer partof indicates annotated word part word interest suggestion idea approach problem,2019-11-28 23:29:28,2019-11-28 23:29:28,annotating vocabulary using word vec model,nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
23918,23918,58927877,2019-11-19 06:27:33,,trained word embedding word vec model using gensim used similar method find associated word result wonder coefficient low even top word le thank,,2019-11-19 06:27:33,gensim similar method coefficient low,nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
23957,23957,59129793,2019-12-01 20:43:42,,title say would like load custom word vector built vector class found several question folk successfully loaded vector object current project would like separate vector object specifically using biowordvec generate word vector serializes vector using method end calling saving model side either use method load word vector also method expects vocab txt file binary file already binary file link vector documentation reference code test load process tried various combination success help advice would greatly appreciated,,2019-12-02 22:35:52,load word vector gensim spacy vector class,python gensim spacy,,,CC BY-SA 4.0,False,True,True,False,False
23974,23974,59232589,2019-12-08 05:05:46,,trying apply tfidf vectorizer gensim lda model success look like use sure going vectorizer data ha cleaned pre processed data code error asking use asking,2019-12-08 05:10:17,2019-12-08 05:40:16,tfidf vectorizer truth value array one element ambiguous use,python nlp tfidfvectorizer,,,CC BY-SA 4.0,False,False,True,False,False
23981,23981,59281409,2019-12-11 08:17:32,,trying execute simple code lemmatize string error iteration found solution reinstalling web py worked python code error,,2019-12-11 08:25:50,gensim lemmatize error generator raised stopiteration,python nlp gensim lemmatization,,,CC BY-SA 4.0,False,False,True,False,False
24000,24000,59282572,2019-12-11 09:29:46,,would like load pretrained multilingual word embeddings fasttext library gensim link embeddings http fasttext cc doc en crawl vector html particular would like load following word embeddings cc de vec gb cc de bin gb gensim offer following two option loading fasttext file load input hidden weight matrix facebook native fasttext bin output file load facebook model load full model word embeddings enables continue model training load word embeddings model saved facebook native fasttext bin format load facebook vector load word embeddings faster doe enable continue training source gensim documentation http radimrehurek com gensim model fasttext html gensim model fasttext load facebook model since laptop ha gb ram continuing get memoryerrors loading take long time several minute option load large model disk memory efficient,,2019-12-11 19:54:18,memory efficiently loading pretrained word embeddings fasttext library gensim,python nlp gensim word-embedding fasttext,,,CC BY-SA 4.0,False,False,True,False,False
24011,24011,59168273,2019-12-04 02:53:11,,adapted existing implementation doc vec model gensim library implementation used found github gotten work version use error rate performance metric would like know accuracy precision f score model also trying adapt existing code generate accuracy precision f score also successful put function generates error rate anyone help adapt also generate previously mentioned metric would much appreciated,,2019-12-04 02:53:11,generating performance metric gensim doc vec model,python-3.x gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
24033,24033,59268044,2019-12-10 13:12:54,,trying measure word mover distance lot text using gensim word vec tool python comparing text text first use itertools create pairwise combination like memory sake combination text repeated big dataframe instead make reference dataframe index text look like comparison function use index look text original dataframe solution work fine wondering whether would able big datasets instance row dataset text give year worth computation laptop way could optimized better code right,2020-07-23 12:45:31,2020-07-23 12:45:31,optimize word mover distance look function,python python-multiprocessing dask gensim wmd,,,CC BY-SA 4.0,False,False,True,False,False
24038,24038,59237691,2019-12-08 16:58:26,,topic modeling ldamallet give meaningful topic problem visualize output pyldavis tried work,2019-12-08 21:10:05,2019-12-08 21:10:05,convert ldamallet model basic gensim ldamodel pyldavis,lda,,,CC BY-SA 4.0,False,False,True,False,False
24061,24061,59270197,2019-12-10 15:06:41,,got file regarding pre trained data link bin file http fasttext cc doc en crawl vector html want use file input layer neural network maybe form vector want pre trained data learn training data let call training data data txt loaded pre trained model using fasttext genism library however know train please advice,2019-12-13 11:17:10,2019-12-13 11:17:10,fasttext gensim train additional data pre trained data bin,gensim bin fasttext,,,CC BY-SA 4.0,False,False,True,False,False
24062,24062,59270202,2019-12-10 15:07:15,,looking documentation text vec finding hard see might make sample matrix document distance value matrix distance two doc looking example code problem end matrix find hard interpret something like provided able normal wmd tool gensim buch calling similarity function unsure done rwmd reason trying want get faster speed lc rwmd seems implemented text vec thanks lot,,2019-12-10 15:07:15,pairwise comparison document relaxed wmd text vec r,gensim word2vec wmd text2vec glove,,,CC BY-SA 4.0,False,False,True,False,False
24073,24073,59318935,2019-12-13 08:45:43,,already training model fasttext gensim get distance two sentence described doe calculate value like know formula api document http radimrehurek com gensim model keyedvectors html gensim model keyedvectors doc veckeyedvectors distance,,2019-12-14 23:08:40,doe gensim model fattext wv wmdistance calculate two document,python-3.x gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
24087,24087,59289611,2019-12-11 15:57:00,,take stand word around target word impact positive negative way kind interpretation sne graph given end page link provided reference thank http www kaggle com pierremegret gensim word vec tutorial source post page bf getting started,2019-12-11 16:22:02,2019-12-11 16:22:02,anybody explain sne visualization graph word vec model signifies,data-visualization data-science word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
24088,24088,59292179,2019-12-11 18:46:09,,code gensim import model import numpy np create tf idf model tfidf model tfidfmodel corpus smartirs ntc show tf idf weight doc tfidf corpus print dictionary id np around freq decimal id freq doc result brocolli brother eat good like rata saluut brother rata around basebal drive lot mother practic spend time rata drive blood caus expert health increas may pressur suggest tension want remove tuples exaple word drive want remove tuple,,2019-12-11 18:46:09,remove tuple corpus tf idf,python tuples gensim tf-idf,,,CC BY-SA 4.0,False,False,True,False,False
24094,24094,59293936,2019-12-11 20:55:57,,standard process gensim us compile cython bit forked project edited cython code seem recompile run getting error seem even attempt compile cython code fresh clone branch compile gensim source ubuntu gcc,2019-12-12 19:27:24,2019-12-12 19:27:24,compile cython module gensim,gensim,,,CC BY-SA 4.0,False,False,True,False,False
24105,24105,59358828,2019-12-16 14:39:13,,getting error following code trying load model model folder keep getting error traceback update error wa solved upgrading numpy model wa dumped using new version wa loading using older version,2019-12-16 15:57:31,2019-12-16 15:57:31,python error typeerror errstate object callable,python scikit-learn gensim,,,CC BY-SA 4.0,False,False,True,False,True
24127,24127,59312001,2019-12-12 20:08:37,,getting error create model based implementation module entry ha three part presented within list model contains three entry sake demonstration tried value edit error stack trace correcting form feature vector according comment gojomo,2019-12-13 09:29:17,2019-12-13 09:29:17,word vec rid typeerror unhashable type list attributeerror dlsym x fa c attachdebuggertracing symbol found,gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
24136,24136,59297344,2019-12-12 03:34:19,,aim text summarization sure correctly plan got dataframe called train data cell every row contains message looking iterate cell message dataframe column get keywords message using gensim summarization keyword package understand keyword function take text input pas whole df column inside tried iterate cell keyword function text seem work missing code plan count length original v new message ie keyword column get compression rate ratio,,2019-12-12 07:52:08,getting keywords message,python nlp nltk gensim text-classification,,,CC BY-SA 4.0,True,False,True,False,False
24139,24139,59322409,2019-12-13 12:14:22,,using pyldavis visualise result lda mallet need wrapper gensim library print found topic ordered however using pyldavis visualise topic topic order doe align printed topic example see topic smartphones however visualise model pyldavis topic smartphones another topic car example smartphone topic anymore topic example example known error normal somebody help,,2020-06-06 06:53:51,pyldavis visualisation doe align generated topic,python gensim lda topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
24175,24175,59348206,2019-12-15 21:27:14,,complete novice nlp would like load zipped xlm file hungarian wikipedia corpus mb downloaded dumpfile started parsing python gensim hour laptop crashed complaining run ram fairly old laptop gb ram wa wondering whether way could solve problem either tinkering code e g reducing corpus taking say th random sample using cloud platform enhance cpu power read post aws used puposes unsure service select amazon ec also checked google colab got confused list hardware acceleration option gpu cpu context tensorflow sure suitable nlp find post jupyter notebook code tried downloading wikipedia dump guidance would much appreciated,2019-12-15 22:57:23,2019-12-16 01:47:50,loading wikipedia xml file gensim,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
24178,24178,59331278,2019-12-14 00:17:18,,python building ngrams gensim passing word spacy lemmatization finding spacy working well keeping many word plural look like mostly happening mistakenly tagging noun proper noun output preferred output would change way accomplish spacy tool,,2019-12-16 19:15:30,improve spacy lemmatization bigram proper noun plural,python nlp gensim spacy,,,CC BY-SA 4.0,False,True,True,False,False
24182,24182,59333165,2019-12-14 07:28:08,,run py file containing following code following error generated traceback recent call last file assignment py line model gensim model keyedvectors keyedvectors load model file user harshpanwar desktop enthire assignment myenv lib python site package gensim model keyedvectors py line load model super wordembeddingskeyedvectors cl load fname handle kwargs file user harshpanwar desktop enthire assignment myenv lib python site package gensim model keyedvectors py line load return super basekeyedvectors cl load fname handle kwargs file user harshpanwar desktop enthire assignment myenv lib python site package gensim utils py line load compress subname saveload adapt suffix fname file user harshpanwar desktop enthire assignment myenv lib python site package gensim utils py line adapt suffix compress suffix true npz fname endswith gz fname endswith bz else false npy attributeerror word vec object ha attribute endswith,,2019-12-14 09:33:32,attributeerror word vec object ha attribute endswith,python machine-learning nlp artificial-intelligence word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
24185,24185,59397949,2019-12-18 18:15:49,,training embeddings large corpus gather documentation build vocabulary beginning training case building vocabulary take many hour like save time using vocabulary first model method take object another model dummy example,2019-12-18 18:37:13,2019-12-19 18:23:47,initialize gensim model vocabulary another model,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
24190,24190,59316635,2019-12-13 05:29:57,,need find similarity document give score normal essay marking anyone please give hint reference thank much,,2019-12-13 05:29:57,use gensim aes automatic essay scoring project,python nlp,,,CC BY-SA 4.0,False,False,True,False,False
24204,24204,59368232,2019-12-17 05:48:21,,wonder doe function gensim actually difference using thank,,2019-12-17 06:08:36,gensim word vec fasttext build vocab frequency,python gensim word2vec fasttext,,,CC BY-SA 4.0,False,False,True,False,False
24208,24208,59418433,2019-12-20 00:14:31,,study gensim topic modeling use result lda model ha two function get topic get document topic find topic word document topic want try find get topic result something like get document topic find relation document topic somewhere read instruction http radimrehurek com gensim model hdpmodel html find maybe miss something function hdp model like get document topic lda model,2019-12-21 13:25:22,2020-03-17 11:20:32,get document topic using model hdpmodel hierarchical dirichlet process gensim,document gensim word lda hdp,,,CC BY-SA 4.0,False,False,True,False,False
24210,24210,59419123,2019-12-20 02:16:48,,new gensim topic modeling sample code far good want use lda model predict text least need know topic distribution text topic word relation think prediction common important function lda know find function gensim answer say doc lda model doc bow prediction calculating topic distribution unseen document gensim sure,2019-12-21 13:25:57,2020-02-11 10:49:42,use gensim topic modeling predict new document,document gensim predict lda,,,CC BY-SA 4.0,False,False,True,False,False
24213,24213,59385399,2019-12-18 04:18:30,,use wrapper link run gensim library provide parameter assign argument ref gensim code line found seems working different setting running time matter run computer colab result similar worker spent time also tried dose mean using proper way run mallet lda parallel thanks reference code,,2019-12-18 04:18:30,parallel problem mallet lda gensim wrapper,gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
24244,24244,59423553,2019-12-20 10:17:37,,dear trained word vec gensim using wikipedia data saved using following program want use model kera multi class text classification change need following code actually new trying learn,,2019-12-20 16:07:31,using pretrained gensim word vec embedding along data set kera,python-3.x machine-learning keras artificial-intelligence gensim,,,CC BY-SA 4.0,False,False,True,False,False
24249,24249,59465247,2019-12-24 07:20:17,,topic modeling using gensim jupyter notebook successfully created model visualized code want find dominant topic sentence using code however getting error typeerror traceback recent call last df topic sent keywords format topic sentence ldamodel lda model corpus corpus text data format format topic sentence ldamodel corpus text get main topic document row enumerate ldamodel corpus row sorted row key lambda x x reverse true get dominant topic perc contribution keywords document j topic num prop topic enumerate row typeerror supported instance int tuple understand problem anyone help thanks advance,,2020-03-20 04:30:28,type error finding dominant topic sentence gensim,jupyter-notebook typeerror python-3.7 gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
24275,24275,59469032,2019-12-24 12:44:25,,built semantic similarity engine based lsi gensim receiving result similarity score high input text garbage text interpret score used cosine similarity vector obtained lsi result word appears one sentence input text token garbage semantic similarity function,,2019-12-24 12:44:25,lsi returning high similarity score garbage input,python nlp gensim latent-semantic-indexing,,,CC BY-SA 4.0,False,False,True,False,False
24283,24283,59510075,2019-12-28 10:32:18,,application need load pretrained model located path using running code getting error basically error occurring say permission denied try load model using simple python script outside flask app work fine error occurring inside flask application,,2019-12-28 18:24:51,unable load file flask application,python python-3.x flask gensim,,,CC BY-SA 4.0,False,False,True,False,False
24297,24297,59391403,2019-12-18 11:50:00,,want ask improve score query corpus trained word embedding thanks really grateful read reference,,2019-12-18 11:50:00,improving word mover distance similarity score,python gensim word2vec fasttext sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
24329,24329,59478986,2019-12-25 13:45:50,,trained doc vec model using corpus document model used infering docvec million document everyday ensure stability set small value large instead setting constant random seed accepts one document time take almost second infer docvec handle series document infering step,,2019-12-25 21:19:29,perform doc vec infer vector million document,gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
24357,24357,59548233,2019-12-31 20:28:45,,got several hundred panda data frame ha column long string need processed sentencized finally tokenized modeling word vec store format disk build stream pas gensim word vec function format would best important criterion would performance vi vi training take many day coherent structure filesystem would also nice would crazy store several million maybe even billion text file containing one sentence perhaps sort database wa numerical data use hdf text cleanest would store original data frame seems le ideal perspective load data frame largish every epoch make sense,,2020-01-02 05:00:26,best way store processed text data streaming gensim,stream nlp storage gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
24368,24368,59568131,2020-01-02 18:20:04,,new machine learning first time using python gensim order extract topic text successfully trained model topic idea use model http api created using python flask endpoint give back term given text btw model loaded initialize api trying production memory small vm gb ram exhausted finally got error question gensim lda model used way mean http api yes trick make happen need least mb memory per request doe scale alternative approach thank advance,2020-01-03 20:03:26,2020-01-22 06:09:35,lda gensim model flask http api memory issue,http flask out-of-memory gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
24373,24373,59521204,2019-12-29 16:29:13,,specifically using build believe general tf idf question let say build tf idf model document use model detect word high value model represented specific seen unseen document example document use word banana frequently discover document document used build model use know could pull dictionary word value model kind comparison wondering better way,,2019-12-29 16:29:13,use tf idf model find missing represented word document,python nlp data-science gensim tf-idf,,,CC BY-SA 4.0,False,False,True,False,False
24378,24378,59501121,2019-12-27 12:55:42,,confused use doc vec using gensim imdb sentiment classification dataset got doc vec embeddings training corpus built logistic regression model using use make prediction new review sklearn tf idf ha transform method used test data training training data equivalent gensim doc vec,,2019-12-27 17:27:22,sentiment classification using doc vec,python nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,True
24391,24391,59634935,2020-01-07 19:31:03,,construct sentence using word different way observe word vector unchanged word following different sentence type type type training model follows result changing sentence type also change word suppose result change wanted know result change changed sentence result changed updated value,,2020-01-08 01:04:28,understanding gensim word vec similar result word,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
24393,24393,59570511,2020-01-02 21:54:47,,downloaded wiki news subword bin zip loaded follows expected see following output also see following three numpy array serialized disk understand however used internally look source code finding word vector see attribute used anywhere see attribute bing used however remove file able load model using method someone please explain variable used remove interested looking word vector reduce memory footprint thanks,,2020-01-07 00:23:11,fasttextkeyedvectors difference vector vector vocab vector ngrams instance variable,gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
24395,24395,59482140,2019-12-25 22:01:34,,gensim doc vec infer vector paragraph unseen word generates vector differ based character unsween word trying understand unseen word affect initialization infer vector look like different character produce different vector trying understand,,2019-12-25 23:16:57,gensim doc vec infer vector unseen word differs based character word,gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
24410,24410,59573454,2020-01-03 05:07:44,,trying find simple way calculate soft cosine similarity two sentence attempt learning unable understand please help find henceforth soft cosine similarity python,2020-02-20 15:09:37,2020-05-09 07:04:36,soft cosine similarity two sentence,python gensim cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,False
24444,24444,59605023,2020-01-05 23:12:48,,would like load gensim pretrained model continue training example fails tried many variant gensim api trying seem possible,,2020-01-05 23:12:48,process convert gensim keyedvector model,python model gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
24453,24453,59592326,2020-01-04 15:52:27,,wonder algorithm best semantic similarity anyone explain thank,,2020-01-04 18:55:13,word mover distance v cosine similarity,python nlp gensim semantics cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,False
24463,24463,59690985,2020-01-11 01:48:35,,trying train gensim word vec model bigram get bigram run following code standing long list split sentence using lemmatized spacy lowercased could include bigram occur time run get understand present something wrong misinterpreting output,,2020-01-11 09:00:28,gensim phrase observing min count parameter,python gensim,,,CC BY-SA 4.0,False,True,True,False,False
24530,24530,59631259,2020-01-07 15:20:33,,doe mean must provide tokenized word document list string simply document list string input doc word please clarify,,2020-01-07 17:59:36,understanding parameter model infer vector doc vec gensim,python gensim doc2vec,2020-01-08 07:55:52,,CC BY-SA 4.0,False,False,True,False,False
24537,24537,59765941,2020-01-16 08:53:24,,using lda topic modelling task suggested various forum online trained model fairly large corpus nytimes news dataset mb csv file ha report regarding wide variety news topic surprisingly topic predicted mostly related u politics test new document regarding educate child parenting stuff predicts likely topic two may make company house thing case use kindly look model data part come content section nytimes news dataset used gensim library lda question well trained lda model predicts badly hype effective alternative method,2020-01-16 09:01:45,2020-01-20 16:14:41,lda topic modelling topic predicted huge corpus make sense,python data-science gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
24543,24543,59712626,2020-01-13 08:06:41,,trying unknown word give putting polytechnic diploma dictionary doe even try find source able add word dictionary find able find function code calling function added call nltk working new gensim coding really need help,2020-01-15 08:06:46,2020-01-15 08:06:46,adding unknown word gensim dictionary teaching model,python nltk gensim tf-idf,,,CC BY-SA 4.0,True,False,True,False,False
24561,24561,59736023,2020-01-14 14:41:59,,huge data frame fit memory thus access python via distributed want train word vec doc vec model package based entry one column data frame built iterator like question train using multiple core whose number need specify similarly allows use multiple core far gave available core number core reasoning would fetching data training data exclusive task done time fight core indeed error message still training seems quite slow suspect better way distribute work doe anyone experience matter,,2020-01-17 03:22:18,efficient use multiple core dask distributed gensim,python multithreading dask gensim dask-distributed,,,CC BY-SA 4.0,False,False,True,False,False
24569,24569,59667894,2020-01-09 16:03:17,,created k mean cluster gensim word vec value want retrieve cluster value frequency,2020-01-09 16:38:01,2020-01-09 19:45:11,select cluster maximum frequency k mean,python k-means gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
24588,24588,59820942,2020-01-20 10:06:34,,want add full stop every line sentence getting cleaned text performing text cleaning order perform summarisation using heapq gensim get full stop heapq gensim understand different sentence would take sentence one using following code str clean summary look like give sentence different line need add full stop sentence treated separately,2020-01-20 10:55:13,2020-01-20 11:02:35,adding full stop every sentence line using spacy nlp perform summarisation,python python-3.x nlp spacy,,,CC BY-SA 4.0,False,True,True,False,False
24590,24590,59823688,2020-01-20 12:51:43,,trying build gensim word vec model corpus contains sentence using callback print loss every epoch epoch loss becomes zero idea loss becomes,2020-01-20 15:22:03,2020-01-27 10:04:08,gensim word vec model loss becomes epoch,deep-learning gensim word2vec loss-function,,,CC BY-SA 4.0,False,False,True,False,False
24620,24620,59775594,2020-01-16 18:15:10,,way gensim generate strictly bigram trigram list word successfully generate unigrams bigram trigram would like extract bigram trigram example list use creates list unigrams bigram follows question way regular expression extract strictly bigram example new york would result,,2020-01-16 19:24:19,generate bigram trigram corpus,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
24624,24624,59827389,2020-01-20 16:28:01,,trying set pipeline increase summarization result would like following already able summarize algorithm see repo however hoping process produce accurate consolidated summary doe anyone know make happen,2020-01-21 17:19:54,2020-01-21 17:19:54,run gensim result spacy spacy result nltk nltk result sumy,nlp stanford-nlp spacy spacy-pytorch-transformers,,,CC BY-SA 4.0,True,True,True,True,False
24625,24625,59827730,2020-01-20 16:48:53,,following following example using doc vec text classification http github com susanli nlp python blob master text classification model selection ipynb ran notebook datasets want apply one doc vec model rd dataset eg overall dataset test train model wa built tried really practical applied purpose data one want predict might available time train testing model performance decreased result save model applying completely different dataset would seems would need update doc vec model doc dataset well,2020-01-20 16:54:48,2020-01-21 06:06:24,save reuse doc vec based model prediction,machine-learning scikit-learn gensim,,,CC BY-SA 4.0,False,False,True,False,True
24627,24627,59794837,2020-01-17 21:04:35,,working lda model using generically point output like append original dataframe text came topic percent contribution document original df look like standard preprocessing including lemmatization removing stop word etc compute percent contribution document output look like thought could concat dfs back together like index match left sort frankenstein df look like happy post fuller code would helpful hoping someone know better way point might print topic,2020-01-17 21:18:50,2020-01-17 21:18:50,append merge dataframe lda output,python python-3.x pandas gensim,,,CC BY-SA 4.0,False,False,True,False,False
24639,24639,59845191,2020-01-21 16:17:13,,plan use nltk gensim scikit learn nlp text mining using library work org data question using library make api call process data data taken python shell processed security question wa wondering someone ha documentation reference appreciate help,,2020-01-22 21:22:25,api call nltk gensim scikit learn,python api nlp nltk gensim,,,CC BY-SA 4.0,True,False,True,False,True
24658,24658,59863559,2020-01-22 15:53:08,,trying predict big personality trait extraversion neuroticism agreeableness conscientiousness openness based text analysis written user preprocessed data set word vec model vocabulary consists word question use word vec vector tensorflow model replace every word every row x vector word vec model think quite expensive calculation another possibility sorry question sound dummy really new nlp tensorflow,2020-01-22 17:01:36,2020-01-22 17:01:36,use word vec classification problem tensorflow,python tensorflow nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
24667,24667,59813664,2020-01-19 19:33:28,,getting attributeerror trying implement embedding vector attributeerror word veckeyedvectors object ha attribute get,2020-01-19 19:34:20,2020-01-19 19:57:02,error implementing word vec model embedding vector,python machine-learning keras gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
24673,24673,59721715,2020-01-13 17:57:52,,generated pyspark word vec model save like use pyspark w v collected sample hive table huge sample thats transformed spark dataframe panda dataframe need gensim want make beautiful visualisation need cluster word vec model visualise pyspark function got much function use tensorboard tried load model gensim work test data put data pyspark model path also work solve problem also know idea cluster visualise pyspark welcome,2020-01-21 13:21:41,2020-01-21 13:21:41,convert pyspark word vec model load gensim word vec model,python machine-learning pyspark cluster-analysis word2vec,,,CC BY-SA 4.0,False,False,True,False,False
24681,24681,59878593,2020-01-23 12:28:35,,trained gensim hdp model large corpus gb text million line result wa set topic nearly slight difference word pipeline preprocessing input text includes trivial method like text normalization stopword removal calculate bigram tf idf also ignoring sentence le word straight forward approach topic modeling hdp similar method give accurate result,,2020-01-23 12:28:35,topic gensim hdp model converge one topic,gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
24692,24692,59835900,2020-01-21 07:16:40,,working word vec model way get ideal value one parameter e like way used k mean elbo curve plot get k value way parameter tuning model,,2020-01-21 19:33:13,gensim word vec model parameter tuning,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
24696,24696,59865719,2020-01-22 18:00:05,,trying get textual representation closest word given word embedding using bert basically trying get similar functionality gensim far able generate contextual word embedding using bert service figure get closest word embedding used pre trained bert model uncased l h done fine tuning,,2020-03-22 20:59:20,find closest word vector using bert,nlp word-embedding bert-language-model,,,CC BY-SA 4.0,False,False,True,False,False
24719,24719,59949098,2020-01-28 12:46:50,,try build gensim lda model topic modeling output trained model need give real time input check document come topic model question classification like qunts reasoning verbal question please help,,2020-01-28 12:46:50,classifiy document topic using gensim lda model training deploy code,input gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
24726,24726,59919462,2020-01-26 14:51:28,,trying build word vec fasttext model using gensim massive dataset composed file contains sentence sentence contains word training wa made gb ram core machine validated first tried following hour decided running long stopped tried building vocabulary based single file train based file follows checked sample word vector training wa change mean actual training wa done use advise run quickly successfully thanks update code check vector update vector exactly,2020-01-28 12:18:10,2020-01-28 12:18:10,speed gensim word vec massive dataset,gensim word2vec fasttext,,,CC BY-SA 4.0,False,False,True,False,False
24749,24749,59872029,2020-01-23 05:25:42,,using word vec doc vec get embeddings sentence want completely ignore word order currently using gensim use package necessary example text look like intentionally want apple considered close zucchini banana set window size large number say aware problem may arise problem window might roll start sentence creating following training pair eventually get correct would seem effect making apple closer banana zucchini since many pair containing apple banana pair containing apple zucchini problem heard pair sampled inverse proportion distance target word context word also cause issue making nearby word seem connected want way around problem using cbow opposed sgns hyperparameters aware best way go removing ignoring order case thank,,2020-01-23 18:48:16,word vec window size sentence boundary,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
24765,24765,59924168,2020-01-27 00:56:17,,need combine word vec model end need persist flag binary one enough sentence corpus ha two type k target class sentence need retrieve flag vector creation store retrieve information inside input sentence need order train deep neural network p using implementation p corpus ha sentence produce vector edit detail regarding corpus requested structure corpus follows sentence label python list string string string sentence label python list string string string sentence given input feed cnn extracted feature case target sentence need label sentence well,2020-01-27 19:06:27,2020-01-27 19:06:27,word vec store retrieve extra information regarding instance corpus,deep-learning gensim word2vec one-hot-encoding word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
24772,24772,59925207,2020-01-27 04:37:37,,created word vec model made visualization top n similar word particular term using tsne matplotlib understand run multiple time word plotted different position even though word vector time case feeling ha way tsne reduces dimensionality vector case really reliable use method visualization since different every time,,2020-03-03 16:21:42,random point visualizing word vec embeddings using tsne,python matplotlib pca gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
24780,24780,59889710,2020-01-24 02:33:11,,trying use gensim file based training example documentation however actual corpus contains many document containing many sentence example let assume corpus play shakespeare play document document ha many many sentence would like learn embeddings play word embeddings within sentence since file based training meant one document per line assume put one play per line however documentation file based training example document multiple sentence way peek inside model see document word context pair found trained correct way build file maintaining sentence boundary thank,,2020-01-25 02:35:19,correct way represent document containing multiple sentence gensim file based training,gensim corpus doc2vec sentence,,,CC BY-SA 4.0,False,False,True,False,False
24791,24791,59909099,2020-01-25 12:13:50,,using word vec model problem storing reading get following error following way laoding work call get following error typeerror unsupported operand type pow list int wrong use save word vec format function,2020-01-25 20:26:11,2020-01-25 20:26:11,gensim framework saving storing word vec keyed vector,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
24801,24801,59938853,2020-01-27 21:01:18,,trying tokenize following sentence type every tokenizer tried far return following including punkt tokenizer trained corpus adding abbreviation tokenizer would problem sentence ending,2020-01-27 21:31:27,2020-02-04 06:42:24,stop sentence tokenizer splitting sentence abbreviation,python nlp nltk gensim,,,CC BY-SA 4.0,True,False,True,False,False
24809,24809,59926638,2020-01-27 07:22:16,,code model using gensim run returned tuple wan na know one number token value wa returned model need know wan na know number token,2020-01-27 07:30:45,2020-01-27 20:03:11,find number token gensim model,python-3.x gensim,,,CC BY-SA 4.0,False,False,True,False,False
24831,24831,59891168,2020-01-24 06:05:47,,set text document label liked disliked document consists word trying supervised learning document approach would vectorize document corpus say doc row label viz like dislike using ml classification supervised model train dataset row vectorize create dataset,2020-01-24 12:03:14,2020-01-24 12:50:18,supervised learning gensim word vec doc vec large corpus text document,python nlp gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
24906,24906,60077757,2020-02-05 14:14:57,,using gensim lda implementation would like test mallet lda implementation problem run gensim container specify path mallet executable case seen hub docker container mallet problem doe one know specify path mallet containerized application,2020-02-05 16:58:16,2020-02-05 16:58:16,gensim wrapper mallet lda container image,containers gensim mallet,,,CC BY-SA 4.0,False,False,True,False,False
24922,24922,60081431,2020-02-05 17:50:25,,trying load fasttext bin model spanish donwloaded http fasttext cc doc en crawl vector html continue training new sentence specific domain interested system anaconda jupyter notebook python upgraded gensim code toy example old new vector word equal remains vocab model learnt nothing wrong,,2020-02-05 17:50:25,fasttext model loaded gensim continue training new sentence,python gensim fasttext resuming-training,,,CC BY-SA 4.0,False,False,True,False,False
24951,24951,60085407,2020-02-05 23:06:39,,got error change input parameter error becomes code,2020-02-06 00:13:06,2020-02-06 00:13:06,error checking input expected embedding input shape got array shape,python keras lstm gensim,,,CC BY-SA 4.0,False,False,True,False,False
25005,25005,60108919,2020-02-07 07:30:54,,created bigram model using gensim try get bigram sentence picking bigram sentence anyone explain get bigram new york mayor others,2020-06-20 09:12:55,2020-02-07 18:22:49,bigram created gensim phrase tool,python nlp gensim n-gram word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
25007,25007,60171782,2020-02-11 15:01:15,,issue memory wa wondering anybody ha idea could happening trying following processing text creating vocabulary removing word corpus vocabulary big panda series train x test x occupies around gb together train x around create vocabulary text function increase memory consumption gb going post function since long really relevant issue finally want create list list element word appears vocabulary vocabulary size k actually lot word going removed therefore used following function however perform operation memory consumption leap gb sure could causing much consumption since trying delete variable use anymore know python necessarily collect garbage code environment moment reference variable idea happening suggestion better way operation welcomed ideally final output list list since need use input gensim word vec model create vector word,,2020-02-11 15:01:15,transforming dataframe list list bursting memory python,python memory-management memory-leaks nlp,,,CC BY-SA 4.0,False,False,True,False,False
25023,25023,60142106,2020-02-09 22:52:43,,gensim ldamodel ha parameter control number training epoch callback get information convergence possibility stop training difference two epoch small e early stopping,2020-02-12 15:53:35,2020-02-18 09:14:57,gensim ldamodel early stopping,python python-3.x gensim lda early-stopping,,,CC BY-SA 4.0,False,False,True,False,False
25076,25076,60246570,2020-02-16 08:03:17,,created gensim lda model shown tutorial http www machinelearningplus com nlp topic modeling gensim python generates topic log perplexity lda model log perplexity data df bow corpus run coherence model calculate coherence score like lda score nan wrong,,2020-02-16 08:45:14,gensim lda coherence score nan,python machine-learning gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
25081,25081,60211920,2020-02-13 15:57:49,,wrote following code following error show please guide error command c mallet bin mallet import file preserve case keep sequence remove stopwords token regex input c user mhradm appdata local temp f corpus txt output c user mhradm appdata local temp f corpus mallet returned non zero exit status,2020-02-13 16:31:31,2020-02-13 16:31:31,topic modeling ldamallet,gensim lda topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
25087,25087,60248118,2020-02-16 11:46:01,,quite new python coding general seem run issue trying run code credit matthew mayo whole thing found however function branch seems run partly stopping never make exiting repeating beginning code yielding result error actually come warning output tried uninstalling required package numpy smart open well gensim active conda environment nothing ha changed also difference main multiprocessing one specification win py edit running logging debug level logging file also wa added branch,2020-02-17 12:59:56,2020-02-18 21:13:46,problem gensim wikicorpus aliasing chunkize chunkize serial mp main instead main,python python-3.x windows nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
25113,25113,60281456,2020-02-18 12:58:26,,trying learn nlp python data called abstract consisting several row different setnences tokenizing get series called abstract tokenized series ha around item iam trying doc bow function one element unable understand result ideally get index word count occurences element list doc bow example string cute dog cute tail doc bow return running data attached getting result getting wrong frequency every word file ha column one ha raw data ha doc bow result,,2020-02-18 12:58:26,interpreting gensim library doc bow function run series word,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
25118,25118,60166663,2020-02-11 10:22:14,,working task like text classification qa original vocabulary generated corpus usually large containing lot unimportant word popular way seen reduce vocabulary size discarding stop word word low frequency example practice setting minimum count empirical doe seems quite exact notice term frequency word vocabulary often follows long tail distribution good way keep top k word occupies x total term frequency sensible way reduce vocabulary without seriously influencing nlp task,,2020-02-11 19:46:53,good way reduce size vocabulary natural language processing,machine-learning deep-learning nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
25125,25125,60185968,2020-02-12 10:17:04,,using mallet lda gensims implemented wrapper want get topic distribution several unseen document store nested list print code try print list yield result tried code print properly probability topic distributuion wrong get result however printing one element list yield correcr result another problem one document distribution printed time also looked answer gensim interface transformedcorpus use didnt help doin wrong,,2020-02-12 10:44:59,transforming gensim interface transformedcorpus readable result,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
25127,25127,60318511,2020-02-20 11:05:14,,error problem ran script jupyter notebook base root environment log said gensim library ha installed run command pip install gensim import still imported error said modulenotfounderror module named gensim anyone help problem really appreciate help help thesis work thank attention,,2020-02-20 11:21:27,module named gensim already installed,python machine-learning jupyter-notebook gensim word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
25132,25132,60286735,2020-02-18 17:47:38,,large corpus data train word similarity e g hot similar warm cold however like train doc vec relatively small corpus doc classify domain specific document elaborate let use toy example assume training doc given sentence love hot chocolate hate hot chocolate love hot tea love hot cake given test document adore hot chocolate would expect doc vec invariably return love hot chocolate closest document expectation true word vec already supply knowledge adore similar love however getting similar document hate hot chocolate bizarre suggestion circumvent e able use pre trained word embeddings need venture training adore close love hate close detest code jupyter nodebook python jensim,2020-02-18 18:21:27,2020-02-18 20:49:40,gensim doc vec use pre trained word vec word similarity,python nlp gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
25142,25142,60301796,2020-02-19 13:45:52,,large number sentence database want find similar sentence single sentence user type look like may able annoy gensim example see using word vec believe good finding single similar word sentence however note annoyindexer take word vec doc vec model correct process swapping word vec model doc vec model using doc vec vector search sentence need use pre trained word embeddings way literally train doc vec model corpus sentence database thank,,2020-02-19 21:40:11,gensim annoy finding similar sentence,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
25158,25158,60254825,2020-02-17 01:20:24,,output get using gensim mallet wrapper link understood token mean model log liklihood divided total number token however topic like etc see term tried run code range topic step starting output show last topic generated missing something,,2020-02-17 15:19:52,gensim mallet output doe term topic,nlp gensim lda topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
25162,25162,60305405,2020-02-19 16:51:58,,building document vector gensim custom list tag called url want use taggeddocument every custom url sequence number result look like see end field custom number training model runnning similarity query unseen test document yield first document see tag index every sublist custom tag generic number wrong,2020-02-19 16:58:09,2020-02-19 21:43:33,using custom tag tagged document gensim,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
25169,25169,60324422,2020-02-20 16:23:37,,trying implement gensim lda model dataset contains approximately review got online currently able achieve perplexity coherence score using default parameter however corresponding topic keywords review seem quite far see relationship hard time fine tuning understanding parameter parameter important gensim lda model find best parameter dataset learned lda would really appreciate help thank,,2020-02-20 16:23:37,fine tune parameter gensim lda model,gensim lda topic-modeling,2020-02-25 15:17:40,,CC BY-SA 4.0,False,False,True,False,False
25175,25175,60290296,2020-02-18 22:22:37,,trained several word vec model using gensim different language different vector obtained like use input different model different vector size obtain corresponding word second model,,2020-02-19 21:31:06,word vec compare vector different model different size,python nlp artificial-intelligence gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
25179,25179,60292744,2020-02-19 03:51:08,,want extract print bigram using gensim purpose used code googlecolab error tried wrong,,2020-02-19 05:04:05,typeerror extracting bigram gensim python,python machine-learning nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
25188,25188,60343072,2020-02-21 16:49:29,,several thousand document like use gensim doc vec model gram document full text original word order doc vec tutorial gensim website http radimrehurek com gensim auto example tutorial run doc vec lee html corpus created full text model trained corpus look something like possible create training corpus document consists list gram rather list word original order,,2020-02-23 21:01:13,gensim doc vec training ngrams,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
25191,25191,60344269,2020-02-21 18:17:58,,faced trouble load model using gensim model fasttext load code error get downloaded model google drive folder though somehow damage npy file quite big downloaded file file model separately help also read sometimes caused bad unzipping load method passing already unzipped file also work grateful help,,2020-02-23 21:12:55,load model gensim fasttext,python numpy gensim,,,CC BY-SA 4.0,False,False,True,False,False
25222,25222,60396376,2020-02-25 14:01:05,,currently lda analysis using python gensim mallet wrapper training model getting topic want see topic distributed various document normal gensim lda analysis possible use get document topic function could used iterate every document file however mallet wrapper doe function retrieve distribution topic one specific document find solution collect store every document instance list dataframe use following code acquire topic distribution one document would return following output however get iterate le document dataset additional code could relevant anyone suggestion thanks advance,2020-02-26 08:48:54,2020-02-26 08:48:54,lda mallet alternative get document topic measuring topic per document,python lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
25242,25242,60271345,2020-02-17 22:39:35,,trying understand use lda case corpus many document want see specific set word ngrams distributed across topic way specify list specific word vocabulary topic modeling working gensim implementation believe argument handle documentation clear understanding correct,,2020-02-20 15:56:27,specifying vocabulary input lda,python nlp cluster-analysis gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
25245,25245,60307249,2020-02-19 18:46:02,,working steadily growing corpus train document vector doc vec implemented python possible update document vector want use document vector document recommendation,,2020-02-19 21:47:40,possible update doc vec vector,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
25260,25260,60383368,2020-02-24 20:22:17,,going notebook lda document similarity http www kaggle com ktattan lda document similarity notebook document similarity small set document get computed however want compute similarity whole corpus instead using test df like notebook want use train df however doe work asumption possible list used create numpy array tup case length possible create proper array needed compute jensen divergence somebody experienced tell trying possible,,2020-03-01 16:34:15,possible compute document similarity every document lda corpus,python numpy gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
25263,25263,60316242,2020-02-20 09:06:25,,following tutorial following dataset quora already cleaned tokenize data column q clean q clean trained w vmodel using googlenews pretrained model following code feature analysis following function get average computed distance computed tfidf use weight calling get pairwise distance function like tutorial function need pas embedded version q clean q clean x x weight already computed using tfidf getting clue embed two column vector using pretrained model pas given function,2020-02-20 10:15:34,2020-02-21 14:10:42,embed dataframe using already trained model gensim googlenews vector negative bin,machine-learning scikit-learn nlp nltk gensim,,,CC BY-SA 4.0,True,False,True,False,True
25302,25302,60420718,2020-02-26 18:57:43,,training lda model using gensim training need topic analysis unfortunately show topic function return topic expected defined number topic doe anyone know purpose error solved,,2020-02-26 22:21:20,python gensim lda model show topic funciton,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
25305,25305,60451614,2020-02-28 12:21:32,,see code us wikicorpus arabic wikipedia dump know process take long time execute also searched around warning get executing say userwarning detected window aliasing chunkize chunkize serial warning warn detected window aliasing chunkize chunkize serial answer said ok nothing serious warning waiting day without response start wondering whether truly work arabic dump file certain kind pre processing passing arabic dump file wikicorpus object data size mb surround wikicorpus code line two print command know started finished executing like self f arabic wikipedia dump like path file located arwiki page article xml bz never reached second print command runtime,,2020-02-28 22:16:33,doe wikicorpus gensim library work arabic wikipedia dump,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
25335,25335,60454355,2020-02-28 15:05:28,,trained model using gensim draw plot using pca clear much wan na change capable zooming result dense result possible,2020-02-28 19:18:35,2020-03-01 07:13:30,draw plot gensim model,python-3.x pca gensim,,,CC BY-SA 4.0,False,False,True,False,False
25345,25345,60459403,2020-02-28 21:22:00,,coworker exact code using library yet code work mine gotten stuck trying figure wrong help would greatly appreciated code error code output error,,2020-02-28 21:22:00,return nonzero ldamallet,gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
25348,25348,60524589,2020-03-04 11:02:45,,curiosity wa debugging gensim fasttext code replicating implementation vocabulary oov word able accomplish process following training tiny model toy corpus comparing resulting vector word vocabulary mean whole process ok output array code used test output script false every dimension compared array would nice someone could point missing something something wrong thanks advance,,2020-03-04 18:02:19,reproduce pre trained word vector vector ngrams,python-3.x gensim fasttext oov,,,CC BY-SA 4.0,False,False,True,False,False
25353,25353,60491035,2020-03-02 14:35:01,,attempting load word vec model trained gensim window machine receive following error successfully trained numerous model gensim past system variation time split phase adding save time hack epoch also used different iterator vocab build training phrase dataset tokenization pipeline epoch progress tracking saving load baseline model vocab build set parameter training like finally save end product like training appeared work properly model saved expected unfortunately load full debug readout,2020-03-03 00:54:42,2020-03-03 01:02:42,unable load model trained gensim pickle related error,python-3.x nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
25396,25396,60445602,2020-02-28 05:11:29,,use case want find top n nearest word given set word vector like want restrict vocab given set word want create low latency api using vocab different request suggestion achieve optimally,,2020-02-28 05:11:29,get top n similar word given list word vector using gensim,java python gensim word2vec cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,False
25402,25402,60515074,2020-03-03 20:33:16,,way save gensim lda model onnx format need able train using python gensim operationalize onnx model publish use,,2020-03-03 20:43:46,saving gensim lda model onnx,gensim lda onnx,,,CC BY-SA 4.0,False,False,True,False,False
25405,25405,60482161,2020-03-02 03:25:28,,attempting semi supervised lda model based however result obtained lda model different set topic predefined set code took link set review scraped online set predefined topic result obtained model different set topic defined earlier wrong increase probability predefine keywords appearing topic generated model,2020-03-04 06:29:57,2020-03-04 06:29:57,semi supervised guided lda predefined topic different topic generated,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
25422,25422,60464982,2020-02-29 12:05:54,,genism documentation code http radimrehurek com gensim auto example tutorial run word vec html question regarding iter parameter set print str executed twice iter simple preprocess executed time customized preprocess heavy going slow avoid preprocessing repetition using genism word vec,,2020-02-29 19:24:06,understand gensim iter parameter implication preprocessing,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
25444,25444,60599396,2020-03-09 11:14:47,,saved ldawallet model first train saved model using save method forgot set prefix certain file trained mode consequence lost temporary file created gensim training doctopics etc think load model want predict topic get error errno file directory var folder f ttl hvqn g rb cdg qg c gn e doctopics txt infer tried unsuccessfully reproduce model data setting prefix lose temporary file wondering possible use method print topic forgot say loading model working get topic word topic retrieve weight word related topic compute probability know lda model predict topic document sure idea work idea fix issue want predict document probabibity topic thank,,2020-04-01 16:47:47,python mallet lda errno file directory,nlp gensim lda mallet,,,CC BY-SA 4.0,False,False,True,False,False
25445,25445,60600004,2020-03-09 11:50:33,,followed step gensim python http radimrehurek com gensim wiki html train wikipedia lda model problem file directory f,,2020-03-09 11:50:33,training lda wikipedia corpus tag arbitary aritcle,gensim wikipedia training-data lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
25461,25461,60602768,2020-03-09 14:36:19,,code creating model code gridsearchcv output,2020-03-10 05:42:35,2020-03-10 05:53:58,scikit learn gridsearchcv failing gensim lda model,python scikit-learn gensim lda gridsearchcv,,,CC BY-SA 4.0,False,False,True,False,True
25465,25465,60501793,2020-03-03 07:07:40,,dealing ton pdf document petetions data filled text data number tabular data etc objective client summarize given document reduce man force reading entire document tried conventional method like lsa gensim summarizer bert extractive summarizer pysummarizer result good please suggest way find industry level summarizer extrative abstractive would give good start solve issue,,2020-03-03 07:16:54,way summarize text data ha number table python either extractive way abstarctive way,machine-learning text deep-learning nlp summarization,,,CC BY-SA 4.0,False,False,True,False,False
25471,25471,60584750,2020-03-08 05:30:34,,trained word vec model using gensim two set word word w want find top word similar w currently way word word similarity get top n dict value large becomes slow quicker way compute large pair word word vec either genism tensorflow,,2020-03-10 21:47:57,speed word vec similarity calculation,tensorflow gensim,,,CC BY-SA 4.0,False,False,True,False,False
25472,25472,60584927,2020-03-08 06:08:08,,wan na calculate recall query terminator movie google pre trained model googlenews vector negative bin know relevant movie solution problem,2020-03-11 15:56:54,2020-03-11 15:56:54,calculate recall know relevant result,gensim precision-recall pre-trained-model,,,CC BY-SA 4.0,False,False,True,False,False
25491,25491,60587089,2020-03-08 11:40:00,,going gensim lda implementation say need corpus dictionary corpus http radimrehurek com gensim model ldamodel html reason,2020-03-08 20:43:44,2020-03-08 20:43:44,doe lda gensim implemantion need corpus dictionary,python nlp gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
25492,25492,60588557,2020-03-08 14:35:36,,using gensim generate summary different row original dataframe look like able apply summarization every row using gensim problem want every row summary appear original happening code look like ouput code shown individual summary generated gensim row grab individual summary corresponding original content place dataframe,,2020-03-08 15:25:22,gensim row wise dataframe summary,python pandas for-loop gensim summarization,,,CC BY-SA 4.0,False,False,True,False,False
25493,25493,60588590,2020-03-08 14:39:23,,using gensim lda topic modelling working fine tuning model improve coherence score thought bigger dictionary better would topic modelling look like keen understand relationship dictionary coherence score,,2020-03-08 14:39:23,dictionary size impact coherence score gensim lda,python-3.x gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
25504,25504,60606705,2020-03-09 18:54:32,,trying find sentence similarity word emebeddings applying cosine similarity score tried cbow skip gram method embedding solve problem product review data two column first two review semantic meaning completely different algorithm find semantic meaning sentence score approach text pre processing train cbow skip gram using gensim data set sentence level encoding via averaging word vector sentence take cosine similarity problem wa able find context sentence hence result wa poor approch used pre trained bert without pre processing sentence result wa improving either approach would capture context semantics sentence train bert data set scratch without using pre trained model,,2020-03-30 23:41:10,find sentence similarity using deep learning,python nlp,,,CC BY-SA 4.0,False,False,True,False,False
25514,25514,60637654,2020-03-11 13:51:50,,trying apply lda dataset topic modelling everytime run lda model code run indefinitely shutdown kernel error size dataset gb tried ldamodel gensim well pyspark mllib clustering library faced issue pre processing step work fine tried running gcp data proc luck image dataset,2020-03-21 03:06:13,2020-03-21 03:06:13,lda using pyspark,out-of-memory lda,,,CC BY-SA 4.0,False,False,True,False,False
25516,25516,60638629,2020-03-11 14:42:06,,data frame like want create corpus tried resulting corpus seems properly created typeerror doc bow expects array unicode token input single string someone help would like resulting dictionary represent fact word tree occurred twice data frame e sum column,2020-03-11 15:15:50,2020-03-11 15:15:50,gensim corpus sparse matrix,python python-3.x gensim,,,CC BY-SA 4.0,False,False,True,False,False
25528,25528,60627294,2020-03-10 23:29:42,,using python version virtual environment trying import command getting importerror import name type gensim model phrase import phraser uninstalled package installed gensim still fails suggestion would great help gensim model phrase import phraser gensim model word vec import word vec import pickle botocore client import config simcloud package venv lib python site package gensim init py gensim import parsing corpus matutils interface model similarity summarization utils noqa f import logging simcloud package venv lib python site package gensim parsing init py porter import porterstemmer noqa f preprocessing import remove stopwords strip punctuation strip punctuation noqa f strip tag strip short strip numeric strip non alphanum strip multiple whitespaces simcloud package venv lib python site package gensim parsing preprocessing py import glob gensim import utils gensim parsing porter import porterstemmer simcloud package venv lib python site package gensim utils py import numpy np import number import scipy sparse six import iterkeys iteritems itervalues u string type unichr simcloud package venv lib python site package scipy init py make scipy import fft return scipy fft np fft del fft import fft simcloud package venv lib python site package scipy fft init py future import division print function absolute import basic import fft ifft fft ifft fftn ifftn rfft irfft rfft irfft rfftn irfftn simcloud package venv lib python site package scipy fft basic py scipy lib uarray import generate multimethod dispatchable import numpy np def x replacer args kwargs dispatchables simcloud package venv lib python site package scipy lib uarray py uarray import function else uarray import uarray import function simcloud package venv lib python site package scipy lib uarray init py backend import version ga scipy simcloud package venv lib python site package scipy lib uarray backend py typing import callable iterable enter code dict tuple importerror import name type,,2020-03-11 03:19:04,importing gensim gensim model phrase import phraser fails importerror import name type,gensim,,,CC BY-SA 4.0,False,False,True,False,False
25533,25533,60672361,2020-03-13 14:34:59,,used gensims word embeddings find vector word used k mean find cluster word close token word want plot want plot result following way annotate point name different color cluster done though annotating failing color different group cluster anyother approach annoates word anmes color different cluster,,2020-03-14 12:46:30,plot output k mean clustering word embedding using python,python-3.x matplotlib gensim,,,CC BY-SA 4.0,False,False,True,False,False
25546,25546,60629671,2020-03-11 05:19:59,,csv term document matrix wan na perform latent dirichlet allocation using gensim python however particularly familiar python lda posted gensim forum dunno called guy wrote package responded say big term document csv matrix small enough fit ram could use numpy loadtxt load csv memory matrix convert matrix corpus gensim matutils dense corpus check document column flag let switch document term term document transposition easily use corpus train lda model lead believe answer question correct seems like dictionary necessary input lda model correct think successfully stick csv corpus help would appreciated edit turn gensim dictionary python dictionary exactly thing,2020-03-14 00:37:59,2020-03-14 00:37:59,trying make use library conduct topic modeling going well,python gensim lda corpus,,,CC BY-SA 4.0,False,False,True,False,False
25564,25564,60613532,2020-03-10 08:03:07,,best model lda sklearn based lda model trying find coherence score model output error pop trying find coherence score sklearn lda topic model way around also metric sklearn lda using group word together,,2020-06-02 12:46:44,calculate coherence score sklearn lda model,scikit-learn gensim lda,,,CC BY-SA 4.0,False,False,True,False,True
25576,25576,60727025,2020-03-17 17:05:46,,similar question asked regarding topic really satisfied reply far please excuse first using function python library problem run model every word corpus long set parameter greater one would say logic cause choose ignore word appearing function behaving weird cause give error saying word blabla vocabulary whereas exactly want want word vocabulary imagine clear find reproducible example find google model example feel free use model without point post notified commentary code running model paris work country course set parameter everything work fine hope clear enough thanks,,2020-03-19 00:10:24,word vec gensim handling missing word vocabulary parameter min count,python nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
25590,25590,60644150,2020-03-11 20:40:14,,trying train word vec model coha corpus using pre computed bigram count co occurrence count corpus author make available achieve using gensim,,2020-03-12 20:06:59,train word vec gensim list co occurrence bigram count,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
25598,25598,60680146,2020-03-14 05:56:44,,trying use gensim lda modelling topic model dataset food recipe wish topic based key ingredient recipe recipe text contains word generic english ingredient name hence topic outcome good expected trying understand impact word frequency lda topic outcome thanks,,2020-09-06 15:54:08,impact word frequency gensim lda topic modelling,python-3.x gensim lda topic-modeling word-frequency,,,CC BY-SA 4.0,False,False,True,False,False
25606,25606,60669506,2020-03-13 11:17:40,,trying use order learn phrase special meaning base corpus suppose corpus related car brand removing punctuation stopwords tokenizing sentence eg way would like use learn output look like however lot sentence lot punctuation output look like case handle sentence lot punctuation prevent case make output look like thanks much helping,,2020-03-14 01:56:47,gensim phrase handling sentence lot punctuation,python nlp gensim phrase,,,CC BY-SA 4.0,False,False,True,False,False
25610,25610,60729841,2020-03-17 20:35:14,,input sample tried implementing dictionary corpus dictionary text data error get typeerror doc bow expects array unicode token input single string please help see work,,2020-03-17 20:42:37,python gensim dictionary,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
25616,25616,60682634,2020-03-14 12:18:28,,trying load trained fasttext model using gensim model ha trained data earlier used extension use later training process saving model using format generates file respectively bin bin trainable vector ngrams lockf bin wv vector ngrams unable load trained binary file bin understand getting error named raise notimplementederror supervised fasttext model supported notimplementederror supervised fasttext model supported going many blog people suggested doe support supervised training fine question able load trained binary model shall need train model differently help appreciated tried training process,2020-03-14 13:48:18,2020-03-14 20:00:51,issue loading trained fasttext model using gensim,python python-3.x gensim word-embedding fasttext,,,CC BY-SA 4.0,False,False,True,False,False
25622,25622,60685536,2020-03-14 17:41:13,,trying load word vec vector trained using gensim word vec way cnn using embedding layer using following setting problem know extract vector embedding weight correctly tryed cnn actually accepts input accuracy stall immediatly rate two class think giving wrong input cnn,,2020-03-14 17:41:13,plug self trained embedding vector cnn,keras gensim word2vec embedding cnn,,,CC BY-SA 4.0,False,False,True,False,False
25645,25645,60785538,2020-03-21 07:42:28,,calculated distance two sentence using wmdistance funtion gensim pre trained model want similarity tried n similarity funnction keyerror occured keyerror word vacabulary show screenshoot error example anyone got idea please,2020-06-20 09:12:55,2020-03-22 05:51:19,gensim pretrained model wmdistance working well n similarity,gensim,,,CC BY-SA 4.0,False,False,True,False,False
25660,25660,60786940,2020-03-21 10:56:43,,runtime error try run code want obtain optimal number topic corpus obtain topic interpreting topic model result biologist know fix thanks help,,2020-03-22 05:56:29,runtime error running lda model gensim fix,model runtime-error runtime gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
25665,25665,60738355,2020-03-18 11:14:39,,working multi label emotion classification problem solved word vec code learned couple tutorial accuracy low telling something wrong code find tried code tf idf bow obviously except word vec part got much better accuracy score seems one somehow wrong result printed predicted variable tweet see look like see show example mean tweet number emotion number mean tweet number emotion number emotion considered imagine like better understand done accuracy method used union intersect index one one gold emotion predicted emotion tweet two loop creating word vec vector tweet want use gensim create word vec vector tweet dataset changed part code get error,2020-06-20 09:12:55,2020-04-08 14:17:36,classification accuracy low word vec,python nlp classification word2vec emotion,,,CC BY-SA 4.0,False,False,True,False,False
25685,25685,60723228,2020-03-17 13:17:19,,database supermarket product item contains name description price stock etc want make price comparison supermarket need know supermarket b refers product example found supermarket ha product called supermarket b ha product named refers product pointed need semantic comparison case new problem really know best solution underestimate problem overkill right great result using product name remove stop word product name convert sentence array word get frequency every word word ha frequency delete word create dictionary bag word use map array word sentence converted feature vector train tfidf model feature vector make comparison great result using python lp gensim create model dictionary bag word make comparison edit another example,2020-03-17 15:44:00,2020-03-17 15:44:00,kind model technique use compare supermarket product name,python machine-learning nlp artificial-intelligence gensim,2020-03-19 17:27:18,,CC BY-SA 4.0,False,False,True,False,False
25718,25718,60792362,2020-03-21 19:29:03,,need suggestion unsupervised training doc vec option scenario n document size greater token training alternative better training whole document breaking document chunk token training,,2020-03-22 05:49:29,doc vec unsupervised training,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
25739,25739,60873334,2020-03-26 17:54:33,,trained model saved according post everything look fine load model different name something go wrong however use common command example work something seems broken loading perhaps saving could someone help please,,2020-03-27 00:23:15,trouble loading custom trained word vector created gensim spacy,python-3.x spacy gensim,,,CC BY-SA 4.0,False,True,True,False,False
25744,25744,60839302,2020-03-24 21:03:32,,data like wa output gensim lda model result like anyone help,2020-03-24 21:43:14,2020-03-24 22:06:47,turn list tuples data frame different score,python list dataframe tuples lda,,,CC BY-SA 4.0,False,False,True,False,False
25750,25750,60702160,2020-03-16 07:55:02,,executing giving output hundred line shown picture know doe mean actually want probability topic method use get topic probability,2020-03-20 04:15:46,2020-03-20 04:15:46,get topic probability ldamodel using gensim,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
25771,25771,60840809,2020-03-24 23:18:27,,saved ldamodel saved file want use visualize topic seems need model corpus dictionary wa able load model dictionary possible load corpus,,2020-09-03 17:16:07,gensim load corpus saved lda model,gensim lda corpus,,,CC BY-SA 4.0,False,False,True,False,False
25778,25778,60778921,2020-03-20 17:31:17,,trying load chine fasttext model cc zh bin gensim stucked following error unicodedecodeerror utf codec decode byte xba position invalid start byte anyone help please detailed error,2020-03-20 18:52:26,2020-03-20 21:15:33,load chinese fasttext model gensim,gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
25796,25796,60903484,2020-03-28 16:25:37,,python wa running file used train word vec model input corpus file output word vec model got following error please help change particular error think folder like already created w v model wordmodel folder tried many way provide smart open lib py program file trace back code tell kindly request help fr change error,,2020-03-28 21:44:51,ioerror error directory w v model wordmodel,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
25799,25799,60832982,2020-03-24 14:22:18,,using lda topic modelling using gensim package set document training getting top term topic present tagged document coding error making thanks advance,,2020-03-24 14:22:18,topic modelling using lda top term present document,lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
25806,25806,60862484,2020-03-26 07:16:46,,confusion use coherence score evaluating lda model run lda model dataset obtained coherence score ranging perplexity score ranging various number topic using lda model gensim package code use calculate coherence score always understood use coherence score find optimal number topic used lda model wa also told coherence score bad someone kindly explain coherence score used doe score signifies bad model comparing different lda model better evaluation method perplexity coherence score,2020-04-01 03:09:21,2020-04-01 03:09:21,coherence value lda model,lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
25849,25849,60704127,2020-03-16 10:21:34,,dataset mil single sentence description word want cluster n cluster vector conversion want use doc vec get mil equal size vector however sure size parameter read however since document case ha fewer token word vector small,2020-03-16 10:44:19,2020-03-16 16:47:29,tuning size parameter doc vec,python cluster-analysis gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
25867,25867,60850956,2020-03-25 14:31:31,,trying evaluate home made topic model using list topic represented keywords want use call corpus list string one document requires understand corresponds get using vectorize text embeddings compute similarity within model,,2020-03-25 16:23:17,topic coherence dictionary glove gensim,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
25869,25869,60852962,2020-03-25 16:22:38,,training word vec scratch gb pre processed marco corpus gb preprocessed corpus sentnecepiece tokenized size training word vec model using following code model running hour doubtful since laptop core using core every moment time plus program seems read gb data disk know anything wrong main reason doubt training gb read disk whole corpus gb code ha read gb data disk doe anyone know much time take train word vec gb text core cpu running parallel thank information also attaching photo process system monitor want know model ha read gb memory even corpus gb total training ever get finished also bit worried health laptop since running constantly peak capacity since last hour really hot add additional parameter quicker training without much performance loss,,2020-05-20 11:53:36,training time gensim word vec,nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
25875,25875,60935894,2020-03-30 17:16:39,,general following code using following dictionary variable dictioanry compute similarity phone iphone get nonzero value index matrix similarity phone iphone similarity matrix get zero entry matter fact almost entry zero word lost missing nonzero similarity equivalent know matrix numpy sparse matrix maybe parameter passing confused element matrix zero parameter passed based documentation seem causing many entry note nonzero limit hundred nonzero entry anyway could fix get around,,2020-03-30 17:16:39,would similarity matrix gensim word veckeyedvectors sparse compared model,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
25880,25880,60913104,2020-03-29 10:49:34,,trained two word vec model suing gensim separate corpus corpus english one corpus different word present want map common word one model want get vector unknown word mapping tried following code however code return top word destination w v model want get vector proposed token way thank advance,,2020-03-30 16:48:24,get vector gensim translation matrix,mapping translation gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
25888,25888,60938299,2020-03-30 19:42:38,,doe gensim word vec mean downsampling used training documentation say useful range e however putting threshold would cause p wi equal meaning word would discarded understanding right working relatively small dataset facebook post word embeddings perform far better using rather anything else within recommended range particular reason text size,,2020-03-30 23:00:28,gensim word vec downsampling sample,python math gensim word-embedding subsampling,,,CC BY-SA 4.0,False,False,True,False,False
25924,25924,60894446,2020-03-27 21:37:59,,possible access fasttext model gensim using multithreading currently trying load model due size loading time stay memory access similarity function multiple thousand time row want parallel current approach us wrapper class load model passed worker look like doe return result wrapper class initiated processor class make use method using seems work mention expertise python multithreading,,2020-03-28 21:51:18,use fasttext model gensim threading,python multithreading gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
25938,25938,60942672,2020-03-31 02:46:07,,performing sentiment analysis using gensim library word vec doc vec model successfully completed word vec dbow distributed bag word dmc distributed memory concatenated dmm distributed memory mean want combination dbow dmc dbow dmm dbow dmc run error function dbow dmc combination error line th error typeerror builtin function method object iterable using tensorflow backend juypter notebook python anaconda please suggest resolve error thanks advance,,2020-03-31 02:46:07,solve typeerror builtin function method object iterable sentiment analysis using gensim,tensorflow jupyter-notebook typeerror python-3.7 gensim,,,CC BY-SA 4.0,False,False,True,False,False
25951,25951,60988425,2020-04-02 09:34:03,,trying apply lda topic modeling using mallet wrapper gensim python code running follows mallet installed c drive running command prompt c mallet bin mallet help command also working import dir java also installed environment variable path also set mallet java yet output show following error already tried response past query stack overflow without improvement would greatly appreciate help manit,2020-06-07 10:14:15,2020-06-07 10:21:01,python gensim mallet,python-3.x jupyter-notebook gensim mallet,,,CC BY-SA 4.0,False,False,True,False,False
25969,25969,61021821,2020-04-03 23:21:08,,currently implementing natural text generator school project dataset sentence predetermined lenght key word convert vector thanks gensim googlenews vector negative bin gz train recurrent neural network create list vector compare list vector real sentence try get close possible real vector problem happens convert back vector word vector necessarily google set would like know efficient solution get closest vector google set outpout vector work python tensorflow thanks lot feel free ask question project charles,,2020-04-04 01:08:20,get closest vector unknown vector gensim,python-3.x nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
25983,25983,60960326,2020-03-31 21:38:12,,order fine tune embeddings following piece code worked previous version however get error message depracated use try fine tune model train method get following error attributeerror word veckeyedvectors object ha attribute train still solution load existing fine tune additional corpus response user ignoring warning doe work module already depracated also running word vec path downloaded embedding make word vec fails check,2020-04-01 06:39:45,2020-04-08 20:54:32,still solution load existing googlenews w v gensim finetune additional corpus,python nlp gensim word2vec embedding,,,CC BY-SA 4.0,False,False,True,False,False
25987,25987,60990456,2020-04-02 11:25:31,,corpus plain text want train bert model tensorflow similar gensim word vec get embedding vector word found example related downstream nlp task like classification want train bert model custom corpus get embedding vector given word lead helpful,,2020-04-02 17:46:23,training bert word embedding model tensorflow,python tensorflow nlp bert-language-model,,,CC BY-SA 4.0,False,False,True,False,False
25997,25997,61055072,2020-04-06 07:42:56,,give result normal word skip use another tokenizer bonus question doe deacc true paramater mean,,2020-04-06 17:26:32,doe gensim simple preprocess python tokenizer seem skip token,python nlp tokenize gensim,,,CC BY-SA 4.0,False,False,True,False,False
26009,26009,61041080,2020-04-05 10:19:12,,doubt training doc vec document since document legal domain really hard clean get ready training hence decided remove period document said confused parameter doc vec recognize sentence two view presented question doc vec differentiate sentence document algorithm work chunk text without idea sentence paragraph document etc might even common tokenization retain punctuation period sentence standalone token therefore confusion adopted approach eliminating punctuation period right kindly provide supportive answer doubt document scrapped range token hence approach pretty even sized document training doc vec even reduce vocabulary consider document size greater token case make use first token token last token motivation kind approach paper related classification document using bert sequence token generated like want know idea somewhat good proceed recommended update saw common text corpus used gensim tutorial link http radimrehurek com gensim model doc vec html found document corpus simply token word contain punctuation eg output ha followed tutorial http radimrehurek com gensim auto example tutorial run doc vec lee html approach removing period document valid window parameter work documentation defined follows window int optional maximum distance current predicted word within sentence,2020-04-05 17:55:09,2020-04-05 18:55:12,significance period sentence training document doc vec,python gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
26010,26010,61041099,2020-04-05 10:20:49,,complete noob machine learning natural language processing using doc vec approach gensim python library find similar document random string problem whenever like add new document trained model need retrain model scratch approach stand ability add new document vocabulary trained model without need train scratch approach would train faster overwhelmed approach nlp started found popular word vec doc vec looking direction study thanks recommendation,,2020-04-05 10:20:49,nlp approach best suited updating model new word without need train scratch,python nlp,,,CC BY-SA 4.0,False,False,True,False,False
26036,26036,61079896,2020-04-07 12:19:14,,trying execute command tried various way changing path still getting following error somebody please help error thanks naseer,2020-04-08 07:32:28,2020-04-08 07:32:28,getting calledprocesserror trying run ldamallet function,python gensim topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
26065,26065,61029524,2020-04-04 14:23:43,,dataset review different hotel trying find similar hotel using review hotel using algorithm achieve way measure accuracy model using rather evaluating result using function,2020-04-06 20:06:45,2020-04-06 20:06:45,measure accuracy doc vec model,gensim unsupervised-learning doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
26071,26071,61080872,2020-04-07 13:14:53,,currently trying process large amount big k word text file data pipeline identified gensim tokenize function bottleneck relevant part provided mwe calling function given example take roughly would like improve number anything still optimize code hardware mid consumer notebook issue would interested runtimes people recent hardware well thank advance,,2020-04-07 14:13:00,improve performance large document text tokenization python regex,regex python-3.x nltk gensim,,,CC BY-SA 4.0,True,False,True,False,False
26118,26118,61085836,2020-04-07 17:26:27,,installed gensim tried always got error attributeerror module smart open ha attribute anybody help fix thanks,2020-04-07 20:40:02,2020-04-07 20:40:02,gensim installation question,gensim,,,CC BY-SA 4.0,False,False,True,False,False
26120,26120,61087427,2020-04-07 18:58:56,,tried save word vec vector text didnt work got error dont really understand duplicate appear wv proposed maybe somone explain thank advance,,2020-04-08 06:49:44,saving word vec text format,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
26129,26129,61105818,2020-04-08 16:49:39,,calculate topic coherence score top word using gensim return nan find compute c v score top word return compute c v score top word number larger return nan happens one topic code follows top word hour session extended error message message seems error caused dividing case get coherence score top word,,2020-04-08 16:49:39,gensim coherence score return nan using top word number using top word,python gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
26138,26138,61134211,2020-04-10 04:49:18,,trained test imdb movie review dataset using gensim word vec model want predict sentiment unlabelled data tried got error reusing open source code full code run code got error valueerror traceback recent call last pred w v dnn predict class new data article print pred pd dataframe pred column sentiment csv abcd sentiment csv pycharmprojects news venv lib python site package kera engine sequential py predict class self x batch size verbose numpy array class prediction proba self predict x batch size batch size verbose verbose proba shape return proba argmax axis pycharmprojects news venv lib python site package kera engine training py predict self x batch size verbose step callback max queue size worker use multiprocessing case symbolic tensor numpy array like x self standardize user data x self stateful x shape batch size x shape batch size pycharmprojects news venv lib python site package kera engine training py standardize user data self x sample weight class weight check array length batch size feed input shape check batch axis false enforce batch size exception prefix input none pycharmprojects news venv lib python site package kera engine training utils py standardize input data data name shape check batch axis exception prefix expected name shape str shape got array shape str data shape return data valueerror error checking input expected dense input shape got array shape somebody suggest solve error predict sentiment unlabeled data using python jupyter notebook pycharm ide thanks advance,2020-04-10 09:01:45,2020-04-10 09:01:45,predict unlabelled data sentiment using gensim word vec model,python-3.7 gensim word2vec sentiment-analysis valueerror,,,CC BY-SA 4.0,False,False,True,False,False
26142,26142,61136557,2020-04-10 08:26:58,,want use gensim create word vec vector tweet dataset code multi label emotion classification based tweet aggregated tweet file contains k tweet used creating word vec vector based code get error look like post mostly code please add detail error site god detail sorry bypass error second averaging method,2020-06-20 09:12:55,2020-04-10 10:40:42,getting error averaging word vec crerated vector,python nlp classification word2vec emotion,,,CC BY-SA 4.0,False,False,True,False,False
26146,26146,61185290,2020-04-13 09:52:56,,text data need sentiment classification positive negative label data unlabelled want use gensim word vec model sentiment classification possible till find anything doe every blog article using kind labelled dataset imdb dataset train test word vec model one going predicting unlabelled data someone tell possibility least theoretically thanks advance,,2020-07-29 14:27:01,possible sentiment analysis unlabelled text using word vec model,python-3.7 gensim word2vec sentiment-analysis,,,CC BY-SA 4.0,False,False,True,False,False
26161,26161,61119374,2020-04-09 10:46:29,,project lda topic modelling used gensim python read reference said get best model topic thera two parameter need determine number pass number topic true number pass see point pass stable number topic see topic ha lowest value necessary use parameter gensim library,,2020-04-10 07:06:43,latent dirichlet allocation implementation gensim,machine-learning lda topic-modeling unsupervised-learning perplexity,,,CC BY-SA 4.0,False,False,True,False,False
26178,26178,61062237,2020-04-06 14:35:23,,need train model word vec fasttext readind different sourcs found different information model trained like read enough creat train model saw people seperatly confused dont know correct sombody help make clear thank,,2020-04-06 17:21:02,gensim train word vec fasttext,python machine-learning gensim,,,CC BY-SA 4.0,False,False,True,False,False
26185,26185,61123616,2020-04-09 14:34:02,,trying estimate cosine similarity document corpus document corpus idea efficiently working pretty large datasets essentially want get document corpus similar document within corpus,,2020-04-10 14:33:33,compute cosine similarity different corpus,python nlp nltk spacy gensim,,,CC BY-SA 4.0,True,True,True,False,False
26198,26198,61125887,2020-04-09 16:32:46,,working word vec gensim python understand meaning sentence word goal able realize sentence indicates feeling speaker find kind dictionary word example one dictionary word indicate happiness sadness thanks,,2020-04-11 19:03:50,build word vec word dictionary indicate feeling,python gensim word2vec glove,,,CC BY-SA 4.0,False,False,True,False,False
26210,26210,61066227,2020-04-06 18:13:15,,trying run following topic modeling get everything last part line run original part command prompt set environmental variable mallet home technically skip part code say import environ work command prompt yes coded corpus earlier code show part code long friend run code ha problem idea get last part work,,2020-04-06 18:13:15,python mallet error return non zero status,python python-3.x error-handling gensim mallet,,,CC BY-SA 4.0,False,False,True,False,False
26215,26215,61126512,2020-04-09 17:09:16,,using gensim hdp hierarchical dirichlet process model wa wondering parameter defines acceptable closeness topic want minimal overlap final topic distribution also doe using best lda method best way visualize using pyldavis,,2020-04-09 17:09:16,gensim hdp parameter separation topic,python nlp gensim dirichlet,,,CC BY-SA 4.0,False,False,True,False,False
26249,26249,61182206,2020-04-13 05:49:23,,written code received error module smart open ha attribute local file solve,2020-04-13 18:36:47,2020-04-29 10:01:49,module smart open ha attribute local file,gensim,,,CC BY-SA 4.0,False,False,True,False,False
26256,26256,61198009,2020-04-13 22:47:13,,reference already looked following question gensim lda text classification python gensim lda model show topic funciton looking lda model trained gensim classify sentence one topic model creates something long line know gensim doe function would one go accomplishing documentation following gotten anywhere http radimrehurek com gensim auto example core run topic transformation html sphx glr auto example core run topic transformation py thanks advance edit documentation http radimrehurek com gensim model ldamodel html,2020-04-13 23:03:05,2020-06-29 06:58:35,classify text gensim lda model,python-3.x gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
26259,26259,61244205,2020-04-16 06:42:59,,one document use lda find one topic got understand number keyword,2020-04-17 14:05:10,2020-04-17 14:05:10,doe number keyword lda topic mean,gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
26274,26274,61070763,2020-04-07 00:01:04,,appropriate way save doc vec model ha transformed sne e g tagged document model wa trained reducing model using sne take hour would good save future use putting panda dataframe saving dataframe csv future use best way sne appropriate way save apparent doc,2020-04-07 00:07:00,2020-04-07 00:09:08,save sne result future use,python gensim dimensionality-reduction saving-data,,,CC BY-SA 4.0,False,False,True,False,False
26289,26289,61218334,2020-04-14 22:30:06,,trying process text using gensim specifically gensim corpus dictionary keep getting error sample code used command prompt install verified numpy scipy installed date checked file path gensim confirmed gensim installed machine also corpus folder gensim obvious issue running python command prompt call module like panda nltk numpy folder location gensim sure getting issue try import gensim know fix issue ha anyone come across issue grateful help thanks output generated running command prompt found c user owner dir b python c user owner vscode extension python python pythonfiles lib python c user owner vscode extension python python pythonfiles lib python parso python c user owner appdata local program python c user owner appdata local program microsoft v code resource app extension python c user owner appdata local program microsoft v code resource app extension python c user owner appdata roaming python c user owner dir b pip c user owner appdata local pip c user owner appdata local program python python lib site package pip c user owner appdata local program python python lib site package pip,2020-04-15 05:24:28,2020-04-16 07:16:10,modulenotfounderror module named gensim corpus gensim package,python-3.x gensim,,,CC BY-SA 4.0,True,False,True,False,False
26303,26303,61280748,2020-04-17 21:10:55,,running word vec model gensim understand metric qsize qsize reported log file spent bit time searching find explanation sample log file,2020-04-18 19:17:17,2020-04-18 19:17:17,meaning qsize qsize gensim word vec log file,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
26310,26310,61235170,2020-04-15 17:43:48,,trying figure solution requirement required map long text unigrams bigram example ability motivate manage team able track progress team intervene improve progress long text mapped team management basically trying figure communication analytical skill long text seen document like job description struggling figure solution want hard code long text keep changing thanks help,,2020-04-15 21:39:32,map detailed text unigram bigram,python-3.x nlp cluster-analysis gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
26341,26341,61367839,2020-04-22 14:37:26,,big gensim doc vec model need infer vector loading training document vector source possible load without big npy file edit remove file manually ask note file exists directory model run server download model file storage question model must file inference want run low memory consumption possible thanks edit file model trainables syn neg npy model weight file model wv vector npy necessary running inference,2020-04-22 21:30:03,2020-04-23 03:58:59,load doc vec without doc vector infer vector,gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
26357,26357,61303579,2020-04-19 11:28:03,,implementing paper compare performance paper uathor say dimensional pre trained word vec vector mikolov et al wondering whether pretrained word vec gensim model pretrained embeddings official google site googlenews vector negative bin gz file source doubt arises line gensim documentation word vec demo section fetch word vec model trained part google news dataset covering approximately million word phrase doe mean model gensim fully trained different official embeddings mikolov,2020-04-19 12:41:10,2020-04-20 19:56:12,gensim word vec model standard model mikolov,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
26364,26364,61253758,2020-04-16 15:13:45,,doc vec model created gensim want use dbscan look clustering sentence within model struggling work best transform model vector work dbscan plot cluster finding many directly applicable example web far output believe two cluster outlier going right way would plot chart visualise cluster thanks,2020-04-20 15:53:14,2020-04-20 15:58:59,plotting dbscan clustering doc vec model,python machine-learning scikit-learn gensim dbscan,,,CC BY-SA 4.0,False,False,True,False,True
26368,26368,61337315,2020-04-21 06:34:44,,visualize lda using pyldavis see topic overlap want know word causing topic overlap want know word intersection topic bubble guidance appreciated,,2020-04-21 13:02:09,common word cause topic overlap gensim lda,python-3.x gensim lda topic-modeling pyldavis,,,CC BY-SA 4.0,False,False,True,False,False
26369,26369,61337725,2020-04-21 07:03:49,,volunteer essay writing format want identify similar user based essay writing feel like word vec suitable problem like however since want embed user name model sure example found internet us word see example code case wondering special way word vec simply consider user name word input model please let know thought happy provide detail needed,2020-04-21 08:16:26,2020-04-21 08:16:26,embed user name word vec model gensim,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
26371,26371,61371059,2020-04-22 17:13:02,,trying import gensim getting error try read word embedding model getting following error trace kindly help using window python anaconda tried everything unable resolve please help trace traceback recent call last file c user user desktop work plot scatter py line gensim model import fasttext file c user user anaconda lib site package gensim init py line gensim import parsing corpus matutils interface model similarity summarization utils noqa f file c user user anaconda lib site package gensim parsing init py line preprocessing import remove stopwords strip punctuation strip punctuation noqa f file c user user anaconda lib site package gensim parsing preprocessing py line gensim import utils file c user user anaconda lib site package gensim utils py line smart open import open file c user user anaconda lib site package smart open init py line smart open lib import open parse uri smart open register compressor file c user user anaconda lib site package smart open smart open lib py line import boto file c user user anaconda lib site package boto init py line boto session import session file c user user anaconda lib site package boto session py line import botocore session file c user user appdata roaming python python site package botocore session py line import botocore configloader file c user user appdata roaming python python site package botocore configloader py line botocore compat import six file c user user appdata roaming python python site package botocore compat py line botocore vendored import six modulenotfounderror module named botocore vendored,,2020-04-22 17:13:02,error botocore vendored module found installing gensim,python python-3.x anaconda gensim botocore,,,CC BY-SA 4.0,False,False,True,False,False
26392,26392,61403580,2020-04-24 07:49:32,,trying see pre trained model ha included common phrase news thought googlenews vector negative bin comprehensive one turned doe even include deep learning machine learning social network social responsibility pre trained model could include word often occur news public report,2020-04-24 10:17:19,2020-04-24 21:00:40,word vocabulary googlenews vector negative bin,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
26394,26394,61405111,2020-04-24 09:24:06,,currently training gensim fasttext model document certain domain unsupervised training method gensim training word representation would like train set sentence label line ultimately test model return precision recall value like possible facebooks fasttext implementation via train supervised test doe gensims implementation support supervised training testing couldnt get work find required method help much appreciated,,2020-04-24 20:54:30,supervised training testing gensims fasttext implementation,machine-learning text classification gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
26407,26407,61310229,2020-04-19 19:17:45,,want use hdp model get number topic corpus already used corpus dictionary train regular lda model work fine get bug edit add system information,2020-04-22 11:34:06,2020-04-22 11:34:06,bug gensim hdp model python,python-3.x time gensim python-3.8,,,CC BY-SA 4.0,False,False,True,False,False
26424,26424,61407835,2020-04-24 11:59:17,,tried run code get keyerror issue,2020-04-24 17:09:32,2020-04-25 04:56:41,keyerror word frans z vocabulary,python nlp data-science gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
26441,26441,61427634,2020-04-25 14:57:53,,code build word vec model databricks using python sparksql got code work another data set tried diffrent data set get error get feeling didnt work well dataset get error goal build model,,2020-04-25 14:57:53,attributeerror builtin function method object ha attribute unique dataset,python databricks gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
26464,26464,61394114,2020-04-23 18:08:53,,trying perform text classification roman urdu dataset using word vec word embedding deep learning model approach based first loading corpus cleaning data tokenize sentence later sentence word tokenized data trained word vec model using gensim library vector size window size later word embedding used get feature vector document getting mean word vector acquired doc vector split training testing data finally sent deep learning model text classification positive negative neutral getting accuracy anyone suggest wrong approach code reference creating doc vector taking mean word vector deep learning model,,2020-04-23 18:08:53,get better text classification accuracy using deep learning word vec feature,python tensorflow deep-learning word2vec text-classification,,,CC BY-SA 4.0,False,False,True,False,False
26483,26483,61448908,2020-04-26 22:25:59,,chat interaction utterance customer advisor would want know advisor interaction contains particular sentence similar sentence list example sentence looking advisor interaction get extract sentence similar intent meaning newbie nlp believe sentence classification extraction problem hand would like know way achieve need basically trying achieve,2020-04-26 22:33:57,2020-04-26 22:58:23,extract sentence ha similar meaning intent compared example list sentence,python-3.x nlp gensim doc2vec sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
26484,26484,61396498,2020-04-23 20:34:51,,installed gensim module using pip install gensim installed successfully importing jupyter notebook showing,,2020-05-13 06:37:34,unable import gensim module,python-3.x jupyter-notebook gensim word2vec topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
26494,26494,61460683,2020-04-27 14:03:20,,would like train model using unordered list keywords category document therefore vocabulary quite small around k token would performance improved training step used actual sentence document example benefit using full document could someone also explain case since model predicts next word document would benefit learning two word often come together given vocabulary,,2020-04-27 18:18:40,word vec using document body keywords training corpus,machine-learning nlp gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
26503,26503,61343809,2020-04-21 12:41:06,,list sentence text file want use existing topic model get topic every sentence tutorial found trained topic model corpus want use one wa trained existing corpus apply sentence possible,,2020-04-21 17:10:35,get topic sentence pre trained model,nlp gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
26515,26515,61357566,2020-04-22 04:56:09,,working around k document based single topic however document cover various different event happened across world related single topic want find subtopics event document achieve using gensim lda model since wa unaware number topic case used elbow method determine optimal number topic case come also coherence score increasing beyond want know going wrong approach would help solve problem better way please let know information regarding approach required,,2020-04-22 04:56:09,topic modeling get different sub topic single topic,machine-learning data-science gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
26527,26527,61436912,2020-04-26 06:56:06,,wish achieve variable length input text based upon label someway use later purpose question effectively vectorize keeping mind would new word test case represeted kmeans cluster represetation encode possibly onehotencoder use fitting model could help select one one hot encoding approach tried would work well text classification model example wish achieve first query approach far used gensim train data output dimension passed score unique word sklearn model choosing cluster give output word new word test data put check word available vocabulary instead assigning random score passing fitted get random label directly assigned cluster label imagine contains kind word query two possible way could think deciding first label encode cluster label mapping pad sequence uptil chosen max length resulting data mapped one hot encoder style mapping b use sklearn multilabelbinarizer hot encode clean way suppose dataframe look like mapped cluster label got word vec kmeans padded mapped using list onehotencoder style mapping mapped mapping b b padded print mapped likewise b look like sklearn preprocessaing import multilabelbinarizer mlb multilabelbinarizer mapped pd dataframe mlb fit transform df cluster rep column mlb class index df index print mapped c c c c c know long post please bear let know valuable suggestion example option end goal represent text line classification line would often name place location etc make difficult consider easier option like bow model etc let know question asked approach think would fit better thanks advance,2020-04-26 07:02:20,2020-04-26 07:02:20,implement kmeans clustering word vec text classification model,python nlp word2vec text-classification one-hot-encoding,,,CC BY-SA 4.0,False,False,True,False,True
26550,26550,61361996,2020-04-22 09:45:35,,number known theme dataset phrase theme result need get theme phrase dataset train gensim doc vec model dataset using phrase taggeddocument list word phrase find closest phrase new phrase check theme closest phrase based cosine similarity probably closest phrase close enough decide new phrase ha theme closest doe approach make sense doc vec model used correctly,,2020-04-22 09:45:35,python gensim doc vec classify phrase theme,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
26591,26591,61569868,2020-05-03 05:06:15,,gensim return phonologically close word similar sound instead semantically similar one normal might happen documentation http radimrehurek com gensim model keyedvectors html gensim model keyedvectors wordembeddingskeyedvectors similar training data contains academic paper wa training script,2020-05-07 15:35:25,2020-10-12 21:27:14,gensim model wv similar return phonologically similar word,python data-science gensim embedding word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
26606,26606,61521498,2020-04-30 10:39:00,,trying run python gensim package r environment via reticulate specifically trying build doc vec model corpus token tag need prepared taggeddocument function problem example python trying reproduce r result output kind used build vocabulary train doc vec model get result r possibly without loop thanks advance edit trying even simpler setting keep receiving error message blockquote error py call impl callable dot args dot keywords attributeerror str object ha attribute word detailed traceback file c anaconda lib site package gensim model doc vec py line build vocab progress per progress per trim rule trim rule file c anaconda lib site package gensim model doc vec py line scan vocab total word corpus count self scan vocab document docvecs progress per trim rule file c anaconda lib site package gensim model doc vec py line scan vocab isinstance document word string type wrong,2020-05-05 15:32:44,2020-10-04 10:07:32,use taggeddocument function gensim doc vec via reticulate r,r gensim doc2vec reticulate,,,CC BY-SA 4.0,False,False,True,False,False
26614,26614,61572397,2020-05-03 09:41:08,,copy simple python script building wikipedia text corpus natural language processing build corpus stripping wikipedia markup article using gensim cose anyway obtained error although installed package edit try obtain error,2020-05-03 11:09:39,2020-05-03 15:49:29,build corpus wikipedia modulenotfounderror module named gensim,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
26619,26619,61472611,2020-04-28 04:26:29,,code doe return computer science expected right method extract phrase pragmatically,,2020-04-29 20:11:25,phrase detection using phrasestransformer,nlp gensim n-gram phrase,,,CC BY-SA 4.0,False,False,True,False,False
26654,26654,61509408,2020-04-29 18:48:56,,currently getting segmentation fault loading model gensim order create model save however problem start load model use similar method using get segmentation fault process finished exit code interrupted signal sigkill help appreciated thank,,2020-04-29 18:54:56,segmentation fault gensim,python segmentation-fault gensim,,,CC BY-SA 4.0,False,False,True,False,False
26658,26658,61625273,2020-05-06 00:22:50,,tokenized string made panda column print column look like next running word vec print vocabulary using getting character instead long list word vocabulary sure wrong,,2020-05-06 04:40:51,word vec giving character instead word,python pandas nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
26693,26693,61596101,2020-05-04 15:42:09,,trying calculate topic cosine similarity score lda topic model prof complicated first expected ha method calculate distance topic unfortunately cosine distance implemented ha jaccard distance bit vector length dependent e comparing top important word per topic distance lower comparing top distance full length vector compared topic includes term different probability problem output model look like shown top word order calculate cosine sim distance would parse second element tuple e part indicates term probability wa wondering whether easier way get cosine similarity model parsing individual string term probability really way go thanks help,,2020-05-04 19:17:29,calculating cosine similarity gensim model,python gensim topic-modeling cosine-similarity,,,CC BY-SA 4.0,False,False,True,False,False
26702,26702,61608275,2020-05-05 07:52:35,,training text data using gensim doc vec model google colab repository gpu runtime want save trained model test v file following code snippet following error generated colab notebook usr local lib python dist package smart open smart open lib py userwarning function deprecated use smart open open instead see migration note detail http github com rare technology smart open blob master readme rst migrating new open function see migration note detail migration note url,,2020-05-05 13:39:05,save gensim doc vec trained model google colab,nlp google-colaboratory gensim sentiment-analysis doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
26718,26718,61511101,2020-04-29 20:29:46,,let say train model million word order find similar word need calculate distance embedding test word embeddings million word word find nearest word seems gensim calculate result fast although want calculate similar function extremely slow would like know gensim manages calculate nearest word fast efficient way calculate similares,,2020-04-30 03:46:08,doe gensim manage find similar word fast,python time-complexity gensim word2vec similarity,,,CC BY-SA 4.0,False,False,True,False,False
26794,26794,61638940,2020-05-06 15:22:45,,got lda model using gensim save locally result four file specified place loading back simple however want model saved work save individual bit example work actually meaningfully read back function expected coherent model idea somebody could take file use model python anybody help,,2020-05-07 09:04:10,save gensim lda model,python amazon-s3 gensim,,,CC BY-SA 4.0,False,False,True,False,False
26846,26846,61693100,2020-05-09 07:12:38,,using window python tried download fasttext model calculate soft cosine similarity document run python file stop arriving statement error responding stop without reaction doe anybody know happens thanks,2020-05-10 05:53:37,2020-05-10 05:53:37,fix problem downloading fasttext model,text-mining gensim similarity cosine-similarity sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
26847,26847,61693901,2020-05-09 08:33:13,,study exploring statistically significant ideological bias one set medium compared another wa hoping explore using word embeddings approach let u take u uk news medium example build corpus u medium article given time period separate corpus uk medium article period train using word embeddings algorithm set parameter e g window vector size possible test cosine similarity obtained pair word u corpus statistically significantly larger cosine similarity obtained pair word uk corpus many thanks help,2020-05-09 08:53:22,2020-05-09 13:37:24,possible compare similarity score across two word embeddings repository,nlp stanford-nlp gensim word2vec fasttext,,,CC BY-SA 4.0,False,False,True,True,False
26851,26851,61736874,2020-05-11 18:38:20,,two corpus one woman leader speech men leader speech would like test hypothesis cosine similarity two word one corpus significantly different cosine similarity two word another corpus test equivalent logical possible cosine similarity different across two corpus could examine cosine similarity two word third corpus similar first second corpus,,2020-05-12 00:24:17,compare cosine similarity across three pretrained model,nlp gensim word2vec word-embedding glove,,,CC BY-SA 4.0,False,False,True,False,False
26918,26918,61746512,2020-05-12 07:56:42,,working gensim fasttext modeling following question output ft model save base path model path fname save following file correct way combine three file attempt load training file use get following error function object ha attribute wv finally model way store output run part code every time want train model compare thanks assistance fasttext train model usage model full tracible error message,2020-05-12 17:31:40,2020-05-12 20:51:25,python gensim fasttext saving loading model,python gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
26922,26922,61797610,2020-05-14 12:40:30,,want train glove embeddings based corpus however want initial weight word vocabulary equal vector pre trained glove model function specify initial weight trying find function succeed also found e g glove gensim package reason use one package also train another similar model fasttext function specifying initial weight fasttext glove complete beginner come python would really appreciate tip,,2020-05-14 12:40:30,initial weight glove fasttext embeddings python,python gensim fasttext glove,,,CC BY-SA 4.0,False,False,True,False,False
26942,26942,61800216,2020-05-14 14:42:01,,try compute similarity two word using cosine distance source code similarity called try compare result similarity using library gensim word vec result different example difference get similarity using library similarity,2020-05-14 21:30:26,2020-05-15 00:16:00,get different result cosine similarity compare library result,python nlp cosine-similarity edit-distance,,,CC BY-SA 4.0,False,False,True,False,False
26971,26971,61622340,2020-05-05 20:20:44,,option save trained gensim word vec model saved model using tf word save trained embedding vector saved model signature work tensorflow following step correct normally edit example helped http kera io example nlp pretrained word embeddings,2020-06-16 08:47:14,2020-06-16 08:47:14,save trained gensim word vec model tensorflow savedmodel,tensorflow gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
27001,27001,61807128,2020-05-14 20:48:25,,actually injecting document gensim mode reading database first script save document file system load doc check similarity vector infer vector understand come also return id tagged one yield section enter code,,2020-05-14 20:48:25,anormal number sims document gensim,gensim,,,CC BY-SA 4.0,False,False,True,False,False
27010,27010,61789168,2020-05-14 04:09:52,,trying parse glove b data kaggle via google colab run word vec process apology huge url fastest link found however hitting bug token parsed correctly resulting error attempted handle way also looked load word vec format method tried ignore error however seem make difference tried map method line two following combination advice link b fixed changed error message received e removing change nothing text per comment exact error getting follows system work fine using text file containing test additionally searching source text file glove b txt occurrence come result window done executing calling pre post map call provide following output note kept mapping call completeness effort effect print first ten line file get following text match word vec format additionally count occurrence string document find none search method evidently thusfar ineffective would really appreciate help,2020-05-15 03:08:57,2020-05-15 22:58:14,glove b parsing could convert string float,python text gensim word-embedding glove,,,CC BY-SA 4.0,False,False,True,False,False
27014,27014,61853117,2020-05-17 14:07:44,,trained word vec model using gensim model matrix value floating point look like e need use value matrix string way remove e e etc,,2020-05-17 21:48:51,gensim word vec model floating point,python nlp nltk gensim,,,CC BY-SA 4.0,True,False,True,False,False
27018,27018,61854977,2020-05-17 16:16:51,,beginner python actually face following problem initial point dataframe like following want buliding dictionary corpus bow gensim using hdp tfidf problem want topic relevance word class wa get something like dictionary need one list like row like tried different approches like loop always crash huge amount data guess list get long used following code grouped domain plaintext class solution get corpus bow grouped,,2020-05-17 16:16:51,groupby agg command dataframe crash list str aggregation long,python dataframe dictionary group-by gensim,,,CC BY-SA 4.0,False,False,True,False,False
27027,27027,61921588,2020-05-20 19:43:49,,trying load pre trained doc vec model using gensim use map paragraph vector referring http github com jhlau doc vec pre trained model downloaded english wikipedia dbow also link however load doc vec model wikipedia infer vector using following code get error know couple thread regarding infer vector issue stack overflow none resolved problem downloaded gensim package using addition looked source code gensim package found use doc vec load doc vec class really load function since subclass word vec call super method load word vec make model word vec object however infer vector function unique doc vec doe exist word vec causing error also tried casting model doc vec got error fact want gensim convert paragraph vector using pre trained model work well academic article reason want train model would really grateful someone help resolve issue btw using python current gensim version thanks,,2020-05-21 01:34:38,load doc vec object using gensim,python gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
27096,27096,61944240,2020-05-21 21:36:07,,wa using gensim loading pre trained word vec showed following error calling code sample,,2020-05-21 21:36:07,gensim v word vec deprecationwarning call deprecated wv attribute removed use self instead,python-3.x gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
27110,27110,61977341,2020-05-23 19:11:08,,used following code lemmatize text already excluding stop word kept word longer however using following code split existing word wheres youre pron expect pron result text caused behaviour,,2020-05-23 19:11:08,unexpected lemmatize result gensim,nlp nltk gensim lemmatization,,,CC BY-SA 4.0,True,False,True,False,False
27133,27133,61873864,2020-05-18 16:01:41,,issue following pretrained vector saved txt format load dict try save training gensim give error like following using code create gensim word vec replacing current untrained vector code replaces untrained random vector wit pretrained next train gensim finally save replace vector saving work need replace save txt help edit split function bit data dimension embedding index added code python code run fine without vector crash populate embedding index go word vector txt reason vector dim skip edit stack trace full error traceback recent call last,2020-05-19 16:56:55,2020-05-25 08:43:14,gensim saving word vector txt format error,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
27138,27138,61949436,2020-05-22 06:57:42,,trying use gensim implementation lda suggests using automatic learning hyperparameters set somewhat technical essentially automatically learning two parameter model usually would specify explicitly however seeing article lda hyperparameter tuning see also possible tune parameter black box train model different fixed value parameter select best one let call function iterate range topic alpha beta parameter value essential difference two method special case second method better first one,,2020-05-22 06:57:42,difference automatic manual lda hyperparameter tuning,gensim lda topic-modeling hyperparameters,,,CC BY-SA 4.0,False,False,True,False,False
27152,27152,61983014,2020-05-24 07:45:57,,try import gensim library python library last version first import got second import got error,,2020-05-27 06:37:21,import gensim got typeerror expected byte descriptor found,python import typeerror gensim attributeerror,,,CC BY-SA 4.0,False,False,True,False,False
27164,27164,61952950,2020-05-22 10:29:01,,looking similar word vocab oov word using gensim something like way achieve task option gensim also welcomed,,2020-05-22 18:21:24,find similar word oov word,python nlp gensim similarity oov,,,CC BY-SA 4.0,False,False,True,False,False
27174,27174,61918360,2020-05-20 16:40:53,,trained gensim lda model corpus list list k sentence list try see topic distribution word give empty list also set min probability training model one parameter see topic shown irrespective low probability edit debugged find wa problem case wa chunksize parameter set time training earlier wa default changed higher value case word term started giving topic distribution know yet chunksize wa causing issue,2020-05-21 07:35:30,2020-05-21 07:35:30,lda get term topic give empty list,python nlp gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
27200,27200,62032372,2020-05-26 22:22:47,,read question coherence score good bad found coherence score u mass experiment got score u mass c v wonder u mass score range update used gensim library scanned number topic u mass start lowest negative point turn back bit like upsidedown version c v,2020-05-27 07:10:37,2020-05-27 19:09:41,coherence score u mass good bad,nlp lda topic-modeling lsa topicmodels,,,CC BY-SA 4.0,False,False,True,False,False
27221,27221,62085134,2020-05-29 11:39:24,,wrote code used used spacy restrict word tweet content word e noun verb adjective transform word lower case add po underderscore e g love verb old fashioneds noun want train word vec model average resulting embedding matrix dont idea help please,,2020-05-29 17:26:43,want train word vec model average resulting embedding matrix,python pandas nlp spacy gensim,,,CC BY-SA 4.0,False,True,True,False,False
27223,27223,61990540,2020-05-24 18:30:54,,large dataframe row one column contains document text trying unsuccessfully run gensim summarize specific column entire dataframe extracting row variable running summarize work well slow ugly also get error find row one sentence hundred thousand anyone help,2020-05-25 06:00:51,2020-05-25 06:00:51,summarize panda dataframe column,python pandas dataframe gensim,,,CC BY-SA 4.0,False,False,True,False,False
27237,27237,62007088,2020-05-25 16:54:27,,question interpret situation trained doc vec model following tutorial http blog griddynamics com customer vec representation learning automl customer analytics personalization reason return seems return proper value doc vec object return doctags vector doc thank comment answer advance code used train doc vec model return,,2020-05-25 20:45:35,doe gensim doc vec object return empty doctags,gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
27252,27252,62052038,2020-05-27 20:11:50,,trained gensim word vec model python using custom dataset deploying model chrome extension using angular typescript willing use trained gensim model vocabulary generate embeddings go due memory constraint plan use keyedvectors instead deploying entire model currently model file stored really new deploying gensim model someone please suggest good method use trained gensim model preferably keyedvectors angular provide information problem needed,2020-05-27 22:50:59,2020-05-27 22:50:59,deploy gensim keyedvectors angular,angular machine-learning google-chrome-extension data-science gensim,,,CC BY-SA 4.0,False,False,True,False,False
27298,27298,62076017,2020-05-28 23:09:42,,trying make code run raspberry pi stuck error hour code segment throw error run perfectly window project def create lem text data list def sent word sentence sentence sentence yield gensim utils simple preprocess str sentence deacc true deacc true remove punctuation code turned called function error message tried reinstalling spacy en model running directly pi spacy version window machine pi basically information online error,,2020-05-31 21:36:43,python spacy keyerror e retrieve string hash,python raspberry-pi spacy raspberry-pi4,,,CC BY-SA 4.0,False,True,True,False,False
27309,27309,62025647,2020-05-26 15:25:06,,currently composing topic model using gensim mallet see code snippet using coherence model mallet model get coherence score look performance run lot model optimize parameter timed one run program usind topic optimize interval came min sec building ldamallet model took sec building coherence model sec getting coherence score took min sec like double time took build original model doe anyone know case make coherence score calculation effecient best nero,2020-05-26 15:30:22,2020-05-26 15:30:22,extremely low performance calculating coherence score,gensim lda topic-modeling mallet topicmodels,,,CC BY-SA 4.0,False,False,True,False,False
27329,27329,62140106,2020-06-01 20:01:45,,method find top n similar word method way find n least similar word,2020-06-14 13:25:08,2020-06-14 13:25:08,least similar gensim doc vec,gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
27335,27335,62059196,2020-05-28 07:27:12,,tried load pre trained fasttext vector fastext wiki word vector code work well warning message little annoying message said deprecated better use decided changed code changed code like error occurred error message like understand thing happen change message said work know anything please let know always thanks guy help,,2020-05-28 08:50:09,gensim fasttext load facebook vector work,python gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
27348,27348,62125400,2020-06-01 03:49:11,,know train model multiple batch doc vec since load data ram loaded,2020-06-01 16:42:23,2020-06-02 21:07:58,anyway train doc vec model multiple batch,gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
27354,27354,62094471,2020-05-29 20:55:51,,trying find duplicate document plan incrementally every time add document check duplicate big store document work part one weird thing setting increase get error could set something like something probably safe seems silly wa looking something would change find doc googling around help make think whole process wrong new python machine learning possible thought process completely help appreciated,,2020-05-29 20:55:51,gensim similarity index updating num feature,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
27363,27363,62045818,2020-05-27 14:39:55,,natural language process project try use gensim api get lsi similarity matrix every time run code lsimodel give different similarity matrix totally different slightly different like last time one number change next time run code make rest analysis change totally checked input corpus tfidf dictionary every time would happen solution,,2020-05-27 14:39:55,lsimodel gensim show different output taking input,python nlp gensim lsa,,,CC BY-SA 4.0,False,False,True,False,False
27415,27415,62179243,2020-06-03 17:40:03,,everyone trying import gensim jupyter got following error p tried gensim version,,2020-06-03 17:40:03,importerror import name deprecated import gensim,python-3.x jupyter-notebook gensim,,,CC BY-SA 4.0,False,False,True,False,False
27457,27457,62235365,2020-06-06 17:23:19,,developed jupyter notebook local machine train model python v library set variable fixed integer result always tried moving notebook workspace azure machine learning studio classic result differ even leave suggested following link installed library version checked version wa variable wa set sne generates different result different machine python code data different result different machine still able get result else check happening update generate file local machine import aml result intention pkl file still looking get result possible without importing pkl file library version code full code found sample data link inside,2020-06-07 00:25:15,2020-06-07 01:37:03,model generate different result moving azure machine learning studio,python scikit-learn gensim azure-machine-learning-studio,,,CC BY-SA 4.0,False,False,True,False,True
27459,27459,62181162,2020-06-03 19:29:13,,wa got error see open solve tried install different version upgraded version,,2020-07-24 15:51:56,import name open smart open,deep-learning nlp importerror gensim,,,CC BY-SA 4.0,False,False,True,False,False
27464,27464,62200198,2020-06-04 17:00:29,,way get topic distribution unseen document using pretrained lda model without using lda model unseendoc syntax trying implement lda model web application wa way use matrix multiplication get similar result could use model javascript example tried following pretrained model topic word conventional syntax output first element tuple index topic second element probability topic matrix multiplication version probability index value probability clearly two match example lda model unseendoc show topic ha probability matrix multiplication method say topic ha probability missing step,,2020-06-05 01:36:53,way infer topic distribution unseen document gensim lda pre trained model using matrix multiplication,gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
27497,27497,62222500,2020-06-05 19:04:11,,run gensim code create lda model set document ha created list topic possible go back document assign one topic none applicable able find code sample accomplish online thank,,2020-06-05 19:04:11,creating lda model document assign topic,python machine-learning nlp gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
27520,27520,62204536,2020-06-04 21:34:55,,information retrieval scenario basically purpose find textual similarity two kind document first document extract keywords using gensim summarization retrieve tag associated document already given user retrieve similar word fasttext word found previous step put word similar word together use searching query bm problem ofted bm give poor result query often long wa thinking poor result could depend doe bm suffers long query query bm fewer word query instead thank,,2020-06-04 21:34:55,long query search rank bm,nlp,,,CC BY-SA 4.0,False,False,True,False,False
27542,27542,62174945,2020-06-03 14:08:34,,several gensim model fit million document like pull top representative document model topic help pick best model let say model corpus get topic probability following form list tuples sort list tuples topic probability retrieve top document corpus guessing answer look something like method assigning topic struggling work list tuples maintaining document index somewhat complicated fact know argument topic probability suppressed model take day run like avoid running possible,,2020-06-05 19:02:18,gensim extract representative document topic,python tuples gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
27565,27565,62227888,2020-06-06 05:48:00,,someone help flow process using nlp python totally new nlp,,2020-06-06 05:48:00,get similarity resume one resume best x job role fresher resume need compare best one,python-3.x nlp nltk gensim,,,CC BY-SA 4.0,True,False,True,False,False
27589,27589,62195045,2020-06-04 12:50:49,,currently building topic model gensim running gensim model ldamulticore method seems something weird somehow seems rerun file reload something print code printed console lot time current setup iterating multiple alpha beta value max coherence score see code calling lda function contains gensim model ldamulticore within loop get console even get print tell past line gensim model ldamulticore stated positioned one function get notice ran print line loop multiple time without loop moving forward b moved forward loop without finishing execute second line wait longer take minute ran loop variation get result lda first iteration alpha beta start behaviour extremely performance heavy somehow need run whole loop actually lda tryed different scenario see commented code gave loop one value go version executed fraction runtime took programm complete first first iteration doesnt make sense hope someone help nero,,2020-06-04 12:50:49,gensim lda rerunning python file time,python gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
27591,27591,62291303,2020-06-09 20:28:05,,coming kera pytorch would like create pytorch embedding layer matrix size vocabulary word index embedding vector dimension glove vector confused needed step kera load glove vector embedding layer constructor take argument looking pytorch torchtext library see embeddings loaded twice layer sample code found specifically glove embeddings loaded addition thought function build vocabulary training data glove embeddings involved step stackoverflow question answer question pytorch gensim load pre trained word embeddings embedding pytorch pytorch lstm using word embeddings instead nn embedding thanks help,,2020-06-10 00:21:50,pytorch loading word vector field vocabulary v embedding layer,python machine-learning pytorch word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
27597,27597,62244610,2020-06-07 11:28:17,,try use parallelism word vec implemented gensim library notice increase thread training slow know setting make use debian python cython benefit parallelism thanks advance,,2020-06-08 16:45:22,parallelization benefit training word vec model,parallel-processing nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
27609,27609,62279337,2020-06-09 09:30:27,,running error valueerror create tensor proto whose content larger gb reason error seems trying create tensor gb big numpy array array biosentvec pretrained embeddings pubmed source http github com ncbi nlp biosentvec biosentvec original code look like source http github com kaggarwal clinicalnotesicu found thread seems fit problem create tensor proto whose content larger gb implemented like receive error anybody help understanding even solving problem also think reason issue could origin else original code source also ha worked author paper loaded embeddings gensim saved model pickle accessed model vector saved file gensim,,2020-06-09 09:30:27,loading biosentvec create tensor proto content larger gb,python tensorflow protocol-buffers gensim pubmed,,,CC BY-SA 4.0,False,False,True,False,False
27616,27616,62211396,2020-06-05 08:42:07,,refer image process word vec skipgram extract training datasets word pair input sentence e g love love may ask word pair sentence contains one word happy happy happy tested word vec algorithm genism one word training set sentence word included sentence word vec algorithm still construct embedding vector specific word sure algorithm able update answer posted think word embedding vector created word word sentence random initialization neural network weight,2020-06-14 12:52:43,2020-06-14 12:52:43,doe gensim word vec word embedding extract training word pair word sentence,nlp text-mining gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
27629,27629,62308418,2020-06-10 16:24:41,,trying load pretrained vec file facebook fasttext crawl vec next code fails next error possible load vector possible afterwards train sentence thanks advance whole error trace,2020-06-11 09:43:31,2020-06-11 09:43:31,word embedding gensim fasttext training pretrained vector,python gensim word-embedding fasttext,,,CC BY-SA 4.0,False,False,True,False,False
27630,27630,62310124,2020-06-10 18:01:13,,trying save custom fasttext model trained gensim want save binary file possibility training model may code save binary file next one obtaining next error line clue could happening thanks advance,,2020-06-24 18:53:06,saving fasttext custom model binary gensim,save gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
27632,27632,62343252,2020-06-12 11:22:16,,trying use gensim phraser column df sample df given wrote method bigram tried get character output bigram missing,,2020-06-13 11:27:23,use gensim phraser panda column using apply method,python pandas gensim n-gram phrase,,,CC BY-SA 4.0,False,False,True,False,False
27645,27645,62344470,2020-06-12 12:39:35,,synonym detection based word vec model gensim possibility automatic calculate recall precision want metric based trained model whitout giving list correct synoynms cheer marvin,,2020-06-12 12:39:35,automatic calculate recall precision word vec model,python gensim word2vec synonym,,,CC BY-SA 4.0,False,False,True,False,False
27662,27662,62298548,2020-06-10 07:59:18,,want use pretrained model microsoft powerapps powerapps provides readymade model train use however take example want call gensim sematic match string powerapp use dont want run model azureml server call via exposed api requirement gensim word vec hosted powerapps run prediction demand,,2020-06-10 07:59:18,pretrained model microsoft powerapps,gensim powerapps,,,CC BY-SA 4.0,False,False,True,False,False
27677,27677,62299869,2020-06-10 09:12:50,,used word vec get vector sample textual data assuming word w vector also similarity matrix show cosine similarity word question new word x similarity matrix get vector let say similarity w x similarity w x compute vector x multiply vector word w similarity sum value read still sure correct approach example link doe answer question since data related new word similarity matrix available http datascience stackexchange com question train existing word vec gensim model new word,,2020-06-10 09:12:50,word embedding new word using similarity,vector cosine-similarity word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
27684,27684,62348760,2020-06-12 16:44:04,,getting different value similarity measure swap position camera final baby final though similarity measure using symmetrical nature using lda model gensim,2020-06-12 16:44:58,2020-06-12 16:44:58,getting different value similarity measure change position input data,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
27685,27685,62348981,2020-06-12 16:58:33,,code work absolutely fine data set containing instance whenever reduce data set throw key error word vocabulary every data point throw error data set excel format http stack imgur com ycbiq png know fix problem since little knowledge still learning please help fix problem,2020-06-12 17:12:29,2020-06-12 17:26:42,word vec recommendation system keyerror word vocabulary,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
27690,27690,62315518,2020-06-11 01:09:41,,word array pickle file corresponding vector array npy file combine make gensim w v model,,2020-06-11 16:39:08,combining word array vector array make gensim w v model,gensim word2vec embedding word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
27739,27739,62419353,2020-06-16 23:57:19,,would possible look text within certain topic determined lda list topic word found using lda analysed text dataframe column would like select filter row text one specific topic need information provide referring step return output created print keyword topic original column text analysed called look like expected output would thanks,2020-06-17 00:39:12,2020-06-27 15:42:09,select text topic lda,python gensim text-classification lda,,,CC BY-SA 4.0,False,False,True,False,False
27740,27740,62387623,2020-06-15 11:51:59,,tried dataframe column message get error,,2020-06-15 12:14:26,remove stopwords gensim,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
27755,27755,62304813,2020-06-10 13:29:10,,working nlp problem gensim requires use multilingual embeddings already pretrained aligned txt embeddings fasttext provides web sadly provide full model vector missing important vocabulary problem per character embedding ability fasttext model come handy case question way recreate entire model infer new vocabulary also vector space aligned embeddings still way obtain term aligned embedding space without retrain new entire fasttext align already pre trained one,,2020-06-10 13:29:10,full fasttext model keyedvectors infer new word aligned space,nlp gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
27760,27760,62451936,2020-06-18 14:09:49,,unfortunately know introduce issue lda trying assign topic text getting error try determine threshold assigning topic valueerror traceback recent call last print score threshold sum score len score valueerror operand could broadcast together shape investigating bit found output output causing issue list value list list reporting step get lda model see set something wrong code hope help go example output creation dictionary example output code top question could please tell error mean fix thank,2020-06-18 14:15:21,2020-06-18 14:15:21,problem threshold assigning topic text using lda,python nltk gensim text-classification lda,,,CC BY-SA 4.0,True,False,True,False,False
27770,27770,62356383,2020-06-13 06:36:31,,using gensim mallet wrapper topic modeling worked surprisingly fast step see obtain topic distribution document n taking long time ha taken hour complete document sure incorrectly way get topic distribution document much faster,2020-06-13 06:55:15,2020-06-18 07:20:48,gensim mallet wrapper get document topic weight,python gensim lda topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
27780,27780,62339753,2020-06-12 07:42:45,,trained lda model using guidedlda http guidedlda readthedocs io possible transfer lda model gensim framework continue working,,2020-06-12 07:42:45,possible load pre trained lda model gensim,python nlp gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
27787,27787,62358583,2020-06-13 10:38:34,,trying train gensim doc vec model tagged document around document following code tried modifying doc vec parameter without luck data trained word vec model much accurate comparison doc vec model similar result word vec model different doc vec model following code searching similar result output aforementioned cited,,2020-06-14 15:57:14,improving doc vec gensim efficiency,python nltk gensim word2vec doc2vec,,,CC BY-SA 4.0,True,False,True,False,False
27805,27805,62454568,2020-06-18 16:16:19,,need train word vec model done need use calculate likelihood previously unseen data stuck though seen wmd calculating similarity sentence trying calculate likelihood text model,,2020-06-18 16:16:19,calculate likelihood sentence using word vec model,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
27838,27838,62492450,2020-06-20 22:31:59,,new gensim learning gensim followed example http www machinelearningplus com nlp gensim tutorial sure last line creates corpus dictionary creating dictionary already used simple preprocess process document line line wa thinking creating corpus using dictionary needed use simple preprocess process document line line redundant thanks alex,2020-06-22 16:49:07,2020-06-22 16:49:07,question gensim create corpus dictionary,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
27896,27896,62529967,2020-06-23 07:55:10,,order use class compute similarity word one need provide corpus size dictionary case corpus word vector computed using word vec model wonder need size dictionary also need size dictionary used create word vec model size dictionary corpus want compute similarity,2020-06-23 08:17:04,2020-06-23 17:14:06,computing similarity gensim need size dictionary,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
27899,27899,62534889,2020-06-23 12:36:29,,trouble error using word vec gensim code happen error please help thanks attention,2020-06-23 13:25:16,2020-06-23 13:25:16,memoryerror unable allocate mib array shape data type float,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
27959,27959,62581874,2020-06-25 18:19:05,,difference using noticed parameter would like know one used,,2020-06-25 18:19:05,gensim ldamallet v ldamodel,gensim lda topic-modeling mallet,,,CC BY-SA 4.0,False,False,True,False,False
27966,27966,62565772,2020-06-24 23:52:38,,would like know possible group together word included lda output e word generated example would like group mispelled together would possible relevant previous code thank,2020-06-29 00:52:37,2020-07-03 20:03:52,grouping word meaning lda,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
27972,27972,62636828,2020-06-29 11:09:49,,trying import gensim run following error tried uninstalling numpy scipy gensim using command prompt installing doe resolve issue also looked suggestion similar problem tried installing numpy mkl cp cp win amd whl resulted separate error thus stuck using numpy scipy gensim installed via additionally installed scipy version latest version give following error described link error loading scipy oserror winerror specified module could found help greatly appreciated additional information using python window,2020-06-30 04:11:06,2020-06-30 07:09:11,importerror dll load failed specified module could found trying import gensim,numpy scipy gensim,,,CC BY-SA 4.0,False,False,True,False,False
27978,27978,62543491,2020-06-23 20:47:35,,trying understand going wrong following example train text dataset described doc one ha following give good embedding vector verified evaluating word similarity task however loading textfile used manually model still say training number epoch training much faster resulting vector bad performance similarity task happening suppose could number sentence text file seems single line doe gensim downloader split text file sentence yes length,2020-06-23 20:56:06,2020-06-23 21:09:44,inconsistent result training gensim model gensim downloader v manual loading,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
27980,27980,62620509,2020-06-28 09:13:55,,wrote lda model notebook trying wrap gensim lda model mallet getting following error calledprocesserror command input mymallet mallet bin mallet import file preserve case keep sequence remove stopwords token regex input tmp fbcc b corpus txt output tmp fbcc b corpus mallet returned non zero exit status error raised second line path correct tried solution gensim mallet calledprocesserror returned non zero exit status work,2020-06-28 10:24:23,2020-06-28 10:24:23,fix mallet gensim,gensim lda kaggle mallet,,,CC BY-SA 4.0,False,False,True,False,False
27994,27994,62603978,2020-06-26 23:00:08,,running nlp algorithm ultimately performs topic modelling gensim lda model run code many time work properly run selection even selecting whole program run file get errno broken pipe defined user function go follows function run cycle go follows said code run perfectly run selection option crash run file use spyder anaconda environment python appreciate suggestion know solve consider need information doubt reply thank,2020-06-26 23:37:52,2020-06-26 23:37:52,broken pipe error runing selection work properly runing file crash,python gensim broken-pipe,,,CC BY-SA 4.0,False,False,True,False,False
28004,28004,62656022,2020-06-30 11:05:00,,trained lda model using following parameter applied model given corpus wa expecting lda corpus list list matrix number row number doc number column number topic element matrix tuple form topic index probability however getting weird result element list would appreciate help,,2020-07-08 10:12:52,unexpected output applying lda trained model given corpus,python gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
28034,28034,62626282,2020-06-28 17:53:54,,might seem like trivial question many clear model look like also tokenize x train x test like embedding layer look like get model dimension size pad sequence max sequence length aka max sentence length also get embedding matrix definition w v dimension size first embedding layer referring w v dimension size second would max input length aka max length pad sequence get dimensional size w v model equal let say doe mean pad sequence maxlen also also input length embedding layer example w v size sentence length want predict pad sequence maxlen would would neural net able correctly predict sentence length,,2020-06-28 17:53:54,size word vec model equal max input size sentence,python gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
28129,28129,62730537,2020-07-04 14:46:03,,installed gensim however keep getting error try import importerror import name open using updated version gensim smart open reinstalled several time still get work,,2020-07-04 14:46:03,importing gensim,gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
28147,28147,62654478,2020-06-30 09:36:47,,trying create dictionary set big file expected use walk inside readfiles walk file inside directory use readtxtfile read file got error use readfiles ok one file comment code typeerror decoding str need byte like object list found,2020-06-30 12:31:56,2020-06-30 12:31:56,iterator iterator reading txt file decoding str need byte like object txt file,python dictionary iterator gensim yield,,,CC BY-SA 4.0,False,False,True,False,False
28164,28164,62783726,2020-07-07 20:50:29,,new nlu project document embedding want fine tune doc vec model gensim small dataset see help document clustering read tutorial website mention anything fine tuning find doc vec pertained wikipedia twitter big dataset,,2020-07-07 20:50:29,fine tune doc vec gensim,nlp gensim nlu,,,CC BY-SA 4.0,False,False,True,False,False
28173,28173,62766787,2020-07-07 01:30:18,,first apology long winded mathematician hoping dumbed solution short attempting compare two body text generate recommendation see novice attempt measuring similarity using nlp open feedback primary question doe method described serve accurate mean finding similarity wording sentiment etc two body text would generate recommendation engine new method new data etc currently two dictionary one personality data called personality feature dict includes personality type associated descriptor word called book feature dict containing book title descriptor word extracted using tf idf stand using following code calculate similarity dictionary value identify similarity first create larger corpus using dictionary item create lda model identify similarity knowledge lda modeling limited spot error appreciate flagging finally iterate set value bag word compare first personality type compare book description value finding hellinger distance finally print instance lda model come back high correlation percentage result look something like,,2020-09-30 08:49:45,python library tool analyzes two body text similarity order provide recommendation,python python-3.x nlp gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
28192,28192,62802812,2020-07-08 20:05:57,,trying remove stopwords nlp pre processing step use function would also like add stopwords,,2020-07-08 20:19:22,remove custom stopwords,python nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
28193,28193,62803770,2020-07-08 21:17:28,,trying find similar document new document doc vec model wa trained first introducing new document inferred vector new document know doc vec well new document ha lot word row old model never encountered handled,2020-07-11 00:44:53,2020-07-11 00:44:53,doe doc vec ass new word,new-operator gensim word2vec word doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
28201,28201,62735947,2020-07-05 01:19:16,,new world nlp working word embedding program gensim work file small size try using larger file several gigabyte get error message saying open file stalling two hour wa looking seems like need find way stream file order read program confused find example word embedding streaming file also process going slow terabyte data thanks help,2020-07-05 05:09:48,2020-07-05 05:09:48,word embedding large file,nlp inputstreamreader,,,CC BY-SA 4.0,False,False,True,False,False
28211,28211,62737231,2020-07-05 05:37:05,,approximately gigabyte text data separated want read text list put gensim library word vec analysis far know list form input allowed gensim word vec process tried read text data line line append empty list keep caused memory error since according found searching read line line doe really damage memory usage suspect could process appending result list know solve problem computer ram size gb use ubuntu lts python pycharm fundamentally impossible load gb text file list computer mean better add ram size computer also wonder would better read csv text found panda good tool read huge file tried approach failed convert text column list memory issue code used thanks advice,,2020-07-05 05:37:05,read gigabyte text list gensim word vec analysis,python list gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
28221,28221,62752484,2020-07-06 08:54:12,,really confused see result coherence score using python gensim r texminer package trained model number topic using first one average score around second one model coming r use coherence score low would like use r experienced language find solution switch python wanted know idea solve problem gensim python provide better quality algorithm p tried training lda r different parameter make sure source problem situated inthere thank advance support help best evangelia,,2020-08-26 09:07:13,python gensim package give better coherence score compared texminer r,python r text-mining lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
28227,28227,62806942,2020-07-09 03:29:56,,code executing error occurs rd line error stack known issue someone provide solution workaround,,2020-07-09 17:40:24,setting gensim wordvectors init sim property true error valueerror output array read,nlp gensim word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
28241,28241,62722755,2020-07-03 21:13:01,,new topic recognition want try question dataframe using latent dirichelet allocation following article article asks create implement lda whenever try create seems dataset article taken bbc website get empty list indeed get create corpus train lda extract topic given question like one instance,,2020-07-03 21:13:01,create corpus lds trained,python-3.x gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
28260,28260,62810179,2020-07-09 08:04:45,,use gensim work lda model model work set parameter small value topic increase value larger like topic number model break returning proper result empty topic important word importance value someone similar problem happening information dataset ha around small text document minimum length word word know option consider beside lda want understand model even delivering result,,2020-07-09 08:04:45,gensim lda model break,nlp gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
28265,28265,62742964,2020-07-05 15:49:26,,currently attempting record graph coherence score various topic number value order determine number topic would best corpus several trial using u mass data proved inconclusive since score plateau around specific topic number aware cv range using u mass however value range selecting accurate topic number possible due issue attempted use c v instead u mass receive following error code computing coherence value anyone could provide assistance resolving issue either c v u mass would greatly appreciated thank,,2020-07-05 15:49:26,lda coherence value using u mass v c v,machine-learning gensim lda dirichlet,,,CC BY-SA 4.0,False,False,True,False,False
28266,28266,62743531,2020-07-05 16:39:07,,trained fasttext model gensim corpus short sentence word know test set includes word train corpus e word corpus like oxytocin lexitocin ematrophin betaxitocin given new word test set fasttext know pretty well generate vector high cosine similarity similar word train set using character level n gram incorporate fasttext model inside lstm kera network without losing fasttext model list vector vocab handle oov even fasttext well idea,,2020-07-06 06:45:22,using gensim fasttext model lstm nn kera,keras nlp gensim word-embedding fasttext,,,CC BY-SA 4.0,False,False,True,False,False
28287,28287,62822914,2020-07-09 20:10:06,,completed topic modeling lda using gensim printed top word topic using code code wa ran excel sheet read specifically column named text research text curious could add column excel sheet put topic number corresponding cell apart something like,,2020-07-09 20:10:06,topic number lda gensim,gensim modeling lda,,,CC BY-SA 4.0,False,False,True,False,False
28310,28310,62797525,2020-07-08 14:48:50,,set small document talk particular kind issue training data want identify doc k document talking issue purpose using doc vec implementation facing strange issue result highly un reliable score even slightest match score changing great margin every time running function someone please help wrong,2020-07-09 00:53:04,2020-07-09 00:53:04,doc vec giving different un reliable result,machine-learning nlp gensim similarity doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
28345,28345,62827849,2020-07-10 05:29:48,,know method work entering previously added string reverse search numpy array word,2020-07-10 07:25:10,2020-07-10 08:02:11,find similar array gensim,python-3.x nlp gensim,,,CC BY-SA 4.0,False,False,True,False,False
28350,28350,62801052,2020-07-08 18:10:33,,training model using code list instance set later check model result good might gone wrong,2020-07-10 19:16:59,2020-08-28 06:34:28,doc vec code many loop training giving good result might wrong,gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
28353,28353,62686729,2020-07-01 23:26:02,,problem poster unfortunately accepted answer work new solution problem,,2020-07-01 23:26:02,index error updating gensim lda model,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
28384,28384,62861346,2020-07-12 12:54:23,,gensim downloader api throw error errno file directory user vtim gensim data information json wrong,2020-07-12 20:20:42,2020-08-11 16:13:40,download dataset gensim download api,python download dataset gensim glove,,,CC BY-SA 4.0,False,False,True,False,False
28398,28398,62831166,2020-07-10 09:22:47,,working hdpmodel gensim ha parameter please anybody explain exactly value k mean know number topic wanted case k understand second level truncation level phrase give example could awesome thanks,,2020-07-10 09:22:47,meaning k hdpmodel gensim,python gensim,,,CC BY-SA 4.0,False,False,True,False,False
28439,28439,62903275,2020-07-14 20:11:24,,word vec model trained tweet also list word need get embeddings word compute first two principal component plot word dimensional space trying follow tutorial one http machinelearningmastery com develop word embeddings python gensim however tutorial create model based random sentence use calculate pca word model want want calculate plot specific word use model already ha thousand word compute first two principal component set list word around like link model word sentence wrote x model model wv vocab pca fit transform x copy code would pca huge model want want extract embeddings word model compute pca word hopefully make sense thanks advance please let know need clarify anything,,2020-07-14 20:33:02,pca word vec embeddings using pre existing model,python nlp jupyter-notebook pca word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
28454,28454,62939869,2020-07-16 17:02:29,,word embeddings training gensim meaningless similarity known relationship king man woman queen others simply hold even close might well random using training data equivalent parameter get meaningful result facebook fasttext comparison tried gensim fasttext word vec class returning meaningless embeddings narrow thing setting gb training data text file space separated token newline separated sentence final vocab size training word vector dimension disabled subwords disabled n gram negative sampling skip gram min count training code would rather avoid using facebook fasttext would require changing source code achieve vocab size could going wrong debug able import facebook fasttext vector gensim work fine,2020-07-16 18:19:04,2020-07-16 18:19:04,gensim training meaningless word embeddings,nlp gensim embedding word-embedding fasttext,,,CC BY-SA 4.0,False,False,True,False,False
28463,28463,62970416,2020-07-18 15:35:12,,working project group job posted various job portal cluster based description job using k mean found work vector using word vec guess serve purpose need vector whole job description know average word vector sentence get sentence vector worried accuracy loose ordering word way get vector,,2020-07-20 00:57:27,get sentence vector k mean clustering task,machine-learning nlp vectorization gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
28482,28482,62941476,2020-07-16 18:39:05,,trying use doc vec go classic exercise training wikipedia article using article title tag code result something missing would give matching result similar following tutorial used wiki english dataset came gensim,,2020-07-16 19:04:06,doc vec providing adequate result similar,python gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
28506,28506,62910645,2020-07-15 08:27:31,,need assistance regarding principal component displayed pyldavis show pc pc default however interested exploring component well referred documentation specified option change plot label using pyldavis gensim,2020-07-17 15:14:38,2020-08-10 19:40:30,pyldavis argument specifying principal component,python-3.x gensim lda topic-modeling pyldavis,,,CC BY-SA 4.0,False,False,True,False,False
28522,28522,63025899,2020-07-22 02:30:55,,currently using gensim lda topic modeling tuning hyper parameter found model always give negative log perplexity normal model behave like even possible smaller perplexity better bigger one better,,2020-08-29 00:16:03,gensim lda give negative log perplexity value normal interpret,gensim lda perplexity,,,CC BY-SA 4.0,False,False,True,False,False
28525,28525,62993607,2020-07-20 10:39:17,,trying vectorize text classify using gensim tensorflow kera train shape follows train following shape logging gensim understand part dataset losing text anyone explain reason shape get smaller trying learn topic would grateful anyone explain,,2020-07-20 18:10:25,gensim vector shape changing,python nlp gensim word2vec shapes,,,CC BY-SA 4.0,False,False,True,False,False
28567,28567,63062583,2020-07-23 20:24:38,,output unable understand embeddings embeddings changing change new data way correct solving problem statement optimize find best embeddings dataset anyone provide suggestion,2020-07-29 02:45:24,2020-07-29 02:45:24,building recommendation system using word vec,python nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
28594,28594,63079854,2020-07-24 18:55:28,,extracted mb english wikipedia plain text would use build word vec model gensim need split sentence first tried fails idea want use much ram,2020-07-24 19:08:11,2020-07-24 20:35:24,split text file sentence word vec gensim,python spacy gensim,,,CC BY-SA 4.0,False,True,True,False,False
28600,28600,63095512,2020-07-26 02:30:44,,trying ass doc vec model based code basically want know percentual inferred document found similar current code code work perfectly smaller datasets however since huge file million document code becomes slow would take month compute profiled code time consumed following line mistaken measure document every document think computation time might massively reduced change instead since thing want know similar document basically take doc e measure similar document e see could implement help idea welcome,,2020-07-26 18:44:23,assessing doc vec accuracy,gensim doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
28603,28603,63096897,2020-07-26 06:35:13,,need create bigram trigram barcharts using gensim tried using nltk ngrams need replicate using gensim example completed course passed distinction,,2020-07-26 06:35:13,create ngrams bar chart using gensim similar nltk ngram,python gensim,,,CC BY-SA 4.0,True,False,True,False,False
28623,28623,63065232,2020-07-24 00:53:22,,use virtualenv python use gensim script get error name gensim defined tried install genism using pip conda ended updating conda package suggested solution see genism reunnig pip list still error could please tell p take input html form flask function inside function call script ha genism program show form input button clicking submit buton get error message thanks advance,,2020-07-24 00:53:22,gensim defined even though show virtualenv package,python-3.x flask gensim,,,CC BY-SA 4.0,False,False,True,False,False
28626,28626,63082446,2020-07-24 22:55:27,,trying extract topic using gensim library lda model persona chat dataset pre processing part try find best number topic order get best keywords regarding topic ran code different number topic coherence score increase whenever number topic increased time perplexity score decrease well information understood use far know perplexity small coherence high see score number topic k k coherence score perplexity k coherence score perplexity k coherence score perplexity k coherence score perplexity k coherence score perplexity however whenever used number topic keywords weight repeated every topic white chalk princeton gymnast vanilla rain cow employed dirty white chalk princeton gymnast vanilla rain cow employed dirty white chalk princeton gymnast vanilla rain cow employed dirty made research found keywords repeated maybe number topic much decreased number topic want know way fix since perplexity coherence score show lda model would work better number topic find code well best regard,2020-07-27 00:24:48,2020-07-27 00:24:48,topic extraction using gensim,python nlp gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
28636,28636,63096909,2020-07-26 06:36:54,,trying implement word vec problem briefly explain problem statement dealing clinical data want predict top n disease given set symptom note word prefix diagnosis rest symptom corpus sentence paragraph contains symptom name diagnosis patient applying word vec corpus able generate top diagnosis given set input symptom want understand output generated know cosine similarity adding input vector unable validate output understand improve really want understand exactly going background lead output anyone help answer question highlight drawback advantage approach,2020-07-29 08:24:56,2020-07-29 08:24:56,interpret output gensim word vec similar method understand coming output value,python nlp gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
28648,28648,63021096,2020-07-21 18:42:48,,given list document word e g gensim used get bi gram follows wa wondering get score bi gram detected bigram model,,2020-07-21 18:48:26,get score filtered bi gram gensim,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
28651,28651,63100943,2020-07-26 13:42:36,,currently trying use dynamic topic modeling news crawled web unfortunately receive warning log info using serial lda version node using google find issue learned numpy error often produced nan null value regard dynamic topic modeling probably refers empty document dont empty document dataframe,2020-07-27 07:29:09,2020-07-27 07:29:09,ldaseqmodel runtimewarning invalid value double scalar,nlp gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
28652,28652,63101674,2020-07-26 14:45:05,,using word vec gensim currently set context size easily set number word left right center word consider sometimes better consider word left separately word right would give two embeddings per word done gensim python compatible tool,,2020-07-26 18:54:52,make word vec use left context right context separately,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
28691,28691,63087891,2020-07-25 11:40:54,,question conceptual type wa using pre trained word vector spacy model problem lot domain specific word get vector assignet overall result gerneral good wa wondering one proceed try fine tune existing vector would one approach use pre trained word vector spacy create edit want fine tune pre trained vector read could train already trained model data question use spacy load model download vector spacy train gensim model afterwards vector better way thank advance input,2020-08-05 09:30:50,2020-08-05 09:30:50,fine tune spacy word vector,spacy word-embedding,,,CC BY-SA 4.0,False,True,True,False,False
28699,28699,63107425,2020-07-27 01:14:07,,try use methode tmtoolkit topicmod evaluate metric coherence gensim calculate coherence score sklearn lda model doe work code output,,2020-07-27 01:14:07,calculate coherence score sklearn lda model,python scikit-learn gensim lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,True
28701,28701,63136275,2020-07-28 14:19:05,,trained lda model via gensim gensim format pickle file would like see training parameter used extract chunksize also need pass well possible clarification would like able recreate modeling process exactly given training corpus,2020-08-04 21:19:42,2020-08-04 21:19:42,way see training parameter trained gensim lda model,python parameters model gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
28794,28794,63147796,2020-07-29 06:44:37,,using lda topic modelling python gensim implementation lda allows u set alpha auto lda mallet wrapper provided gensim option setting alpha auto way learn alpha corpus lda mallet,,2020-07-29 11:31:32,lda gensim mallet setting alpha auto,python gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
28796,28796,63162298,2020-07-29 20:56:06,,dataset following format disease generating vector using word vec showing vector example practice vector generating array taking average vector issue averaging word vector fact combination disease average vector totally different disease relevant average vector get matched make concept averaging vector flawed counter understanding increase dimension vector even le possibility couple question better way averaging output word vec vector generate array generated vector treated feature classifier model trying build disease disease combination generate feature vector word vec shall use something like pca reduce dimension shall consider feature vector feature classifier,,2020-07-29 20:56:06,good substitute averaging vector generated word vec,vector pca gensim word2vec word-embedding,,,CC BY-SA 4.0,False,False,True,False,False
28819,28819,63200943,2020-08-01 01:34:23,,trying reproduce code http github com n obcoder skip gram model however getting error could please tell wrong,,2020-08-01 01:51:02,word vec scratch module named utils modified,python gensim word2vec torch,,,CC BY-SA 4.0,False,False,True,False,False
28834,28834,63218694,2020-08-02 16:54:45,,problematic code panda dataframe df build followed two column created tokenized tokenized consists list word get following error message running problematic code bizzare column tokenized single string tried converting column single list list list tuple nothing ha worked far thanks advance help,,2020-08-02 17:09:41,gensim corpus dictionary type error interprets tokenized column single string,python dictionary gensim,,,CC BY-SA 4.0,False,False,True,False,False
28842,28842,63299446,2020-08-07 09:58:07,,following code version gensim numpy saving model vocab model file generated generated use file doe necessary generate file,,2020-08-07 18:18:11,vocab model docvecs doctag syn npy generated saving doc vec model,python numpy gensim,,,CC BY-SA 4.0,False,False,True,False,False
28852,28852,63284211,2020-08-06 13:03:03,,predicting similarity document using pre trained spacy word embeddings lot domain specific word want fine tune vector rather small data set containing domain specific vocabulary idea wa train spacy model data since word vector spacy built sure way train spacy model data research found train vector using gensim would download pre trained model example google news dataset model afterwards could train data set way way proceed spacy model help greatly appreciated,,2020-10-13 11:28:08,fine tune spacys word vector,spacy word-embedding,,,CC BY-SA 4.0,False,True,True,False,False
28873,28873,63335897,2020-08-10 07:32:35,,thank stopping need help logging issue spyder page looked http markroxor github io gensim static notebook lda training tip html written link suggest following way choose iteration pass first enable logging described many gensim tutorial set ldamodel training model look line log look something like set see line time make sure final pass document converged want choose pass iteration high enough happen thing know logging find logging lda using gensim tutorial want know coverage log set proper pass iteration possible spyder one going enlighten thank advance,2020-08-10 07:54:12,2020-08-10 07:54:12,question logging function spyder using lda gensim,python-3.x spyder gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
28912,28912,63306635,2020-08-07 17:28:30,,trying run gensim dtm colab get permissionerror errno permission denied binary file location drive tried chmod path dtm binary stat iexec solve problem idea thanks,,2020-08-07 17:28:30,permission error trying run gensim dtm google colab,google-colaboratory gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
28940,28940,63275259,2020-08-06 00:33:16,,given query document would like compute similarity score using gensim doc vec document consists multiple field e g main title author publisher etc training better concatenate document field treat row unique document split field use different training example inference treat query like document meaning call model trained document query,2020-08-06 10:22:36,2020-08-06 10:22:36,query document similarity doc vec,machine-learning gensim word2vec information-retrieval doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
28946,28946,63345527,2020-08-10 17:55:23,,trying build docker application us python gensim library version installed via pip requirement txt file however docker seems trouble trying run pip install r requirement txt requirement txt reference dockerfile error tried thread docker unable install numpy scipy gensim suggested added line dockerfile still working,2020-08-10 23:55:45,2020-08-11 21:39:42,error building image requirement txt docker,python docker gensim,,,CC BY-SA 4.0,False,False,True,False,False
28955,28955,63324116,2020-08-09 08:24:40,,im using gensim version im running model word vec fasttext log function missing value example part log fasttext index missing printed way solve version bug,,2020-08-10 16:47:51,word vec logging missing value,python-3.x gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
28973,28973,63377398,2020-08-12 13:19:01,,trying create custom word vec loinc longnames contained list however tring match discharge summary alredy present list able find searched similar word code used train model list word,,2020-08-12 13:19:01,custom word vec vocabulary gensim,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
28979,28979,63332046,2020-08-09 22:43:31,,data x different source e people instagram want fine tune word vec model afterwards wish use model web api question since user analyzed vocabulary based data alone okay fine tune word vec model different user keep vocabulary separate analyze particular user filter word vec result based user vocabulary train word vec model user individually,,2020-08-09 22:43:31,gensim fine tuning word vec model,nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
28991,28991,63411408,2020-08-14 10:54:23,,quite new datascience apologize advance make mistake reasoning trying write application nlp form emotion analysis found main category emotion anger joy sadness fear surprise going use process real time voice stream actually stuck turned word vectorization calculate distance word relative emotion taking word evil example calculate distance evil every emotion check distance emotion word vector find word polarity excluding emotion distant still wip need think since language need italian bit hard time understanding train model understand sense vec gensim seem work well tandem kind operation frankly quite lost documentation like ask help also open change module way,,2020-08-14 10:54:23,emotion analysis python sense vec language,python nlp data-science sense2vec,,,CC BY-SA 4.0,False,False,True,False,False
29045,29045,63419318,2020-08-14 19:59:19,,following piece code piece code work one machine another model file going error message get following install gensim used,,2020-08-14 23:08:19,array reshape error loading word vec model,python amazon-ec2 gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
29053,29053,63385272,2020-08-12 22:01:03,,trying load pre trained word vec model pkl format taken line code use load however keep getting following error full traceback tried loading load word vec format luck idea might wrong,,2020-08-13 02:02:57,fix unpickling key error loading word vec gensim,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
29057,29057,63371536,2020-08-12 07:08:40,,two list one list containing document name another list also containing document name find document name one list semantically simalar list build custom embeddings,,2020-08-12 07:08:40,list semantic similarity,python list gensim word2vec taxonomy,,,CC BY-SA 4.0,False,False,True,False,False
29081,29081,63472132,2020-08-18 15:45:17,,created glove vector r previously using library easy way export use python script compare contract gensim created word vector know specific word vec c format im sure r ha capability producing,,2020-08-21 13:19:34,export r text vec vector use gensim python,python r gensim text2vec,,,CC BY-SA 4.0,False,False,True,False,False
29091,29091,63459657,2020-08-17 22:55:40,,multiple text file around file ha around article average word document single line text file memory limitation wanted use dynamic loading text file training perhaps iterator class proceed train text file save model load model rerun new data way iterator class automatically give sentence sentence article article text file text file input model training,,2020-08-17 23:15:24,load large dataset gensim word vec model,python iterator gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
29123,29123,63524493,2020-08-21 14:11:48,,using gensim package trained word vec model corpus working follows using numpy initialized random array dimension would like find word word vec similar random vector initialized word word vec run output list similar word according distance would like get similar output initialized array however run get following error overcome error find similar word array checked page however unclear could solve problem suggestion,2020-08-21 16:04:19,2020-08-21 16:04:19,find similar word randomy initialized array,python numpy typeerror gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
29129,29129,63537713,2020-08-22 15:10:38,,using doc vec gensim train document embedding training even give infer vector function random word still give back vector throw exception anything word vec reacts differently throw exception happens example still return vector question vector computed non word training corpus random random better return non word corpus classification model us vector giving random value instead confuse model anyway make give vector non training corpus overall good vector give model sentence classification better method use instead doc vec corpus basically non english word sentence,2020-08-22 23:53:16,2020-08-22 23:53:16,happens give word infer vector gensim wa training corpus,python deep-learning gensim doc2vec,2020-08-23 00:26:30,,CC BY-SA 4.0,False,False,True,False,False
29149,29149,63479304,2020-08-19 02:49:30,,trained lda model according gensim documentation attempting get main topic document take forever speed model stored bag word vector stored model wa trained document,2020-08-19 22:20:56,2020-08-19 22:20:56,optimize extracting main topic lda model,python optimization gensim lda,,,CC BY-SA 4.0,False,False,True,False,False
29151,29151,63481736,2020-08-19 07:10:22,,created word vec model gensim looking way visualize already created plot confusing assuming one performs dimensionality reduction dimension possibility visualize data point interactively within jupyter notebook interactive mean might able navigate plot closer look different point thanks lot,,2020-08-19 08:43:56,interactive visualization word vec model gensim,python data-visualization word2vec,,,CC BY-SA 4.0,False,False,True,False,False
29171,29171,63564117,2020-08-24 15:31:32,,wa thinking underlying dictionary supervised classification unsupervised word embedding want analyze classification model word vector built supervised problem using gensim got following error know gensim ha implemented supervised learning part fastext focusing word embedding want load dictionary analyze pointer,,2020-08-25 15:57:13,doe gensim reject load supervised model dict built fasttext facebook library,gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
29177,29177,63581374,2020-08-25 14:43:51,,wa trying use project http github com ukplab sentence transformer embedding non english sentence language human speaking language machine language x problem find simple example show embed sentence using custom dataset without label similarity value sentence basically array sentence list without label sentence similarity value want embed vector way preserve semantic sentence best way possible far used word vec doc vec using gensim library wanted try method see better also suggestion method use appreciated,2020-08-25 17:02:57,2020-08-25 17:02:57,use sentence transformer embed non english sentence without label,nlp word-embedding doc2vec bert-language-model sentence-similarity,,,CC BY-SA 4.0,False,False,True,False,False
29178,29178,63547850,2020-08-23 14:03:20,,topic modelling python gensim package want seed prior probability specific word using eta parameter sure probability word w number occurrence w topic total number token topic tried manually check inspecting lda get topic lda get term topic shape numtopics numwords like dictionary intending pas eta however call first term give different result thought w w give value index explain different understand would know calculate value pas eta keywords working example would nice thanks,,2020-08-23 14:03:20,topic modelling seeding specific word python,gensim lda seeding eta,,,CC BY-SA 4.0,False,False,True,False,False
29180,29180,63528600,2020-08-21 18:54:47,,trying figure identify unigrams bigram text r keep final output based threshold done python gensim phraser model figured r example thank,,2020-08-22 08:40:25,output text unigrams bigram r,r nlp n-gram,,,CC BY-SA 4.0,False,False,True,False,False
29188,29188,63499110,2020-08-20 05:56:51,,hoping help creating web app python flask one thing web app provide smart document search enter text fetch result document similar portion text entered used flask front end serve html manage db interaction required display result pas query gensim similarity model query question best way host explored loading model part loading flask slows thing quite lot c gb memory work query model quite easily within program scope concern would scalable possibly best practice may better host model separately make api call flask web app thought view would much appreciated thanks pete,,2020-08-20 06:36:30,best practice deploying machine learning web app flask,python flask gensim,2020-08-20 21:29:48,,CC BY-SA 4.0,False,False,True,False,False
29196,29196,63509864,2020-08-20 16:58:37,,using word vec module gensim library train word embedding dataset k sentence k unique word english using code monitor calculate loss problem epoch loss vector monitored word dont change problem normal tokenized corpus list list something like tokenized corpus word word googled seems like old version gensim problem calculating loss function almost year ago seems like fixed right tried code provided answer question well still loss loss doe decrease training word vec gensim edit adding compute loss true loss show keep going higher higher top similar word similarity change,2020-08-20 18:23:32,2020-08-20 18:23:32,gensim word vec ha loss epoch,nlp pytorch gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
29198,29198,63549977,2020-08-23 17:24:27,,research requires direct manipulation embedding one hot vector trying use gensim load pretrained word vec model problem seem direct api working hot vector looking work arounds wanted know anyone know way specifically vocab index defined quite ambiguously could index corresponding hot vector context found seems question related tried accessing input embeddings assuming one hot representation via model syn link answer got non sparse matrix also appears refer word index doctags search doctag index another question giving context index although quite answering question official documentation class gensim model keyedvectors vocab kwargs base object single vocabulary item used internally collecting per word frequency sampling info constructing binary tree incl word leaf inner node,,2020-08-23 18:14:19,gensim vocab index index corresponding hot vector,gensim word2vec one-hot-encoding,,,CC BY-SA 4.0,False,False,True,False,False
29203,29203,63551484,2020-08-23 20:03:59,,testing feeding gensim word vec different sentence overall vocabulary see sentence carry better information others method train word vec look like hoping time w v run start fresh model train scratch however testing kind sentence test code look like however noticed remove one test set test combination set three overall quality clustering decrease go back add call overall cluster quality also go remains consistent matter many datasets tested give constructor actually building fresh model time new weight doc source code give indication quite sure evaluation method everything wa fixed wa added loss run actually independent call equivalent retraining previous model new data ask nowhere outside scope variable time variable name used whole program odd edit detail important using word vec build node embeddings graph way node vec doe different walk strategy embeddings fed logistic regression model calculates area roc sample output model adding call method averaged trial output difference del model encoding method random walk policy walk e greedy walk see case variance low value standard error difference two run almost whole standard deviation seems odd call word vec wa truly independent manually freeing data structure would large effect,2020-08-24 13:48:04,2020-08-24 13:48:04,doe gensim word vec constructor make completely independent model,python gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
29229,29229,63633739,2020-08-28 12:24:03,,trouble updating model gensim use following command create model save model used far remember first step training model create vocab anyway stop training iter want load continue training load model use train method continue update trying give error must specify either total example total word proper job parameter updationand progress calculation usual value total example model corpus count anyway could define parameter used creating model size window min count worker ok believe size already defined worker thanks advance,,2020-08-28 18:34:26,update trained word vec model gensim parameter,parameters gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
29238,29238,63567713,2020-08-24 19:40:43,,trained word vec model called using gensim package size created new numpy array also size added word vec follows seems go fine even call get array output expected however want look similar word model run following code get following error error seems indicate indexing correct since indexing indirectly key rather actual numeric index see need change know go wrong overcome error,,2020-08-24 21:10:23,indexerror index bound word vec,python-3.x numpy gensim word2vec index-error,,,CC BY-SA 4.0,False,False,True,False,False
29266,29266,63590239,2020-08-26 03:54:04,,training data json file trying use word embedding word vec however idea proceed mostly everything looked deal direct sentence given json file right done read json file using python please guide could done next trying use gensim,2020-08-26 09:53:23,2020-08-26 09:53:23,word vec json file,python json gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
29277,29277,63513647,2020-08-20 21:55:48,,trying find alternative lda need calculate coherence score subject extracted new model calculate coherence score without using lda latent dirichlet allocation model help plz example using gensim model coherencemodel method,,2020-08-20 21:55:48,calculate coherence score subject like gensim model coherencemodel method doe without using lda model,nlp lda topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
29278,29278,63514464,2020-08-20 23:28:52,,list sentence topic two like see similarity sentence trying relate multiple sentence visualise characteristic using graph directed graph built similarity matrix applying row ordering sentence shown created new column time show order sentence first row trump say time second row prime minister suggests time something like would like find relationship order clear overview topic multiple path sentence would show multiple information associated determine similarity two sentence tried extract noun verb follows keywords whatever sentence keyword noun verb appears sentence x sentence represents difference two sentence think better approach however could using word vec gensim wmd similarity ha calculated sentence would like build graph show content sentence example since two topic trump chinese minister need look sub topic trump ha sub topic presidential election example node graph represent sentence word node represent difference sentence showing new info sentence example word sentence time adjacent sentence time would like find way similar result shown picture tried using mainly noun verb extraction probably right way proceed tried ha consider sentence time compare sentence assigning similarity score noun verb extraction also word vec repeat sentence problem extract difference create graph make sense part graph would consider use networkx digraph show direction relationship provided different example make clearer worked previous example would fine well apology inconvenience since first question wa clear provide also better probably easier example,2020-10-10 18:25:31,2020-10-10 20:09:20,graph connect sentence,python nlp nltk networkx word2vec,,,CC BY-SA 4.0,True,False,True,False,False
29282,29282,63637245,2020-08-28 15:59:06,,new deep learning trying play pretrained word embedding model paper downloaded following file sa fasttext model sa fasttext model trainables syn neg npy sa fasttext model trainables vector ngrams lockf npy sa fasttext model wv vector npy sa fasttext model wv vector ngrams npy sa fasttext model wv vector vocab npy case detail needed sa sanskrit embedding dimension fasttext fasttext dont prior experience gensim load model gensim tensorflow tried filenotfounderror errno file directory content sa fasttext sa fasttext model wv vector ngrams npy bin,2020-08-28 18:06:55,2020-08-29 03:33:16,load pre trained fasttext model gensim npy extension,gensim pre-trained-model fasttext,,,CC BY-SA 4.0,False,False,True,False,False
29291,29291,63625873,2020-08-28 00:32:53,,well issue document passed document training gensim model successfully trained saved model model format current format new file also generated doc vec model doc vec model trainables syn neg npy doc vec model wv vector npy due limitation hardware trained saved model google colab google driver respectively downloaded generated model extra file local machine ran code giving file found error whereas added particular file py file current working directory well used code code loading model help would greatly appreciated thanks cheer,2020-08-28 10:16:56,2020-08-28 10:16:56,gensim model class filenotfounderror,python python-2.7 gensim word2vec doc2vec,,,CC BY-SA 4.0,False,False,True,False,False
29324,29324,63740186,2020-09-04 11:20:58,,trained fasttext model french language using gensim library suddenly trained model getting loaded memory using code throw following error model trained large dataset way recover load model,,2020-09-04 11:25:43,unable load gensim fasttext model utf unicode error,python encoding pickle gensim fasttext,,,CC BY-SA 4.0,False,False,True,False,False
29405,29405,63749621,2020-09-05 01:17:56,,trying topic modelling using gensim python following dataset doc tried lemmatise follows run lda however getting error know fix thanks error whole error message,2020-09-05 21:22:51,2020-09-05 21:47:48,topic modelling gensim,python gensim topic-modeling,,,CC BY-SA 4.0,False,False,True,False,False
29414,29414,63752033,2020-09-05 08:40:41,,want train previous trained word vec model increased way update word weight word ha seen previous training process create update weight new word ha seen previous training process example seems previous word embedding updated even though previous word context ha benn changed new corpus could someone tell make previous embedding weight updated,2020-09-07 06:26:29,2020-09-07 06:26:29,gensim word vec model updating previous word embedding weight increased training,python nlp gensim word2vec,,,CC BY-SA 4.0,False,False,True,False,False
