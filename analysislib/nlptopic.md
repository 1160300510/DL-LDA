## stanfordnlp

|                  $Topic$                   |                          $keywords$                          | $category$ |
| :----------------------------------------: | :----------------------------------------------------------: | :--------: |
|       $java\quad client \quad error$       | $$java,edu,error,file,model,corenlp,jar,class,stanfordcorenlp,pipeline,code,exception,http,tagger,run$$ |     1      |
|          $dependency \quad parse$          | $parser,dependency,tree,sentence,parse,parsing,using,get,np,output,phrase,node,like,nn,python$ |     3      |
|                 $tokenize$                 | $sentence,word,using,get,corenlp,way,one,would,like,text,document,code,java,string,method$ |     3      |
| $part \quad of \quad speech \quad tagging$ | $word,po,text,tag,tagger,sentence,token,using,tagging,like,noun,part,example,name,want$ |     3      |
|     $python \quad client \quad error$      | $python,corenlp,file,using,error,code,use,server,nltk,run,command,following,get,tried,work$ |     1      |
|   $name \quad entity \quad recognition$    | $entity,named,ner,text,extract,relation,corenlp,sentence,extraction,like,using,recognition,date,openie,example$ |     3      |
|            $model \quad train$             | $model,sentiment,ner,data,training,train,analysis,using,classifier,file,like,entity,feature,use,custom$ |     4      |

## spacy

|                $Topic$                |                          $keywords$                          | $category$ |
| :-----------------------------------: | :----------------------------------------------------------: | :--------: |
|          $code \quad error$           | $model,code,error,http,nlp,python,example,use,com,google,using,wa,io,github,following$ |     4      |
|          $word \quad vector$          | $word,vector,document,similarity,using,nlp,text,way,python,use,list,vec,embedding,get,one$ |     4      |
|         $install \quad error$         | $python,error,model,en,using,core,tried,install,nlp,web,get,code,version,load,package$ |     1      |
|        $file \quad operation$         | $file,python,program,user,package,lib,rasa,py,site,line,microsoft,local,nlu,appdata,server$ |     1      |
|          $model\quad train$           | $model,training,data,train,ner,text,custom,dataset,format,file,label,using,code,classification,like$ |     4      |
|                 $nlp$                 | $sentence,nlp,python,word,noun,text,using,dependency,like,want,code,get,object,verb,po$ |     3      |
|              $tokenize$               | $token,sentence,pattern,python,like,matcher,list,match,column,want,code,one,using,text,rule$ |     3      |
| $name \quad entity \quad recognition$ | $entity,ner,nlp,python,text,named,name,using,recognition,extract,sentence,like,new,example,use$ |     3      |

## gensim

|       $Topic$       |                          $keywords$                          | $category$ |
| :-----------------: | :----------------------------------------------------------: | :--------: |
|      $doc2vec$      | $vec,doc,document,model,word,training,doc2vec,using,parameter,vector,result,train,data,sentence,use$ |     4      |
|  $lda \quad topic$  | $topic,lda,model,modeling,using,score,document,coherence,number,python,get,probability,modeling,want,text$ |     4      |
|      $corpus$       | $corpus,python,dictionary,model,document,using,matrix,text,use,nlp,term,tf,idf,similarity,like$ |     2      |
|    $similarity$     | $similarity,sentence,list,cosine,nlp,python,would,time,word,two,find,like,using,data,text$ |     5      |
| $input \quad data$  | $python,text,code,data,like,list,input,error,get,using,dataframe,column,dictionary,following,array$ |     2      |
| $import\quad error$ | $python,error,file,code,model,import,package,following,user,trying,run,py,line,using,tried$ |     1      |
|     $word2vec$      | $word,model,vec,vector,embedding,using,trained,word2vec,python,use,fasttext,want,sentence,train,get$ |     4      |

## nltk

|                 $Topic$                 |                          $keywords$                          | $category$ |
| :-------------------------------------: | :----------------------------------------------------------: | :--------: |
| $part\quad of\quad speech\quad tagging$ | $tag,po,tagger,part,tagging,speech,tagged,sentence,corpus,using,pos,nlp,word,code,use$ |     3      |
|                 $topic$                 | $document,topic,gensim,tf,idf,similarity,matrix,vector,cluster,model,term,using,learn,score,scikit$ |     5      |
|  $name \quad entity \quad recognition$  | $spacy,name,nlp,entity,extract,ner,using,named,text,person,want,recognition,like,extraction,location$ |     3      |
|                $ error$                 | $error,code,import,package,following,run,using,py,get,trying,getting,tried,self,download,data$ |     1      |
|       $sentiment \quad analysis$        | $sentiment,data,analysis,model,classifier,feature,classification,using,learning,training,machine,train,review,text,code$ |     3      |
|               $tokenize$                | $word,list,text,sentence,like,code,output,string,want,using,get,would,column,tokenize,function$ |     3      |
|           $stop \quad words$            | $word,stop,stopwords,lemmatization,stemming,text,nlp,remove,like,article,date,stem,english,chatbot,would$ |     3      |
|                $n-gram$                 | $frequency,bigram,word,gram,count,corpus,probability,trigram,find,using,get,distribution,vocabulary,plot,want$ |     4      |
|                 $parse$                 | $tree,sentence,grammar,nn,parse,phrase,parser,nlp,chunk,parsing,using,stanford,np,rule,nnp$ |     3      |
|                $wordnet$                | $wordnet,word,synset,noun,get,verb,synonym,find,using,similarity,adjective,distance,example,company,way$ |     4      |
|               $language$                | $nlp,language,stanford,http,use,english,using,java,natural,model,library,processing,algorithm,org,html$ |     1      |
|            $read \quad data$            | $file,corpus,text,csv,line,txt,code,read,save,using,program,data,want,use,load$ |     2      |

## sklearn

|      $Topic$       |                          $keywords$                          | $category$ |
| :----------------: | :----------------------------------------------------------: | :--------: |
| $using \quad data$ | $code,class,data,text,using,model,pipeline,analysis,feature,classifier,sentiment,error,tweet,classification,dataset$ |     2      |
|      $tf-idf$      | $idf,tf,scikit,matrix,learn,word,tfidfvectorizer,document,tfidf,count,nlp,value,using,sklearn,term$ |     4      |
|      $error$       | $error,file,nltk,spacy,code,text,use,nlp,sentence,using,package,get,function,model,txt$ |     1      |
|  $classification$  | $model,data,text,classification,dataset,label,using,trained,training,predict,set,test,scikit,learn,sentiment$ |     4      |
|   $word vector$    | $word,text,vector,learn,scikit,using,classification,one,feature,would,nlp,similarity,like,document,input$ |     4      |
| $lda \quad topic$  | $topic,lda,learn,scikit,model,result,id,gensim,using,jupyter,doc,sklearn,corpus,modeling,nmf$ |     4      |

## 统计

|               | $preliminary\quad preparation$ | $data \quad processing$ | $natural\quad  language\quad processing$ | $model \quad training$ | $model \quad result \&  saving$ |
| :-----------: | :----------------------------: | :---------------------: | :--------------------------------------: | :--------------------: | :-----------------------------: |
|    $nltk$     |               2                |            1            |                    6                     |           2            |                1                |
|   $sklearn$   |               1                |            1            |                    0                     |           4            |                0                |
|    $spacy$    |               2                |            0            |                    3                     |           3            |                0                |
|   $gensim$    |               1                |            2            |                    0                     |           3            |                1                |
| $stanfordnlp$ |               2                |            0            |                    4                     |           1            |                0                |

