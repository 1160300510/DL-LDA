,Id,CreationDate,DeletionDate,Body,LastEditDate,LastActivityDate,Title,Tags,ClosedDate,CommunityOwnedDate,ContentLicense,opencv,matlab,emgucv,scikit-image,ffmpeg
23,8702946,2012-01-02 16:09:48,,"<p>i have 2 images. main image of a face, and a mouth image(a rectangle). i attach the mouth image to the main image replacing the main image's mouth. i'd like to make the mouth look like it belongs to the main image (colors around the mouth are too light/dark). 
i was wandering how to do so ? using mask functions ? or altering each pixel ? </p>

<p>main image and mouth image are both opencv images, but if bitmap class has a useful function for my problem i can change that type. </p>

<p>thanks in advanced. </p>
",,2012-01-03 08:56:22,"merge 2 opencv images, then darken / lighten the main image",<c#><image><image-processing><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
76,8740869,2012-01-05 10:22:34,,"<p>I am building an object tracking program that should track the unknown object. The user must select a region in the live video stream that should be tracked. My project is similar to this video.</p>

<p><a href=""http://www.youtube.com/watch?v=G5GLIKIkd6E"" rel=""nofollow"">http://www.youtube.com/watch?v=G5GLIKIkd6E</a></p>

<p>I have tried a method but it is not robust enough and the tracker moves a lot. So I am starting from scratch again. </p>

<p>Anyone knows a method on how I can come up with the one in the video? I am a newbie in emgucv and as of now I really have no idea where to start again. </p>
",,2018-05-08 12:20:22,Object Tracking in EmguCV,<c#><opencv><emgucv><template-matching>,,,CC BY-SA 3.0,True,False,True,False,False
84,8767333,2012-01-07 04:23:51,,"<p>In OpenCV I use <code>std::vector&lt;std::vector&lt;cv::Point&gt;&gt;::const_iterator</code> like the code here:</p>

<pre><code>std::vector&lt;std::vector&lt;cv::Point&gt;&gt; contours;
cv::findContours(contour,contours,CV_RETR_TREE,CV_CHAIN_APPROX_SIMPLE);    
std::vector&lt;std::vector&lt;cv::Point&gt;&gt;::const_iterator itContours = contours.begin();

while(itContours != contours.end())
{
    if(Condition1)
        itContours = contours.erase(itContours);
    else if(Condition2)
    itContours = contours.erase(itContours);
    else if(Condition3)
        itContours = contours.erase(itContours);
    else
        ++itContours;
}
</code></pre>

<p>But now I start using EmguCV but I can't find how to do like the code above. How can I do it?</p>
",2012-01-09 09:58:35,2019-11-15 02:04:22,How to use iterator in C# with EmguCV?,<c#><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
141,8800212,2012-01-10 08:07:11,,"<p>I am creating a windows application using C#, where in a button on the GUI when clicked, should display the on-screen keyboard.</p>

<p>Would appreciate if any help is granted. thanks.</p>

<p>Also, since I am mostly using Emgu Cv library for the rest of my app, Can we simply use it for calling the On-screen keyboard?</p>
",,2017-10-05 14:58:50,Calling the on-screen keyboard using a button in C#,<c#><.net><emgucv><on-screen-keyboard>,,,CC BY-SA 3.0,False,False,True,False,False
252,8896387,2012-01-17 14:33:13,,"<p>I am developing an application called virtual wardrobe and for that application I need to know the size of the user .My question is how to obtain size of the user from edge detected image .I m using cvcanny for edge detection .
I don't have much knowledge about emgu.
Any suggestions .
Thank you in advance </p>
",,2013-03-15 03:52:39,cvcanny and emgu,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
289,9907490,2012-03-28 12:27:58,,"<p>I have an <code>UInt16</code> array representing an image and width/height for it, and I would like to turn this into an EMGU image in the least painful way possible.</p>

<p>EMGU has an <code>Image</code> constructor that looks promising, which is described <a href=""http://www.emgu.com/wiki/files/2.3.0/document/html/84dd94e7-f03f-ceb8-f629-8462326d13a6.htm"" rel=""nofollow"">here</a>.</p>

<p>But I can't understand how to format my data, it says that the first dimension is height, but why would I need a whole dimension to describe ONE number? Clearly there is something I don't understand. Something like <code>Image(ushort[], height, width)</code> makes more sense to me. </p>
",2012-04-04 07:30:00,2012-04-04 07:30:00,UInt16[] to EMGU image in C#,<c#><.net><emgucv><image-generation>,,,CC BY-SA 3.0,False,False,True,False,False
305,8891787,2012-01-17 08:46:40,,"<p>I used EmguCV in C# for a face recognition project, but I found Emgu's support vector machine (SVM) predicts wrong classes when I use poly and RBF (redial basis function) kernels.</p>

<p>I compared Emgu's SVM answers with Matlab's svmclassify and found Matlab classifies all test cases right but Emgu predicts wrong.
may be there is something wrong with my code, but I don't this think so.</p>

<p>I reported the bug I found ----> <a href=""http://www.emgu.com/bugs/show_bug.cgi?id=53"" rel=""nofollow"">here</a> &lt;----, but I got no answers.</p>

<p>can anyone help me to find out what is wrong with Emgu's SVM or to find a library for a good multi-class support vector machine that uses different kernels like RBF (redial basis function)</p>
",,2012-01-18 08:33:57,"Emgu SVM classifier, predicts incorrect with poly and RBF kernels",<machine-learning><emgucv><face-recognition><svm>,,,CC BY-SA 3.0,False,True,True,False,False
314,8910314,2012-01-18 12:46:59,,"<p>I need to write wrapper to my C++ code to use it inside c# application. Basicly I need to preocess Emgu image from C# in c++ side and return it back. I try to do it this way in un-managed c++ side:</p>

<pre><code>public ref class ImageProcessor
{
public:
    void process(Image&lt;Bgr, Byte&gt;^ InImage)
    {
            cv::Mat image(InImage-&gt;Width,
                          InImage-&gt;Height,
                          CV_8UC3,
                          InImage-&gt;Ptr.ToPointer());

            cv::imwrite(""mask.png"", mask); //this line throws exception 

    }
 };
</code></pre>

<p>When I call thiss function from c#, the exception is throw:
System.AccessViolationException was unhandled
  Message=Attempted to read or write protected memory. This is often an indication that other memory is corrupt.</p>

<p>Question is how to correctly pass Emgu::CV::Image^ from managed code to unmanaged c++?</p>
",2012-01-18 14:40:31,2012-01-18 14:40:31,using Emgu Image in unmanaged c++ code,<c#><opencv><c++-cli><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
350,8918080,2012-01-18 21:58:53,,"<p>Hi all I have a simple question that I have been struggling with....what is the difference, if any, between motion component (blob?) tracking and blob tracking? As defined by OpenCV.</p>

<ol>
<li><p>Does one cover the other? or are they entirely different things?</p></li>
<li><p>Can they be used in conjunction to improve tracking accuracy?</p></li>
<li><p>Is the former designed for motion while the latter for (relatively) static objects? </p></li>
</ol>

<p>Thanks for helping out a newbie. </p>

<p>p.s. I am using Emgu (on .NET) and my terminology might reflect that.</p>
",,2012-01-24 07:42:47,Motion Tracking vs Blob Tracking,<opencv><motion-detection><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
358,9915001,2012-03-28 20:16:05,,"<p>I am trying to make a movie with openCV.  I can put all the images into the avi and it works great, except that the image is slanted at a big angle.  It looks like it has been smeared across the image.</p>

<p>The frames are perfectly square, so it cannot be a matter of getting the height and width confused.  The images are 24 bit.  The other thing that is weird is that it does not seem to be consistent when it happens.  sometimes it looks great, sometimes it is slanted.</p>

<p>Here is an image from the movie:
<a href=""http://dl.dropbox.com/u/63600049/MIP.avi"" rel=""nofollow"">http://dl.dropbox.com/u/63600049/MIP.avi</a></p>

<p>Here is the code:</p>

<p>PINVOKE Method</p>

<pre><code>                IntPtr _ptr = CvInvoke.cvCreateVideoWriter(AVIFilename, CvInvoke.CV_FOURCC('M', 'J', 'P', 'G'), 15, size, 1);

                int count = 0;
                for (int n = 1; n &lt; Frames.Length; n++)
                {
                    if (Frames[n].Trim().Length &gt; 0)
                    {
                        try
                        {
                            FileInfo file = new FileInfo(Frames[n]);
                            IntPtr ptr = CvInvoke.cvLoadImage(file.FullName, Emgu.CV.CvEnum.LOAD_IMAGE_TYPE.CV_LOAD_IMAGE_ANYCOLOR | Emgu.CV.CvEnum.LOAD_IMAGE_TYPE.CV_LOAD_IMAGE_ANYDEPTH);
                            if (ptr == IntPtr.Zero)
                                throw new NullReferenceException(String.Format(""Unable to load image from file \""{0}\""."", file.FullName));

                            CvInvoke.cvWriteFrame(_ptr, ptr);
                            //VW.WriteFrame&lt;Bgr, byte&gt;(frame);
                            count++;
                        }
                        catch (Exception ex)
                        {
                            System.Diagnostics.Debug.Print(ex.Message);
                        }
                    }
                }
                CvInvoke.cvReleaseVideoWriter(ref _ptr);
</code></pre>

<p>EMGU Version</p>

<pre><code> public static void CreateAVIVideoEMGU(string AVIFilename, string[] Frames)
    {
        Bitmap bitmap = new Bitmap(Frames[0]);

        VideoWriter VW = null;

        VW = new VideoWriter(AVIFilename, CvInvoke.CV_FOURCC('M', 'J', 'P', 'G'), 15, bitmap.Height, bitmap.Width, true);

        int count = 0;
        for (int n = 1; n &lt; Frames.Length; n++)
        {
            if (Frames[n].Trim().Length &gt; 0)
            {
                var frame = new Emgu.CV.Image&lt;Bgr, byte&gt;(ConvertBitmapTo24(new Bitmap ( Frames[n])));
                VW.WriteFrame&lt;Bgr, byte&gt;(frame);
                count++;
            }
        }

        VW.Dispose();
    }
</code></pre>

<p>The images are all 24 bit jpg of the same dimensions</p>
",2012-03-29 23:45:02,2012-03-30 12:21:50,Slanted video in openCV,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
426,13808204,2012-12-10 19:57:04,,"<p>I am using Emgu CV 2.4.2 and want to perform the following algorithm:</p>

<ol>
<li><strong>Get the blob</strong></li>
<li><strong>Set the ROI to speed up computation</strong></li>
<li><strong>Get the pixel position of local minima from the blob</strong></li>
<li><strong>Dividing the blob</strong></li>
<li><strong>Draw the bounding rectangle into divided blob</strong></li>
</ol>

<p>I have done step 1-2 and extracted the blob by using BGStatModel. This is the result I've got :</p>

<p><a href=""http://chardavid.files.wordpress.com/2012/12/newbox.jpg"" rel=""nofollow"">Blob Picture</a></p>

<p>I want to get the pixel position of the local minima in vertical projection. After getting it, I want to divide the blob and draw the rectangle like this :</p>

<p><a href=""http://chardavid.files.wordpress.com/2012/12/vertical-projection.jpg"" rel=""nofollow"">vertical projection Picture</a></p>

<p>I have tried to get get the pixel position of local minima by checking every pixel in the blob area but it makes my application runs very slow. Here's my code :</p>

<pre><code>Point minPix = new Point(0,0);

//copy the foreground frame
Image&lt;Gray, Byte&gt; foreFrame_copy = foreFrame.Copy();

//find the contour
Contour&lt;Point&gt; contours = foreFrame.FindContours(
    CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
    RETR_TYPE.CV_RETR_EXTERNAL);

//looping every contour
while (contours != null)
{
    double PPixel = contours.Area;
    if (PPixel &gt;= 1400)
    {
        //get the contour width
        WR = contours.BoundingRectangle.Width;
        //divide the contour using estimated pixel position
        Num = Convert.ToInt32(WR / 40);

    if (Num &gt; 1)
    {
        //save the estimated pixel position for ROI in arraylist
        ArrayList XList = new ArrayList();
        for (int i = 1; i &lt;= Num; i++)
        {
            int x = i * WR / Num;
            XList.Add(x);
        }

        //get the estimated pixel position 
        foreach (int pos in Xlist)
        {
            //roiWidth= 10px
            int roiWidth = (pos-5) + (pos+5);
            //roiHeight= 20px
            int roiHeight = 20;

            int pixValue = 0;
            //STEP 2: set the ROI to speed up computation
            foreFrame_copy.ROI = new Rectangle(contours.BoundingRectangle.X, contours.BoundingRectangle.Y, roiWidth, roiHeight);
            for (int i = (pos-5); i &lt; roiWidth; i++)
            {
                for (int j = (pos-5); j &lt; (pos+5); j++)
                {
                    pixValue = foreFrame_copy.Data[i, j, 0];
                    //find the white pixel
                    if (pixValue == 255) {
                        //find the position of minimum pixel
                        if (j &lt; j-1) {
                        minPix.X = i;
                        minPix.Y = j;
                        }
                    }

                }
            }
        }

    }
    //draw the red rectangle
    estimatedFrame.Draw(contours.BoundingRectangle, new Bgr(Color.Red), 1);
    contours = contours.HNext;
}
else
{
    contours = contours.HNext;
}
}
//show frame in framebox
blobBox.Image = foreFrame_copy;
estimatedBox.Image = estimatedFrame;
</code></pre>

<p><strong>Please help me how can I do step 2-5 in fastest way using Emgu CV. I would be highly appreciate if someone elaborate these three steps and some code also.</strong></p>

<p>Thanks in advance,
David</p>
",2012-12-12 15:35:33,2012-12-12 20:38:12,Dividing the blob in Emgu CV,<c#><image-processing><blob><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
476,11878766,2012-08-09 07:37:58,,"<p>Below transformation is what I want to do. </p>

<p>For each tile in source image, I know the coordinate of each corner, and I know the coordinate of each corresponding corner in the output image, so I can call <strong>cvWarpPerspective</strong> to warp each tile and then connect the quadrangles together to get the final output image. </p>

<p>Can <strong>cvRemap</strong> do this in one transformation? If yes, how do I construct the map (mapx, and mapy) from the coordinate that I have so to pass to the cvRemap function? I've searched the EmguCV documentation but could not find a cvRemap example.</p>

<p><img src=""https://i.stack.imgur.com/iEzCE.png"" alt=""The source image""></p>

<p><img src=""https://i.stack.imgur.com/KaIpf.png"" alt=""The output image""></p>
",,2012-08-09 08:39:13,cvRemap to replace cvWarpPerspective,<image-processing><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
501,10907853,2012-06-06 03:36:15,,"<p>I'm trying to capture a video using EMGU CV in visual studio 2010, but when it executes the line </p>

<pre><code>video.WriteFrame&lt;Bgr, byte&gt;(marked);
</code></pre>

<p>i get the follwing error:</p>

<p>System.AccessViolationException was unhandled</p>

<p>Attempted to read or write protected memory. This is often an indication that other memory is corrupt.</p>

<pre><code>private void button3_Click_1(object sender, EventArgs e)
    {
        Capture camera = new Capture();
        if (camera == null)
        {
            MessageBox.Show(""can't find a camera"", ""error"");
        }
        double fps = camera.GetCaptureProperty(CAP_PROP.CV_CAP_PROP_FPS);
        double cpHeight = camera.GetCaptureProperty(CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT);
        double cpWidth = camera.GetCaptureProperty(CAP_PROP.CV_CAP_PROP_FRAME_WIDTH);
        double fourcc = camera.GetCaptureProperty(CAP_PROP.CV_CAP_PROP_FOURCC);
        CvInvoke.cvNamedWindow(""camera"");
        Image&lt;Bgr, byte&gt; temp = camera.QueryFrame();
        //路径
        SaveFileDialog SaveFileDialog1 = new SaveFileDialog();
        SaveFileDialog1.FileName = DateTime.Now.ToString(""yyyyMMddhhmmss"");
        SaveFileDialog1.Filter = ""Image Files(*.avi)|*.avi|All files (*.*)|*.*"";
        if (SaveFileDialog1.ShowDialog() == DialogResult.OK)
        {
            MessageBox.Show(""START RECORD，ESC TO STOP"");
        }
        VideoWriter video = new VideoWriter(SaveFileDialog1.FileName, (int)fourcc, 15, 800, 600, true);
        while (temp != null)
        {
            CvInvoke.cvShowImage(""camera"", temp.Ptr);
            temp = camera.QueryFrame();
            int c = CvInvoke.cvWaitKey(20);
            Image&lt;Bgr, byte&gt; marked = faceDetection(temp);
            video.WriteFrame&lt;Bgr, byte&gt;(marked);
            if (c == 27) break;
        }
        video.Dispose();
        camera.Dispose();
        CvInvoke.cvDestroyWindow(""camera"");
    }
</code></pre>

<p>Does anyone know what might be causing this?</p>

<p>Thanks</p>

<p>Evan</p>
",,2013-10-25 14:33:17,"""System.AccessViolationException was unhandled"" error when writing video using emgu CV",<c#><visual-studio-2010><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
508,9928662,2012-03-29 15:33:06,,"<p>I'm trying to select a pixel color of the frames of my webcam. So I capture the frames an show then in a ImageBox without any problem. But when I try to access the image stored on ImageBox when I double click on the ImageBox I get a CvException. The exception pop when I try to get the pixel of the image.</p>

<blockquote>
  <p>OpenCV: unrecognized or unsupported array type</p>
</blockquote>

<p>This is how I capture the frames:</p>

<pre><code>// On Form Load
Application.Idle += ProcessFrame;

private void ProcessFrame(object sender, EventArgs arg)
    {
        if (cap != null)
        {
            using (Image&lt;Bgr, byte&gt; frame = cap.QueryFrame())
            {
                if (frame != null)
                {
                    imageFrame = frame;
                    imageBoxFrame.Image = imageFrame;

                    Bgr color = imageFrame[50, 100];
                }
            }
        }
    }
</code></pre>

<p>And in DoubleClick Event:</p>

<pre><code>private void imageBoxFrame_MouseDoubleClick(object sender, MouseEventArgs e)
    {
        if (treeViewObjects.SelectedNode is ColorNode &amp;&amp; !isTracking)
        {
            if (imageFrame == null)
                return;

            Emgu.CV.UI.ImageBox imageBox = (Emgu.CV.UI.ImageBox)sender;
            Image&lt;Bgr, byte&gt; image = (Image&lt;Bgr, byte&gt;)imageBox.Image;

            Bgr color = image[e.X, e.Y]; // This line causes the Exception
        }
    }
</code></pre>

<p>Apparently the image is not null.
What I doing wrong? Maybe something with thread things?</p>
",2015-01-26 20:05:45,2015-01-26 20:05:45,How can I get a EmguCV ImageBox image?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
544,11886454,2012-08-09 15:10:13,,"<p>I'm write a simple video play with Emgu, which is a c# wrapper of opencv.</p>

<p>Now I can play a video, but I found the fps is not accurate, a little faster than normal.</p>

<p>In my code, I use <code>Thread.sleep()</code> to wait a while between 2 frames. The code is:</p>

<pre><code>int fps = getFromFile(file); // which is 30
while (true) {
    var frame = CvInvoke.cvQueryFrame(capture);
    if (frame.ToInt32() == 0) break;

    Image&lt;Bgr, byte&gt; dest = new Image&lt;Bgr, byte&gt;(Convert.ToInt32(width), Convert.ToInt32(height));
    CvInvoke.cvCopy(frame, dest, IntPtr.Zero);
    box.Image = dest;

    Thread.Sleep(1000 / Convert.ToInt32(fps));
}
</code></pre>

<p>Where is wrong, and how to fix it?</p>

<hr>

<p><strong>update</strong></p>

<p>The <code>box</code> in the code is <code>Emgu.UI.ImageBox</code>, which is thread-safety, and I can access it from other thread directly: <code>box.Image = dest</code></p>
",2012-08-09 15:19:36,2012-08-09 17:43:32,How to use c# to write a simple video player which plays the video with accurate fps?,<c#><multithreading><video><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
556,14780088,2013-02-08 19:39:42,,"<p>I am trying to perform PCA on a data set currently I have 8 sets of data and for each piece of data I have 618 pieces of information about it. Below is the code I have tried so far:</p>

<pre><code>        double[,] RawData = new double[8, 618];

        for (int i = 0; i &lt; 8; i++)//Copies Data to Emgu Matrix
        {
            for (int j = 0; j &lt; 618; j++)
            {
                double val = Convert.ToDouble(DataList[i][j]);
                RawData.SetValue(val, i, j);
            }
        }

        Matrix&lt;Double&gt; DataMatrix = new Matrix&lt;Double&gt;(RawData);
        Matrix&lt;Double&gt; Mean = new Matrix&lt;Double&gt;(1, 618);
        Matrix&lt;Double&gt; EigenValues = new Matrix&lt;Double&gt;(1, 618);
        Matrix&lt;Double&gt; EigenVectors = new Matrix&lt;Double&gt;(618, 618);

        CvInvoke.cvCalcPCA(DataMatrix, Mean, EigenValues, EigenVectors, Emgu.CV.CvEnum.PCA_TYPE.CV_PCA_DATA_AS_COL);

        Matrix&lt;Double&gt; PC1 = new Matrix&lt;Double&gt;(1, 618);
        for (int i = 0; i &lt; 618; i++)
             PC1[0, i] = EigenVectors[0, i];

        Matrix&lt;Double&gt; Results = new Matrix&lt;Double&gt;(8, 1);

        CvInvoke.cvProjectPCA(DataMatrix, Mean, PC1, Results);

        TestStatus.Items.Add(""PCA Projection Results = "");
        for (int i = 0; i &lt; 8; i++)
        {
            TestStatus.Items.Add(Convert.ToString(DataMatrix[i, 0]));
        }
</code></pre>

<p>Emgu.CV.Util.CvException: OpenCV: (evals0.cols == 1 || evals0.rows == 1) &amp;&amp; ecount0 &lt;= ecount &amp;&amp; evects0.cols == evects.cols &amp;&amp; evects0.rows == ecount0</p>

<p>at Emgu.CV.CvInvoke.CvErrorHandler(Int32 status, String funcName, String errMsg, String fileName, Int32 line, IntPtr userData)</p>

<p>at Emgu.CV.CvInvoke.cvCalcPCA(IntPtr data, IntPtr avg, IntPtr eigenvalues, IntPtr eigenvectors, PCA_TYPE flags)
   at Project_3._0.MainWindow.Capture_3D_Face_Click(Object sender, RoutedEventArgs e) in f:\Project\Project 3.0\Project 3.0\MainWindow.xaml.cs:line 516</p>

<p>Which is being caused by the line: (which is in the code above)</p>

<pre><code>        CvInvoke.cvCalcPCA(DataMatrix, Mean, EigenValues, EigenVectors, Emgu.CV.CvEnum.PCA_TYPE.CV_PCA_DATA_AS_COL);
</code></pre>

<p>How do I set up matrices correctly for the PCA to function?</p>
",2013-02-08 22:43:24,2013-03-07 10:51:17,PCA for data set using Emgu,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
578,13820556,2012-12-11 12:35:13,,"<p>In reference to: <a href=""https://stackoverflow.com/questions/13563880/c-sharp-wpf-emgu-how-to-detect-and-count-a-spirals-turns"">How to detect and count a spiral&#39;s turns</a></p>

<p>I am not able to get count even in the pixel based calculation also.</p>

<p>If I have attached image how to start with the counting the turns.</p>

<p>I tried the FindContours(); but doesn't quite get the turns segregated which it can't. Also the matchshape() I have the similarity factor but for whole coil.</p>

<p>So I tried as follows for turn count:</p>

<pre><code> public static int GetSpringTurnCount()
        {
            if (null == m_imageROIed)
                return -1;
            int imageWidth = m_imageROIed.Width;
            int imageHeight = m_imageROIed.Height;

            if ((imageWidth &lt;= 0) || (imageHeight &lt;= 0))
                return 0;

            int turnCount = 0;

            Image&lt;Gray, float&gt; imgGrayF = new Image&lt;Gray, float&gt;(imageWidth, imageHeight);

            CvInvoke.cvConvert(m_imageROIed, imgGrayF);

            imgGrayF = imgGrayF.Laplace(1); // For saving integer overflow.

            Image&lt;Gray, byte&gt; imgGray = new Image&lt;Gray, byte&gt;(imageWidth, imageHeight);
            Image&lt;Gray, byte&gt; cannyEdges = new Image&lt;Gray, byte&gt;(imageWidth, imageHeight);

            CvInvoke.cvConvert(imgGrayF, imgGray);

            cannyEdges = imgGray.Copy();

            //cannyEdges = cannyEdges.ThresholdBinary(new Gray(1), new Gray(255));// = cannyEdges &gt; 0 ? 1 : 0;
            cannyEdges = cannyEdges.Max(0);

            cannyEdges /= 255;

            Double[] sumRow = new Double[cannyEdges.Cols];
            //int sumRowIndex = 0;
            int Rows = cannyEdges.Rows;
            int Cols = cannyEdges.Cols;
            for (int X = 0; X &lt; cannyEdges.Cols; X++)
            {
                Double sumB = 0;

                for (int Y = 0; Y &lt; cannyEdges.Rows; Y ++)
                {
                    //LineSegment2D lines1 = new LineSegment2D(new System.Drawing.Point(X, 0), new System.Drawing.Point(X, Y));

                    Double pixels = cannyEdges[Y, X].Intensity;

                    sumB += pixels;


                }
                sumRow[X] = sumB;
            }

            Double avg = sumRow.Average();

List&lt;int&gt; turnCountList = new List&lt;int&gt;();

            int cnt = 0;
            foreach(int i in sumRow)
            {
                sumRow[cnt] /=  avg;
                if(sumRow[cnt]&gt;3.0)
                turnCountList.Add((int)sumRow[cnt]);
                    cnt++;
            }
            turnCount = turnCountList.Count();

 cntSmooth = cntSmooth * 0.9f + (turnCount) * 0.1f;
            return (int)cntSmooth;
    }
</code></pre>

<p><img src=""https://i.stack.imgur.com/rTFIX.jpg"" alt=""enter image description here""></p>

<p>I am next trying surf.</p>

<p>==================================================</p>

<p>Edit: Adding samples. If you like it do it.
<img src=""https://i.stack.imgur.com/PDWuj.jpg"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/EAIkY.jpg"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/b09vF.jpg"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/cDPvw.jpg"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/nWWtw.jpg"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/bSfj4.jpg"" alt=""enter image description here""></p>

<p>==================================================</p>

<p>Edit: Tried another algo:</p>

<ol>
<li>ROI then Rotate ( biggest thin light blue rectangle )</li>
<li>GetMoments() shrink ROI height and position.Y using the moment.</li>
<li>Set the shrinked ROI and ._And() it with a blank image. ( Gray region with green rectangle )</li>
<li>cut the image into half-half.</li>
<li>contour and fit ellipse. </li>
<li>get maximum number of fitted ellipses.</li>
</ol>

<p>Later will work on better algos and results.</p>

<p><img src=""https://i.stack.imgur.com/Ec5s7.jpg"" alt=""enter image description here""></p>
",2019-01-02 10:40:26,2019-01-02 10:40:26,How to count spring coil turns?,<c#><image-processing><emgucv><image-segmentation>,,,CC BY-SA 4.0,False,False,True,False,False
591,9938573,2012-03-30 07:19:32,,"<p>I am working on a project. Which captures frame with cam and detect characters with using OCR.  When i developed this project i benefited from EMGU CV's standart &quot;OCR&quot; and &quot;Capture&quot; examples. Now, i can capture frame but i did'nt get real OCR result yet.  Do you suggest an example or method for doing this.</p>
<p>P.S. my english is not enough for reading so technical article. Because of this reason, if your suggestion contains the code, that will be good for me.</p>
<p>Thank very much for your help, already now.
Example, frame sources like below;</p>
<p><img src=""https://i.stack.imgur.com/xg2vW.jpg"" alt=""enter image description here"" />
<img src=""https://i.stack.imgur.com/XZ2Re.jpg"" alt=""enter image description here"" /></p>
",2020-06-20 09:12:55,2012-05-22 05:53:55,How can get digits from led secreen with EmguCV?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
685,14792779,2013-02-09 23:24:19,,"<p>After some color detection and binary thresholding, I use the following code to find the contours and draw them onto the image:</p>

<pre><code> using (MemStorage stor = new MemStorage())
        {
           Contour&lt;Point&gt; contours = img.FindContours(
              Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
              Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST,
              stor);

           for (; contours != null; contours = contours.HNext)
           {
              Contour&lt;Point&gt; currentContour = contours.ApproxPoly(contours.Perimeter * poly, stor);

              img.Draw(currentContour,new Bgr(255,255,255),1);

              Rectangle currentrect = currentContour.BoundingRectangle;

              img.Draw(currentrect,new Bgr(255,255,255),2);
            }
        }
</code></pre>

<p>My problem is, as I expected, that if the contour is a rectangle but is rotated in the image, the bounding rectangle does not change its orientation to fit the rotation. Is their another way to accomplish this function? Any help would be greatly appreciated.</p>
",,2014-10-21 17:22:53,Approximating a contour with rotated rectangles,<emgucv><contour>,,,CC BY-SA 3.0,False,False,True,False,False
713,10930610,2012-06-07 11:09:21,,"<p>We are building a web application (C# .NET) that uses unmanaged libraries in the form of the Emgu opencv wrapper. We are forcing the build to be in 32-bit (x86), and we are using the 32-bit version of Emgu.</p>

<p>All this works nice on local builds, but when being published to our webserver the openCV Dll(s) fail to load:</p>

<pre><code>System.DllNotFoundException
Unable to load DLL 'opencv_core240': The specified module could not be found. (Exception from HRESULT: 0x8007007E)

System.TypeInitializationException: The type initializer for 'Emgu.CV.CvInvoke' threw an exception. ---&gt; System.DllNotFoundException: Unable to load DLL 'opencv_core240': The specified module could not be found. (Exception from HRESULT: 0x8007007E)
   at Emgu.CV.CvInvoke.cvRedirectError(CvErrorCallback errorHandler, IntPtr userdata, IntPtr prevUserdata)
   at Emgu.CV.CvInvoke..cctor()
   --- End of inner exception stack trace ---
   at Emgu.CV.CvInvoke.cvCreateImageHeader(Size size, IPL_DEPTH depth, Int32 channels)
   at Emgu.CV.Image`2.AllocateData(Int32 rows, Int32 cols, Int32 numberOfChannels)
   at Emgu.CV.Image`2.set_Bitmap(Bitmap value)
   at Emgu.CV.Image`2..ctor(Bitmap bmp)
</code></pre>

<p>I tried the following things that I've found on stackoverflow and other sources:</p>

<ul>
<li>Put the unmanaged Opencv Dll's in a seperate directory and put the
path to this directory in the path environment variable, and restart
the webservice. </li>
<li>Tested whether the server config allows for unmanaged    code
execution (yes)  </li>
<li>Putting the unmanaged Opencv Dll's in system32\inetsrv and
SysWOW64\inetsrv directories</li>
<li>Puting the unmanaged Opencv Dll's in a subdirectory 'x86' in the
before mentioned folders</li>
</ul>

<p>I understand this: 
<a href=""http://msdn.microsoft.com/en-us/library/ms366723.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms366723.aspx</a></p>

<p>is the reason of all trouble, however I do not understand why editing the path variable to include the correct path containing the Dll's doesn't solve anything.</p>

<p>Last useful post about this issue was in 2008, however no fool-proof solution has ben offered yet, so all the help is much appreciated!</p>
",2012-06-08 07:07:00,2013-06-27 20:57:48,OpenCV Unmanaged DLLs not found asp.net,<c#><asp.net><opencv><unmanaged><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
718,11902593,2012-08-10 13:22:58,,"<p>I am looking for way to (as quick as possible) get the corresponding depth to a color pixel from the Kinect camera.</p>

<p>I have found the MapDepthFrameToColorFrame function. But that only gives me the color at a certain depth position, I want the opposite.</p>

<p>The reason I want this is that I will be able to click on a position at the RGB image and get the position to that pixel.</p>

<p>Is there a way to do this faster than looping through all results from MapDepthFrameToColorFrame?</p>
",,2012-08-10 13:42:42,"Get Depth at Color position, Kinect SDK",<wpf><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
747,13837608,2012-12-12 10:23:41,,"<p>Using EMGUCV, for C#, it is possible to save a Matrix to XML so it can be read later.
Being that VectorOfKeyPoint is a Serializable class, it can also be saved to a XML file.
Nonetheless, when it is open, this UnmanagedObject VectorOfKeyPoint is empty and can not be used.</p>

<p>Is it possible to do something in this way, meaning, in order to load the VectorOfKeyPoint from a XML and use it in the same way?</p>

<p>Nowadays, the working code, as explained in EMGU Wiki, but changed for a VectorOfKeyPoint:</p>

<p><a href=""http://www.emgu.com/wiki/index.php/Working_with_Images#XML_Serialization"" rel=""nofollow"">Parsing from/to XML</a></p>
",,2013-01-03 19:23:52,Save EMGUCV VectorOfKeyPoint to XML and load again,<c#><.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
796,9957690,2012-03-31 16:32:23,,"<p>i am new on EMGU CV. I would like to SURF detect more than one patterns with using cam. Like <a href=""http://www.youtube.com/watch?v=SUU_kNls5Ak"" rel=""nofollow"">this</a> video. But now, i try to develop this just one pattern for starting point.</p>

<p>I examined EMGUCV's SURF example. When i try to implement this codes to cam capture's example, error turns on run time.  I searched more but did not find any code example.</p>

<p>So, do you suggest me a code snippet or tutorial which is explained good. </p>

<p>Thank very much already now.</p>

<p>Codes are below which i am working on;</p>

<pre><code>...........................................
FrameRaw = capture.QueryFrame();
                    CamImageBox.Image = FrameRaw;
        Run(FrameRaw);
...........................................    

     private void Run(Image&lt;Bgr, byte&gt; TempImage)
            {

                Image&lt;Gray, Byte&gt; modelImage = new Image&lt;Gray, byte&gt;(""sample.jpg"");
                Image&lt;Gray, Byte&gt; observedImage = TempImage.Convert&lt;Gray, Byte&gt;();
                // Image&lt;Gray, Byte&gt; observedImage = new Image&lt;Gray,byte&gt;(""box_in_scene.png"");

                Stopwatch watch;
                HomographyMatrix homography = null;

                SURFDetector surfCPU = new SURFDetector(500, false);

                VectorOfKeyPoint modelKeyPoints;
                VectorOfKeyPoint observedKeyPoints;
                Matrix&lt;int&gt; indices;
                Matrix&lt;float&gt; dist;
                Matrix&lt;byte&gt; mask;

                if (GpuInvoke.HasCuda)
                {
                    GpuSURFDetector surfGPU = new GpuSURFDetector(surfCPU.SURFParams, 0.01f);
                    using (GpuImage&lt;Gray, Byte&gt; gpuModelImage = new GpuImage&lt;Gray, byte&gt;(modelImage))
                    //extract features from the object image
                    using (GpuMat&lt;float&gt; gpuModelKeyPoints = surfGPU.DetectKeyPointsRaw(gpuModelImage, null))
                    using (GpuMat&lt;float&gt; gpuModelDescriptors = surfGPU.ComputeDescriptorsRaw(gpuModelImage, null, gpuModelKeyPoints))
                    using (GpuBruteForceMatcher matcher = new GpuBruteForceMatcher(GpuBruteForceMatcher.DistanceType.L2))
                    {
                        modelKeyPoints = new VectorOfKeyPoint();
                        surfGPU.DownloadKeypoints(gpuModelKeyPoints, modelKeyPoints);
                        watch = Stopwatch.StartNew();

                        // extract features from the observed image
                        using (GpuImage&lt;Gray, Byte&gt; gpuObservedImage = new GpuImage&lt;Gray, byte&gt;(observedImage))
                        using (GpuMat&lt;float&gt; gpuObservedKeyPoints = surfGPU.DetectKeyPointsRaw(gpuObservedImage, null))
                        using (GpuMat&lt;float&gt; gpuObservedDescriptors = surfGPU.ComputeDescriptorsRaw(gpuObservedImage, null, gpuObservedKeyPoints))
                        using (GpuMat&lt;int&gt; gpuMatchIndices = new GpuMat&lt;int&gt;(gpuObservedDescriptors.Size.Height, 2, 1))
                        using (GpuMat&lt;float&gt; gpuMatchDist = new GpuMat&lt;float&gt;(gpuMatchIndices.Size, 1))
                        {
                            observedKeyPoints = new VectorOfKeyPoint();
                            surfGPU.DownloadKeypoints(gpuObservedKeyPoints, observedKeyPoints);

                            matcher.KnnMatch(gpuObservedDescriptors, gpuModelDescriptors, gpuMatchIndices, gpuMatchDist, 2, null);

                            indices = new Matrix&lt;int&gt;(gpuMatchIndices.Size);
                            dist = new Matrix&lt;float&gt;(indices.Size);
                            gpuMatchIndices.Download(indices);
                            gpuMatchDist.Download(dist);

                            mask = new Matrix&lt;byte&gt;(dist.Rows, 1);

                            mask.SetValue(255);

                            Features2DTracker.VoteForUniqueness(dist, 0.8, mask);

                            int nonZeroCount = CvInvoke.cvCountNonZero(mask);
                            if (nonZeroCount &gt;= 4)
                            {
                                nonZeroCount = Features2DTracker.VoteForSizeAndOrientation(modelKeyPoints, observedKeyPoints, indices, mask, 1.5, 20);
                                if (nonZeroCount &gt;= 4)
                                    homography = Features2DTracker.GetHomographyMatrixFromMatchedFeatures(modelKeyPoints, observedKeyPoints, indices, mask, 3);
                            }

                            watch.Stop();
                        }
                    }
                }
                else
                {
                    //extract features from the object image
                    modelKeyPoints = surfCPU.DetectKeyPointsRaw(modelImage, null);
                    //MKeyPoint[] kpts = modelKeyPoints.ToArray();
                    Matrix&lt;float&gt; modelDescriptors = surfCPU.ComputeDescriptorsRaw(modelImage, null, modelKeyPoints);

                    watch = Stopwatch.StartNew();

                    // extract features from the observed image
                    observedKeyPoints = surfCPU.DetectKeyPointsRaw(observedImage, null);
                    Matrix&lt;float&gt; observedDescriptors = surfCPU.ComputeDescriptorsRaw(observedImage, null, observedKeyPoints);

                    BruteForceMatcher matcher = new BruteForceMatcher(BruteForceMatcher.DistanceType.L2F32);
                    matcher.Add(modelDescriptors);
                    int k = 2;
                    indices = new Matrix&lt;int&gt;(observedDescriptors.Rows, k);
                    dist = new Matrix&lt;float&gt;(observedDescriptors.Rows, k);
                    matcher.KnnMatch(observedDescriptors, indices, dist, k, null);

                    mask = new Matrix&lt;byte&gt;(dist.Rows, 1);

                    mask.SetValue(255);

                    Features2DTracker.VoteForUniqueness(dist, 0.8, mask);

                    int nonZeroCount = CvInvoke.cvCountNonZero(mask);
                    if (nonZeroCount &gt;= 4)
                    {
                        nonZeroCount = Features2DTracker.VoteForSizeAndOrientation(modelKeyPoints, observedKeyPoints, indices, mask, 1.5, 20);
                        if (nonZeroCount &gt;= 4)
                            homography = Features2DTracker.GetHomographyMatrixFromMatchedFeatures(modelKeyPoints, observedKeyPoints, indices, mask, 3);
                    }

                    watch.Stop();
                }

                //Draw the matched keypoints
                Image&lt;Bgr, Byte&gt; result = Features2DTracker.DrawMatches(modelImage, modelKeyPoints, observedImage, observedKeyPoints,
                   indices, new Bgr(255, 255, 255), new Bgr(255, 255, 255), mask, Features2DTracker.KeypointDrawType.NOT_DRAW_SINGLE_POINTS);

                #region draw the projected region on the image
                if (homography != null)
                {  //draw a rectangle along the projected model
                    Rectangle rect = modelImage.ROI;
                    PointF[] pts = new PointF[] { 
                   new PointF(rect.Left, rect.Bottom),
                   new PointF(rect.Right, rect.Bottom),
                   new PointF(rect.Right, rect.Top),
                   new PointF(rect.Left, rect.Top)};
                    homography.ProjectPoints(pts);

                    result.DrawPolyline(Array.ConvertAll&lt;PointF, Point&gt;(pts, Point.Round), true, new Bgr(Color.Red), 5);
                }
                #endregion

               // ImageViewer.Show(result, String.Format(""Matched using {0} in {1} milliseconds"", GpuInvoke.HasCuda ? ""GPU"" : ""CPU"", watch.ElapsedMilliseconds));
            }
</code></pre>
",,2016-10-28 19:58:06,EmguCV SURF with cam?,<c#><opencv><emgucv><surf>,,,CC BY-SA 3.0,True,False,True,False,False
807,8961229,2012-01-22 12:57:36,,"<p>i am using in my view in an Image Control to display my webcam
in the view's cs file i used EmguCV with a background worker to sample each frame and inject it to the Image.source and it worked perfectly.</p>

<p>Now i'm trying to do it with binding via the ViewModel but the Image.Source never updates.</p>

<p>View:</p>

<pre><code>&lt;Image x:Name=""imgVideo"" Canvas.Left=""0"" Canvas.Top=""0"" Stretch=""Fill"" Source=""{Binding Path=ImageSource}"" Width=""400"" Height=""266"" /&gt;
</code></pre>

<p>ViewModel (relevant parts):</p>

<pre><code>using System.Windows.Media;

 ImageSource imageSource;
        public ImageSource ImageSource
        {
            get { return imageSource; }
            set
            {
                imageSource = value;
                this.RaisePropertyChanged(""ImageSource"");
            }
        }

 void worker_DoWork(object sender, DoWorkEventArgs e)
        {
                Image&lt;Bgr, Byte&gt; currentFrame = m_capture.QueryFrame();
               ... 
                  e.Result = currentFrame ;
}

private void worker_RunWorkerCompleted(object sender, RunWorkerCompletedEventArgs e)
        {
                Image&lt;Bgr, Byte&gt; result = e.Result as Image&lt;Bgr, Byte&gt;;

                BitmapSource bitmapSource = ToBitmapSource(result);
                JpegBitmapEncoder encoder = new JpegBitmapEncoder();
                MemoryStream memoryStream = new MemoryStream();

                encoder.Frames.Add(BitmapFrame.Create(bitmapSource));
                encoder.Save(memoryStream);

                var source = new BitmapImage();
                source.BeginInit();
                source.StreamSource = new MemoryStream(memoryStream.ToArray());
                source.EndInit();

                memoryStream.Close();


                ImageSource = source;


                result.Dispose();
}
</code></pre>

<p>any help will be highly appreciated, Thanks.</p>
",2012-01-22 14:45:41,2012-01-22 14:45:41,Image Source Binding for injecting webcam frame using EmguCV,<c#><wpf><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
1010,15777181,2013-04-03 01:06:32,,"<p>I'm making an app that gets the stream from the camera and uses the canny algorithm to display the edges. 
In android everything worked fine,using OpenCv to get the egdes and it was in real time. After that i went on developing to WP8, and found out WP8 doesn't support OpenCv yet. Because my only problem was that canny edge algorithm i got one from the internet,adapted the code to silverlight and it was a complete mess. It wasn't real-time at all,I was displaying the information in like 1 sec.I searched a bit about alternatives, found:EmguCv(but nothing about canny edge algorithm) and some guys that tried to compile an Opencv subset for W8 ARM.Even tried the second one,but ended up failing.My questions now are:</p>

<ol>
<li>why on earth is it moving so slow?</li>
<li>if i manage to get a OpenCv library,will it be quicker?</li>
<li>do you guys have another alternatives/sugestions?</li>
</ol>
",,2013-05-24 15:27:38,Canny Edge algorithm vs OpenCv - Windows Phone 8,<opencv><windows-phone-8>,,,CC BY-SA 3.0,True,False,True,False,False
1019,11923549,2012-08-12 15:54:42,,"<p>For my project I need to recognize the Object(In my case it is a door) using SURF. I'm using emguCV (openCv c# wrapper).</p>

<p>I have been working with the <a href=""http://www.emgu.com/wiki/index.php/SURF_feature_detector_in_CSharp"" rel=""nofollow"">surf feature detection example</a> from the emguCV library.</p>

<p>By using this I can recognize only few number of object image (e.g.: door) with the given template (model) image.</p>

<p>Since there is different kind of doors, for some door images it was not detected as the door. So, I decided If I can put different kind of door images (2 or more images) as model(template)image, then I can get more accurate result.</p>

<p>My problem is I have no clear idea about how to write a code for work with 2 or more model (template) images? Basically, I want to know by using which parameter, we can say that it is detected or not from the code?</p>

<p>(Visually if it is detected, it draws a red rectangle around the matched object.)</p>

<p>Will be really grateful for your help.</p>

<p>Thank you</p>
",2012-08-12 18:41:23,2012-10-29 06:28:34,Object Recognition using SURF in emgu CV,<c#><.net><image-processing><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
1047,11927676,2012-08-13 02:53:55,,"<p>Im trying to get the OCR sample app to recognise some small text and how I'm doing it is to resize the image. Once I have resized the image it is all 'pixel-ee'</p>

<p><strong>I want to use the SmothGaussian method to clean it up but I get an error each time I execute the method</strong></p>

<p>Here is the code:</p>

<pre><code>Image&lt;Bgr, Byte&gt; image = new Image&lt;Bgr, byte&gt;(openImageFileDialog.FileName);

           using (Image&lt;Gray, byte&gt; gray = image.Convert&lt;Gray, Byte&gt;().Resize(800, 600, Emgu.CV.CvEnum.INTER.CV_INTER_LINEAR, true))
           {

               gray.Convert&lt;Gray, Byte&gt;()._SmoothGaussian(4);



              _ocr.Recognize(gray);
              Tesseract.Charactor[] charactors = _ocr.GetCharactors();
              foreach (Tesseract.Charactor c in charactors)
              {
                  image.Draw(c.Region, drawColor, 1);
              }

              imageBox1.Image = image;

              //String text = String.Concat( Array.ConvertAll(charactors, delegate(Tesseract.Charactor t) { return t.Text; }) );
              String text = _ocr.GetText();
              ocrTextBox.Text = text;
           }
</code></pre>

<p>Here is the image:</p>

<p><img src=""https://i.stack.imgur.com/O0yqa.jpg"" alt=""enter image description here""></p>
",2013-04-24 14:21:27,2013-04-24 14:21:27,How do i use the Emgu CV _SmoothGausian Method,<c#-4.0><gaussian><emgucv><computer-vision>,,,CC BY-SA 3.0,False,False,True,False,False
1097,14820448,2013-02-11 20:39:13,,"<p>I'm using optical flow as a real time obstacle detection and avoidance system for the visually impaired. I'm developing the application in c# and using Emgu Cv for image processing. I use the Lucas and Kanade method and I'm pretty satisfied with the speed of the algorithm. I am using monocular vision thus making it hard for me to compute the depth accurately to each of the features being tracked and to alert the user accordingly. I plan on using an ultrasonic sensor to help with the obstacle detection due to the fact that depth computation is hard with monocular camera. Any suggestions on how I could get an accurate estimation of depth using the camera alone?</p>
",,2016-10-28 07:01:01,Real Time Optical Flow,<opencv><image-processing><computer-vision><emgucv><opticalflow>,,,CC BY-SA 3.0,True,False,True,False,False
1145,9984460,2012-04-02 22:00:06,,"<p>I have the following code to display an image in imagebox using EmgucV:</p>

<pre><code>    Capture capture;
    Image&lt;Bgr, Byte&gt; image;

    public Form1()
    {
        InitializeComponent();
        Application.Idle += new EventHandler(Start);
    }
    void Start(object sender, EventArgs e)
    {
        capture = new Capture();
        image = capture.QueryFrame();
        imageBox1.Image = image;
    }
</code></pre>

<p>I get the exception <code>Attempted to read or write protected memory</code>. What do I need to do to correct this?</p>
",2012-04-23 19:39:05,2018-09-01 18:15:48,EmguCV Attempted to read or write protected memory,<c#><exception><exception-handling><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
1174,10968508,2012-06-10 12:03:39,,"<p>I am currently working on project which combines emgu cv(as Image Processing) and wpf(2D/3D reconstruction)..</p>

<p>The project first was build in Windows Forms until I find out that if I want to construct 2D/3D object, I have to use WPF control (such as viewport 3D) which will be overlayed on top over the Image Frame/Capture...</p>

<p>So,I used usercontrol to host WPF control in windows form and the code run successfully...
<a href=""http://i.imgur.com/F9O7i.png"" rel=""nofollow"">http://i.imgur.com/F9O7i.png</a></p>

<p>but, when I tried to make a simple animation(such as the rectangle background color turns into another color,etc), it's not working..</p>

<p>any idea how to solve this problem?
<a href=""http://i.imgur.com/2ZCph.png"" rel=""nofollow"">http://i.imgur.com/2ZCph.png</a></p>
",,2012-06-10 13:01:31,wpf animation not working on windows form,<wpf><c#-4.0><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
1228,13875514,2012-12-14 09:05:45,,"<p>I'm trying to start using emgu CV open CV for C#. But I'm having trouble making it work.
I'm following this guide to make simple program using emgu CV <a href=""http://www.emgu.com/wiki/index.php/Setting_up_EMGU_C_Sharp"">Link</a> but I get following error: (any idea what I'm doing wrong?)</p>

<pre><code>    System.TypeInitializationException was unhandled
      Message=The type initializer for 'Emgu.CV.CvInvoke' threw an exception.
      Source=Emgu.CV
      TypeName=Emgu.CV.CvInvoke
      StackTrace:
       at Emgu.CV.Image`2..ctor(String fileName) in c:\Emgu\emgucv-windows-x86-gpu 2.4.2.1777\Emgu.CV\Image.cs:line 144
       at TEST.Form1.button1_Click(Object sender, EventArgs e) in c:\documents and settings\laci\my documents\visual studio 2010\Projects\TEST\TEST\Form1.cs:line 28
       at System.Windows.Forms.Control.OnClick(EventArgs e)
       at System.Windows.Forms.Button.OnClick(EventArgs e)
       at System.Windows.Forms.Button.OnMouseUp(MouseEventArgs mevent)
       at System.Windows.Forms.Control.WmMouseUp(Message&amp; m, MouseButtons button, Int32 clicks)
       at System.Windows.Forms.Control.WndProc(Message&amp; m)
       at System.Windows.Forms.ButtonBase.WndProc(Message&amp; m)
       at System.Windows.Forms.Button.WndProc(Message&amp; m)
       at System.Windows.Forms.Control.ControlNativeWindow.OnMessage(Message&amp; m)
       at System.Windows.Forms.Control.ControlNativeWindow.WndProc(Message&amp; m)
       at System.Windows.Forms.NativeWindow.DebuggableCallback(IntPtr hWnd, Int32 msg, IntPtr wparam, IntPtr lparam)
       at System.Windows.Forms.UnsafeNativeMethods.DispatchMessageW(MSG&amp; msg)
       at System.Windows.Forms.Application.ComponentManager.System.Windows.Forms.UnsafeNativeMethods.IMsoComponentManager.FPushMessageLoop(IntPtr dwComponentID, Int32 reason, Int32 pvLoopData)
       at System.Windows.Forms.Application.ThreadContext.RunMessageLoopInner(Int32 reason, ApplicationContext context)
       at System.Windows.Forms.Application.ThreadContext.RunMessageLoop(Int32 reason, ApplicationContext context)
       at System.Windows.Forms.Application.Run(Form mainForm)
       at TEST.Program.Main() in c:\documents and settings\laci\my documents\visual studio 2010\Projects\TEST\TEST\Program.cs:line 18
       at System.AppDomain._nExecuteAssembly(RuntimeAssembly assembly, String[] args)
       at System.AppDomain.ExecuteAssembly(String assemblyFile, Evidence assemblySecurity, String[] args)
       at Microsoft.VisualStudio.HostingProcess.HostProc.RunUsersAssembly()
       at System.Threading.ThreadHelper.ThreadStart_Context(Object state)
       at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean ignoreSyncCtx)
       at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)
       at System.Threading.ThreadHelper.ThreadStart()
  InnerException: System.DllNotFoundException
       Message=Unable to load DLL 'opencv_core242': The specified module could not be found. (Exception from HRESULT: 0x8007007E)
       Source=Emgu.CV
       TypeName=""""
       StackTrace:
            at Emgu.CV.CvInvoke.cvRedirectError(CvErrorCallback errorHandler, IntPtr userdata, IntPtr prevUserdata)
            at Emgu.CV.CvInvoke..cctor() in c:\Emgu\emgucv-windows-x86-gpu 2.4.2.1777\Emgu.CV\PInvoke\CvInvoke.cs:line 166
       InnerException: 
</code></pre>
",2012-12-14 09:07:16,2019-08-01 11:40:24,Unable to load DLL 'opencv_core242': The specified module could not be found. Emgu CV,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
1253,9995493,2012-04-03 14:36:38,,"<p>So i have an image that has been processed with the sobel method, and now i need to extract that image.</p>

<p>My problem is how can i start scanning the image from the mid line uo and down line by line, and when the number of edge is less than 60, record that coordinate to crop the image.</p>

<p>The image in question is a barcode, and this method should work for extracting only the bars. The problem is the implementation with emgu cv.</p>

<p><strong>Update:</strong></p>

<p>I am following the method described in this paper: <a href=""http://bit.ly/HUWdcy"" rel=""nofollow"">http://bit.ly/HUWdcy</a></p>

<p>This question is referent to the C. Image Extraction Chapter</p>
",2012-04-04 18:10:52,2012-04-04 18:10:52,Scan a image with emgu cv,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
1286,8999462,2012-01-25 08:04:07,,"<p>I am new to the image processing.I want to know that how i can add the effects to the image using EmguCV or any other technique.Just like Microsoft LifeCam.(ex. showing hat on the head,showing name on the head etc.)</p>

<p>Please help,thanks in advance.</p>

<p><strong>Update</strong>::I am now working with the code </p>

<blockquote>
  <p>face recognition x86</p>
</blockquote>

<p>in that i am using the function currentFrame.Draw(...) to drow the image.
now i want to add the new bitmap image with the current image but it showing me the exception.</p>

<pre><code>OpenCV: The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array'
</code></pre>

<p>So anything which i will do with the Image myimg.Add()</p>
",2012-01-25 11:38:39,2012-01-25 11:38:39,How to add effects to image,<c#><image><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
1324,11949587,2012-08-14 09:38:29,,"<p>I'm trying to initialize a new <code>Image&lt;Gray,float&gt;</code> and set all the pixel values manually based on the gradients. My question is: How to set the pixel gray intensity. It won't accept double precision numbers.</p>

<pre><code>if (i &gt;= 1 &amp;&amp; j &gt;= 1 &amp;&amp; grayTextIm[i, j].Intensity + gthres &lt; grayTextIm[i, j].Intensity &amp;&amp; grayTextIm[i, j].Intensity &lt; grayTextIm[i, j].Intensity-gthres)
{
    gradIm[i, j].Intensity = 1.0;
}
else
{
    gradIm[i,j]= 0;
}
</code></pre>
",2012-08-14 09:50:17,2013-05-27 02:59:58,OpenCv Emgu - How to set grayscaleimage pixel intensity,<opencv><grayscale><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
1354,13885729,2012-12-14 20:24:26,,"<p>I can't get Emgu CV to work with the cameras on the new Atom based Windows 8 x86 tablets. These are not the ARM based tablets running Windows 8 RT these are running the full blown Windows 8 Pro x86 on x86 Atom CPUs. I've tried working code on a release version of the Samsung XE500T1C (Ativ?) and on a pre-release version of the HP ElitePad 900.</p>

<p>Emgu CV tells me: ""Error: Unable to create capture from camera 0"". The problem is probably related to the fact that the new Atom chipset is handling some of the camera functions. I've attached a screenshot of the device manager with the offending cameras highlighted.</p>

<p>Under Imaging devices we have:<br />
Intel(R) Imaging Signal Processor 2300</p>

<p>Under System devices we have:<br />
Camera Sensor OV2720<br />
Camera Sensor OV8830<br />
Flash LM3554</p>

<p><img src=""https://i.stack.imgur.com/iH7Z0.png"" alt=""Samsung XE500T1C Running Windows 8 Pro 32-bit""></p>

<p>I've searched the Internets high and low and can't find anything useful. I've contacted HP and they're contacting their engineering. I tried Intel and the best I got was this: <a href=""http://software.intel.com/en-us/articles/sample-windows-store-app-for-camera-picture-taking"" rel=""nofollow noreferrer"">http://software.intel.com/en-us/articles/sample-windows-store-app-for-camera-picture-taking</a> which is actually for the Windows Store apps. Although it does work.</p>

<p>Does anyone have any ideas? Needless to say I'm in a bind. One other thing Emgu CV is working fine on my Samsung Slate Series 7 that is running Windows 8 Pro. It also runs fine in a 32-bit Windows 8 Pro VM. It just appears to be these new ones with the new Atoms with the Intel Imaging Signal Processor 2300.</p>

<p>Thanks everyone!</p>

<p>Hal</p>
",,2013-04-03 19:43:51,x86 Windows 8 Tablet running Pro can't access Integrated Cameras with Emgu OpenCV,<opencv><windows-8><tablet><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
1388,11958473,2012-08-14 18:26:42,,"<p>I'm using Emgu.CV to perform some basic image manipulation and composition. My images are loaded as <code>Image&lt;Bgra,Byte&gt;</code>.</p>

<p><strong>Question #1:</strong> When I use the <code>Image&lt;,&gt;.Add()</code> method, the images are always blended together, regardless of the alpha value. Instead I'd like them to be composited one atop the other, and use the included alpha channel to determine how the images should be blended. So if I call <code>image1.Add(image2)</code> any fully opaque pixels in image2 would completely cover the pixels from image1, while semi-transparent pixels would be blended based on the alpha value.</p>

<p>Here's what I'm trying to do in visual form. There's a city image with some ""transparent holes"" cut out, and a frog behind. This is what it should look like:</p>

<p><img src=""https://i.stack.imgur.com/Th19r.jpg"" alt=""enter image description here""></p>

<p>And this is what openCV produces.</p>

<p><img src=""https://i.stack.imgur.com/uCH7J.jpg"" alt=""This is what OpenCV (Emgu.CV) produces when I call &quot;add&quot;""></p>

<p>How can I get this effect with OpenCV? And will it be as fast as calling <code>Add()</code>?</p>

<p><strong>Question #2:</strong> is there a way to perform this composition in-place instead of creating a new image with each call to <code>Add()</code>?  (e.g. <code>image1.AddImageInPlace(image2)</code> modifies the bytes of  <code>image1</code>?)</p>

<p><strong>NOTE</strong>: Looking for answers within Emgu.CV, which I'm using because of how well it handles perspective warping.</p>
",2012-08-17 18:55:21,2017-10-31 13:24:31,OpenCV (Emgu.CV) -- compositing images with alpha,<image-processing><opencv><emgucv><alphablending>,,,CC BY-SA 3.0,True,False,True,False,False
1412,13891613,2012-12-15 11:06:16,,"<p>My current project has required me to learn face detection/tracking and image processing, given my experience in c#, I chose <code>Emgu CV</code> as my choice library for face detection and tracking. From what I've learned so far, I can do face detection and tracking, and basic image processing.</p>

<p>My goal is to be able to place virtual hair on the detected face. What I want to achieve is similar to [this video]: <a href=""http://www.youtube.com/watch?v=BdPmECfUFcI"" rel=""nofollow"">http://www.youtube.com/watch?v=BdPmECfUFcI</a>.</p>

<p>What I would like to know is the technique(s) to use in handling hair placement for different kind of hairstyles on the detected face. In what image format do I store the the hair? </p>
",2012-12-15 11:17:00,2012-12-16 18:03:24,Virtual Hair on Detected face using Emgu CV - C#,<c#><image-processing><emgucv><face-detection>,,,CC BY-SA 3.0,False,False,True,False,False
1473,15816710,2013-04-04 16:29:38,,"<p>I didn't find any explanations how to use a matrix with more than one channel im emgucv</p>

<pre><code>var matrixa = new Matrix&lt;float&gt;(usablePoints.Count, 1, 2);
</code></pre>

<p>I tried with the Split() function but it didn't change the values of <strong>matrixa</strong></p>

<pre><code>var channels = matrixa.Split();
for (int i = 0; i &lt; usablePoints.Count; ++i)
{
  channels[0][i, 0] = usablePoints[i].X;
  channels[1][i, 0] = usablePoints[i].Y;
}
</code></pre>

<p>What am I missing? How can i manipulate values of matrixa?</p>
",,2013-04-09 13:52:15,How to set values for multichannel matrix in Emgucv,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
1479,9015498,2012-01-26 08:31:57,,"<p>I need Haar Cascades xml files for Mouth, Eyes &amp; Nose. Do provide me useful links.</p>

<p>Any kind of help would be highly appreciated.</p>
",,2017-09-23 07:30:08,"Need Haar Casscades for Nose, Eyes & Lips(Mouth)",<opencv><face-detection><emgucv><emotion>,,,CC BY-SA 3.0,True,False,True,False,False
1524,10996572,2012-06-12 12:22:35,,"<p>I am using <a href=""http://code.google.com/p/twaindotnet/"" rel=""nofollow noreferrer"">Twain Dot Net</a> to scan a relatively simple image and ultimately I am using <a href=""http://www.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow noreferrer"">Emgu CV</a> to find the edges.  Here is a screenshot of something I have scanned:</p>

<p><img src=""https://i.stack.imgur.com/WKqLx.png"" alt=""white/gray image""></p>

<p>However I adjust the thresholds in the image detection I get exactly the same edge detected but it is not the correct position (it is too wide - the thing I have scanned is grey).  If I scan an image that is black like this I get the edge detected that I would expect:</p>

<p><img src=""https://i.stack.imgur.com/6RbRf.png"" alt=""black image""></p>

<p>In both cases you can see a purple edge (which is not there on the real object).</p>

<p>My feeling is that this purple edge is causing the edge detection to do the wrong thing for the first one because it matches where the purple is but for the black one it matches where the black is (because the intensity of the black is higher than purple but the intensity of the grey is not).  I am thinking that would explain why adjusting the threshold values in emgu makes no difference.</p>

<p>So, my question is - is there a twain setting that I can set to remove this purple or is it a feature of the scanner (I found <a href=""http://www.flickr.com/groups/diy_color/discuss/72157629964165335/"" rel=""nofollow noreferrer"">this</a> interesting discussion on Flickr that points to the hardware but I have tried it with three different scanners (two the same model, one completely different) and they all do the same)?</p>

<p>Here is the code I am using to scan the image:</p>

<pre><code>var resolution = new ResolutionSettings
{
    Dpi = 2400,
    ColourSetting = ColourSetting.Colour
};

var rotation = new RotationSettings
{
    AutomaticBorderDetection = false,
    AutomaticDeskew = false,
    AutomaticRotate = false,
    FlipSideRotation = FlipRotation.FanFold
};

var areaSettings = new AreaSettings(Units.Centimeters, 
    4.0f,
    0.0f, 
    6.0f, 
    19.0f)

var twainSettings = new TwainScanSettings
{
    UseDocumentFeeder = null,
    ShowTwainUI = false,
    ShowProgressIndicatorUI = false,
    UseDuplex = false,
    Resolution = resolution,
    Area = areaSettings,
    AdditionalLight = true,
    Rotation = rotation
};

var scanner = new TwainEngine(new WinFormsWindowMessageHook(form.Handle));
scanner.SelectSource(""Microtek ScanWizard EZ"");
scanner.TransferImage += (tsender, targs) =&gt;
{
    targs.Image.Save(@""c:\Users\Public\out.bmp"",
        System.Drawing.Imaging.ImageFormat.MemoryBmp);
};

scanner.StartScanning(twainSettings);
</code></pre>
",,2012-06-12 12:22:35,Twain Scanning Removing Purple Edges,<c#><.net><twain><emgucv><twaindotnet>,,,CC BY-SA 3.0,False,False,True,False,False
1561,15823994,2013-04-05 00:27:08,,"<p>I wrote a code that it finds the K closest matches by KNN algorithm. After getting the matMatch and matchIndices I tried to draw the match pairs between two consequence frames.  </p>

<p>I feed <strong>matMask</strong> and <strong>matchIndices</strong> into function <strong>Features2DToolbox.DrawMatches</strong> : </p>

<pre><code>Image&lt;Bgr, byte&gt; imResult = Features2DToolbox.DrawMatches(imModelCurr, imModel.keyPoints, imObserPrev,imObser.keyPoints, **matchIndices**, new Bgr(System.Drawing.Color.Yellow), new Bgr(System.Drawing.Color.Red), **matMask**, Features2DToolbox.KeypointDrawType.NOT_DRAW_SINGLE_POINTS);
</code></pre>

<p><a href=""http://www.emgu.com/wiki/files/2.4.0/document/html/e92d37e6-fe4a-ad09-9304-cd2d2533bfa8.htm"" rel=""nofollow noreferrer"">http://www.emgu.com/wiki/files/2.4.0/document/html/e92d37e6-fe4a-ad09-9304-cd2d2533bfa8.htm</a> but I noticed it gives me back wrong drawing between matching pairs:  </p>

<p><img src=""https://i.stack.imgur.com/NvTN6.png"" alt=""enter image description here""></p>

<p>Then I tried to implement such function by myself:</p>

<pre><code> for (int i = 0; i &lt; matMask.Rows; ++i)
        {
            if (**matMask[i, 0]** &gt; 0) 
            {
                int indForCurrFrm = **matchIndices[i, 0]**;
                int indForPrevFrm = i;

                //for frame i-1
                PointF fromFirstFrame = getImgObserved(keyPoints[indForPrevFrm]);

                //for frame i
                PointF NextCorrespondingMatchedFrame = getImModelXY(keyPoints[indForCurrFrm]);

                imColorPrv2.Draw(new CircleF(fromFirstFrame, 5), new Bgr(mtchColor), 3);// for frame i-1
                imColorShow.Draw(new CircleF(NextCorrespondingMatchedFrame, 5), new Bgr(mtchColor), 3); // for frame i

                 // draw line on my own matching
              imResult.Draw(new LineSegment2DF(fromFirstFrame,NextCorrespondingMatchedFrame),new Bgr(System.Drawing.Color.FloralWhite),1);

            }
        }
</code></pre>

<p>and fetch the corresponding pair point coordinates (X,Y) and draw it by myself [ see the results in snapshot].</p>

<p>One the left bottom you could see the matches(shown by white line) and each corresponding pairs with a circle in same color [by my own Function] and on the other side-bottom right , it is the results drawn by DrawMatches function from Emgu.Pay attention that these two functions use the same matMash and matchIndices.</p>

<p>So I was wondering if DrawMatches at EMGU has bugs or I am doing somewhere wrong?</p>
",2013-04-05 00:53:42,2013-07-25 15:00:22,Drawing match pairs in image-calculated by KNN and the potential bug in Features2DToolbox.DrawMatches,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
1571,13901704,2012-12-16 13:25:08,,"<p>I'm using emgu CV &amp; C# and getting low FPS (approx. 8fps) while capturing/displaying webcam video! so far this is what I have tried:
I have to apply some filters as well, how can I make my code more efficient?
is there any way to process these frames using GPU?</p>

<pre><code>    private Capture _capture;
    private bool _captureInProgress;
    private Image&lt;Bgr, Byte&gt; frame;
    private void ProcessFrame(object sender, EventArgs arg)
    {
        frame = _capture.QueryFrame();
        captureImageBox.Image = frame;

    }

    private void startToolStripMenuItem_Click(object sender, EventArgs e)
    {
        #region if capture is not created, create it now
        if (_capture == null)
        {
            try
            {
                _capture = new Capture();
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(excpt.Message);
            }
        }
        #endregion

        Application.Idle += ProcessFrame;

        if (_capture != null)
        {
            if (_captureInProgress)
            {
                //stop the capture

                startToolStripMenuItem.Text = ""Start"";
                Application.Idle -= ProcessFrame;
            }
            else
            {
                //start the capture
                startToolStripMenuItem.Text = ""Stop"";
                Application.Idle += ProcessFrame;
            }

            _captureInProgress = !_captureInProgress;
        }
    }
</code></pre>
",,2013-08-22 07:14:10,How to increase frame rate of webcam's video input? Emgu CV,<c#><image-processing><emgucv><frame-rate>,,,CC BY-SA 3.0,False,False,True,False,False
1738,11013895,2012-06-13 11:27:41,,"<p>I want to detect two hands (using HSV filtered image).</p>

<p>the problem is that when i get the two hands together the head gets in between and then the hands cannot be recognized.</p>

<p>im using Haar to detect the 2 hands when the application starts and then i turn the image into HSV (black and white). then im using segmentation to detect the objects central mass so i can follow them. i dismiss the objects which their area is small enough.</p>

<p>any ideas how can i solve this problem ?</p>
",2013-01-15 08:37:26,2013-01-15 08:37:26,emgu two hands detection,<c#><emgucv><image-segmentation><haar-wavelet>,,,CC BY-SA 3.0,False,False,True,False,False
1810,11993589,2012-08-16 18:51:20,,"<p>I am totally new in GPU programing , i have no experience before working with a GPU  , I have some functions , I have to convert those functions so that they run in GPU , The cpu version is running fine , I have used emgucv for image operations . My code is given bellow , please help me .</p>

<pre><code>public static Image Highlight(Image image)
    {
      if (image == null)
      {
        throw new ArgumentNullException(""image"");
      }

      using (Image&lt;Bgr, byte&gt; originalImage = ConvertToEmgu(image))
      using (Image&lt;Bgr, byte&gt; resavedOriginalImage = ConvertToEmgu(ResaveImageWithGivenCompression(image)))
      using (Image&lt;Bgr, byte&gt; errorLevelImage = (originalImage - resavedOriginalImage) * scalingFactor)
      {
        return errorLevelImage.ToBitmap();
      }
    }

    private static Image&lt;Bgr, byte&gt; ConvertToEmgu(Image image)
    {
      using (Bitmap bitmap = new Bitmap(image))
      {
        return new Image&lt;Bgr, byte&gt;(bitmap);
      }
    }

    private static Image ResaveImage(Image image)
    {
      EncoderParameters jpegEncoderParameters = new EncoderParameters(1);
      ImageCodecInfo jpegWithGivenCompressionFormat = GetEncoderInfo(""image/jpeg"");

      jpegEncoderParameters.Param[0] = new EncoderParameter(Encoder.Quality, compressionQuality);

      using (MemoryStream resavedImageStream = new MemoryStream())
      {
        image.Save(resavedImageStream, jpegWithGivenCompressionFormat, jpegEncoderParameters);

        return Image.FromStream(resavedImageStream);
      }
    }

    private static ImageCodecInfo GetEncoderInfo(string mimeType)
    {
      ImageCodecInfo[] encoders = ImageCodecInfo.GetImageEncoders();

      return encoders.FirstOrDefault(encoder =&gt; encoder.MimeType == mimeType);
    }
  }
</code></pre>
",2012-08-16 20:26:39,2013-06-06 04:06:56,Convert an emgu code to GPU,<gpu><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
1813,14887938,2013-02-15 03:44:00,,"<p>I'm working on a project for school involving C#, Kinect, and Emgu CV. I fairly new to both C# and Emgu CV, so I may be missing something simple. What I am trying to do is use the image from the Kinect as an Emgu CV image for processing, but I keep getting an error. The error that comes up is ""TypeInitializationException was unhandled"" and ""The type initializer for 'Emgu.Cv.CVInvoke' threw an exception."" </p>

<p>The code I'm using to get the image from the Kinect is:</p>

<pre><code>using (ColorImageFrame colorFrame = e.OpenColorImageFrame()) 
{
    if (colorFrame != null)
    {           
        byte[] pixels = new byte[colorFrame.PixelDataLength];
        colorFrame.CopyPixelDataTo(pixels);

        int stride = colorFrame.Width * 4;
        BitmapSource color = BitmapImage.Create(colorFrame.Width, colorFrame.Height,96, 96, PixelFormats.Bgr32, null, pixels, stride);
        liveFeed.Source = color;

        EmguCVProcessing(color); 
    }
    else
    {
        return;
    }
}
</code></pre>

<p>I also found some code that I am using to convert the BitmapSource to a Bitmap from: <a href=""https://stackoverflow.com/questions/2284353/is-there-a-good-way-to-convert-between-bitmapsource-and-bitmap"">Is there a good way to convert between BitmapSource and Bitmap?</a></p>

<p>The code that isn't working is as follows:</p>

<pre><code>void EmguCVProcessing(BitmapSource bitmap)
{
    Bitmap bmp = GetBitmap(bitmap);

    Image&lt;Bgr, Byte&gt; imgLiveFeed = new Image&lt;Bgr, Byte&gt;(bmp);
}
</code></pre>

<p>From what I can find, this should convert the Bitmap into an Emgu CV image but for some reason it isn't. </p>

<p>Just some more information: </p>

<p>InnerException: Make sure the file image is a valid managed assembly.</p>

<p>InnerException: Make sure you have supplied a correct file path for the assembly.</p>

<p>My best guess is that the program is using different versions of the .NET Framework, but I am unsure of how to fix this problem.</p>
",2017-05-23 11:58:22,2015-02-08 18:21:52,Trouble using Kinect ColorImageFrame with Emgu CV,<c#><kinect><emgucv><computer-vision>,,,CC BY-SA 3.0,False,False,True,False,False
1883,10050860,2012-04-07 01:10:05,,"<p>Currently I am working on 3D image visualizing project using C# and emgucv.net. On that project following steps already done with 2 images of same scene(a little different in rotation and translation),</p>

<ol>
<li>Feature detection(SURF), matching and calculate homography</li>
<li>calculate fundamental matrix</li>
<li>calculate essential matrix using above fundamental and camera intrinsic matrices</li>
<li>finally calculate the Rotational and translational matrices</li>
</ol>

<p>Also I have obtain 4 possible answers for transformational matrix(3X4 [R|T]) using different combinations of R and T by changing its sign. Now I want to select the correct transformation matrix from those 4 answers. Before that I want to check either one of the answer is correct. So I have to re-project the points of second image using ""Camera intrinsic matrix"" and each one of ""Transformation matrix"". After that I can compare with resultant points with the second image points to confirm the result(translational matrix).</p>

<p>My question is, How to re-combine translational matrix(rotational[3X3] and translational[3X1] matrix ) and camera intrinsic matrix to project points into image points using emgucv.net?</p>

<p>OR any alternative method to confirm the transformational matrix that I obtain?</p>

<p>Thanks in advance for any help.</p>
",,2012-04-07 01:10:05,Project points using intrinsic and transformational matrices,<opencv><computer-vision><transformation><emgucv><homography>,,,CC BY-SA 3.0,True,False,True,False,False
1929,11031748,2012-06-14 11:04:35,,"<p>I have an image that looks like this:</p>

<p><img src=""https://i.stack.imgur.com/LM6ck.png"" alt=""original""></p>

<p>and I want to find the edges of the dark part so like this (the red lines are what I am looking for):</p>

<p><img src=""https://i.stack.imgur.com/NBNkJ.png"" alt=""required""></p>

<p>I have tried a few approaches and none have worked so I am hoping there is an emgu guru out there willing to help me...</p>

<h2>Approach 1</h2>

<ul>
<li>Convert the image to grayscale</li>
<li>Remove noise and invert </li>
<li>Remove anything that is not really bright</li>
<li>Get the canny and the polygons</li>
</ul>

<p>Code for this (I know that I should be disposing of things properly but I am keeping the code short):</p>

<pre><code>var orig = new Image&lt;Bgr, byte&gt;(inFile);

var contours = orig
    .Convert&lt;Gray, byte&gt;()
    .PyrDown()
    .PyrUp()
    .Not()
    .InRange(new Gray(190), new Gray(255))
    .Canny(new Gray(190), new Gray(255))
    .FindContours(CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
                  RETR_TYPE.CV_RETR_TREE);

var output = new Image&lt;Gray, byte&gt;(orig.Size);    
for (; contours != null; contours = contours.HNext)
{
    var poly = contours.ApproxPoly(contours.Perimeter*0.05,
                                   contours.Storage);
    output.Draw(poly, new Gray(255), 1);
}
output.Save(outFile);
</code></pre>

<p>This is the result:</p>

<p><img src=""https://i.stack.imgur.com/LlD7C.png"" alt=""approach 1 result""></p>

<h2>Approach 2</h2>

<ul>
<li>Convert the image to grayscale</li>
<li>Remove noise and invert </li>
<li>Remove anything that is not really bright</li>
<li>Get the canny and then lines</li>
</ul>

<p>Code for this:</p>

<pre><code>var orig = new Image&lt;Bgr, byte&gt;(inFile);

var linesegs = orig
    .Convert&lt;Gray, byte&gt;()
    .PyrDown()
    .PyrUp()
    .Not()
    .InRange(new Gray(190), new Gray(255))
    .Canny(new Gray(190), new Gray(255))
    .HoughLinesBinary(
        1,
        Math.PI/45.0,
        20,
        30,
        10
    )[0];

var output = new Image&lt;Gray, byte&gt;(orig.Size);    
foreach (var l in linesegs)
{
    output.Draw(l, new Gray(255), 1);
}
output.Save(outFile);
</code></pre>

<p>This is the result:</p>

<p><img src=""https://i.stack.imgur.com/KJoG3.png"" alt=""approach 2 result""></p>

<p><em>Notes</em> </p>

<p>I have tried adjusting all the parameters on those two approaches and adding smoothing but I can never get the simple edges that I need because, I suppose, the darker region is not a solid colour.  </p>

<p>I have also tried dilating and eroding but the parameters I have to put in for those are so high to get a single colour that I end up including some of the grey stuff on the right and lose accuracy.</p>
",2013-12-24 14:35:51,2013-12-24 14:35:51,"Is it possible to find the edge of a ""spotty"" region in emgucv?",<c#><.net><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
1998,9062406,2012-01-30 10:25:27,,"<p>I'm working on Microsoft Surface 1.0 and working with leds to create a pen for tabletops.
My question is, how can i set the minimum size of a blob that can be recognized by the surface? </p>

<p>I mean, if I've thresholded the RAW image of surface cameras and show just the LED i want to be recognized and saved into a <code>CircleF[]</code> array, can I create a contact giving the coordinates of the circle I've saved?.</p>

<p>The point is, when the LED touch the surface, the blob disappear because is too small so it can't be recognized.</p>
",2012-01-30 12:04:20,2012-01-30 14:25:14,Microsoft Surface 1.0 How to create a contact from RAW image and Emgu CV,<c#><.net-3.5><pixelsense><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
2045,12991537,2012-10-20 18:43:13,,"<p>I am working on a project which involves extracting features from color and depth frames from Kinect Camera. The problem I am facing is that whenever I try displaying 2 Images, the UI hangs. When I tried debugging, the depthFrame and colorFrame were coming as null. If enable only the color steam then both colorImage and featureImage1 are displayed properly and if I enable only the depth stream, it works as it should. But when I enable them both, the UI hangs. I have no idea what is causing the problem. I have the following the following code for my Kinect Application. What is the cause of this problem and how can I fix it?
Config: Windows 8 Pro 64bit, 2Ghz Core2Duo, VisualStudio 2012 Ultimate, EmguCV 2.4.0.</p>

<pre><code>using System;
using System.Collections.Generic;
using System.Drawing;
using System.Linq;
using System.Runtime.InteropServices;
using System.Text;
using System.Threading.Tasks;
using System.Windows;
using System.Windows.Controls;
using System.Windows.Data;
using System.Windows.Documents;
using System.Windows.Input;
using System.Windows.Media;
using System.Windows.Media.Imaging;
using System.Windows.Navigation;
using System.Windows.Shapes;
using Microsoft.Kinect;
using Emgu.CV;
using Emgu.CV.WPF;
using Emgu.CV.Structure;
using Emgu.Util;
namespace features
{
public partial class MainWindow : Window
{  
    public MainWindow()
    {
        InitializeComponent();
    }
    private Image&lt;Bgra, Byte&gt; cvColorImage;
    private Image&lt;Gray, Int16&gt; cvDepthImage;
    private int colorWidth = 640;
    private int colorHeight = 480;
    private int depthWidth = 640;
    private int depthHeight = 480;
    private static readonly int Bgr32BytesPerPixel = (PixelFormats.Bgr32.BitsPerPixel + 7) / 8;
    private byte[] colorPixels;
    private byte[] depthPixels;
    private short[] rawDepthData;
    private bool first = true;
    private bool firstDepth = true;
    Image&lt;Bgra, byte&gt; image2;
    private void Window_Loaded(object sender, RoutedEventArgs e)
    {
        kinectSensorChooser.KinectSensorChanged += new DependencyPropertyChangedEventHandler(kinectSensorChooser_KinectSensorChanged);
    }
    void kinectSensorChooser_KinectSensorChanged(object sender, DependencyPropertyChangedEventArgs e)
    {
        KinectSensor oldSensor = (KinectSensor)e.OldValue;
        KinectStop(oldSensor);
        KinectSensor _sensor = (KinectSensor)e.NewValue;
        _sensor.ColorStream.Enable(ColorImageFormat.RgbResolution640x480Fps30);
        _sensor.DepthStream.Enable(DepthImageFormat.Resolution640x480Fps30);
        _sensor.DepthFrameReady += new EventHandler&lt;DepthImageFrameReadyEventArgs&gt;(_sensor_DepthFrameReady);
        _sensor.ColorFrameReady += new EventHandler&lt;ColorImageFrameReadyEventArgs&gt;(_sensor_ColorFrameReady);
        _sensor.DepthStream.FrameHeight);
        try
        {
            _sensor.Start();
        }
        catch
        {
            kinectSensorChooser.AppConflictOccurred();
        }
    }
    void KinectStop(KinectSensor sensor)
    {
        if (sensor != null)
        {
            sensor.Stop();
        }
    }

    private void Window_Closed(object sender, EventArgs e)
    {
        KinectStop(kinectSensorChooser.Kinect);
    }

    void _sensor_ColorFrameReady(object sender, ColorImageFrameReadyEventArgs e)
    {
        using (ColorImageFrame colorFrame = e.OpenColorImageFrame())
        {
            if (colorFrame == null) return;
            if (first)
            {
                this.colorPixels = new Byte[colorFrame.PixelDataLength];
                first = false;
            }
            colorFrame.CopyPixelDataTo(this.colorPixels); //raw data in bgrx format
            processColor();
        }
    }
    void _sensor_DepthFrameReady(object sender, DepthImageFrameReadyEventArgs e)
    {
        using (DepthImageFrame depthFrame = e.OpenDepthImageFrame())
        {
            if (depthFrame == null) return;
            if (firstDepth)
            {
                this.rawDepthData = new short[depthFrame.PixelDataLength];
                firstDepth = false;
            }
            depthFrame.CopyPixelDataTo(rawDepthData);
            processDepth();
        }
    }
    private void processColor(){...}
    private void processDepth(){...}
}
}
</code></pre>

<p>The processDepth function is as follows. I am just making an Image from the RAW depth data.</p>

<pre><code>private void processDepth() {
    GCHandle pinnedArray = GCHandle.Alloc(this.rawDepthData, GCHandleType.Pinned);
    IntPtr pointer = pinnedArray.AddrOfPinnedObject();
    cvDepthImage = new Image&lt;Gray, Int16&gt;(depthWidth, depthHeight, depthWidth &lt;&lt; 1, pointer);
    pinnedArray.Free();
    depthImage.Source = BitmapSourceConvert.ToBitmapSource(cvDepthImage.Not().Bitmap);
}
</code></pre>

<p>The processColor function is as follows. Here just for the sake of it, I am trying to display the cloned image instead of extracting features, just to check the lag. When both streams are enabled (color and depth) the following function displays the colorImage properly, but as soon as I uncomment the commented lines, the UI hangs.</p>

<pre><code>private void processColor() {
    GCHandle handle = GCHandle.Alloc(this.colorPixels, GCHandleType.Pinned);
    Bitmap image = new Bitmap(colorWidth, colorHeight, colorWidth&lt;&lt;2, System.Drawing.Imaging.PixelFormat.Format32bppRgb, handle.AddrOfPinnedObject());
    handle.Free();
    cvColorImage = new Image&lt;Bgra, byte&gt;(image);
    image.Dispose();
    BitmapSource src = BitmapSourceConvert.ToBitmapSource(cvColorImage.Bitmap);
    colorImage.Source = src;
    //image2 = new Image&lt;Bgra, byte&gt;(cvColorImage.ToBitmap()); //uncomment and it hangs
    //featureImage1.Source = BitmapSourceConvert.ToBitmapSource(image2.Bitmap); //uncomment and it hangs
}
</code></pre>
",2014-08-03 05:52:16,2014-08-03 05:52:16,UI Freezes while processing frames from Kinect using EmguCV in WPF C# Application,<c#><wpf><kinect><emgucv><kinect-sdk>,,,CC BY-SA 3.0,False,False,True,False,False
2056,10066490,2012-04-08 21:03:50,,"<p>I'm trying to load a video to using Emgucv Caputre class.</p>

<p>This is my code:</p>

<pre><code>Capture capture = new Capture(filename);
</code></pre>

<p>Very simple, except that I get a TypeInitializationException every time.
I'm trying to read an mp4 file captured using an android phone.</p>

<p>I read <a href=""http://opencv.willowgarage.com/wiki/VideoCodecs"" rel=""nofollow"">http://opencv.willowgarage.com/wiki/VideoCodecs</a> and I tried converting it to avi in all forms. I tried using mencoder like this:
mencoder in.avi -ovc raw -vf format=i420 -nosound -o out.avi</p>

<p>But it still won't work.</p>

<p>Please help me figure out why.</p>

<p>Thanks.</p>
",,2012-05-12 10:27:19,Playing video in Emgucv,<video><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
2093,14912790,2013-02-16 17:00:28,,"<p>I keep getting a cv.invoke when I try to read a simpe image. My application has no further code than this (emgu-opencv wise). I checked the call stack and it says <code>Thrown: ""Unable to load DLL 'opencv_core249': The specified module could not be found.</code> </p>

<p>The problem is that I tried adding the two .dlls <code>(opencv_core249 and opencv_imgproc249)</code> in the solution as resource (with copy always in properties) and still get the exception
also tried changing their property as content and still nothing.</p>

<p>Also tried manually copying them in the debug folder and still I get the same exception.
I have already followed the guidelines point out at <a href=""https://stackoverflow.com/questions/14426942/the-type-initializer-for-emgu-cv-cvinvoke-threw-an-exception-for-win8-64bit-v/14662701#14662701"">this question</a> but still I get the same error</p>

<p>If it is of any help I am using Visual Studio 2012 and Windows 8</p>
",2017-05-23 11:52:40,2013-08-10 14:45:16,CV.Invoke on emgu,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
2140,13952659,2012-12-19 12:38:07,,"<p>I am trying to detect images of CDs from a database of images. I figured that I would be able to use a Circle Hough Transform on each image, and select ones which contain concentric circles with a similar centre. </p>

<p>I have tried using the HoughCircles method in EMGU, which works fine if the circles are not in the centre of the outer circle, but does not work if they are. Is this a limitation of the Hough Transform itself, or is it just a problem with the minDist limit of the implementation?</p>

<p>Using the following parameters (I have fiddled extensively) on the following 2 images:</p>

<pre><code>Gray cannyThresh = new Gray(180);
Gray accumulatorThresh = new Gray(300);
int dp = 3;
double minDist = 0.0000001 //Ideally higher, but ok for illustrating this point

CircleF[] circles = gray.HoughCircles(cannyThresh, accumulatorThresh, dp, minDist, 0, 0)[0]
</code></pre>

<p>Offset inner circle (works fine):</p>

<p><img src=""https://i.stack.imgur.com/3mqDX.png"" alt=""offset inner circle""></p>

<p>Central inner circle (fails to detect outer circle properly, presumably because of the closeness of the centre to the inner circle?)</p>

<p><img src=""https://i.stack.imgur.com/0BFxx.png"" alt=""central inner circle""></p>

<p>Is there anything I can do to detect circles whether or not they share a similar centre?</p>
",2012-12-19 13:09:21,2016-06-15 17:19:36,Detecting concentric circles with Hough Circle Transform,<image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
2155,13002105,2012-10-21 20:53:06,,"<p>I have seen numerous examples and sample code for detecting emotions from a human face. I am in desperate need of some algorithm to change expressions. I am a new OpenCV learner. I am also confused if this image manipulation can be done using opencv ? Can functions such as warpaffine() be used for this ? If shall be grateful if someone can guide me in steps how to perform this eg. input a neutral face emotion and convert it to smile ?</p>
",,2013-03-30 17:14:22,Face Expression Change,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
2255,13009180,2012-10-22 10:10:29,,"<p>We have a large number of Images taken from a car for a project. To satisfy privacy norms, we need to detect faces &amp; License Plates and then blur those areas. I came to know of the Emgucv project, and the tutorial given at <a href=""http://www.emgu.com/wiki/index.php/License_Plate_Recognition_in_CSharp"" rel=""nofollow"">http://www.emgu.com/wiki/index.php/License_Plate_Recognition_in_CSharp</a> has been very useful to detect Licensplates. </p>

<p>Is there a way of blurring this region using Emgu itself?</p>
",,2012-10-22 15:09:00,How to blur part of an Image using EmguCV?,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
2289,15882944,2013-04-08 15:20:55,,"<p>I'm using EMGU CV for my project and I'm facing a weird problem.<br/>
I use cannyedges to find some squares in a photo.<br/>
This is working correctly. After that i want to take a pixel inside each square and use that to draw the border.<br/></p>

<p>The problem I'm facing is that i need the vertices of each corner in order to generate a random pixel.
To do this I use the code:</p>

<pre><code>PointF[] corners = rectangle.GetVertices();
float x = Math.Max(corners[1].X, corners[0].X);
float y = Math.Max(corners[1].Y, corners[2].Y);
float width = Math.Min(corners[2].X, corners[3].X) - x;
float height = Math.Min(corners[0].Y, corners[3].Y) - y;
</code></pre>

<p>The problem with this code is that rectangle.GetVertices(); gives a different order of corners each time.<br/>
The first rectangle returns bottomleft as corner 0, top left as corner 1 etc.<br/>
How ever the second rectangle returns bottomright as corner 0, bottomleft as corner 1  etc.<br/></p>

<p>I'm wondering if anyone else is having this problem and if anyone knows how to fix this?<br/><br/>
If you need more info to answer this problem please tell me.</p>
",,2013-09-16 17:04:42,EMGU CV MCvBox2D.GetVertices gives different order of corners,<c#><emgucv><rectangles>,,,CC BY-SA 3.0,False,False,True,False,False
2360,10091437,2012-04-10 15:14:01,,"<p>I'm trying to use Emgucv in c# to decompose a projection matrix into a rotation matrix, a translation matrix and a camera matrix. I could easily do it with RQ-Factorization but I couldn't find it by inspecting Emgucv API reference.</p>

<p>Since Emgucv is a opencv wrapper I search opencv functions and I've found the following c++ functions:</p>

<pre><code>void cvDecomposeProjectionMatrix(const CvMat *projMatrix, CvMat *cameraMatrix, 
     CvMat *rotMatrix, CvMat *transVect, CvMat *rotMatrX=NULL, CvMat *rotMatrY=NULL, 
     CvMat *rotMatrZ=NULL, CvPoint3D64f *eulerAngles=NULL)

void RQDecomp3x3(const Mat&amp; M, Mat&amp; R, Mat&amp; Q)
</code></pre>

<p>The question is: Is there any way I can use these functions with Emgucv?</p>
",2012-04-10 19:13:18,2012-04-11 00:35:56,Calling opencv through Emgucv,<c#><c++><opencv><emgucv><camera-calibration>,,,CC BY-SA 3.0,True,True,True,False,False
2395,11070463,2012-06-17 10:00:13,,"<p>I am trying to implement an edge detection method. Since it is impossible to copy here all lines I have copied just related codes. When I compile, I get this error:</p>

<blockquote>
  <p>Unable to cast object of type 'Emgu.CV.Structure.Gray' to type 'System.IConvertible'.</p>
</blockquote>

<p>I have already searched it but I couldn't find something useful.
Is there any way to convert MyImage from Gray to Double?</p>

<p>Thanks in advance</p>

<pre><code>Image&lt;Gray,Byte&gt; MyImage = null;
public Gray input_i(int x, int y, int z)
{
    Gray input;
    input = MyImage[x,y];
    return input;
}

result[I] += hueckel_func.HueckelDisk(point_x, point_y, I) * Convert.ToDouble(input_i(point_a, point_b, I));
</code></pre>
",2016-10-12 20:49:54,2016-10-12 20:49:54,Converting from gray to double not possible,<c#><casting><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
2442,11075314,2012-06-17 22:33:57,,"<p>i am trying to do a webcam stitch in real time with EMGUCV. Something similar to 
<a href=""http://www.youtube.com/watch?v=GH1p1HtNegY&amp;feature=related"" rel=""nofollow"">this setup on youtube</a>.
The problem is I am not getting a stitched video only images. </p>

<p>This is my code
`</p>

<pre><code>    public Form1()
    {
        InitializeComponent();
        capture1 = new Emgu.CV.Capture(0);
        this.capture1.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, 1920.0f);
        this.capture1.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, 1080.0f);
        capture2 = new Emgu.CV.Capture(1);
        this.capture2.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, 1920.0f);
        this.capture2.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, 1080.0f);

    }
    private void button1_Click(object sender, EventArgs e)
    {
        #region if capture is not created, create it now
        if (capture1 == null)
        {
            try
            {
                capture1 = new Emgu.CV.Capture(0);
                capture2 = new Emgu.CV.Capture(1);
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(excpt.Message);
            }
        }
        #endregion

        if (capture1 != null)
        {
            if (captureInProgress)
            {  //if camera is getting frames then stop the capture and set button Text
                // ""Start"" for resuming capture
                button1.Text = ""Start!""; //
                Application.Idle -= ProcessFrame;



            }
            else
            {
                //if camera is NOT getting frames then start the capture and set button
                // Text to ""Stop"" for pausing capture
                button1.Text = ""Stop"";
                Application.Idle += ProcessFrame;
            }

            captureInProgress = !captureInProgress;
        }
    }
    private void ProcessFrame(object sender, EventArgs arg)
    {
        Image&lt;Bgr, Byte&gt; ImageFrame = capture1.QueryFrame();
        camimageBox.Image = ImageFrame; //line 2
        Image&lt;Bgr, Byte&gt; ImageFrame2 = capture2.QueryFrame();
        imageBox1.Image = ImageFrame2;
    }

    private void ReleaseData()
    {
        if (capture1 != null)
            capture1.Dispose();
    }

    private void button2_Click(object sender, EventArgs e)
    {

        Image&lt;Bgr, byte&gt;[] frames2 = new Image&lt;Bgr, byte&gt;[2];
        //List&lt;Image&lt;Bgr, Byte&gt;&gt; frames2 = new List&lt;Image&lt;Bgr, byte&gt;&gt;();
        frames2[0] = capture1.QueryFrame();
        frames2[1] = capture2.QueryFrame();

        camimageBox.Image = frames2[0];
        imageBox1.Image = frames2[1];

        try
        {
            using (Stitcher stitcher = new Stitcher(true))
            //using (Stitcher stitcher = new Stitcher(true))
            {
                Image&lt;Bgr, Byte&gt; result = stitcher.Stitch(frames2);
                imageBox2.Image = result;
            }
        }
        finally
        {
            foreach (Image&lt;Bgr, Byte&gt; img in frames2)
            {
                img.Dispose();
            }

        }
    }
}
</code></pre>

<p>I am using Nvidia NVS 450 GPU. I am able to read the individual cameras as seperate streams. I was wondering if I could combine the streams together using EMGUCV to produce one stream (more like 2 webcams in a virtual webcam). </p>

<p>I am will be grateful for any help giving. PLS  mind my English!</p>
",2012-06-30 18:12:55,2012-06-30 18:12:55,Realtime Webcam video stitching with EmguCV,<c#><webcam><emgucv><image-stitching>,,,CC BY-SA 3.0,False,False,True,False,False
2448,9100811,2012-02-01 18:00:24,,"<p>I am developing an application that maps users eye movements with the cursor movements, hence developing ahands free cursor control system.</p>

<p>I am using Open CV library's .NET Wrapper for C# i.e. Emgu CV for development.</p>

<p>I am stuck at a point where I want to open a file/folder such that when a cursor is placed over a file/folder for say 3 to 5 seconds, the file/folder should open up or just perform a double-click event of a conventional mouse.</p>

<p>What could I use so as to solve this problem?</p>
",2012-02-02 08:40:41,2012-02-02 12:19:32,Double click timer event ,<c#><.net><winforms><emgucv><eye-tracking>,,,CC BY-SA 3.0,False,False,True,False,False
2483,14944253,2013-02-18 19:56:01,,"<p>I'm trying to convert <a href=""https://stackoverflow.com/a/10242156/130993"">this snippet of code</a> in Emgu CV using C#. I think I converted most of the thing in what they are supposed to be in EmguCV but the cvKMeans2 keeps shooting me Exception that doesn't make sense.</p>

<p>Here is my code:</p>

<pre><code>Image&lt;Bgr, float&gt; src = new Image&lt;Bgr, float&gt;(""c:\\blanc.jpg"");
         Matrix&lt;Single&gt; samples = new Matrix&lt;Single&gt;(src.Rows * src.Cols, 3);
         for (int y = 0; y &lt; src.Rows; y++)
         {
            for (int x = 0; x &lt; src.Cols; x++)
            {
               for( int z = 0; z &lt; 3; z++)
               {
                  if(z == 0)
                     samples[y + x * src.Rows, z] = Convert.ToSingle(src[y, x].Blue);
                  else if(z == 1)
                     samples[y + x * src.Rows, z] = Convert.ToSingle(src[y, x].Green);
                  else if (z == 2)
                     samples[y + x * src.Rows, z] = Convert.ToSingle(src[y, x].Red);
               }
            }
         }

         MCvTermCriteria term = new MCvTermCriteria(10000, 0.0001); 
         term.type = TERMCRIT.CV_TERMCRIT_ITER | TERMCRIT.CV_TERMCRIT_EPS;

         int clusterCount = 3;
         Matrix&lt;Int32&gt; labels = new Matrix&lt;Int32&gt;(src.Width, 1);
         int attempts = 5;
         Matrix&lt;Single&gt; centers = new Matrix&lt;Single&gt;(clusterCount, samples.Cols);
         CvInvoke.cvKMeans2(samples, clusterCount, labels, term, attempts, IntPtr.Zero, KMeansInitType.PPCenters, centers, IntPtr.Zero );

         Image&lt;Bgr, float&gt; new_image = new Image&lt;Bgr, float&gt;(src.Size);

         for (int y = 0; y &lt; src.Rows; y++)
         {
            for (int x = 0; x &lt; src.Cols; x++)
            { 
               //nTotal++;
               int cluster_idx = labels[y + x * src.Rows, 0];

               float n1 = centers[cluster_idx, 0];
               float n2 = centers[cluster_idx, 1];
               float n3 = centers[cluster_idx, 2];

               MCvScalar sca = new MCvScalar(n1, n2, n3);
               CvInvoke.cvSet2D(new_image, y, x, sca);
            }
         }

         CvInvoke.cvShowImage( ""clustered image"", new_image );
         CvInvoke.cvWaitKey( 0 );
</code></pre>

<p>I keep receiving this exception:</p>

<blockquote>
  <p>Additional information: OpenCV: labels.isContinuous() &amp;&amp; labels.type()
  == CV_32S &amp;&amp; (labels.cols == 1 || labels.rows == 1) &amp;&amp; labels.cols + labels.rows - 1 == data.rows</p>
</blockquote>

<p>It doesn't make sense that the label needs to be of Single type because I need to use it as an index in the loop just after the cvKMeans2. Can anyone help me get this code working? If this code works, there is big chance that we will buy a commercial license of Emgu to use in our software.</p>

<p>Thanks!</p>

<p><strong><em>EDIT</em></strong></p>

<p>Based on the answer below, I've adapted my code and got it working like this:</p>

<pre><code>Image&lt;Bgr, float&gt; src = new Image&lt;Bgr, float&gt;(@""C:\\test.png"");
            Matrix&lt;float&gt; samples = new Matrix&lt;float&gt;(src.Rows * src.Cols, 1, 3);
            Matrix&lt;int&gt; finalClusters = new Matrix&lt;int&gt;(src.Rows * src.Cols, 1);

            for (int y = 0; y &lt; src.Rows; y++)
            {
                for (int x = 0; x &lt; src.Cols; x++)
                {
                    samples.Data[y + x * src.Rows, 0] = (float)src[y, x].Blue;
                    samples.Data[y + x * src.Rows, 1] = (float)src[y, x].Green;
                    samples.Data[y + x * src.Rows, 2] = (float)src[y, x].Red;
                }
            }

            MCvTermCriteria term = new MCvTermCriteria(10000, 0.0001);
            term.type = TERMCRIT.CV_TERMCRIT_ITER | TERMCRIT.CV_TERMCRIT_EPS;

            int clusterCount = 3;
            int attempts = 5;
            Matrix&lt;Single&gt; centers = new Matrix&lt;Single&gt;(clusterCount, samples.Cols, 3);
            CvInvoke.cvKMeans2(samples, clusterCount, finalClusters, term, attempts, IntPtr.Zero, KMeansInitType.PPCenters, centers, IntPtr.Zero);

            Image&lt;Bgr, Byte&gt; new_image = new Image&lt;Bgr, Byte&gt;(src.Size);

            for (int y = 0; y &lt; src.Rows; y++)
            {
                for (int x = 0; x &lt; src.Cols; x++)
                {
                    int cluster_idx = finalClusters[y + x * src.Rows, 0];
                    MCvScalar sca1 = CvInvoke.cvGet2D(centers, cluster_idx, 0);
                    Bgr color = new Bgr(sca1.v0, sca1.v1, sca1.v2);

                    PointF p = new PointF(x, y);
                    new_image.Draw(new CircleF(p, 1.0f), color, 1);
                }
            }

            CvInvoke.cvShowImage(""clustered image"", new_image);
            CvInvoke.cvWaitKey(0);
</code></pre>
",2017-05-23 12:00:49,2016-08-19 04:23:45,Exception using cvKMeans2 in EmguCV,<c#><.net><opencv><emgucv><k-means>,,,CC BY-SA 3.0,True,False,True,False,False
2525,11081467,2012-06-18 11:02:41,,"<p>I'm trying to save the value of each pixel in a gray scale image into a text file. For example, if a pixel location (x, y) has a value of 255 (pure white), an 255 will be saved in the correspondent coordinate in a text file. </p>

<p>Here's my code. It's a WinForm applicaton in Emgu CV 2.4.0, MSFT Visual Studio 2010 and MSFT .NET 4.0 on an x86 machine.</p>

<pre><code>OpenFileDialog OpenFile = new OpenFileDialog();//open an image file.
        if (OpenFile.ShowDialog() == DialogResult.OK)
        {
            Image&lt;Bgr, Byte&gt; My_Image = new Image&lt;Bgr, byte&gt;(OpenFile.FileName);//Read the file as an Emgu.CV.Structure.Image object.
            Image&lt;Gray, Byte&gt; MyImageGray = new Image&lt;Gray, Byte&gt;(My_Image.Width, My_Image.Height);//Initiate an Image object to receive the gray scaled image. 
            CvInvoke.cvCvtColor(My_Image.Ptr, MyImageGray.Ptr, COLOR_CONVERSION.CV_RGB2GRAY);//convert the BGR image to gray scale and save it in MyImageGray
            CvInvoke.cvNamedWindow(""Gray"");
            CvInvoke.cvShowImage(""Gray"", MyImageGray.Ptr);
            StreamWriter writer = File.CreateText(""test.txt"");//Initiate the text file writer
            Gray pixel;
            //try to iterate through all the image pixels.
            for (int i = 0; i &lt; MyImageGray.Height; i++)
            {
                for (int j = 0; j &lt; MyImageGray.Width; j++)
                {
                    pixel = MyImageGray[j, i];
                    Console.WriteLine(string.Format(""Writing column {0}"", j));//debug output
                    writer.Write(string.Format(""{0} "",pixel.Intensity));
                }
                writer.WriteLine();
            }
        }
</code></pre>

<p>I tried to run it but for some reason, it got stuck after i=0 and j=MyImageGray.Width-1. It should go to process the next row but the whole Visual Studio 2010 and the application froze. By froze I mean the window of my application can not be moved and the cursor in the VS can not move either. I have to kill the application by pressing Shift+F5. Meanwhile, I got a ""A first chance exception of type 'Emgu.CV.Util.CvException' occurred in Emgu.CV.dll"" when I'm reading the (0, 414) pixel. Actually the debug message looks like: </p>

<pre><code>Writing column 413
WritinA first chance exception of type 'Emgu.CV.Util.CvException' occurred in     Emgu.CV.dll
g column 414
Writing column 415
</code></pre>

<p>I tried to put a break point at i=MyImageGray.Width-1 and the program seems to freeze before it hit the break point.
I really don't know what's wrong in my approach. Any idea would be appreciated and I'm happy to provide more info upon request. Thanks ahead!</p>
",,2012-06-28 13:40:46,Accessing and output the gray scale of each pixel using Emgu CV,<c#><visual-studio-2010><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
2538,10105907,2012-04-11 12:28:50,,"<p>I'm using EmguCV wrapper for OpenCV and I'm trying to do uncalibrated rectification via fundamental matrix.</p>

<p>I've found image points with FindChessboardCorners function,from both cameras, and then I would like to find fundamental matrix, but I have problem passing parameters to function  <a href=""http://www.emgu.com/wiki/files/2.0.0.0/html/215e547a-75d0-7e82-36db-bbc144cd9e22.htm"" rel=""nofollow"">eCvInvoke.cvFindFundamentalMat()</a> CvInvoke.cvFindFundamentalMat() </p>

<p>What bothers me is the array of 2D points, just can't get the right format to pass it to OpenCv function cvFindFundamentalMat.</p>

<p>As I've understood EmguCV/OpenCV openCv expects one dimensional array of type CvMat, passed through IntPtr...
But even when I do so, OpenCV throws an error message ""OpenCV: Either the number of channels or columns or rows must be =1""</p>

<pre><code>PointsF[] points1 = Camera1.Points;
PointF[] points2 = Camera2.Points

Matrix&lt;float&gt; points1 = new Matrix&lt;float&gt; (1, Camera1.ImagePoints[0].Length*2, 1);
for (int i =0; i &lt;  Camera1.ImagePoints[0].Length-1; i+=2)
{
      points1[0, i] = Camera1.ImagePoints[0][i].X;
      points1[0, i+1] = Camera1.ImagePoints[0][i].Y;
 }

Matrix&lt;float&gt; points2= new Matrix&lt;float&gt;(1, Camera2.ImagePoints[0].Length * 2, 1);
for (int i = 0; i &lt; Camera2.ImagePoints[0].Length-1; i+=2)
{
      points1[0, i] = Camera2.ImagePoints[0][i].X;
      points1[0, i+1] = Camera2.ImagePoints[0][i].Y;
}

IntPtr points1Matrix = Marshal.AllocHGlobal(StructSize.MCvMat);
GCHandle handlePoints1Ptr = GCHandle.Alloc(points1.MCvMat, GCHandleType.Pinned);
points1Matrix = handlePoints1Ptr.AddrOfPinnedObject();

IntPtr points2Matrix = Marshal.AllocHGlobal(StructSize.MCvMat);
GCHandle handlePoints2Ptr = GCHandle.Alloc(points2.MCvMat, GCHandleType.Pinned);
points2Matrix = handlePoints2Ptr.AddrOfPinnedObject();

_fundamentalMatrix = new Matrix&lt;double&gt;(3, 3, 1);

CvInvoke.cvFindFundamentalMat(points1Matrix, points2Matrix, _fundamentalMatrix.Ptr, CV_FM.CV_FM_RANSAC, 1.0, 0.99, IntPtr.Zero);
</code></pre>

<p>What am I doing wrong? </p>
",2014-07-15 09:45:53,2014-07-15 09:45:53,EmguCV FindFundamentalMat - input params,<c#><image-processing><opencv><emgucv><camera-calibration>,,,CC BY-SA 3.0,True,False,True,False,False
2564,12060877,2012-08-21 18:27:51,,"<p>I am using Mono for Android and followed the instructions mentioned on this page: <a href=""http://file.emgu.com/wiki/index.php/Emgu_CV_for_Android"" rel=""nofollow noreferrer"">http://file.emgu.com/wiki/index.php/Emgu_CV_for_Android</a> but when I run the application on the emulator, it throws the following exception:</p>

<blockquote>
  <p>Java.Lang.UnsatisfiedLinkError has been thrown Cannot load library:
  find_library[1199]:    37 'libopencv_highgui.so' failed to load
  previously</p>
  
  <p>Java.Lang.UnsatisfiedLinkError: Cannot load library:
  find_library[1199]:    37 'libopencv_highgui.so' failed to load
  previously   at Android.Runtime.JNIEnv.CallStaticVoidMethod (IntPtr
  jclass, IntPtr jmethod, Android.Runtime.JValue[] parms) [0x00023] in
  /Users/builder/data/lanes/monodroid-mac-monodroid-4.2.4-branch/9f7cbd60/source/monodroid/src/Mono.Android/src/Runtime/JNIEnv.g.cs:973</p>
  
  <p>at Java.Lang.JavaSystem.LoadLibrary (System.String libName)
  [0x00034] in
  /Users/builder/data/lanes/monodroid-mac-monodroid-4.2.4-branch/9f7cbd60/source/monodroid/src/Mono.Android/platforms/android-15/src/generated/Java.Lang.JavaSystem.cs:253</p>
  
  <p>at Emgu.CV.CvInvoke..cctor () [0x00000] in :0</p>
  
  <p>--- End of managed exception stack trace ---</p>
  
  <p>java.lang.UnsatisfiedLinkError: Cannot load library:
  find_library[1199]:    37 'libopencv_highgui.so' failed to load
  previously</p>

<pre><code>  at java.lang.Runtime.loadLibrary(Runtime.java:370)

  at java.lang.System.loadLibrary(System.java:535)

  at
</code></pre>
  
  <p>mono.android.view.View_OnClickListenerImplementor.n_onClick(Native
  Method)</p>

<pre><code>  at
</code></pre>
  
  <p>mono.android.view.View_OnClickListenerImplementor.onClick(View_OnClickListenerImplementor.java:29)</p>

<pre><code>  at android.view.View.performClick(View.java:3511)

  at android.view.View$PerformClick.run(View.java:14105)

  at android.os.Handler.handleCallback(Handler.java:605)

  at android.os.Handler.dispatchMessage(Handler.java:92)

  at android.os.Looper.loop(Looper.java:137)

  at android.app.ActivityThread.main(ActivityThread.java:4424)

  at java.lang.reflect.Method.invokeNative(Native Method)

  at java.lang.reflect.Method.invoke(Method.java:511)

  at
</code></pre>
  
  <p>com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:784)</p>

<pre><code>  at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:551)

  at dalvik.system.NativeStart.main(Native Method)
</code></pre>
</blockquote>

<p>Here is a screenshot of OpenCV-2.4.2 reference<br>
<img src=""https://i.imgur.com/zV5pf.jpg"" alt=""Reference Screenshot""></p>
",,2013-03-27 00:52:15,Emgu CV for Android throwing Exception Java.Lang.UnsatisfiedLinkError,<opencv><xamarin.android><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
2636,12070411,2012-08-22 09:44:55,,"<p>I'm new to image processing, but I'm using EMGU for C# image analysis. However, I know the homography matrix isn't unique to EMGU, and so perhaps someone with knowledge of another language can explain better.</p>

<p>Please (in as simplified as can be) can someone explain what each element does. I've looked this up online but can't find an answer that I can properly understand (as I said, I'm kinda new to all this!)</p>

<p>I analyse 2 images, both 2 dimensional. Therefore a 3x3 matrix is needed to account for the rotation / translation of the image. If no movement is detected, the homography matrix is:
100,
010,
001</p>

<p>I know from research (eg <a href=""https://stackoverflow.com/questions/9275567/opencv-homography-transform-a-point-what-is-this-code-doing"">OpenCV Homography, Transform a point, what is this code doing?</a>) that:
10Tx,
01Ty,
XXX </p>

<p>The 10,01 bit is the rotation of the x and y coordinates. The Tx and Ty bits are the translational movement, but what is the XXX bit? This is what I don't understand? Is it something to do with affine transformations? Please can someone explain:
1. If I'm currently right in what I say above.
2. what the XXX bit means</p>
",2018-07-20 09:20:52,2019-06-18 20:20:16,What do the elements in a homography matrix mean?,<matrix><emgucv><homography>,,,CC BY-SA 3.0,True,False,True,False,False
2801,15934961,2013-04-10 19:42:12,,"<p>Using Visual Basic 2008 and Emgu CV, I can capture the stream of a webcam on my PC. <strong>What I want to do is connect to an IP camera, knowing its URL, using Capture = New Capture().</strong> </p>

<p>Here is the code I have:</p>

<pre><code>Imports Emgu.CV
Imports Emgu.CV.Util
Imports Emgu.CV.Structure

Public Class Form1

Dim capturez As Capture = New Capture(""rtsp://[IP Address]/mpeg4/media.amp"")

Private Sub Timer1_Tick(ByVal sender As System.Object, ByVal e As System.EventArgs) Handles Timer1.Tick

    Dim imagez As Image(Of Bgr, Byte) = capturez.QueryFrame()
    PictureBox1.Image = imagez.ToBitmap()

End Sub

End Class
</code></pre>

<p>I get the following error: <em>Unable to create capture from rtsp://[IP Address]/mpeg4/media.amp</em></p>

<p>Is it possible to do this using Capture = New Capture? If not, is their any other method?</p>

<p>Thanks.</p>
",,2017-05-15 13:39:43,Connect to IP Camera Using Emgu CV's Capture = New Capture(),<vb.net><ip-address><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
2811,11110985,2012-06-19 23:36:32,,"<p>So I am trying to develop a WPF app that will allow me to turn off the auto zoom and auto focus abilities of my webcam. I'm using the Emgu c# wrapper for opencv and want to be able to do frame differencing without my camera auto focusing when an object comes into the screen. </p>

<p>I have tried looking for an sdk that would allow me to develop something like this but apparently logitech ditched theirs a couple of years ago. I am using an HD pro Webcam c920. I have heard that maybe you can use the dll's that shipped with it to tweak the options but I have no idea how to do this. </p>

<p>Any help would be awesome.</p>
",2017-08-14 07:18:04,2017-08-14 07:18:04,Interfacing with a webcam,<c#><focus><zoom><webcam><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
2870,9142609,2012-02-04 16:58:41,,"<p>I have written simple program to open image and show image in VS 2010 in C# using EmguCV but I am getting the following exception:</p>

<blockquote>
  <p>The type initializer for 'Emgu.CV.CvInvoke' threw an exception.</p>
</blockquote>

<p>at line <code>Image&lt;Bgr, Byte&gt; myimg = new Image&lt;Bgr, Byte&gt;(openfile.FileName);</code></p>

<p>here is my code..</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.Util;
using Emgu.CV.Structure;

namespace imgdisplay2
{
    public partial class Form1 : Form
    {
        public Form1()
        {
            InitializeComponent();
        }

        private void imageBox1_Click(object sender, EventArgs e)
        {
        }

        private void button1_Click(object sender, EventArgs e)  
        {
            OpenFileDialog openfile = new OpenFileDialog();
            if (openfile.ShowDialog() == DialogResult.OK)
            {
                // imageBox1 =new Emgu.CV.UI.ImageBox() ;
                Image&lt;Bgr, Byte&gt; myimg = new Image&lt;Bgr, Byte&gt;(openfile.FileName);
                pictureBox1.Image = myimg.ToBitmap();
                //imageBox1.Image =myimg ;
            }  
        }

        private void pictureBox1_Click(object sender, EventArgs e)
        {
        }
    }
}
</code></pre>
",2012-02-05 09:21:47,2013-12-06 21:15:29,The type initializer for 'Emgu.CV.CvInvoke' threw an exception,<c#><image><exception><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
2873,15940663,2013-04-11 04:15:27,,"<p>I calibrated my camera and found the intrinsic parameters(K). Also I have calculated the Fundamental Matrix (F).</p>

<p>Now E= K_T* F * K . So far so good.</p>

<p>Now we pass the Essential Matrix(E) to the SVD to use the decomposition values (U,W,V) to extract the Rotation and Translation:</p>

<pre><code> essentialMatrix = K.Transpose().Mul(fund).Mul(K);
 CvInvoke.cvSVD(essentialMatrix, wMatrix, uMatrix, vMatrix, Emgu.CV.CvEnum.SVD_TYPE.CV_SVD_DEFAULT);
</code></pre>

<p>** Question) At this point, two methods have been proposed, and it has confused me which one really give out the right answer- specifically for Translation:</p>

<p>At first method <a href=""http://www.eecis.udel.edu/~cer/arv/readings/old_mkss.pdf"" rel=""noreferrer"">enter link description here</a> the author suggests to compute the R,T as following:  </p>

<p><img src=""https://i.stack.imgur.com/oaTuk.png"" alt=""enter image description here""></p>

<p>But in Second method [<a href=""http://isit.u-clermont1.fr/~ab/Classes/DIKU-3DCV2/Handouts/Lecture16.pdf]"" rel=""noreferrer"">http://isit.u-clermont1.fr/~ab/Classes/DIKU-3DCV2/Handouts/Lecture16.pdf]</a> the author provides another formula for T which is +U , -U as shown below:  </p>

<p><img src=""https://i.stack.imgur.com/crBMt.png"" alt=""enter image description here""></p>

<p>I am implementing this on C# .Net using openCv libraries. Anybody knows which Translation Formula is the right one?</p>
",2013-04-11 18:27:47,2015-01-19 20:25:33,Correct way to extract Translation from Essential Matrix through SVD,<opencv><emgucv><svd><opencvsharp>,,,CC BY-SA 3.0,True,False,True,False,False
2890,10143272,2012-04-13 14:59:56,,"<p>I trying to make an array of webcams using th capture class but It does not build.
I am not sure how it can be done. I have search and search and seen nothing. The aim of the code is to take video frames in realtime from 2 webcams and stitch them in realtime using EMGUcv I am guessing in can be done in opencv. Please if you have any other options I willing to explore them</p>

<pre><code>    public partial class StitchingMainForm : Form
   {
       //declaring global variables
       Capture[] cap= new Capture[2];//takes images from cameras as image frames
       private bool captureInProgress;

      public StitchingMainForm()
      {
         InitializeComponent();
      }

      private void selectImagesButton_Click(object sender, EventArgs e)
      {
          Capture[] cap = new Capture[2];
         if (cap!= null)

         {
            sourceImageDataGridView.Rows.Clear();

            Image&lt;Bgr, Byte&gt;[] sourceImages = new Image&lt;Bgr, byte&gt;[cap.Length];

            for (int i = 0; i &lt; sourceImages.Length; i++)
            {
               sourceImages[i] = new Image&lt;Bgr, byte&gt;(cap.[i]);

               using (Image&lt;Bgr, byte&gt; thumbnail = sourceImages[i].Resize(200, 200, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC, true))
               {
                  DataGridViewRow row = sourceImageDataGridView.Rows[sourceImageDataGridView.Rows.Add()];
                  row.Cells[""FileNameColumn""].Value = cap.[i];
                  row.Cells[""ThumbnailColumn""].Value = thumbnail.ToBitmap();
                  row.Height = 200;
               }
            }

i want to display the captured frames on seperate rows and see the final image after stitching. 

 1. Cannot apply indexing with [] to an expression of type 'method group'
 2. (40,34): error CS1502: The best overloaded method match for              Emgu.CV.Image&lt;Emgu.CV.Structure.Bgr,byte&gt;.Image(byte[*,*,*])' has some invalid arguments
 3. (40,55): error CS1503: Argument 1: cannot convert from 'method group' to 'byte[*,*,*]'
 4. (45,55): error CS0021: Cannot apply indexing with [] to an expression of type   'method group'





Thanks
</code></pre>
",2012-05-02 11:09:16,2012-05-02 11:09:16,Making an Array of webcams using capture,<c#><arrays><webcam><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
2934,10144527,2012-04-13 16:15:13,,"<p><strong>Summary:</strong></p>

<p>I'm trying to get video from IP camera in emgu, I could display video in the browser from an ip like ""<a href=""http://169.254.255.253"" rel=""nofollow noreferrer"">http://169.254.255.253</a>"".</p>

<p><strong>Question:</strong></p>

<p>How could I display this from emgu?</p>
",2019-10-18 17:08:09,2019-10-18 17:08:09,how to get video from ip camera using emgucv,<emgucv><ip-camera>,,,CC BY-SA 4.0,False,False,True,False,False
2962,9150963,2012-02-05 16:41:47,,"<p>I am wondering if there is anyway to trigger a click/double click event at the place where the cursor is hovering?</p>

<p>I am using c# and emgu CV for my application.</p>
",2012-02-05 17:19:12,2012-02-05 17:19:12,How to programmatically make a click happen at the co-ordinates the cursor is pointing to?,<c#><.net><winforms><mouseevent><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3006,14032048,2012-12-25 15:48:30,,"<p>I am working with Face Recognition. I need to compute Eigenvector and Eigenvalue from a matrix. I am using C sharp . Is there any library for Eigenvector and Eigenvalue computation. I think Emgu CV has no function for Eigenvector and Eigenvalue computaion. I am new so I don't know well . I need a library for Eigenvector and Eigenvalue computaion for C Sharp. Please help me.</p>
",,2014-08-29 16:01:28,Library for Eigenvector and Eigenvalue computation in C Sharp,<emgucv><eigenvector><eigenvalue>,,,CC BY-SA 3.0,False,False,True,False,False
3032,11130530,2012-06-21 01:47:56,,"<p>I am using <strong>Emgu.CV</strong> library for object detection and 
worrying if it is possible to save my <strong>.bmp</strong> image as a frame to <strong>.AVI</strong> with this library.
I found VideoWriter class but pls give some examples or links.</p>

<p>I appreciate any ideas and give marks^^</p>
",2012-06-21 05:51:41,2012-12-08 11:50:29,Emgu.CV to make an .avi,<c#><emgucv><avi>,,,CC BY-SA 3.0,False,False,True,False,False
3110,9160339,2012-02-06 12:47:51,,"<p>As I mentioned in <a href=""https://stackoverflow.com/questions/9100811/double-click-timer-event"">this</a> question, I am trying to implement a feature in my app whereby placing a cursor over some point for a while (say 3-5 seconds) triggers a double-click event. Based on the answers provided in that thread, I wrote the following. This code is not working as expected. Can someone please help?</p>

<pre><code>    #region Timer Mouse Double Click event

    timer.Elapsed += new ElapsedEventHandler(timer_Elapsed);

    //Here, the timer for Timer click event will start when mouse hovers over an area
    private void form_MouseHover(object sender, System.EventArgs e)
    {
        timer.Start();
    }

    private void form_MouseLeave(object sender, System.EventArgs e)
    {
        timer.Stop();
    }

    void timer_Elapsed(object sender, ElapsedEventArgs e)
    {
        timer.Stop();
        DoubleClickEvent();
    }

    //This method allows the user to click a file/folder by hovering/keeping still the mouse for specified time
    void DoubleClickEvent()
    {

        DoClickMouse(0x2);      // Left mouse button down
        DoClickMouse(0x4);      // Left mouse button up
    }

    static void DoClickMouse(int mouseButton)
    {
        var input = new INPUT()
        {
            dwType = 0, // Mouse input
            mi = new MOUSEINPUT() { dwFlags = mouseButton }
        };

        if (SendInput(1, input, Marshal.SizeOf(input)) == 0)
        {
            throw new Exception();
        }
    }
    [StructLayout(LayoutKind.Sequential)]
    struct MOUSEINPUT
    {
        int dx;
        int dy;
        int mouseData;
        public int dwFlags;
        int time;
        IntPtr dwExtraInfo;
    }
    struct INPUT
    {
        public uint dwType;
        public MOUSEINPUT mi;
    }
    [DllImport(""user32.dll"", SetLastError = true)]
    static extern uint SendInput(uint cInputs, INPUT input, int size);

    #endregion
</code></pre>
",2017-05-23 12:03:52,2013-07-06 02:06:48,Implementing double click event using timer,<c#><.net><winforms><mouseevent><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3151,15006179,2013-02-21 15:37:09,,"<p>I need to know how to properly dispose of Bitmaps so that I don't have a memory leak.
I am grabbing video in a BackgroundWorker and assigning it to a PictureBox as such:</p>

<pre><code>private void bwVideo_ReadCamera(object sender, DoWorkEventArgs e)
{
  Bitmap temp = null;
  while (true)
  {
    Image&lt;Bgr, Byte&gt; frame = logitec.QueryFrame();
    if (temp != null)
      temp.Dispose();
    temp = frame.ToBitmap();
    pictureBox2.Image = temp;
   }
}
</code></pre>

<p>The problem is that I still get a ""Out of Memory Exception"" with this code.  I have tried freeing the pictureBox2.Image variable by using a BackgroundWorker ReportProgress and waiting in the above code for the dispose to finish (you need to be synched with the gui to call dispose on the PictureBox image).  I have also tried to use the ""Bitmap"" property of the Image class which shares data between the Image and Bitmap.</p>

<p>So my questions is, in this situation, what is the proper way to dispose of my image?</p>
",2013-02-21 15:58:48,2013-02-21 16:15:02,Disposing of Bitmaps used in background thread,<c#><multithreading><bitmap><dispose><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3216,12122033,2012-08-25 12:37:22,,"<p>I'm a newer in computer vision field.</p>

<p>I found some code examples in EmguCV(.NET wrapper for OpenCV)  which I`m trying to use.</p>

<p>Currently I'm working on triangle traffic sign recognition and I'm using cvMatchShapes function.</p>

<p>The function returns ""zero"" in ideal case, it means that the shapes are the same and the number is</p>

<p>close to zero if shapes are similar.</p>

<p>The problem is that in my case function returns me result which is out of logic.
when function compares triangle with the circle, it returns figure which is less than figure, got
after comparing two triangles.</p>

<p>Here is the function that I use and the images: </p>

<pre><code>                double ratio = CvInvoke.cvMatchShapes(modelSignTraffic, trafficSign, Emgu.CV.CvEnum.CONTOURS_MATCH_TYPE.CV_CONTOURS_MATCH_I3, 0);
</code></pre>

<p>modelSignTraffic - is a template.
In my case it is -</p>

<p><img src=""https://i.stack.imgur.com/ymFhP.jpg"" alt=""enter image description here""></p>

<p>trafficSign - is an shape that should be compared to the template.</p>

<p>first compared shape-</p>

<p><img src=""https://i.stack.imgur.com/viW1C.png"" alt=""enter image description here""></p>

<p>second compared shape-</p>

<p><img src=""https://i.stack.imgur.com/OG4vl.png"" alt=""enter image description here""></p>

<p>For the first shape I get ratio 0.55 and for the second shape I get ratio 0.61 .</p>

<p>I would be very grateful if anybody could explain why do I get such illogical result and how  I can fix 
it?</p>

<p>Thank you in advance.</p>
",2012-08-25 14:29:32,2012-09-07 05:50:22,cvMatchShapes returns me result which is out of logic,<image-processing><opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
3233,9173186,2012-02-07 08:38:52,,"<p>I am currently working on face detection WPF Application using Emgu CV and Kinect for Windows SDK v1. I ever made same application before with Emgu CV, but using a web cam to capture the image frame. Using a web cam, it's not difficult to get the camera frame and convert it to type of Image&lt;> in Emgu CV so that I could process it with face detection algorithm. But now, when I use color RGB camera form Kinect hardware, i can't do that. Neither implicit nor explicit conversion from type of ImageColorFrame (in Kinect for Windows SDK) to type of Image&lt;> (in Emgu CV) are not working. How i could do that?</p>

<p>FYI, instead of doing a conversion, I also try to assign bytes property of type Image&lt;> like this code below. But it's not working too. Thanks in advance.</p>

<pre><code>using (ColorImageFrame colorFrame = e.OpenColorImageFrame())
        {
            if (colorFrame == null)
            {
                return;
            }

            byte[] pixels = new byte[colorFrame.PixelDataLength];
            colorFrame.CopyPixelDataTo(pixels);

            nextFrame = new Image&lt;Bgr, byte&gt;(448, 336);
            nextFrame.Bytes = pixels;
            using (nextFrame.Bitmap = colorFrame.ToBitmap())
            {
                grayImage = new Image&lt;Gray, byte&gt;(448, 336);
                grayImage = nextFrame.Convert&lt;Gray, Byte&gt;();
                HaarCascade faceHaarCascade = new HaarCascade("""" + Environment.CurrentDirectory + ""\\haarcascade_frontalface_alt_tree.xml"");

                MCvAvgComp[][] facesDetected = grayImage.DetectHaarCascade(
                   faceHaarCascade,
                   1.1,
                   10,
                   Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                   new System.Drawing.Size(20, 20));

                foreach (MCvAvgComp face in facesDetected[0])
                {
                    // draw rectangle in the facial image
                    nextFrame.Draw(face.rect, new Bgr(System.Drawing.Color.Blue), 2);
                }
                imageVideoRGB.Source = ToBitmapSource(nextFrame);
            }
        }
</code></pre>
",,2013-04-22 20:33:38,How to convert type of ImageColorFrame in Kinect for Windows SDK v1 to type of Image<> in Emgu Cv?,<wpf><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3279,10175441,2012-04-16 13:51:47,,"<p>How can I save an Emgu <code>Image&lt;Bgr, Byte&gt; frame</code> in a memory stream as JPEG?</p>
",,2017-02-11 10:50:27,"How to save an Emgu `Image<Bgr, Byte> frame` in a memory stream as JPEG?",<opencv><computer-vision><emgucv><opencvdotnet>,,,CC BY-SA 3.0,True,False,True,False,False
3294,15015540,2013-02-22 01:50:04,,"<p>I have a multi-cast UDP Video stream that I need my OPenCV (Emgu ) 2.4.x app to capture and process (""client""). </p>

<p>On the client, I can capture the stream using VLC (udp://xx.yy.zz.aaa:1234, However the my app fails to capture this udp stream. My code is quite simple (</p>

<pre><code>Capture cap = new Capture (""udp://@212.1.1.1:1234"");
</code></pre>

<p>p.s. I have tried with and 2/o the @ also tried rtp on that address. No luck :-/</p>

<p>Does OpenCV directly allow ""capture"" of UDP streams? or do I need to run VLC on the client to re-stream the video as rtp or http or some other....?</p>

<p>Thanks.</p>
",2013-02-22 04:07:05,2013-03-01 17:16:18,Capturing a Multicast UDP Video stream using OpenCV,<opencv><udp><video-streaming><video-capture><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
3315,12130491,2012-08-26 13:25:04,,"<p>Where can I find the source code for 'cvextern.dll' of Emgu OpenCV?</p>

<p>Thank you.</p>
",,2016-05-08 21:52:39,Where is the source code of 'cvextern.dll' of Emgu OpenCV?,<opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
3320,11155119,2012-06-22 11:14:31,,"<p>I have found a problem when I use the method getCols() of type Matrix.
Check this piece of code:</p>

<p>let suppose that size of orig is [1000, 384] and numFeat is = 50;</p>

<pre><code>private Matrix&lt;float&gt; ComputePCA(Matrix&lt;float&gt; orig, int numFeat)
    {
        Matrix&lt;float&gt; avg = new Matrix&lt;float&gt;(1, orig.Cols);
        Matrix&lt;float&gt; eigval = new Matrix&lt;float&gt;(orig.Cols, 1);
        Matrix&lt;float&gt; eigvec = new Matrix&lt;float&gt;(orig.Cols, orig.Cols);
        Matrix&lt;float&gt; featMat = new Matrix&lt;float&gt;(orig.Rows, numFeat);

        CvInvoke.cvCalcPCA(masterMat, avg, eigval, eigvec, Emgu.CV.CvEnum.PCA_TYPE.CV_PCA_DATA_AS_ROW);

        Matrix&lt;float&gt; choosenAutovec = new Matrix&lt;float&gt;(orig.Cols, numFeat);

        choosenAutovec = eigvec.GetCols(0, numFeat - 1);

        featMat = choosenAutovec.Transpose() * orig.Transpose();

        return featMat.Transpose();
    }
</code></pre>

<p>after eigvec.GetCols I suppose to have a variable choosenAutovec of size [384, 50] right? But I get a matrix [384, 384] instead... Any suggestions to take just the first 50 cols?</p>

<p>Thanks.</p>
",,2013-04-11 14:15:01,emgu Matrix<float>.getCols,<c#><matrix><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3329,15979356,2013-04-12 19:26:06,,"<p>I'm studying Image Processing and i need to make gaussian noise in c# with emgu cv.
i find the code</p>
<blockquote>
<p>Mat gaussian_noise = img.clone();</p>
<p>randn(gaussian_noise,128,30);</p>
</blockquote>
<p>is make gaussian noise in open cv.
what is the traslate code in emgu cv?</p>
",2020-06-20 09:12:55,2013-04-12 20:23:14,translate gaussian noise in opencv to emgu cv,<c#><opencv><noise><emgucv>,2013-04-12 20:49:56,,CC BY-SA 3.0,True,True,True,False,False
3344,13108511,2012-10-28 11:43:50,,"<p>I got stuck with Access violation exception in managed code. Histogram pointer is not null and everything seems ok. Got example of creating IntPtr's from <a href=""http://www.emgu.com/forum/viewtopic.php?f=8&amp;t=59"" rel=""nofollow"">http://www.emgu.com/forum/viewtopic.php?f=8&amp;t=59</a></p>

<pre><code>// initializing data
var random = new Random();
var array = new double[1000];
for (int i = 0; i &lt; 1000; i++)
{
    array[i] = random.NextDouble();
}
var arrayPtr = GetDataPtr(array);

//initializing ranges array
double[] rangesArray = { 0, 1 };
var rangesArrayPtr = GetRangesArrayPtr(rangesArray);
//creating and querying histogram
var histogramStructure = CvInvoke.cvCreateHist(1, new[] {20}, HIST_TYPE.CV_HIST_ARRAY, rangesArrayPtr, true);
var histogram = CvInvoke.cvMakeHistHeaderForArray(1, new[] { 20 }, histogramStructure, arrayPtr, rangesArrayPtr, 1);
CvInvoke.cvNormalizeHist(histogram, 1.0);
CvInvoke.cvQueryHistValue_1D(histogram, 0); // getting exception here
</code></pre>

<p>help methods</p>

<pre><code>private static IntPtr[] GetRangesArrayPtr(double[] array)
{
    var ranges = new IntPtr[1];
    ranges[0] = Marshal.AllocHGlobal(array.Length * sizeof(double));
    Marshal.Copy(array, 0, ranges[0], array.Length);
    return ranges;
}
private static IntPtr GetDataPtr(double[] array)
{
    var ranges = new IntPtr();
    ranges = Marshal.AllocHGlobal(array.Length * sizeof(double));
    Marshal.Copy(array, 0, ranges,array.Length);
    return ranges;
}
</code></pre>
",2012-10-28 11:47:21,2015-04-20 12:19:03,Acess violation exception emguCV cvQueryHistValue,<c#><opencv><access-violation><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
3354,15982176,2013-04-12 23:00:38,,"<p>I 'm working on project, part of it stitching images using Emgu.cv; Asking the user to import images. Once user presses ""Stitching"" button, the images must stitcing &amp; displayed as one image using the pictureBox, but instead of that, an error appeared:</p>

<p><a href=""http://img203.imageshack.us/img203/9943/77522160.png"" rel=""nofollow"">Error Image</a></p>

<p>I try Vb instead of c# following this tutorial : <a href=""http://www.youtube.com/watch?v=Lk37LR50viw"" rel=""nofollow"">http://www.youtube.com/watch?v=Lk37LR50viw</a>
but the project isn't built.   </p>

<p>the c# code in the button :</p>

<pre><code>        Stitcher x = new Stitcher(false);

        Image&lt;Bgr, Byte&gt; result = x.Stitch(images);
        imageBox.Image = result.ToBitmap();
</code></pre>

<p>While images is:</p>

<pre><code>    Image&lt;Bgr, Byte&gt;[] images = new Image&lt;Bgr, Byte&gt;[9];
</code></pre>

<p>that all the imported images are stored:</p>

<pre><code>        private void importbuofd_FileOk(object sender, CancelEventArgs e)
    {

        switch (x)
        {
            case 1: pictureBox1.ImageLocation = importbuofd.FileName; x = x + 1; images[0] = new Image&lt;Bgr, Byte&gt;(new Bitmap(pictureBox1.Image)); count++; break;
            case 2:  pictureBox2.ImageLocation = importbuofd.FileName; x = x + 1; images[1] = new Image&lt;Bgr, Byte&gt;(new Bitmap(pictureBox2.Image)); count++; break;
            case 3: pictureBox3.ImageLocation = importbuofd.FileName; x = x + 1; images[2] = new Image&lt;Bgr, Byte&gt;(new Bitmap(pictureBox3.Image)); count++; break;
            case 4: pictureBox4.ImageLocation = importbuofd.FileName; x = x + 1; images[3] = new Image&lt;Bgr, Byte&gt;(new Bitmap(pictureBox4.Image)); count++; break;
            case 5: pictureBox5.ImageLocation = importbuofd.FileName; x = x + 1; images[4] = new Image&lt;Bgr, Byte&gt;(new Bitmap(pictureBox5.Image)); count++; break;
            case 6: pictureBox6.ImageLocation = importbuofd.FileName; x = x + 1; images[5] = new Image&lt;Bgr, Byte&gt;(new Bitmap(pictureBox6.Image)); count++; break;
            case 7: pictureBox7.ImageLocation = importbuofd.FileName; x = x + 1; images[6] = new Image&lt;Bgr, Byte&gt;(new Bitmap(pictureBox7.Image)); count++; break;
            case 8:pictureBox8.ImageLocation = importbuofd.FileName; x = x + 1; images[7] = new Image&lt;Bgr, Byte&gt;(new Bitmap(pictureBox8.Image)); count++; break;
            case 9: pictureBox9.ImageLocation = importbuofd.FileName; x = x + 1; images[8] = new Image&lt;Bgr, Byte&gt;(new Bitmap(pictureBox9.Image)); count++; break;
            default: MessageBox.Show(""Sorry, This is the maximum number You can import""); break;

        }
    }
</code></pre>

<p>What shall I do?!</p>
",,2013-06-19 17:24:21,Stiching Images Emgu.cv exception,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3369,11159740,2012-06-22 15:51:10,,"<p>As you can see in <a href=""http://social.msdn.microsoft.com/Forums/getfile/124973"" rel=""nofollow"">the link</a>, I have two elements: first is <em>image</em> element which is taken from camera (using EmguCV) and the other one is <em>viewport3d</em> which renders 3d object. I also include 2d object (see the rectangle).</p>

<p>When I run my program I see <a href=""http://social.msdn.microsoft.com/Forums/getfile/124977"" rel=""nofollow"">this</a>.</p>

<p>Yes indeed, the object (hand) will be ordered in front of the image.</p>

<p>The question is how to order 2d/3d object behind the hand object? Is it possible to do it using single camera? Just like <a href=""http://www.youtube.com/watch?v=DRU6Ns0tBpQ"" rel=""nofollow"">this one</a>.</p>

<p>Thanks in advance for your answers.</p>
",2012-06-22 18:27:04,2012-06-26 06:21:17,Ordering 2d/3d object behind other element,<wpf><opencv><wpf-controls><emgucv><viewport3d>,,,CC BY-SA 3.0,True,False,True,False,False
3379,12134139,2012-08-26 21:41:52,,"<p>I compare two similar shapes with help of cvMatchShapes() function.</p>

<pre><code>  result  =  CvInvoke.cvMatchShapes(shapeA, shapeB, Emgu.CV.CvEnum.CONTOURS_MATCH_TYPE.CV_CONTOURS_MATCH_I3, 0);
</code></pre>

<p>But I get the result relatively large, 2.3 .</p>

<p>When I compare two <strong>same</strong> shapes: </p>

<pre><code>result  =  CvInvoke.cvMatchShapes(shapeA, shapeB, Emgu.CV.CvEnum.CONTOURS_MATCH_TYPE.CV_CONTOURS_MATCH_I3, 0);
</code></pre>

<p>I get result 1.25. (as I understand in this case I have to get result ~0)</p>

<p>Any idea why function returns such unexpected results?</p>

<p>Thank you in advance.</p>
",,2012-08-26 21:41:52,cvMatchShapes function returns strange results,<image-processing><opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
3383,15024488,2013-02-22 12:41:41,,"<p>I'm in the process of converting my application that was using an old OpenCV wrapper to EmguCV (updated and very good wrapper).</p>

<p>So far so good, except that in one of my class, I was using 3 trackbars to adjust the threshold in some filters. The trackbar were created using this code in the old wrapper which is exactly how it's created in openCV C++</p>

<pre><code>cvlib.cvCreateTrackbar(""minH"", ""Couleur"", ref dValueMin, 256, new cvlib.CvTrackbarDelegate(onTrackbarSlide));
</code></pre>

<p>The trackbar was creating using the HighGui of OpenCV ans the trackbar were visible on the
I'm pretty sure that Emgu team remove this from the wrapper and replace it with something better but I can't find anything about this in the documentation. Can anybody suggest me how to achieve that?</p>

<p>Thanks!</p>

<p>P.S: I have googled this and all the question were unanswered... I hope to have more luck here on Stack Overflow.</p>
",,2013-07-12 18:05:50,Is cvCreateTrackbar available in emguCV?,<c#><opencv><wrapper><emgucv><trackbar>,,,CC BY-SA 3.0,True,False,True,False,False
3407,10187145,2012-04-17 07:43:04,,"<p>I have a simple Winforms app that allows users to select multiple videos (files) simultaneously and runs background workers threads to loop through each of the videos in the BW. Have pasted code below, I get a NullReferenceException as ""Unable to create capture from ..."" at this line</p>

<pre><code>Capture _capture = new Capture(videoFileName) 
</code></pre>

<p>in processVideo method.</p>

<p>N.B: The same code work fine if I select a <strong>single</strong> video. So some issue with the multiple instances of Capture class. </p>

<p>I would expect the ProcessVideo method to have new instance of Capture and open it separately. Any ideas on what I might be doing wrong?</p>

<pre><code>    private void openVideoToolStripMenuItem_Click(object sender, EventArgs e)
        {
            try
            {
                OpenFileDialog ofd = new OpenFileDialog();
                ofd.Filter = ""Video | *.AVI;*.MPEG;*.WMV;*.MP4;*.MOV;*.MPG;*.MPEG;*.MTS;*.FLV"";
                ofd.Multiselect = true;
                if (ofd.ShowDialog() == System.Windows.Forms.DialogResult.OK)
                {
                    string[] videos = ofd.FileNames;
                    if (videos != null)
                    {

                        BackgroundWorker[] bw = new BackgroundWorker[videos.GetLength(0)];
                        int n = 0;
                        foreach (string video in videos)
                        {
                            bw[n] = new BackgroundWorker();
                            bw[n].DoWork += new DoWorkEventHandler(bw_DoWork);
                            bw[n++].RunWorkerAsync(video);
                        }
                    }
                }
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(excpt.Message);
            }

        }


        void bw_DoWork(object sender, DoWorkEventArgs e)
        {
            string filename = (string)e.Argument;
            ProcessVideo(filename);
        }


       private void ProcessVideo(string videoFileName)
        {

            Capture _capture = new Capture(videoFileName);
             UInt64 TOTAL_FRAMES = Convert.ToUInt64(_capture.GetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_COUNT));
                for (UInt64 n = 0; n &lt; TOTAL_FRAMES; n++)
                {
                    using (Image&lt;Bgr, Byte&gt; img1 = _capture.QueryFrame())
                    {

//do something with the frame

                }
        }

}
</code></pre>
",2012-04-17 08:20:50,2012-04-17 09:23:25,Capture class (Emgu) issue in multiple background worker threads,<c#><multithreading><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3410,12135940,2012-08-27 03:31:44,,"<p>So in my spare time I like to try and automate various games through computer vision techniques.  Normally template matching with filters and pixel detection works fine with me.  However, I recently decided to try my hand at navigating through a level by using feature matching.  What I intended was to save a filtered image of an entire explored map.
<img src=""https://i.imgur.com/jvHLlh.png"" alt=""FullMap""></p>

<p>Then to copy the Minimap from the screen every few seconds and filter it in the same manner and use Surf to match it to my full map which should hopefully give me a players current location (center of the match would be where the player is on the map). A good example of this working as intended is below(full map with found match on left, right is mini map image.
<img src=""https://i.imgur.com/SnUjIh.png"" alt=""GoodMatch""></p>

<p>What I am having trouble with is the Surf Matching in the EMGU library seems to find incorrect matches in many cases.
<img src=""https://i.imgur.com/xgASIh.png"" alt=""BadMatch"">
<img src=""https://i.imgur.com/LGMoqh.png"" alt=""BadMatch2""></p>

<p>Sometimes its not completely bad like below:
<img src=""https://i.imgur.com/4fVwkh.png"" alt=""WonkyMatch""></p>

<p>I can kind of see whats happening is that its finding better matches for the keypoints in different locations on the map since Surf is supposed to be scale invariant.  I don't know enough about the EMGU library or Surf to limit it so that it only accepts matches like the initial good one and either throws away these bad matches, or to tune it so those wonky matches are good ones instead.</p>

<p>I am using the new 2.4 EMGU code base and my code for the SURF matching is below.  I would really like to get it to the point so that it only returns matches that are always the same size(scaled ratio of normal minimap size to what it would be on the full map) so that I don't get some crazy shaped matches.</p>

<pre><code>public Point MinimapMatch(Bitmap Minimap, Bitmap FullMap)
    {
        Image&lt;Gray, Byte&gt; modelImage = new Image&lt;Gray, byte&gt;(Minimap);
        Image&lt;Gray, Byte&gt; observedImage = new Image&lt;Gray, byte&gt;(FullMap);     
        HomographyMatrix homography = null;

        SURFDetector surfCPU = new SURFDetector(100, false);
        VectorOfKeyPoint modelKeyPoints;
        VectorOfKeyPoint observedKeyPoints;
        Matrix&lt;int&gt; indices;

        Matrix&lt;byte&gt; mask;
        int k = 6;
        double uniquenessThreshold = 0.9;
        try
        {
            //extract features from the object image
            modelKeyPoints = surfCPU.DetectKeyPointsRaw(modelImage, null);
            Matrix&lt;float&gt; modelDescriptors = surfCPU.ComputeDescriptorsRaw(modelImage, null, modelKeyPoints);

            // extract features from the observed image
            observedKeyPoints = surfCPU.DetectKeyPointsRaw(observedImage, null);
            Matrix&lt;float&gt; observedDescriptors = surfCPU.ComputeDescriptorsRaw(observedImage, null, observedKeyPoints);
            BruteForceMatcher&lt;float&gt; matcher = new BruteForceMatcher&lt;float&gt;(DistanceType.L2);
            matcher.Add(modelDescriptors);

            indices = new Matrix&lt;int&gt;(observedDescriptors.Rows, k);
            using (Matrix&lt;float&gt; dist = new Matrix&lt;float&gt;(observedDescriptors.Rows, k))
            {
                matcher.KnnMatch(observedDescriptors, indices, dist, k, null);
                mask = new Matrix&lt;byte&gt;(dist.Rows, 1);
                mask.SetValue(255);
                Features2DToolbox.VoteForUniqueness(dist, uniquenessThreshold, mask);
            }

            int nonZeroCount = CvInvoke.cvCountNonZero(mask);
            if (nonZeroCount &gt;= 4)
            {
                nonZeroCount = Features2DToolbox.VoteForSizeAndOrientation(modelKeyPoints, observedKeyPoints, indices, mask, 1.5, 20);
                if (nonZeroCount &gt;= 4)
                    homography = Features2DToolbox.GetHomographyMatrixFromMatchedFeatures(modelKeyPoints, observedKeyPoints, indices, mask, 2);
            }

            if (homography != null)
            {  //draw a rectangle along the projected model
                Rectangle rect = modelImage.ROI;
                PointF[] pts = new PointF[] { 
                new PointF(rect.Left, rect.Bottom),
                new PointF(rect.Right, rect.Bottom),
                new PointF(rect.Right, rect.Top),
                new PointF(rect.Left, rect.Top)};
                homography.ProjectPoints(pts);
                Array.ConvertAll&lt;PointF, Point&gt;(pts, Point.Round);

                Image&lt;Bgr, Byte&gt; result = Features2DToolbox.DrawMatches(modelImage, modelKeyPoints, observedImage, observedKeyPoints, indices, new Bgr(255, 255, 255), new Bgr(255, 255, 255), mask, Features2DToolbox.KeypointDrawType.DEFAULT);
                result.DrawPolyline(Array.ConvertAll&lt;PointF, Point&gt;(pts, Point.Round), true, new Bgr(Color.Red), 5);                  

                return new Point(Convert.ToInt32((pts[0].X + pts[1].X) / 2), Convert.ToInt32((pts[0].Y + pts[3].Y) / 2));
            }


        }
        catch (Exception e)
        {
            return new Point(0, 0);
        }


     return new Point(0,0);
  }
</code></pre>
",,2012-08-29 08:31:24,Surf Feature detection/matching issues in EMGU 2.4,<c#><image-processing><opencv><emgucv><surf>,,,CC BY-SA 3.0,True,False,True,False,False
3464,15989760,2013-04-13 15:59:32,,"<p>I have gray Bitmap image.</p>

<pre><code>       Image&lt;Gray, byte&gt; cannyImage = new Image&lt;Gray, byte&gt;(pathImg);
       Bitmap drawImg = cannyImage.ToBitmap();
</code></pre>

<p>I want to draw on this image some shape :</p>

<pre><code>    Graphics g = Graphics.FromImage(drawImg);
    g.DrawLines(new Pen(Color.Purple), shapes[0].sample.pointsArray);
</code></pre>

<p>In last row of the code I get this error:</p>

<p><strong>A Graphics object cannot be created from an image that has an indexed pixel format.</strong></p>

<p>Any idea how can I draw colored shapes on gray Bitmap image?
Thank you in advance!</p>
",,2013-04-16 01:24:36,How can I draw colored shapes on gray Bitmap image?,<.net><opencv><graphics><bitmap><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
3471,15030377,2013-02-22 17:59:44,,"<p><strong>Hello everybody,</strong>
I works on a face detection and recognizing project with EmguCv in C#, so i already do some steps:
-detect front face and left face
-recognize faces</p>

<p><em>but the problem</em> it when i want to detect right side of face it didn't work because the classifier profileface.xml just work for left side, i found some ideas for do a mirror but i have no idea how to do it.</p>

<p>so plz plz if some one have any idea to do it i will be very happy.</p>

<p>Mohammed Hassar.    </p>
",,2013-02-22 20:20:34,Right side Face detection with EmguCv,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
3479,10192552,2012-04-17 13:49:48,,"<p>I'm trying to do calibration of Kinect camera and external camera, with Emgu/OpenCV. 
I'm stuck and I would really appreciate any help.</p>

<p>I've choose do this via fundamental matrix, i.e. epipolar geometry. 
But the result is not as I've expected. Result images are black, or have no sense at all. 
Mapx and mapy points are usually all equal to infinite or - infinite, or all equals to 0.00, and rarely have regular values. </p>

<p>This is how I tried to do rectification: </p>

<p>1.) <strong>Find image points</strong>  get two arrays of  image points (one for every camera) from set of images. I've done this with chessboard  and FindChessboardCorners function.</p>

<p>2.)  <strong>Find fundamental matrix</strong> </p>

<pre><code> CvInvoke.cvFindFundamentalMat(points1Matrix, points2Matrix, 
_fundamentalMatrix.Ptr, CV_FM.CV_FM_RANSAC,1.0, 0.99, IntPtr.Zero);
</code></pre>

<p>Do I pass all collected points from whole set of images, or just from two images trying to rectify? </p>

<p>3.) <strong>Find homography matrices</strong> </p>

<pre><code> CvInvoke.cvStereoRectifyUncalibrated(points11Matrix, points21Matrix, 
_fundamentalMatrix.Ptr, Size, h1.Ptr, h2.Ptr, threshold);
</code></pre>

<p>4.) <strong>Get mapx and mapy</strong> </p>

<pre><code>double scale = 0.02;
CvInvoke.cvInvert(_M1.Ptr, _iM.Ptr, SOLVE_METHOD.CV_LU);

CvInvoke.cvMul(_H1.Ptr, _M1.Ptr, _R1.Ptr,scale);
CvInvoke.cvMul(_iM.Ptr, _R1.Ptr, _R1.Ptr, scale);
CvInvoke.cvInvert(_M2.Ptr, _iM.Ptr, SOLVE_METHOD.CV_LU);
CvInvoke.cvMul(_H2.Ptr, _M2.Ptr, _R2.Ptr, scale);
CvInvoke.cvMul(_iM.Ptr, _R2.Ptr, _R2.Ptr, scale);

CvInvoke.cvInitUndistortRectifyMap(_M1.Ptr,_D1.Ptr, _R1.Ptr, _M1.Ptr, 
mapxLeft.Ptr, mapyLeft.Ptr) ;
</code></pre>

<p>I have a problem here...since I'm not using calibrated images, what is my camera matrix and distortion coefficients ? How can I get it from fundamental matrix or homography matrices? </p>

<p>5.) <strong>Remap</strong>  </p>

<pre><code>CvInvoke.cvRemap(src.Ptr, destRight.Ptr, mapxRight, mapyRight, 
(int)INTER.CV_INTER_LINEAR, new MCvScalar(255));
</code></pre>

<p>And this doesn't returning good result. I would appreciate if someone would tell me what am I doing wrong. </p>

<p>I have set of 25 pairs of images, and chessboard pattern size 9x6. </p>
",2013-12-22 10:08:44,2020-06-03 00:58:11,"Rectification of uncalibrated cameras, via fundamental matrix",<image-processing><opencv><emgucv><camera-calibration>,,,CC BY-SA 3.0,True,False,True,False,False
3493,10192645,2012-04-17 13:55:15,,"<p>I am writing a C# web camera application using Emgu CV. I tried to handle when user unplug the web cam during frame capturing in pictureBox.<br>
If the web camera is unplugged, then the application should start scanning for new web cam connectivity every 2 seconds until the pictureBox can be updated again.<br>
The following timer code could not catch anything, the program initially captures frames, I unplug the camera, then plug back, but the camera can not be restart. </p>

<pre><code>private void timer1_Tick(object sender, EventArgs e)
    {

        if (cap == null)
        {
            try
            {
                cap = new Capture(0);
                cap.SetCaptureProperty(CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, 320);
                cap.SetCaptureProperty(CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, 240);

                Console.WriteLine(""Restarting Cam"");
            }
            catch (Exception ee){ 
                Console.WriteLine(""null""); cap = null;  return; 
            }
        }
        else
        {
            Console.WriteLine(""NO null"");
        }

        try
        {
            Image&lt;Bgr, byte&gt; nextFrame = cap.QueryFrame();
        }
        catch(Exception ee)
        {
            Console.WriteLine(""Frame Capture fail"");
            cap.Dispose();
            cap = null;
            return;
        }
        using (Image&lt;Bgr, byte&gt; nextFrame = cap.QueryFrame())
        {
            if (nextFrame != null)
            {
                Image&lt;Gray, byte&gt; grayframe = nextFrame.Convert&lt;Gray, byte&gt;();
                videoBox.Image = nextFrame.ToBitmap();
            }
        }
    }
</code></pre>

<p>The program keep printing ""No null"", 20 second after unplugging the camera, the output console printed out The thread '' (0xb96c) has exited with code 0 (0x0) </p>
",2013-05-24 14:01:01,2017-03-04 19:01:44,Emgu CV check web cam connectivity,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3553,15997277,2013-04-14 08:48:37,,"<p>I cannot use the <code>SURFDetector</code> object, because the program crashes.</p>

<p>I'm using the version 2.4.9 of Emgu (downloaded form <a href=""http://sourceforge.net/projects/emgucv/files/emgucv/2.4.9-alpha/"" rel=""nofollow"">here</a>), and I've followed the instructions about adding the OpenCV dependencies (<a href=""http://www.emgu.com/wiki/index.php/Download_And_Installation#Have_you_copied_the_OpenCV_dlls_to_the_execution_directory.3F"" rel=""nofollow"">link</a>):</p>

<blockquote>
  <p>For EMGU CV version >=2.4 cudart64_42_9.dll, cvextern.dll, npp64_42_9.dll, opencv_calib3dXXX.dll, opencv_contribXXX.dll, opencv_coreXXX.dll, opencv_features2dXXX.dll, opencv_flannXXX.dll, opencv_highguiXXX.dll, opencv_imgprocXXX.dll, opencv_legacyXXX.dll, opencv_mlXXX.dll, opencv_nonfreXXX.dll, opencv_objectdetectXXX.dll, opencv_videoXXX.dll, where XXX is the OpenCV version number. </p>
</blockquote>

<p>I also added referencies to <code>Emgu.CV.dll</code>, <code>Emgu.Util.dll</code> and <code>Emgu.CV.UI</code>. In order to try to resolve the problem, I tried to add also <code>Emgu.CV.GPU.dll</code> and <code>opencv_gpuXXX.dll</code>, wit no success.</p>

<p>I'm working on a 64-bit PC, with Windows 7 installed, but my project is built for x86, and I'm using the dependencies for x86 architectures. Before using the <code>SURFDetector</code> object, everything worked fine.</p>

<p>The crash happens when the program reaches the following line:</p>

<pre><code>SURFDetector surfCPU = new SURFDetector(500, false);
</code></pre>

<p>The program throws two kind of exceptions (yes, two), and I cannot realize why it throws one rather than the other:</p>

<ol>
<li>System.Reflection.TargetInvocationException in mscorlib.dll</li>
<li>System.DllNotFoundException in Emgu.CV.dll (impossible to load
the 'cvextern' DLL), with a strange error code (HRESULT: 0x8007007E)</li>
</ol>

<p>In both cases, VisualStudio 2012 opens a new tab, called ""Source not available"" or something like that (I'm not sure about the exactly words used by the english version of VisualStudio, because I'm using the italian one).</p>

<p>EDIT: I want to add to the foregoing, that the executable file of the example provided with the library, called SURFFeature, works perfectly...</p>
",2013-04-14 08:56:40,2013-04-14 08:56:40,Crash when use SURFDetector in EmguCv,<c#><crash><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
3576,10199451,2012-04-17 21:28:38,,"<p>I can save a jpeg 2000 image file by following</p>

<pre><code>Image&lt;Bgr, byte&gt; img; img.Save(""photo.jp2"");
</code></pre>

<p>How can I convert Emgu CV Image to jpeg 2000 then store to an byte array</p>
",2014-01-09 07:39:43,2014-01-09 07:39:43,Convert Emgu CV Image to jpeg 2000 then store to an byte array,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3579,15998172,2013-04-14 10:42:45,,"<p>I want to train a neural network in order to classify different classes of grayscale images.</p>

<p>As input of this network, I want to use the features extracted by the SURF-128 algorithm. The following code (a semplification of the <a href=""http://www.emgu.com/wiki/index.php/SURF_feature_detector_in_CSharp"" rel=""nofollow noreferrer"">example provided with EmguCV library</a>) shows how I use the API:</p>

<pre><code>SURFDetector surfCPU = new SURFDetector(500, true);
VectorOfKeyPoint observedKeyPoints;

BriefDescriptorExtractor descriptor = new BriefDescriptorExtractor();

observedKeyPoints = surfCPU.DetectKeyPointsRaw(img, null);
Matrix&lt;Byte&gt; observedDescriptors = descriptor.ComputeDescriptorsRaw(img, null, observedKeyPoints);
</code></pre>

<p>By using the following code:</p>

<pre><code>observedDescriptors.Save(@""SURF.bmp"");
</code></pre>

<p>I can save some results. The following image shows that the above code extracts features with different sizes (on the right, there are the results saved with the previous line of code):</p>

<p><img src=""https://i.stack.imgur.com/geGo9.png"" alt=""Image tests""></p>

<p>What I want is to obtain a vector with a fixed size.</p>

<p>How can I transform a generic grayscale image in a 128-dimensional array, using the API provided by the EmguCV library for C#?</p>
",2013-04-15 15:15:40,2013-04-15 15:21:35,SURF features in EmguCv: how to extract a fixed number of features,<c#><emgucv><surf>,,,CC BY-SA 3.0,False,False,True,False,False
3590,9200236,2012-02-08 19:40:18,,"<p>I want to get all pixels coordinates that have same color as one pixel</p>

<pre><code>List&lt;cv::Point&gt; GetAllPixels(cv::Point x)
{
//imp
}
</code></pre>

<p>How can I do this in EmguCV or OpenCV?</p>
",2012-02-08 20:27:27,2012-07-01 11:25:10,Get all pixels coordinates that have same color,<c#><image-processing><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
3618,11179809,2012-06-24 17:52:43,,"<p>I use surf in emgu cv lib to detect and recgnize my object i need to insert 3d model in the place of this object i have the homography matrix what i want to know is how to get modelview matrix of sharpgl from this homography matrix .i want steps that can result me the correct modelview matrix where i can place the 3d object
any answer will help me 
thanks in advance</p>
",,2012-06-26 14:47:21,determine correct place using homography matrix (AR),<c#><augmented-reality><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3653,12157859,2012-08-28 11:00:35,,"<p>I want to make a video player with detection of objects using Emgu CV. I'd like to start with reading from a video source file and that is where I got an error. In line:</p>

<pre><code>Capture capture = new Capture(@""C:/Users/Paul/Desktop/Film/parrot.avi"");
</code></pre>

<p>there is an exception:</p>

<blockquote>
  <p>An unhandled exception of type 'System.NullReferenceException' occurred in Emgu.CV.dll<br>
  Additional information: Unable to create capture from <code>C:/Users/Paul/Desktop/Film/parrot.avi</code></p>
</blockquote>

<p>I have tried many combinations and different source types like AVI, WMV, MPEG and still got the exception. What can I do to make it work?</p>
",2012-09-11 13:13:48,2016-10-04 10:57:00,Video Player using Emgu CV,<c#><video><video-capture><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3655,15045295,2013-02-23 20:29:25,,"<p>I Need fastest way to iterate an EmguCV bitmap matrix and set pixel. i found this after google but it takes about 3 sec for 700x500 image:</p>

<p>Documents says that access (get) data matrix is just o(1) but its not clearly declare about set data.</p>

<pre>
<code>

    for(int i = 0; i &lt; img.Rows ; i++)

        for(int j = 0; j &lt; img.Cols; j++){

            img.Data[x,y,0] = 255;

            img.Data[x,y,1] = 255;

            img.Data[x,y,2] = 255;

        }

</code>
</pre>

<p>Thanks in advance.</p>
",,2017-12-06 08:07:39,EMGUCV fastest set pixel,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3708,14089609,2012-12-30 09:12:23,,"<p>Hi I am learning Emgu CV. I would like to perform alpha blend(addWeighted). I have the following codes</p>

<pre><code>Image&lt;Bgr, Byte&gt; image = new Image&lt;Bgr, Byte&gt;(filename);
Image&lt;Gray, Byte&gt; grayImage = image.Convert&lt;Gray, Byte&gt;();
Image&lt;Bgr, Byte&gt; blendImage;
</code></pre>

<p>How to alpha blend these two images? (Bgr and Gray)</p>
",2012-12-30 09:50:39,2013-04-11 14:39:21,Alpha Blending in Emgu CV,<alphablending><emgucv><computer-vision>,,,CC BY-SA 3.0,False,False,True,False,False
3721,9214854,2012-02-09 16:34:15,,"<p>Could anyone share their code for calculating the PGH (Pairwise Geometric Histogram) similarity ? I need to find the most similar object from within a list of images. </p>

<p>I have written up the following code, but the results make no sense. I'd bet I am doing a silly error, and I am stuck.</p>

<p>Any suggestions?</p>

<pre><code> public double GetBestPGHMatch(Contour&lt;Point&gt; currContour, List&lt;Contour&lt;Point&gt;&gt; ContoursList)
    {
        double match = -1.0d;
        DenseHistogram histCurrContour = new DenseHistogram(
                                                       new int[2]
                                                                {
                                                                    currContour.Total,
                                                                    currContour.Total,
                                                                },
                                                        new RangeF[2]
                                                                {
                                                                    new RangeF(0, 100),
                                                                    new RangeF(0, 100)
                                                                }
                                                   );

        CvInvoke.cvCalcPGH(currContour.Ptr, histCurrContour.Ptr);
        foreach (Contour&lt;Point&gt; contour in ContoursList)
        {
            DenseHistogram hist = new DenseHistogram(
                                              new int[2]
                                                                {
                                                                    currContour.Total,
                                                                    currContour.Total,
                                                                },
                                                new RangeF[2]
                                                                {
                                                                    new RangeF(0, 100),
                                                                    new RangeF(0, 100)
                                                                }
                                          );

            CvInvoke.cvCalcPGH(contour.Ptr, hist.Ptr);
            double c = CvInvoke.cvCompareHist(histCurrContour.Ptr, hist.Ptr, Emgu.CV.CvEnum.HISTOGRAM_COMP_METHOD.CV_COMP_CORREL);
            if (c &gt; match) match = c;
        }

        return match;
    }
</code></pre>
",,2012-03-07 15:57:39,PGH using OpenCV (Emgu),<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
3762,11193314,2012-06-25 16:28:41,,"<p>I am working in a project where each user has a big avatar and a thumbnail of this avatar. The avatar is 150x215 and the thumbnail is 50x50. To generate the thumbnail, the user selects a square area inside the avatar and the system crops and resizes the avatar to generate the thumbnail.</p>

<p>Now I need to have a 70x70 thumbnail. I cannot resize the 50x50 thumbnail because it does not look nice. My idea was to create a tool to find the thumbnail inside the avatar and, using the thumbnail location, generate the new 70x70 image. It was working well until I notice that some thumbnails are not only cropped, they are resized. When the image is resized it loses pixels what makes a pixel-by-pixel comparison impossible (so I can't detect the thumbnail location inside the avatar).</p>

<p>Is there any way to identify where the thumbnail is located(even though it is resized)? I am using <a href=""http://www.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow"">EMGU</a> to handle the images.</p>

<p>Thanks for any help</p>
",2012-06-27 18:57:42,2012-06-27 18:57:42,Locate a resized subimage inside an image,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
3877,10227487,2012-04-19 11:54:55,,"<p>I want to use Opencv 2.4.0 (beta2) together with EmguCV and MonoDevelop on my Mac OS X Lion system. But I failed to compile the OpenCV 2.4.0 by Cmake and it shows lacking of some dylib files of highgui.</p>

<p>Anybody can tell me the whole configuration and process to compile OpenCV 2.4.0 in Mac OS X? Thanks.</p>
",,2012-05-04 13:21:49,How to compile OpenCV 2.4.0 (beta2) by Cmake on Mac OS X Lion?,<macos><image-processing><opencv><cmake><computer-vision>,,,CC BY-SA 3.0,True,False,True,False,False
4039,14122121,2013-01-02 12:33:23,,"<p><strong>Objective:</strong> I want to count <img src=""https://i.stack.imgur.com/uzioi.jpg"" alt=""enter image description here""> from image below.</p>

<p><img src=""https://i.stack.imgur.com/XfQBq.jpg"" alt=""enter image description here""></p>

<p>What are the ideas can work here?</p>

<p>I tried <code>FindContour()</code>. It returns boundary. Further I need to use those contour points.Using matchShape() and Contour.slice() is not helping.. Any working example for this case will be very helpful.</p>

<p>Any help will be appreciated.</p>
",2013-01-02 12:40:59,2013-01-02 13:12:52,How to segment a part of any object for counting purpose as per given binary image?,<c#><image-processing><computer-vision><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
4049,12193642,2012-08-30 09:19:22,,"<p>I found a similar question: <a href=""https://stackoverflow.com/questions/4905893/creating-histogram-using-emgu-cv-c-sharp"">creating histogram using emgu cv c#</a><br />
and it works well when i passed grayscaled images, but when i use the Matrix, program throws exceptions. my code:</p>

<pre><code>Matrix&lt;double&gt; mat = new Matrix&lt;double&gt;(10, 10);
mat.SetRandUniform(new MCvScalar(0.0), new MCvScalar(20.0));
DenseHistogram histo = new DenseHistogram(5, new RangeF(0.0f, 20.0f));
histo.Calculate(new Matrix&lt;double&gt;[] { mat }, false, null);//&lt;--throws exception here
CvInvoke.cvShowImage(""Mat Histogram"", histo.GetHistogramImage().Ptr);
CvInvoke.cvWaitKey(0);
</code></pre>

<p>and the declaration in emgu doc is:</p>

<pre><code>public void Calculate&lt;TDepth&gt;(
    Matrix&lt;TDepth&gt;[] matrices,
    bool accumulate,
    Matrix&lt;byte&gt; mask
)
where TDepth : new()
</code></pre>

<p>i cant figure out what's wrong :(</p>
",2017-05-23 11:44:49,2012-08-30 13:44:42,emgu Calculate histogram with matrices,<c#><.net><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
4073,14124293,2013-01-02 15:08:27,,"<p>I having a problem on given green rectangle on the picture.jpg when the picture with 5 people in there. I'm using emguCV v2.2
here the code for the button when i click and fire it.</p>

<pre><code>Image InputImg = Image.FromFile(@""C:\img\Picture.jpg""); 
Image&lt;Bgr,byte&gt; ImageFrame = new Image&lt;Bgr,byte&gt;(new Bitmap(InputImg));

Image&lt;Gray, byte&gt; grayframe = ImageFrame.Convert&lt;Gray, byte&gt;();
 var faces =  grayframe.DetectHaarCascade(haar, 1.4, 4,
                                    HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                                    new Size(25, 25))[0];
foreach (var face in faces)
            {
                ImageFrame.Draw(face.rect, new Bgr(Color.Green), 3);
            }
CamImageBox.Image = ImageFrame;
</code></pre>

<p>I expected it should return me the picture.jpg with green rectangle on each faces. But it doesn't . May i know why? is any mistake here?</p>

<p>Thanks</p>
",,2017-09-13 09:30:23,faceDetection EmguCV,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
4126,13170952,2012-11-01 04:27:09,,"<p>I'm building an image processing application using Emgu CV (for x64) and I want to use the filtering functions on images. So, I use <code>opencv_imgproc.dll</code> but it throws  <a href=""http://msdn.microsoft.com/en-us/library/system.badimageformatexception.aspx"" rel=""nofollow""><code>BadImageFormatException</code></a>  </p>

<pre class=""lang-none prettyprint-override""><code>Solution Platform : x86 
Operating System : Windows 7 - 64
Language: C# 
IDE: Visual C# 2010 express 
</code></pre>
",2012-11-02 07:04:25,2012-11-02 07:04:25,opencv_imgproc.dll throws BadImageFormatException,<c#><opencv><emgucv><badimageformatexception>,,,CC BY-SA 3.0,True,False,True,False,False
4131,15089089,2013-02-26 12:25:25,,"<p>I am trying to setup EMGU library for my C# project. I am following this link <a href=""http://file.emgu.com/wiki/index.php/Setting_up_EMGU_C_Sharp"" rel=""nofollow"">http://file.emgu.com/wiki/index.php/Setting_up_EMGU_C_Sharp</a>. </p>

<p>I am stuck in: <strong>x64 Architecture and the EMGU.CV.Invoke Exception</strong> step. I am using Visual C# 2010 Express edition and the platform target is not showing x64 option. I tried to check the Show Advanced build Configurations and then Run my project but it is throwing Type Initialization Error with Inner Exception: <strong>""Unable to load DLL 'opencv_core242': The specified module could not be found. (Exception from HRESULT: 0x8007007E)""</strong>. But according to the above link it should throw error with ‘InnerException’ ""An attempt was made to load a program with an incorrect format....”. </p>

<p>Exception is thrown in following line.</p>

<pre><code>cap = new Capture(0);
</code></pre>

<p>Please help me out.</p>
",2013-02-26 17:25:36,2014-01-17 08:05:21,Exception in setting up EMGU library in C#,<c#><.net><visual-c#-express-2010><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
4207,13181929,2012-11-01 16:59:17,,"<p>Is there a way i can retrieve the observed keypoints from a 3D model instead from an image. This is since i need to track an uneven object (simple spaceship right now: <a href=""http://i.msdn.microsoft.com/dynimg/IC129855.jpg"" rel=""nofollow"">http://i.msdn.microsoft.com/dynimg/IC129855.jpg</a>) that can be visible from any side. Currently the system works somewhat fine when using an image but like i said i need it be able to identify the model if being viewed from any side. Currently using an implementation of the SURF tutorial found over here:
<a href=""http://www.emgu.com/wiki/index.php/SURF_feature_detector_in_CSharp"" rel=""nofollow"">http://www.emgu.com/wiki/index.php/SURF_feature_detector_in_CSharp</a></p>

<p>Moreover is there a way to specify the detail of the keypoints or the number?</p>
",,2012-11-01 16:59:17,EmguCV detect keypoints from 3D Model,<surf><emgucv><object-recognition><keypoint>,,,CC BY-SA 3.0,False,False,True,False,False
4235,16056812,2013-04-17 09:46:50,,"<p>I have a black and white image containing objects from a set. I'd like to be able to locate these objects. I'm almost sure that the objects in the image are the same size and almost exactly the same shape as the samples in my set. </p>

<p>One way of doing this is to move the objects in my set one by one over the image until I get a reasonable match between the pixels in my image and the pixels in the sample object. I can write my own code for this but I'd rather not reinvent the wheel. Is there anything in AForge or EMGU/OpenCV that does this already?</p>
",,2013-04-17 14:04:16,How to locate an object in an image?,<c#><opencv><image-processing><aforge><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
4271,12211619,2012-08-31 08:32:19,,"<p>I have two images (let's assume they have the same size), i want to calculate the correlation between the two images Using EMGU and C#.</p>

<p>I didn't found any function that does it and implemented the correlation calculation by myself.. but i'd rather use built in function.</p>

<p>Is such function exist ? </p>

<p>Thanks.</p>
",,2012-12-15 00:35:06,How to calculate the correlation between two images in EMGU?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
4273,12212356,2012-08-31 09:16:26,,"<p>I'm trying to multiply the fundamental matrix with a one column matrix (a 2D homogeneous coordinates), but I get the following error: <code>CvException occurred - OpenCV: src1.size == dst.size &amp;&amp; src1.channels() == dst.channels()</code></p>

<p>The code looks like this:</p>

<pre><code>IntPtr fundamentalMatrix = CvInvoke.cvCreateMat(3, 3, MAT_DEPTH.CV_32F);

[... finding the fundamental matrix ...]

IntPtr cam1PointRef = CvInvoke.cvCreateMat(3, 1, MAT_DEPTH.CV_32F);
IntPtr cam2PointRef = CvInvoke.cvCreateMat(3, 1, MAT_DEPTH.CV_32F);

//cam1Point is known
CvInvoke.cvSet2D(cam1PointRef, 0, 0, new MCvScalar(cam1Point.X));
CvInvoke.cvSet2D(cam1PointRef, 1, 0, new MCvScalar(cam1Point.Y));
CvInvoke.cvSet2D(cam1PointRef, 2, 0, new MCvScalar(1));

CvInvoke.cvMul(fundamentalMatrix, cam1PointRef, cam2PointRef, 1);

Matrix&lt;float&gt; cam2PointMat = new Matrix&lt;float&gt;(3, 1, cam2PointRef);

PointF cam2Point = new PointF();
cam2Point.X = cam2PointMat[0, 0] / cam2PointMat[0, 2];
cam2Point.Y = cam2PointMat[0, 1] / cam2PointMat[0, 2];
</code></pre>

<p>If i invert the multiplication order like this: <code>CvInvoke.cvMul(cam1PointRef, fundamentalMatrix, cam2PointRef, 1);</code> I get another exception: </p>

<p><code>OpenCV: The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array'</code></p>

<p>What I'm doing wrong? Why I can not multiply (3 x 3) matrix with (3 x 1) matrix for getting the corespondent point?</p>
",2012-08-31 09:21:13,2012-08-31 21:26:04,CvInvoke.cvMul exception,<c#><opencv><emgucv><matrix-multiplication>,,,CC BY-SA 3.0,True,True,True,False,False
4280,14142562,2013-01-03 16:05:07,,"<p>I am working with the Kinect SDK and I am trying to filter the depth image data in two ways:</p>

<ol>
<li>Remove all depths that are not associated with a player</li>
<li>Remove all depths that are greater than a given depth (calculated form the position of a players wrists)</li>
</ol>

<p>The result of which is essentially to show only the parts of a players body which are less than a certain depth from the sensor.</p>

<p>Whilst the code below does what i want it to do, its not proving very good when i run performance analysis, so I am looking for ways in which it could be improved.</p>

<p>The basic issue is that the array contains 307200 values (as the depth image size is 640x480), and I am trying to get this method called around 30 times a second.</p>

<p>Does anyone have any pointers as to how this could be done more efficiently?  The code also uses EmguCV libraries in other parts and I have tinkered with using the cvInvokeThreshold method but it didn't seeem to work as well as this code...</p>

<p>If you need any more information, let me know.</p>

<p>Many Thanks,</p>

<p>Dave McB</p>

<pre><code>public static byte[] GetDepths(byte[] depths, DepthImagePixel[] depthPixels, int width, int height, int threshold)
    {

        Parallel.For(0, width, i =&gt;
        {
            for (int j = 0; j &lt; height; j++)
            {
                //Have to calculate the index we are working on using i and j
                int rawDepthDataIndex = i * height + j;

                //gets the depth and player values
                short depth = depthPixels[rawDepthDataIndex].Depth;
                short player = depthPixels[rawDepthDataIndex].PlayerIndex;

                if (player &gt; 0 &amp;&amp; depth &lt; threshold)
                    depths[rawDepthDataIndex] = (byte)depth;
                else
                    depths[rawDepthDataIndex] = 0;
            }


        });
        return depths;
    }
</code></pre>
",,2013-05-11 21:54:22,Efficient Kinect Depth Image (or large Array) Filtering,<arrays><filtering><kinect><emgucv><kinect-sdk>,,,CC BY-SA 3.0,False,False,True,False,False
4325,13190293,2012-11-02 06:16:36,,"<p>when i trie to build c# project(project for road sign detection system), that could build and debug without excption. but when i click button in main interface of the project, there was an exception as  **</p>

<blockquote>
  <p><strong>""Unable to create ocr model using Path tessdata and language eng.""</strong></p>
</blockquote>

<p>and that highlighted code is </p>

<pre><code>public void Init(String dataPath, String language, OcrEngineMode mode)
      {
         /*if (!IsEngineModeSupported(mode))
            throw new ArgumentException(String.Format(""The Ocr engine mode {0} is not supported in tesseract v{1}"", mode, Version));*/
         int initResult= TessBaseAPIInit(_ptr, dataPath, language, mode);
         if (initResult != 0) throw new ArgumentException(String.Format(""Unable to create ocr model using Path {0} and language {1}."", dataPath, language));
      }
</code></pre>

<p>please help me to solve this. 
thank you very much</p>
",,2017-03-22 04:49:18,"How to solve exception ""Unable to create ocr model using Path tessdata and language eng"" in emgucv",<c#><image-processing><emgucv><object-detection>,,,CC BY-SA 3.0,False,False,True,False,False
4335,9271150,2012-02-14 03:05:21,,"<p>I have already done the comparison of 2 images of same scene which are taken by one camera with different view angles(say left and right) using <strong>SURF</strong> in emgucv (C#). And it gave me a 3x3 homography matrix for 2D transformation. But now I want to make those 2 images in 3D environment (using DirectX). To do that I need to calculate relative location and orientation of 2nd image(right) to the 1st image(left) in 3D form. How can I calculate <strong>Rotation and Translate</strong> matrices for 2nd image?</p>

<p>I need also z value for 2nd image.</p>

<p>I read something called 'Homograhy decomposition'. Is it the way?</p>

<p>Is there anybody who familiar with homography decomposition and is there any algorithm which it implement?</p>

<p>Thanks in advance for any help.</p>
",2012-02-14 03:24:10,2014-04-16 06:55:00,How to calculate Rotation and Translation matrices from homography?,<computer-vision><emgucv><homography>,,,CC BY-SA 3.0,False,False,True,False,False
4439,10276052,2012-04-23 06:55:35,,"<p>I am using EmguCV 2.3.0.1416 from a simple console application (.net 4.0 and c#) and I have a question around canny's, edge detection etc.  Given the following code:</p>

<pre><code>var colours = new[]
                  {
                      new Bgr(Color.YellowGreen),
                      new Bgr(Color.Turquoise),
                      new Bgr(Color.Blue),
                      new Bgr(Color.DeepPink)
                  };

// Convert to grayscale, remove noise and get the canny
using (var image = new Image&lt;Bgr, byte&gt;(fileName)
    .Convert&lt;Gray, byte&gt;()
    .PyrDown()
    .PyrUp()
    .Canny(new Gray(180),
           new Gray(90)))
{
    // Save the canny out to a file and then get each contour within
    // the canny and get the polygon for it, colour each a different
    // colour from a selection so we can easily see if they join up
    image.Save(cannyFileName);

    var contours = image
        .FindContours(CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
                      RETR_TYPE.CV_RETR_EXTERNAL);

    using (var debug = new Image&lt;Bgr, byte&gt;(image.Size))
    {
        int colIndex = 0;
        for (; contours != null; contours = contours.HNext)
        {
            Contour&lt;Point&gt; poly = contours
                .ApproxPoly(contours.Perimeter*0.05,
                            contours.Storage);

            debug.Draw(poly, colours[colIndex], 1);

            colIndex++;
            if (colIndex &gt; 3) colIndex = 0;
        }

        debug.Save(debugFileName);
    }
}
</code></pre>

<p>I get this output (this is actually just a part of the image but it shows what I am asking about):</p>

<p><img src=""https://i.stack.imgur.com/U7NYH.png"" alt=""Canny Edge""></p>

<p>As you can see it has a blue line with a little bit of pink and then a green line.  The real thing has just a solid edge here so I want this to be a single line in order that I can be sure it is the edge of what I am looking at.</p>

<p>The original image looks like this (I have zoomed it but you can see it has a very distinctive edge that I was expecting to be able to find easily).</p>

<p><img src=""https://i.stack.imgur.com/AktvR.png"" alt=""Orignal""></p>

<p>If I look at just the canny I can see the gap there so I tried adjusting the parameters for creating the canny (the threshold and linking threshold) but they have made no difference.</p>

<p>I also dilated and then eroded the canny (using the same value for the iterations parameter - 10 incidentally) and that seemed to do the trick but could I lose accuracy by doing this (it just feels a bit wrong somehow)?</p>

<p>So, how should I ensure that I get a single line in this instance?</p>
",2012-04-30 08:43:39,2013-06-06 03:02:04,How can I get a continuous polygon using EmguCV?,<c#><.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
4444,16075551,2013-04-18 06:00:51,,"<p>I have a matrix <strong>M</strong> of m*n dimension. <strong>M</strong> contains n number of data each has m dimension and m is very very large than n.</p>

<p>Now my question is, how to compute or what are the steps or procedure to find <strong>PCA</strong> of <strong>M</strong> using <strong>SVD</strong> in <strong>OpenCV</strong> keeping only those eigenvectors containing <strong>99%</strong> of total load or energy ?</p>
",,2014-02-25 08:42:32,PCA using SVD in OpenCV,<opencv><image-processing><artificial-intelligence><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
4477,13206288,2012-11-03 05:30:33,,"<p>I'm trying to calculate mahalanobis distance in c# using emgu cv. I have 3 image each sized 100x100. The step are, first I calculate the covariance matrix, then I calculate the inverse covariance matrix, and last calculate mahalanobis distance with another new image.</p>

<p>But the program throw an SEHException when I calculate the inverse covariance matrix. 
The program running perfectly when I use image that sized 3x3 only. At first i suspect my covariance matrix is too huge (10000x10000) thus the inverse operation fail. But if it was the memory problem it should've thrown an OutOfMemoryException (CMIIW).</p>

<p>The HResult for SEHException is 0x80004005 or HRESULT E_FAIL which is unspecified failure. I dont know how to fix this. Or maybe there's another way to calculate mahalanobis distance safely?</p>

<p>This is my complete code</p>

<pre><code>    MySqlConnection SqlCon;
MySqlCommand SqlCmd;
MySqlDataReader SqlDataReader;
string ConString = ""SERVER=localhost;"" +
                    ""USER=root;"";
string CmdString;
string DBString = ""TrainingDB"";

Image&lt;Gray, Byte&gt;[] TrainingImage100 = new Image&lt;Gray, byte&gt;[3];
Image&lt;Gray, float&gt; covarImage = new Image&lt;Gray, float&gt;(10000, 10000);
Image&lt;Gray, float&gt; invCovarImage = new Image&lt;Gray, float&gt;(10000, 10000);
Image&lt;Gray, float&gt; averageImage = new Image&lt;Gray, float&gt;(100, 100);

SqlCon = new MySqlConnection(ConString);
try
{
    SqlCon.Open();

    CmdString = ""USE `"" + DBString + ""`"";
    SqlCmd = new MySqlCommand(CmdString, SqlCon);
    SqlCmd.ExecuteNonQuery();

    CmdString = ""SELECT `face_image` FROM `face100_table` WHERE `person_id` = 1 LIMIT 1"";
    SqlCmd = new MySqlCommand(CmdString, SqlCon);
    SqlDataReader = SqlCmd.ExecuteReader();
    while (SqlDataReader.Read())
    {
        byte[] blob = (byte[])SqlDataReader[""face_image""];
        MemoryStream ms = new MemoryStream(blob);
        Bitmap bmp = new Bitmap(ms);
        Image&lt;Gray, Byte&gt; tempFrame = new Image&lt;Gray, byte&gt;(bmp);
        TrainingImage100[0] = tempFrame;
        ms.Close();
    }
    SqlDataReader.Close();

    CmdString = ""SELECT `face_image` FROM `face100_table` WHERE `person_id` = 2 LIMIT 1"";
    SqlCmd = new MySqlCommand(CmdString, SqlCon);
    SqlDataReader = SqlCmd.ExecuteReader();
    while (SqlDataReader.Read())
    {
        byte[] blob = (byte[])SqlDataReader[""face_image""];
        MemoryStream ms = new MemoryStream(blob);
        Bitmap bmp = new Bitmap(ms);
        Image&lt;Gray, Byte&gt; tempFrame = new Image&lt;Gray, byte&gt;(bmp);
        TrainingImage100[1] = tempFrame;
        ms.Close();
    }
    SqlDataReader.Close();

    CmdString = ""SELECT `face_image` FROM `face100_table` WHERE `person_id` = 3 LIMIT 1"";
    SqlCmd = new MySqlCommand(CmdString, SqlCon);
    SqlDataReader = SqlCmd.ExecuteReader();
    while (SqlDataReader.Read())
    {
        byte[] blob = (byte[])SqlDataReader[""face_image""];
        MemoryStream ms = new MemoryStream(blob);
        Bitmap bmp = new Bitmap(ms);
        Image&lt;Gray, Byte&gt; tempFrame = new Image&lt;Gray, byte&gt;(bmp);
        TrainingImage100[2] = tempFrame;
        ms.Close();
    }
    SqlDataReader.Close();
}
catch (Exception excpt)
{
    MessageBox.Show(""load - "" + excpt.Message);
}
SqlCon.Close();

IntPtr[] inObjs = Array.ConvertAll&lt;Image&lt;Gray, byte&gt;, IntPtr&gt;(TrainingImage100, delegate(Image&lt;Gray, byte&gt; img) { return img.Ptr; });

CvInvoke.cvCalcCovarMatrix(inObjs, 3, covarImage, averageImage, COVAR_METHOD.CV_COVAR_NORMAL);
Console.WriteLine(covarImage.Size);
Console.WriteLine(averageImage.Size);

CvInvoke.cvInvert(covarImage, invCovarImage, SOLVE_METHOD.CV_SVD_SYM);
Console.WriteLine(invCovarImage.Size);
</code></pre>

<p>The error point to method <code>CvInvoke.cvInvert()</code> . And for additional information I'm using Visual Studio 2010 and emgu cv version 2.3.0.</p>
",,2012-11-03 05:30:33,SEHException when inverting huge matrix,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
4483,11258435,2012-06-29 08:25:56,,"<p>I use this code in my project.
      <code>haar = new HaarCascade(""face_detect.xml"");</code>
When program run, It gives an exception like ""'Emgu.CV.CvInvoke' threw an exception"".
Can anybody give me any suggestion why it is? </p>

<p>edit:
I search about this. It says copy some dlls to emgucv. I don't know from where to where need to copy those dlls. </p>
",2012-06-29 08:31:16,2014-10-26 22:21:25,The type initializer for 'Emgu.CV.CvInvoke' threw an exception,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
4522,11262625,2012-06-29 13:23:01,,"<p>I used the Face Recognition class with EmguCV version 2.2 and everything worked fine.
I just recently upgraded to the 2.4 version.</p>

<p>I start by creating a Recognizer class.</p>

<pre><code>_recognizer = new EigenObjectRecognizer(_trainingImages.ToArray(), _nameList.ToArray(), ref _terminationCriteria);
</code></pre>

<p>Now I want to get a result for my picture with</p>

<pre><code>EigenObjectRecognizer.RecognitionResult fN = _recognizer.Recognize(face);
</code></pre>

<p>but the RecognitionResult is always null.</p>

<p>EDIT: It works using an eigenDistanceThreshold of 5000.</p>
",2012-07-17 10:41:46,2012-07-17 10:41:46,Face Recognition with EmguCV 2.4 returns NULL,<emgucv><face-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
4566,14168499,2013-01-05 04:11:51,,"<p>Hy, 
I am trying to convert BitmapSource to Bitmap from Kinect RGB Color Stream. I am getting null.
I am using Kinect for Windows SDK 1.6, Visual Studio 2012, Windows 7 Ultimate 64bit, EmguCV 2.4.2.1777.
Here is the Code:</p>

<pre><code>void _kinect_ColorFrameReady( object sender, ColorImageFrameReadyEventArgs e )
    {
        using ( ColorImageFrame colorFrame = e.OpenColorImageFrame() )
        {
            if ( colorFrame == null )
            {
                return;
            }

            if ( colorFrame != null )
            {
                this.colorPixels = new byte[colorFrame.PixelDataLength];

                colorFrame.CopyPixelDataTo( this.colorPixels );

                int stride = colorFrame.Width * 4;

                colorBmp = BitmapSource.Create( 
                    colorFrame.Width, 
                    colorFrame.Height, 
                    96, 
                    96, 
                    PixelFormats.Bgr32, 
                    null, 
                    colorPixels,
                    stride 
                );

                currentColorFrame = new Image&lt;Bgr, Byte&gt;( colorBmp.ToBitmap() );

                this.imgOutput.Source = ImageHelpers.ToBitmapSource( currentColorFrame ); 
            }
        }           
    }
</code></pre>

<p>Helper Methods:</p>

<pre><code>   public static System.Drawing.Bitmap ToBitmap(this BitmapSource bitmapsource)
    {
        System.Drawing.Bitmap bitmap;
        using ( var outStream = new MemoryStream() )
        {
            // from System.Media.BitmapImage to System.Drawing.Bitmap
            BitmapEncoder enc = new BmpBitmapEncoder();
            enc.Frames.Add( BitmapFrame.Create( bitmapsource ) );
            enc.Save( outStream );
            bitmap = new System.Drawing.Bitmap( outStream );
            return bitmap;
        }         
    }


    [DllImport(""gdi32"")]
    private static extern int DeleteObject(IntPtr o);

    /// &lt;summary&gt;
    /// Convert an IImage to a WPF BitmapSource. The result can be used in the Set Property of Image.Source
    /// &lt;/summary&gt;
    /// &lt;param name=""image""&gt;The Emgu CV Image&lt;/param&gt;
    /// &lt;returns&gt;The equivalent BitmapSource&lt;/returns&gt;
    public static BitmapSource ToBitmapSource(IImage image)
    {
        using (System.Drawing.Bitmap source = image.Bitmap)
        {
            IntPtr ptr = source.GetHbitmap(); //obtain the Hbitmap

            BitmapSource bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
                ptr,
                IntPtr.Zero,
                Int32Rect.Empty,
                System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions());

            DeleteObject(ptr); //release the HBitmap
            return bs;
        }
    }
</code></pre>

<p>Please point out my mistake or give me any suggestion as soon as possible.</p>
",,2013-01-12 18:58:36,BitmapSource to Bitmap Returns Null( EmguCV2.4.2.1777 + Kinect ),<c#><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
4622,11271815,2012-06-30 05:49:02,,"<p>I'm translating some OpenCV code from C++ to C# wrapped by EmguCV. One thing continuously bothers me is that in Opencv, a lot of stuff are pointers say <code>IplImage*</code>, <code>CvCapture*</code>, etc and when I translate them into C#, they all become <code>IntPtrs</code> like <code>IntPtr Capture=CvInvoke.CvCreateCameraCapture(0)</code> In this particular question, I'm having problem accessing the data of a matrix in form of <code>IntPtr</code></p>

<p>The original Code looks like:</p>

<pre><code>CvMat* ObjectPoints = CvCreateMat(/*some parameters*/);//initialize the matrix header
float* TempPoints = new float[/*size of the array of the TempPoints*/];
//assign some values to TempPoints
*ObjectPoints = cvMat(rows, cols, type, TempPoints)//assign the changed TempPoints as the data of the ObjectPoint matrix. other irrelevant parameters are omitted.
</code></pre>

<p>When I rewrite the part above in C#, it looks like</p>

<pre><code>IntPtr ObjectPoints = CvInvoke.CvCreateMat(/*some parameters*/);
float* TempPoints = new float[/*size of the array of the tempPoints*/];
//assign some value to TempPoints
//Then what? ObjectPoints is a pointer and EmguCV does not have a CvMat() method. So how can I achieve the effect as in the original code?
</code></pre>

<p>And if I could expand a little beyond this question, in other occasions like I have <code>IntPtr Frame = CvInoke.CvQueryImage(Capture);</code> and another function requires an <code>Image&lt;RGB, Byte&gt;</code>, how can I convert an IntPtr to an Image? I know the reverse one is simple, just use MyImage.Ptr. But how to convert an IntPtr to an Image?</p>
",2012-06-30 11:26:45,2012-06-30 11:26:45,Dealing with a wrapped IntPtr Object,<c#><c++><pointers><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
4641,12247802,2012-09-03 12:22:39,,"<p>Any Idea how to convert <code>Image</code> type to <code>Image&lt;Bgr, Byte&gt;</code> type?</p>

<p>I get the image from <code>PictureBox</code> Control and I need to convert it to <code>Image&lt;Bgr, Byte&gt;</code> type.</p>

<pre><code>Image pictureBoxImage = pictureBox.Image;
Image&lt;Bgr, Byte&gt; image = // ...
</code></pre>
",2012-09-03 12:40:33,2018-05-09 17:33:51,"How to convert Image type to Image<Bgr, Byte>?",<c#><.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
4740,13227715,2012-11-05 07:25:15,,"<p>I'm trying to write a simple program that will detect a face off a webcam and then trigger an event(optionally take a snapshot of the face)</p>

<p>I don't need anything fancy like to compare it to other faces I just need to send out an email that someone is at the door (hopefully with attached photo)</p>

<p>the problem is im very confused about how and what to use</p>

<p>I see there is a very powerful ""opencv"" that has a few wrapper classes namely opencv.net and emgu.cv</p>

<p>I've seen a few examples here and there but i have yet to find a working set of source code that works with flex 4</p>

<p>Can anyone recommend what the best course of action for a amateur programmer like me.</p>

<p>thanks</p>
",,2012-11-18 20:17:42,face detection in flex,<actionscript-3><apache-flex><flex4><emgucv><face-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
4798,16107165,2013-04-19 14:37:13,,"<p>I have byte array with yuv420 data.</p>

<pre><code>byte[] yuv420;//yuv data
</code></pre>

<p>How can I convert this to an <code>Image&lt;Bgr, byte&gt;</code>?</p>

<p>I found a math formula to convert to RGB and then to <code>Image&lt;Bgr, byte&gt;</code> but it is very slow.  Is there a way to convert it faster?</p>

<p>There is a class in Emgu for converting </p>

<pre><code>COLOR_CONVERSION(enum CV_YUV2RGB    Convert YUV color to RGB)
</code></pre>

<p>but I can not understand how use this class.  Can anyone help?</p>

<pre><code>static Bitmap ConvertYUV2RGB(byte[] yuvFrame, byte[] rgbFrame, int width, int height)
{
    int uIndex = width * height;
    int vIndex = uIndex + ((width * height) &gt;&gt; 2);
    int gIndex = width * height;
    int bIndex = gIndex * 2;

    int temp = 0;


    //图片为pic1,RGB颜色的二进制数据转换得的int r,g,b;
    Bitmap bm = new Bitmap(width, height);

    int r = 0;
    int g = 0;
    int b = 0;


    for (int y = 0; y &lt; height; y++)
    {
        for (int x = 0; x &lt; width; x++)
        {
            // R分量
            temp = (int)(yuvFrame[y * width + x] + (yuvFrame[vIndex + (y / 2) * (width / 2) + x / 2] - 128) * YUV2RGB_CONVERT_MATRIX[0, 2]);
            rgbFrame[y * width + x] = (byte)(temp &lt; 0 ? 0 : (temp &gt; 255 ? 255 : temp));
            // G分量
            temp = (int)(yuvFrame[y * width + x] + (yuvFrame[uIndex + (y / 2) * (width / 2) + x / 2] - 128) * YUV2RGB_CONVERT_MATRIX[1, 1] + (yuvFrame[vIndex + (y / 2) * (width / 2) + x / 2] - 128) * YUV2RGB_CONVERT_MATRIX[1, 2]);
            rgbFrame[gIndex + y * width + x] = (byte)(temp &lt; 0 ? 0 : (temp &gt; 255 ? 255 : temp));
            // B分量
            temp = (int)(yuvFrame[y * width + x] + (yuvFrame[uIndex + (y / 2) * (width / 2) + x / 2] - 128) * YUV2RGB_CONVERT_MATRIX[2, 1]);
            rgbFrame[bIndex + y * width + x] = (byte)(temp &lt; 0 ? 0 : (temp &gt; 255 ? 255 : temp));
            Color c = Color.FromArgb(rgbFrame[y * width + x], rgbFrame[gIndex + y * width + x], rgbFrame[bIndex + y * width + x]);
            bm.SetPixel(x, y, c);
        }
    }
    return bm;

}

static double[,] YUV2RGB_CONVERT_MATRIX = new double[3, 3] { { 1, 0, 1.4022 }, { 1, -0.3456, -0.7145 }, { 1, 1.771, 0 } };
static byte clamp(float input)
{
    if (input &lt; 0) input = 0;
    if (input &gt; 255) input = 255;
    return (byte)Math.Abs(input);
}
</code></pre>
",2013-04-19 14:48:50,2016-03-06 23:11:56,"Convert from yuv 420 to image<Bgr,byte>",<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
4849,9318912,2012-02-16 20:55:16,,"<p>Alright, so basically I am trying to use openCV with the Kinect (Microsoft's new Kinect 1.0 SDK).  I am very new to both C# and Kinect.  But what I want to do is use the kinect for facial recognition using EMGU (openCV wrapper for C#).  So far I have successfully captured the video stream from the kinect, converted it into an EMGU Image&lt;>, then converted it a Byte[] array so that I can use the BitmapSource to display my image on the screen.</p>

<p>While that works fine, problems seem to arise when I try to actually do some image processing with the Image&lt;> class.  It actually seems to be processing fine, but it is not very fast.  This wouldn't necessarily be a problem for me, but now the BitmapSource isn't being displayed at all.</p>

<p>Here is an example of my code to detect faces:</p>

<pre><code>img = new Image&lt;Bgr, byte&gt;(clone);
haar = new HaarCascade(""directory"");

Image&lt;Gray, Byte&gt; gray;
using (HaarCascade face = new HaarCascade(""blablabla.xml""))
using (HaarCascade eye = new HaarCascade(""blarg.xml""))
{

using ( gray = img.Convert&lt;Gray, Byte&gt;()) //Convert it to Grayscale
{
  MCvAvgComp[] facesDetected = face.Detect(gray, 1.1, 1,  mgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new System.Drawing.Size(img.Width / 8, img.Height / 8));
  foreach (MCvAvgComp f in facesDetected)
  {
    img.Draw(f.rect, new Bgr(System.Drawing.Color.Blue), 2);
    imgDoneProc = img.ToBitmap();
  }
 }
}
</code></pre>

<p>Then I use the BitmapSource.Create() :</p>

<pre><code>BitmapSource bmapa = BitmapSource.Create(PImage.Width, PImage.Height, 96, 96, PixelFormats.Bgr32, null, bmpBytes, PImage.Width * PImage.BytesPerPixel);

image1.Source = bmapa;
</code></pre>

<p>(PImage is the stream from the Kinect; bmpBytes is a Byte[] converted from the Image&lt;>)</p>

<p>So, if I comment out the code that does the image processing, all of the converting back and forth works fine.  When I add the image proc code, I can write to the console some useful data, but the image is not displayed.  I have also noticed that the 'bmapa' is not updated quickly.  That is the only noticeable difference other than nothing being displayed in image1.</p>

<p>So, am I using BitmapSource incorrectly, or is there are way speed up my code or perhaps slow BitmapSource's ""refresh rate""?  Because when I am just converting between data structures, I get a steady stream from the kinect and all works fine.</p>

<p>Thanks,
Brent</p>
",2012-02-16 21:13:22,2012-04-03 17:01:02,Kinect and EMGU (OpenCV) - BitmapSource issue,<c#><opencv><kinect><emgucv><bitmapsource>,,,CC BY-SA 3.0,True,False,True,False,False
4984,9328231,2012-02-17 12:30:42,,"<p>I'm confused about the way I should make the ""features extraction "" method 
I want to use SVMs to apply ""Object recognition"" in images ,
There's a sample in Emgu's examples that holds an XML file contains the features of a cat !
and I've been trying since a week to know how they did it and what methods they used 
and I came across this page 
<a href=""http://experienceopencv.blogspot.com/2011/02/learning-deformable-models-with-latent.html"" rel=""nofollow"">http://experienceopencv.blogspot.com/2011/02/learning-deformable-models-with-latent.html</a>
that displays the steps ! It's so complicated plus couldn't do it myself
I'm so lost !! can anyone tell me an appropriate method of  ""features extraction ""Compatible with SVMs learning ?
Accord has SVM example but it's on hand writing and doesn't deal with color images =(
any helping links ?
thanks </p>
",,2019-08-02 17:01:40,How to extract features from image for classification and object recognition?,<image-processing><emgucv><svm><object-recognition><feature-extraction>,,,CC BY-SA 3.0,False,False,True,False,False
5015,14206699,2013-01-08 00:57:40,,"<p>I am working on a people counter. For this I have the Microsoft Kinect installed over the door.
I am working with C# and EmguCV. I have extracted the heads of the people, so that they appear as white blobs on a black image. Then I have created a bounding box around the heads. That works fine. So I now how many blobs I have per frame and I also now their position. This works fine. But now I want to track the blobs because I want to count how much people come in and go out, but I don't know how to do this. Can anyone help me? The problem is that every frame, new blobs can appear and old blobs can disappear. Can anyone give me an algorithm or maybe some code? or a paper. 
Thanks a lot!</p>

<hr>

<p>Sure. This is the code for the blobs:</p>

<pre><code>using (MemStorage stor = new MemStorage())
        {



            Contour&lt;System.Drawing.Point&gt; contours = head_image.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_EXTERNAL, stor);



            for (int i = 0; contours != null; contours = contours.HNext)
            {

                i++;



                //if ((contours.Area &gt; Math.Pow(sliderMinSize.Value, 2)) &amp;&amp; (contours.Area &lt; Math.Pow(sliderMaxSize.Value, 2)))
                {

                    MCvBox2D box = contours.GetMinAreaRect();

                    blobCount++;

                    contour_image.Draw(box, new Bgr(System.Drawing.Color.Red), 1);


                    new_position = new System.Drawing.Point((int)(box.center.X), (int)(box.center.Y));
                    new_x = box.center.X;
                    new_y = box.center.Y;
                }

            }
        }
</code></pre>
",2013-01-08 05:50:07,2013-01-08 14:34:18,Tracking Blobs with Microsoft Kinect,<c#><image-processing><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
5029,11305237,2012-07-03 05:56:34,,"<p>im tring to use opencv like in the examples that opencv provide</p>

<p>when i run it in the example (in winform) it works fine but in my website i get this error:</p>

<pre><code>The type initializer for 'Emgu.CV.CvInvoke' threw an exception.
</code></pre>

<p>and inner exception:</p>

<pre><code>An attempt was made to load a program with an incorrect format. (Exception from HRESULT: 0x8007000B)
</code></pre>

<p>with the stack:</p>

<pre><code>at Emgu.CV.CvInvoke.cvLoadImage(String filename, LOAD_IMAGE_TYPE loadType)
at Emgu.CV.Image`2.LoadImageUsingOpenCV(FileInfo file)
at Emgu.CV.Image`2..ctor(String fileName)
</code></pre>

<p>im using the emgucv windows x64 2.40 version</p>
",2012-07-03 06:05:45,2012-07-04 10:08:54,openCV in asp.net,<asp.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5073,16132251,2013-04-21 14:37:07,,"<p>I have made image processing software on Microsoft Visual C# 2010 and it works very well.  The software uses EMGU CV image processing libraries, so I have put the .dll files along with a video and a picture inside a file on my computer. Everything still works well.</p>

<p>But when I transfer the same file, which contains the .exe and .dll and video and picture, to another computer, it doesn't work. My doubts are about the .net framework on the other computer. I'm sure .net is there but I'm not sure about the version.  The version on my own computer is 4.5.</p>

<p>Is the only problem the .net framework? Or might there be another problem?</p>
",2013-04-21 15:11:21,2013-04-21 15:11:21,.exe file doesn't work when moved to another computer,<exe><pc><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
5075,16133225,2013-04-21 16:09:57,,"<p>For an educational project we are currently working on a basic motion and gesture detection system. Our main goal is to detect a human body on a camera stream. Using this information we want to detect a basic skeleton of the body to do a further detection of the gestures the person does. </p>

<p>We are using EmguCV / OpenCV to process our stream. I found this video on Youtube: <a href=""http://www.youtube.com/watch?v=fYZtmkfWh5g"">http://www.youtube.com/watch?v=fYZtmkfWh5g</a>. He is able to detect the upper body and place a basic skeleton in it, but how? He does not mention any algorithms used. </p>

<p>We already tried to detect the body contour using a background subtraction (BackgroundSubtractorMOG2) but the camera noise and lightning conditions made us fail. </p>

<p>Does anybody have an idea to detect the body exactly like shown in the video?</p>
",,2017-09-10 19:25:39,Upper Body Skeleton Detection,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5085,10334110,2012-04-26 13:10:36,,"<p>I am trying to convert a WriteableBitmap which is having Rgb24 as a pixelFormat. I want to store the same image into a EmguCV Image having Bgr format. I have written a following code but it is not giving appropriate results.</p>

<pre><code>public unsafe void Convert(WriteableBitmap bitmap)
    {
        byte[] retVal = new byte[bitmap.PixelWidth * bitmap.PixelHeight * 4];
        bitmap.CopyPixels(new Int32Rect(0, 0, bitmap.PixelWidth, bitmap.PixelHeight), retVal, bitmap.PixelWidth * 4, 0);

        Bitmap b = new Bitmap(bitmap.PixelWidth, bitmap.PixelHeight);
        int k = 0;
        byte red, green, blue, alpha;
        for (int i = 0; i &lt; bitmap.PixelWidth; i++)
        {                
            for (int j = 0; j &lt; bitmap.PixelHeight &amp;&amp; k&lt;retVal.Length; j++)
            {
                alpha = retVal[k++];
                blue = retVal[k++];
                green = retVal[k++];
                red = retVal[k++];

                System.Drawing.Color c = new System.Drawing.Color();
                c = System.Drawing.Color.FromArgb(alpha, red, green, blue);

                b.SetPixel(i, j, c);   
            }
        }
        currentFrame = new Image&lt;Bgr, byte&gt;(b);

        currentFrame.Save(""Converted.jpg"");
}
</code></pre>

<p>Thanks in advance. </p>
",,2012-09-02 15:54:07,"How to convert WriteableBitmap in RGB24 pixel format into a EmguCV image<Bgr, Byte> format?",<c#><image><image-processing><emgucv><writeablebitmap>,,,CC BY-SA 3.0,False,False,True,False,False
5115,12290023,2012-09-05 21:25:47,,"<p>The Project: Add a running date/time stamp on each and every frame of a video. (The result of digital video camera, and my father asked me how can he add the timestamp(to the milliseconds resolution) permanently to the video.</p>

<p>A friend pointed me to opencv (emgucv actually) , and because of my preferences I tried my luck with opencv in python.</p>

<p>The documentation is lame, and I had even hard time(took me like 5 hours or so) just to install the package.
Sources:</p>

<ul>
<li>OpenCV 2.4 (willow garage): <a href=""http://sourceforge.net/projects/opencvlibrary/files/opencv-win/2.4.2/"" rel=""nofollow noreferrer"">http://sourceforge.net/projects/opencvlibrary/files/opencv-win/2.4.2/</a></li>
<li>Numpy (I didn't even understood what does it do or why needed): <a href=""http://sourceforge.net/projects/numpy/files/NumPy/1.6.2/numpy-1.6.2-win32-superpack-python2.7.exe/download"" rel=""nofollow noreferrer"">http://sourceforge.net/projects/numpy/files/NumPy/1.6.2/numpy-1.6.2-win32-superpack-python2.7.exe/download</a></li>
<li>Active Python 2.7: <a href=""http://downloads.activestate.com/ActivePython/releases/2.7.2.5/ActivePython-2.7.2.5-win32-x86.msi"" rel=""nofollow noreferrer"">http://downloads.activestate.com/ActivePython/releases/2.7.2.5/ActivePython-2.7.2.5-win32-x86.msi</a></li>
</ul>

<p>I am working on Windows 7 x64 , so I had to downgrade my python to work with numpy(no numpy version for win64)</p>

<p>Working with PyCharm IDE.</p>

<p>The resulting installation got me to have the file C:\Python27\Lib\site-packages\cv2.pyd</p>

<p>I am trying to find documentation to start working with, but I am very confused and have no clue where to start from, all the examples are confusing - ie:</p>

<ul>
<li>The ""official"" documentation is for c/c++, no python references: <a href=""http://docs.opencv.org/doc/user_guide/ug_mat.html"" rel=""nofollow noreferrer"">http://docs.opencv.org/doc/user_guide/ug_mat.html</a></li>
<li>Example for python that seems reasonable but not close to what i need: <a href=""https://stackoverflow.com/questions/10456727/python-opencv-2-4-writes-half-complete-png-video-frames"">Python OpenCV 2.4 writes half-complete PNG video frames</a></li>
<li>Example that is close to what I need, but doesn't seem logical(cv and not cv2 ???): <a href=""https://stackoverflow.com/questions/5426637/writing-video-with-opencv-python-mac"">Writing video with OpenCV + Python + Mac</a></li>
</ul>

<p>My Questions:</p>

<ol>
<li>Am i doing something wrong? Is this not the way to install opencv?</li>
<li>Where can i find good documentation?</li>
<li>Suppose i have my text ready(in a string) can somebody try to help me with a start to my application?</li>
</ol>

<p>Thanks</p>
",2017-05-23 10:29:06,2015-01-09 22:23:02,OpenCV 2.4 in python - Video processing,<python><opencv><video-processing>,,,CC BY-SA 3.0,True,True,True,False,False
5138,11315970,2012-07-03 17:20:47,,"<p>I am confused by the current state of Emgu GPU functionality (using Emgu 2.4 x64). The methods available from a GPUImage are very limited - I am trying to use it for blob detection. Specifically a code structure like this could use GPU to speed up blob extraction.</p>

<p>Any thoughts on how I could leverage GPU functionality from Emgu? Alternately, what are choices are available to leverage GPUs (other than a rewrite in CUDA)?</p>

<pre><code>        using (Image&lt;Gray, Byte&gt; currentGrayFrame = imgCurrentFrame.Convert&lt;Gray, Byte&gt;())
        {
            using (MemStorage storage = new MemStorage())
            {
                currentGrayFrame._SmoothGaussian(3);
                currentGrayFrame._GammaCorrect(1.8d);
                currentGrayFrame._EqualizeHist();
                CvInvoke.cvCanny(currentGrayFrame, currentGrayFrame, 120, 60, 3);
                int blobID = 0;
                for (Contour&lt;System.Drawing.Point&gt; contours = currentGrayFrame.FindContours(CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, RETR_TYPE.CV_RETR_EXTERNAL, storage);
                     contours != null; contours = contours.HNext)
                {
                    Contour&lt;Point&gt; contour = contours.ApproxPoly(contours.Perimeter * 0.001);
                    if (contour.Area &gt; 100)
                        if (contour.Total &gt; 5)
                        {
                            Rectangle rect = contour.BoundingRectangle;
                            Image&lt;Bgr, Byte&gt; imgBlob = imgCurrentFrame.Copy(rect);
                            {
                                //Bitmap bmpBlob = imgBlob.Bitmap;
                                blobsList.Add(new Blob
                                {
                                    BlobID = ++blobID,
                                    BlobImage = imgBlob,
                                    Location = rect,
                                });
                                //imgBlob.Dispose();
                            }
                        }
                }
            }
        }
</code></pre>
",,2012-07-03 17:20:47,emgu GPU Blob detection,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5145,15177195,2013-03-02 17:15:36,,"<p>i'm working on color tracking..
and i'm specifically tracking an orange ball, a basketball ball perhaps, along with kinect for the body, i'm making a free throw shooting guide.
here's my case</p>

<p>i have already thresholded my image, eroded it to remove noise, and other insignificant objects (non-ball) and then dilated a few times to emphasize the ball..
and so i've come to a final binary image - where i've successfully isolated the ball.. there are other blobs..(smaller blobs that aren't the ball).. how do i get the largest blob(the ball) and put a bounding box?</p>

<p>i've tried hough circles btw, however this is very slow,,..thanks! some code would be useful</p>
",,2013-03-03 16:02:44,emguCV getting the largest blob,<opencv><blob><tracking><emgucv><threshold>,,,CC BY-SA 3.0,True,False,True,False,False
5149,15181699,2013-03-03 02:07:19,,"<p>I get the following error when I try to invoke the <code>BOWImgDescriptorExtractor</code> compute method with <code>BriefDescriptorExtractor</code> and <code>BruteForceMatcher</code>.</p>

<blockquote>
  <p>An unhandled exception of type 'Emgu.CV.Util.CvException' occurred in Emgu.CV.dll
  Additional information: OpenCV: type == src2.type() &amp;&amp; src1.cols == src2.cols &amp;&amp; (type == CV_32F || type == CV_8U)</p>
</blockquote>

<p>Any idea how I can resolve this?</p>
",2013-03-03 02:11:41,2013-03-07 02:01:16,Error in BOWImgDescriptorExtractor in EmguCV,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5154,11317143,2012-07-03 18:40:34,,"<p>I'm working on a project in which we use a radio modem to transmit data (video and telemetry) from an unmanned aerial vehicle to a ground station. What we need to do is display the video in real-time and be able to know which frame corresponds to each chunk of telemetry data in C#.</p>

<p>The data is decapsulated to bytes of telemetry and video (mpeg4). As I've got some experience with OpenCV, I'd like to use it to decode, display and grab clicks position from the video. To do so I'm using the OpenCV wrapper for C# called Emgu.</p>

<p>The problem is that OpenCV loads video from a device or from a file and I've got only a callback with some bytes. I've tried writing those bytes to a file and opening this file with OpenCV, but once it gets to the end, I need to reopen it and continue from where it stopped, which generates lag.</p>

<p>Anyone got any idea how to do this?</p>
",,2012-07-03 19:32:02,How do I display a video with opencv from bytes?,<c#><video><opencv><byte><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5184,16140906,2013-04-22 06:40:17,,"<p>I am using Emgucv to capture frames from a video file Here is my Code</p>

<pre><code>private void Frame(object sender, EventArgs arg)
    {
        try
        {
            timesbetweenframes++;
            Image&lt;Bgr, Byte&gt; frame = FrameExtractor.QueryFrame();
            if (timesbetweenframes == 10 || timesbetweenframes == 0)
            {

                if (frame != null)
                {
                    Bgr min = new Bgr(65, 65, 65);
                    Bgr threshold = new Bgr(128, 128, 128);
                    Image&lt;Bgr, Byte&gt; Frame2 = frame;
                    //Noise Removal 
                    frame._SmoothGaussian(5);

                    VideoBox.Image = Frame2;
                    Bgr drawColor = new Bgr(Color.Blue);
                    using (Image&lt;Gray, byte&gt; gray = frame.Convert&lt;Gray, Byte&gt;())
                    {
                        TextExtract.Recognize(gray);
                        Tesseract.Charactor[] charactors = TextExtract.GetCharactors();
                        foreach (Tesseract.Charactor c in charactors)
                        {
                            Frame2.Draw(c.Region, drawColor, 1);
                        }

                    }
                    cptrdImage.Image = frame;
                    String text = TextExtract.GetText();
                    //removal of noise in this section 
                    Tags.Items.Add(text);
                    WriteData(text, fileName,frame);
                    fileName++;
                }
                else
                {
                    MessageBox.Show(""Done!"");
                    FrameExtractor = null;
                    InProgress = false;
                    timer1.Elapsed -= Frame;
                }
                timesbetweenframes = 0;
            }

        }
</code></pre>

<p>The frame function is being added to the timer event , this automatically fires the frame function after every 500 ms and extracting every 10th frame .Now the problem is that after calling queryframe() function , the program crashes with an error: 
""The instriction at 0x7777f7a99 referenced memory at 0x00000000. The memory coudl not be read"" after sometime.</p>

<p>Am i using it the wrong way , or is there any other way of doing this without getting this error . </p>
",,2013-07-26 15:23:54,EmguCV : How to Detect whether the file has reached end of file using QueryFrame(),<ocr><video-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
5204,14224296,2013-01-08 21:25:15,,"<p>I new to EmguCV. I am using Emgu CV 2.4.2 for my application. I've a problem to find the contour index using Seq(T).Item Property. When I used that property in contour, the system sent the error message like this :</p>

<pre><code>Error 11 'Emgu.CV.Contour&lt;System.Drawing.Point&gt;' does not contain a definition for'Item' and no
extension method 'Item' accepting a first argument of type 'Emgu.CV.Contour&lt;System.Drawing.Point&gt;'
could be found (are you missing a using directive or an assembly reference?)    E:\TUGAS_AKHIR\headDetection\headDetection.cs   284 45  headDetection
</code></pre>

<p>I've read the documentation <a href=""http://www.emgu.com/wiki/files/2.4.2/document/html/b65b4ab2-9d04-16f1-bd41-3be67aa400f7.htm"" rel=""nofollow"">here</a>, but I have no idea why the error appears. Here's my code :</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;

using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.CV.VideoSurveillance; 
using Emgu.CV.CvEnum; 
using Emgu.Util;
using Emgu.CV.Cvb;
using System.Collections;

//background subtraction 
...

//foreFrame is the result of background subtraction
 Contour&lt;Point&gt; contours = foreFrame.FindContours(
    CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
    RETR_TYPE.CV_RETR_EXTERNAL);

while (contours != null)
{
    int idx = contours.Item; //THE ERROR MESSAGE APPEARS HERE
        Console.WriteLine(""contour index = {0}"", idx);

    //next contour
    contours = contours.HNext;
}//endwhile
</code></pre>

<p>Please help me how to find the contour index either using Seq(T).Item Property or another approach in EmguCV. I would be highly appreciate if someone elaborate it.</p>

<p>Thanks in advance,
David :)</p>
",2013-01-09 06:38:48,2013-01-09 14:10:07,Finding contour index using Seq(T).Item Property in EmguCV,<c#><image-processing><contour><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
5227,10342682,2012-04-26 23:11:07,,"<p>I would really appreciate your help with an installation error. I've been trying to figure this out for days and can't find the answer online. Also, I need to use the EMGUCV wrapper for my work, and cannot use OpenCVsharp or other .net wrappers for opencv.</p>

<p>I am using OSX 10.6.8, I have installed mono/cmake and have followed the instructions in the <a href=""http://www.emgu.com/wiki/index.php/Download_And_Installation#OSX"" rel=""nofollow"">wiki</a> for the trunk version. I execute the following command, but the package fails to configure. I don't know how to interpret the output. Have also asked on the EmguCV forum, but not getting a lot of views there.</p>

<p>Thanks,
Rishi</p>

<pre><code>cmake -DCMAKE_OSX_ARCHITECTURES=i386 -DBUILD_NEW_PYTHON_SUPPORT:BOOL=FALSE -DBUILD_PERF_TESTS=FALSE -DBUILD_TESTS:BOOL=FALSE -DBUILD_DOCS:BOOL=FALSE -DBUILD_JPEG=TRUE -DBUILD_PNG=TRUE -DBUILD_TIFF=TRUE .


-- Found csc: /usr/bin/gmcs
-- Found gacutil: /usr/bin/gacutil
-- Found al: /usr/bin/al
-- Found resgen: /usr/bin/resgen
-- Extracting Emgu CV svn version, please wait...
-- Emgu CV SVN VERSION: 1661
-- Building 32bit library
-- Detected version of GNU GCC: 42 (402)
-- Extracting svn version, please wait...
-- SVNVERSION: svn:8208
-- Could NOT find Jasper (missing: JASPER_LIBRARIES JASPER_INCLUDE_DIR) 
-- checking for module 'libavcodec'
-- package 'libavcodec' not found
-- checking for module 'libavformat'
-- package 'libavformat' not found
-- checking for module 'libavutil'
-- package 'libavutil' not found
-- checking for module 'libswscale'
-- package 'libswscale' not found
-- checking for module 'libdc1394-2'
-- package 'libdc1394-2' not found
-- checking for module 'libdc1394'
-- package 'libdc1394' not found
-- CUDA detected: 4.1
-- CUDA NVCC target flags: -gencode;arch=compute_11,code=sm_11;-gencode;arch=compute_12,code=sm_12;-gencode;arch=compute_13,code=sm_13;-gencode;arch=compute_20,code=sm_20;-gencode;arch=compute_20,code=sm_21;-gencode;arch=compute_20,code=compute_20
-- 
-- General configuration for OpenCV 2.4.0 =====================================
-- Version control: svn:8208
-- 
-- Platform:
-- Host: Darwin 10.8.0 i386
-- CMake: 2.8.8
-- CMake generator: Unix Makefiles
-- CMake build tool: /usr/bin/make
-- 
-- C/C++:
-- Built as dynamic libs?: YES
-- C++ Compiler: /usr/bin/c++ (ver 4.2.1)
-- C++ flags (Release): -Wall -pthread -O3 -DNDEBUG -fomit-frame-pointer -msse -msse2 -DNDEBUG
-- C++ flags (Debug): -Wall -pthread -g -O0 -DDEBUG -D_DEBUG -ggdb3
-- C Compiler: /usr/bin/gcc
-- C flags (Release): -Wall -pthread -O3 -DNDEBUG -fomit-frame-pointer -msse -msse2 -DNDEBUG
-- C flags (Debug): -Wall -pthread -g -O0 -DDEBUG -D_DEBUG -ggdb3
-- Linker flags (Release): 
-- Linker flags (Debug): 
-- 
-- OpenCV modules:
-- To be built: calib3d contrib core features2d flann gpu highgui imgproc legacy ml nonfree objdetect photo stitching ts video videostab
-- Disabled by user: python
-- Disabled by dependency: -
-- Unavailable: androidcamera java
-- 
-- GUI: 
-- Cocoa: YES
-- OpenGL support: NO
-- 
-- Media I/O: 
-- ZLib: /usr/lib/libz.dylib (ver 1.2.3)
-- JPEG: libjpeg (ver 62)
-- PNG: build (ver 1.5.9)
-- TIFF: build (ver 42)
-- JPEG 2000: build (ver 1.900.1)
-- OpenEXR: NO
-- OpenNI: NO
-- OpenNI PrimeSensor Modules: NO
-- 
-- Video I/O: QTKit
-- FFMPEG: NO
-- codec: NO
-- format: NO
-- util: NO
-- swscale: NO
-- gentoo-style: NO
-- 
-- Other third-party libraries:
-- Use IPP: NO
-- Use TBB: NO
-- Use Cuda: YES (ver 4.1)
-- Use Eigen: NO
-- Use Clp: NO
-- 
-- NVIDIA CUDA:
-- Use CUFFT: YES
-- Use CUBLAS: NO
-- NVIDIA GPU arch: 11 12 13 20 21
-- NVIDIA PTX archs: 11 12 13 20 21
-- NVIDIA GPU features: 11 12 13 20 20 20
-- 
-- Python:
-- Interpreter: /Library/Frameworks/EPD64.framework/Versions/Current/bin/python (ver 2.7.2)
-- 
-- Tests and samples:
-- Tests: NO
-- Performance tests: NO
-- Examples: NO
-- 
-- Install path: /usr/local
-- 
-- cvconfig.h is in: /Users/rawatenator/emgucv
-- -----------------------------------------------------------------
-- 
CMake Warning at opencv/CMakeLists.txt:973 (message):
The source directory is the same as binary directory. ""make clean"" may
damage the source tree


-- WITH CVBLOB: ON
-- Could NOT find TIFF (missing: TIFF_LIBRARY) (found version ""3.8.2"")
-- CVEXTERN: ZLIB found.
-- Skipping GEOTIFF
-- CPACK_GENERATOR: Bundle
CMake Error: The following variables are used in this project, but they are set to NOTFOUND.
Please set them or make sure they are set and tested correctly in the CMake files:
CUDA_nvcuvid_LIBRARY (ADVANCED)
linked by target ""opencv_gpu"" in directory /Users/rawatenator/emgucv/opencv/modules/gpu
</code></pre>
",,2012-11-02 08:25:26,Building EmguCV on OSX Snow Leopard,<mono><emgucv>,,,CC BY-SA 3.0,True,False,True,False,True
5248,11323702,2012-07-04 06:41:37,,"<p>I need to use the VideoWriter class of Emgu CV library  in order to capture a screen at real time.</p>

<p>what is problem now is the FILE SIZE... so, i have to use the specific codec.</p>

<p>so far i have tried the code im posting:</p>

<blockquote>
  <p>// VideoWriter prototype: VideoWriter(String fname, Int32 comprescode,
  Int32 pfs, Int32 width, Int32 height, Boolean isColor);</p>
  
  <p>VideoWriter captureOutput;= new VideoWriter(@""test.avi"", -1, 1, width,
  height, true);</p>
</blockquote>

<p>as a result I got video COmpression dialog which i have a chance to select the codec.</p>

<p><img src=""https://i.stack.imgur.com/UAJAY.png"" alt=""enter image description here""></p>

<p>I selected Microsoft Windows Media Video 9 codec and it seems i need to use this codec in order solve the file size problem.</p>

<p>Instead to select every time when my program runs, I am gonna select it out in my program (in source code).</p>

<p>there are some codec codes can be applied with CvInvoke.CV_FOURCC('I', 'Y', 'U', 'V') or others but i dont have any ideas for Windows Media Video 9.</p>

<p>I am just wondering if there somebody faced same problem like im experiencing.</p>

<p>any ideas highly appreciated.
thanks~</p>
",2012-07-04 06:50:23,2016-10-12 14:40:40,Emgu CV VideoWriter with specific codec,<c#><emgucv><avi><opencvdotnet>,,,CC BY-SA 3.0,False,False,True,False,False
5296,15194310,2013-03-04 03:53:34,,"<p>Let me start off by saying that I have indeed followed many tutorials such as the one located on EmguCv's main site in their entirety but get a TypeInitializationException thrown.  </p>

<p>Now, listen closely because here comes the extremely weird part. I'll start by saying that there are three ""levels"" of my problem, however, the code in all ""levels"" is EXACTLY the same without even the slightest of change. This would naturally point to that I have a reference or linkage problem, but again I've attempted multiple attempts following different tutorials but to no avail.  </p>

<p>Level 1 (this level produces a TypeInitializationException)<br>
I create a new project, properly reference everything and such, then write my code in this new project. Upon debug, I get that exception thrown and my program exits. Here's a link to a picture of the problem: <a href=""http://prntscr.com/uychc"" rel=""nofollow"">http://prntscr.com/uychc</a>  </p>

<p>Level 2 (this level runs completely fine and no exception is thrown)<br>
In this level, I pretty much located one of EmguCv's example projects (VideoSurveilance in this case) then delete the default code and copy and paste all of my code in there. After adding a few more references that I needed, the program works fine. I cant post more than 3 links, but you'll have to trust me that the video picture displays correctly.</p>

<p>Level 3 (this level does not throw an exception but warns me of a ""first chance"" of one)<br>
In this level, I copy and paste my whole Level 2 project into a different directory. After finding and relinking missing files/references, I am able to run the program but the pictures do not show and I get a ""A first chance exception of type ""System.TypeInitializationException"" occurred in Emgu.CV.dll warning. <a href=""http://prntscr.com/uycmn"" rel=""nofollow"">http://prntscr.com/uycmn</a>  </p>

<p>I currently run Windows 7 x64 (yes I changed build options to x64 and x64 .dlls) and am running EmguCv 2.4.9 and 2.4.2 (tested on both) and Visual Studios 2010 and 2012 (tested on both).  </p>

<p>Here's the code for what it may be worth:  </p>

<pre><code>    using System;
    using System.Collections.Generic;
    using System.ComponentModel;
    using System.Data;
    using System.Drawing;
    using System.Linq;
    using System.Text;
    //using System.Threading.Tasks;
    using System.Windows.Forms;

    using System.Windows;
    using System.Windows.Controls;
    using System.Windows.Data;
    using System.Windows.Documents;
    using System.Windows.Input;
    using System.Windows.Media;
    using System.Windows.Media.Imaging;
    using System.Windows.Navigation;
    using System.Windows.Shapes;

    using Microsoft.Kinect;
    using Emgu.CV;
    using Emgu.CV.CvEnum;
    using Emgu.CV.Structure;
    using Emgu.CV.UI;
    using System.IO;

    namespace VideoSurveilance
    {
       public partial class VideoSurveilance : Form
       {
            KinectSensor sensor;
            WriteableBitmap depthBitmap;
            WriteableBitmap colorBitmap;
            DepthImagePixel[] depthPixels;
            byte[] colorPixels;

            int blobCount = 0;

          public VideoSurveilance()
          {
             InitializeComponent();

          }

          private void VideoSurveilance_Load(object sender, System.EventArgs e)
          {
              foreach (var potentialSensor in KinectSensor.KinectSensors)
              {
                  if (potentialSensor.Status == KinectStatus.Connected)
                  {
                      this.sensor = potentialSensor;
                      break;
                  }
              }


              if (null != this.sensor)
              {

                  this.sensor.DepthStream.Enable(DepthImageFormat.Resolution640x480Fps30);
                  this.sensor.ColorStream.Enable(ColorImageFormat.RgbResolution640x480Fps30);
                  this.colorPixels = new byte[this.sensor.ColorStream.FramePixelDataLength];
                  this.depthPixels = new DepthImagePixel[this.sensor.DepthStream.FramePixelDataLength];
                  this.colorBitmap = new WriteableBitmap(this.sensor.ColorStream.FrameWidth, this.sensor.ColorStream.FrameHeight, 96.0, 96.0, PixelFormats.Bgr32, null);
                  this.depthBitmap = new WriteableBitmap(this.sensor.DepthStream.FrameWidth, this.sensor.DepthStream.FrameHeight, 96.0, 96.0, PixelFormats.Bgr32, null);



                  WriteableBitmap bitmap;
                  bitmap = new WriteableBitmap(this.sensor.DepthStream.FrameWidth, this.sensor.DepthStream.FrameHeight, 96.0, 96.0, PixelFormats.Bgr32, null);



                  byte[] retVal = new byte[bitmap.PixelWidth * bitmap.PixelHeight * 4];
                  bitmap.CopyPixels(new Int32Rect(0, 0, bitmap.PixelWidth, bitmap.PixelHeight), retVal, bitmap.PixelWidth * 4, 0);

                  Bitmap b = new Bitmap(bitmap.PixelWidth, bitmap.PixelHeight);
                  int k = 0;
                  byte red, green, blue, alpha;
                  for (int i = 0; i &lt; bitmap.PixelWidth; i++)
                  {
                      for (int j = 0; j &lt; bitmap.PixelHeight &amp;&amp; k &lt; retVal.Length; j++)
                      {
                          alpha = retVal[k++];
                          blue = retVal[k++];
                          green = retVal[k++];
                          red = retVal[k++];

                          System.Drawing.Color c = new System.Drawing.Color();
                          c = System.Drawing.Color.FromArgb(alpha, red, green, blue);

                          b.SetPixel(i, j, c);
                      }
                  }


                  Image&lt;Bgr, Byte&gt; temp = new Image&lt;Bgr, byte&gt;(b);



                  this.ibOriginal.Image = temp;

                  this.sensor.AllFramesReady += this.sensor_AllFramesReady;

                  try
                  {
                      this.sensor.Start();
                  }
                  catch (IOException)
                  {
                      this.sensor = null;
                  }
              }
          }


          private void sensor_AllFramesReady(object sender, AllFramesReadyEventArgs e)
          {
              blobCount = 0;
              BitmapSource depthBmp = null;
              Image&lt;Bgr, Byte&gt; openCVImg;
              using (ColorImageFrame colorFrame = e.OpenColorImageFrame())
              {
                  using (DepthImageFrame depthFrame = e.OpenDepthImageFrame())
                  {
                      if (depthFrame != null)
                      {

                          blobCount = 0;
                          if (colorFrame != null)
                          {
                              byte[] pixels = new byte[colorFrame.PixelDataLength];
                              colorFrame.CopyPixelDataTo(pixels);

                              int stride = colorFrame.Width * 4;
                              BitmapSource color = BitmapImage.Create(colorFrame.Width, colorFrame.Height, 96, 96, PixelFormats.Bgr32, null, pixels, stride);
                              openCVImg = new Image&lt;Bgr, byte&gt;(color.ToBitmap());
                          }
                          else
                          {
                              return;
                          }

                          Image&lt;Gray, byte&gt; gray_image;

                          using (MemStorage stor = new MemStorage())
                          {
                              gray_image = openCVImg.InRange(new Bgr(0, 0, 150), new Bgr(200, 200, 255));

                              gray_image = gray_image.SmoothGaussian(9);

                              CircleF[] circles = gray_image.HoughCircles(new Gray(100),
                                                                          new Gray(50),
                                                                          2,
                                                                          gray_image.Height / 4,
                                                                          10,
                                                                          400)[0];

                              foreach (CircleF circle in circles)
                              {
                                  CvInvoke.cvCircle(openCVImg,
                                                    new System.Drawing.Point(Convert.ToInt32(circle.Center.X), Convert.ToInt32(circle.Center.Y)),
                                                    3,
                                                    new MCvScalar(0, 255, 0),
                                                    -1,
                                                    LINE_TYPE.CV_AA,
                                                    0);

                                  openCVImg.Draw(circle,
                                                 new Bgr(System.Drawing.Color.Red),
                                                 3);
                              }
                          }
                          ibOriginal.Image = openCVImg;
                          ibProcessed.Image = gray_image;

                      }
                  }



              }
          }


       }
    }

using System;
using System.Globalization;
using System.IO;
using System.Windows;
using System.Windows.Media;
using System.Windows.Media.Imaging;
using Microsoft.Kinect;
using System.ComponentModel;
using System.Runtime.InteropServices;
using Emgu.CV;

namespace VideoSurveilance
{
    public static class Helper
    {

        private const int MaxDepthDistance = 4000;
        private const int MinDepthDistance = 850;
        private const int MaxDepthDistanceOffset = 3150;

        public static BitmapSource SliceDepthImage(this DepthImageFrame image, int min = 20, int max = 1000)
        {
            int width = image.Width;
            int height = image.Height;

            //var depthFrame = image.Image.Bits;
            short[] rawDepthData = new short[image.PixelDataLength];
            image.CopyPixelDataTo(rawDepthData);

            var pixels = new byte[height * width * 4];

            const int BlueIndex = 0;
            const int GreenIndex = 1;
            const int RedIndex = 2;

            for (int depthIndex = 0, colorIndex = 0;
                depthIndex &lt; rawDepthData.Length &amp;&amp; colorIndex &lt; pixels.Length;
                depthIndex++, colorIndex += 4)
            {

                // Calculate the distance represented by the two depth bytes
                int depth = rawDepthData[depthIndex] &gt;&gt; DepthImageFrame.PlayerIndexBitmaskWidth;

                // Map the distance to an intesity that can be represented in RGB
                var intensity = CalculateIntensityFromDistance(depth);

                if (depth &gt; min &amp;&amp; depth &lt; max)
                {
                    // Apply the intensity to the color channels
                    pixels[colorIndex + BlueIndex] = intensity; //blue
                    pixels[colorIndex + GreenIndex] = intensity; //green
                    pixels[colorIndex + RedIndex] = intensity; //red                    
                }
            }

            return BitmapSource.Create(width, height, 96, 96, PixelFormats.Bgr32, null, pixels, width * 4);
        }




        public static byte CalculateIntensityFromDistance(int distance)
        {
            // This will map a distance value to a 0 - 255 range
            // for the purposes of applying the resulting value
            // to RGB pixels.
            int newMax = distance - MinDepthDistance;
            if (newMax &gt; 0)
                return (byte)(255 - (255 * newMax
                / (MaxDepthDistanceOffset)));
            else
                return (byte)255;
        }


        public static System.Drawing.Bitmap ToBitmap(this BitmapSource bitmapsource)
        {
            System.Drawing.Bitmap bitmap;
            using (var outStream = new MemoryStream())
            {
                // from System.Media.BitmapImage to System.Drawing.Bitmap
                BitmapEncoder enc = new BmpBitmapEncoder();
                enc.Frames.Add(BitmapFrame.Create(bitmapsource));
                enc.Save(outStream);
                bitmap = new System.Drawing.Bitmap(outStream);
                return bitmap;
            }
        }


        [DllImport(""gdi32"")]
        private static extern int DeleteObject(IntPtr o);

        /// &lt;summary&gt;
        /// Convert an IImage to a WPF BitmapSource. The result can be used in the Set Property of Image.Source
        /// &lt;/summary&gt;
        /// &lt;param name=""image""&gt;The Emgu CV Image&lt;/param&gt;
        /// &lt;returns&gt;The equivalent BitmapSource&lt;/returns&gt;
        public static BitmapSource ToBitmapSource(IImage image)
        {
            using (System.Drawing.Bitmap source = image.Bitmap)
            {
                IntPtr ptr = source.GetHbitmap(); //obtain the Hbitmap

                BitmapSource bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
                    ptr,
                    IntPtr.Zero,
                    Int32Rect.Empty,
                    System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions());

                DeleteObject(ptr); //release the HBitmap
                return bs;
            }
        }

    }
}
</code></pre>

<p>I sincerely thank anyone who even attempts to help me and hope that anyone with similar problems can benefit from this long question.</p>
",,2015-12-05 18:21:04,EmguCv TypeInitializationException Thrown by EmguCv.CV.CvInvoke,<c#><exception><opencv><kinect><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5303,14230027,2013-01-09 07:10:22,,"<p>HI Im using the code for face detection. but not im going to continue with face recognition. But im get stack here where, how for the next step. However, im using the emgu version 2.2</p>

<pre><code>            if (faces.Length &gt; 0)
            {
                foreach (var face in faces)
                {
                    ImageFrame.Draw(face.rect, new Bgr(Color.Green), 2);
                    //Extract face 
                    ExtractedFace = new Bitmap(face.rect.Width, face.rect.Height);

                    FaceConvas = Graphics.FromImage(ExtractedFace);
                    FaceConvas.DrawImage(GrayBmpInput, 0, 0, face.rect, GraphicsUnit.Pixel); 
                    ExtcFacesArr[faceNo] = ExtractedFace;
                    faceNo++;

                }

                faceNo = 0; 
                picExtcFaces.Image = ExtcFacesArr[faceNo];

                CamImageBox.Image = ImageFrame;
            }
        }
</code></pre>

<p>Where should i continue with the face recognition and do have any good reference online in C# code?</p>
",,2013-01-15 08:02:26,face regonition OpenCV 2.2,<c#><asp.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5318,12303614,2012-09-06 15:38:02,,"<p>I am using kinect skd 1.5 and WPF application to simulate mouse events. To do that i am using kinect sensor. Hear i use depthFrames to get the distance to hand and track the hand. I have tracked the hand correctly. But to do the gesture recognition I have to use the gray scale image. I can get the hand using depthFrame. But it return the byte[] array.. Is there any way to convert this byte array to grayScale image. To do the gesture recognition I am using EmguCV for openCV wrapper. This is my soruce code. But when i converting,My bitmap opject->static members have error saying ""Cannot dereference Expression.The pointer is not valid"".. How can i do this process corectly. plz help me..</p>

<pre><code>using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Windows;
using System.Windows.Controls;
using System.Windows.Data;
using System.Windows.Documents;
using System.Windows.Input;
using System.Windows.Media;
using System.Windows.Media.Imaging;
using System.Windows.Navigation;
using System.Windows.Shapes;
using Microsoft.Kinect;
using System.Windows.Forms;
using Emgu.CV.Structure;
using Emgu.CV;
using System.IO;
using System.Drawing;
using System.ComponentModel;
using System.Drawing.Imaging;
using System.Runtime.InteropServices;

namespace SkelitonApp
{
/// &lt;summary&gt;
/// Interaction logic for MainWindow.xaml
/// &lt;/summary&gt;
public partial class MainWindow : Window
{

    byte[] pixeData;
    private WriteableBitmap colorBitmap;
    KinectSensor kinectsensor = KinectSensor.KinectSensors.FirstOrDefault(s =&gt; s.Status == KinectStatus.Connected);
    public MainWindow()
    {

        InitializeComponent();

    }

    const int skeletonCount = 6;
    Skeleton[] allSkeletons = new Skeleton[skeletonCount];

    private void Window_Loaded(object sender, RoutedEventArgs e)
    {

        kinectsensor.Start();
        kinectsensor.AllFramesReady+=new EventHandler&lt;AllFramesReadyEventArgs&gt;(kinectsensor_AllFramesReady);
        kinectsensor.ColorStream.Enable();
        kinectsensor.DepthStream.Enable();
        kinectsensor.SkeletonStream.Enable();
    }

    void kinectsensor_AllFramesReady(object sender, AllFramesReadyEventArgs e)
    {

        Skeleton first = GetFirstSkeleton(e);
        if (first == null)
        {
            return;
        }
        GetCameraPoint(first, e);
        //set scaled position
        /*ScalePosition(headImage, first.Joints[JointType.Head]);
        ScalePosition(leftEllipse1, first.Joints[JointType.HandLeft]);
        ScalePosition(rightEllipse2, first.Joints[JointType.HandRight]);*/


        using (DepthImageFrame handDepthFrame = e.OpenDepthImageFrame())
        {
            byte[] handBytes = null;
            SkeletonFrame newskeletonFrame;
            if (handDepthFrame == null)
            {
                return;
            }
            using (newskeletonFrame = e.OpenSkeletonFrame())
            {
                if (newskeletonFrame == null)
                {
                    return;
                }


            }
            handBytes = GenerateColoredBytes(handDepthFrame, newskeletonFrame, first);
            int stride = handDepthFrame.Width * 4;
            image2.Source =
                BitmapSource.Create(handDepthFrame.Width, handDepthFrame.Height, 96, 96, PixelFormats.Bgr32, null, handBytes, stride);

             //Hear is the place that i have the error(nnn bitmap variable)
            Bitmap nnn = BitmapSourceToBitmap2(BitmapSource.Create(handDepthFrame.Width, handDepthFrame.Height, 96, 96, PixelFormats.Bgr32, null, handBytes, stride));



            Console.WriteLine(""aa"");
        }
    }
    public static System.Drawing.Bitmap BitmapSourceToBitmap2(BitmapSource srs)
    {
        System.Drawing.Bitmap btm = null;
        int width = srs.PixelWidth;
        int height = srs.PixelHeight;
        int stride = width * ((srs.Format.BitsPerPixel + 7) / 8);
        IntPtr ptr = Marshal.AllocHGlobal(height * stride);
        srs.CopyPixels(new Int32Rect(0, 0, width, height), ptr, height * stride, stride);
        btm = new System.Drawing.Bitmap(width, height, stride, System.Drawing.Imaging.PixelFormat.Format1bppIndexed, ptr);
        return btm;
    }

    private byte[] GenerateColoredBytes(DepthImageFrame handDepthFrame, SkeletonFrame newskeletonFrame, Skeleton first)
    {


       short[] rawDepthdata=new short[handDepthFrame.PixelDataLength];
       handDepthFrame.CopyPixelDataTo(rawDepthdata);
        Byte[] pixels=new byte[handDepthFrame.Height*handDepthFrame.Width*4];

        DepthImagePoint rightHandPoint = handDepthFrame.MapFromSkeletonPoint(first.Joints[JointType.HandRight].Position);

        int DistanceToHand = rightHandPoint.Depth;
        const int BlueIndex = 0;
        const int GreenIndex =1;
        const int RedIndex = 2;

        int handDistanceMax = DistanceToHand + 10;
        int handDistancemin = DistanceToHand - 60;
        //int handAreaDiff = handDistanceMax - handDistancemin;

        for (int depthIndex = 0, colorIndex = 0; depthIndex &lt; rawDepthdata.Length &amp;&amp; colorIndex &lt; pixeData.Length; depthIndex++, colorIndex += 4)
        {
            int player = rawDepthdata[depthIndex] &amp; DepthImageFrame.PlayerIndexBitmask;
            int depth = rawDepthdata[depthIndex] &gt;&gt; DepthImageFrame.PlayerIndexBitmaskWidth;

            /*if (depth &lt; 900)
            {
                pixels[colorIndex + BlueIndex] = 255;
                pixels[colorIndex + GreenIndex] = 0;
                pixels[colorIndex + RedIndex] = 0;

            }*/

            if (depth &lt;handDistanceMax &amp;&amp; depth&gt;handDistancemin)
            {
                pixels[colorIndex + BlueIndex] = 255;
                pixels[colorIndex + GreenIndex] = 0;
                pixels[colorIndex + RedIndex] = 0;

            }

        }


        return pixels;
    }




    private void ScalePosition(FrameworkElement element, Joint joint)
    {
        /*Joint scaledJoint = joint.ScaleTo(1280, 720);

        Canvas.SetLeft(element, scaledJoint.Position.X);
        Canvas.SetTop(element, scaledJoint.Position.Y); */
    }

    private void GetCameraPoint(Skeleton first, AllFramesReadyEventArgs e)
    {
        using (DepthImageFrame depth = e.OpenDepthImageFrame())
        {
            if (depth == null)
            {
                return;
            }

            //map a joint location to a point on the depth map
            DepthImagePoint headDepthPoint =
                depth.MapFromSkeletonPoint(first.Joints[JointType.Head].Position);
            DepthImagePoint leftDepthPoint =
                depth.MapFromSkeletonPoint(first.Joints[JointType.HandLeft].Position);
            DepthImagePoint rightDepthPoint =
                depth.MapFromSkeletonPoint(first.Joints[JointType.HandRight].Position);

            //map a depth point to a point in the color image
            ColorImagePoint headColorPoint =
                depth.MapToColorImagePoint(headDepthPoint.X,headDepthPoint.Y,
                ColorImageFormat.RgbResolution640x480Fps30);

            ColorImagePoint leftColorPoint =
                depth.MapToColorImagePoint(leftDepthPoint.X, leftDepthPoint.Y,
                ColorImageFormat.RgbResolution640x480Fps30);

            ColorImagePoint rightColorPoint =
                depth.MapToColorImagePoint(rightDepthPoint.X, rightDepthPoint.Y,
                ColorImageFormat.RgbResolution640x480Fps30);

            //set location

            //System.Windows.Forms.Cursor.Position = new System.Drawing.Point(rightColorPoint.X,rightColorPoint.Y);

            double screenWidth = Screen.PrimaryScreen.WorkingArea.Width;
            double screenHeight = Screen.PrimaryScreen.WorkingArea.Height;
            double windowWidth = Convert.ToInt32(image1.Width);
            double windowHeight = Convert.ToInt32(image1.Height);
            double x1 = rightColorPoint.X;
            double y1 = rightColorPoint.Y;
            double posX = (x1*100/ windowWidth);
            posX = posX / 100 * screenWidth;

            double posY = (y1 * 100 / windowHeight);
            posY = posY / 100 * screenHeight;

          //  System.Windows.Forms.Cursor.Position = new System.Drawing.Point((int)posX, (int)posY);

           /*
            CameraPosition(headImage,headColorPoint);
            CameraPosition(leftEllipse1, leftColorPoint);
            CameraPosition(rightEllipse2, rightColorPoint);
            */


        }
    }

    private void CameraPosition(FrameworkElement element, ColorImagePoint point)
    {

        Canvas.SetLeft(element,point.X-element.Width/2);
        Canvas.SetTop(element, point.Y - element.Height / 2);

    }

    private Skeleton GetFirstSkeleton(AllFramesReadyEventArgs e)
    {
        ////////////////////////
        bool receiveData = false;
        using (ColorImageFrame colorImageFrame = e.OpenColorImageFrame())
        {
            if (colorImageFrame != null)
            {
                if (pixeData == null)
                {
                    pixeData = new byte[colorImageFrame.PixelDataLength];
                }
                colorImageFrame.CopyPixelDataTo(pixeData);
                receiveData = true;



                this.colorBitmap = new WriteableBitmap(this.kinectsensor.ColorStream.FrameWidth, this.kinectsensor.ColorStream.FrameHeight, 96.0, 96.0, PixelFormats.Bgr32, null);


            }
            else
            {
                // apps processing of image data is taking too long, it got more than 2 frames behind.
                // the data is no longer avabilable.
            }

        }
        if (receiveData)
        {
            this.colorBitmap.WritePixels(
                   new Int32Rect(0, 0, this.colorBitmap.PixelWidth, this.colorBitmap.PixelHeight),
                   this.pixeData,
                   this.colorBitmap.PixelWidth * sizeof(int),
                   0);
            image1.Source = this.colorBitmap;
        }

        ///////////////////////////



       using(SkeletonFrame skeletonFrameData=e.OpenSkeletonFrame())
       {
           if (skeletonFrameData == null)
           {
               return null;
           }

           skeletonFrameData.CopySkeletonDataTo(allSkeletons);

           //get the first tracked skeleton
           Skeleton first=(from s in allSkeletons
                               where s.TrackingState==SkeletonTrackingState.Tracked
                               select s).FirstOrDefault();

            return first;
       }

    }


}
</code></pre>

<p>}</p>
",,2012-09-07 11:48:07,Convert byte[] array to bitmap with kinect 1.5 sdk in WPF application,<bitmap><byte><kinect><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5372,11335806,2012-07-04 21:56:08,,"<p><a href=""http://www.cognotics.com/opencv/servo_2007_series/part_5/fig_6_thumb.png"" rel=""nofollow"">http://www.cognotics.com/opencv/servo_2007_series/part_5/fig_6_thumb.png</a></p>

<p>Can anyone explain why nEgiens must not be over nTrainFace-1 on the picture above?</p>

<p>I am using EmguCv. When nEgiens and nTrainFace are equals, last eigen image is returned blank (black).
However, on emgucv implementation:</p>

<pre><code>`if (termCrit.max_iter &lt;= 0 || termCrit.max_iter &gt; trainingImages.Length)
    termCrit.max_iter = trainingImages.Length;`
</code></pre>
",,2012-07-05 13:10:59,Why Can't EigensCount Be Greater Than TrainingImagesCount-1 [EigenObjectRecognizer],<opencv><emgucv><face-recognition><eigen>,,,CC BY-SA 3.0,True,False,True,False,False
5411,16160945,2013-04-23 04:26:01,,"<p>I have installed EmguCV 2.4.2.1777. I have a 32-bit windows 7 so I installed it using the installer. Now I am trying to write a simple code to capture a webcam's video in a window in C#. 
The problem is after during execution I am getting the following famous error:</p>

<pre><code>A first chance exception of type 'System.DllNotFoundException' occurred in Emgu.CV.dll 
A first chance exception of type 'System.TypeInitializationException' occurred in Emgu.CV.dll
An unhandled exception of type 'System.TypeInitializationException' occurred in Emgu.CV.dll
</code></pre>

<p>The file Emgu.CV.dll is present in the folder. I don't understand why its giving that error.
I tried all the checks which are suggested by fellow stackoverflow users and also many other references:</p>

<p>1) Installed MSVCR:  MSVCRT 10.0 SP1 x86</p>

<p>2) copied the OpenCV dlls to the execution directory</p>

<p>3) I also have a 32-bit OS. So that also should'nt be an issue.</p>

<p>But when I checked for dependencies, I faced a problem:</p>

<p>I used DependecyWalker to open cvextern.dll and found the following dependencies missing:</p>

<pre><code>NVCUDA.DLL
API-MS-WIN-CORE-COM-L1-1-0.DLL
API-MS-WIN-CORE-WINRT-ERROR-L1-1-0.DLL
API-MS-WIN-CORE-WINRT-L1-1-0.DLL
API-MS-WIN-CORE-WINRT-ROBUFFER-L1-1-0.DLL
API-MS-WIN-CORE-WINRT-STRING-L1-1-0.DLL
API-MS-WIN-SHCORE-SCALING-L1-1-0.DLL
DCOMP.DLL
IESHIMS.DLL
</code></pre>

<p>It also gave the following:</p>

<p>Error: At least one required implicit or forwarded dependency was not found.
Warning: At least one delay-load dependency module was not found.
Warning: At least one module has an unresolved import due to a missing export function in a delay-load dependent module.</p>

<p>Please help me out with the exception. Thanks in advance.</p>
",,2013-07-18 22:40:51,EmguCV 'Emgu.CV.CvInvoke' Exception,<visual-studio-2010><exception><opencv><emgucv><typeinitializeexception>,,,CC BY-SA 3.0,True,False,True,False,False
5505,10369056,2012-04-29 01:48:38,,"<pre><code>        m_capture.SetCaptureProperty(CAP_PROP.CV_CAP_PROP_POS_FRAMES, frameID);
        double cap = m_capture.GetCaptureProperty(CAP_PROP.CV_CAP_PROP_POS_FRAMES);
</code></pre>

<p>I am using Emgu 2.3 (x64) and the set capture property as above works bizarrely. For instance in the above I am setting frameID = 500 and check the capture property back and it is set to returns value of 3325.</p>

<p>Anything I am doing wrong?</p>
",,2012-04-29 01:48:38,Emgu SetCaptureProperty CV_CAP_PROP_POS_FRAMES does not work as expected,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
5507,10372044,2012-04-29 12:13:56,,"<p>I am working with EmguCV and I don't know how I can pass array of 2xN, Nx2, 3xN, Nx3 or 1xN (N is number of points) for image points like documented <a href=""http://www.emgu.com/wiki/files/1.5.0.0/Help/html/215e547a-75d0-7e82-36db-bbc144cd9e22.htm"" rel=""nofollow"">here</a>. </p>

<p>I have a method to create an array of float[N,2] but Marshal.Copy has no overloads for multidimensional arrays and I have no idea how I can pass X and Y values as one.</p>
",,2012-04-29 12:46:58,How can I convert List of PointF to IntPtr?,<c#><.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
5515,13296020,2012-11-08 19:09:01,,"<p>I am trying to use sift algorithm to make the keypoints and descriptors in c# by using opencv library.</p>

<pre><code>     fileAddress = dlg.FileName;
     cap = new Emgu.CV.Capture(dlg.FileName);
     cap.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_POS_FRAMES, 3945);
     imGray = cap.QueryGrayFrame();
     Emgu.CV.Features2D.SIFTDetector siftDet = new Emgu.CV.Features2D.SIFTDetector();
     siftDet.DetectKeyPoints(imGray);
     MessageBox.Show(""test SIFT"");
</code></pre>

<p>but when it go through the line <strong>Emgu.CV.Features2D.SIFTDetector siftDet = new Emgu.CV.Features2D.SIFTDetector();</strong>  I face the error:</p>

<p><img src=""https://i.stack.imgur.com/UrGpi.png"" alt=""enter image description here"">  </p>

<p>and view detail is as following:</p>

<p><img src=""https://i.stack.imgur.com/qfqEm.png"" alt=""enter image description here"">  </p>

<p>How could I solve this exception?</p>
",2012-11-08 19:22:06,2012-11-08 23:10:40,While want to make an instance of SIFTDetector: Get an Attempted to read or write protected memory exception Error,<c#><.net><c#-4.0><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5518,16170250,2013-04-23 13:11:02,,"<p>I'm trying to run DFT in 4x4 blocks over this image (look closely, it's small) <img src=""https://i.stack.imgur.com/3likh.png"" alt=""enter image description here""> It may be a bit too small to see, but it's a 4x12 pixel image. The first 4x4 square is a checkerboard pattern with each square having one pixel, the second 4x4 square is the same pattern with each square having two pixels, and the last 4x4 square is a black square.</p>

<p>The problem I have is that the frequency components I get are not what I expect at all. For example, for the first square I expect to have a DC component in the matrix, but it's not there. I figure I must be doing something wrong but I'm new to EMGU so I'm not sure what. Below is my code.</p>

<pre><code>using (Image&lt;Bgr, byte&gt; image = new Image&lt;Bgr, byte&gt;(Openfile.FileName))                
using (Image&lt;Gray, float&gt; gray = image.Convert&lt;Gray, float&gt;())
{
    int numRectanglesPerRow = image.Width / WIDTH;
    int numRectanglesPerColumn = image.Height / HEIGHT;

    for (int i = 0; i &lt; numRectanglesPerColumn; i++)
    {
        for (int j = 0; j &lt; numRectanglesPerRow; j++)
        {
            Rectangle rectangle = new Rectangle(WIDTH * j, HEIGHT * i, WIDTH, HEIGHT);

            Image&lt;Gray, float&gt; subImage = gray.Copy(rectangle);

            Matrix&lt;float&gt; dft = new Matrix&lt;float&gt;(subImage.Rows, subImage.Cols, 2);
            CvInvoke.cvDFT(subImage, dft, Emgu.CV.CvEnum.CV_DXT.CV_DXT_FORWARD, -1);

            //The Real part of the Fourier Transform
            Matrix&lt;float&gt; outReal = new Matrix&lt;float&gt;(subImage.Size);
            //The imaginary part of the Fourier Transform
            Matrix&lt;float&gt; outIm = new Matrix&lt;float&gt;(subImage.Size);
            CvInvoke.cvSplit(dft, outReal, outIm, IntPtr.Zero, IntPtr.Zero);
        }
    }
}
</code></pre>
",2013-04-25 11:48:19,2013-04-25 11:48:19,DFT with EMGU/OpenCV - I'm doing something wrong,<fft><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5524,12324947,2012-09-07 20:29:01,,"<p>Can someone please help me out with how exactly to start from scratch for using OpenCV for hand gesture recognition? We're basically creating a media player that can function with hand gestures (simple functions such as play, pause, volume up/down etc). </p>

<p>I've installed OpenCV and also EmguCV after visiting one of the links mentioned in the questions, but I need to know how exactly do I get webcam on to detect my hand and gestures.</p>
",2012-09-08 04:19:55,2012-09-08 10:05:14,Gesture Recognition OpenCV ( for media player ),<opencv><media-player><tracking><emgucv><gesture-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
5528,11348384,2012-07-05 16:12:00,,"<p>I always get this error when I run my program...</p>
<p><img src=""https://i.stack.imgur.com/KEOaf.png"" alt=""enter image description here"" /></p>
<p>i'm not sure about what's wrong with my program, FYI, actually my program consist of many image processing algorithm's such as</p>
<ul>
<li>viola-jones, haarcascade for hand detection</li>
<li>camshift + kalman filter for hand tracking</li>
<li>convex hull and convexity defects for counting finger</li>
<li>and other preprocessing ....</li>
</ul>
<p>I have no idea whether these process triggering the error or not...</p>
<p>but when I remove convexhull / convexity defects, the errors gone...
any solution?</p>
<p>Edited : (added)</p>
<p>this is the code snippet</p>
<pre><code> private void ExtractContourAndHull()
        {
            using (MemStorage storage = new MemStorage())
            {
                
                Contour&lt;Point&gt; contours = backproject.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST, storage);
                Contour&lt;Point&gt; biggestContour = null;

                Double Result1 = 0;
                Double Result2 = 0;
                while (contours != null)
                {
                    Result1 = contours.Area;
                    if (Result1 &gt; Result2)
                    {
                        Result2 = Result1;
                        biggestContour = contours;
                    }
                    contours = contours.HNext;
                }

                if (biggestContour != null)
                {
                    //image.Draw(biggestContour, new Bgr(Color.DarkViolet), 2);
                    Contour&lt;Point&gt; currentContour = biggestContour.ApproxPoly(biggestContour.Perimeter * 0.005, storage);
                    image.Draw(currentContour, new Bgr(Color.LimeGreen), 2);
                    biggestContour = currentContour;
                 

                    hull = biggestContour.GetConvexHull(ORIENTATION.CV_CLOCKWISE);
                    box = biggestContour.GetMinAreaRect();
                    PointF[] points = box.GetVertices();
                    //handRect = box.MinAreaRect();
                    //image.Draw(handRect, new Bgr(200, 0, 0), 1);

                    Point[] ps = new Point[points.Length];
                    for (int i = 0; i &lt; points.Length; i++)
                        ps[i] = new Point((int)points[i].X, (int)points[i].Y);

                    image.DrawPolyline(hull.ToArray(), true, new Bgr(200, 125, 75), 2);
                    image.Draw(new CircleF(new PointF(box.center.X, box.center.Y), 3), new Bgr(200, 125, 75), 2);

                    //ellip.MCvBox2D= CvInvoke.cvFitEllipse2(biggestContour.Ptr);
                    //image.Draw(new Ellipse(ellip.MCvBox2D), new Bgr(Color.LavenderBlush), 3);

                    //PointF center;
                    //float radius;
                    //CvInvoke.cvMinEnclosingCircle(biggestContour.Ptr, out  center, out  radius);
                    //image.Draw(new CircleF(center, radius), new Bgr(Color.Gold), 2);

                    //image.Draw(new CircleF(new PointF(ellip.MCvBox2D.center.X, ellip.MCvBox2D.center.Y), 3), new Bgr(100, 25, 55), 2);
                    //image.Draw(ellip, new Bgr(Color.DeepPink), 2);

                    //CvInvoke.cvEllipse(image, new Point((int)ellip.MCvBox2D.center.X, (int)ellip.MCvBox2D.center.Y), new System.Drawing.Size((int)ellip.MCvBox2D.size.Width, (int)ellip.MCvBox2D.size.Height), ellip.MCvBox2D.angle, 0, 360, new MCvScalar(120, 233, 88), 1, Emgu.CV.CvEnum.LINE_TYPE.EIGHT_CONNECTED, 0);
                    //image.Draw(new Ellipse(new PointF(box.center.X, box.center.Y), new SizeF(box.size.Height, box.size.Width), box.angle), new Bgr(0, 0, 0), 2);


                    filteredHull = new Seq&lt;Point&gt;(storage);
                    for (int i = 0; i &lt; hull.Total; i++)
                    {
                        if (Math.Sqrt(Math.Pow(hull[i].X - hull[i + 1].X, 2) + Math.Pow(hull[i].Y - hull[i + 1].Y, 2)) &gt; box.size.Width / 10)
                        {
                            filteredHull.Push(hull[i]);
                        }
                    }

                    defects = biggestContour.GetConvexityDefacts(storage, Emgu.CV.CvEnum.ORIENTATION.CV_CLOCKWISE);
                    
                    defectArray = defects.ToArray();
                }
            }
        }
        private void DrawAndComputeFingersNum()
        {
            using (MemStorage storage = new MemStorage())
            {
                int fingerNum = 0;
                
                

                #region hull drawing
                //for (int i = 0; i &lt; filteredHull.Total; i++)
                //{
                //    PointF hullPoint = new PointF((float)filteredHull[i].X,
                //                                  (float)filteredHull[i].Y);
                //    CircleF hullCircle = new CircleF(hullPoint, 4);
                //    image.Draw(hullCircle, new Bgr(Color.Aquamarine), 2);
                //}
                #endregion


                #region defects drawing
                ***defects = new Seq&lt;MCvConvexityDefect&gt;(storage);***
                for (int i = 0; i &lt; defects.Total; i++)
                {
                    PointF startPoint = new PointF((float)defectArray[i].StartPoint.X,
                                                    (float)defectArray[i].StartPoint.Y);

                    PointF depthPoint = new PointF((float)defectArray[i].DepthPoint.X,
                                                    (float)defectArray[i].DepthPoint.Y);

                    PointF endPoint = new PointF((float)defectArray[i].EndPoint.X,
                                                    (float)defectArray[i].EndPoint.Y);

                    LineSegment2D startDepthLine = new LineSegment2D(defectArray[i].StartPoint, defectArray[i].DepthPoint);

                    LineSegment2D depthEndLine = new LineSegment2D(defectArray[i].DepthPoint, defectArray[i].EndPoint);

                    CircleF startCircle = new CircleF(startPoint, 5f);

                    
                    CircleF depthCircle = new CircleF(depthPoint, 5f);
                  
                    CircleF endCircle = new CircleF(endPoint, 5f);
                    MCvFont angga = new MCvFont(Emgu.CV.CvEnum.FONT.CV_FONT_HERSHEY_SCRIPT_COMPLEX, 0.5, 0.5);
                   // image.Draw(defectArray[i].StartPoint.X.ToString() + &quot; , &quot; + defectArray[i].StartPoint.Y.ToString(), ref angga, new Point(defectArray[i].StartPoint.X, defectArray[i].StartPoint.Y), new Bgr(Color.Red));
                    image.Draw(defectArray[i].StartPoint.X.ToString() + &quot; , &quot; + defectArray[i].StartPoint.Y.ToString() + &quot; , &quot; + i.ToString(), ref angga, new Point(defectArray[i].StartPoint.X, defectArray[i].StartPoint.Y), new Bgr(Color.Red));

                    //Custom heuristic based on some experiment, double check it before use
                    if ((startCircle.Center.Y &lt; box.center.Y || depthCircle.Center.Y &lt; box.center.Y) &amp;&amp; (startCircle.Center.Y &lt; depthCircle.Center.Y) &amp;&amp; (Math.Sqrt(Math.Pow(startCircle.Center.X - depthCircle.Center.X, 2) + Math.Pow(startCircle.Center.Y - depthCircle.Center.Y, 2)) &gt; box.size.Height / 6.5))
                    {
                        fingerNum++;
                        //image.Draw(startDepthLine, new Bgr(Color.Blue), 2);
                        //image.Draw(depthEndLine, new Bgr(Color.Magenta), 2);
                    }


                    image.Draw(startCircle, new Bgr(Color.Red), 2);
                    image.Draw(depthCircle, new Bgr(Color.Yellow), 5);
                    //image.Draw(endCircle, new Bgr(Color.DarkBlue), 4);
                }
                #endregion

                MCvFont font = new MCvFont(Emgu.CV.CvEnum.FONT.CV_FONT_HERSHEY_DUPLEX, 5d, 5d);
                image.Draw(fingerNum.ToString(), ref font, new Point(50, 150), new Bgr(Color.White));
                hand.fingerChangedCompute = fingerNum;
            }

        }

       
        
        public MemStorage storage { get; set; } 
</code></pre>
<p>orgin
take a look at DrawandComputeFingersNUm() you'll see a line</p>
<pre><code>defects = new Seq&lt;MCvConvexityDefect&gt;(storage);
</code></pre>
<p>the problem will occur when I uncomment the line above..</p>
<p>anyone knows how to solve this problem?
any help would be appreciated..
thanks</p>
",2020-06-20 09:12:55,2014-01-20 05:49:58,AccessViolationException was unhandled in EMGU CV,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5532,11351047,2012-07-05 19:16:52,,"<p>(A newbie in computer vision)</p>

<p>Goal is to reconstitute a game level using image stitching or <strong>any other</strong> method. The level played by someone is video-recorded, these frames will be the input.</p>

<p>Expected result : (level 4-4 of SMB from <a href=""http://www.vgmaps.com/"" rel=""nofollow noreferrer"">http://www.vgmaps.com/</a>)
<img src=""https://i.stack.imgur.com/h2Odj.png"" alt=""enter image description here""></p>

<p>This is my first attempt at addressing this problem, using OpenCV (EmguCV). So far results are excellent but I was wondering whether there are more appropriate techniques knowing that my input will be strictly in 2D ? </p>

<p>I am open to try another framework/technique providing it's not overly complex.</p>

<p>Here are source images :</p>

<p><img src=""https://i.stack.imgur.com/eURJ7.jpg"" alt=""enter image description here""></p>

<p>Result of the 7 first images :
(for some reasons, the Stitcher in OpenCV did not accept 10 at once ...)</p>

<p><img src=""https://i.stack.imgur.com/udqRF.jpg"" alt=""enter image description here""></p>

<p>Result of the last 3 images :</p>

<p><img src=""https://i.stack.imgur.com/XAGCR.jpg"" alt=""enter image description here""></p>
",2012-07-05 21:27:25,2012-07-05 21:27:25,Fine tuning image stitching in OpenCV,<opencv><2d><image-stitching>,,,CC BY-SA 3.0,True,False,True,False,False
5535,12327148,2012-09-08 00:52:59,,"<p>Is it possible to rewrite examples from <a href=""http://opencv.itseez.com/modules/core/doc/xml_yaml_persistence.html"" rel=""nofollow"">XML/YAML Persistence page</a> from <a href=""http://opencv.itseez.com/index.html"" rel=""nofollow"">OpenCV</a> to <a href=""http://file.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow"">EmguCV</a>?<br>
I mean code in first two subchapters: <em>""XML/YAML file storages. Writing to a file storage""</em> and <em>""Reading data from a file storage.""</em></p>

<p>I am mostly interested in saving and loading <code>int</code>-s and sequences.</p>

<p>I have found <a href=""http://www.emgu.com/wiki/files/1.5.0.0/Help/html/4fec74c3-3f3d-4bce-95d9-d049c937ff0c.htm"" rel=""nofollow"">EmguCV cvOpenFileStorage</a> doc - most arguments are <code>IntPtr</code>s and it is not clear for me how to use it for mentioned types (concerning matrices - I have found working examples).</p>
",2012-09-08 21:50:00,2015-04-28 19:01:11,OpenCV FileStorage - how to use in C# with EmguCV?,<c#><opencv><persistence><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5591,9384405,2012-02-21 20:08:06,,"<p>Sir,</p>

<p>I am new to Emgu CV.I am making a face recognition software.I was able to detect the faces using HaarCascade xml Classifiers.But i m stuck up at the next step regarding how to recognise the face.Anyone please tell me how to use MatchTemplate function...</p>

<p>I found this code on the internet </p>

<pre><code>Image&lt;Gray, Byte&gt; templateImage = new Image&lt;Gray, Byte&gt;(bmpSnip);
Image&lt;Gray, float&gt; resultImage = sourceImage.MatchTemplate(templateImage,Emgu.CV.CvEnum.TM_TYPE.CV_TM_CCOEFF_NORMED);

float[,,] matches = resultImage.Data;
for (int x = 0; x &lt; matches.GetLength(1); x++)
{
for (int y = 0; y &lt; matches.GetLength(0); y++)
{
double matchScore = matches[y, x, 0];
if (matchScore &gt; 0.75)
{
Rectangle rect = new Rectangle(new Point(x,y), new Size(1, 1));
imgSource.Draw(rect, new Bgr(Color.Blue), 1);
}
}
</code></pre>

<p>I didnt understand this code...First of all this code is not working ....Secondly if anyone know how to do it correctly ... Please post the code.....</p>
",2012-02-21 20:23:25,2012-02-22 12:23:41,How to perform to Template Matching in Emgu CV,<c#><opencv><emgucv><opencvdotnet>,,,CC BY-SA 3.0,True,False,True,False,False
5594,14255836,2013-01-10 10:34:23,,"<p>I want to develop a marker based augmented reality app, and I've chosen emgu as OpenCV wrapper because is the only framework I found that supports Mono for Android and Monotouch (if you know other frameworks I'll be happy to consider them, if Mono is supported).
I'm developing on windows with a webcam now, and so far I've detected the marker with FindChessboardCorners, using a chessboard as marker. I get the poins and drawing a bitmap in perspective over the chessboard, 3D comes later.</p>

<p>For my app I would like to use, as marker, a QR code, or specifically the 3 squares (with a square inside) that the QR code us as marker (that are the same for every QR code).</p>

<p>What's the best (and fastest,it should work with a cam) way to pass an image and a mark image (the QR code markers in BW) and get the markers positions like FindChessboardCorners?
Or should I stick to the chessboard?</p>

<p>Can you point me to an example, or give me a hint on how to proceed?</p>

<p>Thanks!
mattia</p>
",,2013-01-10 10:34:23,Computer vision: marker shape and way to detect it,<opencv><xamarin.ios><xamarin.android><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5631,14262143,2013-01-10 16:07:30,,"<p>I am familiar with basic code to display an Emgu image in a WPF image box, when all the source code is in the MainWindow.xaml.cs code-behind.</p>

<p>However I am trying to place my Emgu-related code, including the ""ProcessFrame"" event / Queryframe snippet, into a separate class of static methods so that I can reuse them later. I am doing this because while I will want to be able to grab images from the same camera at a later stage, I also want the flexibility to display those images in a different image box. I am having trouble with this step. </p>

<p>If I could bind the Image box dynamically to a property in the static method (and also enable / disable that binding programmatically), I think that would solve my problem. However, there may be some other problem with the approach I am trying to take. Any code / xaml modifications greatly appreciated.</p>

<p>The following code works, but is unsatisfactory because it forces me to bundle ProcessFrame method into the MainWindow code:</p>

<p>XAML (working):</p>

<pre><code>&lt;Window x:Class=""EmguWPF_Test.MainWindow""
     xmlns=""http://schemas.microsoft.com/winfx/2006/xaml/presentation""
     xmlns:x=""http://schemas.microsoft.com/winfx/2006/xaml""
     Title=""MainWindow"" Height=""350"" Width=""525""&gt;
     &lt;Grid&gt;
       &lt;Image Height=""215"" HorizontalAlignment=""Left"" Margin=""62,66,0,0"" Name=""image1"" Stretch=""Fill"" VerticalAlignment=""Top"" Width=""224""  /&gt;
     &lt;/Grid&gt;
&lt;/Window&gt;
</code></pre>

<p>MainWindow Code Snippet (working):</p>

<pre><code>//using statements etc
public partial class MainWindow : Window
{
private Image&lt;Bgr, Byte&gt; image; 
private Capture capture = null;

private void button1_Click(object sender, RoutedEventArgs e)
{
    InitializeCameras();
    timer = new DispatcherTimer();
    timer.Tick+=new EventHandler(ProcessFrame);
    timer.Interval = new TimeSpan(0, 0, 0, 0, 10);
    timer.Start();            
}

private void InitializeCameras()
    {
        if (capture == null)
        {
            try
            {
                capture = new Capture(0);
            }
            catch // etc 
        }
    }

private void ProcessFrame(object sender, EventArgs arg)
    {
        image = capture.QueryFrame();
        image1.Source = BitmapSourceConvert.ToBitmapSource(image);
    }
}

public static class BitmapSourceConvert
{
   [DllImport(""gdi32"")]
    private static extern int DeleteObject(IntPtr o);

    public static BitmapSource ToBitmapSource(IImage image)
    {
        using (System.Drawing.Bitmap source = image.Bitmap)
        {
            IntPtr ptr = source.GetHbitmap(); //obtain the Hbitmap

            BitmapSource bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
                ptr,
                IntPtr.Zero,
                Int32Rect.Empty,
                System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions());

            DeleteObject(ptr); //release the HBitmap
            return bs;
        }
    }
}
</code></pre>

<p>The following code is where I am up to but need help:</p>

<p>XAML (same as before)</p>

<pre><code>&lt;Window x:Class=""EmguWPF_Test.MainWindow""
    xmlns=""http://schemas.microsoft.com/winfx/2006/xaml/presentation""
    xmlns:x=""http://schemas.microsoft.com/winfx/2006/xaml""
    Title=""MainWindow"" Height=""350"" Width=""525""&gt;

&lt;Grid&gt;
    &lt;Image Height=""215"" HorizontalAlignment=""Left"" Margin=""62,66,0,0"" Name=""image1"" Stretch=""Fill"" VerticalAlignment=""Top"" Width=""224""  /&gt;
&lt;/Grid&gt;
&lt;/Window&gt;
</code></pre>

<p>ViewModel Snippet (yes - perhaps too ambitious to be experimenting with design patterns):</p>

<pre><code>public ViewModel()
    {    
        CaptureMethods.InitializeCameras();
        timer = new DispatcherTimer();
        timer.Tick += new EventHandler(CaptureMethods.ProcessFrame);
        timer.Interval = new TimeSpan(0, 0, 0, 0, 10);
        timer.Start(); 
    }
</code></pre>

<p>CaptureMethods class, not working as a separate class in the way I want it to. You will notice I am now defining the capture field in this class, not in the ViewModel class:</p>

<pre><code>class CaptureMethods
{
    private static Capture capture = null;

    public static void InitializeCameras()
    {
        if (capture == null)
        {
            try
            {
                capture = new Capture(0);
            }
            catch // etc 
        }
    }

public static void ProcessFrame(object sender, EventArgs arg)
    {
        image = capture.QueryFrame();
        image1.Source = BitmapSourceConvert.ToBitmapSource(image); // this is my problem line
    }
}

// BitmapSourceConvert class not repeated here to avoid duplication.
</code></pre>

<p>Thanks!</p>
",,2013-10-12 15:33:59,"WPF, Displaying Emgu Image, using Binding",<wpf><design-patterns><binding><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
5659,12336657,2012-09-09 05:07:14,,"<p>Related to: <a href=""https://stackoverflow.com/questions/12328438/opencv-finding-multiple-matches/12328880#12328880"">OpenCv: Finding multiple matches</a></p>

<p>I am now able to mark where all my matches are.  However, because some of the matches aren't perfect, I need to lower my threshold a little.  This means that I have bunches of pixels that are all a match for the same item.</p>

<p>So, if the actual match is at 5,5, I have 9 matches in the range of 4,4 to 6,6.</p>

<p>What's the best approach to combining each of those so that I have a single point for each cluster of matches?</p>
",2017-05-23 12:21:17,2012-09-10 10:21:32,"OpenCV: Match Template, combining close matches",<opencv><emgucv><matchtemplate>,,,CC BY-SA 3.0,True,False,True,False,False
5719,13312932,2012-11-09 17:25:09,,"<p>i want to detect specific object from live ongoing video.so i implement frame extraction part(opencv, c++) as one part and other detection function(emgucv, c#) for other part. for integrating those part i added exe file of c++ project to c# project and that is working well. but now i want to test this project in offline. That mean i want to test this project by using video that saved in hard disk. before integration,c++ project could able to  execute on both online and offline situations.  but after integration that could execute only in online condition. please help me to solve this.</p>
",,2012-11-09 17:37:16,How to get playing video as a camera input?,<c#><c++><image-processing><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5721,12339564,2012-09-09 13:40:38,,"<p>I am working with c# project. so in here I used emguCV image processing library. this is my sample code to access to the web camera and stop. this code works but when I stop the video device it not stop properly.</p>

<pre><code> private void btnStart_Click(object sender, EventArgs e)
    {
        if(capture==null){
            try
            {                    
                capture = new Capture();
            }
            catch(NullReferenceException ex){
                MessageBox.Show(ex.Message);
            }
        }

        if(capture!=null){
            if (captureInProgress)
            {
                btnStart.Text = ""!Start"";
                Application.Idle -= ProcessFrame;
            }
            else {
                btnStart.Text = ""Stop"";
                Application.Idle += ProcessFrame;
            }
        }
        captureInProgress = !captureInProgress;
    }
</code></pre>

<p>what I missed here. please help me.</p>
",,2012-10-17 03:11:56,How to video capture device stop properly,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
5744,11369684,2012-07-06 21:10:17,,"<p>i really a newbie with EgmuCV</p>

<p>i try to capture images from webcam with the following code:</p>

<pre><code>//Program.cs (Winform)
using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;

using Emgu.CV;
using Emgu.CV.UI;
using Emgu.Util;
using Emgu.CV.Structure;

namespace EgmuCVTest
{
    public partial class Form1 : Form
    {
        public Form1()
        {
            InitializeComponent();
        }

        private void button1_Click(object sender, EventArgs e)
        {
            Capture cp = new Capture();
            ImageViewer imv = new ImageViewer();

            Application.Idle += new EventHandler(delegate(object s, EventArgs ea)
            {
                imv.Image = cp.QueryFrame();
            });

            imv.ShowDialog();

        }
    }
}
</code></pre>

<p>i get the follow error: </p>

<p><img src=""https://web.archive.org/web/20150831024424/http://i.stack.imgur.com/nJxD1.jpg"" alt=""enter image description here""></p>

<p>i check and have all necesary dll in the .exe folder</p>
",2015-08-31 02:44:54,2018-05-09 21:31:10,EmguCV TypeInitializationException,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
5746,12343337,2012-09-09 21:56:34,,"<p>Using OpenCV.</p>

<p>I have an RGB image, each value is a float.
I also have a standard color correction matrix 3x4.</p>

<p>What would be the <strong>fastest</strong> way to 'apply' this matrix over the image?</p>

<p>If you don't know color correction... This is a simple matrix operation.</p>

<p>If the Image looks like this (each pixel is 3 floats):</p>

<pre><code>R G B
R G B
R G B
R G B
R G B
.
.
.
</code></pre>

<p>Then I would like to perform the following:</p>

<pre><code>1 R G B     [ A1, A2, A3 ] 
1 R G B     [ R1, R2, R3 ]
1 R G B  *  [ G1, G2, G3 ]
1 R G B     [ B1, B2, B3 ]
1 R G B
.
.
.
</code></pre>

<p>All the values in the 3x4 matrix are constants.</p>

<p>Thanks.</p>
",2012-09-09 23:18:38,2018-03-05 13:09:54,OpenCV - Color correction,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5780,16193644,2013-04-24 13:44:42,,"<p>I'm trying to convert some code from an open source library written with OpenCV 1.0 to EmguCV C# in .NET.</p>

<p>Here is the problematic code:</p>

<pre><code>float* ptr = rotatedEdges-&gt;data.fl;
int step = rotatedEdges-&gt;step / sizeof(float);

for(i = 0; i &lt; _LOCAL_ROT_DIVS; ++i)
{
    reRowPtrs[i] = ptr + i*step;
}
</code></pre>

<p>I know that the <code>rotatedEdges</code> has a <code>Data</code> getter, but this returns a 2D array of float. In OpenCV, the <code>data</code> field in an 1D array of float (if my memory is correct).
So I was wondering what is the correct way of doing this loop so it does exactly the same thing?</p>

<p>Thanks!</p>

<p><em><strong>EDIT</em></strong></p>

<p><a href=""http://code.google.com/p/cvaddon/source/browse/cvaddon_fast_sym/cvaddon_fast_sym_detect.cpp"" rel=""nofollow"">Here is the page</a> with the code I'm trying to convert as asked in the comment.</p>
",2013-04-26 11:37:43,2013-04-26 11:37:43,EmguCV: How to convert code working with pointers and step?,<c#><.net><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5793,12346886,2012-09-10 07:15:12,,"<p>I need to mask a green pixels in the image. 
I have have example of the masking red pixels.
Here the example:</p>

<pre><code>Image&lt;Hsv, Byte&gt; hsv = image.Convert&lt;Hsv, Byte&gt;()

Image&lt;Gray, Byte&gt;[] channels = hsv.Split();

               //channels[0] is the mask for hue less than 20 or larger than 160

CvInvoke.cvInRangeS(channels[0], new MCvScalar(20), new MCvScalar(160), channels[0]);
               channels[0]._Not();
</code></pre>

<p>but, I cant understand from where those parameters where token:</p>

<pre><code>new MCvScalar(20), new MCvScalar(160)
</code></pre>

<p>Any idea which parameters I have to take to mask the green pixels?
Thank you in advance.</p>
",,2012-09-11 19:03:52,How to mask green pixels?,<image-processing><opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5821,12349433,2012-09-10 10:06:23,,"<p>How to convert Image&lt; Bgr,Byte > to Image?</p>

<p>Thank you in advance.</p>
",,2012-09-19 07:43:12,How to convert Emgu.image into image in C#?,<image-processing><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5862,15240782,2013-03-06 06:48:09,,"<p>i've recently switched to Emgu CV from OpenCv.. in opencv, i calculated absolute difference using <code>cvAbsDiff(Frame1,Frame2,foreground);</code>
and i could check the value of frame difference as: <code>if(cvNorm(frame2,frame1) &gt; xyz){ ... }</code>
and here in Emgu cv, i've calculated as: <code>Difference = Previous_Frame.AbsDiff(Frame);</code>
as explained <a href=""http://www.emgu.com/wiki/index.php/CompareImages_-_Difference"" rel=""nofollow"">Here</a> the type of Difference is Image .. i want to know, how can i get the value (double) of difference?? 
Thanks :)</p>
",,2013-03-07 13:52:01,Absolute difference EmguCv,<emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
5866,14280310,2013-01-11 14:33:53,,"<p>I'm looking for a way to use OpenCV (or specifically emguCV in C#) to capture video from the same firewire on 2 different programs simultaneously.  Some posts here said that it can't be done since the source driver would be locked into one application at a time.</p>

<p>I found some <a href=""https://stackoverflow.com/questions/4238029/opencv-how-to-be-capable-to-capture-frames-from-same-camera-with-2-different-ap"">answers</a> here suggesting the use of <a href=""http://splitcam.biz/"" rel=""nofollow noreferrer"">SplitCam</a>, but it seems to only work with Webcam.  Also I don't like the ads on SplitCam (but I can't complain since it's a freeware).  </p>

<p>SplitCam seems to be using the source signal and creates a virtual driver for other programs to use.  Is there a way to do the same thing as SplitCam does using OpenCV?  OpenCV can access firewire camera and I have no issue using it in emguCV with a single program running.</p>
",2017-05-23 10:24:48,2013-01-16 20:11:01,Using emguCV (OpenCV) to capture video in 2 different program from the firewire camera?,<c#><emgucv><firewire>,,,CC BY-SA 3.0,True,False,True,False,False
5886,10401532,2012-05-01 17:21:17,,"<p>Hi I try to calculate fundamental matrix using emguCV library. Here what i did but the returning matrice has values in the image <a href=""http://i46.tinypic.com/2v8pt6v.jpg"" rel=""nofollow"">http://i46.tinypic.com/2v8pt6v.jpg</a></p>

<p>I checked the EmguCV documentation and parameters seems appropriate.</p>

<p>Matrix firstImagePoints = new Matrix(2, 8);</p>

<pre><code>  firstImagePoints[0, 0] = 224.0;
  firstImagePoints[0, 1] = 245.0;
  firstImagePoints[0, 2] = 232.0;
  firstImagePoints[0, 3] = 277.0;
  firstImagePoints[0, 4] = 533.0;
  firstImagePoints[0, 5] = 477.0;
  firstImagePoints[0, 6] = 528.0;
  firstImagePoints[0, 7] = 510.0;

  firstImagePoints[1, 0] = 60.0;
  firstImagePoints[1, 1] = 95.0;
  firstImagePoints[1, 2] = 284.0;
  firstImagePoints[1, 3] = 223.0;
  firstImagePoints[1, 4] = 48.0;
  firstImagePoints[1, 5] = 86.0;
  firstImagePoints[1, 6] = 302.0;
  firstImagePoints[1, 7] = 266.0;
</code></pre>

<p>Matrix secondImagePoints = new Matrix(2, 8);</p>

<pre><code>    secondImagePoints[0, 0] = 111.0;
    secondImagePoints[0, 1] = 129.0;
    secondImagePoints[0, 2] = 123.0;
    secondImagePoints[0, 3] = 159.0;
    secondImagePoints[0, 4] = 401.0;
    secondImagePoints[0, 5] = 344.0;
    secondImagePoints[0, 6] = 402.0;
    secondImagePoints[0, 7] = 382.0;

    secondImagePoints[1, 0] = 79.0;
    secondImagePoints[1, 1] = 111.0;
    secondImagePoints[1, 2] = 295.0;
    secondImagePoints[1, 3] = 236.0;
    secondImagePoints[1, 4] = 52.0;
    secondImagePoints[1, 5] = 94.0;
    secondImagePoints[1, 6] = 317.0;
    secondImagePoints[1, 7] = 279.0;


   fundamentalMatrice=new Matrix&lt;double&gt;(3,3,1);



    CvInvoke.cvFindFundamentalMat(firstImagePoints.Ptr, secondImagePoints.Ptr, fundamentalMatrice.Ptr, Emgu.CV.CvEnum.CV_FM.CV_FM_RANSAC, 1.0, 0.99, IntPtr.Zero);
    isFundamentalMatrixCalculated = true;
</code></pre>
",2012-05-01 17:33:43,2012-05-03 14:15:07,CvInvoke.findFundamentalMatrix method in emguCV,<image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
5920,11381546,2012-07-08 07:47:23,,"<p>when im running emgu on visual studio development server i get this error:</p>

<pre><code>An attempt was made to load a program with an incorrect format. (Exception from HRESULT:0x8007000B)
</code></pre>

<p>but when i running debug on local iis web server it works fine.
it happen on the first code line of emgu that im using:</p>

<pre><code>Image&lt;Bgr, Byte&gt; image = new Image&lt;Bgr, byte&gt;(imagePath);
</code></pre>

<p>this line bind the file in the emgu dll</p>

<p>i allready try to compile emgu on 86 and 64 target and moved those dlls to my project but it didnt make any diffrente still i couldnt run my project on the development server</p>
",,2012-07-08 10:16:28,emgucv on windows 7 64bit,<c#><asp.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
5948,11383816,2012-07-08 14:17:33,,"<p>I am just looking for a efficient way for the following code since I get an stack overflow error, I gave as much as info I can but maybe you don't need all these explanations but just the code itself would suffice, any help would be appreciated to make me get ride of this error;</p>

<p>What I am trying to do applying an operator (Hueckel edge detection operator) to an 9x9 area at a time and repeat it for the whole image. So it is a regular edge detection fundamental. You can see what I mean at the second picture.</p>

<p><img src=""https://i.stack.imgur.com/PyXOV.png"" alt=""enter image description here""> <img src=""https://i.stack.imgur.com/TvexG.png"" alt=""enter image description here""></p>

<p>Function a() is being called 8 times in another function called hueckel_operator() at a time and hueckel_operator is a recursive function which call itself +5 for both x and y parameters every time. That means a() is being called pretty much for the big images and the real problem MyImage[] which is an emgucv Image&lt;> object. Because MyImage[] should check every pixel in a 9x9 matrix and bring the value of it, it is being called 69 * j times more than the function a().</p>

<p>Function input_i_y() brings the y coordinate and there is another function called input_i_x() which brings the x coordinate of the 9x9 matrix. I know, it is extreme to make two seperate function in order to use them as parameter of another function but I couldn't find any better solution. HueckelDisk class is calculating the formula of the 9 different hueckel disks according to the x,y coordinates. According to the fitting accuracy we become sure if there is an edge or not.</p>

<p><img src=""https://i.stack.imgur.com/3nwgq.png"" alt=""enter image description here""></p>

<p>here is the terminating condition of the hueckel_operator()</p>

<pre><code>if (mod_width + counter4 + 10 &gt;= MyImage.Width &amp;&amp; mod_height + counter5 + 10 &gt;= MyImage.Height)
            {
                goto EXIT2;
            }
</code></pre>

<p>here is the beginning and end of the hueckel_operator()</p>

<pre><code>public void hueckel_operator(int counter2, int counter3)
        {      
            counter2 = counter4;
            counter3 = counter5;

               int mod_width = MyImage.Width % 5;
            int mod_height = MyImage.Height % 5;

            if (mod_width + counter4 + 10 &gt;= MyImage.Width &amp;&amp; mod_height + counter5 + 10 &gt;= MyImage.Height)
            {
                goto EXIT2;
            }
            else
            {
                if (mod_width + counter4 + 10 &gt;= MyImage.Width)
                {
                    if (counter5 == 1)
                    {
                        counter5 += 4;
                    }
                    else
                    {
                        counter5 += 5;
                    }
                    counter4 = 1;
                }
                if (counter4 == 1)
                {
                    counter4 += 4;
                }

                else if(counter4 != 0)

                {
                    counter4 += 5;
                }

                if (counter5 == 0 &amp;&amp; counter4 == 0)
                {
                    counter4 = 1;
                    counter5 = 1;
                }
            }
</code></pre>

<p>Here is the end of the hueckel_operator();</p>

<p>EXIT:</p>

<pre><code>               hueckel_operator(counter5, counter4);

        EXIT2:

            MessageBox.Show(""done"");
        }
</code></pre>

<p>here is the function a()</p>

<pre><code> public double a(int j,  int counter6,  int counter7)
                {

                    double result = 0;

                    HueckelDisks hueckel_formula = new HueckelDisks();

                    counter6 = counter4;
                    counter7 = counter5;


                    for (int II = 0; II &lt;= j ; II++)
                    {
                        for (KK = 1; KK &lt; 69; KK++)
                        {

                            result += hueckel_formula.HueckelDisk(input_i_x(KK),input_i_y(KK),j) * MyImage[point_a, point_b].Intensity;

                        }
                    }

                    return result;
                }


         public int input_i_y(int y)
                {        
                    Tuple&lt;int, int&gt;[] myArray =
                    {
                        Tuple.Create(3,1),Tuple.Create(4,1),Tuple.Create(5,1),Tuple.Create(6,1),Tuple.Create(7,1),Tuple.Create(2,2),
                        Tuple.Create(3,2),Tuple.Create(4,2),Tuple.Create(5,2),Tuple.Create(6,2),Tuple.Create(7,2),Tuple.Create(8,2),
                        Tuple.Create(1,3),Tuple.Create(2,3),Tuple.Create(3,3),Tuple.Create(4,3),Tuple.Create(5,3),Tuple.Create(6,3),
                        Tuple.Create(7,3),Tuple.Create(8,3),Tuple.Create(9,3),Tuple.Create(1,4),Tuple.Create(2,4),Tuple.Create(3,4),
                        Tuple.Create(4,4),Tuple.Create(5,4),Tuple.Create(6,4),Tuple.Create(7,4),Tuple.Create(8,4),Tuple.Create(9,4),
                        Tuple.Create(1,5),Tuple.Create(1,5),Tuple.Create(2,5),Tuple.Create(3,5),Tuple.Create(4,5),Tuple.Create(5,5),
                        Tuple.Create(6,5),Tuple.Create(7,5),Tuple.Create(8,5),Tuple.Create(9,5),Tuple.Create(1,6),Tuple.Create(2,6),
                        Tuple.Create(3,6),Tuple.Create(4,6),Tuple.Create(5,6),Tuple.Create(6,6),Tuple.Create(7,6),Tuple.Create(8,6),
                        Tuple.Create(8,6),Tuple.Create(1,7),Tuple.Create(2,7),Tuple.Create(3,7),Tuple.Create(4,7),Tuple.Create(5,7),
                        Tuple.Create(6,7),Tuple.Create(7,7),Tuple.Create(8,7),Tuple.Create(9,7),Tuple.Create(2,8),Tuple.Create(3,8),
                        Tuple.Create(4,8),Tuple.Create(5,8),Tuple.Create(6,8),Tuple.Create(7,8),Tuple.Create(8,8),Tuple.Create(3,9),
                        Tuple.Create(4,9),Tuple.Create(5,9),Tuple.Create(6,9),Tuple.Create(7,9),

                    };


                    return myArray[y].Item2;


                }
</code></pre>
",2012-07-08 15:12:36,2012-07-08 16:22:53,Stack overflow error due to large amount of calculations,<c#><image-processing><stack-overflow>,,,CC BY-SA 3.0,False,False,True,False,False
5979,11386089,2012-07-08 19:43:32,,"<p>I'm trying to build a basic video tracker that tracks an object by his histogram, i have a region (rectangle) where the object is initially located. And i want to get the histogram of the image in that region. (and then to look around in the next frame for that histogram).</p>

<p>How can i get an histogram in a specific area as efficiently as possible ?</p>

<p>p.s 
I work with c# + emgu .. but if there is no solution in emgu but there is in OpenCV it will be helpful too
Thanks.</p>
",,2013-06-04 19:25:52,How can i get the histogram in a region of a picture using EMGU or OpenCv?,<c#><opencv><histogram><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
6006,15253896,2013-03-06 17:20:44,,"<p>I am new at image processing and I use emgu cv with c# and I have a problem.
How can I get R,G,B pixel value from RGB value from an image?</p>
",2013-03-06 18:16:56,2013-03-08 00:17:16,"Get r,g,b pixel from an image",<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6021,12365983,2012-09-11 08:47:35,,"<p>I have an <code>Image&lt;Gray, Byte&gt;</code> trainImage with the size NxN, and i want to change it into 1D <code>Matrix&lt;float&gt;</code> trainMatrix with the size <code>(N^2)x1</code>.</p>

<p>What I am trying to do is to call <code>CvInvoke.cvCalvCovarmatrix()</code>. For the first parameter I'm using <code>Matrix&lt;Single&gt;[]</code> that i convert into <code>IntPtr[]</code>.</p>

<pre><code>Matrix&lt;Single&gt; avg = new Matrix&lt;float&gt;(7, 1);
Matrix&lt;Single&gt; cov = new Matrix&lt;float&gt;(7, 7);
Matrix&lt;Single&gt;[] input = new Matrix&lt;float&gt;[3];
for (int i = 0; i &lt; 3; i++)
    input[i] = new Matrix&lt;float&gt;(7, 1);

IntPtr[] inObjs = Array.ConvertAll&lt;Matrix&lt;Single&gt;, IntPtr&gt;(input, delegate(Matrix&lt;Single&gt; mat) { return mat.Ptr; });

CvInvoke.cvCalcCovarMatrix(inObjs, 3, cov, avg, COVAR_METHOD.CV_COVAR_NORMAL);
</code></pre>

<p>But now i have input that is <code>Image&lt;Gray, Byte&gt;[]</code> with each image size (let's assume) 7x7. I think i will need to convert each image into <code>Matrix&lt;float&gt;</code> with size 49x1 first before changing it into <code>IntPtr[]</code>. How to do it?</p>
",2012-09-11 09:32:12,2012-09-12 00:23:41,"How to convert Image<Gray, Byte> into 1D Matrix<float>?",<c#><image><matrix><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
6028,14294627,2013-01-12 15:08:50,,"<p>I have extracted eyes and mouth from the face, but want to extract emotions from eyes and mouth.. However, mouth is not detected properly..
This is my code..</p>

<pre><code>private void timer1_Tick(object sender, EventArgs e)
{
    using (Image&lt;Bgr, byte&gt; nextFrame = cap.QueryFrame())
    {
        if (nextFrame != null)
        {
            // there's only one channel (greyscale), hence the zero index
            //var faces = nextFrame.DetectHaarCascade(haar)[0];
            Image&lt;Gray, byte&gt; grayframe = nextFrame.Convert&lt;Gray, byte&gt;();
            Image&lt;Gray, Byte&gt; gray = nextFrame.Convert&lt;Gray, Byte&gt;();
            Image&lt;Gray, Byte&gt; gray1 = nextFrame.Convert&lt;Gray, Byte&gt;();

            var faces = grayframe.DetectHaarCascade(
                            haar, 1.4, 4,
                            HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                            new Size(nextFrame.Width / 8, nextFrame.Height / 8)
                            )[0];

            MCvAvgComp[][] eyes = gray.DetectHaarCascade(eye, 1.1, 1, Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(20, 20));
            gray.ROI = Rectangle.Empty;

            MCvAvgComp[][] mouthsDetected = gray.DetectHaarCascade(mouth, 1.1, 10, Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(20, 20));
            gray1.ROI = Rectangle.Empty;

            foreach (MCvAvgComp mouthsnap in mouthsDetected[0])
            {
                Rectangle mouthRect = mouthsnap.rect;
                // mouthRect.Offset(f.rect.X, f.rect.Y);
                nextFrame.Draw(mouthRect, new Bgr(Color.Red), 2);
                detectedmouth = mouthRect;

            }
            foreach (MCvAvgComp eyesnap in eyes[0])
            {
                Rectangle eyeRect = eyesnap.rect;
                // mouthRect.Offset(f.rect.X, f.rect.Y);
                nextFrame.Draw(eyeRect, new Bgr(Color.Green), 2);
            }
            foreach (var face in faces)
            {
                nextFrame.Draw(face.rect, new Bgr(Color.LightGreen), 3);
                facesnap = face.rect;
            }

            pictureBox1.Image = nextFrame.ToBitmap();
        }
    }

}

private void Form1_Load(object sender, EventArgs e)
{
    cap = new Capture(0);
    // adjust path to find your xml
    //haar = new HaarCascade(""haarcascade_frontalface_alt2.xml"");
    haar = new HaarCascade(""haarcascade_frontalface_alt_tree.xml"");
    mouth = new HaarCascade(""Mouth.xml"");

    eye = new HaarCascade(""haarcascade_eye_tree_eyeglasses.xml"");
}

private void button1_Click(object sender, EventArgs e)
{
    Image snap = pictureBox1.Image;

    snap.Save(""c:\\snapshot.jpg"", System.Drawing.Imaging.ImageFormat.Jpeg);

    pictureBox2.Image = snap;
    pictureBox3.Image = cropImage(snap,facesnap);
    pictureBox4.Image = cropImage(snap, detectedmouth);

}

private static Image cropImage(Image img, Rectangle croparea)
{
    Bitmap bmpImage = new Bitmap(img);
    Bitmap bmpCrop = bmpImage.Clone(croparea, bmpImage.PixelFormat);
    return (Image)(bmpCrop);
}
</code></pre>

<p>Please help me in emotion detection and better mouth detection using c#.</p>
",2013-04-06 08:08:42,2013-04-06 08:08:42,Eye and Mouth detection from face using haar-cascades,<c#><.net><winforms><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6068,15255680,2013-03-06 18:57:06,,"<p>So I'm new to image processing, and i'm kinda learning emgucv right now..
..I want to track a Ball with a specific color- orange.. however..
so..what i needed was to threshold, isolate , or binarize (i don't know the right term).. the image to retain a gray image of white and black. the white being the orange colors and black the non-orange.. (sorry if this sounds kinda dumb).. there are however many considerations when binarizing an image... the shadows.. the shades of oranges...</p>

<p>i'm confused as to what is the best function to use..
i've tried the inRange function for Image..</p>

<p>imgProcessed = imgOriginal.InRange(mincolor,maxcolor);</p>

<p>howver,.. i find it slow..and i can't really binarize all of the ball.. (from dark oranges to light oranges).. plus i gotta adjust the values everytime light conditions changes.. are there any ways to get ""all"" or atleast ""most"" of the shades of orange? Sorry..newbie here...I'd appreciate any help..code is not necessary..thanks!:D</p>

<p>there are so many functions to use.. HSV.. inrange.. cvthreshold..what are the best waY? will using hsv rather than bgr be faster?</p>
",,2014-01-12 22:03:46,Efficient Fast Color Extraction Emgucv,<performance><colors><tracking><emgucv><hsv>,,,CC BY-SA 3.0,False,False,True,False,False
6070,11395415,2012-07-09 12:53:05,,"<p>I am trying to programm an edge detection method. And I have used emgucv Image class. Since I need gray values I have declared it as </p>

<pre><code>Image&lt;Gray,float&gt; MyImage = new Image&lt;Gray,float&gt;;
</code></pre>

<p>I select an image and assign its pixel values into MyImage as</p>

<pre><code>public void selectImage()
          { 
               OpenFileDialog opp = new OpenFileDialog();
              if (opp.ShowDialog() == DialogResult.OK)
              {                 
                   MyImage = new Image&lt;Gray,float&gt;(opp.FileName);
                  InputArray = new Image&lt;Gray, float&gt;(opp.FileName);
                  Convert.ToString(MyImage);
                  pictureBox1.Image = MyImage.ToBitmap();                
              }             
          }
</code></pre>

<p>When I click on edge detection button it calls the main recursive function</p>

<pre><code>private void detect_edges_Click(object sender, EventArgs e)
        {          
           hueckel_operator(1, 1);
        }
</code></pre>

<p>This operator repeats itself with 5pixel intervals. In other words I apply it on x axis by incrementing x parameter by 5 and at the end of the row I increment y axis by 5 and so on.</p>

<p>In hueckel_operator, the function ""a()"" which calculates again a very heavy formula is being called 8 times. Here is the a() function</p>

<pre><code> public double a(int j,  int counter6,  int counter7)
            {

                for (int II = 0; II &lt;= j ; II++)
                {
                    for (KK = 1; KK &lt; 70; KK++)
                    {
                         x_value = input_i_x(KK); //this function brings the x coordinate
                         y_value = input_i_y(KK); // this function brings the y coordinate

                result += HueckelDisk(x_value,y_value,j) * MyImage[x_value+counter6, y_value+counter7].Intensity;
                //MyImage.Dispose();
                    }
                }                           
                return result;
            }
</code></pre>

<p>But the problem is approximately at the coordinate (75,5) it throws a stack overflow exception. I debugged it with performance analyse and MyImage seems to eat all memory. You probably wants to see recursive function but since it is too big I can not put it here and I am sure that recursive function (hueckel_operator()) can not reach terminating condition since I found out how many times it has been called. What I want is to find out if there is another way to calculate ""result"" in a more efficient way. </p>

<p>My other question is that, object MyImage is used in function a() 69*j times and does it mean that it allocates memory space 69*j times whenever a() is called?</p>

<p>During my desperate tries, I have declared and defined almost every variable as global in order to reduce the memory usage because I have thought otherwise whenever hueckel_operator() and a() are called, local variables would allocate extra memory in stack over and over, is it a good or necessary approach?</p>

<p>I use 4 very nested and heavy functions and I don't use any class. Would it be the main problem? To be honest I don't see anything here to convert into class.</p>

<p>I know, I have asked too many questions but I am really desperate right now. I am reading articles since some weeks and I guess I need a kick start. Any help would be appreciated.</p>

<p><img src=""https://i.stack.imgur.com/zwG4d.png"" alt=""enter image description here""></p>
",,2012-07-09 13:02:03,How to deal with memory stack overload,<c#><image-processing><stack-overflow><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6085,15260961,2013-03-07 00:34:09,,"<p>I'm using EmguCV Matrix.Add method to append one matrix to another matrix.</p>

<pre><code>Emgu.CV.Matrix&lt;float&gt; descriptors = new Emgu.CV.Matrix&lt;float&gt;(0, dictionarySize);
Emgu.CV.Matrix&lt;float&gt; BOWDescriptor = imageDescriptorExtractor.Compute(trainingImage, keyPoints);
descriptors.Add(BOWDescriptor);
</code></pre>

<p>The corresponding OpenCV code is given below:</p>

<pre><code>Mat bowDescriptor(0, dictionarySize, CV_32FC1);
Mat bowDescriptor;
bowDE.compute(img, keypoints, bowDescriptor);
descriptors.push_back(bowDescriptor);
</code></pre>

<p>During compilation, I will not get any exception. But, when running the app I get the following error:</p>

<blockquote>
  <p><strong>An unhandled exception of type 'Emgu.CV.Util.CvException' occurred in Emgu.CV.dll Additional information: OpenCV: Unknown array type</strong></p>
</blockquote>

<p>Does this have something to do with CV_32FC1 data type? Is my OpenCV to EmguCV conversion correct?</p>

<p>Appreciate your help on this.</p>

<p>Thanks
Jay</p>
",,2013-03-07 01:35:41,OpenCV: Unknown Array Type error in Matrix.cpp,<c#><c++><opencv><matrix><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
6103,12368626,2012-09-11 11:24:28,,"<p>I'm working with Emgu Cv in Winforms to do face recognition using Kinect. Now, i want to move to WPF. However, the EmguCv library support only <strong>Bitmap</strong> class.</p>

<p>Can i use the Bitmap class (used in Winforms) in WPF ? if not, is there an other method to use Emgu cv with kinect in WPF?</p>

<p>Thanks.</p>
",,2014-10-12 23:17:22,Bitmap class in WPF,<wpf><bitmap><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6109,11399190,2012-07-09 16:23:48,,"<p>I am totally new to programming using emgu.I recently understood that it would be helpful to use this library for image processing.So I need to have a good text or ebook which can help me to get familiar with different functions and structures.I would be thankful if you name the best of them and tell me where I can download them.</p>
",2014-04-13 20:42:31,2017-08-17 11:18:10,How can I start image processing using EMGU?,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6143,11402314,2012-07-09 20:09:06,,"<p>I have problems with the following code</p>

<pre><code>namespace MyApp
{    
    public partial class PhotoWindow : Window
    {
        private Capture _capture;

        public PhotoWindow ()
        {
            InitializeComponent();    
            _capture = new Capture();

            if (_capture != null)
            {
                //&lt;Image&gt; in XAML
                CaptureSource.Width = 150;
                CaptureSource.Height = 180;

                _capture.ImageGrabbed += ProcessFrame;
                _capture.Start();                
            }

            Activated += (s, e) =&gt; _capture.Start();
            Closing += (s, e) =&gt;
            {
                if (_capture == null) return;
                _capture.Stop();                
                _capture.Dispose();
            };
        }

        private void ProcessFrame(object sender, EventArgs e)
        {
            try
            {
                Image&lt;Bgr, Byte&gt; frame = _capture.RetrieveBgrFrame();                   
                CaptureSource.Source = Helper.ToBitmapSource(frame);
            }
            catch (Exception exception)
            {

                System.Windows.MessageBox.Show(exception.ToString());
            }
        }

    }
}
</code></pre>

<p>when I run the application I get the exception <code>System.InvalidOperationException: The thread that this call can not access this object because the owner is another thread</code> on line <code>CaptureSource.Source = Helper.ToBitmapSource(frame);</code></p>

<p><strong>As I can solve this?</strong></p>
",2012-07-09 20:54:32,2015-11-26 08:19:10,EmguCV ImageGrabbed Event WPF App,<c#><multithreading><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6147,14303208,2013-01-13 11:59:49,,"<p>I have detected eyes using this code:</p>

<pre><code>MCvAvgComp[][] eyes = gray1.DetectHaarCascade(eye, 1.1, 1, 
       Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(20, 20));
gray1.ROI = Rectangle.Empty;
foreach (MCvAvgComp eyesnap in eyes[0])
{
    Rectangle eyeRect = eyesnap.rect;
    eyeRect.Offset(f.rect.X, f.rect.Y);
    nextFrame.Draw(eyeRect, new Bgr(Color.Green), 2);
}
</code></pre>

<p>I want to take snapshot of both eyes in different picturebox. Can any one help me understand how I can take a snapshot of individual eyes?</p>
",2013-01-13 12:20:37,2013-01-13 16:25:14,Snap Shot of Individual Eyes,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
6165,9434989,2012-02-24 17:09:50,,"<p>I get this error:</p>

<blockquote>
  <p>Unable to find an entry point named 'cvCreateContourTree' in DLL
  'opencv_imgproc231'.</p>
</blockquote>

<p>I am programming in EmguCV 2.3 and have the latest binaries for OpenCV. I checked the DLL exports for 'opencv_imgproc231 and it appears this method is not exported. </p>

<p>Has this method been deprecated? refactored? the documentation seems to state this method is available.</p>

<p>Any ideas? </p>
",2012-02-24 19:03:04,2012-02-24 19:03:04, 'cvCreateContourTree' in DLL 'opencv_imgproc231' - deprecated?,<c#><visual-c++><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
6181,11406479,2012-07-10 04:10:56,,"<p>When i add Emgu.CV Refenrece</p>

<ul>
<li>Emgu.CV.dll</li>
<li>Emgu.CV.UI.dll</li>
<li>Emgu.Util.dll</li>
</ul>

<p>and try to debug in Visual studio 2010 (press the F5 key) then application close abruptly without any warn or alert.</p>

<p>my app have a MainWindow and open a new Window, qhen i try to open the second window (Contain Emgu.CV.Capture) the app close without warn or throw exception</p>
",,2012-07-10 04:10:56,EmguCV close abruptly when debug from visual studio,<visual-studio-2010><visual-studio-debugging><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6213,10427338,2012-05-03 07:58:16,,"<p>If someone can share the code for </p>

<p>What is C++(OpenCV) equivalent for Image.setValue(...) method in C# EmguCV framework.
emgucv reference:
<a href=""http://www.emgu.com/wiki/files/2.3.0/document/Index.html"" rel=""nofollow"">http://www.emgu.com/wiki/files/2.3.0/document/Index.html</a></p>

<p>for example how to code in C++ next:</p>

<pre><code> private static Image&lt;Gray, Byte&gt; FilterPlate(Image&lt;Gray, Byte&gt; plate)
 {
  ...
  Image&lt;Gray, Byte&gt; thresh = plate.ThresholdBinaryInv(new Gray(120), new Gray(255));
  using (Image&lt;Gray, Byte&gt; plateMask = new Image&lt;Gray, byte&gt;(plate.Size))
  plateMask.SetValue(255.0);
  ...
  thresh.SetValue(0, plateMask);
  }
</code></pre>

<p>especially what is C++ equivalent for next:</p>

<pre><code>  thresh.SetValue(0, plateMask);
</code></pre>

<p>Thanks.</p>
",,2012-05-03 08:46:27,C++ OpenCV equivalent for C# EmguCV Image.setValue(...) method,<c#><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
6245,13355723,2012-11-13 04:47:00,,"<p>I have a float[n,128] array. Now I want to convert each row into a separate vector as following:</p>

<p>// The code here is a Pseudo Code  </p>

<pre><code>int n=48;  
    float[,] arrFloat=new float[n,128];  
    VectorOfFloat v1 = new VectorOfFloat(128);  // Vn equals to number of n

     v1= arrFloat[0];
     v2=arrFloat[1]
      .
      .
      .
      .
      Vn
</code></pre>

<p><strong>What is the optimize way?</strong></p>

<hr>

<p>I could possibly write the code as following, but I think there should be a better way:</p>

<pre><code> List&lt;VectorOfFloat&gt; descriptorVec = new List&lt;VectorOfFloat&gt;();
VectorOfFloat v1 = new VectorOfFloat();  
                    var temp = new float[128];  
                    for (int i = 0; i &lt; descriptors1.GetLength(0); i++)  
                    {  
                        for (int j = 0; j &lt; descriptors1.GetLength(1); j++)  
                        {  
                            temp[j] = descriptors1[0, j];  
                        }  
                        v1.Push(temp);  
                        descriptorVec.Add(v1);  
                    }  
</code></pre>
",2012-11-13 06:21:34,2012-11-13 12:27:23,Convert each row of matrix( float) in to a vector,<c#><.net><c#-4.0><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6248,12386859,2012-09-12 11:13:17,,"<p>I have developed a bunch of algorithms on facial recognition using VC# 10 and Emgucv and now I am supposed to export that on cloud through an web API. I don't really want to rewrite the entire code and I am hoping there is a very flexible way of incorporating all the modules I have developed into a single web api to be deployed on azure. I have tried converting them into dlls and running them under xbap. This is the route I want to avoid. Deeply appreciated if you could respond to my query.</p>
",2013-09-04 00:01:07,2013-09-04 00:01:07,Facial recognition algorithms Windows form to Web surface API on cloud?,<visual-studio><cloud><emgucv><face-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
6277,12387127,2012-09-12 11:28:49,,"<p>I'm doing a skin detection method in c# using EmguCV. For skin detection I'm referring this <a href=""http://ac.aua.am/skhachat/Public/Papers%20on%20Face%20Detection/RGB-H-CbCr%20Skin%20Colour%20Model%20for%20Human%20Face%20Detection.pdf"" rel=""nofollow"">article</a>. I'm new in EmguCV. I just want to know how to get or set every pixel value of image that is capturing via webcam. If skin pixel matched it become white else black. I just want RGB value of pixel without degrading the performance of application.</p>
",2012-10-06 13:41:01,2012-10-06 13:41:01,EmguCV Skin Detection,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6303,14318964,2013-01-14 13:06:12,,"<p>I need to reference EmguCV from a solution containing one C# WinForms project.</p>

<p>There are four versions of the same library i.e. x86 vand x64, each with and without GPU support. The library requires references to EmguCV's managed DLLs as well as OpenCV's unmanaged DLLs. Copying the correct unmanaged version to the <code>[Bin]</code> folder is easy enough through post-build events.</p>

<p>I want to be able to switch between the managed references easily through code. Maybe something like the following:</p>

<pre><code>public enum EnumEmguCvTarget
{
    None, // Do not use EmguCv
    EmguCvTargetTbb86, // Target EmguCv for x86 without GPU.
    EmguCvTargetGpu86, // Target EmguCv for x86 with GPU.
    EmguCvTargetTbb64, // Target EmguCv for x64 without GPU.
    EmguCvTargetGpu64, // Target EmguCv for x64 with GPU.
}

public EnumEmguCvTarget EmguCvTarget
{ get { return (EnumEmguCvTarget.EmguCvTargetGpu64); } }
</code></pre>

<p>Since I am referencing these assemblies at compile time (not late binding), is there a way I can programatically switch between versions based on the value of <code>[EmguCvTarget]</code>?</p>
",2013-01-14 14:26:54,2013-01-14 14:26:54,Auto switching between multiple versions of referenced assemblies,<.net><reflection><reference><emgucv><early-binding>,,,CC BY-SA 3.0,True,False,True,False,False
6305,14321165,2013-01-14 15:16:04,,"<p>I am using an <a href=""http://www.epson.com/cgi-bin/Store/jsp/Product.do?sku=B11B178011"" rel=""nofollow noreferrer"">Epson Perfection V700</a> scanner and selecting the following options when scanning using their tool:</p>

<ul>
<li>ICM Color correction (source: EPSON-Standard and target: sRGB)</li>
<li>Unsharp Mask (medium)</li>
</ul>

<p>That produces this image:</p>

<p><img src=""https://i.stack.imgur.com/XOcNp.png"" alt=""Image from Epson Tool""></p>

<p>Now my problem is this - I actually need to interact with this scanner using <a href=""http://code.google.com/p/twaindotnet/"" rel=""nofollow noreferrer"">TWAIN .Net</a> and when I do so, the image I get back is this:</p>

<p><img src=""https://i.stack.imgur.com/0znWL.png"" alt=""TWAIN Scanned Image""></p>

<p><em>Aside: I unselected the aforementioned two options and scanned again with the Epson and got a very similar image to what I get through <a href=""http://www.twain.org"" rel=""nofollow noreferrer"">TWAIN</a>.</em></p>

<p>So I figure that perhaps these are post processing steps that I can do myself on the image (maybe they are done in the hardware somehow though, I don't know).  </p>

<p>I am using <a href=""http://www.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow noreferrer"">EmguCV</a> so first of all I created an extension method that applies the ICM (I struggled to find any documentation for this, so it is a bit of a guess and maybe I am wrong straight away but I got the information from here: <a href=""http://www.i-programmer.info/programming/wpf-workings/678-the-bitmap-transform-classes.html?start=2"" rel=""nofollow noreferrer"">The bitmap transform class</a> and it seems to make a difference to the image):</p>

<pre><code>public static Image&lt;Bgr, TDepth&gt; ApplyIcm&lt;TDepth&gt;(
    this Image&lt;Bgr, TDepth&gt; source,
    string sourceIcm,
    string targetIcm)
    where TDepth : new()
{
    var target = source.CopyBlank();

    using (source)
    {
        using (var b = source.Bitmap)
        {
            using (var memory = new MemoryStream())
            {
                b.Save(memory, ImageFormat.Bmp);
                memory.Position = 0;

                var bitmapImage = new BitmapImage();
                bitmapImage.BeginInit();
                bitmapImage.StreamSource = memory;
                bitmapImage.CacheOption = BitmapCacheOption.OnLoad;
                bitmapImage.EndInit();

                var ccb = new ColorConvertedBitmap();
                ccb.BeginInit();
                ccb.Source = bitmapImage;

                ccb.SourceColorContext =
                    new ColorContext(new Uri(sourceIcm));

                ccb.DestinationColorContext =
                    new ColorContext(new Uri(targetIcm));

                ccb.EndInit();

                var encoder = new BmpBitmapEncoder();
                encoder.Frames.Add(BitmapFrame.Create(ccb));
                using (var ms = new MemoryStream())
                {                            
                    encoder.Save(ms);
                    target.Bitmap = new Bitmap(ms);
                }
            }
        }
    }

    return target;
}
</code></pre>

<p>Then I looked at that unsharpen thing and came across this question:  <a href=""https://stackoverflow.com/questions/4993082/how-to-sharpen-an-image-in-opencv"">How to sharpen an image in OpenCV?</a> which says:</p>

<blockquote>
  <p>You use a gaussian smoothing filter and subtract the smoothed version from the original image </p>
</blockquote>

<p>(I also checked this question to find out what the equivalent emgucv call is <a href=""https://stackoverflow.com/a/8217530/1039947"">Why might EmguCV Gaussian blur not return identical results as OpenCV Gaussian blur?</a>) and came up with this additional extension method:</p>

<pre><code>public static Image&lt;Bgr, TDepth&gt; UnsharpMask&lt;TDepth&gt;(
    this Image&lt;Bgr, TDepth&gt; source,
    Size kernelSize,
    int kernelHoritonalStandardDeviation,
    int kernelVerticalStandardDeviation,
    double alpha,
    double beta,
    double gamma)
    where TDepth : new()
{

    Image&lt;Bgr, TDepth&gt; ret = source.CopyBlank();

    CvInvoke.cvSmooth(source,
                      ret,
                      SMOOTH_TYPE.CV_GAUSSIAN,
                      kernelSize.Width,
                      kernelSize.Height,
                      kernelHoritonalStandardDeviation,
                      kernelVerticalStandardDeviation);

    CvInvoke.cvAddWeighted(source, alpha, ret, beta, gamma, ret);

    return ret;
}
</code></pre>

<p>Now I call it like so:</p>

<pre><code>string sourceIcm = @""C:\Windows\System32\spool\drivers\color\ewrgb18.icm"";
string targetIcm = @""C:\Windows\System32\spool\drivers\color\ewsrgb.icm"";

using(var im = new Image&lt;Bgr, byte&gt;(""out.bmp""))
{
    using (var icmmed = im.ApplyIcm(sourceIcm, targetIcm))
    {
        using (var ret = icmmed.UnsharpMask(new Size(0, 0), 5, 5, 2.4, -1.5, 0))
        {
            ret.Save(""ret.bmp"");
        }
    }
}
</code></pre>

<p>and this is the result:</p>

<p><img src=""https://i.stack.imgur.com/B3bJa.png"" alt=""After my sharpening""></p>

<p>Not very good! :-(</p>

<p>I have fiddled with the parameters endlessly but I just cannot work out how (or even if) I can achieve the same result as the Epson tool.</p>

<p>So, my question is:</p>

<p><strong>Does anyone know if it is possible to achieve a result using opencv/emgucv (or even TWAIN - I had a look through the documentation for that and tried adjusting some of the capability parameters but I just made the image worse) that is similar in sharpness to the original image above or is there another technique I should try (could it be that I would need to know some details about the hardware itself in order to achieve correct sharpening)?</strong></p>
",2017-05-23 12:04:34,2013-04-04 15:28:19,How to achieve good sharpness with twain/emgu/open cv?,<c#><.net><opencv><emgucv><twain>,,,CC BY-SA 3.0,True,False,True,False,False
6349,11419873,2012-07-10 18:47:07,,"<p>I'm using the Emgu library for integrating the open CV webcam features in C#. </p>

<p>I use this code for choosing the capture device and setting its size:</p>

<pre><code>camera = new Capture(0);
camera.SetCaptureProperty(CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, videoSettings.width);
camera.SetCaptureProperty(CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, videoSettings.height);
</code></pre>

<p>Then I display it in an imageBox like this: <code>imageBox1.Image = camera.QueryFrame();</code></p>

<p>Then to capture a snapshot of the current frame I use this code:</p>

<pre><code>Image&lt;Bgr, byte&gt; snapshot = camera.QueryFrame();
snapshot.Save(""snapshot.jpg"");
</code></pre>

<p>Though I would want to be able to save the snapshot at a higher resolution than the preview window. </p>

<p>But the problem is that as far as I know I can't create a new ""Capture"" object using the same webcamera. So I'm wondering if it is maybe possible to set the <code>camera.setCaptureProperty</code> height and width to let's say 1028x720 but then in some way crop it for displaying it in the imageBox with the resolution of 514x360?  </p>

<p>Or is there any other way to do this?</p>
",2017-06-13 07:18:19,2017-06-13 07:18:19,"C#, Emgu webcam - choose capture size",<c#><video-capture><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6384,11424466,2012-07-11 01:51:12,,"<p><img src=""https://i.stack.imgur.com/qe2a5.png"" alt=""enter image description here""></p>

<p>I am using Emgu CV, i want to detect two sharp in the picture, first i convert the image to gray,and call cvCanny, then call FindContours， but just one contour found, the triangle not found.</p>

<p>Code:</p>

<pre><code> public static void Do(Bitmap bitmap, IImageProcessingLog log)
    {
        Image&lt;Bgr, Byte&gt; img = new Image&lt;Bgr, byte&gt;(bitmap);
        Image&lt;Gray, Byte&gt; gray = img.Convert&lt;Gray, Byte&gt;();
        using (Image&lt;Gray, Byte&gt; canny = new Image&lt;Gray, byte&gt;(gray.Size))
        using (MemStorage stor = new MemStorage())
        {
            CvInvoke.cvCanny(gray, canny, 10, 5, 3);
            log.AddImage(""canny"",canny.ToBitmap());

            Contour&lt;Point&gt; contours = canny.FindContours(
             Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
             Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_TREE,
             stor);

            for (int i=0; contours != null; contours = contours.HNext)
            {
                i++;
                MCvBox2D box = contours.GetMinAreaRect();

                Image&lt;Bgr, Byte&gt; tmpImg = img.Copy();
                tmpImg.Draw(box, new Bgr(Color.Red), 2);
                log.AddMessage(""contours"" + (i) +"",angle:""+box.angle.ToString() + "",width:""+box.size.Width + "",height:""+box.size.Height);
                log.AddImage(""contours"" + i, tmpImg.ToBitmap());
            }
        }
    }
</code></pre>
",2014-09-08 04:01:59,2014-09-08 04:01:59,How to detect triangle edge in opencv or emgu cv?,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
6401,9457827,2012-02-26 22:26:47,,"<p>I am working on a project in which i should design an application which can detect all the faces of the persons passing by...I have a very large database comprising of several known people...I have used the EigenObjectRecognizer to recognize the image frame captured by the webcam...But the problem is sometimes it recognizes some persons wrongly....So if get the confidence value of this facial match...Then i can write a conditional loop so that if it is greater than 75%, then only detect him otherwise don't.Also I know that PCA based recognition is basic,I ll definitely move on to other new algorithms.But owing to the deadline of the project,I should submit it quickly....So please tell me how to get the confidence value of this EigenObjectRecognizer facial recognition....</p>
",,2016-06-05 13:14:51,How to get Confidence value in face recognition using EMGU CV?,<c#><opencv><emgucv><opencvdotnet>,,,CC BY-SA 3.0,True,False,True,False,False
6453,12401629,2012-09-13 07:42:05,,"<p>I have a lot of upper body/face pictures and i'm trying to create a page similar to this:
<a href=""http://www.mediatechsummit.com/ehome/index.php?eventid=45432&amp;tabid=76964&amp;"" rel=""nofollow"">http://www.mediatechsummit.com/ehome/index.php?eventid=45432&amp;tabid=76964&amp;</a></p>

<p>The problem is my pictures vary in size and type, some are more face while
some are upper body.
I want to write an algorithm that will scale/crop pictures to a specific ratio (1/1.3)
using my implemented face detection -  EMGU CV library.</p>

<p>it needs to be ""smart"", taking the square from face detected and decide how
to keep it in the center while not loosing important parts from the picture (ears, forehead).</p>
",2012-09-13 08:21:21,2012-09-13 08:23:07,Algorithm to crop face image to a specific ratio using face detection,<c#><.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6540,13381052,2012-11-14 14:44:46,,"<p>Here is a snapshot of my code,</p>

<pre><code>Matrix&lt;byte&gt; mask;
int k = 2;
VectorOfKeyPoint modelKeyPoints;
VectorOfKeyPoint observedKeyPoints;
SURFDetector surfCPU = new SURFDetector(500, false);
modelKeyPoints = surfCPU.DetectKeyPointsRaw(modelImage, null);
Matrix&lt;float&gt; modelDescriptors = surfCPU.ComputeDescriptorsRaw(modelImage, null, modelKeyPoints);
observedKeyPoints = surfCPU.DetectKeyPointsRaw(observedImage, null);
Matrix&lt;float&gt; observedDescriptors = surfCPU.ComputeDescriptorsRaw(observedImage, null, observedKeyPoints);
BruteForceMatcher&lt;float&gt; matcher = new BruteForceMatcher&lt;float&gt;(DistanceType.L2);
matcher.Add(modelDescriptors);
indices = new Matrix&lt;int&gt;(observedDescriptors.Rows, k);
using (Matrix&lt;float&gt; dist = new Matrix&lt;float&gt;(observedDescriptors.Rows, k))
{
      matcher.KnnMatch(observedDescriptors, indices, dist, k, null);
}
</code></pre>

<p>I always get the following exception at KnnMatch()</p>

<p><strong>Emgu.CV.Util.CvException occurred
Message: OpenCV: queryDescriptors.type() == trainDescCollection[0].type()</strong></p>

<p>I have tried so hard to get rid of this exception and no hope :(</p>
",,2014-01-08 18:29:51,EMGU 2.4.0 BruteForceMatcher KNNMATCH not working?,<c#><image-processing><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
6542,13382565,2012-11-14 16:09:20,,"<p>I have managed to load an Image on the control only by right-click' selecting the ""load image"" option while in runtime.</p>

<p>I want to know if there's a way to load it passing specifically the Image object,
since when I try doing as I normally would, setting it like <code>imagebox.Image = (...)</code>
would give an error because the <code>imagebox.Image</code> is a ""IImage"" object.</p>

<p>any tips? 
thanks :)</p>
",2012-11-14 16:12:16,2013-10-05 15:13:34,"Load an Image in EmguCV's Imagebox, damned IImage",<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6545,15301439,2013-03-08 19:05:59,,"<p>I am in need of using the standard Hough Transformation (instead of the using the HoughLinesBinary method which implements Probabilistic Hough Transform) and have attempted doing so by creating a custom version of the HoughLinesBinary method:</p>

<pre><code>using (MemStorage stor = new MemStorage())
     {
        IntPtr lines = CvInvoke.cvHoughLines2(canny.Ptr, stor.Ptr, Emgu.CV.CvEnum.HOUGH_TYPE.CV_HOUGH_STANDARD, rhoResolution, (thetaResolution*Math.PI)/180, threshold, 0, 0);

        Seq&lt;MCvMat&gt; segments = new Seq&lt;MCvMat&gt;(lines, stor);
        List&lt;MCvMat&gt; lineslist = segments.ToList();
        foreach(MCvMat line in lineslist)
        {
           //Process lines: (rho, theta)
        }
     }
</code></pre>

<p>My problem is that I am unsure of what type is the sequence returned. I believe it should be MCvMat, due to reading the documentation that CvMat* is used in OpenCV, which also states that for STANDARD ""the matrix must be (the created sequence will be) of CV_32FC2 type""</p>

<p>I am unclear as to what I would need to do to return and process that correct output data from the STANDARD hough lines (i.e. the 2x1 vector for each line giving the rho and theta information).</p>

<p>Any help would be greatly appreciated. Thank you</p>

<p>-Sal</p>
",,2013-03-12 16:06:43,Standard Hough Lines in EMGU CV,<opencv><emgucv><hough-transform>,,,CC BY-SA 3.0,True,False,True,False,False
6636,15310130,2013-03-09 11:27:02,,"<p>I need to implement <code>push_back</code> in OpenCV using EmguCV. I used the add function in Matrix.
However, it does not seems to be working. Even though, I have added elements, matrix is empty.</p>

<p>Here is my OpenCV function:.</p>

<pre><code>Mat labels(0, 1, CV_32FC1);
float label=atof(entryPath.filename().c_str());
labels.push_back(label);
</code></pre>

<p>And this is the EmguCV code I wrote:</p>

<pre><code>Matrix&lt;int&gt; labels = new Matrix&lt;int&gt;(1, 1, 1);
int label = 1;
labels.Add(label); 
</code></pre>

<p>Can someone help me to this conversion?</p>
",2013-03-09 11:28:42,2016-05-08 17:47:47,Implement push_back in OpenCV using EmguCV,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
6669,9477602,2012-02-28 06:47:27,,"<p>I need to <strong>crop</strong> an image without changing its aspect ratio. I am taking picture from <strong>CANON1100D</strong> using EDSDK. Captured image:
  <strong>Width = 1920</strong> and     <strong>Height=1280</strong><br>
Aspect ration is <strong>1.5</strong>. but I need picture which aspect ratio is <strong>1.33</strong>. </p>

<pre><code>
// convert into processing resolution (1600,1200) 

Image&lt;Bgr, byte&gt; runtime_frm = new Image&lt;Bgr, byte&gt;(frame.ToBitmap(1600,1200));

// also in bitmap processing 

// Bitmap a = new Bitmap(runtime_frm.ToBitmap());  
// Bitmap b = new Bitmap(a, new Size(1600,1200));

</code></pre>

<p>It's resizing the image so the aspect ratio of image is changed but it creates stress in image. I need to crop the image (1920x1280) to (1600x1200) in runtime.  </p>

<p>How can i do this programmatically? any idea   </p>
",2017-07-19 12:37:31,2017-07-19 12:37:31,How to Crop Image without changing the aspect ratio,<c#><image-processing><emgucv><edsdk>,,,CC BY-SA 3.0,False,False,True,False,False
6680,14351262,2013-01-16 04:13:49,,"<p>I just want to reproduce the result as posted <a href=""http://nuigroup.com/forums/viewthread/3414/"" rel=""noreferrer"">here</a>.</p>

<p>I rewrite the source to EmguCV form.</p>

<pre><code>    Image&lt;Bgr, byte&gt; image = new Image&lt;Bgr, byte&gt;(@""B:\perspective.png"");

    CvInvoke.cvShowImage(""Hello World!"", image);

    float[,] scrp = { { 43, 18 }, { 280,40}, {19,223 }, { 304,200} };
    float[,] dstp = { { 0,0}, { 320,0}, { 0,240 }, { 320,240 } };
    float[,] homog = new float[3, 3];


    Matrix&lt;float&gt; c1 = new Matrix&lt;float&gt;(scrp);
    Matrix&lt;float&gt; c2 = new Matrix&lt;float&gt;(dstp);
    Matrix&lt;float&gt; homogm = new Matrix&lt;float&gt;(homog);


    CvInvoke.cvFindHomography(c1.Ptr, c2.Ptr, homogm.Ptr, Emgu.CV.CvEnum.HOMOGRAPHY_METHOD.DEFAULT, 0, IntPtr.Zero);
    CvInvoke.cvGetPerspectiveTransform(c1, c2, homogm);

    Image&lt;Bgr, byte&gt; newImage = image.WarpPerspective(homogm, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC, Emgu.CV.CvEnum.WARP.CV_WARP_DEFAULT, new Bgr(0, 0, 0));

    CvInvoke.cvShowImage(""newImage"", newImage);
</code></pre>

<p>This is the testing image.
<img src=""https://i.stack.imgur.com/DKsXs.png"" alt=""enter image description here""></p>

<p>The newImage is always a blank image.</p>

<p>Can anyone help me make my source code work???</p>
",2013-01-16 04:46:16,2016-04-27 09:32:10,How to make PerspectiveTransform work?,<c#><image-processing><opencv><emgucv><perspective>,,,CC BY-SA 3.0,True,False,True,False,False
6717,12425199,2012-09-14 13:05:48,,"<p>I created imageHolder class:</p>

<pre><code>public class ImageHolder : Image&lt;Bgr, Byte&gt;
{   
    private String imagePath;

    public ImageHolder(String path):base(path)
    {
       this.imagePath = path;                     
    }   
    public String imgPathProperty
    {
        get
        { return imagePath; }
        set
        { imagePath = value; }
    }
}
</code></pre>

<p>I create instance of the class and initialize it,like this:</p>

<pre><code>private ImageHolder originalImageHolder;
originalImageHolder = new ImageHolder(openFileDialog.FileName);
</code></pre>

<p>In runtime i get this exception:</p>

<p><strong>The type initializer for 'Emgu.CV.CvInvoke' threw an exception.</strong></p>

<p><img src=""https://i.stack.imgur.com/OCHdz.png"" alt=""enter image description here""></p>

<p>Here is Solution Explorer window:</p>

<p><img src=""https://i.stack.imgur.com/60aBe.png"" alt=""enter image description here""></p>

<p>Any idea why i get this exception and how can i fix it?</p>

<p>Thank you in advance.</p>
",2018-08-31 07:59:34,2018-08-31 07:59:34,Type initialization exception,<c#><.net><opencv><constructor><emgucv>,,,CC BY-SA 4.0,True,False,True,False,False
6724,9483874,2012-02-28 14:37:27,,"<p>Emgu.CV, a .Net wrapper to OpenCV comes with a video surveillance example. If used with a laptop embedded camera under artificial lightning, the whole picture is ""noisy"", and a foreground detected by an OpenCV's FGDetector is massive. </p>

<p>What can I do (plain OpenCV answer will also work) to filer out this noise to feed a relatively nosiseless image to a BlobTracker? </p>
",2012-02-28 19:47:02,2012-02-28 19:47:02,"Filtering out noise from being detected as ""moving"" foreground in OpenCV/Emgu.CV",<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
6726,13393906,2012-11-15 08:37:56,,"<p>In the Emgu.CV.OCR sample project, there is a class <code>Tesseract</code>, which is a wrapper for the Tesseract-OCR engine.
In Tesseract.cs, there are declarations like:</p>

<pre><code>[DllImport(CvInvoke.EXTERN_LIBRARY, CallingConvention = CvInvoke.CvCallingConvention)]
private static extern IntPtr TessBaseAPICreate();
</code></pre>

<p>CvInvoke.EXTERN_LIBRARY points to cvextern.dll.</p>

<p>I opened cvextern.dll in DependencyWalker, and there aren't any Tesseract functions anywhere, only OpenCV functions.</p>

<p>I'm sure I'm missing something obvious, but where are the actual function definitions that are being used here?</p>
",,2012-11-21 08:10:37,Where does EmguCV use tesseract from?,<c#><dllimport><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
6847,12437080,2012-09-15 11:47:26,,"<p>I am trying to write the captured video to a file using VideoWriter and Capture from emguCV,
the problem is: If i playback the video that I have just recorded it plays to fast or to slow.
How can i fix this, so the video I record will be playbacked/recorded in realtime, so not to slow or to fast?</p>

<p>this is my code:</p>

<hr>

<pre><code>    Capture capture = new Capture();
    VideoWriter vw;
    Size ms_hd_cam_5000_resolution = new Size(1280, 720);
    Label width_label, height_label, recordingTime;
    Button record;
    Thread isRecording;
    Image&lt;Bgr, byte&gt; imageFrame;

    int seconds;
    int minutes;

    public Form1()
    {
        InitializeComponent();
        InitializeConrols();

        //Cam_Properties
        capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, 1280);
        capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, 720);
        capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FPS, 30);

        //VideoWriting_Properties
        vw = new VideoWriter(""test.avi"", 30, ms_hd_cam_5000_resolution.Width, ms_hd_cam_5000_resolution.Height, true);


    }

    private void InitializeConrols()
    {
        this.BackColor = Color.Black;
        this.ClientSize = new Size(ms_hd_cam_5000_resolution.Width + 25, ms_hd_cam_5000_resolution.Height + 75);
        this.Picture_box.Size = ms_hd_cam_5000_resolution;

        width_label = new Label();
        width_label.Location = new Point(10, ms_hd_cam_5000_resolution.Height + 15);
        width_label.ForeColor = Color.White;
        width_label.Text = ""width: "" + capture.Width.ToString();

        height_label = new Label();
        height_label.Location = new Point(10, ms_hd_cam_5000_resolution.Height + 40);
        height_label.ForeColor = Color.White;
        height_label.Text = ""height: "" + capture.Height.ToString();

        recordingTime = new Label();
        recordingTime.Location = new Point(225, ms_hd_cam_5000_resolution.Height + 40);
        recordingTime.ForeColor = Color.White;
        recordingTime.Text = ""time: 0"";

        record = new Button();
        record.Location = new Point(225, ms_hd_cam_5000_resolution.Height + 15);
        record.ForeColor = Color.White;
        record.Text = ""record"";

        Controls.Add(width_label);
        Controls.Add(height_label);
        Controls.Add(record);
        Controls.Add(recordingTime);

        record.Click += Record_Click;
    }

    private void Form1_Load(object sender, EventArgs e)
    {
        captureCamImage(sender, e);
        Application.Idle += captureCamImage;
    }

    private void Record_Click(object sender, EventArgs e)
    {
        if (isRecording == null)
        {
            recordingTime.Text = ""Time: 0"";
            record.Text = ""stop"";
            isRecording = new Thread(this.Record);
            isRecording.Start(); 
        }
        else
        {
            record.Text = ""record"";
            isRecording = null;
        }
    }

    private void captureCamImage(object sender, EventArgs e)
    {
        imageFrame = capture.QueryFrame();
        Picture_box.Image = imageFrame.ToBitmap();
        recordTime();
    }

    private void recordTime()
    {
        recordingTime.Text = ""Time: "" + minutes.ToString() + "" : "" + seconds.ToString();
    }

    private void Record()
    {
        Stopwatch stopWatch = new Stopwatch();
        stopWatch.Reset();
        stopWatch.Start();
        while (isRecording != null)
        {
            seconds = stopWatch.Elapsed.Seconds;
            minutes = stopWatch.Elapsed.Minutes;

            vw.WriteFrame(imageFrame);
            Thread.Sleep(1000 / 30);
        }
    }
</code></pre>

<hr>
",,2012-11-10 10:09:50,C# emgu cv: Recorded Videos playsback to fast/slow,<c#><video-capture><playback><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6855,9495147,2012-02-29 07:28:20,,"<p>I have leverage the facial recognition code from <a href=""http://www.codeproject.com/Articles/239849/Multiple-face-detection-and-recognition-in-real-ti"" rel=""nofollow"">http://www.codeproject.com/Articles/239849/Multiple-face-detection-and-recognition-in-real-ti</a> and had a good start using it to recognize a few faces. </p>

<p>But challenge is that the accuracy is getting pretty low once I increase the number of different people.  I wrote some code to programatically produce training images for the recognizer, with around 1300 trained faces (all 100 x 100 pixel gray scale) of about 280 different people.</p>

<p>The tips from the above webpage doesn't seems to help much in improving the accuracy.  I was wonder do any one has any good hints and experience with using Emgu CV to do accurate face recognition.  Speed is not too important for now.</p>

<p>Much appreciated, Thanks in advance.</p>
",,2013-11-21 02:32:27,Emgu CV Face Recognition: How to Improve the accuracy,<emgucv><face-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
6902,12444093,2012-09-16 02:52:14,,"<p>I'd really appreciate some help with the following questions:</p>

<p>Have captured, then rectified, grayscale images from a calibrated stereo rig. 
Am now attempting to get real world x,y, z coords , relative to the left camera, of specific points, in the left image; I am trying to use cvPerspectiveTransform to do so.</p>

<p>My abbreviated code is below.</p>

<p>The code appears to work to some extent, and returns the following 4 data points: 
(15.4510, -474.7451, -527.0327, -912.6536), which I understand to represent x,y,z and w. </p>

<p>Question 1) is this assumption correct? - it may be that division by w has already taken place and that XYZ have already been returned, in which case -912.6536 is an artefact to be ignored - any views on this are welcome.</p>

<p>Question 2) However if ,to achieve realworld coordinates X,Y,Z, each of 'x','y','z' respectively is to be divided by 'w', in what units are the resulting XYZ coordinates? I understand them to be related to the ""points"" used in calibration - in this case chessboard corners were 2.5 cm apart, however the distance from the camera of the object in this case was approximately 60cm... as you can see the math doesn't quite work. </p>

<p>I have diligently read the relevant pages in the Bradski book (and searched online), but I must be missing something.</p>

<pre><code>Matrix&lt;float&gt; inputMatLeft = new Matrix&lt;float&gt;(4,1,3);
inputMatLeft[0,0] = xL; // xL, a float, the x coord of a point in the left image
inputMatLeft[1,0] = yL; // yL, a float, the y coord of same point in left image
inputMatLeft[2,0] = d;  // d, a float, the disparity between the same featurepoint in the left and right rectified images,  is calc'd and defined elsewhere
inputMatLeft[3,0] = 1F;

Matrix&lt;float&gt; rwCoords = new Matrix&lt;float&gt;(4,1,3);
rwCoords = computeRealWorldCoords(inputMatLeft);

// ....do stuff with rwCoords

public Matrix&lt;float&gt; computeRealWorldCoords(Matrix &lt;float&gt; leftSrc)
{
Matrix&lt;float&gt; leftDest = new Matrix&lt;float&gt;(4,1,3);
CvInvoke.cvPerspectiveTransform(leftSrc, leftDest, inputMatrixQ); // Q Matrix is 4x4 float
return leftDest;
}
</code></pre>

<p>Thanks!</p>
",2012-09-16 16:00:03,2012-09-16 16:00:03,"Real World Distance: Stereo cam, cvPerspectiveTransform, Emgu, C#",<c#><distance><emgucv><stereo-3d>,,,CC BY-SA 3.0,False,False,True,False,False
6927,11464397,2012-07-13 05:02:19,,"<p>What's the best set of image preprocessing operations to apply to images for text recognition in EmguCV? </p>

<p>I've included two sample images <a href=""http://notsonerdygeeks.onlyatbits.com/upload/sample.png"">here</a>.</p>

<p>Applying a low or high pass filter won't be suitable, as the text may be of any size. I've tried median and bilateral filters, but they don't seem to affect the image much.</p>

<p>The ideal result would be a binary image with all the text white, and most of the rest black. This image would then be sent to the OCR engine.</p>

<p>Thanks</p>
",,2019-07-31 13:43:14,Image preprocessing for text recognition,<image-processing><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
6967,9501759,2012-02-29 15:19:54,,"<p>I am a newbie in image processing. Could anyone teach me how to do blob detection in gray image? A sample code would be really appreciated. I would then have to count the number of blobs present. By the way the input would be from web camera. And also how to determine the size of the blob? Like to compare if the size is almost the same size as a head? Actually I'm doing a head counter where I have to count the number of people passing through the door.</p>
",,2012-03-26 19:29:54,Emgu CV blob detection in gray image,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
6992,14374423,2013-01-17 07:51:54,,"<p>I'm working on the source code from <a href=""http://www.emgu.com/wiki/index.php/SURF_feature_detector_in_CSharp"" rel=""nofollow"">here</a>.</p>

<p>It seems that <code>indices</code> variable stores the match information, but I don't know how the information is stored. </p>

<p>For example, can you tell me how many matched pair of points are found? Which point matches which point?</p>
",,2016-07-09 14:36:29,Use SURF to match images in OpenCV\EmguCV,<c#><image-processing><opencv><emgucv><surf>,,,CC BY-SA 3.0,True,False,True,False,False
7014,9504987,2012-02-29 18:57:41,,"<p>I wish to use EMGU.CV's Tesseract object to do OCR on some pictures. To start, I've downloaded, compiled and ran their OCR and LicensePlateRecognition examples.</p>

<p>However, Tesseract kept throwing the following exception:</p>

<blockquote>
  <p>Unable to create ocr model using Path 'teseract' and language 'eng'.</p>
</blockquote>

<p>And I traced the source to the line:</p>

<p><code>_ocr = new Tesseract(@""tessdata"", ""eng"", Tesseract.OcrEngineMode.OEM_TESSERACT_CUBE_COMBINED);</code></p>

<p>I tried fixing it with the most obvious ways: I gave it the full path, I copied the files around to just 'C: \', and I made sure that my program's current directory was the same one with the tessdata in it.</p>

<p>None of those worked, so I used procmon and discovered it was looking for the files here:</p>

<blockquote>
  <p>C: \Program Files (x86)\Tesseract-OCR\tessdata</p>
</blockquote>

<p>And it seems no matter what I do I cannot change it from this location. (Moving the files there worked, of course). This location does not exist anywhere in EMGU.cv's code, so my guess is that it's compiled into Tesseract's code as some default (?).</p>

<p>So, how do I change Tesseract from using this location?  The obvious way is that the Tesseract constructor should DO something with the path I pass into it, so what am I missing?</p>
",2012-03-10 10:06:00,2016-01-27 00:34:51,Emgu.cv's Tesseract object using incorrect path for OCR files,<c#><emgucv><tesseract><tessnet2>,,,CC BY-SA 3.0,False,False,True,False,False
7015,9505778,2012-02-29 20:03:25,,"<p>I am working on a face detection and recognition software...i succeeded in detecting the faces and recognizing them using EigenObjectRecognizer...But sometimes its giving wrong results...So i would set the roi of the faces using HaarCascade object to an ellipse so that i should be able to nullify the effect of the background...</p>

<p>ellipse = new Ellipse(new PointF(face.rect.X + (face.rect.Width / 2), face.rect.Y + (face.rect.Height / 2)), new SizeF(face.rect.Width - 5, face.rect.Height - 25), 0);
ImageFrame.Draw(ellipse, new Bgr(Color.Green), 2);</p>

<p>Now it can draw an ellipse around the face...But how to set the face's roi to this ellipse...</p>

<p>Please help me with this...</p>
",,2015-10-11 20:02:18,Setting Image ROI to a shape other an rectangle in EMGU CV...?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
7022,11474440,2012-07-13 16:22:49,,"<p>I have trouble debugging an application made ​​on. NET 4.0.</p>

<p>A written WPF/.NET4.0 and other in WPF/.NET3.5  both compiled fine, but in .NET4.0 I can not debug, the application abruptly closes, I have seen all the examples and these are brought EmguCV made on .NET3.5.</p>

<p><strong>how i can debug an application with EmguCV over .NET4.0?</strong></p>
",2012-07-13 17:19:01,2012-07-13 17:19:01,EmguCV not debug on. NET4.0,<c#><.net><visual-studio-2010><debugging><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7035,13417449,2012-11-16 13:20:23,,"<p>Hey this is my first time using this website, but I a problem. I saw this awesome youtube video about getting ocr to work with vb.net. Here the url:</p>

<p><a href=""http://www.youtube.com/watch?v=Kjdu8SjEtG0"" rel=""nofollow"">http://www.youtube.com/watch?v=Kjdu8SjEtG0</a></p>

<p>So I decided to download the emgu libraries, here the url:</p>

<p><a href=""http://sourceforge.net/projects/emgucv/"" rel=""nofollow"">http://sourceforge.net/projects/emgucv/</a></p>

<p>I did everything the video say and I get this error: ""An error occurred creating the form. See Exception.InnerException for details.  The error is: The type initializer for 'Emgu.CV.OCR.Tesseract' threw an exception.""</p>

<p>I even copy the exception(if that do any help):</p>

<pre><code>System.InvalidOperationException was unhandled
  Message=An error occurred creating the form. See Exception.InnerException for details.  The error is: The type initializer for 'Emgu.CV.OCR.Tesseract' threw an exception.
  Source=WindowsApplication1
  StackTrace:
       at WindowsApplication1.My.MyProject.MyForms.Create__Instance__[T](T Instance) in 17d14f5c-a337-4978-8281-53493378c1071.vb:line 190
       at WindowsApplication1.My.MyProject.MyForms.get_Form1()
       at WindowsApplication1.My.MyApplication.OnCreateMainForm() in C:\Users\UltimateSoul\AppData\Local\Temporary Projects\WindowsApplication1\My Project\Application.Designer.vb:line 35
       at Microsoft.VisualBasic.ApplicationServices.WindowsFormsApplicationBase.OnRun()
       at Microsoft.VisualBasic.ApplicationServices.WindowsFormsApplicationBase.DoApplicationModel()
       at Microsoft.VisualBasic.ApplicationServices.WindowsFormsApplicationBase.Run(String[] commandLine)
       at WindowsApplication1.My.MyApplication.Main(String[] Args) in 17d14f5c-a337-4978-8281-53493378c1071.vb:line 81
       at System.AppDomain._nExecuteAssembly(RuntimeAssembly assembly, String[] args)
       at System.AppDomain.ExecuteAssembly(String assemblyFile, Evidence assemblySecurity, String[] args)
       at Microsoft.VisualStudio.HostingProcess.HostProc.RunUsersAssembly()
       at System.Threading.ThreadHelper.ThreadStart_Context(Object state)
       at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean ignoreSyncCtx)
       at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)
       at System.Threading.ThreadHelper.ThreadStart()
  InnerException: System.TypeInitializationException
       Message=The type initializer for 'Emgu.CV.OCR.Tesseract' threw an exception.
       Source=Emgu.CV.OCR
       TypeName=Emgu.CV.OCR.Tesseract
       StackTrace:
            at Emgu.CV.OCR.Tesseract..ctor(String dataPath, String language, OcrEngineMode mode)
            at WindowsApplication1.Form1..ctor() in C:\Users\UltimateSoul\AppData\Local\Temporary Projects\WindowsApplication1\Form1.vb:line 8
       InnerException: System.TypeInitializationException
            Message=The type initializer for 'Emgu.CV.CvInvoke' threw an exception.
            Source=Emgu.CV
            TypeName=Emgu.CV.CvInvoke
            StackTrace:
                 at Emgu.CV.CvInvoke.CV_MAKETYPE(Int32 depth, Int32 cn)
                 at Emgu.CV.OCR.Tesseract..cctor()
            InnerException: System.DllNotFoundException
                 Message=Unable to load DLL 'opencv_core242': The specified module could not be found. (Exception from HRESULT: 0x8007007E)
                 Source=Emgu.CV
                 TypeName=""""
                 StackTrace:
                      at Emgu.CV.CvInvoke.cvRedirectError(CvErrorCallback errorHandler, IntPtr userdata, IntPtr prevUserdata)
                      at Emgu.CV.CvInvoke..cctor()
                 InnerException: 
</code></pre>

<p>I been on this for days, and got no where. Please help thanks!</p>

<p>I sorry here the code </p>

<pre><code>Imports Emgu.CV
Imports Emgu.Util
Imports Emgu.CV.OCR
Imports Emgu.CV.Structure

Public Class Form1

    Dim OCRz As Tesseract = New Tesseract(""tessdata"", ""eng"", Tesseract.OcrEngineMode.OEM_TESSERACT_ONLY)
    Dim pic As Bitmap = New Bitmap(270, 100)
    Dim gfx As Graphics = Graphics.FromImage(pic)

    Private Sub Timer1_Tick(ByVal sender As System.Object, ByVal e As System.EventArgs) Handles Timer1.Tick

        gfx.CopyFromScreen(New Point(Me.Location.X + PictureBox1.Location.X + 4, Me.Location.Y + PictureBox1.Location.Y + 30), New Point(0, 0), pic.Size)
        PictureBox1.Image = pic

    End Sub

    Private Sub Button1_Click(ByVal sender As System.Object, ByVal e As System.EventArgs) Handles Button1.Click

        OCRz.Recognize(New Image(Of Bgr, Byte)(pic))
        RichTextBox1.Text = OCRz.GetText

    End Sub
End Class
</code></pre>
",2012-11-16 13:34:16,2017-03-10 08:58:10,Exception initializing Emgu.CV,<vb.net><ocr><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
7080,9513599,2012-03-01 09:26:04,,"<p>I am using following code in WPF to display image in webcam usingEmguCv library  now i want to save image on my computer any of you have any idea how to do that ? What method should come in button1_click </p>

<pre><code>        private Capture capture;
       private DispatcherTimer timer;

    #region ImageConverter

    // Converting EmguCV image to WPF image
    [DllImport(""gdi32"")]
    private static extern int DeleteObject(IntPtr o);

    public static BitmapSource ToBitmapSource(Emgu.CV.IImage image)
    {
        using (System.Drawing.Bitmap source = image.Bitmap)
        {
            IntPtr ptr = source.GetHbitmap();
            BitmapSource bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(ptr, IntPtr.Zero, Int32Rect.Empty, System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions());
            DeleteObject(ptr);
            return bs;
        }
    }

    #endregion

    private void Window_Loaded(object sender, RoutedEventArgs e)
    {
        capture = new Capture();
        // capture.FlipHorizontal = true;
        timer = new DispatcherTimer();
        timer.Interval = new TimeSpan(150);
        timer.Tick += new EventHandler(timer_Tick);
        timer.Start();

    }
    void timer_Tick(object sender, EventArgs e)
    {
        using (Image&lt;Bgr, byte&gt; Frame = capture.QueryFrame())
        {
            if (Frame != null)
            {
                webcam.Source = ToBitmapSource(Frame);

            }
        }
    }



    private void Window_Closing(object sender, System.ComponentModel.CancelEventArgs e)
    {

        if (capture != null)
        {
            capture.Dispose();
        }

    }

    private void button1_Click(object sender, RoutedEventArgs e)
    {

    }
}
}
</code></pre>
",,2012-03-16 13:58:29,Image store on computer using EmguCV,<c#><wpf><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7099,16305158,2013-04-30 16:55:17,,"<p>I am building a program that needs to capture the image from a webam and show it to the user. I am using EmguCV to capture the image from the webcam and make some computer vision processing and then i need to show the image to the user. I have the image in the EmguCV's format (<code>Image&lt;Bgr, byte&gt;</code>)</p>

<p>The forms are WPF, so I just have an <code>Image</code> item on the form showing the result.</p>

<p>I guess I can save the image to the hard drive and make the form to load it again, but I dont think this is a good solution since I need to show the captured images in ""real time"".</p>

<p>How can I load the EmguCV image into the form image container?</p>
",,2013-04-30 16:57:00,Show EmguCV Image in WPF form,<c#><wpf><image><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7148,13431210,2012-11-17 13:52:13,,"<p>I can't install the nvidia installation in cuda toolkit. I don't have a nvidia card. Does that means I can't use emgu.cv? I been on this all yesterday and emgu.cv is still giving me problems.</p>

<p>Here the link that still shows my problem:
<a href=""https://stackoverflow.com/questions/13417449/exception-initializing-emgu-cv"">Exception initializing Emgu.CV</a></p>
",2017-05-23 12:03:52,2012-12-08 22:05:47,Nvidia: the graphic driver could not find compatible graphic hardware,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7166,14388797,2013-01-17 21:52:34,,"<p>I am making a project using <code>Emgucv</code> library, he problem is as follows,</p>

<ol>
<li>I Capture image</li>
<li>detect feature</li>
<li>extract it</li>
<li>draw it </li>
</ol>

<p>After that i copy the drawn items in a blank image, now I want find contours inside that new image, but the result is always bull, Why is That?</p>

<p>Thanks in advance</p>
",2013-01-17 22:02:08,2013-02-02 15:46:37,Emgucv drawn items,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7187,11488799,2012-07-15 01:56:48,,"<p>I'm having some problems while trying to compile 64 bit OpenCV libraries. This is what I've done so far:</p>

<ol>
<li>Got the source code using svn</li>
<li>In the <code>opencv</code> I have <code>mkdir build</code> then <code>cd build</code></li>
<li><code>cmake -G ""Unix Makefiles"" -D CMAKE_OSX_ARCHITECTURES=x86_64 -D CMAKE_C_FLAGS=-m64 -D CMAKE_CXX_FLAGS=-m64 ..</code></li>
</ol>

<p>This then leaves me with the output (below), which worries me because a number of packages are not found. I have tried disabling the <code>WITH_CUDA</code> flag as suggest in this post <a href=""https://stackoverflow.com/questions/10342682/building-emgucv-on-osx-snow-leopard"">Building EmguCV on OSX Snow Leopard</a> but it doesn't seem to help.</p>

<pre><code>-- Extracting svn version, please wait...
-- SVNVERSION:  svn:9029
-- checking for module 'libdc1394-2'
--   package 'libdc1394-2' not found
-- checking for module 'libdc1394'
--   package 'libdc1394' not found
-- checking for module 'libavcodec'
--   package 'libavcodec' not found
-- checking for module 'libavformat'
--   package 'libavformat' not found
-- checking for module 'libavutil'
--   package 'libavutil' not found
-- checking for module 'libswscale'
--   package 'libswscale' not found
-- Looking for libavformat/avformat.h
-- Looking for libavformat/avformat.h - not found
-- Looking for ffmpeg/avformat.h
-- Looking for ffmpeg/avformat.h - not found
Traceback (most recent call last):
  File ""&lt;string&gt;"", line 1, in &lt;module&gt;
ImportError: No module named sphinx
-- 
-- General configuration for OpenCV 2.4.9 =====================================
-- Version control:                 svn:9029
-- 
--   Platform:
--     Host:                        Darwin 11.4.0 i386
--     CMake:                       2.8.8
--     CMake generator:             Unix Makefiles
--     CMake build tool:            /usr/bin/make
--     Configuration:               Release
-- 
--   C/C++:
--     Built as dynamic libs?:      YES
--     C++ Compiler:                /usr/bin/c++
--     C++ flags (Release):         -m64   -O3 -DNDEBUG 
--     C++ flags (Debug):           -m64   -g 
--     C Compiler:                  /usr/bin/gcc
--     C flags (Release):           -m64   -O3 -DNDEBUG 
--     C flags (Debug):             -m64   -g 
--     Linker flags (Release):      
--     Linker flags (Debug):        
--     Precompiled headers:         NO
-- 
--   OpenCV modules:
--     To be built:                 core imgproc flann highgui features2d calib3d ml video objdetect contrib nonfree legacy gpu photo python stitching ts videostab
--     Disabled:                    world
--     Disabled by dependency:      -
--     Unavailable:                 androidcamera java
-- 
--   GUI: 
--     QT 4.x:                      NO
--     Cocoa:                       YES
--     OpenGL support:              NO
-- 
--   Media I/O: 
--     ZLib:                        build (ver 1.2.6)
--     JPEG:                        build (ver 62)
--     PNG:                         build (ver 1.5.9)
--     TIFF:                        build (ver 42 - 4.0.1)
--     JPEG 2000:                   build (ver 1.900.1)
--     OpenEXR:                     NO
-- 
--   Video I/O:
--     DC1394 1.x:                  NO
--     DC1394 2.x:                  NO
--     FFMPEG:                      NO
--       codec:                     NO
--       format:                    NO
--       util:                      NO
--       swscale:                   NO
--       gentoo-style:              NO
--     OpenNI:                      NO
--     OpenNI PrimeSensor Modules:  NO
--     PvAPI:                       NO
--     QuickTime:                   NO
--     QTKit:                       YES
-- 
--   Other third-party libraries:
--     Use IPP:                     NO
--     Use TBB:                     NO
--     Use Cuda:                    NO
--     Use Eigen:                   NO
--     Use Clp:                     NO
-- 
--   Python:
--     Interpreter:                 /usr/bin/python (ver 2.7.1)
--     Libraries:                   /usr/lib/libpython2.7.dylib (ver 2.7.1)
--     numpy:                       /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/core/include (ver 1.5.1)
--     packages path:               lib/python2.7/site-packages
-- 
--   Documentation:
--     Build Documentation:         NO
--     Sphinx:                      NO
--     PdfLaTeX compiler:           /usr/texbin/pdflatex
-- 
--   Tests and samples:
--     Tests:                       YES
--     Performance tests:           YES
--     Examples:                    NO
-- 
--   Install path:                  /usr/local
-- 
--   cvconfig.h is in:              /Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/build
-- -----------------------------------------------------------------
-- 
-- Configuring done
-- Generating done
-- Build files have been written to: /Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/build
</code></pre>

<p>If I then try <code>make -j8</code> I get something that starts off like this and goes on fo a while:</p>

<pre><code>[  0%] [  0%] [  0%] [  1%] [  1%] [  1%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/adler32.c.o
Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/compress.c.o
Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/crc32.c.o
Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngerror.c.o
Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/png.c.o
Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/deflate.c.o
[  1%] [  1%] Building C object 3rdparty/libjasper/CMakeFiles/libjasper.dir/jas_cm.c.o
Building C object 3rdparty/libjpeg/CMakeFiles/libjpeg.dir/jcapimin.c.o
In file included from /Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/libpng/pngerror.c:19:
/Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/libpng/pngpriv.h:45:20: error: stdlib.h: No such file or directory
In file included from /Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/libpng/pngpriv.h:127,
                 from /Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/libpng/pngerror.c:19:
/Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/libpng/png.h:442:26: error: setjmp.h: No such file or directory
/Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/libpng/png.h:450:24: error: time.h: No such file or directory
In file included from /Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/libpng/png.c:14:
/Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/libpng/pngpriv.h:45:20: error: stdlib.h: No such file or directory
In file included from /Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/libpng/pngpriv.h:127,
                 from /Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/libpng/png.c:14:
/Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/libpng/png.h:442:26: error: setjmp.h: No such file or directory
/Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/libpng/png.h:450:24: error: time.h: No such file or directory
In file included from /Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/zlib/zlib.h:34,
                 from /Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/3rdparty/zlib/compress.c:9:
/Users/Dash/Documents/SmartServices/AirLink/ProjectGhost/myOpencv/trunk/opencv/build/3rdparty/zlib/zconf.h:403:48: error: sys/types.h: No such file or directory
</code></pre>

<p><strong>INSTRUCTIONS</strong></p>

<ol>
<li>Download the zip from <a href=""https://github.com/Itseez/opencv"" rel=""nofollow noreferrer"">https://github.com/Itseez/opencv</a></li>
<li>When you unzip it you should be left with a folder called 'opencv-master', cd into it.</li>
<li>mkdir build</li>
<li>cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_PYTHON_SUPPORT=ON ..</li>
<li>make</li>
<li>sudo make install</li>
</ol>
",2017-05-23 12:04:43,2013-04-22 14:17:20,Compiling OpenCV Source Code for 64 bit (Mac),<opencv><64-bit>,,,CC BY-SA 3.0,True,False,True,False,True
7191,12467818,2012-09-17 22:13:14,,"<p>I'm using .NET2 </p>

<p>I need to use EMGU library in my project.</p>

<p>But when i try to attach EMGU DLL's I get this massage:</p>

<p><img src=""https://i.stack.imgur.com/cUOdH.png"" alt=""enter image description here""></p>

<p>How I can understand .NET2 doesn't support EMGU.</p>

<p>Any ideas how can I use EMGU in .NET2 project.</p>

<p>Thank you in advance.</p>
",,2012-09-24 05:48:01,How can I use EMGU in .NET2 project,<.net><opencv><.net-2.0><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
7267,16320772,2013-05-01 15:08:58,,"<p>I want to resize the captured image inside the imagebox and to set the location of it inside the imagebox. is that possible if yes how can I do it?</p>
",,2013-05-02 07:52:49,How to resize captured image inside imagebox (C# OpenCV winsforms)?,<c#-4.0><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
7329,12479535,2012-09-18 14:53:17,,"<p>I am attempting to detect an image's blurriness using EmguCV. Right now I am attempting to do an FFT of the gray image, but I am stuck because my program just hangs after calling <code>CvInvoke.cvCopy</code>. See below:</p>

<pre><code> _capturedFrames.ForEach(x =&gt;
 {
    using(var gray = x.Convert&lt;Gray, float&gt;())
    {
       IntPtr complexImage = CvInvoke.cvCreateImage(gray.Size, IPL_DEPTH.IPL_DEPTH_32F, 2);

       CvInvoke.cvSetZero(complexImage);  // Initialize all elements to Zero
       CvInvoke.cvSetImageCOI(complexImage, 1);
       CvInvoke.cvCopy(gray.Ptr, complexImage, IntPtr.Zero);
       CvInvoke.cvSetImageCOI(complexImage, 0);

       var dft = new Matrix&lt;float&gt;(gray.Rows, gray.Cols, 2);
       CvInvoke.cvDFT(complexImage, dft, CV_DXT.CV_DXT_FORWARD, 0);

       double min;
       double max;
       Point minLoc;
       Point maxLoc;
       dft.MinMax(out min, out max, out minLoc, out maxLoc);

       if (max &gt; overallMax)
       {
          overallMax = max;
          index = _capturedFrames.IndexOf(x);
       }

       CvInvoke.cvReleaseImage(ref complexImage);
    }
 });
</code></pre>

<p>The objective of the code above is to loop through a collection of images in memory and find the index of the sharpest image. Lets just pretend the method above was working... Is this a robust way of detecting the sharpest image? Are FFTs reliable for this purpose?</p>
",2016-03-21 21:47:15,2016-03-21 21:47:15,EmguCV Detect Image Blurriness,<c#><computer-vision><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7345,11500479,2012-07-16 08:19:58,,"<p>I've tried to code a face recognition program and need some help from the community.
The code posted below compiled with no error but the recognizer seems to be not working?
Basically target.jpg contain a person crop out of the pic1.jpg(3 person inside) so the recognizer should be able to detect it more easily.</p>

<p>The code below run with no errors but all 3 person in pic1.jpg is boxed, and the GetEigenDistances for all 3 faces is 0. By right only the person in pic1.jpg(person in target.jpg) should be boxed.</p>

<p>Any idea on where have i gone wrong? Thanks in advance.</p>

<p>I'm using emgu cv 2.4 with c# 2010 express</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.Util;
using Emgu.CV.Structure;
using Emgu.CV.UI;
using Emgu.CV.CvEnum;


namespace FaceReco
{
    public partial class Form1 : Form
    {
        private HaarCascade haar;
        List&lt;Image&lt;Gray, byte&gt;&gt; trainingImages = new List&lt;Image&lt;Gray, byte&gt;&gt;();
        Image&lt;Gray, byte&gt; TrainedFace, UnknownFace = null;
        MCvFont font = new MCvFont(FONT.CV_FONT_HERSHEY_TRIPLEX, 0.5d, 0.5d);


        public Form1()
        {
            InitializeComponent();
        }

        private void Form1_Load(object sender, EventArgs e)
        {
            // adjust path to find your XML file 
            haar = new HaarCascade(""haarcascade_frontalface_alt_tree.xml"");

            //Read an target image
            Image TargetImg = Image.FromFile(Environment.CurrentDirectory + ""\\target\\target.jpg"");
            Image&lt;Bgr, byte&gt; TargetFrame = new Image&lt;Bgr, byte&gt;(new Bitmap(TargetImg));

            //FACE DETECTION FOR TARGET FACE
            if (TargetImg != null)   // confirm that image is valid
            {
                //convert the image to gray scale
                Image&lt;Gray, byte&gt; grayframe = TargetFrame.Convert&lt;Gray, byte&gt;();
                var faces = grayframe.DetectHaarCascade(haar, 1.4, 4,
                                        HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                                        new Size(25, 25))[0];
                foreach (var face in faces)
                {
                    //add into training array
                    TrainedFace = TargetFrame.Copy(face.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
                    trainingImages.Add(TrainedFace);
                    break;
                }
                TargetImageBox.Image = TrainedFace;
            }


            //Read an unknown image
            Image UnknownImg = Image.FromFile(Environment.CurrentDirectory + ""\\img\\pic1.jpg"");
            Image&lt;Bgr, byte&gt; UnknownFrame = new Image&lt;Bgr, byte&gt;(new Bitmap(UnknownImg));

            //FACE DETECTION PROCESS
            if (UnknownFrame != null)   // confirm that image is valid
            {
                //convert the image to gray scale
                Image&lt;Gray, byte&gt; grayframe = UnknownFrame.Convert&lt;Gray, byte&gt;();

                //Detect faces from the gray-scale image and store into an array of type 'var',i.e 'MCvAvgComp[]'
                var faces = grayframe.DetectHaarCascade(haar, 1.4, 4,
                                        HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                                        new Size(25, 25))[0];

                //draw a green rectangle on each detected face in image
                foreach (var face in faces)
                {
                    UnknownFace = UnknownFrame.Copy(face.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
                    MCvTermCriteria termCrit = new MCvTermCriteria(16, 0.001);
                    //Eigen face recognizer
                    EigenObjectRecognizer recognizer = new EigenObjectRecognizer(trainingImages.ToArray(), ref termCrit);

                    // if recognise face, draw green box
                    if (recognizer.Recognize(UnknownFace) != null)
                    {
                        UnknownFrame.Draw(face.rect, new Bgr(Color.Green), 3);
                    }

                    float f = recognizer.GetEigenDistances(UnknownFace)[0];
                    // display threshold
                    UnknownFrame.Draw(f.ToString(""R""), ref font, new Point(face.rect.X - 3, face.rect.Y - 3), new Bgr(Color.Red));

                }

                //Display the image
                CamImageBox.Image = UnknownFrame;
            }
        }
    }
}
</code></pre>
",,2013-09-03 10:18:01,Emgu CV EigenObjectRecognizer not working,<c#><face-recognition><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7456,12488857,2012-09-19 05:01:53,,"<p>I am trying to use EMGUCV for C#. Currently i have installed Visual Studio 2010 express Edition. When trying to execute some simple commands the <code>Emgu.CV.CvInvoke</code> threw an exception came out so i put the unmanaged code in the exe folder. But still it continued to give me the error. So i tried adding the unmanaged code to solution explorer and still it is giving me this error. Is there anything else which i can do so i can finally use emguCV?</p>

<p>The exception is </p>

<pre><code>System.TypeInitializationException was unhandled 
   Message=The type initializer for 'Emgu.CV.CvInvoke' threw an exception.
</code></pre>

<p>having stack trace:</p>

<pre><code>   at Emgu.CV.CvInvoke.cvCreateCameraCapture(Int32 index)
   at Emgu.CV.Capture..ctor(Int32 camIndex) in C:\Program Files (x86)\Emgu\libemgucv-windows-x64-2.2.1.1150\Emgu.CV\Capture\Capture.cs:line 105
   at Emgu.CV.Capture..ctor() in C:\Program Files (x86)\Emgu\libemgucv-windows-x64-2.2.1.1150\Emgu.CV\Capture\Capture.cs:line 93
   at cameraWorks.Form1.camButton_Click(Object sender, EventArgs e) in C:\Users\Adrian\documents\visual studio 2010\Projects\cameraWorks\cameraWorks\Form1.cs:line 38
   at System.Windows.Forms.Control.OnClick(EventArgs e)
   at System.Windows.Forms.Button.OnClick(EventArgs e)
   at System.Windows.Forms.Button.OnMouseUp(MouseEventArgs mevent)
   at System.Windows.Forms.Control.WmMouseUp(Message&amp; m, MouseButtons button, Int32 clicks)
   at System.Windows.Forms.Control.WndProc(Message&amp; m)
   at System.Windows.Forms.ButtonBase.WndProc(Message&amp; m)
   at System.Windows.Forms.Button.WndProc(Message&amp; m)
   at System.Windows.Forms.Control.ControlNativeWindow.OnMessage(Message&amp; m)
   at System.Windows.Forms.Control.ControlNativeWindow.WndProc(Message&amp; m)
   at System.Windows.Forms.NativeWindow.DebuggableCallback(IntPtr hWnd, Int32 msg, IntPtr wparam, IntPtr lparam)
   at System.Windows.Forms.UnsafeNativeMethods.DispatchMessageW(MSG&amp; msg)
   at System.Windows.Forms.Application.ComponentManager.System.Windows.Forms.UnsafeNativeMethods.IMsoComponentManager.FPushMessageLoop(IntPtr dwComponentID, Int32 reason, Int32 pvLoopData)
   at System.Windows.Forms.Application.ThreadContext.RunMessageLoopInner(Int32 reason, ApplicationContext context)
   at System.Windows.Forms.Application.ThreadContext.RunMessageLoop(Int32 reason, ApplicationContext context)
   at System.Windows.Forms.Application.Run(Form mainForm)
   at cameraWorks.Program.Main() in C:\Users\Adrian\documents\visual studio 2010\Projects\cameraWorks\cameraWorks\Program.cs:line 18
   at System.AppDomain._nExecuteAssembly(RuntimeAssembly assembly, String[] args)
   at System.AppDomain.ExecuteAssembly(String assemblyFile, Evidence assemblySecurity, String[] args)
   at Microsoft.VisualStudio.HostingProcess.HostProc.RunUsersAssembly()
   at System.Threading.ThreadHelper.ThreadStart_Context(Object state)
   at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean ignoreSyncCtx)
   at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)
   at System.Threading.ThreadHelper.ThreadStart()
</code></pre>

<p>InnerException:</p>

<blockquote>
  <p>InnerException: System.BadImageFormatException
         Message=An attempt was made to load a program with an incorrect format. (Exception from HRESULT: 0x8007000B)
         Source=Emgu.CV
         StackTrace:
              at Emgu.CV.CvInvoke.cvRedirectError(CvErrorCallback errorHandler, IntPtr userdata, IntPtr prevUserdata)
              at Emgu.CV.CvInvoke..cctor() in C:\Program Files (x86)\Emgu\libemgucv-windows-x64-2.2.1.1150\Emgu.CV\PInvoke\CvInvoke.cs:line 50</p>
</blockquote>

<p>I am only executing some simple code being:</p>

<pre><code>public partial class Form1 : Form
{
    private Capture capture;
    private bool captureInProgress;

    public Form1()
    {
        InitializeComponent();
    }

    private void ProcessFrame(Object sender, EventArgs args )
    {
        Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
        CamImageBox1.Image = ImageFrame;
    }

    private void camButton_Click(object sender, EventArgs e)
    {
        if (capture == null)
        {
            try
            {
                capture = new Capture();
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(excpt.Message);
            }
        }

        if (capture != null)
        {
            if (captureInProgress)
            {
                camButton.Text = ""start"";
            }
            else
            {
                camButton.Text = ""stop"";
                Application.Idle += ProcessFrame;
            }
            captureInProgress = !captureInProgress;
        }
    }

    private void ReleaseData()
    {
        if (capture != null)
        {
            capture.Dispose();
        }
    }
</code></pre>

<p>The examples of emguCV work on my computer.
Thanks Alot 
Adrian</p>
",2012-09-24 05:52:05,2014-04-04 07:37:47,Emgu.CV.CvInvoke' threw an exception,<c#><computer-vision><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7510,11515274,2012-07-17 02:30:41,,"<p>What is the difference between Matrix and McvMat in Emgu cv? How do I create a McvMat?</p>
",2012-07-17 06:35:03,2012-07-25 09:34:02,What is the difference between Matrix<Depth> and McvMat in Emgu cv?,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
7524,12494191,2012-09-19 11:54:11,,"<p>I created this type:</p>

<pre><code> public class ImageHolder :Image&lt;Bgr,byte&gt;
    {   
        private String imagePath;

        public ImageHolder(String path):base()
        {
           this.imagePath = path;            
        }

        public String imgPathProperty
        {
            get
            {
                return imagePath;
            }
            set
            {
                imagePath = value;
            }
        }
    }
</code></pre>

<p>Here is the instance of the class:</p>

<pre><code>ImageHolder sd = new ImageHolder(""path"");
</code></pre>

<p>I need to get the base type of SignDetection type.</p>

<pre><code>Image&lt;Bgr,Byte&gt; img = sd.BaseType;
</code></pre>

<p>Any idea how can I implement it?</p>

<p>Thank you in advance.</p>
",2012-09-19 12:05:00,2012-09-19 12:12:41,How to get a base class?,<c#><.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7591,11522584,2012-07-17 12:37:01,,"<p>I want to train a Random forest of 500 trees.
In OpenCV, there is a parameter under <a href=""http://docs.opencv.org/modules/ml/doc/random_trees.html#cvrtparams-cvrtparams"" rel=""nofollow"">CvRTParams</a> called: max_num_of_trees_in_the_forest.</p>

<p>I cannot find this parameter in Emgu equivalent object: <a href=""http://www.emgu.com/wiki/files/1.5.0.0/Help/html/22a7f4f4-5976-c63c-acce-d23817b79e96.htm"" rel=""nofollow"">MCvRTParams</a>.</p>

<p>So how could I build a model consisting of 500 random trees in the absence of this parameter in the managed Emgu object?</p>

<p>Please help.</p>

<p>Thanks</p>
",,2012-07-17 23:04:17,Where is 'max_num_of_trees_in_the_forest' parameter in Emgu C# MCvRTParams?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
7593,12498089,2012-09-19 15:38:38,,"<p>I'm trying to write a program that detects a circle when you hold it in front of the webcam. I know how the circle detection works for an image, but I can't figure out how to get it to work with a webcam stream, using the following code:</p>

<pre><code>static class Program
{
    /// &lt;summary&gt;
    /// The main entry point for the application.
    /// &lt;/summary&gt;
    [STAThread]
    static void Main()
    {
        ImageViewer viewer = new ImageViewer(); //create an image viewer
        Capture capture = new Capture(); //create a camera capture
        Application.Idle += new EventHandler(delegate(object sender, EventArgs e)
        {  //run this until application closed (close button click on image viewer)
            Image&lt;Bgr, Byte&gt; image = capture.QueryFrame();
            //MemStorage storage = new MemStorage();
            //Contour&lt;Point&gt; contours = image.FindContours();
           //Contour&lt;Point&gt; currentContour = contours.ApproxPoly(contours.Perimeter * 0.05, storage);
            viewer.Image = image; //draw the image obtained from camera
        });
        viewer.ShowDialog(); //show the image viewer
}
</code></pre>

<p>As you can see I've tried using FindContours in the innermost loop but the program just freezes when I try running it, so I commented that particular part out. Can anyone tell me how to implement circle detection using a webcam?</p>
",,2012-09-24 05:38:43,Emgu circle detection using a webcam,<webcam><detection><geometry><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7600,9556761,2012-03-04 16:44:05,,"<p>I'm trying to open a mpg-File using emguCV. I use the following code:</p>

<pre><code>    if (instance == null)
    {
        lock (m_lock)
        {
            try
            {
                instance = new Capture(0);  // capture from camera works fine if a camera is connected
            }
            catch (NullReferenceException)
            {
                String sFileName = @""C:\tmp\MarkerMovie.mpg"";


                try
                {
                    if (File.Exists(sFileName))
                    {
                        instance = new Capture(sFileName);  // here the exception is thrown
                    }
                    else
                    {
                        MessageBox.Show(""No Camera and no Video-File found"");
                    }
                }
                catch (NullReferenceException)
                {
                    MessageBox.Show(""Couldn't open Video: ""+sFileName);
                }
            }
        }
    }
</code></pre>

<p>If a webcam is connected everything works fine, but when I unplug the webcam the line <code>instance = new Capture(sFileName);</code> throws a NullReferenceException:</p>

<blockquote>
  <p>Message = ""Unable to create capture from C:\tmp\MarkerMovie.mpg""</p>
</blockquote>

<p>I debugged and found the reason is in the constructor of capture. The following command always returns a Null-Pointer:</p>

<pre><code>_ptr = CvInvoke.cvCreateFileCapture(fileName);
</code></pre>

<p>I could open the same video using C++ using this code:</p>

<pre><code>cap = cvCaptureFromFile(""C:\\tmp\\MarkerMovie.mpg"");
</code></pre>

<p>I'm new to openCV, so I'm not sure which information you need to help me. I installed emguCV yesterday from <a href=""http://sourceforge.net/projects/emgucv/"" rel=""nofollow"">http://sourceforge.net/projects/emgucv/</a> on a Windows XP computer. The installer-version is x86_2.3.0.1416. I included opencv_core231.dll, opencv_highgui231.dll and opencv_imgproc231.dll to my project.</p>

<p>Does somebody know how I can make this code working?
Let me know if you need more information.</p>

<p>Thanks.</p>
",,2016-07-06 16:13:20,Can't open a mpg-File for capture using EmguCV with C#,<c#><.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
7602,14425841,2013-01-20 15:05:39,,"<p>i have a document image (b/w, 300dpi) containing newspaper like formated text (title, paragraph columns etc).<br>
- How can i detect paragraphs columns to floodfill them with Black Color?<br>
- How can i get distance with of floodfill textcolumns?</p>

<p>Is this possible using OpenCV or EmguCV/C# ?</p>

<p>See this link <a href=""http://goo.gl/6djHt"" rel=""nofollow"">http://goo.gl/6djHt</a> (no Spam its a shortlink) of what i mean.</p>

<p>Thanks in advance for any hints and code-snippets.</p>
",2013-01-20 15:31:33,2013-01-22 18:27:07,Detect & floodfill ROI using OpenCV,<c#><image-processing><opencv><emgucv><imaging>,,,CC BY-SA 3.0,True,False,True,False,False
7604,14426942,2013-01-20 17:05:23,,"<p>I am trying to use EmguCV to make a website in Visual Studio. Getting an error <code>The type initializer for 'Emgu.CV.CvInvoke' threw an exception</code> with the Inner Exception <code>An attempt was made to load a program with an incorrect format. (Exception from HRESULT: 0x8007000B).</code></p>
<p>Following are the details of my setup:</p>
<blockquote>
<p>Windows 8 64-bit</p>
<p>VS2012</p>
<p>Emgu library 2.3 for Windows x64</p>
</blockquote>
<p>Most of the help I saw in forums was for a project, but in case it matters, this is a website.</p>
<p>I have already copied all DLLs into '<code>Website\bin</code>' folder. So, I doubt if that is the problem. I put these DLLs into <code>System32</code> and <code>SysWOW64</code> folders as well. Didn't work.</p>
",2020-06-20 09:12:55,2015-02-19 20:37:49,"The type initializer for 'Emgu.CV.CvInvoke' threw an exception for Win8 64bit, VS2012",<visual-studio-2012><runtime-error><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7633,9560416,2012-03-05 00:54:44,,"<p>I am trying improve the speed of detecting faces in images by running the DetectHaarCascade face detection concurrently on multiple files.  But I am hitting AccessViolationException, wondering does anyone have examples on how to run EMGU CV face detection parallelly.</p>

<p>Here is a simple test I wrote where I have 98 images to detect:</p>

<pre><code>    [TestMethod]
    public void TestDetectParallel()
    {
        var face = new HaarCascade(""haarcascade_frontalface_default.xml"");
        var images =
            Directory.EnumerateFiles(Environment.CurrentDirectory, ""*.jpg"").AsParallel().Select(
                file =&gt; new Image&lt;Gray, byte&gt;(file));
        Parallel.ForEach(
            images, 
            image =&gt;
            {
                image.DetectHaarCascade(face, 1.2, 10, HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                                        new Size(20, 20));
            });
    }
</code></pre>

<p>because i am running it in parallel, I hit some multithread issue, with stack trace:</p>

<pre><code>System.AccessViolationException was unhandled by user code
  Message=Attempted to read or write protected memory. This is often an indication that other memory is corrupt.
  Source=Emgu.CV
  StackTrace:
       at Emgu.CV.CvInvoke.cvHaarDetectObjects(IntPtr image, IntPtr cascade, IntPtr storage, Double scaleFactor, Int32 minNeighbors, HAAR_DETECTION_TYPE flags, Size minSize)
       at Emgu.CV.Image`2.&lt;&gt;c__DisplayClassa.&lt;DetectHaarCascade&gt;b__6(IImage img, Int32 channel) in C:\Emgu\emgucv-windows-x86 2.3.0.1416\Emgu.CV\Image.cs:line 888
       at Emgu.CV.Image`2.ForEachDuplicateChannel[TReturn](Func`3 conv) in C:\Emgu\emgucv-windows-x86 2.3.0.1416\Emgu.CV\Image.cs:line 1229
       at Emgu.CV.Image`2.DetectHaarCascade(HaarCascade haarObj, Double scaleFactor, Int32 minNeighbors, HAAR_DETECTION_TYPE flag, Size minSize) in C:\Emgu\emgucv-windows-x86 2.3.0.1416\Emgu.CV\Image.cs:line 904
       at PhotosortService.UnitTest.UnitTest1.&lt;&gt;c__DisplayClass3.&lt;TestDetectParallel&gt;b__1(Image`2 image) in C:\Users\bchiu\Desktop\PhotosortService\PhotosortService.UnitTest\UnitTest1.cs:line 35
       at System.Threading.Tasks.Parallel.&lt;&gt;c__DisplayClass32`2.&lt;PartitionerForEachWorker&gt;b__30()
       at System.Threading.Tasks.Task.InnerInvoke()
       at System.Threading.Tasks.Task.InnerInvokeWithArg(Task childTask)
       at System.Threading.Tasks.Task.&lt;&gt;c__DisplayClass7.&lt;ExecuteSelfReplicating&gt;b__6(Object )
       at System.Threading.Tasks.Task.ExecuteSelfReplicating(Task root)
       at System.Threading.Tasks.Task.Execute()
       at System.Threading.Tasks.Task.ExecutionContextCallback(Object obj)
       at System.Threading.ExecutionContext.runTryCode(Object userData)
       at System.Runtime.CompilerServices.RuntimeHelpers.ExecuteCodeWithGuaranteedCleanup(TryCode code, CleanupCode backoutCode, Object userData)
       at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state)
       at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean ignoreSyncCtx)
       at System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task&amp; currentTaskSlot)
       at System.Threading.Tasks.Task.ExecuteEntry(Boolean bPreventDoubleExecution)
       at System.Threading.Tasks.ThreadPoolTaskScheduler.TryExecuteTaskInline(Task task, Boolean taskWasPreviouslyQueued)
       at System.Threading.Tasks.TaskScheduler.TryRunInline(Task task, Boolean taskWasPreviouslyQueued, Object threadStatics)
       at System.Threading.Tasks.Task.InternalRunSynchronously(TaskScheduler scheduler)
       at System.Threading.Tasks.Task.RunSynchronously(TaskScheduler scheduler)
       at System.Threading.Tasks.Parallel.PartitionerForEachWorker[TSource,TLocal](Partitioner`1 source, ParallelOptions parallelOptions, Action`1 simpleBody, Action`2 bodyWithState, Action`3 bodyWithStateAndIndex, Func`4 bodyWithStateAndLocal, Func`5 bodyWithEverything, Func`1 localInit, Action`1 localFinally)
       at System.Threading.Tasks.Parallel.ForEachWorker[TSource,TLocal](IEnumerable`1 source, ParallelOptions parallelOptions, Action`1 body, Action`2 bodyWithState, Action`3 bodyWithStateAndIndex, Func`4 bodyWithStateAndLocal, Func`5 bodyWithEverything, Func`1 localInit, Action`1 localFinally)
       at System.Threading.Tasks.Parallel.ForEach[TSource](IEnumerable`1 source, Action`1 body)
       at PhotosortService.UnitTest.UnitTest1.TestDetectParallel() in C:\Users\bchiu\Desktop\PhotosortService\PhotosortService.UnitTest\UnitTest1.cs:line 33
  InnerException: 
</code></pre>

<p>Thank you very much!</p>
",,2015-06-06 17:07:28,Emgu CV Face Recognition: Running DetectHaarCascade on multiple files in parallel issues,<multithreading><emgucv><face-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
7656,13470239,2012-11-20 09:35:52,,"<p>I'd like to convert a Bgr value (one pixel) to an Hsv value. How can I do that (without writing the conversion code from scratch) in EmguCV? </p>

<p>Please note that I am not interested in converting whole image's color space but only one pixel, therefore <code>CvInvoke.cvCvtColor()</code> does not work for me.</p>
",,2017-08-19 17:03:26,How to convert Bgr pixel to Hsv pixel in EmguCV?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
7713,12509582,2012-09-20 09:16:50,,"<p>Im using emgu in my project.</p>

<p>I get this exceptit:
<img src=""https://i.stack.imgur.com/cdAit.png"" alt=""enter image description here""></p>

<p>Here the details of the exception:
<img src=""https://i.stack.imgur.com/46nUU.png"" alt=""enter image description here""></p>

<p>The opencv_core242 is in the folder project,and platform target set to x86.</p>

<p>Any idea what might cause the exception and how to solve it?</p>
",,2014-01-21 17:29:05,Emgu.CV.CvInvoke threw an exception,<.net><dll><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
7728,13477452,2012-11-20 16:19:20,,"<p>I'm working on hand detection using EmguCv. I have successfully detected the skin color object in live video feed. With in that skin detected object I want to track the moving hand only. Please someone tell me how to achieve this without degrading the performance. A code or step by step procedure will be helpful. </p>

<p>Is there any best reference ebook on EmguCv for learning or any other material with code snipets?</p>
",,2015-08-12 02:10:15,Emgu Cv Motion Detection,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7735,9568908,2012-03-05 15:07:55,,"<p>I'm creating an application in which the user will use their face to move the mouse. I have used Emgucv (wrapper for opencv) to create an application in C# which detects the face of a person and locates the center-point on their face.
I'm using the <code>setcursorpos</code> function to move the cursor. What I'm doing is I'm passing the center coordinates of the face detection to <code>setcursorpos</code>, so the mouse movement is very limited.</p>

<p>How do I move the mouse anywhere on the screen smoothly by the slightest face movement?</p>
",2012-03-05 15:12:11,2012-03-06 08:06:36,Cursor movement through face center?,<c#><opencv><emgucv><motion-detection>,,,CC BY-SA 3.0,True,False,True,False,False
7760,15403898,2013-03-14 07:57:03,,"<p>I am developing a winForm c# program for smile detection with a webcam by using EmguCV library. I use some haarcascade_smile xml file to do it successfully.
However, a detection error occures in some cases: Sometimes the mouth shape line is wrongly identified as the mouth.</p>

<p>I have a new idea, which is to look for the color red in addition to the original xml file to improve mouth detection, and attempt to reduce the error rate.</p>

<p>Does anyone know of a command or library that can be used to detect red color ?</p>

<p>Many thanks :)</p>

<pre><code>var smiles = grayframe.DetectHaarCascade(_smiles, 
                                         ScaleIncreaseRate, 
                                         MinNeighbors, 
                                         HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, 
                                         new Size(WindowsSize, WindowsSize))[0];
if (smiles.Length == 0)
{
    // Number of smile face detected is 0
}
else
{

}
</code></pre>
",2013-03-14 08:07:53,2013-03-14 09:11:38,Color detection by using C#,<c#><winforms><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7764,15406235,2013-03-14 10:06:14,,"<p>I am writing a c# program with emgucv library.
I use the imagebox in emgucv to capture image from webcam.
And I want to get the color pixel of the image by using bitmap.Getpixel() by mouse clicking the imagebox.
However,
it contain error The error is..it cannot implicitly convert type 'Emgu.CV.IImage' to 'System.Drawing.Bitmap'</p>

<p>Can anyone give me idea to solve this problem?</p>

<pre><code>      Bitmap bitmap = newdetectimageBox.Image; //error
</code></pre>
",2013-03-14 14:00:36,2016-01-27 11:19:25,Convert EmguCV image to system drawing bitmap,<c#><winforms><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7797,10561222,2012-05-12 05:02:03,,"<p>I've got an image that I've scanned, but the white paper is not white on the screen. Is there a way to equalize the contract/brightness to make the background whiter?</p>

<p><a href=""https://i.stack.imgur.com/9jU1U.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/9jU1Um.jpg"" alt=""""></a></p>

<p><strong>Update</strong></p>

<p>I've tried the suggested Image._EqualizeHist function from EmguCv:</p>

<pre><code>string file = @""IMG_20120512_055533.jpg"";
Image&lt;Bgr, byte&gt; originalColour = new Image&lt;Bgr, byte&gt;(file);

Image&lt;Bgr, byte&gt; improved = originalColour.Clone();
improved._EqualizeHist();
</code></pre>

<p>But get an even worse result (also when first gray scaled):</p>

<p><a href=""https://i.stack.imgur.com/vetKe.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/vetKem.jpg"" alt=""""></a></p>

<p>Am I missing other parameters?</p>
",2012-05-12 05:31:36,2018-09-16 22:33:33,How do I equalize contrast & brightness of images using opencv?,<c#><opencv><image-manipulation><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
7804,9574740,2012-03-05 22:04:22,,"<p>I'm using the EMGU OpenCV wrapper for c#.  I've got a disparity map being created nicely.  However for my specific application I only need the disparity values of very few pixels, and I need them in real time.  The calculation is taking about 100 ms now, I imagine that by getting disparity for hundreds of pixel values rather than thousands things would speed up considerably.  I don't know much about what's going on ""under the hood"" of the stereo solver code, is there a way to speed things up by only calculating the disparity for the pixels that I need?  </p>
",,2012-03-19 17:51:12,EMGU OpenCV disparity only on certain pixels,<opencv><emgucv><disparity-mapping>,,,CC BY-SA 3.0,True,False,True,False,False
7844,15411369,2013-03-14 13:58:52,,"<p>I am writing a C# program which use the webcam to capture image.
For the box to output image, <code>imagebox</code> (in <code>EmguCV</code> library) is chosen.
I am willing to get the pixel information from the output image.
According to my finding, I need to convert the image in <code>imagebox</code> to bitmap then I can use the <code>picturebox</code> in c# to perform the analysis
(<a href=""http://www.emgu.com/wiki/index.php/Working_with_Images#Using_ImageBox"" rel=""nofollow"">http://www.emgu.com/wiki/index.php/Working_with_Images#Using_ImageBox</a>)
So, Tobitmap() method is requied. Can anyone give me idea on how to convert the imagebox image to bitmap base on the function?
Many thanks</p>

<pre><code>private void ProcessFrame(object sender, EventArgs arg)
{
   ImageFrame = _capture.QueryFrame();
   detectimageBox.Image = ImageFrame;
}
</code></pre>
",2013-03-14 14:02:31,2013-03-14 14:11:23,Imagebox convert to bitmap,<c#><winforms><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7876,15415369,2013-03-14 16:50:05,,"<p>I am try to using EmguCV's sift lib.
It's O.K. for me to find features from the image, i.e. </p>

<pre><code>SIFTDetector sift = new SIFTDetector();
var features = sift.DetectFeatures();
</code></pre>

<p>Now I want to do something like tracking the features, and I think it's might be using some api like ""feature2Dtracker"" ...
but I can't find how to use or place the syntax with ""Tdescriptor""...</p>

<p>I've googled for the whole official site from the EMGU, there's only an old SURF example...
Do you have any idea? 
Thanks</p>
",,2013-03-14 16:50:05,How to use Feature2DExtractor<TDescriptor> with EmguCV 2.4.0,<sift><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
7934,13493149,2012-11-21 12:21:45,,"<p>I have developed a c++ program which uses OpenCV. Now i want to develop a windows form based application in C#.
As C# can only handle managed code it is nearly impossible to run OpenCV directly on C# application. I have searched for different ways to create C# application using OpenCV, one of which is EmguCV and the other method that i am much more interested in is importing the c++ .dll file in C# application and calling the unmanaged functions this way.</p>

<p>I started by creating simple functions in c++ and i was able to use <code>cout</code> and <code>cin</code> in my C# application by importing the dll. The problem comes when i try to include OpenCV header files in my c++ application and when i compile i get this error</p>

<blockquote>
  <p>error LNK1104: cannot open file 'tbb_debug.lib'</p>
</blockquote>

<p>Some one has done this before but i cant figure out how he interface c++ with C# in 
<a href=""https://stackoverflow.com/questions/12616529/displaying-webcam-feed-in-cvmat-format-in-a-picturebox"">Displaying webcam feed in cv::Mat format in a picturebox</a></p>

<p>The Question is that i have function which takes in a cv::Mat variable and performs some image processing on it and returns the processed matrix. i want to use that function written in c++ in my C# application. but the problem is that i am unable to create the dll when i include OpenCV library in c++.</p>

<blockquote>
  <p>So please Don't Suggest me to use EmguCV or any other .NET wrappers
  for OpenCV.</p>
</blockquote>

<p>i am using Visual Studio 2010 for my Project. </p>
",2017-05-23 10:33:00,2016-11-26 05:36:01,calling opencv c++ code in C# application,<c#><c++><opencv>,,,CC BY-SA 3.0,True,True,True,False,False
7962,14458054,2013-01-22 11:59:16,,"<h2>Question</h2>

<p>What is the equivalent of <a href=""http://docs.opencv.org/modules/core/doc/utility_and_system_functions_and_macros.html?highlight=saturate_cast#template%3C...%3E%20_Tp%20saturate_cast%28_Tp2%20v%29"" rel=""nofollow"">saturate_cast</a> in <a href=""http://www.emgu.com/"" rel=""nofollow"">emgucv</a>?</p>

<h2>Background</h2>

<p>I have an <code>Image&lt;Bgr, byte&gt;</code> and I want to perform a simple calculation on every pixel within it (incidentally: <code>alpha * val + beta</code> where <code>alpha</code> and <code>beta</code> are passed in).  To do this in <code>C++</code> I can do this:</p>

<pre><code>cv::Mat new_image = cv::Mat::zeros(image.size(), image.type());
for (int y = 0; y &lt; image.rows; y++)
{ 
    for (int x = 0; x &lt; image.cols; x++)
    { 
        for (int c = 0; c &lt; 3; c++)
        {
            new_image.at&lt;cv::Vec3b&gt;(y,x)[c] = cv::saturate_cast&lt;uchar&gt;(
                alpha * (image.at&lt;cv::Vec3b&gt;(y,x)[c]) + beta);
        }
    }
}
</code></pre>

<p>A really slow way to do the same in Emgu CV would be this:</p>

<pre><code>var newImage = image.CopyBlank();
for (int y = 0; y &lt; image.Rows; y++)
{
    for (int x = 0; x &lt; image.Cols; x++)
    {
        MCvScalar orig = image[y, x].MCvScalar;            
        var v0 = alpha * orig.v0 + beta;
        var v1 = alpha * orig.v1 + beta;
        var v2 = alpha * orig.v2 + beta;
        var v3 = alpha * orig.v3 + beta;
        var newCol = new Bgr();
        newCol.MCvScalar = new MCvScalar(v0, v1, v2, v3);
        newImage[y, x] = newCol;
    }
}
</code></pre>

<p>But that is just, as I say, terribly slow (too slow), so I <a href=""http://www.emgu.com/wiki/index.php/Working_with_Images#The_fast_way"" rel=""nofollow"">read</a> that one should use the <a href=""http://www.emgu.com/wiki/files/2.4.2/document/html/8eaaf685-939e-9365-2bd9-22ef02c39b20.htm"" rel=""nofollow"">Data</a> property so I can do something like this:</p>

<pre><code>var data = image.Data;
var newImage = image.CopyBlank();
for (int y = 0; y &lt; image.Rows; y++)
{
    for (int x = 0; x &lt; image.Cols; x++)
    {
        for (int c = 0; c &lt; 3; c++)
        {
            var b = data[y, x, c];
            double ret = alpha * b + beta;      

            // Eek, now I need to saturate_cast...                          
            newImage.Data[y, x, c] = (byte)ret;
        }
    }
}
</code></pre>

<p>But that does not do the correct thing as I am just casting the <a href=""http://msdn.microsoft.com/en-us/library/system.double.aspx"" rel=""nofollow"">double</a> to a <a href=""http://msdn.microsoft.com/en-us/library/system.byte.aspx"" rel=""nofollow"">byte</a> and not performing a <code>saturate_cast</code>.</p>

<p>I could also use the <a href=""http://www.emgu.com/wiki/index.php/Working_with_Images#Generic_Operation"" rel=""nofollow"">Convert</a> generic method, which I kind of prefer, but the problem is the same - I have a <a href=""http://msdn.microsoft.com/en-us/library/system.byte.aspx"" rel=""nofollow"">byte</a>, I apply my calculation to it and have a <a href=""http://msdn.microsoft.com/en-us/library/system.double.aspx"" rel=""nofollow"">double</a> but I need to get back to a <a href=""http://msdn.microsoft.com/en-us/library/system.byte.aspx"" rel=""nofollow"">byte</a>.</p>
",2013-01-22 15:12:17,2014-09-03 13:12:14,What is the Emgu CV equivalent of the Open CV saturate_cast function?,<c#><.net><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
8025,15428236,2013-03-15 08:59:02,,"<p>I am new to Kinect and C#. I am trying to get the Depth Image from the Kinect, convert it to a bitmap to perform some OpenCV operations and then display it. The problem is, I am getting only a third of the depth image and the rest is completely black(as seen in the picture). This is not the raw depth image but the image that I receive after painting.</p>

<p><img src=""https://i.stack.imgur.com/6NBcl.jpg"" alt=""enter image description here""></p>

<p>Here is the code-</p>

<p>image and image1 are the two image canvas i have for display.</p>

<pre><code>void DepthFrameReady(object sender, DepthImageFrameReadyEventArgs e)
    {

        DepthImageFrame Image;
        Bitmap bm;
        using (Image = e.OpenDepthImageFrame())
        {


           if (Image != null)
            {
            this.shortpixeldata = new short[Image.PixelDataLength];
            this.depthFrame32 = new byte[Image.Width * Image.Height * Bgr32BytesPerPixel];


            bmp = new Bitmap(Image.Width, Image.Height, System.Drawing.Imaging.PixelFormat.Format32bppRgb);
            Image.CopyPixelDataTo(this.shortpixeldata);

            byte[] convertedDepthBits = this.ConvertDepthFrame(this.shortpixeldata, ((KinectSensor)sender).DepthStream);


            BitmapData bmapdata = bmp.LockBits(
                                new System.Drawing.Rectangle(0, 0, Image.Width, Image.Height),
                                ImageLockMode.WriteOnly,
                                bmp.PixelFormat);


            IntPtr ptr = bmapdata.Scan0;
            Marshal.Copy(convertedDepthBits, 0, ptr, Image.PixelDataLength);
            bmp.UnlockBits(bmapdata);

            MemoryStream ms1 = new MemoryStream(); 
            bmp.Save(ms1, System.Drawing.Imaging.ImageFormat.Jpeg);
            System.Windows.Media.Imaging.BitmapImage bImg = new System.Windows.Media.Imaging.BitmapImage();
            bImg.BeginInit();
            bImg.StreamSource = new MemoryStream(ms1.ToArray());
            bImg.EndInit();

            image.Source = bImg;

                if (bmp != null)
            {

                Image&lt;Bgr, Byte&gt; currentFrame = new Image&lt;Bgr, Byte&gt;(bmp); 

                Image&lt;Gray, Byte&gt; grayImage = currentFrame.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();
                Image&lt;Gray, Byte&gt; Dest = new Image&lt;Gray, Byte&gt;(grayImage.Size);
                CvInvoke.cvCanny(grayImage, Dest, 10, 60, 3);


                image1.Source = ToBitmapSource(Dest);

                CalculateFps();
            }



            }



            else
            {
                System.Diagnostics.Debug.WriteLine(""depth bitmap empty :/"");
            }
        }
    }


        private byte[] ConvertDepthFrame(short[] depthFrame, DepthImageStream depthStream)
        {
            System.Diagnostics.Debug.WriteLine(""depthframe len :{0}"", depthFrame.Length);

        for (int i16 = 0, i32 = 0; i16 &lt; depthFrame.Length &amp;&amp; i32 &lt; this.depthFrame32.Length; i16++, i32 += 4)
        {

        int realDepth = depthFrame[i16] &gt;&gt; DepthImageFrame.PlayerIndexBitmaskWidth;


        byte Distance = 0;


        int MinimumDistance = 800;
        int MaximumDistance = 4096;


        if (realDepth &gt; MinimumDistance)
        {


        //White = Close
        //Black = Far
        Distance = (byte)(255-((realDepth-MinimumDistance)*255/(MaximumDistance-MinimumDistance)));


        this.depthFrame32[i32 + RedIndex] = (byte)(Distance);
        this.depthFrame32[i32 + GreenIndex] = (byte)(Distance);
        this.depthFrame32[i32 + BlueIndex] = (byte)(Distance);
        }

        else
        {
        this.depthFrame32[i32 + RedIndex] = 0;
        this.depthFrame32[i32 + GreenIndex] = 150;
        this.depthFrame32[i32 + BlueIndex] = 0;
        }
        }

        return this.depthFrame32;
        }
</code></pre>

<p>I tried different PixelFormats to no avail. I can't figure out the problem. Does someone have any idea what I'm doing wrong?
Thanks</p>
",2013-03-15 13:27:52,2013-05-22 16:37:14,Kinect Depth Image only partly visible,<c#><opencv><kinect><emgucv><kinect-sdk>,,,CC BY-SA 3.0,True,False,True,False,False
8039,14462927,2013-01-22 16:09:14,,"<p>I've been working with EMGU+OpenCV for quite some time and ran into this <code>AccessViolationException</code> mystery.</p>

<p>First thing first, the code:</p>

<pre><code>class AVE_Simulation
    {
        public static int Width = 7500;
        public static int Height = 7500;
        public static Emgu.CV.Image&lt;Rgb, float&gt;[] Images;

        static void Main(string[] args)
        {
            int N = 50;
            int Threads = 5;

            Images = new Emgu.CV.Image&lt;Rgb, float&gt;[N];
            Console.WriteLine(""Start"");

            ParallelOptions po = new ParallelOptions();
            po.MaxDegreeOfParallelism = Threads;
            System.Threading.Tasks.Parallel.For(0, N, po, new Action&lt;int&gt;((i) =&gt;
            {
                Images[i] = GetRandomImage();
                Console.WriteLine(""Prossing image: "" + i);
                Images[i].SmoothBilatral(15, 50, 50);
                GC.Collect();
            }));
            Console.WriteLine(""End"");
        }

        public static Emgu.CV.Image&lt;Rgb, float&gt; GetRandomImage()
        {
            Emgu.CV.Image&lt;Rgb, float&gt; im = new Emgu.CV.Image&lt;Rgb, float&gt;(Width, Height);

            float[, ,] d = im.Data;
            Random r = new Random((int)DateTime.Now.Ticks);

            for (int y = 0; y &lt; Height; y++)
            {
                for (int x = 0; x &lt; Width; x++)
                {
                    d[y, x, 0] = (float)r.Next(255);
                    d[y, x, 1] = (float)r.Next(255);
                    d[y, x, 2] = (float)r.Next(255);
                }
            }
            return im;
        }

    }
</code></pre>

<p>The code is simple. Allocate an array of images. Generate a random image and populate it with random numbers. Execute bilateral filter over the image. That's it.</p>

<p>If I execute this program in a single thread, (Threads=1) everything seems to work normally with no problem.
But, if I raise the number of concurrent threads to 5 I get an AccessViolationException very quickly.</p>

<p>I've went over OpenCV code and verified that there are no allocations on the OpenCV side and also went over the EMGU code searching for un-pinned objects or other problems and everything seems correct.</p>

<p>Some notes:</p>

<ol>
<li>If you remove the <code>GC.Collect()</code> you will get the <code>AccessViolationException</code> less often but it will eventually happen.</li>
<li>This happens only when executed in Release mode. In Debug mode I didn't experience any exceptions.</li>
<li>Although each Image is 675MB there is no problem with allocation (I have ALLOT of memory) and a '<code>OutOfMemoryException</code>' is thrown in case the system ran out of memory.</li>
<li>I used bilateral filter but I get this exception with other filters/functions as well. </li>
</ol>

<p>Any help would be appreciated. I've been trying to fix this for more than a week.</p>

<p>i7 (no overclock), Win7 64bit, 32GB RAM, VS 2010, Framework 4.0, OpenCV 2.4.3</p>

<p>Stack:</p>

<pre><code>Start
Prossing image: 20
Prossing image: 30
Prossing image: 40
Prossing image: 0
Prossing image: 10
Prossing image: 21

Unhandled Exception: System.AccessViolationException: Attempted to read or write protected memory. This is often an indication that other memory is corrupt.
   at Emgu.CV.CvInvoke.cvSmooth(IntPtr src, IntPtr dst, SMOOTH_TYPE type, Int32 param1, Int32 param2, Double param3, Double param4)
   at TestMemoryViolationCrash.AVE_Simulation.&lt;Main&gt;b__0(Int32 i) in C:\branches\1.1\TestMemoryViolationCrash\Program.cs:line 32
   at System.Threading.Tasks.Parallel.&lt;&gt;c__DisplayClassf`1.&lt;ForWorker&gt;b__c()
   at System.Threading.Tasks.Task.InnerInvokeWithArg(Task childTask)
   at System.Threading.Tasks.Task.&lt;&gt;c__DisplayClass10.&lt;ExecuteSelfReplicating&gt;b__f(Object param0)
   at System.Threading.Tasks.Task.Execute()
   at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
   at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
   at System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task&amp; currentTaskSlot)
   at System.Threading.Tasks.Task.ExecuteEntry(Boolean bPreventDoubleExecution)
   at System.Threading.Tasks.ThreadPoolTaskScheduler.TryExecuteTaskInline(Task task, Boolean taskWasPreviouslyQueued)
   at System.Threading.Tasks.TaskScheduler.TryRunInline(Task task, Boolean taskWasPreviouslyQueued)
   at System.Threading.Tasks.Task.InternalRunSynchronously(TaskScheduler scheduler, Boolean waitForCompletion)
   at System.Threading.Tasks.Parallel.ForWorker[TLocal](Int32 fromInclusive, Int32 toExclusive, ParallelOptions parallelOptions, Action`1 body, Action`2 bodyWithState, Func`4 bodyWithLocal, Func`1 loc
alInit, Action`1 localFinally)
   at System.Threading.Tasks.Parallel.For(Int32 fromInclusive, Int32 toExclusive, ParallelOptions parallelOptions, Action`1 body)
   at TestMemoryViolationCrash.AVE_Simulation.Main(String[] args) in C:\branches\1.1\TestMemoryViolationCrash\Program.cs:line 35

Unhandled Exception: System.AccessViolationException: Attempted to read or write protected memory. This is often an indication that other memory is corrupt.
   at Emgu.CV.CvInvoke.cvSmooth(IntPtr src, IntPtr dst, SMOOTH_TYPE type, Int32 param1, Int32 param2, Double param3, Double param4)
   at TestMemoryViolationCrash.AVE_Simulation.&lt;Main&gt;b__0(Int32 i) in C:\branches\1.1\TestMemoryViolationCrash\Program.cs:line 32
   at System.Threading.Tasks.Parallel.&lt;&gt;c__DisplayClassf`1.&lt;ForWorker&gt;b__c()
   at System.Threading.Tasks.Task.InnerInvokeWithArg(Task childTask)
   at System.Threading.Tasks.Task.&lt;&gt;c__DisplayClass10.&lt;ExecuteSelfReplicating&gt;b__f(Object param0)
   at System.Threading.Tasks.Task.Execute()
   at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
   at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
   at System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task&amp; currentTaskSlot)
   at System.Threading.Tasks.Task.ExecuteEntry(Boolean bPreventDoubleExecution)
   at System.Threading.ThreadPoolWorkQueue.Dispatch()

Unhandled Exception: System.AccessViolationException: Attempted to read or write protected memory. This is often an indication that other memory is corrupt.
   at Emgu.CV.CvInvoke.cvSmooth(IntPtr src, IntPtr dst, SMOOTH_TYPE type, Int32 param1, Int32 param2, Double param3, Double param4)
   at TestMemoryViolationCrash.AVE_Simulation.&lt;Main&gt;b__0(Int32 i) in C:\branches\1.1\TestMemoryViolationCrash\Program.cs:line 32
   at System.Threading.Tasks.Parallel.&lt;&gt;c__DisplayClassf`1.&lt;ForWorker&gt;b__c()
   at System.Threading.Tasks.Task.InnerInvokeWithArg(Task childTask)
   at System.Threading.Tasks.Task.&lt;&gt;c__DisplayClass10.&lt;ExecuteSelfReplicating&gt;b__f(Object param0)
   at System.Threading.Tasks.Task.Execute()
   at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
   at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
   at System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task&amp; currentTaskSlot)
   at System.Threading.Tasks.Task.ExecuteEntry(Boolean bPreventDoubleExecution)
   at System.Threading.ThreadPoolWorkQueue.Dispatch()
Press any key to continue . . .
</code></pre>
",2013-01-28 18:20:44,2013-01-31 03:06:49,Access Violation Exception mystery,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
8175,15441060,2013-03-15 19:55:20,,"<p>I wish know if EmguCV permits a simple and efficient way to do what in MATLAB is done with the following line:</p>

<pre><code>C = A .* B
</code></pre>

<p>(assuming that A, B and C are matrix representing grayscale images with the same dimensions and types).</p>

<p>Assuming that I want to do the same operation above, but using two <code>Image&lt;Gray, byte&gt;</code> objects of EmguCV, the question is: <strong>is there a way to multiply point by point two image with the same dimensions?</strong></p>
",2013-03-16 00:57:38,2013-03-16 14:24:45,Multiply operation between images in EmguCV,<c#><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
8210,12554178,2012-09-23 16:47:57,,"<p>Is it possible to use FindExtrinsicCameraParams2 to get the pose matrix instead of using homography decomposition with SURF feature detection ?</p>
",,2012-09-23 18:56:39,Open CV Surf And FindExtrinsicCameraParams2,<opencv><augmented-reality><emgucv><homography><pose-estimation>,,,CC BY-SA 3.0,True,False,True,False,False
8238,16401947,2013-05-06 15:23:47,,"<p>I want to convolute my image with a kernel that has the shape of a circle (not filled) using Emgu.
I found the ConvolutionKernelF which suits my needs (<a href=""https://stackoverflow.com/questions/7782941/gaussian-noise-in-emgucv/7812901#7812901"">Gaussian Noise in emgucv</a>).</p>

<p>Does anybody know how I could draw a circle in this kernel? Without anti-aliasing that is.
Another simple method do do a convolution with a circular kernel is also appreciated.</p>

<p>I tried this:</p>

<pre><code>Image&lt;Gray, float&gt; kernel = new Image&lt;Gray, float&gt;(radius * 2 + 1, radius * 2 + 1);
kernel.Draw(new CircleF(new Point(radius, radius), radius), new Gray(1.0), 1);
ConvolutionKernelF ckernel = new ConvolutionKernelF(kernel.Data); // error
kernel.CopyTo(ckernel);
</code></pre>

<p>Unfortunatly, the third statement gives me:</p>

<pre><code>Argument 1: cannot convert from 'float[*,*,*]' to 'float[*,*]'
</code></pre>

<p>In addition, it does'nt seem very efficient.</p>

<p>Cheers,</p>

<p>Tom</p>
",2017-05-23 12:14:42,2013-05-07 10:50:34,Draw a circle in an Emgu ConvolutionKernelF,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
8280,16406958,2013-05-06 20:43:11,,"<p>I'm new to emgu and would like some advice on where to start.</p>

<p>I've looked through the shape detection but its far too complex for what i need .. i think.. and my surfexample isn't working. I get this error:</p>

<p><a href=""https://stackoverflow.com/questions/15643762/cannot-get-surf-example-in-emgu-cv-to-work"">Cannot get SURF example in EMGU.CV to work?</a></p>

<p>Anyway, this is what i would like to do: Find image A in image B. Image A is a simple square which always has the same grey 1 pixel border and always the same size (i believe) but the inner colour could be black or one of about 7 other colours (only ever a solid colour). i need to find the coordinates of image A in image b when i press a button. see the below images.</p>

<blockquote>
  <p>Image <strong>B</strong></p>
  
  <p><img src=""https://i.stack.imgur.com/rybjG.png"" alt=""image b""></p>
</blockquote>

<p>And</p>

<blockquote>
  <p>Image <strong>A</strong></p>
  
  <p><img src=""https://i.stack.imgur.com/HJ29C.png"" alt=""image a""></p>
</blockquote>
",2017-05-23 12:10:41,2013-05-07 14:36:03,emgu finding image a in image b,<c#><emgucv><surf><matchtemplate>,2013-05-07 19:35:26,,CC BY-SA 3.0,False,False,True,False,False
8281,16407267,2013-05-06 21:05:35,,"<p>I am learning to use Emgu CV and stumbled upon this Open CV example : <a href=""http://aishack.in/tutorials/tracking-colored-objects-in-opencv/"" rel=""nofollow noreferrer"">http://aishack.in/tutorials/tracking-colored-objects-in-opencv/</a></p>

<p>I want to recreate the <code>CvInRange</code> function in Emgu by creating this code :</p>

<pre><code>// create upper &amp; lower limit (HSV)
MCvScalar botLimit = new MCvScalar(20, 100, 100);
MCvScalar uprLimit = new MCvScalar(30, 255, 255);

// prepare the destination
Image&lt;Hsv, byte&gt; imageHSVDest = new Image&lt;Hsv, byte&gt;(imageWidth, imageHeight);

// 
CvInvoke.cvInRange(imageHSV, botLimit, uprLimit, imageHSVDest);
</code></pre>

<p>the <code>CvInvoke.cvInRange()</code> produce this error message (in vs2010) :</p>

<blockquote>
  <p>Error  1   The best overloaded method match for 'Emgu.CV.CvInvoke.cvInRange(System.IntPtr, System.IntPtr, System.IntPtr, System.IntPtr)' has some invalid arguments<br>
      Error   2   Argument 2: cannot convert from 'Emgu.CV.Structure.MCvScalar' to 'System.IntPtr'
      Error   3   Argument 3: cannot convert from 'Emgu.CV.Structure.MCvScalar' to 'System.IntPtr'</p>
</blockquote>

<p>It seems there is a mismatch data type. I have searched how to convert Emgu <code>MCvScalar</code> to <code>IntPtr</code> to no avail. </p>

<p>I used the <code>MCvScalar</code> by translating OpenCV <code>cvScalar(20, 100, 100)</code> from the example. Is this wrong?</p>
",2017-05-18 09:45:01,2017-05-18 09:45:01,How to use CvInRange in Emgu CV,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
8294,16407929,2013-05-06 21:54:34,,"<p>Is there any way  to convert an Image of type System.Drawing.Image in to Image of Emgu.CV.Image type or vice versa on EmguCV using C#? I will explain per your request if additional explanation is needed about the purpose of doing this.</p>
",,2020-07-11 18:13:04,"Convert System.Drawing.Image to Emgu.CV.Image<Gray,byte>",<c#><image><emgucv><typeconverter>,,,CC BY-SA 3.0,False,False,True,False,False
8333,9622889,2012-03-08 18:33:00,,"<p>I'm working on tracking objects based on color and I was using EmguCV library to threshold my color image to binary black and white image. Thresholding itself was quite fast, 50ms on 320x240 image. I'm using RG Chromaticity color space, so there are some necessarily calculations.</p>

<p>Now I'm trying to speed it up using pointers, but the result is very similar with what I did with emguCV (around 50ms per image).</p>

<p>I want to ask, if there is some expert who can help me, what I am doing wrong. Here is my short code snippet of my color thresholding implementation. It's based on this one <a href=""http://www.bobpowell.net/onebit.htm"" rel=""nofollow"">http://www.bobpowell.net/onebit.htm</a>.</p>

<pre><code>public static Bitmap ThresholdRGChroma(Bitmap original, double angleMin,
            double angleMax, double satMin, double satMax)
{
    Bitmap bimg = new Bitmap(original.Width, original.Height, PixelFormat.Format1bppIndexed);

    BitmapData imgData = original.LockBits(new Rectangle(0, 0, original.Width, original.Height), ImageLockMode.ReadOnly, original.PixelFormat);
    BitmapData bimgData = bimg.LockBits(new Rectangle(0, 0, bimg.Width, bimg.Height), ImageLockMode.ReadWrite, bimg.PixelFormat);

    int pixelSize = 3;

    double r, g, angle, sat;

    unsafe
    {
        byte* R, G, B;
        byte* row;
        int RGBSum;

        for (int y = original.Height - 1; y &gt;= 0; y--)
        {
            row = (byte*)imgData.Scan0 + (y * imgData.Stride);

            for (int x = original.Width - 1; x &gt;= 0; x--)
            {
                // get rgb values
                B = &amp;row[x * pixelSize];
                G = &amp;row[x * pixelSize + 1];
                R = &amp;row[x * pixelSize + 2];

                RGBSum = *R + *G + *B;

                if (RGBSum == 0)
                {
                    SetIndexedPixel(x, y, bimgData, false);
                    continue;
                }

                //calculate r ang g for rg chroma color space
                r = (double)*R / RGBSum;
                g = (double)*G / RGBSum;

                //and angle and saturation
                angle = GetAngleRad(r, g) * (180.0 / Math.PI);
                sat = Math.Sqrt(Math.Pow(g, 2) + Math.Pow(r, 2));

                //conditions to set pixel black or white
                if ((angle &gt;= angleMin &amp;&amp; angle &lt;= angleMax) &amp;&amp; (sat &gt;= satMin &amp;&amp; sat &lt;= satMax))
                    SetIndexedPixel(x, y, bimgData, true);
                else
                    SetIndexedPixel(x, y, bimgData, false);
            }

        }
    }

    bimg.UnlockBits(bimgData);
    original.UnlockBits(imgData);

    return bimg;
}

private unsafe static void SetIndexedPixel(int x, int y, BitmapData bmd, bool pixel)
{
    int index = y * bmd.Stride + (x &gt;&gt; 3);
    byte* p = (byte*)bmd.Scan0.ToPointer();
    byte mask = (byte)(0x80 &gt;&gt; (x &amp; 0x7));

    if (pixel)
        p[index] |= mask;
    else
        p[index] &amp;= (byte)(mask ^ 0xff);
}

private static double GetAngleRad(double x, double y)
{
    if (x - _rgChromaOriginX == 0)
        return 0.0;
    double angle = Math.Atan((y - _rgChromaOriginY) / (x - _rgChromaOriginX)); // 10ms

    if (x &lt; _rgChromaOriginX &amp;&amp; y &gt; _rgChromaOriginY)
        angle = angle + Math.PI;
    else if (x &lt; _rgChromaOriginX &amp;&amp; y &lt; _rgChromaOriginY)
        angle = angle + Math.PI;
    else if (x &gt; _rgChromaOriginX &amp;&amp; y &lt; _rgChromaOriginY)
        angle = angle + 2 * Math.PI;

    return angle;
}
</code></pre>
",2012-03-08 18:47:43,2015-03-31 19:46:10,How to speed up my color thresholding in C#,<c#><image-processing><color-space><threshold>,,,CC BY-SA 3.0,False,False,True,False,False
8350,12563939,2012-09-24 11:17:32,,"<p>I want to using the GPU to accelerate SURF algorithm. But Actually I found the CPUs(enale TBB) are 
more faster than the GPU for SURF algo.
<strong>My hardware and OS Info:</strong>
CPU: Intel(R) Xeon(R) CPU E3-1230 V2 @ 3.30GHz  (4 cores + 8 thread)
GPU: Nvidia GTX 660ti ~1000MHz (1344 GPU cores)
ubuntu 12.04 (64bit)</p>

<p><strong>Apply scene :</strong>
My folders have about 120 images. i need to get keypoints for every image using SURF.</p>

<p><strong>Time Logs</strong></p>

<p>CPU(TBB) for every image ,spend time logs:</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img0 cost time on SURF ALGO (ON TBB)[s]: 0.00666648</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img1 cost time onSURF ALGO (ON TBB)[s]: 0.00803925</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img2 cost time on SURF ALGO (ON TBB)[s]: 0.0066344</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img3 cost time on SURF ALGO (ON TBB)[s]: 0.00625698</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img4 cost time on SURF ALGO (ON TBB)[s]: 0.00699448</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img5 cost time on SURF ALGO (ON TBB)[s]: 0.00621663</p>

<pre><code>        .................more..................................
</code></pre>

<p>GPU for every image , spend time logs( GPU for every image have 2 lines log, one is upload img to GPU Mem, Second is SURF_GPU algo spend time):</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img0 cost time on GPU upload image[s]: 1.99329</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img0 cost time on Gpu SURF ALGO[s]: 0.00971809</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img1 cost time on GPU upload image[s]: 0.000157638</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img1 cost time on Gpu SURF ALGO[s]: 0.00618778</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img2 cost time on GPU upload image[s]: 8.8108e-05</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img2 cost time on Gpu SURF ALGO[s]: 0.00736609</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img3 cost time on GPU upload image[s]: 8.8599e-05</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img3 cost time on Gpu SURF ALGO[s]: 0.00559131</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img4 cost time on GPU upload image[s]: 8.7626e-05</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img4 cost time on Gpu SURF ALGO[s]: 0.00610033</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img5 cost time on GPU upload image[s]: 8.9125e-05</p>

<p>indexing DB:/home/ole/MatchServer/ImgDB0/img5 cost time on Gpu SURF ALGO[s]: 0.00632997</p>

<pre><code>      ............................more..................................
</code></pre>

<p><strong>I found the first image is very slow about 2 sec that uploading the image mat to GPU . the next is normal about 0.000157638 sec.</strong></p>

<p><strong>GPU CODE</strong>:</p>

<pre><code>    try
    {
        double t0 = (double)getTickCount();
        cv::gpu::SURF_GPU surf_gpu;
        Size size = help_img.size();
        Size size0 = size;
        int type = help_img.type();
        cv::gpu::GpuMat d_m(size0, type);
        if(size0 != help_img.size() )
            d_m = d_m(Rect((size0.width - size.width) / 2, (size0.height - size.height) / 2, size.width, size.height));
        d_m.upload(help_img);
        double t = ((double)getTickCount() - t0)/getTickFrequency();
        std::cout &lt;&lt; ""indexing DB:""&lt;&lt; path &lt;&lt; "" cost time on upload image[s]: "" &lt;&lt; t &lt;&lt; std::endl;

        t0 = (double)getTickCount();
        surf_gpu(d_m, cv::gpu::GpuMat(), help_keypoints);
        t = ((double)getTickCount() - t0)/getTickFrequency();
        std::cout &lt;&lt; ""indexing DB:""&lt;&lt; path &lt;&lt; "" cost time on Gpu image[s]: "" &lt;&lt; t &lt;&lt; std::endl;
    }
    catch (const cv::Exception&amp; e)
    {
       printf(""issue happen!"");
    }
</code></pre>

<p>Please help to give some suggestions about the following question:</p>

<p><strong>1.</strong> Why the first upload the image to GPU is very slower about 2 second ?</p>

<p><strong>2.</strong> Why the GPU not accelerate  the SURF algorithm, SURF have much calculate,in Theory,GPU can accelerate it.</p>

<p><strong>3.</strong> How to do can improve the GPU performance for the SURF algorithm?</p>

<p>Thanks!!</p>
",2012-09-24 11:28:08,2012-09-24 12:10:32,Why the GPU don't show the advantage than CPU for opencv SURF algorithm?,<image-processing><opencv><computer-vision><gpu><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
8360,16413494,2013-05-07 07:27:04,,"<p>I need to resize image,according to the specific aspect ratio.</p>

<p>For example if I have image with this dimensions 1600*800  the ratio is 2:1,</p>

<p>let's say I need to resize the image so the ratio have to be like that 2:3.</p>

<p>Any idea how can I implement it? </p>
",,2013-05-07 09:27:28,how to resize ratio in image,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
8361,16413720,2013-05-07 07:39:19,,"<p>I am suppose to detect if there is a head tilt in photos. These photos are identity card size photos or passport size photos. If a head tilt is detected, then I need to correct / rectify the tilt error by rotating the image clockwise or anticlockwise.</p>

<p>I want to know if there is any open source library or dll that can be used in the project that will help me detect face &amp; facial features like eyes and ears. </p>

<p>The detection must be done on the fly as there will be a 1000's of images opened from a directory.</p>

<p>I've gone through <a href=""http://www.codeproject.com/Articles/462527/Camera-Face-Detection-in-Csharp-Using-Emgu-CV-Open"" rel=""nofollow"">http://www.codeproject.com/Articles/462527/Camera-Face-Detection-in-Csharp-Using-Emgu-CV-Open</a> tutorial, but did not solve my problem. Also I've gone through EmguCV's eg. Example.FaceDetection.exe in the bin folder, but it does not detect the face. I tried loading other images as well, but still the same &amp; no highlighting of face or facial features.</p>
",2013-05-10 06:51:21,2013-05-10 06:51:21,Detect head tilt in a image,<c#><.net><vb.net><image><image-processing>,2013-05-07 08:26:20,,CC BY-SA 3.0,False,False,True,False,False
8384,12568827,2012-09-24 16:09:24,,"<p>How to remove background from a live video feed using emgucv. I need some thing like this <a href=""http://www.youtube.com/watch?v=WOEuE3D88b0"" rel=""nofollow"">video</a>. The only thing I want is a moving object or a human. i tried motion detection but didn't achieve the performance level.</p>
",,2018-07-06 03:20:15,background removal using emgucv,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
8398,11591463,2012-07-21 10:38:18,,"<p>I have an algorithm in created in c++ to make background subtraction, and i want to call it from c# with an argument ""IplImage"" using dll(extern). The problem that i acquire the camera stream in c# and i have the frame as image (bitmap).</p>

<p>How could i convert the bitmap to IplImage to send it in c++ and vice versa to retrieve the frame treated?</p>

<p>Many thanks.</p>
",,2012-07-25 09:10:33,Convert from Bitmap to MIplImage or IplImage c#,<opencv><bitmap><emgucv><iplimage>,,,CC BY-SA 3.0,True,False,True,False,False
8411,9628952,2012-03-09 04:29:42,,"<p>Hey OpenCV/Emgu gurus,</p>

<p>I have an image that I am generating contour for, see below. I am trying to generate a color histogram based pruning of search space of images to look for. How can I get the mask around just the prominent object contour and block out the remaining. So I have a 2 part question:</p>

<ol>
<li><p>How do I ""invert"" the image outside the contour? Floodfill invert, not? I am confused with all the options in OpenCV. </p></li>
<li><p>Second, how do I generate a 1-d color histogram from the contoured object in this case the red car to exclude the black background and only generate the color histogram that includes the car.</p></li>
</ol>

<p>How would I do that in OpenCV (preferably in Emgu/C# code)?</p>

<p><img src=""https://i.stack.imgur.com/V5TOs.jpg"" alt=""Source Image"">
<img src=""https://i.stack.imgur.com/RdLJa.jpg"" alt=""Contoured Image""></p>
",,2013-01-14 16:26:08,Generate Color Histogram around a contoured object,<opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
8493,16422838,2013-05-07 15:24:29,,"<p>I have been working on Microsoft Visual C# 2010 for an image processing program. The software uses EMGU CV 2.4.0. The program is very long (consists of 8 very lengthy functions) so i cannot post it here. Now, the program works perfectly on my pc. I have finished it. I can just run the exe file, and it works. My problem is that the .exe file doesnt work on another computer. Actually, I have 2 separate projects, But both are using EMGU CV. No error message  shows to me when I run the first exe on another pc ( although it shows to me sometimes that ( project1 stopped working, windows is trying to collect information, this might take minutes ) but that's not always. Now the error message that shows to me when i run the second exe on another pc is (microsoft .net framework, EMGU.CV.CVInvoke exception error). then the exe work and a window appear ( which is expected ) but the real task of the program which is doing some image processing is not being done.
Note that both of the projects are windows applications output type. 
Note that .NET framework 4 client profile is the target framework</p>

<p>I don't think this is .NET framework issue. Because I have tried to do a simple program and the exe file works on the other pc (it was just a simple streamwriter program which creates .txt) These are the EMGU CV libraries I'm using: </p>

<pre><code>EMGU.CV.dll
EMGU.CV.GPU.dll
EMGU.CV.UI.dll
EMGU.CV.UTIL.dll
</code></pre>

<p>Just for your information, I have downloaded EMGU CV 2.4.0 on the other pc as well ( after failing in running it with putting the libraries with the .exe in 1 file ) but still nothing works. I have no clue what on earth can be the problem!
I don't know if this is useful, but the program uses SURFFEATURE example as the one in the EMGU CV but with lots and lots of modifications ( I have worked on it since the last Novermber) and basically it is a program for object recognition purpose.</p>
",2014-02-04 17:22:55,2017-05-08 16:11:33,C# exe running issue with EMGU CV,<c#><exe><emgucv><computer-vision>,,,CC BY-SA 3.0,False,False,True,False,False
8530,12580453,2012-09-25 09:51:24,,"<p>I am new to emgu cv; I'm trying to find a code that makes motion detection. I tried this: </p>

<pre><code>CvInvoke.cvAbsDiff(frame, _backgroundImage, BgDifference);
</code></pre>

<p>... but I have lighting problems. I want to get white the pixels where there was motion, and then draw a rectangle there only one rectangle, but I take more areas with white pixels.</p>

<p>What do I need to do? Could I try ananother function?</p>
",2014-07-10 12:51:23,2016-10-30 18:59:03,Looking for a function for motion detection on emgucv,<c#><emgucv><motion-detection>,,,CC BY-SA 3.0,False,False,True,False,False
8604,10633284,2012-05-17 09:45:38,,"<p>I'm trying to use the SURF feature detector of emguCV in C# in order to detect the key points of an image.
I'm using this code:</p>

<pre><code>Image&lt;Gray, Byte&gt; myImage = new Image&lt;Gray, byte&gt;(""test.png"");
SURFDetector surf = new SURFDetector(500, false);
VectorOfKeyPoint myKeyPoints = surf.DetectKeyPointsRaw(myImage, null);
Matrix&lt;float&gt; myDescriptors = surf.ComputeDescriptorsRaw(myImage, null, myKeyPoints);
</code></pre>

<p>So I'm having the key points in that Matrix. What I want to do is to save/export these key points in an .xml file.
Can someone help me on how to do that? Thanks in advance.</p>
",,2012-09-25 17:09:13,How to save Matrix<float> to XML file?,<c#><xml><matrix><emgucv><surf>,,,CC BY-SA 3.0,False,False,True,False,False
8610,9645784,2012-03-10 10:45:15,,"<p>I am currently building an application which is able to access a number of USB webcams. I am well aware that there is no method which can count the number of camera devices on a machine, however, whenever I try to access a camera with a wrong index, I get a black image. Is there some way to use this image to denote a limit?</p>

<p>For example, I have two webcams. The application retrieves frames from the first camera at index 0, and from the second camera at index 1. When i increment index to 2, all I get is a black screen (obviously, since there is no 3rd camera attached).</p>

<p>So far the only way how to go about this is to access every single pixel in a 320x240 bitmap and check that it is black. This is not very efficient so maybe there's some other way of doing this which I am overlooking.</p>

<p>Thanks for your time.</p>
",,2012-03-11 12:57:57,OpenCV counting cameras,<c#><opencv><camera><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
8632,9648077,2012-03-10 16:31:29,,"<p>I'm having a big troubles with the libraries that I have to use in my project .
whenever I tried one of the libraries , a problem appears and I don't have so much time to get lost for all this time :( my project is ""Image Understanding""
so I need a ""feature extraction"" &amp; ""image segmentation "" &amp; ""Machine learning"" 
after reading , it turned out the "" SVM "" is the best one
and I want some code to build mine on it and start off .</p>

<hr>

<p>1- first I looked at ""Aforge &amp; Accord"" and there was an example named ""SupportVectorMachine"" but it's not on images .</p>

<hr>

<p>2- I found a great example in ""EmguCV"" named ""LatentSvmDetector"" and it detected any image of cat I tried it !! but the problem was in the xml file ! 
I just wanted to know how they got it ! and I couldn't find a simple answer 
actually I asked you here and no body answers me :(</p>

<p>[link] <a href=""https://stackoverflow.com/questions/9328231/how-to-extract-features-from-image-for-classification-and-object-recognition"">How to extract features from image for classification and object recognition?</a></p>

<hr>

<p>3- I found an example uses opencv here in this site </p>

<p>[link] <a href=""http://www.di.ens.fr/~laptev/download.html"" rel=""nofollow noreferrer"">http://www.di.ens.fr/~laptev/download.html</a>
but the same problem : xml file ?!!! 
I tried to take the xml file of this example and tried in the ""EmguCV"" example but it didn't work either .</p>

<hr>

<p>4- in all the papers that I read they're using ""ImageNet"" &amp; ""VOC PASCAL"" , I downloaded them and they're not working !! errors in the code of the tool !! and I've fixed them all 
but yet they're not compailing , those tool are written in ""Matlab""
here's my qusetion on this site :
[link] <a href=""https://stackoverflow.com/questions/9602464/mex32-link-error"">Matlab Mex32 link error while compiling Felzenszwalb VOC on Windows</a>
for god sake can anybody tell me what should I do ?! 
I'm running out of time , need your help ! 
thanks.</p>
",2017-05-23 11:48:02,2012-03-11 12:25:58,how can I get the xml files of models for object detection?,<image-processing><opencv><emgucv><svm><object-detection>,,,CC BY-SA 3.0,True,True,True,False,False
8650,11612046,2012-07-23 11:56:21,,"<p>I capture images from a webcam, do some heavy processing on them, and then show the result. To keep the framerate high, i want to have the processing of different frames run in parallel.</p>

<p>So, I have a 'Producer', which captures the images and adds these to the 'inQueue'; also it takes an image from the 'outQueue' and displays it:</p>

<pre><code>public class Producer
{
    Capture capture;
    Queue&lt;Image&lt;Bgr, Byte&gt;&gt; inQueue;
    Queue&lt;Image&lt;Bgr, Byte&gt;&gt; outQueue;
    Object lockObject;
    Emgu.CV.UI.ImageBox screen;
    public int frameCounter = 0;

    public Producer(Emgu.CV.UI.ImageBox screen, Capture capture, Queue&lt;Image&lt;Bgr, Byte&gt;&gt; inQueue, Queue&lt;Image&lt;Bgr, Byte&gt;&gt; outQueue, Object lockObject)
    {
        this.screen = screen;
        this.capture = capture;
        this.inQueue = inQueue;
        this.outQueue = outQueue;
        this.lockObject = lockObject;
    }

    public void produce()
    {
        while (true)
        {
            lock (lockObject)
            {
                inQueue.Enqueue(capture.QueryFrame());

                if (inQueue.Count == 1)
                {
                    Monitor.PulseAll(lockObject);
                }
                if (outQueue.Count &gt; 0)
                {
                    screen.Image = outQueue.Dequeue();                      
                }
            }
            frameCounter++;
        }           
    }
}
</code></pre>

<p>There are different 'Consumers' who take an image from the inQueue, do some processing, and add them to the outQueue:</p>

<pre><code>public class Consumer
{
    Queue&lt;Image&lt;Bgr, Byte&gt;&gt; inQueue;
    Queue&lt;Image&lt;Bgr, Byte&gt;&gt; outQueue;
    Object lockObject;
    string name;

    Image&lt;Bgr, Byte&gt; image;

    public Consumer(Queue&lt;Image&lt;Bgr, Byte&gt;&gt; inQueue, Queue&lt;Image&lt;Bgr, Byte&gt;&gt; outQueue, Object lockObject, string name)
    {
        this.inQueue = inQueue;
        this.outQueue = outQueue;
        this.lockObject = lockObject;
        this.name = name;
    }

    public void consume()
    {
        while (true)
        {
            lock (lockObject)
            {
                if (inQueue.Count == 0)
                {
                    Monitor.Wait(lockObject);
                    continue;
                }                
                image = inQueue.Dequeue();   
            }

            // Do some heavy processing with the image

            lock (lockObject)
            {
                outQueue.Enqueue(image);
            }

        }
    }
}
</code></pre>

<p>Rest of the important code is this section:</p>

<pre><code>    private void Form1_Load(object sender, EventArgs e)
    {
        Consumer[] c = new Consumer[consumerCount];
        Thread[] t = new Thread[consumerCount];

        Object lockObj = new object();
        Queue&lt;Image&lt;Bgr, Byte&gt;&gt; inQueue = new Queue&lt;Image&lt;Bgr, Byte&gt;&gt;();
        Queue&lt;Image&lt;Bgr, Byte&gt;&gt; outQueue = new Queue&lt;Image&lt;Bgr, Byte&gt;&gt;();

        p = new Producer(screen1, capture, inQueue, outQueue, lockObj);

        for (int i = 0; i &lt; consumerCount; i++)
        {
            c[i] = new Consumer(inQueue, outQueue, lockObj, ""c_"" + Convert.ToString(i));
        }
        for (int i = 0; i &lt; consumerCount; i++)
        {
            t[i] = new Thread(c[i].consume);
            t[i].Start();
        }

        Thread pt = new Thread(p.produce);
        pt.Start();
    }
</code></pre>

<p>The parallelisation actually works fine, I do get a linear speed increase with each added thread (up to a certain point of course). The problem is that I get artifacts in the output, even if running only one thread. The artifacts look like part of the picture is not in the right place.</p>

<p><a href=""http://i47.tinypic.com/rm1udf.jpg"" rel=""noreferrer"">Example of the artifact (this is without any processing to keep it clear, but the effect is the same)</a></p>

<p>Any ideas what causes this?
Thanks</p>
",,2014-01-16 00:27:35,parallel image processing artifacts,<c#><image><parallel-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
8670,16435976,2013-05-08 08:29:56,,"<p>Hi I'm using EmguCV and I enjoy programming with it.</p>

<p>However I'm wondering whether there is an elegant way to add two pixels individually.</p>

<p>To add images, you can use CvInvoke.Add(), but for individual pixel operation, you seems to have to write it in an ugly way, </p>

<p>say you have p, p1 and p2 as EmguCV::Bgr, </p>

<p>you have to write </p>

<pre><code>p = new Bgr(p1.b + p2.b, p1.g + p2.g, p1.r + p2.r);
</code></pre>

<p>I really hate this and tried to write an operator for this. But this is apparently impossible since operator overloading must be in the host class.</p>

<p>Is there any way to do this elegantly? </p>

<p>================Edit================</p>

<p>What I want to do is to calculate the summation of the pixels in an image. So the basic operation in this is to add pixels, or Bgr class.</p>
",2013-05-08 11:21:55,2013-05-08 12:16:03,How to add pixels in EmguCV,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
8683,12593058,2012-09-26 00:40:55,,"<p>In my project Im using EMGU librery.</p>

<p>I need to determine the background color of the urban poster or broadsheet.</p>

<p>As I see the background color of the poster or broadsheet is the predominant color.</p>

<p>My question if Emgu has any function that returns(in certain existing models BGR,HSL...) predominant color or some usefull results about colors in the image,
If not , any idea how can I achieve my goal in effective way?</p>

<p>Thank you in advance.</p>
",,2012-09-26 12:55:48,Any idea how to get background color of the poster or broadsheet?,<c#><.net><image-processing><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
8684,12594993,2012-09-26 05:20:00,,"<p>I've been asked to build a real-time face recognition application, and after some looking around I've decided to try EmguCV and OpenCV as the facial recognition library.</p>

<p>The issue I'm having at the moment is trying to get the SDK installed and working. I've followed the instructions found <a href=""http://www.emgu.com/wiki/index.php/Download_And_Installation"">here</a> to try and get it running, but I still can't run the samples. Whenever I try and run them, I get the error</p>

<pre><code>The program can't start because nvcuda.dll is missing from your computer. 
Try reinstalling the program to fix this problem.
</code></pre>

<p>I've tried most of the usual fixes, such as adding the bin folder to my environment path and copying the dll's into my system32 folder, but none of it seems to work.</p>

<ul>
<li>EmguCV version 2.4.2.1777-windows-x64-gpu </li>
<li>Windows 8 </li>
<li>AMD Radeon HD 6700 series graphics card.</li>
</ul>

<p>I'm assuming this is an issue with the fact that I dont have an nVidia graphics card, but I'm not sure what I can do about it. For now, I'm going to try recompiling the source rather than using the downloaded .exe, and seeing if that helps.</p>

<p>Any suggestions?</p>
",2013-03-03 12:21:11,2014-11-19 13:03:48,EmguCV - nvcuda.dll could not be found,<opencv><cuda><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
8725,16444575,2013-05-08 15:29:28,,"<p>I would like to measure the displacement of an object between two images. The displacement can be anything in the image plane. The result should give the displacement, if possible in sub pixel accuracy.</p>

<p>There are some assumptions, which should make it easier, but didn't help me so far:</p>

<ul>
<li>the camara objective is virtualy distortion free (telecentric) and oriented perpendicular to the object plane</li>
<li>the object plane never changes</li>
<li>the flat marker object (could be known image, e.g. a play card) is always in the object plane, so it isn't scaled or warped -> only rotational and translational changing.</li>
</ul>

<p>My first approach was to take the feature recognition example from EmguCV, find the first object in the first image, take the relevant piece of that picture, use it now as template and search it in the second image. This did work, but a little unsatisfactory. There was scaling and warpping in the homography matrix (probably because of some points, that where assigned wrong) and the placing accuracy was quite bad.</p>

<p>I tried this once with the demo of the commercial image processing software Halcon and it worked like a charm in sub pixel accuracy. There you can do some sort of least square fit of a template to the image you are searching the object in. The result is an affine transform matrix and very precise.</p>

<p>Is there something comparable in EmguCV/OpenCV?</p>

<p>Thank you in advance!</p>

<p><strong>Edit:</strong></p>

<p>Found the solution in EmguCV in the function</p>

<pre><code>CameraCalibration.EstimateRigidTransform(PointF[] src, PointF[] dest, bool fullAffine);
</code></pre>

<p>with <code>fullAffine</code> set to <code>false</code>. My problem before was, that I was using </p>

<pre><code>Features2DToolbox.GetHomographyMatrixFromMatchedFeatures();
</code></pre>

<p>from the matching example.</p>
",2013-06-10 12:08:45,2013-06-10 12:08:45,Exact measurement of translation and rotation of marker objects using OpenCV/EmguCV,<opencv><computer-vision><precision><emgucv><measurement>,,,CC BY-SA 3.0,True,False,True,False,False
8747,13563880,2012-11-26 11:27:07,,"<p>I need to detect a spiral shaped spring and count its coil turns.</p>

<p>I have tried as follows:</p>

<pre><code>Image&lt;Bgr, Byte&gt; ProcessImage(Image&lt;Bgr, Byte&gt; img)
{ 
    Image&lt;Bgr, Byte&gt; imgClone = new Image&lt;Bgr,byte&gt;( img.Width, img.Height);
    imgClone = img.Clone();
    Bgr bgrRed = new Bgr(System.Drawing.Color.Red);


    #region Algorithm 1


    imgClone.PyrUp();
    imgClone.PyrDown();
    imgClone.PyrUp();
    imgClone.PyrDown();
    imgClone.PyrUp();
    imgClone.PyrDown();

    imgClone._EqualizeHist();
    imgClone._Dilate(20);
    imgClone._EqualizeHist();
    imgClone._Erode(10);

    imgClone.PyrUp();
    imgClone.PyrDown();
    imgClone.PyrUp();
    imgClone.PyrDown();
    imgClone.PyrUp();
    imgClone.PyrDown();

    imgClone._EqualizeHist();
    imgClone._Dilate(20);
    imgClone._EqualizeHist();
    imgClone._Erode(10);


    Image&lt;Gray, Byte&gt; imgCloneGray = new Image&lt;Gray, byte&gt;(imgClone.Width, imgClone.Height);

    CvInvoke.cvCvtColor(imgClone, imgCloneGray, Emgu.CV.CvEnum.COLOR_CONVERSION.CV_BGR2GRAY);

    imgCloneGray = imgCloneGray.Canny(c_thresh, c_threshLink);//, (int)c_threshSize);

    Contour&lt;System.Drawing.Point&gt; pts = imgCloneGray.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_EXTERNAL);

    CvInvoke.cvCvtColor(imgCloneGray, imgCloneYcc, Emgu.CV.CvEnum.COLOR_CONVERSION.CV_GRAY2BGR);

    if (null != pts)
    {
        imgClone.Draw(pts, bgrRed, 2);
        imgClone.Draw(pts.BoundingRectangle, bgrRed, 2);
    }

    #endregion 

    return imgClone; 
}
</code></pre>

<p><img src=""https://i.stack.imgur.com/i7x7L.jpg"" alt=""Input Image"">
<img src=""https://i.stack.imgur.com/sfu5w.jpg"" alt=""OutputImage""></p>

<p>I am some how able to get the spring but how to get the counts. I am looking for algorithms.
I am currently not looking for speed optimization.</p>

<p>This is similar like counting fingers. Spring spiral is very thin to get using contour. What else can be done. <a href=""http://www.luna-arts.de/others/misc/HandsNew.zip"" rel=""nofollow noreferrer"">http://www.luna-arts.de/others/misc/HandsNew.zip</a></p>
",2013-01-02 14:06:01,2013-01-02 14:06:01,How to detect and count a spiral's turns,<c#><wpf><emgucv><counting>,,,CC BY-SA 3.0,False,False,True,False,False
8837,15498537,2013-03-19 11:42:22,,"<p>I'm searching for a simple method to recognize if an hand is open or closed.</p>

<p>I'm using C# and <a href=""http://www.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow noreferrer"">EmguCV</a>, but this is not significative in this context. I only need a ""pseudo-code"" that describes what I need to do.</p>

<p>The input image to this algorithm is a binary image (I've already implemented the segmentation process) that represents the hand. The output must be a boolean (true for open hand, false otherwise).</p>

<p>This is an input example:</p>

<p><img src=""https://i.stack.imgur.com/qvzru.gif"" alt=""enter image description here""></p>

<p>I tried to consider something about the convex hull, or the percentage of white area, but I guess these methods are not robust enough for this kind of problem.</p>
",,2013-03-19 13:48:58,Open/closed hand recognition: a simple method,<algorithm><pseudocode><image-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
8860,16453792,2013-05-09 03:21:17,,"<p>I've been developing a face recognition application using EmguCV (C#). I got the whole thing working okay if I store the face images (training set) in simple windows folder. But, after I tried to migrate the face images to be stored in a Microsoft Access database, an 'object reference not set to an instance of an object' exception message often occurs (not always, but most of the time) when the application tries to recognize a face from the video feed.</p>

<p>Funny thing is, the recognition actually still works okay if the exception happens to not occur.</p>

<p>Here is the snippet of the code of my program, using windows folder and database:</p>

<p><strong>Reading the stored images from a Windows Folder</strong></p>

<pre><code>private void FaceRecognition_Load(object sender, EventArgs e)
    {
        //if capture is not created, create it now
        if (capture == null)
        {
            try
            {
                capture = new Capture();
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(excpt.Message);
            }
        }

        if (capture != null)
        {
            if (captureInProgress)
            {  
                Application.Idle -= ProcessFrame;
            }
            else
            {
                Application.Idle += ProcessFrame;
            }

            captureInProgress = !captureInProgress;
        }

        #endregion
        {
            // adjust path to find your xml at loading
            haar = new HaarCascade(""haarcascade_frontalface_default.xml"");

            try
            {
                //Load of previus trainned faces and labels for each image
                string Labelsinfo = File.ReadAllText(Application.StartupPath + ""\\TrainedFaces\\TrainedLabels.txt"");
                string[] Labels = Labelsinfo.Split('%');
                NumLabels = Convert.ToInt16(Labels[0]);
                ContTrain = NumLabels;
                string LoadFaces;

                for (int tf = 1; tf &lt; NumLabels + 1; tf++)
                {
                    LoadFaces = ""face"" + tf + "".bmp"";
                    trainingImages.Add(new Image&lt;Gray, byte&gt;(Application.StartupPath + ""\\TrainedFaces\\"" + LoadFaces));
                    labels.Add(Labels[tf]);
                }

            }
            catch (Exception error)
            {
                //MessageBox.Show(e.ToString());
                MessageBox.Show(""Nothing in binary database, please add at least a face(Simply train the prototype with the Add Face Button)."", ""Triained faces load"", MessageBoxButtons.OK, MessageBoxIcon.Exclamation);
            }
        }
    }
</code></pre>

<p><strong>Reading the stored images from a Microsoft Access Database</strong></p>

<pre><code>private void connectToDatabase()
    {
        DBConnection.ConnectionString = @""Provider=Microsoft.Jet.OLEDB.4.0;Data Source=FacesDatabase.mdb"";
        DBConnection.Open();
        dataAdapter = new OleDbDataAdapter(""Select * from TrainingSet1"", DBConnection);
        dataAdapter.Fill(localDataTable);

        if (localDataTable.Rows.Count != 0)
        {
            numOfRows = localDataTable.Rows.Count;
        }
    }

private void FaceRecognition_Load(object sender, EventArgs e)
    {
        //if capture is not created, create it now
        if (capture == null)
        {
            try
            {
                capture = new Capture();
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(excpt.Message);
            }
        }

        if (capture != null)
        {
            if (captureInProgress)
            {  
                Application.Idle -= ProcessFrame;
            }
            else
            {
                Application.Idle += ProcessFrame;
            }

            captureInProgress = !captureInProgress;
        }

        #endregion
        {
            // adjust path to find your xml at loading
            haar = new HaarCascade(""haarcascade_frontalface_default.xml"");

            connectToDatabase();

            Bitmap bmpImage;

            for (int i = 0; i &lt; numOfRows; i++)
            {
                byte[] fetchedBytes = (byte[])localDataTable.Rows[i][""FaceImage""];
                MemoryStream stream = new MemoryStream(fetchedBytes);
                bmpImage = new Bitmap(stream);
                trainingImages.Add(new Emgu.CV.Image&lt;Gray, Byte&gt;(bmpImage));

                String faceName = (String)localDataTable.Rows[i][""Name""];
                labels.Add(faceName);
            }
       }
   }
</code></pre>

<p><strong>The face recognition function that causes the exception (exactly the same both when using windows folder and Access database):</strong></p>

<pre><code>private void ProcessFrame(object sender, EventArgs arg)
    {
        Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();

        Image&lt;Gray, byte&gt; grayframe = ImageFrame.Convert&lt;Gray, byte&gt;();

        MinNeighbors = int.Parse(comboBoxMinNeighbors.Text);
        WindowsSize = int.Parse(textBoxWinSiz.Text);
        ScaleIncreaseRate = Double.Parse(comboBoxMinNeighbors.Text);

        var faces = grayframe.DetectHaarCascade(haar, ScaleIncreaseRate, MinNeighbors,
                                        HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                                        new Size(WindowsSize, WindowsSize))[0];

        if (faces.Length &gt; 0) 
        {
            Bitmap BmpInput = grayframe.ToBitmap();

            Graphics FaceCanvas;

            foreach (var face in faces)
            {
                t = t + 1;
                result = ImageFrame.Copy(face.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

                ImageFrame.Draw(face.rect, new Bgr(Color.Red), 2);

                ExtractedFace = new Bitmap(face.rect.Width, face.rect.Height);

                FaceCanvas = Graphics.FromImage(ExtractedFace);

                FaceCanvas.DrawImage(BmpInput, 0, 0, face.rect, GraphicsUnit.Pixel);

                ImageFrame.Draw(face.rect, new Bgr(Color.Red), 2);

                if (trainingImages.ToArray().Length != 0)
                {

                    MCvTermCriteria termCrit = new MCvTermCriteria(ContTrain, 0.001);

                    EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
                        trainingImages.ToArray(),
                        labels.ToArray(),
                        3000,
                        ref termCrit);
                    try
                    {
                        name = recognizer.Recognize(result).Label; 
                    }
                    catch (Exception error)
                    {
                        MessageBox.Show(error.ToString());
                    }

                    ImageFrame.Draw(name, ref font, new Point(face.rect.X - 2, face.rect.Y - 2), new Bgr(Color.LightGreen));
                }

            }
        }
        CamImageBox.Image = ImageFrame;
    }
</code></pre>

<p><strong>Here is the screenshot of the exception message:</strong>
<a href=""https://i.imgur.com/DvAhABK.jpg"" rel=""nofollow noreferrer"">http://i.imgur.com/DvAhABK.jpg</a></p>

<p>Line 146 where the exception occurs is this line of the ProcessFrame function:</p>

<pre><code>name = recognizer.Recognize(result).Label;
</code></pre>

<p>I tried searching for similar problems in the internet, and found these:
<a href=""https://stackoverflow.com/questions/6359302/object-reference-not-set-to-instance-of-an-object-error-when-trying-to-upload"">&#39;Object reference not set to instance of an object&#39; error when trying to upload image to database</a>
<a href=""https://stackoverflow.com/questions/2491721/c-sharp-object-reference-not-set-to-an-instance-of-an-object"">Object reference not set to an instance of an object #5</a>
<a href=""https://stackoverflow.com/questions/5427509/c-sharp-error-object-reference-not-set-to-an-instance-of-an-object"">C# Error &#39;Object Reference Not Set To An Instance Of An Object&#39;</a>
<a href=""https://stackoverflow.com/questions/5274921/c-object-reference-not-set-to-an-instance-of-an-object-error"">C#, &quot;Object reference not set to an instance of an object.&quot; error</a></p>

<p>Most of them suggests to check if any of the involved variable is null. I've checked the involved variable, and indeed the exception occurs when the <code>recognizer.Recognize(result)</code> statement returns null. </p>

<p>So my question is, why does that statement often return null when I use training images from the database, while it never returns null when I use training images from windows folder?</p>
",2019-07-30 21:13:36,2019-07-30 21:13:36,EmguCV - Face Recognition - 'Object reference not set' exception when using training set from Microsoft Access Database,<c#><ms-access><nullreferenceexception><emgucv><face-recognition>,,,CC BY-SA 4.0,False,False,True,False,False
8862,16454539,2013-05-09 04:44:28,,"<p>i am developing a C# app with emguCV and i am new to emguCV. I have seen this example in internet.</p>

<pre><code>Image&lt;Gray, Byte&gt;[] trainingImages = new Image&lt;Gray,Byte&gt;[5];  
        trainingImages[0] = new Image&lt;Gray, byte&gt;(""brad.jpg"");
        trainingImages[1] = new Image&lt;Gray, byte&gt;(""david.jpg"");
        trainingImages[2] = new Image&lt;Gray, byte&gt;(""foof.jpg"");
        trainingImages[3] = new Image&lt;Gray, byte&gt;(""irfan.jpg"");
        trainingImages[4] = new Image&lt;Gray, byte&gt;(""joel.jpg"");
 String[] labels = new String[] { ""Brad"", ""David"", ""Foof"", ""Irfan"" , ""Joel""}
  MCvTermCriteria termCrit = new MCvTermCriteria(16, 0.001); 

    EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
       trainingImages,
       labels,
       5000,
       ref termCrit);
        Image&lt;Gray,Byte&gt; testImage = new Image&lt;Gray,Byte&gt;(""brad_test.jpg"");

     String label = recognizer.Recognize(testImage);
     Console.Write(label);
</code></pre>

<p>what i need to know is how to train all images?</p>
",,2013-06-14 14:53:12,How to train images with EigenObjectRecognizer,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
8926,16457494,2013-05-09 08:25:22,,"<p>Im trying to apply Harris corners using Emgu CV Wrapper, and I'm learning from a book titled ""Open CV 2, Computer Vision Application Cook Book"" , the book examples are based on C++, below is their example on Harris after replacing cv::Mat with it's equivalent on Emgu MCvMat, however that didn't compile so I used the ""data"" field on the MCvMat object, it did compile but it hangs, no error no exception but it just hang.</p>

<pre><code> MCvMat cornerStrength = new MCvMat(); ;
 CvInvoke.cvCornerHarris(Global.GrayImage.Ptr, cornerStrength.data, 3, 3, 0.1);
</code></pre>

<p>any help will be appreciated</p>
",,2017-11-07 17:56:54,Harris corner using Emgu CV,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
8959,10662209,2012-05-19 04:05:17,,"<p>I've been working with emgu cv(opencv wrapper to capture images from a webcam and using its functions to proccess this images. 
I also detect the hand and track the hand movement...</p>

<p>Now, I need to draw a kind of earth or just an object according to the hand position, for which sharpGL is perfect for perspective transformation and so on. My problem is that I can't achieve that.</p>

<p>I don't know how to say to sharpGL ""you guy, draw that object within this hand tracking window"" 
Is it impossible what I want to do? I am desperate... any help would be great. Thanks in advance </p>

<p>see this video if you're still confused about what I meant (http://www.youtube.com/watch?v=ccL4t36sVvg)</p>

<p>so far, I've just translated this code <a href=""http://blog.damiles.com/2008/10/opencv-opengl/"" rel=""nofollow"">http://blog.damiles.com/2008/10/opencv-opengl/</a> into C#</p>

<p>and here's code snippet</p>

<pre><code>private void openGLControl_OpenGLInitialized(object sender, EventArgs e)
        {
            //  TODO: Initialise OpenGL here.

            //  The texture identifier.
            uint[] textures = new uint[1];

            //  Get the OpenGL object.
            OpenGL gl = openGLControl1.OpenGL;

            //texture.Create(gl);

            //  Get one texture id, and stick it into the textures array.
            gl.GenTextures(1, textures);

            //  Bind the texture.
            gl.BindTexture(OpenGL.GL_TEXTURE_2D, textures[0]);

            //  A bit of extra initialisation here, we have to enable textures.
            gl.Enable(OpenGL.GL_TEXTURE_2D);

            //  Specify linear filtering.
            gl.TexParameter(OpenGL.GL_TEXTURE_2D, OpenGL.GL_TEXTURE_MIN_FILTER, OpenGL.GL_NEAREST);
            gl.TexParameter(OpenGL.GL_TEXTURE_2D, OpenGL.GL_TEXTURE_MAG_FILTER, OpenGL.GL_NEAREST);

            gl.PixelStore(OpenGL.GL_UNPACK_ALIGNMENT, 1);

            //  Set the clear color.
            gl.ClearColor(1.0f, 1.0f, 1.0f, 1.0f);
        }


private void openGLControl_Resized(object sender, EventArgs e)
        {
            //  TODO: Set the projection matrix here.

            //  Get the OpenGL object.
            OpenGL gl = openGLControl1.OpenGL;
            //  Set the projection matrix.
            gl.MatrixMode(OpenGL.GL_PROJECTION);

            //  Load the identity.
            gl.LoadIdentity();

            //  Create a perspective transformation.
            gl.Perspective(60.0f, (double)Width / (double)Height, 0.01, 100.0);

            //  Use the 'look at' helper function to position and aim the camera.
            gl.LookAt(-5, 5, -5, 0, 0, 0, 0, 1, 0);

            //  Set the modelview matrix.
            gl.MatrixMode(OpenGL.GL_MODELVIEW);
        }
</code></pre>

<p>and finally draw an 3D object</p>

<pre><code>private void openGLControl_OpenGLDraw(object sender, PaintEventArgs e)
        {
            //  Get the OpenGL object.
            OpenGL gl = openGLControl1.OpenGL;

            if (capture == null)
            {
                this.start_capture();
            }

            if (capture != null)
            {
                Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();

                //I'm trying to use some algorithm using the code from sample (sharpGLTextureExample)
                //first, I make an Bitmap object that I take from queryframe(convert it to bitmap first)
                Bitmap image = new Bitmap(ImageFrame.ToBitmap());


                //  Clear the color and depth buffer.
                gl.Clear(OpenGL.GL_COLOR_BUFFER_BIT | OpenGL.GL_DEPTH_BUFFER_BIT);
                //ImageFrame.Draw(new Rectangle(2, 2, 2, 2), new Bgr(Color.Aqua), 2);


                //  Load the identity matrix.
                gl.LoadIdentity();

                //then, Lock the image bits (so that we can pass them to OGL).
                BitmapData bitmapData = image.LockBits(new Rectangle(0, 0, image.Width, image.Height),
                ImageLockMode.ReadOnly, PixelFormat.Format32bppArgb);

                gl.BindTexture(OpenGL.GL_TEXTURE_2D, textures[0]);
                //gl.TexImage2D(OpenGL.GL_TEXTURE_2D, 0, (int)OpenGL.GL_RGBA, ImageFrame.Width, ImageFrame.Height, 0, OpenGL.GL_RGBA, OpenGL.GL_UNSIGNED_BYTE, ImageFrame);
                gl.TexImage2D(OpenGL.GL_TEXTURE_2D, 0, (int)OpenGL.GL_RGBA, ImageFrame.Width, ImageFrame.Height, 0, OpenGL.GL_RGBA, OpenGL.GL_UNSIGNED_BYTE, bitmapData.Scan0);


                //gl.Begin(OpenGL.GL_QUADS);

                //gl.TexCoord(0, 0); gl.Vertex(-1, -1, 0);
                //gl.TexCoord(1, 0); gl.Vertex(1, -1, 0);
                //gl.TexCoord(1, 5); gl.Vertex(1, 1, 0);
                //gl.TexCoord(0, 1); gl.Vertex(-1, 1, 0);
                //gl.End();

                //gl.Flush();

                //texture.Bind(gl);
                //
                //CamImageBox.Image = ImageFrame;
            }

        }
</code></pre>

<p>but the output always return an white, no texture on it...</p>

<p>I've also consindering to use Texture class, but it's no use..because there's no method which the input parameter is the frame...</p>
",2012-05-19 06:30:12,2013-05-12 23:27:16,Can't Draw SharpGL(openGL wrapper) object in EMGU CV,<c#><opengl><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
8964,16462306,2013-05-09 12:55:06,,"<p>I was having a hard time loading training set from Ms Access database in to the main form that does the Face Recognition. I saved the training sets with their names and ID in to the database as a binary data with an OLE Object format.The method i used to change, save and read the data from the database and in to the training sets is </p>

<pre><code>private static byte[] ConvertImageToBytes(Image InputImage)
    {
        using (Bitmap BmpImage = new Bitmap(InputImage))
        {
            using (MemoryStream MyStream = new MemoryStream())
            {
                BmpImage.Save(MyStream, System.Drawing.Imaging.ImageFormat.Jpeg);
                byte[] ImageAsBytes = MyStream.ToArray();
                return ImageAsBytes;
            }
        }
    }
</code></pre>

<p>The method that i use to store the converted byte data to the database is the following:</p>

<pre><code>   private void StoreData(byte[] ImageAsBytes,String NameStudent,String IDStudent)
    {

        if (DBConnection.State.Equals(ConnectionState.Closed))
            DBConnection.Open();
        try
        {

            //MessageBox.Show(""Saving image at index : "" + rowPosition);
            using (OleDbCommand insert = new OleDbCommand(String.Format(""Insert INTO
               TrainingSet(rowPosition,StudentName,StudentID,StudentFace) values ('
                {0}','{1}','{2}',@StudentFace)"", rowPosition, NameStudent, IDStudent),
                DBConnection))
            {
        OleDbParameter imageParameter = insert.Parameters.AddWithValue(@""StudentFace"",
                   SqlDbType.Binary);
       imageParameter.Value = ImageAsBytes;
       imageParameter.Size = ImageAsBytes.Length;
       int rowsAffected = insert.ExecuteNonQuery();
       MessageBox.Show(String.Format(""Data stored successfully in {0}
                                       Row"",rowsAffected));
         }
            rowPosition++;

        }
        catch (Exception ex)
        {
            MessageBox.Show(ex.Message);
            MessageBox.Show(ex.Message);
        }
        finally
        {
            RefreshDBConnection();
        }
      }
</code></pre>

<p>The method that i use to Read this binary data is as follows: </p>

<pre><code>    private Image ReadImageFromDB()
    {

        Image FetchedImg;
        if (rowNumber &gt;= 0)
        {

        byte[] FetchedImgBytes = (byte[])LocalDataTable.Rows[rowNumber][""StudentFace""];
            MemoryStream stream = new MemoryStream(FetchedImgBytes);
            FetchedImg = Image.FromStream(stream);
            return FetchedImg;
        }
        else
        {

            MessageBox.Show(""There are no images in the database yet.Please reconnect
                       or add some pictures."");
            return null;
        }

    }
</code></pre>

<p>I have successfully saved the training sets/images as a binary data in to the database.The problem is when i load these training sets for Recognition.</p>

<pre><code>        // Declaring the variables=====trainingImages is where the training sets are
        // loaded from the database NameLabels and IDLabels are text in the database
        // and where name and Id of subject
        //is saved.
      List&lt;Image&lt;Gray,byte&gt;&gt; trainingImages = new List&lt;Image&lt;Gray,byte&gt;&gt;();
      List&lt;string&gt; NameLables= new List&lt;string&gt;();
      List&lt;string&gt; IDLables = new List&lt;string&gt;();
      int ContTrain, NumNameLabels,NumIDLabels, t;

   //The training sets from the database are loaded in to the facerecognizer code as 
   //       follows

  public FaceRecognizer()
    {
        InitializeComponent();

        try
        {
            //Load previous trained and labels for each image from the database Here
        RefreshDBConnection();
        String[] NameLabels = (String[])LocalDataTable.Rows[rowNumber][""StudentName""];
        NumNameLabels = Convert.ToInt16(NameLabels[0]);
        String[] IDLabels = (String[])LocalDataTable.Rows[rowNumber][""StudentID""];
        NumIDLabels = Convert.ToInt16(IDLabels[0]);

        if (NumNameLabels == NumIDLabels)
         {
          ContTrain = NumNameLabels;
          string LoadFaces;
          // Converting the master image to a bitmap
          Image imageFromDB;
          Bitmap imageChangedToBitmap;
          // Normalizing it to grayscale
          Image&lt;Gray, Byte&gt; normalizedMasterImage;

          for (int tf = 1; tf &lt; NumNameLabels + 1; tf++)
           {
              imageFromDB = ReadImageFromDB();
              //image loaded from the database is converted in to Bitmap and then 
              //convert the bitmap image in to Image&lt;Gray,byte&gt; for input to 
              //EigenObjectRecognizer(,,,) 
             imageChangedToBitmap = new Bitmap(imageFromDB);
              normalizedMasterImage = new Image&lt;Gray, Byte&gt;(imageChangedToBitmap);
              LoadFaces = String.Format(""face{0}.bmp"", tf);
              trainingImages.Add(normalizedMasterImage);
                //trainingImages.Add(new Image&lt;Gray, byte&gt;());
              NameLables.Add(NameLabels[tf]);
              IDLables.Add(IDLabels[tf]);
              rowNumber = rowNumber + 1;
            }
         }
       else
           MessageBox.Show(""There's a conflict between Name labels and id labels"");
        }
      catch (Exception e)
        {
   MessageBox.Show(""Nothing in the database, please add at least a
               face.Train the database"",""Triained faces load"",MessageBoxButtons.OK,
               MessageBoxIcon.Exclamation);
        }

    }
</code></pre>

<p>I am only getting the message in the catch when the the form loads even if there are faces saved in the database. I have used EigenObjectRecognizer and i will post the code if necessary.</p>
",2013-05-09 13:59:16,2018-03-26 18:28:41,C# - Emgu Cv - Face Recognition- Loading training sets of Faces saved to Access database as a binary in to EigenObjectRecognizer for Face recognition,<ms-access><database-connection><emgucv><face-recognition><training-data>,,,CC BY-SA 3.0,False,False,True,False,False
8980,15512417,2013-03-19 23:24:21,,"<p>I am just starting to explore OpenCV and the EmguCV .NET wrappers for it and need some general direction from folks who understand the big picture of its capabilities and perhaps those who have tackled a task similar to what I need to accomplish.</p>

<p>I will have a series of still photos and in each image will appear an object or nothing.  The objects are pieces of metal hardware (bolts) and will be laying on their side with their length parallel to the top/bottom of the image (i.e., the picture is taken from above).  If there is an object, it will be one of about 100 discrete types of bolt, some with very similar though not identical features and dimensions.  For example, they will all be mostly rectangular in profile but will vary in length and width (diameter) and can have heads that are either hexagonal or round (which will be seen in profile as rectangular or as the minor segment of a circle, respectively) or will have conical heads for countersunk applications.   An illustration of the types of parts I'm talking about (this is just to show the types of parts - my images are photos of single parts):</p>

<p><a href=""https://i.stack.imgur.com/yilQy.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yilQy.gif"" alt=""An Illustration""></a><br>
<sub>(source: <a href=""http://donsnotes.com/home_garden/images/bolts-type.gif"" rel=""nofollow noreferrer"">donsnotes.com</a>)</sub>  </p>

<p>I need to classify them such that all sizes and types are differentiated.  A 1-3/8"" bolt should classify as different from a 1-1/2"" bolt even if they are the same diameter and have the same head type.  The minimum length difference between sizes will be 1/8"", not the standard 1/16"".</p>

<p>If it matters, I have good control of the following:</p>

<ul>
<li>Lighting (but back-lighting isn't going to be practical) </li>
<li>The appearance of the background (useful for background subtraction maybe?) </li>
<li>The distance from the camera to the object (identical objects will
always appear to be the same size in the images)</li>
<li>Generally, the position of the bolt - it will laying horizontally on
its side, parallel with the top/bottom edges of the image
frame.  I cannot control whether its head is to the left or right in
the image.</li>
</ul>

<p>Unfortunately I cannot find any online papers or articles that directly address what I need to do - but lots that illustrate simpler tasks like finding a colored ball or finding rectangles.  I can't find anything on identifying and classifying each of a large(ish) number of different but similar shapes.   I do have two of the suggested OpenCV books and while they are great, they don't seem to address this issue.</p>

<p>I have found pretty clean Canny edges on my sample images but there is lots of noise in the interior of the part due to lighting.  This makes finding clean Hough line segments kind of spotty. </p>

<p>I'm not certain if I should try to pare down the list of possible matches using absolute dimensions calculated by measuring across the Canny edges - then use something more robust like a cascade classifier...?  Or what.</p>

<p>I'm really just looking for someone's opinion on a general strategy or a point in the right direction...  </p>

<p>Can anyone give me something to start trying?  I'm really at a loss.</p>

<p>Thanks!</p>
",2019-09-01 07:09:36,2019-09-01 07:09:36,Parts Recognition / Classification with OpenCV,<opencv><image-processing><computer-vision><emgucv>,,,CC BY-SA 4.0,True,False,True,False,False
9152,16476050,2013-05-10 05:56:03,,"<p>I'm looking for an elegant way to perform pixel-wise summation and subtraction in EmguCV.</p>

<p>I'm trying to calculate the Haar-like features of an image.
For a one-dimensional situation, it's done by multiplying the vector [x x x x x x x x] by the following vector element-wise:</p>

<pre><code>[ 1 -1  1 -1  1 -1  1 -1]
[ 1  1 -1 -1  1  1 -1 -1]
[ 1  1  1  1 -1 -1 -1 -1]
</code></pre>

<p>So I need to add or subtract the element pixels of an image.</p>

<p>Say,</p>

<pre><code>Bgr sum = new Bgr();
sum = sum + img[0,0] - img[0,1] + img[0,2] - img[0,3];
</code></pre>

<p>Obviously this won't compile since there's no operator ""+"" in class Bgr. I've to make a new Bgr by specifying each of the B, G, R value, which is ugly.</p>

<p>Any idea on performing elegant pixel-wise operation?</p>

<p><a href=""https://stackoverflow.com/questions/16435976/how-to-add-pixels-in-emgucv/16440450#16440450"">Previous Thread</a></p>
",2017-05-23 11:54:35,2013-05-13 15:18:33,Pixel-wise summation and subtraction in EmguCV,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
9215,10683431,2012-05-21 10:19:13,,"<p>Till now I have been able to create an application where the Kinect sensor is at one place. I have used speech recognition EmguCV (open cv) and Aforge.NET to help me process an image, learn and recognize objects. It all works fine but there is always scope for improvement and I am posing some problems: [Ignore the first three I want the answer for the fourth]</p>

<ol>
<li><p>The frame rate is horrible. Its like 5 fps even though it should be like 30 fps. (This is WITHOUT all the processing) My application is running fine, it gets color as well as depth frames from the camera and displays it. Still the frame rate is bad. The samples run awesome, around 25 fps. Even though I ran the exact same code from the samples it wont just budge. :-( [There is no need for code, please tell me the possible problems.]</p></li>
<li><p>I would like to create a little robot on which the kinect and my laptop will be mounted on. I tried using the Mindstorms Kit but the lowtorque motors dont do the trick. Please tell me how will I achieve this.</p></li>
<li><p>How do I supply power on board? I know that the Kinect uses 12 volts for the motor. But it gets that from an AC adapter. [I would not like to cut my cable and replace it with a 12 volt battery]</p></li>
<li><p>The biggest question: How in this world will it navigate. I have done A* and flood-fill algorithms. I read <a href=""http://www.cs.washington.edu/ai/Mobile_Robotics/rgbd-workshop-2011/camera_ready/cunha-rgbd11-localization.pdf"" rel=""nofollow"">this</a> paper like a thousand times and I got nothing. I have the navigation algorithm in my mind but how on earth will it localize itself? [It should not use GPS or any kind of other sensors, just its eyes i.e. the Kinect]</p></li>
</ol>

<p>Helping me will be Awesome. I am a newbie so please don't expect me to know everything. I have been up on the internet for 2 weeks with no luck.</p>

<p>Thanks A lot!</p>
",,2012-05-21 10:52:39,Robotic Navigation using Kinect,<artificial-intelligence><kinect><emgucv><lego>,,,CC BY-SA 3.0,False,False,True,False,False
9236,13602998,2012-11-28 10:33:29,,"<p>After the construction of the recognizer:<br/></p>

<pre><code>recognizer = new EigenObjectRecognizer(trainingImages, labels, 
             eigenDistanceThreshold, ref termCrit);
</code></pre>

<p>is it possible to add new images like:</p>

<pre><code>recognizer.Add(image, label)
</code></pre>

<p>? </p>

<p>Having thousands of trained faces it's not a solution to rebuild (retrain) the recognizer after each new face.</p>
",2012-11-28 10:35:58,2013-03-31 07:30:33,Add new training face to EMGU CV recognizer (C#),<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
9246,9693792,2012-03-13 23:29:54,,"<p>i am completly new in openCV(EmguCV) and face comparision.
I am trying to implement algorithm which will compare two photos against eigenfaces vector and get me a distance (i know how to get distance of image from training set of images)</p>

<p>I am using  Cambridge_FaceDB.zip - db of .pgm images of some faces.
I need to load them as training images and use in:</p>

<pre><code>EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
                           trainingImages.ToArray(),
                           labels.ToArray(),
                           3000,
                           ref termCrit); 
</code></pre>

<p>trainingImages have to be type of Image but i cant create Image like trainingImages.Add(new Image(""test.pgm""));</p>

<p>So I would like to know, how to work with .pgm format and how to add images of this file into training set.
Could someone explain me if i am doing something and why? :)</p>

<p>I am using C# wrapper EmguCV, thanks a lot</p>
",,2012-04-29 08:38:38,Create eigenfaces vector from database,<c#><emgucv><image-recognition><eigenvector>,,,CC BY-SA 3.0,True,False,True,False,False
9260,12641372,2012-09-28 13:53:18,,"<p>I started working with EmguCV, but I stumble upon a performance issue trying to convert from the grabber's bitmap to a Texture2D</p>

<p>This is my code</p>

<pre><code>    private void FrameGrabber()
    {
        NamePersons.Add("""");
        currentFrame = grabber.QueryFrame().Resize(320, 240, INTER.CV_INTER_CUBIC);
        gray = currentFrame.Convert&lt;Gray, Byte&gt;();
        MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(face, 1.2, 10, HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(20, 20));
        foreach (MCvAvgComp f in facesDetected[0])
        {
            t = t + 1;
            result = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
            currentFrame.Draw(f.rect, new Bgr(System.Drawing.Color.Red), 2);
            if (trainingImages.ToArray().Length != 0)
            {
                MCvTermCriteria termCrit = new MCvTermCriteria(ContTrain, 0.001);
                EigenObjectRecognizer recognizer = new EigenObjectRecognizer(trainingImages.ToArray(), labels.ToArray(), 2500, ref termCrit);
                name = recognizer.Recognize(result);
                currentFrame.Draw(name, ref font, new System.Drawing.Point(f.rect.X - 2, f.rect.Y - 2), new Bgr(System.Drawing.Color.LightGreen));
            }
            NamePersons[t - 1] = name;
            NamePersons.Add("""");
        }
        t = 0;
        for (int nnn = 0; nnn &lt; facesDetected[0].Length; nnn++)
            names = names + NamePersons[nnn] + "", "";
        names = """";
        NamePersons.Clear();

        Bitmap b = currentFrame.ToBitmap();

        //slow
        using (MemoryStream s = new MemoryStream())
        {
            b.Save(s, System.Drawing.Imaging.ImageFormat.Png);
            s.Seek(0, SeekOrigin.Begin); //must do this, or error is thrown in next line
            frame = Texture2D.FromStream(GraphicsDevice, s);
        }

        ////second option but image is bluish and still slow
        //GraphicsDevice.Textures[0] = null;
        //if (frame == null || b.Width != frame.Width || b.Height != frame.Height)
        //    frame = new Texture2D(GraphicsDevice, b.Width, b.Height);
        //BitmapData bData = b.LockBits(new System.Drawing.Rectangle(new System.Drawing.Point(), b.Size), ImageLockMode.ReadOnly, PixelFormat.Format32bppRgb);
        //int byteCount = bData.Stride * b.Height;
        //byte[] bmpBytes = new byte[byteCount];
        //Marshal.Copy(bData.Scan0, bmpBytes, 0, byteCount);
        //b.UnlockBits(bData);
        //frame.SetData(bmpBytes);
    }

    protected override void LoadContent()
    {
        spriteBatch = new SpriteBatch(GraphicsDevice);
        grabber = new Capture();
    }

    protected override void UnloadContent()
    {
        grabber.Dispose();
    }

    protected override void Update(GameTime gameTime)
    {
        FrameGrabber();            
        base.Update(gameTime);
    }

    protected override void Draw(GameTime gameTime)
    {
        GraphicsDevice.Clear(Microsoft.Xna.Framework.Color.LightGray);
        spriteBatch.Begin();
        if (frame !=null)
            spriteBatch.Draw(frame, new Microsoft.Xna.Framework.Rectangle(0, 0, ScreenWidth, ScreenHeight), Microsoft.Xna.Framework.Color.White);
        spriteBatch.End();
        base.Draw(gameTime);
    }
</code></pre>

<p>I searched the web for documentation but with no luck.</p>
",2012-09-29 06:58:31,2012-09-29 06:58:31,"XNA, EmguCV and perfomance issue with webcam",<xna-4.0><emgucv><face-detection>,,,CC BY-SA 3.0,False,False,True,False,False
9314,13611008,2012-11-28 17:31:38,,"<p>I am new in Emgu CV . I need a matrix array to store pixel values of gray images. Is it possible to declare a matrix array .</p>

<p>I code like this for matrix array But is gives ""Error""</p>

<pre><code>public Matrix&lt;Double&gt;[] Myimgmatrix = new Matrix&lt;Double&gt;[5](100,80);    
</code></pre>

<p>Error:""Method name expected""
Any one Please Help.</p>
",,2013-04-13 11:50:14,How to Declare Matrix array in Emgu CV?,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
9320,16488081,2013-05-10 17:51:15,,"<p>I am working on hand detection, tracking and recognition and i need to calculate the First Principal Component. I am using C# and EmguCV. My experience with PCA is way limited and I've been looking for documentation, tutorials and code on the matter and can't get one suitable...</p>

<p>The only thing I need to do is get the principal orientation of the hand (as i understand it, it's the first principal component).</p>

<p>Can someone help me understand how to calculate it from a binary image?</p>

<p>Thanks in advance.</p>
",,2013-06-30 11:31:27,EmguCV First Principal Component,<c#><pca><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
9369,9707468,2012-03-14 18:00:18,,"<p>I have a Kinect WPF Application that takes images from the Kinect, does some feature detection using EmguCV (A C# opencv wrapper) and displays the output on the using a WPF image.</p>

<p>I have had this working before, but the application now refuses to update the screen image when the imagesource is written to, but I have not changed the way it works.</p>

<p>the Image(called video) is written to as such:</p>

<p><code>video.Source = bitmapsource;</code></p>

<p>in the colorframeready event handler.</p>

<p>This works fine until I introduce some opencv code before the imagesource is written to. It does not matter what source is used, so I don't think it is a conflict there. I have narrowed down the offending EmguCV code to this line:</p>

<p><code>RecentKeyPoints = surfCPU.DetectKeyPointsRaw(ImageRecent, null);</code></p>

<p>which jumps straight into the opencv code. It is worth noting that:</p>

<ul>
<li>ImageRecent has completely different origins to the bitmapsource updating the screen.</li>
<li>Reading video.Source returns the bitmapsource, so it seems to be writing correctly, just not updating the screen.</li>
</ul>

<p>Let me know if you want any more information...</p>

<pre><code>void nui_ColorFrameReady(object sender, ColorImageFrameReadyEventArgs e)
{
    // Checks for a recent Depth Image
    if (!TrackingReady) return;

    // Stores image
    using (ColorImageFrame colorImageFrame = e.OpenColorImageFrame())
    {
        if (colorImageFrame != null)
        {
            if (FeatureTracker.ColourImageRecent == null)
                //allocate the first time
                FeatureTracker.ColourImageRecent = new byte[colorImageFrame.PixelDataLength];

            colorImageFrame.CopyPixelDataTo(FeatureTracker.ColourImageRecent);
        }
        else return;
    }

    FeatureTracker.FeatureDetect(nui);

    //video.Source = FeatureTracker.ColourImageRecent.ToBitmapSource();
    video.Source = ((Bitmap)Bitmap.FromFile(""test1.png"")).ToBitmapSource();

    TrackingReady = false;
}

public Bitmap FeatureDetect(KinectSensor nui)
{
    byte[] ColourClone = new byte[ColourImageRecent.Length];
    Array.Copy(ColourImageRecent, ColourClone, ColourImageRecent.Length);
    Bitmap test = (Bitmap)Bitmap.FromFile(""test1.png"");

    test.RotateFlip(RotateFlipType.RotateNoneFlipY);

    Image&lt;Gray, Byte&gt; ImageRecent = new Image&lt;Gray, byte&gt;(test);
    SURFDetector surfCPU = new SURFDetector(2000, false);
    VectorOfKeyPoint RecentKeyPoints;
    Matrix&lt;int&gt; indices;
    Matrix&lt;float&gt; dist;
    Matrix&lt;byte&gt; mask;
    bool MatchFailed = false;

    // extract SURF features from the object image
    RecentKeyPoints = surfCPU.DetectKeyPointsRaw(ImageRecent, null);
    //Matrix&lt;float&gt; RecentDescriptors = surfCPU.ComputeDescriptorsRaw(ImageRecent, null, RecentKeyPoints);
    //MKeyPoint[] RecentPoints = RecentKeyPoints.ToArray();

    // don't feature detect on first attempt, just store image details for next attempt
    #region
    /*
    if (KeyPointsOld == null)
    {
        KeyPointsOld = RecentKeyPoints;
        PointsOld = RecentPoints;
        DescriptorsOld = RecentDescriptors;
        return ImageRecent.ToBitmap();
    }
    */
    #endregion

    // Attempt to match points to their nearest neighbour
    #region
    /*
    BruteForceMatcher SURFmatcher = new BruteForceMatcher(BruteForceMatcher.DistanceType.L2F32);
    SURFmatcher.Add(RecentDescriptors);
    int k = 5;
    indices = new Matrix&lt;int&gt;(DescriptorsOld.Rows, k);
    dist = new Matrix&lt;float&gt;(DescriptorsOld.Rows, k);
    */

    // Match features, provide the top k matches
    //SURFmatcher.KnnMatch(DescriptorsOld, indices, dist, k, null);

    // Create mask and set to allow all features
    //mask = new Matrix&lt;byte&gt;(dist.Rows, 1);
    //mask.SetValue(255);
    #endregion

    //Features2DTracker.VoteForUniqueness(dist, 0.8, mask);

    // Check number of good maches and for error and end matching if true
    #region
    //int nonZeroCount = CvInvoke.cvCountNonZero(mask);
    //if (nonZeroCount &lt; 5) MatchFailed = true;
    /*
    try
    {
        nonZeroCount = Features2DTracker.VoteForSizeAndOrientation(RecentKeyPoints, KeyPointsOld, indices, mask, 1.5, 20);
    }
    catch (SystemException)
    {
        MatchFailed = true;
    }
    if (nonZeroCount &lt; 5) MatchFailed = true;

    if (MatchFailed)
    {
        return ImageRecent.ToBitmap();
    }
    */
    #endregion

    //DepthMapColourCoordsRecent = CreateDepthMap(nui, DepthImageRecent);
    //PointDist[] FeatureDistances = DistanceToFeature(indices, mask, RecentPoints);
    //Image&lt;Rgb,Byte&gt; rgbimage = ImageRecent.Convert&lt;Rgb, Byte&gt;();
    //rgbimage = DrawPoints(FeatureDistances, rgbimage);

    // Store recent image data for next feature detect.
    //KeyPointsOld = RecentKeyPoints;
    //PointsOld = RecentPoints;
    //DescriptorsOld = RecentDescriptors;

    //CreateDepthMap(nui, iva);
    //rgbimage = CreateDepthImage(DepthMapColourCoordsRecent, rgbimage);

    // Convert image back to a bitmap
    count++;
    //Bitmap bitmap3 = rgbimage.ToBitmap();
    //bitmapstore = bitmap3;

    //bitmap3.Save(""test"" + count.ToString() + "".png"");

    return null;
}
</code></pre>
",2012-08-23 15:12:54,2012-08-23 15:12:54,Image doesn't update when written to.. weird goings on,<c#><wpf><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
9396,16497649,2013-05-11 13:33:44,,"<p>I want to create an eye-tracker using EmguCV. I came across the problem of calculating the face position, which I need to get in order to correctly estimate the gaze of a person. I wanted to use the Haar cascade to detect face and then, using the optical flow method, track some face features. The problem is what to do next. </p>

<p>How can I project tracked 2D points to the 3D to extract the rotation matrix? I heard about the POSIT algorithm but to use it I need a 3D face model. Is there a method to create a face model automatically during the initialization of a program?</p>
",2013-05-11 20:50:30,2014-02-02 20:45:04,Eye tracking - estimating face position,<c#><opencv><emgucv><opticalflow><eye-tracking>,,,CC BY-SA 3.0,True,False,True,False,False
9406,16499682,2013-05-11 17:10:20,,"<p>I was working on Face Recognition and when i run the code it stops execution at the point where EigenObjectRecognizer is initialized and exits the program with out any error.Have any one else faced the same problem ever before?If you need additional codes i can post more.  I have seen my code working until the point where the recognizer trained with data in the training set</p>

<pre><code>     EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
                       trainingImages.ToArray(),
                        NameLabless.ToArray(),
                        3000,
                       ref termCrit);
                       name = recognizer.Recognize(ExtFaces[faceNo]).ToString();
</code></pre>

<p>The code that i have used to load from the training set is </p>

<pre><code>    public FaceRecognizer()
    {
        InitializeComponent();

        try
        {
            ContTrain = ContTrain + 1;
            //Load previous trained and labels for each image from the database Here
            string NameLabelsinfo = File.ReadAllText(Application.StartupPath +
                          ""/TrainedFaces/TrainedNameLables.txt"");
            string[] NameLabels = NameLabelsinfo.Split('%');
            NumNameLabels = Convert.ToInt16(NameLabels[0]);
            string IDLabelsinfo = File.ReadAllText(Application.StartupPath +
                ""/TrainedFaces/TrainedNameLables.txt"");
            string[] IDLables = IDLabelsinfo.Split('%');
            NumIDLabels = Convert.ToInt16(IDLables[0]);


            if (NumNameLabels == NumIDLabels)
            {
                ContTrain = NumNameLabels;
                string LoadFaces;
                // Converting the master image to a bitmap

                for (int tf = 1; tf &lt; NumNameLabels + 1; tf++)
                {
                    LoadFaces = String.Format(""face{0}.bmp"", tf);
                    trainingImages.Add(new Image&lt;Gray, byte&gt;(String.Format(""
                    {0}/TrainedFaces/{1}"", Application.StartupPath,
                            LoadFaces)));
                    IDLabless.Add(IDLables[tf]);
                    NameLabless.Add(NameLabels[tf]);

                }
            }
        }
        catch (Exception e)
        {
            //MessageBox.Show(e.ToString());
            MessageBox.Show(""Nothing in binary database, please add at least a
            face(Simply train the prototype with the Add
                   Face Button)."", ""Triained faces load"", MessageBoxButtons.OK,
                            MessageBoxIcon.Exclamation);
        }
    }
</code></pre>

<p>And the face recognizer function is as follows</p>

<pre><code>      private void RecognizeFaces()
    {
        //detect faces from the gray-scale image and store into an array of type
         //            'var',i.e 'MCvAvgComp[]'

        Image&lt;Gray, byte&gt; grayframe = GetGrayframe();
        //Assign user-defined Values to parameter variables:
        MinNeighbors = int.Parse(comboBoxMinNeigh.Text);  // the 3rd parameter
        WindowsSize = int.Parse(textBoxWinSiz.Text);   // the 5th parameter
        ScaleIncreaseRate = Double.Parse(comboBoxScIncRte.Text); //the 2nd parameter



        var faces = grayframe.DetectHaarCascade(haar, ScaleIncreaseRate, MinNeighbors,
                                HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                                new Size(WindowsSize, WindowsSize))[0];

        if (faces.Length &gt; 0)
        {
            Bitmap ExtractedFace;   //empty
            ExtFaces = new Image&lt;Gray, byte&gt;[faces.Length];

            faceNo = 0;

            foreach (var face in faces)
            {
                // ImageFrame.Draw(face.rect, new Bgr(Color.Green), 3);
                t = t + 1;
                //set the size of the empty box(ExtractedFace) which will later
                 //        contain the detected face
                ExtractedFace = new Bitmap(face.rect.Width, face.rect.Height);

                ExtFaces[faceNo] = new Image&lt;Gray, byte&gt;(ExtractedFace);
                    //= newExtractedImage;
                ExtFaces[faceNo] = ExtFaces[faceNo].Resize(100, 100,
                    Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
                //TermCriteria for face recognition with numbers of trained images
                 //             like maxIteration
                MCvTermCriteria termCrit = new MCvTermCriteria(ContTrain, 0.001);
                if (trainingImages.ToArray().Length != 0)
                {
                    //Eigen face recognizer
                    EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
                     trainingImages.ToArray(),
                    NameLabless.ToArray(),
                     3000,
                     ref termCrit);
                     name = recognizer.Recognize(ExtFaces[faceNo]).ToString();
                    stringOutput[faceNo] = name;
                }
                faceNo++;
            }

            pbExtractedFaces.Image = ExtFaces[0].ToBitmap(); //draw the face detected
                     in the 0th (gray) channel with blue
                                color
            t = 0;

            if (stringOutput[0] == null)
                {
                    label1.Text = ""Unknown"";
                    label9.Text = """";
                }
                //Draw the label for each face detected and recognized
            else
             {
                   label1.Text = ""Known"";
                   label9.Text = stringOutput[0];

             }
        }
        if (faceNo == 0)
            {
                MessageBox.Show(""No face detected"");
            }
        else
        {
            btnNextRec.Enabled = true;
            btnPreviousRec.Enabled = true;
        }
    }
</code></pre>

<p>When this face recognizer method is called as an event it works until the point where EigenObjectRecognizer is trained and then it stops working(Exit running) and the program stops running at all.</p>

<p>I will look forward for your response,Thanks
Sisay</p>
",2013-05-12 08:06:35,2013-11-24 07:40:44,C# - Emgu CV - Face Recognition code stops execution at EigenObjectRecognizer and exit without error,<c#><emgucv><face-recognition><eigen>,,,CC BY-SA 3.0,False,False,True,False,False
9432,14580948,2013-01-29 10:38:01,,"<p>I am a beginner in Windows Phone app development. My goal is to create a simple augmented reality application which will include shape recognition (ex. hand or face). Additionally I would like to draw 3D objects on screen and place them in reality. The question is what is the best way to start development? Especially which toolkits do You advise to use? My current idea is to detect motion using Motion Class built in WP-SDK and use EmguCV to dectect and recognise shapes. And which library should I use to draw shapes (Direct3d or XNA) ? Is it a good way to start? I am confused if EmguCV is available on Windows Phone platform at all?  </p>

<p>Additional info:<br>
- platform will be WP7.5 or WP8</p>
",,2013-11-25 19:35:50,Window Phone augmented reality and shape recognition,<windows-phone><augmented-reality><emgucv><shape-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
9443,9714371,2012-03-15 05:17:51,,"<p>I am trying to use emgu wrapper >
it contain Surf Algorithm,so i wanna know how to access surftracker class 
what's it's namespace </p>
",,2012-03-15 08:49:32,how to access SURFTracker Class?,<surf><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
9496,15555232,2013-03-21 18:23:13,,"<p>Can anyone tell me about Matrix Reshape(int newChannels, int newRows) function. what is means the argument newChannels ?  My code below</p>

<pre><code>Matrix&lt;Double&gt; A = new Matrix&lt;Double&gt;(4, 4);
Matrix&lt;Double&gt; reshapeMatrix;
reshapeMatrix = A.Reshape(1, 16);
</code></pre>

<p>this code works correctly . but </p>

<pre><code> reshapeMatrix = A.Reshape(2, 8);
</code></pre>

<p>this code run sucessfully but reshapeMatrix size is not correct and I cannot use reshapeMatrix data. </p>

<p>Can anyone explain why this happen? How i use reshape() function for any size matrix?</p>
",2013-03-21 21:35:57,2013-03-28 15:38:06,Matrix.Reshape() function in Emgu CV,<matrix><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
9497,15555615,2013-03-21 18:42:16,,"<p>I am converting Python OpenCV code to Emgu.
In Python, function <code>findContours</code> can return <code>hierarchy</code></p>

<blockquote>
  <p>hierarchy – Optional output vector, containing information about the image topology. It has as many elements as the number of contours. For each i-th contour contours[i] , the elements hierarchy[i][0] , hiearchy[i][1] , hiearchy[i][2] , and hiearchy[i][3] are set to 0-based indices in contours of the next and previous contours at the same hierarchical level, the first child contour and the parent contour, respectively. If for the contour i there are no next, previous, parent, or nested contours, the corresponding elements of hierarchy[i] will be negative.</p>
</blockquote>

<p>Unfortunately in Emgu I can't not return such array for <code>findContours</code> function.Is there any equivalent for this?</p>
",2013-03-21 18:48:57,2013-04-11 14:27:05,equivalent of hierarchy in emgu,<opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
9510,16508664,2013-05-12 15:00:02,,"<p>I made a c# project with emgu CV in x64. It does a template-match. However I now realize i need it to work on x86 systems. When i change this in the build settings i get this error:</p>

<p>An unhandled exception of type 'System.TypeInitializationException' occurred in Emgu.CV.dll
Additional information: The type initializer for 'Emgu.CV.CvInvoke' threw an exception.</p>

<p>I break it and the problem is with this line: </p>

<pre><code>Image&lt;Bgr, byte&gt; template = new Image&lt;Bgr, byte&gt;(imagetofind);
</code></pre>

<p>I have no idea why. (it works perfectly on x64).</p>

<p>P.S i have all dll's set up correctly for x64, do i need to replace them with x86 dll's?</p>
",,2013-05-12 15:24:59,How can i get my emgu function to work on x86?,<c#><x86><64-bit><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
9519,10709892,2012-05-22 20:44:51,,"<p>I am trying to locate dependencies of each EmguCv dll using a decompiler. However I don't want to miss anything because those OpenCv dlls maybe calling each other inside external calls.</p>

<p>Is there a list somewhere? I have tried EmguCV forums but I couldn't get an answer.</p>
",,2012-05-22 21:03:25,List of all needed OpenCV dlls by each EmguCV dll,<opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
9569,16512362,2013-05-12 21:45:13,,"<p>I was working on Face Recognition project. After training the database and calling EigenObjectRecognizer, the result is a black image with unrecognized label.When the code runs, it looks like the following <a href=""http://www.mediafire.com/view/?ewns4iqvd51adsc"" rel=""nofollow"">http://www.mediafire.com/view/?ewns4iqvd51adsc</a> .And as shown in the picture the detected and supposed to be recognized and extracted face in the image box is totally black. And the input image for recognition is exactly the same as the one the database is trained with.So why it has kept giving Unknown or Unrecognized result.
Part of the code looks</p>

<p><strong>Images from the training set loaded as</strong></p>

<pre><code>    public FaceRecognizer()
    {
        InitializeComponent();

        //Load faces from the dataset
        try
        {

           ContTrain = ContTrain + 1;
            //Load previous trained and labels for each image from the database Here
            string NameLabelsinfo = File.ReadAllText(Application.StartupPath +
         ""/TrainedFaces/TrainedNameLables.txt"");
            string[] NameLabels = NameLabelsinfo.Split('%');
            NumNameLabels = Convert.ToInt16(NameLabels[0]);
            string IDLabelsinfo = File.ReadAllText(Application.StartupPath +
        ""/TrainedFaces/TrainedNameLables.txt"");
            string[] IDLables = IDLabelsinfo.Split('%');
            NumIDLabels = Convert.ToInt16(IDLables[0]);


            if (NumNameLabels == NumIDLabels)
            {
                ContTrain = NumNameLabels;
                string LoadFaces;
                // Converting the master image to a bitmap

                for (int tf = 1; tf &lt; NumNameLabels + 1; tf++)
                {
                    LoadFaces = String.Format(""face{0}.bmp"", tf);
                    trainingImages.Add(new Image&lt;Gray, byte&gt;(String.Format(""
       {0}/TrainedFaces/{1}"", Application.StartupPath, LoadFaces)));
                    IDLabless.Add(IDLables[tf]);
                    NameLabless.Add(NameLabels[tf]);

                }
            }
        }
        catch (Exception e)
        {
             //Returns the following message if nothing saved in the training set
            MessageBox.Show(""Nothing in binary database, please add at least a
              face(Simply train the prototype with the Add Face Button)."", ""Triained
                 faces load"",MessageBoxButtons.OK, MessageBoxIcon.Exclamation);
        }
    }
</code></pre>

<p><strong>The face recognizer method looks like</strong></p>

<pre><code>      private void RecognizeFaces()
             {
        //detect faces from the gray-scale image and store into an array of type
         //    'var',i.e 'MCvAvgComp[]'
             Image&lt;Gray, byte&gt; grayframe = GetGrayframe();
              stringOutput.Add("""");
           //Assign user-defined Values to parameter variables:
             MinNeighbors = int.Parse(comboBoxMinNeigh.Text);  // the 3rd parameter
            WindowsSize = int.Parse(textBoxWinSiz.Text);   // the 5th parameter
            ScaleIncreaseRate = Double.Parse(comboBoxScIncRte.Text); //the 2nd 
                                                                      //parameter
             //Detect faces from an image and save it to var i.t MCvAcgComp[][]
           var faces = grayframe.DetectHaarCascade(haar, ScaleIncreaseRate,
                                MinNeighbors,
                                HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                                new Size(WindowsSize, WindowsSize))[0];

        if (faces.Length &gt; 0 &amp;&amp; trainingImages.ToArray().Length != 0)
        {
            Bitmap ExtractedFace;   //empty
            ExtFaces = new Image&lt;Gray, byte&gt;[faces.Length];
            faceNo = 0;
            foreach (var face in faces)
            {
                // ImageFrame.Draw(face.rect, new Bgr(Color.Green), 3);
                //set the size of the empty box(ExtractedFace) which will later
            //contain the detected face
                ExtractedFace = new Bitmap(face.rect.Width, face.rect.Height);

                ExtFaces[faceNo] = new Image&lt;Gray, byte&gt;(ExtractedFace); 
                ExtFaces[faceNo] = ExtFaces[faceNo].Resize(100, 100,
                  Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
                //TermCriteria for face recognition with numbers of trained images
                //    like maxIteration
                MCvTermCriteria termCrit = new MCvTermCriteria(ContTrain, 0.001);

                    //Eigen face recognizer
                        EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
                         trainingImages.ToArray(),
                         NameLabless.ToArray(),
                         700,
                         ref termCrit);
               stringOutput[faceNo] = recognizer.Recognize(ExtFaces[faceNo]);
               stringOutput.Add("""");
               faceNo++;
            }

            pbExtractedFaces.Image = ExtFaces[0].ToBitmap(); //draw the face detected
                  // in the 0th (gray) channel with blue color

            if (stringOutput[0] == """")
                {
                    label1.Text = ""Unknown"";
                    label9.Text = """";
                }
                //Draw the label for each face detected and recognized
            else
             {
                    //string[] label = stringOutput[faceNo].Split(',');
                    label1.Text = ""Known"";
                   // for (int i = 0; i &lt; 2; i++)
                    //{
                    label9.Text = stringOutput[0];
                        //label7.Text = label[1];
                    //}
             }
        }
        if (faceNo == 0)
            {
                MessageBox.Show(""No face detected"");
            }
        else
        {
            btnNextRec.Enabled = true;
            btnPreviousRec.Enabled = true;
        }
    }
</code></pre>

<p><strong>The training set is trained with detected faces as follows</strong></p>

<pre><code>           private void saveFaceToDB_Click(object sender, EventArgs e)
            {
               abd = (Bitmap) pbExtractedFaces.Image;
               TrainedFaces = new Image&lt;Gray, byte&gt;(abd);
               trainingImages.Add(TrainedFaces);
              NameLabless.Add(StudentName.Text);
               IDLabless.Add(StudentID.Text);

               //Write the number of trained faces in a file text for further load
              File.WriteAllText(Application.StartupPath + ""/TrainedFaces
              /TrainedNameLables.txt"", trainingImages.ToArray().Length + ""%"");
              File.WriteAllText(Application.StartupPath + ""/TrainedFaces
               /TrainedIDLables.txt"", trainingImages.ToArray().Length + ""%"");

              //Write the labels of trained faces in a file text for further load
              for (int i = 1; i &lt; trainingImages.ToArray().Length + 1; i++)
                {
                 trainingImages.ToArray()[i - 1].Save(String.Format(""{0}/TrainedFaces
                   /face{1}.bmp"", Application.StartupPath, i));
                  File.AppendAllText(Application.StartupPath + ""/TrainedFaces
             /TrainedIDLables.txt"", NameLabless.ToArray()[i - 1] + ""%"");
              File.AppendAllText(Application.StartupPath + ""/TrainedFaces
             /TrainedNameLables.txt"", IDLabless.ToArray()[i - 1] + ""%"");

            }

          MessageBox.Show(StudentName.Text + ""´s face detected and added :)"", ""Training
              OK"", MessageBoxButtons.OK, MessageBoxIcon.Information);
          }
</code></pre>

<p>Thanks</p>
",2013-05-19 09:13:25,2015-03-14 06:36:49,Face Recognition code using emgu cv and C# and it returns a black image and unknown/unrecognized label all time,<c#><opencv><image-processing><emgucv><face-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
9619,16517272,2013-05-13 07:58:25,,"<p>I need the element-wise square of a matrix. In Matlab I find this code:
if <code>A</code> is matrix then <code>A.^2</code> calculates the element wise square of the matrix. Is there any function in Emgu Cv that does the same?</p>

<p>Actually I need standard deviation of a matrix. If there a function of computing standard deviation of method for computing standard deviation then it will more helpful for me.</p>
",2013-12-17 10:00:36,2015-10-30 06:48:45,Element-wise square of a matrix in EMGU CV,<emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
9642,10721207,2012-05-23 13:41:20,,"<p>I am currently trying to develop a system that tracks people in a queue using EmguCV (OpenCV Wrapper). I started by running and understanting the VideoSurveilance example that's in Emgu package I downloaded. Here is my code based on the example:</p>

<pre><code>    private static void processVideo(string fileName)
    {
        Capture capture = new Capture(fileName);
        MCvFont font = new MCvFont(Emgu.CV.CvEnum.FONT.CV_FONT_HERSHEY_SIMPLEX, 
            1.0, 1.0);
        BlobTrackerAuto&lt;Bgr&gt; tracker = new BlobTrackerAuto&lt;Bgr&gt;();

        //I'm using a class that I implemented for foreground segmentation
        MyForegroundExtractor fgExtractor = new MyForegroundExtractor();

        Image&lt;Bgr, Byte&gt; frame = vVideo.QueryFrame();
        fgExtractor.initialize(frame);

        while (frame != null)
        {
            Image&lt;Gray, Byte&gt; foreground = fgExtractor.getForegroundImg(frame);
            tracker.Process(frame, foreground);

            foreach (MCvBlob blob in tracker)
            {
                if (isPersonSize(blob))
                {
                    frame.Draw((Rectangle)blob, new Bgr(0, 0, 255), 3);
                    frame.Draw(blob.ID.ToString(), ref font, 
                        Point.Round(blob.Center), new Bgr(255.0, 255.0, 255.0));
                }
            }
            CvInvoke.cvShowImage(""window"", frame);
            CvInvoke.cvWaitKey(1);

            frame = capture.QueryFrame();
        }
    }
</code></pre>

<p>The above code is meant to process each frame of an AVI Video, and show the processed frame with red rectangles around each person in scene. I didn't like the results I was getting using the <code>IBGFGDetector&lt;Bgr&gt;</code> class that is used in VideoSurveilance example, so I am trying to use my own foreground detector, using Emgu's functions such as CvInvoke.cvRunningAvg(), CvInvoke.cvAbsDiff(), CvInvoke.cvThreshold() and cvErode/cvDilate(). I have a few issues:</p>

<ol>
<li>The video starts with a few people already in the scene. I am not getting the blobs corresponding to the people that are in the scene when the video starts.</li>
<li>Sometimes I ""lose"" a person for a few frames: I had the red rectangle drawn around a person for several seconds/frames and it disappears and after a while is drawn again with a different ID.</li>
<li>As you can see from the sample code, I check if the blob may be a person checking its height and width (isPersonSize() method), and draw the red rectangle only in the ones that pass in the test. How can I remove the ones that are not person sized?</li>
<li>I want to measure the time a person stays in the scene. What's the best way to know when a blob disappeared? Should I store the IDs of the blobs that I think correspond to people in an array and at each loop check if each one is still there using <code>tracker.GetBlobByID()</code>?</li>
<li><p>I think I am getting better results if I don't process every frame in the loop. I added a counter variable and an if-statement to process at every 3 frames:</p>

<pre><code>if (i % 3 == 0)
    tracker.Process(frame, foreground);
</code></pre></li>
</ol>

<p>I added the if-statement because the program execution was really slow. But when I did that, I was able to track people that I wasn't able before.</p>

<p>To summarize, I would really appreciate if someone that is more used to OpenCV/EmguCV helped me by saying if it is a good approach to track people using BlobTrackerAuto, and by helping me with the issues above. I get the feeling that I am not taking advantage of the tools EmguCV can provide me.</p>
",,2012-05-23 13:41:20,Using BlobTrackerAuto to track people in computer vision application,<opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
9658,14596429,2013-01-30 03:56:06,,"<p>I need to obtain a lock in two different threads in order to access a Bitmap (which is populated from a webcam) in EmguCv.
I have a ""GetFrame"" functions that queries the camera and places what it returns into a .NET Bitmap. I have two threads which need to access this Bitmap, one needs to write to the Bitmap and assign the Bitmap to a picture box, and the other needs to read the Bitmap, convert it to an Image object and assign that to an EMGU ImageBox.
I first lock on an arbitrary Object, then I do my operations. The code is as follows (_Camera.LiveFrame is the Bitmap):</p>

<p>Writing/Reading Thread:</p>

<pre><code>while (_CaptureThreadRunning)
{
   lock (_Camera)
   { 
      // _Camera.GetFrame writes to the Bitmap
      if (_VideoPlaying &amp;&amp; _Camera.GetFrame(500)) 
           pbLiveFeed.Invalidate();
    }
}
_Camera.CloseCamera(true);
_CaptureExitEvent.Set();           // Set to signal captureThread has finished
</code></pre>

<p>Reading/ImageBox Thread:</p>

<pre><code>while (_ProcessThreadRunning)
{
   lock (_Camera)
   {
      //  _Camera.LiveFrame is the Bitmap
      procImage = new Image&lt;Bgr, int&gt;((Bitmap)_Camera.LiveFrame.Clone());          
      procImage.Draw(new Rectangle(10,20,20,15),new Bgr(Color.LightGreen), 5);

      ibProcessed.Image = procImage;
      ibProcessed.Invalidate();
    }
}
_ProcessExitEvent.Set();
</code></pre>

<p>This runs fine most of the time but every now and then I get a ""Object is in use elsewhere"" error when I try to Clone() the Bitmap. Is this not the proper way to lock? I don't see why this would cause a problem.</p>

<p>ps. My threads can no longer exit gracefully either. My .Set() calls outside of my loops are never called. I am guessing the threads are deadlocked?</p>
",2013-01-30 04:02:08,2013-02-06 15:05:05,Trouble with locking an image between threads,<c#><locking><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
9693,14601491,2013-01-30 10:16:19,,"<p>I'm working on some image processing problem where I have to detect areas with a specific pattern. There is absolutely no other usable informationen in the image than the pattern - no color, no way for template matching, horrible changing lighting conditions, shadows and so on. Using the sobel operator I get a relative constistent image.</p>

<p><a href=""http://i.tinyuploads.com/QtI4qF.jpg"" rel=""nofollow"">Here is an example</a> </p>

<p>What approach could I use to detect these crossed areas? There is a lot of other stuff on the image, so blob detection based on intensity is no option.</p>

<p>Any help or hint would be great! Thanks!</p>
",,2013-01-30 12:46:36,Detect patterned areas using openCV,<image-processing><opencv><emgucv><opencvsharp>,,,CC BY-SA 3.0,True,False,True,False,False
9708,13642718,2012-11-30 09:53:09,,"<p>I am trying to detect an object using emgu SURF and ORB features with BruteForce matcher however, getting very wrong results as can be seen in the following pictures. The following two pictures are the results of surf and orb features matching respectively, with threshold 0.8 and k=2.
Can anyone please advise me how to fix this problem or it is just not possible to detect the object(drill) in this scene image? I am using the example SURF code in the emgu.I have tried many different values for threshold, k but never get acceptable results. Which part of the code could possibly contain errors; keypoint detection, feature extraction or matching? I have tried different keypoint detection and feature extraction methods like, sift, freak and brief but matching results are never better than the following. Please guide me.</p>

<p>Thanks</p>

<p><img src=""https://i.stack.imgur.com/yfCeK.jpg"" alt=""SURF feature matching""></p>

<p><img src=""https://i.stack.imgur.com/4uFPj.jpg"" alt=""ORB feature matching""></p>
",,2012-11-30 09:53:09,Emgu SURF feature matching issue,<c#><surf><emgucv><orb>,,,CC BY-SA 3.0,False,False,True,False,False
9739,9740724,2012-03-16 16:10:20,,"<p>I have been working with the SURF feature detection example from the EMGU CV library.</p>

<p>So far it's working amazingly;  I can detect matching objects between 2 given images but I have run into a problem in regards to when the images do not match.</p>

<p>I was looking for support from the forums but they are down from where I am. Would anyone know which parameters determine whether an image is a match or not. When I test with 2 images that are not a match, the code still proceeds as if there was a match and draws a blurred thick red line on a random location of the image even when there is not a match. </p>

<p>If there is no match I would wish to break from the code and not proceed further.</p>

<p>Appendix:</p>

<pre><code>      static void Run()
      {
          Image&lt;Gray, Byte&gt; modelImage = new Image&lt;Gray, byte&gt;(""HatersGonnaHate.png"");
         Image&lt;Gray, Byte&gt; observedImage = new Image&lt;Gray, byte&gt;(""box_in_scene.png"");
         Stopwatch watch;
         HomographyMatrix homography = null;

         SURFDetector surfCPU = new SURFDetector(500, false);

         VectorOfKeyPoint modelKeyPoints;
         VectorOfKeyPoint observedKeyPoints;
         Matrix&lt;int&gt; indices;
         Matrix&lt;float&gt; dist;
         Matrix&lt;byte&gt; mask;

         if (GpuInvoke.HasCuda)
         {
            GpuSURFDetector surfGPU = new GpuSURFDetector(surfCPU.SURFParams, 0.01f);
            using (GpuImage&lt;Gray, Byte&gt; gpuModelImage = new GpuImage&lt;Gray, byte&gt;(modelImage))
            //extract features from the object image
            using (GpuMat&lt;float&gt; gpuModelKeyPoints = surfGPU.DetectKeyPointsRaw(gpuModelImage, null))
            using (GpuMat&lt;float&gt; gpuModelDescriptors = surfGPU.ComputeDescriptorsRaw(gpuModelImage, null, gpuModelKeyPoints))
            using (GpuBruteForceMatcher matcher = new GpuBruteForceMatcher(GpuBruteForceMatcher.DistanceType.L2))
            {
               modelKeyPoints = new VectorOfKeyPoint();
               surfGPU.DownloadKeypoints(gpuModelKeyPoints, modelKeyPoints);
               watch = Stopwatch.StartNew();

               // extract features from the observed image
               using (GpuImage&lt;Gray, Byte&gt; gpuObservedImage = new GpuImage&lt;Gray, byte&gt;(observedImage))
               using (GpuMat&lt;float&gt; gpuObservedKeyPoints = surfGPU.DetectKeyPointsRaw(gpuObservedImage, null))
               using (GpuMat&lt;float&gt; gpuObservedDescriptors = surfGPU.ComputeDescriptorsRaw(gpuObservedImage, null, gpuObservedKeyPoints))
               using (GpuMat&lt;int&gt; gpuMatchIndices = new GpuMat&lt;int&gt;(gpuObservedDescriptors.Size.Height, 2, 1))
               using (GpuMat&lt;float&gt; gpuMatchDist = new GpuMat&lt;float&gt;(gpuMatchIndices.Size, 1))
               {
                  observedKeyPoints = new VectorOfKeyPoint();
                  surfGPU.DownloadKeypoints(gpuObservedKeyPoints, observedKeyPoints);

                  matcher.KnnMatch(gpuObservedDescriptors, gpuModelDescriptors, gpuMatchIndices, gpuMatchDist, 2, null);

                  indices = new Matrix&lt;int&gt;(gpuMatchIndices.Size);
                  dist = new Matrix&lt;float&gt;(indices.Size);
                  gpuMatchIndices.Download(indices);
                  gpuMatchDist.Download(dist);

                  mask = new Matrix&lt;byte&gt;(dist.Rows, 1);

                  mask.SetValue(255);

                  Features2DTracker.VoteForUniqueness(dist, 0.8, mask);

                  int nonZeroCount = CvInvoke.cvCountNonZero(mask);
                  if (nonZeroCount &gt;= 4)
                  {
                     nonZeroCount = Features2DTracker.VoteForSizeAndOrientation(modelKeyPoints, observedKeyPoints, indices, mask, 1.5, 20);
                     if (nonZeroCount &gt;= 4)
                        homography = Features2DTracker.GetHomographyMatrixFromMatchedFeatures(modelKeyPoints, observedKeyPoints, indices, mask, 3);
                  }

                  watch.Stop();
               }
            }
         }
         else
         {
            //extract features from the object image
            modelKeyPoints = surfCPU.DetectKeyPointsRaw(modelImage, null);
            //MKeyPoint[] kpts = modelKeyPoints.ToArray();
            Matrix&lt;float&gt; modelDescriptors = surfCPU.ComputeDescriptorsRaw(modelImage, null, modelKeyPoints);

            watch = Stopwatch.StartNew();

            // extract features from the observed image
            observedKeyPoints = surfCPU.DetectKeyPointsRaw(observedImage, null);
            Matrix&lt;float&gt; observedDescriptors = surfCPU.ComputeDescriptorsRaw(observedImage, null, observedKeyPoints);

            BruteForceMatcher matcher = new BruteForceMatcher(BruteForceMatcher.DistanceType.L2F32);
            matcher.Add(modelDescriptors);
            int k = 2;
            indices = new Matrix&lt;int&gt;(observedDescriptors.Rows, k);
            dist = new Matrix&lt;float&gt;(observedDescriptors.Rows, k);
            matcher.KnnMatch(observedDescriptors, indices, dist, k, null);

            mask = new Matrix&lt;byte&gt;(dist.Rows, 1);

            mask.SetValue(255);

            Features2DTracker.VoteForUniqueness(dist, 0.8, mask);

            int nonZeroCount = CvInvoke.cvCountNonZero(mask);
            if (nonZeroCount &gt;= 4)
            {
               nonZeroCount = Features2DTracker.VoteForSizeAndOrientation(modelKeyPoints, observedKeyPoints, indices, mask, 1.5, 20);
               if (nonZeroCount &gt;= 4)
                  homography = Features2DTracker.GetHomographyMatrixFromMatchedFeatures(modelKeyPoints, observedKeyPoints, indices, mask, 3);
            }

            watch.Stop();
         }

         //Draw the matched keypoints
        Image&lt;Bgr, Byte&gt; result = Features2DTracker.DrawMatches(modelImage, modelKeyPoints, observedImage, observedKeyPoints,
            indices, new Bgr(255, 255, 255), new Bgr(255, 255, 255), mask, Features2DTracker.KeypointDrawType.NOT_DRAW_SINGLE_POINTS);

         #region draw the projected region on the image
         if (homography != null)
         {  //draw a rectangle along the projected model
            Rectangle rect = modelImage.ROI;
            PointF[] pts = new PointF[] { 
               new PointF(rect.Left, rect.Bottom),
               new PointF(rect.Right, rect.Bottom),
               new PointF(rect.Right, rect.Top),
               new PointF(rect.Left, rect.Top)};
            homography.ProjectPoints(pts);

            result.DrawPolyline(Array.ConvertAll&lt;PointF, Point&gt;(pts, Point.Round), true, new Bgr(Color.Red), 5);
         }
         #endregion

         ImageViewer.Show(result, String.Format(""Matched using {0} in {1} milliseconds"", GpuInvoke.HasCuda ? ""GPU"" : ""CPU"", watch.ElapsedMilliseconds));
      }


   }

}
</code></pre>

<p>`</p>
",2012-03-16 16:22:56,2013-12-06 02:48:03,EMGU CV SURF image match,<c#><image-processing><emgucv><surf><object-detection>,,,CC BY-SA 3.0,False,False,True,False,False
9741,13647537,2012-11-30 14:53:50,,"<p>Does Emgu Cv offer any kind of support for working with 16 bit grayscale images? (working with c#).
If it doesn't is there any kind of easy-ish workaround for that?
thanks in advance</p>

<p>On <a href=""http://www.emgu.com/wiki/index.php/Working_with_Images#Depth_and_Color_as_Generic_Parameter"" rel=""nofollow"">here</a> it says ""Any attempts to use a 16-bit floating point or non-grayscale image as a mask will results a compile time error!"" and I'm a bit confused as to what it means.</p>

<p>My confusion comes from the following experiment:</p>

<p>I did try to open and save an image, however, I noticed that after opening and saving an image, the resolution went <strong>from 16bpp to 8bpp</strong> (tiff) - but no error/exception. I'm not sure whether that comes from a lack of support from the library or I'm just not saving the image properly using image.Save()</p>

<p>The code to open the image is:</p>

<pre><code>my_Image = new Image&lt;Gray, ushort&gt;(Openfile.FileName);
</code></pre>

<p>and to save the image:</p>

<pre><code>my_Image.Save(fName); 
</code></pre>
",2012-12-03 16:16:09,2012-12-03 16:16:09,Emgu Cv and 16 bit grayscale images,<c#><compatibility><emgucv><grayscale>,,,CC BY-SA 3.0,False,False,True,False,False
9756,11703264,2012-07-28 17:38:57,,"<p>Here's my relevant code:</p>

<p>In the form's load method:</p>

<pre><code>Application.Idle += new EventHandler(delegate(object s, EventArgs ea)
{
    if (!recording)
    {
        currentFrame = getFrame();
        ib.Image = currentFrame;
    }
    else
    {
        ib.Image = recFrame;
    }
    });
</code></pre>

<p>On a button press (ib is an ImageBox on the form):</p>

<pre><code>Measurements measurements = new Measurements();
String name = txtSampleName.Text;
ib.Image = recFrame;
stopwatch.Start();
recording = true;
while ((count = (int)Math.Floor(stopwatch.ElapsedMilliseconds/(double)1000)) &lt; finalTime)
{
    currentFrame = getFrame();        
    Measurement currentMeasurement = new Measurement(name, currentFrame);
    measurements.add(currentMeasurement);
}
recording = false;
stopwatch.Stop();
measurements.write(txtDirectory.Text);
</code></pre>

<p>The problem is that the frame isn't actually updating. currentFrame takes the value of whatever the frame was before the loop starts. recFrame doesn't become visible in ib.Image - ib just hangs for the duration of the loop - and not filled with recFrame as it should be). currentMeasurement is added to the measurements list as it should be, but the frame in it is not the current frame from the camera. Here's a summary of the code from getFrame(), which is either not returning what is from the webcam at the current time, or is and currentFrame is taking its old value regardless:</p>

<pre><code>private Image&lt;Bgr, Byte&gt; getFrame()
{
    // get the frame
    Image&lt;Bgr, Byte&gt; frame = capture.QueryFrame();

    // draw some stuff on top of the frame
    // ...

    // return
    return frame;
}
</code></pre>

<p>Do I need to add some sort of delay to wait for something to complete? I've tried putting in a Thread.Sleep and it doesn't help anything. I don't understand what the problem is, so haven't been able to look for a sensible solution. When I later export the frames in measurements to an AVI file, all the frames have the value of currentFrame before the loop started, and do not change.</p>

<p>Any ideas?</p>

<p>With many thanks,</p>

<p>Froskoy.</p>

<p>EDIT: Using currentFrame.Copy() on the line currentMeasurement = new Measurement(name,currentFrame) meant that the current captured frame was actually put into the list and later written to the AVI file. I don't understand why though? Also, recFrame is still not displayed in ib, so I don't understand what is going on here either?</p>
",2012-07-28 17:47:18,2012-07-28 17:48:34,Frames not updating in loop,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
9761,12686797,2012-10-02 08:23:14,,"<p>I am using EmguCV and OpenNi in C# to retrieve the pointcloud from the Kinect. The code I am using is below:</p>

<pre>
<code>
IntPtr img = CvInvoke.cvRetrieveFrame(kCapture.Ptr, 1);
                if (img != IntPtr.Zero)
                {
                    MIplImage iplImage = (MIplImage)Marshal.PtrToStructure(img, typeof(MIplImage));

                    MCvPoint3D32f[] points = new MCvPoint3D32f[iplImage.width * iplImage.height];

                    GCHandle handle = GCHandle.Alloc(points, GCHandleType.Pinned);
                    using (Matrix m = new Matrix(iplImage.height, iplImage.width, handle.AddrOfPinnedObject()))
                    {
                        CvInvoke.cvCopy(img, m, IntPtr.Zero);
                    }
                    handle.Free();

                }
</code>
</pre>

<p>I get an exception with the message ""OpenCV: src.channels() == dst.channels()"" when I am trying to perform the copy operation.</p>
",,2012-10-08 08:44:27,Cannot retrieve PointCloud using Kinect,<c#><opencv><kinect><openni>,,,CC BY-SA 3.0,True,False,True,False,False
9802,10731698,2012-05-24 05:35:31,,"<p>I'm trying to substract 1 image from another, somewhat like this:</p>

<pre><code>Image&lt;Gray, float&gt; result, secondImage;
Image&lt;Gray, byte&gt; firstImage;
result = firstImage - secondImage;
</code></pre>

<p>But it gives an error</p>

<pre><code>Operator '-' cannot be applied to operands of type 'Emgu.CV.Image&lt;Emgu.CV.Structure.Gray,byte&gt;' and 'Emgu.CV.Image&lt;Emgu.CV.Structure.Gray,float&gt;'
</code></pre>

<p>Maybe i need to convert firstImage into <code>Image&lt;Gray, float&gt;</code> type. But I don't know how to do it.</p>
",,2012-05-24 05:42:23,"How to convert Image<Gray, Byte> to Image<Gray, float>?",<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
9880,9751102,2012-03-17 15:13:40,,"<p>I am a newbie with this stuff so please bear with me :-)</p>

<p>I am creating a object <strong>recognition</strong> application which can Recognize objects. Frames are grabbed by a webcam and tracking and recognition is done in real-time.</p>

<p>I am a C#/VB.NET developer, and therefore I am using EmguCV OpenCV Wrapper.
I have tried SURF feature detector and it takes 5 seconds per frame!</p>

<p>Therefore I am trying to use FAST descriptor.</p>

<p>Can anybody give me sample code, say a function FAST(Byval modelImage, ByVal observedImage)
which will return the points of the object? Please. If not sample code please help me. The EMGUCV documentation is telling me nothing.</p>

<p>I appreciate your response. I am just a newbie. Please reply. </p>
",,2014-01-08 15:25:47,FAST Feature Detector/Descriptor EMGUCV/OpenCV,<.net><performance><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
9897,16541553,2013-05-14 11:05:20,,"<p>the result of 3d reprojection function is a matrix that has X,Y,Z of each pixel.</p>

<p>let's take the first element of this matrix points[0] which has: X= 414.580017 Y= -85.03029 Z= 10000.0</p>

<p>what is the unit here and where I can find this pixel in the image ? and why it is not like this X=0,Y=0,Z=10000.0!</p>

<pre><code>points = PointCollection.ReprojectImageTo3D(disparityMap, Q);
</code></pre>
",,2013-05-14 11:05:20,Stereo Calibration and 3d Reconstruction,<c#><opencv><computer-vision><emgucv><calibration>,,,CC BY-SA 3.0,True,False,True,False,False
9934,9758403,2012-03-18 12:45:50,,"<p>I recently shifted my project library from Emgu CV to OpenCVSharp. 
The code for flipping the image(using pictureBox) in Emgu CV was:</p>

<pre><code>Image&lt;Bgr,Byte&gt; f = _capture.QueryFrame().Flip(Emgu.CV.CvEnum.FLIP.HORIZONTAL)
</code></pre>

<p>I tried using the <code>Flip(CvArr dst, FlipMode flip_mode)</code> method in OpenCVSharp, but in vain.
I am no sure what to use for <code>dst</code>. </p>
",2012-03-18 13:43:00,2018-03-02 13:31:26,Flipping an image horizontally in OpenCVSharp,<c#><.net><opencv><emgucv><flip>,,,CC BY-SA 3.0,True,False,True,False,False
10009,16553889,2013-05-14 22:28:37,,"<p>I have some images like this where I need to find the central rectangle</p>

<p><img src=""https://i.stack.imgur.com/npHFV.png"" alt=""enter image description here""></p>

<p>Im using a variation of the EmguCV examples to find rectangles and came with this</p>

<pre><code>using (MemStorage storage = new MemStorage())
{ //allocate storage for contour approximation

    //Contour&lt;Point&gt; contours = gray.FindContours()
    Contour&lt;Point&gt; contours = gray.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
     Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST,
  storage);

    for (; contours != null; contours = contours.HNext)
    {
        Contour&lt;Point&gt; currentContour = contours.ApproxPoly(contours.Perimeter * 0.05, storage);
        //Seq&lt;Point&gt; currentContour = contours.GetConvexHull(Emgu.CV.CvEnum.ORIENTATION.CV_CLOCKWISE);

        if (contours.Area &gt; MinRectangleArea) //only consider contours with area greater than 20000
        {
            if (currentContour.Total == 4) //The contour has 4 vertices.
            {
                bool isRectangle = true;
                Point[] pts = currentContour.ToArray();
                LineSegment2D[] edges = PointCollection.PolyLine(pts, true);

                for (int i = 0; i &lt; edges.Length; i++)
                {
                    double angle = Math.Abs(edges[(i + 1) % edges.Length].GetExteriorAngleDegree(edges[i]));
                    if (angle &lt; 90 - RectangleAngleMargin  || angle &gt; RectangleAngleMargin + 90)
                    {
                        isRectangle = false;
                        break;
                    }
                }

                if (isRectangle)
                {
                    boxList.Add(currentContour.GetMinAreaRect());
                }
            }
        }
    }
</code></pre>

<p>}</p>

<p>And the result of executing that over those images sometimes finds this two rectangles:</p>

<p><img src=""https://i.stack.imgur.com/KNTcU.png"" alt=""enter image description here""></p>

<p>The orange rectangle is ok, thats what I need. But I dont want the blue. Sometimes the four vertex are in the border of the image, usually one of them is out. </p>

<p>Changing the RETR_TYPE of the FindContours function to CV_RETR_EXTERNAL, I only get the blue rectangle, so I wonder if there is an option of NOT getting the contours with external points.</p>

<p>The real image actually can have smaller rectangles inside the orange (or a line appears splitting the rectangle), so after that I´m selecting the bigger rectangle to be the one I want, but cant do it that way with that blue one.</p>
",2013-05-14 22:43:56,2013-05-15 14:02:55,Ignore external points when finding rectangles,<c#><opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10011,15602696,2013-03-24 19:04:35,,"<p>I'm doing a small experiment using fourier transform on emgu cv. My aim is to have the fourier transform of an image, then take the inverse fourier transform again, and check if the image shows up or not. mathematically, it should.</p>

<p>this is my code which i believe is correct</p>

<pre><code>Image&lt;Gray, float&gt; image = new Image&lt;Gray, float&gt;(""c://box1.png"");
IntPtr complexImage = CvInvoke.cvCreateImage(image.Size, Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_32F, 2);

CvInvoke.cvSetZero(complexImage);  // Initialize all elements to Zero
CvInvoke.cvSetImageCOI(complexImage, 1);
CvInvoke.cvCopy(image, complexImage, IntPtr.Zero);
CvInvoke.cvSetImageCOI(complexImage, 0);

Matrix&lt;float&gt; dft = new Matrix&lt;float&gt;(image.Rows, image.Cols, 2);
CvInvoke.cvDFT(complexImage, dft, Emgu.CV.CvEnum.CV_DXT.CV_DXT_FORWARD, 0);


Matrix&lt;float&gt; idft = new Matrix&lt;float&gt;(dft.Rows, dft.Cols, 2);
CvInvoke.cvDFT(dft, idft, Emgu.CV.CvEnum.CV_DXT.CV_DXT_INVERSE, 0);

IntPtr complexImage2 = CvInvoke.cvCreateImage(idft.Size, Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_8U, 2);

CvInvoke.cvShowImage(""picture"", idft);
System.Threading.Thread.Sleep(99999); // to wait and see the picture
</code></pre>

<p>I have two problems:</p>

<p>1- error : an error shows up saying "" OpenCV: Source image must have 1, 3 or 4 channels "" i believe its related about the IDFT, but I couldn't solve it</p>

<p>2- it still shows an output image, but unfortunately, its not the original image that was input. all what show is a plain grey image.</p>

<p>Thanks.</p>
",,2013-04-05 08:08:18,direct and inverse fourier transform in EMGU CV,<c#><transform><fft><emgucv><computer-vision>,,,CC BY-SA 3.0,True,False,True,False,False
10037,16555179,2013-05-15 01:06:28,,"<p>I'm getting ""An unhandled exception of type 'System.AccessViolationException'as given below in my code. The video file I have given is 91 MB of size and my RAM is 4 GB (OS - Windows 32 bit)</p>

<blockquote>
  <p>An unhandled exception of type 'System.AccessViolationException'
  occurred in Emgu.CV.dll</p>
  
  <p>Additional information: Attempted to read or write protected memory.
  This is often an indication that other memory is corrupt.</p>
</blockquote>

<pre><code> private static List&lt;Image&lt;Bgr, Byte&gt;&gt; GetVideoFrames(String Filename)
        {
            List&lt;Image&lt;Bgr, Byte&gt;&gt; image_array = new List&lt;Image&lt;Bgr, Byte&gt;&gt;();
            Capture _capture = new Capture(Filename);

            bool Reading = true;

            while (Reading)
            {
                Image&lt;Bgr, Byte&gt; frame = _capture.QueryFrame();
                if (frame != null)
                {
                    image_array.Add(frame.Copy());
                }
                else
                {
                    Reading = false;
                }
            }

            return image_array;
        }
</code></pre>

<p>Can this be an issue with the video file size? What can I do to fix this issue?</p>
",,2013-05-15 01:06:28,An unhandled exception of type 'System.AccessViolationException' EmguCV,<c#><opencv><computer-vision><video-capture><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10075,15611644,2013-03-25 09:36:57,,"<p>I'm doing a small experiment using fourier transform on emgu cv. My aim is to have the fourier transform of an image, then take the inverse fourier transform again, and check if the image shows up or not. mathematically, it should.</p>

<p>this is my code which i believe is correct</p>

<pre><code>Image&lt;Gray, float&gt; image = new Image&lt;Gray, float&gt;(""c://box1.png"");
IntPtr complexImage = CvInvoke.cvCreateImage(image.Size, Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_32F, 2);

CvInvoke.cvSetZero(complexImage);  // Initialize all elements to Zero
CvInvoke.cvSetImageCOI(complexImage, 1);
CvInvoke.cvCopy(image, complexImage, IntPtr.Zero);
CvInvoke.cvSetImageCOI(complexImage, 0);

Matrix&lt;float&gt; dft = new Matrix&lt;float&gt;(image.Rows, image.Cols, 2);
CvInvoke.cvDFT(complexImage, dft, Emgu.CV.CvEnum.CV_DXT.CV_DXT_FORWARD, 0);


Matrix&lt;float&gt; idft = new Matrix&lt;float&gt;(dft.Rows, dft.Cols, 2);
CvInvoke.cvDFT(dft, idft, Emgu.CV.CvEnum.CV_DXT.CV_DXT_INVERSE, 0);

IntPtr complexImage2 = CvInvoke.cvCreateImage(idft.Size, Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_8U, 2);

CvInvoke.cvShowImage(""picture"", idft);
System.Threading.Thread.Sleep(99999); // to wait and see the picture
</code></pre>

<p>I have two problems:</p>

<p>1- error : an error shows up saying "" OpenCV: Source image must have 1, 3 or 4 channels "" i believe its related about the IDFT, but I couldn't solve it</p>

<p>2- it still shows an output image, but unfortunately, its not the original image that was input. all what show is a plain grey image.</p>

<p>Thanks.</p>
",,2014-02-04 01:52:29,Fourier transform in EMGU CV C#,<c#><transform><fft><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10076,14636615,2013-01-31 22:51:34,,"<p>How do I filter an image for red hue? I understand that red lies around zero between 330° and 30° (represented by 165 to 15 in OpenCV?). How can I use that range with the InRange method as there is an overflow at 360° (180 in OpenCV)? </p>
",,2013-04-24 14:48:30,Filter for red hue - emgucv/opencv,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10111,9772653,2012-03-19 15:10:26,,"<p>I try to fond out if tow objects - recorded by a Kinec touches or not. For that I define to kinds of shapes (handArea) and (DangerArea). For collision detection I have written the follwing code:</p>

<pre><code>private bool checkAreaViolation(List&lt;MCvBox2D&gt; DangerAreas, List&lt;MCvBox2D&gt; HandAreas)
{
    int zaehler;
    int ZaehlerDA;
    int Test;
    String TestS;
    Test = 0;
    ZaehlerDA= 0;
    foreach (MCvBox2D DangerBox in DangerAreas)
    {
        zaehler = 0;
        ZaehlerDA++;
        foreach (MCvBox2D HandBox in HandAreas)
        {   
            if(zaehler&lt;=HandAreas.Count-1)
                if (DangerAreas.Contains(HandAreas[zaehler])==true)
                    return true;

            PointF[] handVertices = HandBox.GetVertices();
            for (int i = 0; i &lt; handVertices.Length; i++)
            {
                if (PointInPolygon(handVertices[i], DangerBox.GetVertices()))
                {
                    return true;
                }
                zaehler++; 
            }
        }
    }
    return false;
}   
</code></pre>

<p>unfortunately the <code>if (DangerAreas.Contains(HandAreas[zaehler])==true)</code> doesn't work at all. </p>

<p>Does anybody knows why?</p>
",2012-03-19 15:50:46,2012-03-19 16:00:18,Contains() in visual studio doesnt work,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
10131,14641627,2013-02-01 07:31:27,,"<p>I am using Emgu.CV for some video processing frame by frame. After I grab a frame from the Capture instance I convert the Image to GpuImage to do some GPU processing.</p>

<p>Is it possible to directly display the GpuImage without going back to Image?</p>

<p>My UI is on WPF.</p>
",2013-02-07 08:22:31,2013-09-03 09:51:41,Emgu CV display GpuImage,<c#><wpf><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
10136,15614125,2013-03-25 11:44:54,,"<p>I am developing program for estimating height of human by using emgucv. I use fullbodydetection to detect human body. I use height of detected rectangular box as reference to estimating height. </p>

<p>My program is written as below. I used vb as my programing language</p>

<pre><code>    imgcolor = ImgCap.QueryFrame.Flip(Emgu.CV.CvEnum.FLIP.HORIZONTAL)
    imggray = imgcolor.Convert(Of Gray, Byte)()

    If TextBox1.Text = ""Human Detected"" Then
        TextBox2.Text = Height
    Else
        TextBox2.Text = 0


    End If

    TextBox1.Text = ""Human Detected""


    For Each body As MCvAvgComp In imggray.DetectHaarCascade( _
    objecttodetect, _
    1.2, _
    1, _
         CvEnum.HAAR_DETECTION_TYPE.FIND_BIGGEST_OBJECT, _
    New Size(50, 50))(0) 
        imgcolor.Draw(body.rect, New Bgr(Color.Blue), 3)


        Height = body.rect.Height
</code></pre>

<p>My questions are</p>

<p>1) When i debugged full body detection was not accurate. What should i do to make the detection result accurate?</p>

<p>2) the current size of my image box was 640,480. I wanted to reduce width to 320 but when i do that the view in the image box was halfed as well as my camer (means even if i cover the half of my camera lens it doesn''t affect to image in image box.</p>

<p>Thx in advance for your answer. Sorry for my poor english.</p>
",,2013-04-25 12:39:34,fullbody detection and estimating height of human by using emgucv,<vb.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
10273,14654547,2013-02-01 20:35:37,,"<p>I am performing blob extraction from video and using the blob's aspect ratio  to classify into humans or vehicles. Works pretty well since vehicles and humans have quite differentiated aspect ratios. </p>

<p>However this logic breaks down when a group of humans - say mother &amp; child holding hands, or a group walking closely, come by and the blob detection is one single blob.</p>

<p>I am wondering what the best approach to segmenting the image would be. Ideally I would also like to count the humans in the group.</p>

<p>Here are some thoughts: </p>

<ul>
<li>canny-> contour-> try the various size of the contours using Hu Moments shape matching?
The problem is I don't know how many humans are likely to be in this group</li>
<li>canny->contour> template matching using a template of a human contour. This might work given its general scale invariance.</li>
</ul>

<p>Any other thoughts on how I should approach this? Thanks for all suggestions and inputs/</p>
",,2013-02-01 20:35:37,OpenCV - detecting a shape in a shape collection (e.g. human in a group of humans),<image-processing><opencv><image-segmentation><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10298,16577887,2013-05-16 02:07:00,,"<p>i'm implementing Harries Corner detector using Emgucv
and i've converted the Code to C# 
using this link</p>

<p><a href=""http://docs.opencv.org/doc/tutorials/features2d/trackingmotion/harris_detector/harris_detector.html"" rel=""nofollow"">http://docs.opencv.org/doc/tutorials/features2d/trackingmotion/harris_detector/harris_detector.html</a>
So i want to access the coordinates of those corners or any information about this interest points
how to do this ?
Thanks</p>
",,2013-05-31 19:59:29,How to access the interest points in Harries Corner detection c#,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10334,12734824,2012-10-04 19:52:10,,"<p>I have the following code example:</p>

<pre><code>    //creating histogram using emgu cv c#
    //Create a grayscale image
      Image&lt;Gray, Byte&gt; img = new Image&lt;Gray, byte&gt;(400, 400);
    // Fill image with random values
      img.SetRandUniform(new MCvScalar(), new MCvScalar(255));
    // Create and initialize histogram
      DenseHistogram hist = new DenseHistogram(256, new RangeF(0.0f, 255.0f));
    // Histogram Computing
      hist.Calculate&lt;Byte&gt;(new Image&lt;Gray, byte&gt;[] { img }, true, null);
</code></pre>

<p>After the histogram has been calculated, I want to dislay the result in a chart control.</p>

<p>Can someone provide ideas/sample code for implementing this?  Thanks.</p>
",2013-08-31 17:56:02,2013-08-31 17:56:02,How to display EMGU histogram in chart control?,<.net><opencv><charts><histogram><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10409,16589713,2013-05-16 14:09:06,,"<p>I'm using EmguCV wrapper for OpenCV and I'm rectifing this shape:
<img src=""https://i.stack.imgur.com/lXaA4.png"" alt=""enter image description here""></p>

<p>with help of this code:</p>

<pre><code> public Image&lt;Bgr,byte&gt; Rectify()
    {
        try
        {
            Image&lt;Bgr, byte&gt; warped_Image = new Image&lt;Bgr, byte&gt;(input_Image.Width, input_Image.Height);

            MCvScalar s = new MCvScalar(0, 0, 0);

            PointF[] dsts = new PointF[4];
            dsts[0] = new PointF(0, 0);
            dsts[2] = new PointF(0, input_Image.Height);
            dsts[3] = new PointF(input_Image.Width, input_Image.Height);
            dsts[1] = new PointF(input_Image.Width, 0);

            HomographyMatrix mywarpmat = CameraCalibration.GetPerspectiveTransform(pnts, dsts);

            Image&lt;Bgr, byte&gt; warped_Image2 = warped_Image.WarpPerspective(mywarpmat, Emgu.CV.CvEnum.INTER.CV_INTER_NN, Emgu.CV.CvEnum.WARP.CV_WARP_FILL_OUTLIERS, new Bgr(0, 0, 0));

            CvInvoke.cvWarpPerspective(input_Image, warped_Image2, mywarpmat, (int)Emgu.CV.CvEnum.INTER.CV_INTER_LINEAR, s);

            Image&lt;Bgr, byte&gt; fixedImg = new Image&lt;Bgr, byte&gt;((int)warped_Image2.Width, (int)(warped_Image2.Width / aspectRatio));

            CvInvoke.cvResize(warped_Image2.Ptr, fixedImg.Ptr, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

            return fixedImg;
        }
</code></pre>

<p><strong>I get this result(rectified shape):</strong></p>

<p><img src=""https://i.stack.imgur.com/nNPpn.png"" alt=""enter image description here""></p>

<p>I know the corners coordinates both of the images (before and after rectification). 
Before the rectification I knew coordinates of the upper white line that inside the shape.
Any idea how can i get the coordinates of this white line after rectification?</p>

<p>Thank you in advance!</p>
",,2013-05-16 15:25:32,How to get coordinates of pixel after shape was rectified?,<.net><opencv><image-processing><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10437,14671356,2013-02-03 10:05:12,,"<p>It has been a month now while I am making a robot that would explore an unknown area and would make a 3D map using the Kinect sensor.</p>

<p>As I am a C# developer, I am using EmguCV as a wrapper to the OpenCV library to use its functions for the computer vision.</p>

<p>For a certain purpose I would like to use the ""estimateAffine3D"" function provided by OpenCV but it has not been added to EmguCV yet. Therefore I thought of using ""P/Invoke"" calls to use the function the way Emgu does it. I opened the source of Emgu, found the CvInvoke class and the calib3d class. In that I added the function like this:</p>

<pre><code>  [DllImport(OPENCV_CALIB3D_LIBRARY, CallingConvention = CvInvoke.CvCallingConvention)]
  [return: MarshalAs(CvInvoke.BoolToIntMarshalType)]
  public static extern bool cvEstimateAffine3D(
     IntPtr srcpt,
     IntPtr dstpt,
     out IntPtr outp,
     out IntPtr outliers,
     double ransacThreshold = 3.0f,
     double confidence = 0.99f);
</code></pre>

<p>(Sorry for any obvious errors: I am just a newbie at P/Invoking)</p>

<p>The thing won't work at all. If a put a breakpoint on it and visual studio hits it, it would't stop at the breakpoint, just continue!</p>

<p>Please help!
Any help would be appreciated...</p>

<p>Thanks!</p>

<p>Best</p>
",2013-02-03 10:32:47,2013-03-14 12:56:54,Modifying EmguCV to add a missing function using P/Invoke,<c#><opencv><pinvoke><kinect><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10440,15643762,2013-03-26 17:35:16,,"<p>I am trying to detect a pattern shown in two images. Hence I have been trying to use the SURF algorithim found in emgu.CV, but the ""SURFFeature"" example that is given gives me the following error:</p>

<pre><code>    An unhandled exception of type 'Emgu.CV.Util.CvException' occurred in Emgu.CV.dll

Additional information: OpenCV: norm == NORM_L1 || norm == NORM_L2 || norm == NORM_HAMMING
</code></pre>

<p>Any ideas how to fix this?</p>

<p>When I try the ""Hello World"" example and the face detection example, both seem to work fine.</p>

<p>Thanks for any advice!</p>

<p>Fouad. </p>

<p>PS: Emgu.CV can be downloaded from here: <a href=""http://www.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow"">http://www.emgu.com/wiki/index.php/Main_Page</a></p>
",,2013-09-19 00:55:22,Cannot get SURF example in EMGU.CV to work?,<emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10453,16594774,2013-05-16 18:27:05,,"<p>I trying using OpenCV for polygon detection.
After filtering and canny i have:
<img src=""https://i.stack.imgur.com/00gfL.png"" alt=""enter image description here""></p>

<p>How i can take polygon points and fix problems in green circles?
Thanks.</p>
",,2013-05-16 18:27:05,Extract polygons using OpenCV,<opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10479,16596915,2013-05-16 20:30:50,,"<p>I'm trying to follow the following tutorial but using WPF instead of Win Forms:</p>

<p><a href=""http://www.emgu.com/wiki/index.php/Setting_up_EMGU_C_Sharp#A_Basic_Program"" rel=""nofollow"">A Basic Program</a></p>

<p>WPF doesn't use <code>PictureBox</code>, instead it uses <code>Image</code>.</p>

<p>So here goes trying to load an <code>Image</code>.</p>

<p>XAML</p>

<pre><code>&lt;Image x:Name=""srcImg"" Width=""400"" Height=""300""&gt;&lt;/Image&gt;
</code></pre>

<p><strong>CS Attempt 1:</strong></p>

<pre><code>Image&lt;Bgr, Byte&gt; My_Image = new Image&lt;Bgr, byte&gt;(Openfile.FileName);
srcImg.Source = My_Image.ToBitmap();
</code></pre>

<p>Error Message</p>

<pre><code>Cannot implicitly convert type 'System.Drawing.Bitmap' 
to 'System.Windows.Media.ImageSource'
</code></pre>

<p><strong>CS Attempt 2:</strong></p>

<pre><code>Image&lt;Bgr, Byte&gt; My_Image = new Image&lt;Bgr, byte&gt;(Openfile.FileName);
srcImg.Source = new BitmapImage(My_Image);
</code></pre>

<p>Error Message</p>

<pre><code>Error   1   The best overloaded method match for 'System.Windows.Media.Imaging.BitmapImage.BitmapImage(System.Uri)' has some invalid arguments  
Error   2   Argument 1: cannot convert from 'Emgu.CV.Image&lt;Emgu.CV.Structure.Bgr,byte&gt;' to 'System.Uri' 
</code></pre>

<p>Any ideas what I am doing wrong?</p>
",2013-05-16 21:45:54,2020-09-22 12:37:43,EMGU with C# WPF,<c#><wpf><image><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10549,11778722,2012-08-02 13:42:32,,"<p>I'm creating Kinect mouse aplication. The idea is to hand/wrist kinect joint, as a source for cursor position, and finger detection to perform clicks, holds etc.</p>

<p>I got finger detection and palm gesture recognition working and here I found my blocker:</p>

<p>position of wrist/hand joint is changing when I make palm gesture, for instance when i change from open palm to fist.</p>

<p>Is there any workaround for this issue?</p>

<p>I'm using Kinect SDK 1.5 and EmguCV in this wpf aplication</p>
",2019-07-10 12:05:55,2019-07-10 12:05:55,Kinect wrist/hand joints position changing depending on palm size,<c#><.net><opencv><kinect><emgucv>,,,CC BY-SA 4.0,True,False,True,False,False
10555,16600167,2013-05-17 01:43:24,,"<p>I need to find corner positions of <code>CvBox2D</code> (or <code>MCvBox2D</code>) to map found contours on game object in XNA. I have a problem with correct translation of rotation angle. I thought that this is kind of basic operation but I kind find any  solution in Internet. </p>

<p>I tried:</p>

<pre><code>rotationAngle = box.angle * (180.0/ CV_PI);
angle = box.angle;
box.angle=rotationAngle;
alien.X = box.center.X - box.Width / 2;
alien.Y = box.center.Y - box.Height / 2;
alien.angle=angle;
</code></pre>

<p>but it wasn't translating it correctly.</p>

<p>Had someone ever tried to get corners on this kind of structure?</p>
",,2013-05-17 06:25:37,OpenCV: How to get corners of CvBox2D?,<opencv><xna><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10588,10805668,2012-05-29 19:47:22,,"<p>I have 4 points on the same plane (a flat square object) detected in the camera and I am trying to work out the pose of this square relative to the camera. </p>

<p>I am using the latest version of EmguCV ( <a href=""http://www.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow"">http://www.emgu.com/wiki/index.php/Main_Page</a> ) which is a C# wrapper for OpenCV. </p>

<p>I have seen POSIT ( <a href=""http://opencv.willowgarage.com/wiki/Posit"" rel=""nofollow"">http://opencv.willowgarage.com/wiki/Posit</a> ) but this will not work for coplanar points. I was wondering if there is anything that can solve coplanar pose estimation in OpenCV.</p>

<p>I have also seen solvePnp <a href=""http://opencv.willowgarage.com/documentation/cpp/camera_calibration_and_3d_reconstruction.html#cv-solvepnp"" rel=""nofollow"">http://opencv.willowgarage.com/documentation/cpp/camera_calibration_and_3d_reconstruction.html#cv-solvepnp</a>
 which I believe will do what I want, but I cannot seem to find this functionality in EmguCV.</p>

<p>Does anyone know how to solve this using EmguCV?</p>
",,2015-06-25 17:42:22,Solve coplanar points pose estimation using EmguCV (OpenCV),<c#><math><opencv><computer-vision>,,,CC BY-SA 3.0,True,False,True,False,False
10609,16607031,2013-05-17 10:40:29,,"<p>Using <a href=""http://i.imgur.com/tYRG6II.jpg"" rel=""nofollow"">this</a> image as a refernce I want to find the dirty spot at the bottom of <a href=""http://i.imgur.com/Joq1eX6.jpg"" rel=""nofollow"">this</a> image.</p>

<p>I was able to turn second image to the same scale and orientation and now trying fo find the spot using <a href=""http://docs.opencv.org/modules/core/doc/operations_on_arrays.html#absdiff"" rel=""nofollow""><code>absdiff</code></a> but since images are not perfectly matchet I have edges on the <a href=""http://i.imgur.com/nqzBIn4.jpg"" rel=""nofollow"">diff image</a>.</p>

<p>I'm thinking that instead of difference between pixels with same coordinates I need find minimal difference in an area like n by n pixels. So the question is: does OpenCV have something buitin for that and/or is there better solution to the problem?</p>

<p><strong>EDIT</strong>: Solution using <a href=""http://docs.opencv.org/modules/imgproc/doc/miscellaneous_transformations.html?highlight=threshold#threshold"" rel=""nofollow""><code>threshold</code></a> and <a href=""http://docs.opencv.org/modules/imgproc/doc/filtering.html?highlight=erode#erode"" rel=""nofollow""><code>erode</code></a>:</p>

<pre class=""lang-cs prettyprint-override""><code>public static Image&lt;Bgr, Byte&gt; Diff(Image&lt;Bgr, Byte&gt; image1,
                                    Image&lt;Bgr, byte&gt; image2,
                                    int erodeIterations=2)
{
    return Diff(image1, image2, new Bgr(50, 50, 50), erodeIterations);
}

public static Image&lt;Bgr, Byte&gt; Diff(Image&lt;Bgr, Byte&gt; image1, 
                                    Image&lt;Bgr, byte&gt; image2,
                                    Bgr thresholdColor,
                                    int erodeIterations)
{

    var diff = image1.AbsDiff(image2);
    diff = diff.ThresholdToZero(thresholdColor);
    diff = diff.Erode(erodeIterations);
    return diff;
}
</code></pre>
",2013-05-17 14:10:33,2013-05-17 14:10:33,Differences between two images,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10721,16612513,2013-05-17 15:14:31,,"<p>As you know OpenCV is very useful library that let you do amazing and powerful things in Computer vision. So I passed a good time to figure out how to use it in Unity3d, I had many problems, and searching in the Net, I have found several suggestions but not one worked for me.</p>

<ul>
<li>I’m using a Unity Pro 4.0</li>
<li>This version of Emgu CV (emgucv-windows-universal-gpu 2.4.9.1847)</li>
<li>My target for unity project is: windows and not web player</li>
</ul>
",2014-10-23 08:04:54,2014-10-27 11:55:20,OpenCV (EMGUCV wrapper) integration in Unity,<opencv><unity3d><emgucv><opencvsharp>,,,CC BY-SA 3.0,True,False,True,False,False
10747,16618624,2013-05-17 22:08:41,,"<p>How can I use Luxand API to get to work in visual studio 2010? I need to detect points of chin in a given face, can I do it with any other API? </p>

<p>I have tried this sample code:</p>

<pre><code> OpenFileDialog openFileDialog1 = new OpenFileDialog();
        if (openFileDialog1.ShowDialog() == DialogResult.OK)
        {
            try
            {
                FSDK.CImage image = new FSDK.CImage(openFileDialog1.FileName);

                // resize image to fit the window width
                double ratio = System.Math.Min((pictureBox1.Width + 0.4) / image.Width,
                    (pictureBox1.Height + 0.4) / image.Height);
                image = image.Resize(ratio);

                Image frameImage = image.ToCLRImage();
                Graphics gr = Graphics.FromImage(frameImage);

                FSDK.TFacePosition facePosition = image.DetectFace();
                if (0 == facePosition.w)
                    MessageBox.Show(""No faces detected"", ""Face Detection"");
                else
                {
                    int left = facePosition.xc - facePosition.w / 2;
                    int top = facePosition.yc - facePosition.w / 2;
                    gr.DrawRectangle(Pens.LightGreen, left, top, facePosition.w, facePosition.w);

                    FSDK.TPoint[] facialFeatures = image.DetectFacialFeaturesInRegion(ref facePosition);
                    int i = 0;
                    foreach (FSDK.TPoint point in facialFeatures)
                        gr.DrawEllipse((++i &gt; 2) ? Pens.LightGreen : Pens.Blue, point.x, point.y, 3, 3);

                    gr.Flush();
                }

                // display image
                pictureBox1.Image = frameImage;
                pictureBox1.Refresh();
            }
            catch (Exception ex)
            {
                MessageBox.Show(ex.Message, ""Exception"");
            }
        }
</code></pre>

<p>I get this error:
Could not load file or assembly 'xquisite.application.exe' or one of its dependencies. This assembly is built by a runtime newer than the currently loaded runtime and cannot be loaded.</p>
",2013-05-17 22:40:58,2013-07-12 18:03:43,Luxand API in Visual Studio 2010?,<c#><matlab><image-processing><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
10805,15673560,2013-03-28 03:06:34,,"<p>i'm trying to distinguish circular and rectangular objects from an image. i've labeled the round ones, using contours and the formula:
metric = 4*pie*contour.Area / (contour.perimeter^2)
since i'm almost done, so i wanted to knw the alternate of this formula, wich works for Rectangles..i'm bit weak in maths.. </p>

<p>Thanks</p>
",,2013-04-09 07:16:58,Rectangle - Emgu CV,<emgucv><rectangles>,,,CC BY-SA 3.0,False,False,True,False,False
10841,12783858,2012-10-08 14:32:13,,"<p>I have this array filled by numbers:</p>

<pre><code>Image&lt;Gray, Byte&gt; imgHue = channels[0];
</code></pre>

<p>I need somehow to get quantity of the number in array that are in the range of 100-105.</p>

<p>Any idea how to implement it?</p>
",,2012-10-08 14:40:42,How can I get quantity of numbers in array which are in some range?,<c#><.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10885,12787153,2012-10-08 18:08:42,,"<p>I need to put a smaller image within a larger image. the smaller picture should be centered in the larger picture. I'm working with C# and OpenCV, does anyone know how to do this?</p>
",2012-10-08 18:47:53,2015-07-03 22:21:31,Putting a smaller image within a larger image.,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10892,9838236,2012-03-23 11:13:18,,"<p>I wrote a code for selecting an area out of a Kinect picture (see below). This area should be defined as ROI of an object in the picture. The selection of the area works, but at the line </p>

<pre><code>Image&lt;Bgr, Byte&gt; roiImage = HandImage1.GetSubRect(roi).Convert&lt;Bgr, Byte&gt;();
</code></pre>

<p>the program throws an exception fruthermore the following line is not accepted by the compiler, whereby I dont know if that's depending of the right syntax of the line before.</p>

<p>Have anybody an idea what happens? </p>

<pre><code>private List&lt;MCvBox2D&gt; ProcessHandContoursCheck(Image&lt;Bgr, Byte&gt; IntoImage, Contour&lt;Point&gt; Contours, int MinArea, Point ClickedLocation, Image&lt;Gray, Byte&gt; HandImage1)
    {

        List&lt;Point&gt; centers1 = new List&lt;Point&gt;();                                    
        List&lt;MCvBox2D&gt; minRects1 = new List&lt;MCvBox2D&gt;();                             

        double GrenzeX;
        double GrenzeY;


        while (Contours != null)                                                    
        {

                MCvBox2D minRect = Contours.GetMinAreaRect();                       
                if (Contours.Area &gt;= MinArea)                                       
                {


                    centers1.Add(new Point((int)minRect.center.X, (int)minRect.center.Y)); minRects1.Add(minRect);                                               

                    if (!checkAreaExistanz(Contours.Area))
                           AreaVolumeHand.Add(Contours.Area);                                

                    if (ClickedLocation.X &gt; minRect.center.X)
                        GrenzeX = ClickedLocation.X - minRect.center.X;
                    else
                        GrenzeX = minRect.center.X - ClickedLocation.X;

                    if (ClickedLocation.Y &gt; minRect.center.Y)
                        GrenzeY = ClickedLocation.Y - minRect.center.Y;
                    else
                        GrenzeY = minRect.center.Y - ClickedLocation.Y;


                    DangerB.X= ((int)minRect.center.X - (int)GrenzeX);

                    DangerB.Y = (int)minRect.center.Y - (int)GrenzeY;


                    DangerB.Height= (int)minRect.size.Width + (int)GrenzeX;
                    DangerB.Width = (int)minRect.size.Height+ (int)GrenzeY;


                     Rectangle roi = new Rectangle((int)minRect.center.X - (int)GrenzeX, (int)minRect.center.Y - (int)(GrenzeY), (int)minRect.size.Height + (int)GrenzeY, (int)minRect.size.Width + (int)GrenzeX);




                    Image&lt;Bgr, Byte&gt; roiImage = HandImage1.GetSubRect(roi).Convert&lt;Bgr, Byte&gt;(); //&lt;-----------------------


                    IntoImage.Draw(roiImage, new Bgr(Color.Blue), 2);                            // &lt;----------------------- 

                    // Alternative???

                     Size estimatedSize = new Size((int)minRect.size.Width + (int)GrenzeX, (int)minRect.size.Height + (int)GrenzeY);

                     PointF estimatedCenter = new PointF((float)((int)minRect.center.X - (int)GrenzeX), (float)((int)minRect.center.Y - (int)GrenzeY));


                     Rectangle boostedROI = new MCvBox2D(estimatedCenter, estimatedSize, 0).MinAreaRect();


                     boostedROI.X += DangerB.X;
                     boostedROI.Y += DangerB.Y;

                     IntoImage.Draw(boostedROI, new Bgr(Color.Blue), 2);          


                }

            Contours = Contours.HNext;
        }
        return minRects1;
}
</code></pre>
",2016-12-09 21:28:26,2016-12-09 21:28:26,"GetSubRect(roi).Convert<Bgr, Byte>() throws an exception",<c#><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
10926,16633134,2013-05-19 09:19:59,,"<p>I was new to Emgu Cv and i was wondering if someone could let me know how i change Emgu.Cv.Image to System.Image?If there is a need for further explanation, let me know and i will do it.The language i am using is C#.</p>
",,2013-05-19 12:24:05,"How to Convert Emgu.Cv.Image<Gray,byte> to System.Image",<c#-4.0><image-processing><converter><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
10970,14715817,2013-02-05 19:54:41,,"<p>Can anybody guide me to some existing implementations of anisotropic diffusion, preferably the <strong>perona-malik diffusion</strong>?</p>
",,2020-08-15 01:40:39,Emgu CV - Anisotropic Diffusion,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
10987,9844184,2012-03-23 17:55:59,,"<p>I have a .NET Winform application and i need to show specific frames of a video file. Frames aren't necessarily in sequential order and are loaded when the user moves a slider, or when the application fires some events. I tried the following things:</p>

<ol>
<li><p><strong>Using EmguCV (OpenCV Wrapper)</strong>: The problem here is that when i use SetCaptureProperty (With CAP_PROP.CV_CAP_PROP_POS_FRAMES, AVI_RATIO or MSEC ) to sets capture's position, <strong>the position isn't seted correctly</strong> (I checked it using GetCaptureProperty next to the SetCaptureProperty instruction). So, the frame returned by QueryFrame isn't the needed frame.</p></li>
<li><p><strong>Using WPF MediaElement</strong> with Clock driven behavior: I can set the position of the video at the place that i need. The problem is that <strong>i don't know how get only one frame of the video sequence</strong>. By default, i have the Clock controller paused. When I set the position, If I call Clock.Controller.Resume(), then the video start playing from here. If I don't call Clock.Controller.Resume(), or if i call Clock.Controller.Resume() and then Clock.Controller.Pause() nothing is happening. </p></li>
<li><p>Im looking for <strong>another video library</strong> that can be used for accomplish this work, but i am not sure about what could be used. Any idea? </p></li>
</ol>

<p>Thanks a lot for all comunity members, not only for help with this answer, but for the very big help that you give me with my problems every day. Iam new, but i would try to return these helping others with your problems.</p>

<p><em>Sorry for my terrible english! (Im spanish speaker and english speaking is not my best quality :S)</em></p>
",2012-03-24 15:09:11,2016-05-23 11:00:12,Reading specific frames from video file with .NET (not necessarily in sequential order),<c#><.net><wpf><video><opencv>,,,CC BY-SA 3.0,True,False,True,False,False
11021,11814726,2012-08-05 07:37:09,,"<p>I need some samples / source code for a background subtraction algorithm for using with fixed backgrounds. The background I use is a fixed color background and unfortunately all the samples I've seen so far work for dynamic backgrounds.</p>

<p>Thank you.</p>
",,2012-08-05 17:15:59,Background subtraction in OpenCV / EmguCV with fixed background,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
11029,12798308,2012-10-09 10:43:29,,"<p><img src=""https://i.stack.imgur.com/Xy1z3.jpg"" alt=""original image""></p>

<p>You can see the lanes are askew. I want to make the lanes perpendicular.</p>

<p>I used <strong>Photoshop's perspective transformation function</strong>, got the result:</p>

<p><img src=""https://i.stack.imgur.com/YyEeD.jpg"" alt=""after perspective transformation""></p>

<p>Although the lanes are vertical now, the cars in the far end become large, the cars in the near end become so small. That is not what I　want.</p>

<p>I tried <strong>Photoshop's warp function</strong>. Photoshop gave me 8 control points and I finally got my ideal result.</p>

<p><img src=""https://i.stack.imgur.com/OWwxr.jpg"" alt=""What I want""></p>

<p>What is the name of that kind of transformation?</p>

<p>How to do the transformation programmatically? I'm using C# + EmguCV(OpenCV)</p>

<p>Thanks a lot.</p>
",,2012-10-09 16:37:23,How to transform the image?,<image-processing><opencv><transformation><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
11033,16641846,2013-05-20 02:49:10,,"<p>I want to perform an element-wise division between two images. I am using emgucv and tried the following but it doesn't perform element-wise division.</p>

<pre><code>Image&lt;Gray, double&gt; A = new Image&lt;Gray, double&gt;(634, 474);
Image&lt;Gray, double&gt; B = new Image&lt;Gray, double&gt;(634, 474);
Image&lt;Gray, double&gt; C = new Image&lt;Gray, double&gt;(634, 474);
CvInvoke.cvDiv(A.Ptr, B.Ptr, C.Ptr, 1);
</code></pre>

<p>How can I perform an element-wise division operation like the following:</p>

<pre><code>C[i,j]=A[i,j]/B[i,j];
</code></pre>
",2013-05-20 02:58:13,2013-05-20 11:42:11,Element-wise division between two images using emgu,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
11046,9850279,2012-03-24 08:38:43,,"<p>I want to draw a rectangle using a mouse on video frame (i.e picture box), just like when we select any files. The user will click mouse button select the area and will release the mouse button. Just like snipping or crop!</p>

<p>I m using emgucv!</p>
",,2018-01-30 10:02:43,How to draw a rectangle using a mouse in C# (emgucv)?,<c#><mouse><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
11048,9852124,2012-03-24 13:27:10,,"<p>My .NET application captures detects motion of a specific type of object from webcam. I am able to control movement of mouse within my form by translating the motion of the object. However I want to control the mouse movement outside my form, like some kind of virtual mouse.</p>

<p>What would be the best technique to achieve this?</p>
",,2012-03-25 06:08:29,motion detection from webcam to control mouse pointer using .NET,<.net><mouse><driver><emgucv><motion-detection>,,,CC BY-SA 3.0,False,False,True,False,False
11140,15702373,2013-03-29 11:33:32,,"<p>I'm working on my project which is a robot air hockey player;</p>

<p>in the project I'm using a Microsoft lifecam to identify the ""ball"" place.
that's working.</p>

<p>the problem is when I'm running the project in the main form -
if before entering the game I'm checking the camera (one pic)
that is the code inside the button:</p>

<pre><code> Capture capture = new Capture(0);
 Image&lt;Emgu.CV.Structure.Bgr,byte&gt;  temp = capture.QueryFrame();
 picture pic = new picture(temp);
 pic.ShowDialog();
</code></pre>

<p>and after the check I'm staring playing
the game is stopping giving me this error:</p>

<pre><code>An unhandled exception of type 'System.AccessViolationException' 
occurred in Emgu.CV.dll
Additional information: Attempted to read or write protected memory. 
This is often an indication that other memory is corrupt.
</code></pre>

<p>the image processing code is:</p>

<pre><code> class C_Camera
    {
        public Capture capWebCam = null;
        public bool binCapturingInProgress = false;
        public Image&lt;Bgr, byte&gt; imgOriginal;
        public Image&lt;Gray, byte&gt; imgProcessed;
        public ImageBox imageBox1 = new ImageBox();
        public TextBox textBox1;
        public List&lt;PointF&gt; centerList;
        CircleF[] circles;

        public void newCapture(bool b, List&lt;PointF&gt; centers)
        {
            centerList = centers;
            binCapturingInProgress = b;

            try
            {
                capWebCam = new Capture();
            }
            catch (NullReferenceException except)
            {
                MessageBox.Show(except.Message);
                return;
            }

            Application.Idle += processFrameAndUpdateGUI;//add process image function to the applicationlist in tasks
            binCapturingInProgress = true;
        }


        public void processFrameAndUpdateGUI(object sender, EventArgs arg)
        {
            imgOriginal = capWebCam.QueryFrame();
            if (imgOriginal == null) 
            {
                return;
            }
            imgProcessed = imgOriginal.InRange(new Bgr(0, 0, 150)/*min filter*/, new Bgr(80, 80, 256));
         //   imgProcessed = imgOriginal.InRange(new Bgr(0, 0, 175)/*min filter*/, new Bgr(100, 100, 256));

            imgProcessed = imgProcessed.SmoothGaussian(9);//9
            circles = imgProcessed.HoughCircles(new Gray(100), //canny threshhold
                                                          new Gray(50), //accumolator threshold
                                                          2,//size of image 
                                                          imgProcessed.Height / 4, //min size in pixels between centers of detected circles
                                                          15, //min radios
                                                          43)[0];//max radios and get circles from first channel
            foreach (CircleF circle in circles)
            {


                centerList.Add(circle.Center);
                //     circlesOfBalls.Add(circle);

                if (textBox1.Text != """") textBox1.AppendText(Environment.NewLine);
                textBox1.AppendText(""ball position = x"" + centerList[centerList.Count - 1].X +
                                    "", y = "" + centerList[centerList.Count - 1].Y.ToString().PadLeft(4)
                                    + ""centerList.Count= "" + centerList.Count);

                // + "", radios = "" + centerList[centerList.Count - 1].Radius.ToString(""###,000"").PadLeft(7))

                textBox1.ScrollToCaret();// scrolls the textBox to last line

                // draw a small green circle in the center
                CvInvoke.cvCircle(imgOriginal, // draw on the original image
                                  new Point((int)circle.Center.X, (int)circle.Center.Y),//center point of circle
                                  3, // radios of circle,
                                  new MCvScalar (0, 255, 0), // draw in green color
                                  -1, //indicates to fill the circle
                                  LINE_TYPE.CV_AA, //smoothes the pixels
                                  0);// no shift 

                //draw a red circle around the detected object
              //  if (imgOriginal.Data != null) 
                    imgOriginal.Draw(circle,    //current circle
                                new Bgr(Color.Red), // draw pure red
                                3);
            } // end of for each

           // if(imgOriginal.Data != null)
                imageBox1.Image = imgOriginal;
        }
</code></pre>

<p>i tried to search in google and here for an answer but couldn't find any.
if I'm not entering the camera check it works just fine.</p>
",2013-03-29 12:00:00,2016-04-24 06:04:19,image capturing is failing after one capture,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
11200,11821575,2012-08-06 01:28:34,,"<p>With EmguCV, to capture an image from a web-cam we use :</p>

<pre><code>Capture cap = new Capture(0);

Image &lt; Bgr, byte &gt; nextFrame = cap.QueryFrame();

...

...
</code></pre>

<p>But I don't know how to capture images from my Kinect, I have tried <code>kinectCapture</code> class but it didn't work with me.
Thanks </p>
",2012-08-06 14:37:00,2012-08-21 19:46:19,Using Kinect with Emgu CV,<c#><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
11217,15708743,2013-03-29 17:57:28,,"<p>Running a Monodroid app (Xamarin trial version) using <strong>Emgu CV (libemgucv-android-2.4.2.1773-RC)</strong> throws an <code>UnsatisfiedLinkError</code> when it tries to load <strong>libopencv_highgui.so</strong>, in response to the line of code below.  Other Emgu calls seem to work fine.</p>

<pre><code>var camera = new Capture();
</code></pre>

<ol>
<li>Running in debug or release mode (Visual Studio 2010) has the same error. </li>
<li>My solution and APK include all the correct SO files (including libopencv_highgui.so) for the emulated CPU/ABI.  </li>
<li>I've tried various API levels, all with the same error.</li>
<li>""adb logcat"" doesn't seem to have anything different from the VS exception stack below.</li>
</ol>

<p>Below is the exception stack.</p>

<pre><code>D/dalvikvm( 1228): Trying to load lib /data/app-lib/EyeReaderApp.EyeReaderApp-1/libopencv_highgui.so 0x40ce22a0
E/dalvikvm( 1228): dlopen(""/data/app-lib/EyeReaderApp.EyeReaderApp-1/libopencv_highgui.so"") failed: Cannot load library: find_library(linker.cpp:889): ""/data/app-lib/EyeReaderApp.EyeReaderApp-1/libopencv_highgui.so"" failed to load previously
Unhandled Exception:

Java.Lang.UnsatisfiedLinkError: 
Unhandled Exception:

System.TypeInitializationException: 
I/MonoDroid( 1228): UNHANDLED EXCEPTION: System.TypeInitializationException: An exception was thrown by the type initializer for Emgu.CV.CvInvoke ---&gt; Java.Lang.UnsatisfiedLinkError: Exception of type 'Java.Lang.UnsatisfiedLinkError' was thrown.
I/MonoDroid( 1228):   at Android.Runtime.JNIEnv.CallStaticVoidMethod (IntPtr jclass, IntPtr jmethod, Android.Runtime.JValue[] parms) [0x00023] in /Users/builder/data/lanes/monodroid-lion-bigsplash/0e0e51f9/source/monodroid/src/Mono.Android/src/Runtime/JNIEnv.g.cs:973 
I/MonoDroid( 1228):   at Java.Lang.JavaSystem.LoadLibrary (System.String libName) [0x00034] in /Users/builder/data/lanes/monodroid-lion-bigsplash/0e0e51f9/source/monodroid/src/Mono.Android/platforms/android-14/src/generated/Java.Lang.JavaSystem.cs:259 
I/MonoDroid( 1228):   at Emgu.CV.CvInvoke..cctor () [0x00158] in E:\Visual Studio 2010\Projects\EyeReader\Android\libemgucv-android-2.4.2.1773-RC\Emgu.CV\PInvoke\CvInvokeCore.cs:154 
I/MonoDroid( 1228):   --- End of managed exception stack trace ---
I/MonoDroid( 1228): java.lang.UnsatisfiedLinkError: Cannot load library: find_library(linker.cpp:889): ""/data/app-lib/EyeReaderApp.EyeReaderApp-1/libopencv_highgui.so"" failed to load previously
I/MonoDroid( 1228):     at java.lang.Runtime.loadLibrary(Runtime.java:371)
I/MonoDroid( 1228):     at java.lang.System.loadLibrary(System.java:535)
I/MonoDroid( 1228):     at mono.android.view.View_OnClickListenerImplementor.n_onClick(Native Method)
I/MonoDroid( 1228):     at mono.android.view.View_OnClickListenerImplementor.onClick(View_OnClickListenerImplementor.java:29)
I/MonoDroid( 1228):     at android.view.View.performClick(View.java:4204)
I/MonoDroid( 1228):     at android.view.View$PerformClick.run(View.java:17355)
I/MonoDroid( 1228):     at android.os.Handler.handleCallback(Handler.java:725)
I/MonoDroid( 1228):     at android.os.Handler.dispatchMessage(Handler.java:92)
I/MonoDroid( 1228):     at android.os.Looper.loop(Looper.java:137)
I/MonoDroid( 1228):     at android.app.ActivityThread.main(ActivityThread.java:5041)
I/MonoDroid( 1228):     at java.lang.reflect.Method.invokeNative(Native Method)
I/MonoDroid( 1228):     at java.lang.reflect.Method.invoke(Method.java:511)
I/MonoDroid( 1228):     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:793)
I/MonoDroid( 1228):     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:560)
I/MonoDroid( 1228):     at dalvik.system.NativeStart.main(Native Method)
I/MonoDroid( 1228): 
I/MonoDroid( 1228):   --- End of inner exception stack trace ---
I/MonoDroid( 1228): at Emgu.CV.Capture..ctor (int) [0x0001d] in E:\Visual Studio 2010\Projects\EyeReader\Android\libemgucv-android-2.4.2.1773-RC\Emgu.CV\Capture\Capture.cs:162
I/MonoDroid( 1228): at Emgu.CV.Capture..ctor () [0x00000] in E:\Visual Studio 2010\Projects\EyeReader\Android\libemgucv-android-2.4.2.1773-RC\Emgu.CV\Capture\Capture.cs:149
I/MonoDroid( 1228): at EyeReaderApp.MainScreen.StartCamera () [0x00010] in E:\Visual Studio 2010\Projects\EyeReader\Android\EyeReaderApp\Screens\MainScreen.cs:78
I/MonoDroid( 1228): at EyeReaderApp.MainScreen.CameraButton_Click (object,System.EventArgs) [0x00017] in E:\Visual Studio 2010\Projects\EyeReader\Android\EyeReaderApp\Screens\MainScreen.cs:62
I/MonoDroid( 1228): at Android.Views.View/IOnClickListenerImplementor.OnClick (Android.Views.View) [0x0000b] in /Users/builder/data/lanes/monodroid-lion-bigsplash/0e0e51f9/source/monodroid/src/Mono.Android/platforms/android-14/src/generated/Android.Views.View.cs:1267
I/MonoDroid( 1228): at Android.Views.View/IOnClickListenerInvoker.n_OnClick_Landroid_view_View_ (intptr,intptr,intptr) [0x00010] in /Users/builder/data/lanes/monodroid-lion-bigsplash/0e0e51f9/source/monodroid/src/Mono.Android/platforms/android-14/src/generated/Android.Views.View.cs:1238
I/MonoDroid( 1228): at (wrapper dynamic-method) object.7be55d07-8ea3-4414-a38c-584f4ca07a4b (intptr,intptr,intptr) &lt;IL 0x00017, 0x00043&gt;
Unhandled Exception:

System.TypeInitializationException: 
E/mono    ( 1228): 
E/mono    ( 1228): Unhandled Exception:
E/mono    ( 1228): System.TypeInitializationException: An exception was thrown by the type initializer for Emgu.CV.CvInvoke ---&gt; Java.Lang.UnsatisfiedLinkError: Exception of type 'Java.Lang.UnsatisfiedLinkError' was thrown.
E/mono    ( 1228):   at Android.Runtime.JNIEnv.CallStaticVoidMethod (IntPtr jclass, IntPtr jmethod, Android.Runtime.JValue[] parms) [0x00023] in /Users/builder/data/lanes/monodroid-lion-bigsplash/0e0e51f9/source/monodroid/src/Mono.Android/src/Runtime/JNIEnv.g.cs:973 
E/mono    ( 1228):   at Java.Lang.JavaSystem.LoadLibrary (System.String libName) [0x00034] in /Users/builder/data/lanes/monodroid-lion-bigsplash/0e0e51f9/source/monodroid/src/Mono.Android/platforms/android-14/src/generated/Java.Lang.JavaSystem.cs:259 
E/mono    ( 1228):   at Emgu.CV.CvInvoke..cctor () [0x00158] in E:\Visual Studio 2010\Projects\EyeReader\Android\libemgucv-android-2.4.2.1773-RC\Emgu.CV\PInvoke\CvInvokeCore.cs:154 
E/mono    ( 1228):   --- End of managed exception stack trace ---
E/mono    ( 1228): java.lang.UnsatisfiedLinkError: Cannot load library: find_library(linker.cpp:889): ""/data/app-lib/EyeRea
I/mono    ( 1228): [ERROR] FATAL UNHANDLED EXCEPTION: System.TypeInitializationException: An exception was thrown by the type initializer for Emgu.CV.CvInvoke ---&gt; Java.Lang.UnsatisfiedLinkError: Exception of type 'Java.Lang.UnsatisfiedLinkError' was thrown.
I/mono    ( 1228):   at Android.Runtime.JNIEnv.CallStaticVoidMethod (IntPtr jclass, IntPtr jmethod, Android.Runtime.JValue[] parms) [0x00023] in /Users/builder/data/lanes/monodroid-lion-bigsplash/0e0e51f9/source/monodroid/src/Mono.Android/src/Runtime/JNIEnv.g.cs:973 
The program 'Mono' has exited with code 255 (0xff).
</code></pre>
",2013-03-29 21:28:28,2013-03-30 13:43:51,UnsatisfiedLinkError with monodroid and emgu - libopencv_highgui.so failed to load previously,<android><mono><xamarin.android><xamarin><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
11261,15712573,2013-03-29 22:46:07,,"<p>I have a code that calculate the rotation and translation matrix as following:</p>

<pre><code>matrix Matrix&lt;double&gt; rt = new Matrix&lt;double&gt;(3, 4);  
if (positiveCount[0] &gt; positiveCount[1])  
{  
    rt = R[0].ConcateHorizontal(T[0].GetCol(2));  
}  
else  
{  
    rt = R[1].ConcateVertical(T[1].GetCol(2));  
}  
</code></pre>

<p>I get the error as shown in the <a href=""https://i.stack.imgur.com/Eals7.png"" rel=""nofollow noreferrer"">image</a>, <img src=""https://i.stack.imgur.com/Eals7.png"" alt=""enter image description here""></p>

<p>I checked all the matrices and elements, the size of all is match. </p>

<p>Has anybody experienced same error?</p>
",2013-03-29 22:48:45,2013-03-29 23:29:11,OpenCV: src.depth() == dst.depth() && src.size == dst.size exception,<c#><opencv><emgucv><opencvdotnet>,,,CC BY-SA 3.0,True,False,True,False,False
11298,16669007,2013-05-21 11:34:08,,"<p>I'm trying to visualize the FFT of an image with EMGU. Here's the image I'm processing: </p>

<p><img src=""https://i.stack.imgur.com/8toxR.jpg"" alt=""enter image description here""></p>

<p>Here's the expected result:</p>

<p><img src=""https://i.stack.imgur.com/ilOWH.jpg"" alt=""enter image description here""></p>

<p>Here's what I get:
<img src=""https://i.stack.imgur.com/qhBdd.png"" alt=""enter image description here""></p>

<p>Here's my code:</p>

<pre><code>Image&lt;Gray, float&gt; image = new Image&lt;Gray, float&gt;(@""C:\Users\me\Desktop\sample3.jpg"");
IntPtr complexImage = CvInvoke.cvCreateImage(image.Size, Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_32F, 2);

CvInvoke.cvSetZero(complexImage);
CvInvoke.cvSetImageCOI(complexImage, 1);
CvInvoke.cvCopy(image, complexImage, IntPtr.Zero);
CvInvoke.cvSetImageCOI(complexImage, 0);

Matrix&lt;float&gt; dft = new Matrix&lt;float&gt;(image.Rows, image.Cols, 2);
CvInvoke.cvDFT(complexImage, dft, Emgu.CV.CvEnum.CV_DXT.CV_DXT_FORWARD, 0);

Matrix&lt;float&gt; outReal = new Matrix&lt;float&gt;(image.Size);
Matrix&lt;float&gt; outIm = new Matrix&lt;float&gt;(image.Size);
CvInvoke.cvSplit(dft, outReal, outIm, IntPtr.Zero, IntPtr.Zero);

Image&lt;Gray, float&gt; fftImage = new Image&lt;Gray, float&gt;(outReal.Size);
CvInvoke.cvCopy(outReal, fftImage, IntPtr.Zero);

pictureBox1.Image = image.ToBitmap();
pictureBox2.Image = fftImage.Log().ToBitmap();
</code></pre>

<p>What mistake am I making here?</p>

<p><strong>Update</strong>: as per Roger Rowland's suggestion here's my updated code. The result looks better but I'm not 100% sure it's correct. Here's the result:<br>
<img src=""https://i.stack.imgur.com/Waxz6.png"" alt=""enter image description here""></p>

<pre><code>Image&lt;Gray, float&gt; image = new Image&lt;Gray, float&gt;(@""C:\Users\yytov\Desktop\sample3.jpg"");
        IntPtr complexImage = CvInvoke.cvCreateImage(image.Size, Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_32F, 2);

        CvInvoke.cvSetZero(complexImage);  // Initialize all elements to Zero
        CvInvoke.cvSetImageCOI(complexImage, 1);
        CvInvoke.cvCopy(image, complexImage, IntPtr.Zero);
        CvInvoke.cvSetImageCOI(complexImage, 0);

        Matrix&lt;float&gt; dft = new Matrix&lt;float&gt;(image.Rows, image.Cols, 2);
        CvInvoke.cvDFT(complexImage, dft, Emgu.CV.CvEnum.CV_DXT.CV_DXT_FORWARD, 0);

        //The Real part of the Fourier Transform
        Matrix&lt;float&gt; outReal = new Matrix&lt;float&gt;(image.Size);
        //The imaginary part of the Fourier Transform
        Matrix&lt;float&gt; outIm = new Matrix&lt;float&gt;(image.Size);
        CvInvoke.cvSplit(dft, outReal, outIm, IntPtr.Zero, IntPtr.Zero);

        CvInvoke.cvPow(outReal, outReal, 2.0);
        CvInvoke.cvPow(outIm, outIm, 2.0);

        CvInvoke.cvAdd(outReal, outIm, outReal, IntPtr.Zero);
        CvInvoke.cvPow(outReal, outReal, 0.5);

        CvInvoke.cvAddS(outReal, new MCvScalar(1.0), outReal, IntPtr.Zero); // 1 + Mag
        CvInvoke.cvLog(outReal, outReal); // log(1 + Mag)

        // Swap quadrants
        int cx = outReal.Cols / 2;
        int cy = outReal.Rows / 2;

        Matrix&lt;float&gt; q0 = outReal.GetSubRect(new Rectangle(0, 0, cx, cy));
        Matrix&lt;float&gt; q1 = outReal.GetSubRect(new Rectangle(cx, 0, cx, cy));
        Matrix&lt;float&gt; q2 = outReal.GetSubRect(new Rectangle(0, cy, cx, cy));
        Matrix&lt;float&gt; q3 = outReal.GetSubRect(new Rectangle(cx, cy, cx, cy));
        Matrix&lt;float&gt; tmp = new Matrix&lt;float&gt;(q0.Size);

        q0.CopyTo(tmp);
        q3.CopyTo(q0);
        tmp.CopyTo(q3);
        q1.CopyTo(tmp);                    
        q2.CopyTo(q1);
        tmp.CopyTo(q2);

        CvInvoke.cvNormalize(outReal, outReal, 0.0, 255.0, Emgu.CV.CvEnum.NORM_TYPE.CV_MINMAX, IntPtr.Zero);

        Image&lt;Gray, float&gt; fftImage = new Image&lt;Gray, float&gt;(outReal.Size);
        CvInvoke.cvCopy(outReal, fftImage, IntPtr.Zero);

        pictureBox1.Image = image.ToBitmap();
        pictureBox2.Image = fftImage.ToBitmap();  
</code></pre>
",2013-05-22 13:16:15,2013-05-22 13:16:15,EMGU/OpenCV FFT of image not yielding expected results,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
11359,9880273,2012-03-26 21:41:06,,"<p>I would like to use Kinect and EmguCV together. I've managed to get images from Kinect and create a EmguCV's Image object. I've run the application for a moment and the application crashes after some time because the memory is not released properly. </p>

<p>The little piece of code gets RGB-color images from Kinect and converts them to HSV-color images. I am not able to work out where the memory is not released. I've used ""Using structures"" just like the examples I've read on the internet and in some book.</p>

<p>I'd like to get some advice about what I am doing wrongly in the code because I'm not very acquainted with C# and I must have pulled my leg converting image data. I'm interested in seeing other -simple- Kinect + EmguCV projects too, I would be very grateful if you recommend any.</p>

<p>Thanks in advance. </p>

<p>This is the code:</p>

<pre><code>    private void showHSV(Bitmap bmp)
    {
        Image&lt;Bgr, byte&gt; img = new Image&lt;Bgr, byte&gt;(bmp);
        Image&lt;Hsv, byte&gt; imgHsv = img.Convert&lt;Hsv, byte&gt;();

        Bitmap bmp2 = imgHsv.ToBitmap();

        image2.Source = sourceFromBitmap(bmp2);
    }


    private BitmapSource sourceFromBitmap(Bitmap bmp)
    {
        BitmapSource bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
            bmp.GetHbitmap(),
            IntPtr.Zero,
            System.Windows.Int32Rect.Empty,
            BitmapSizeOptions.FromWidthAndHeight(bmp.Width, bmp.Height));

        return bs;
    }

    private void ColorImageReady(object sender, ColorImageFrameReadyEventArgs e)
    {
        using (ColorImageFrame imageFrame = e.OpenColorImageFrame())
        {
            if (imageFrame != null)
            {   
                byte[] pixelData = new byte[imageFrame.PixelDataLength];
                imageFrame.CopyPixelDataTo(pixelData);

                BitmapSource bmp = BitmapImage.Create(imageFrame.Width, imageFrame.Height, 96, 96, PixelFormats.Bgr32, null,
                    pixelData, imageFrame.Width * imageFrame.BytesPerPixel);

                image1.Source = bmp;

                showHSV(bitmapFromSource(bmp));
            }
            else
            {
                // imageFrame is null because the request did not arrive in time          }
            }
        }
    }

    private System.Drawing.Bitmap bitmapFromSource(BitmapSource bitmapsource)
    {
        System.Drawing.Bitmap bitmap;

        using (System.IO.MemoryStream outStream = new System.IO.MemoryStream())
        {
            BitmapEncoder enc = new BmpBitmapEncoder();
            enc.Frames.Add(BitmapFrame.Create(bitmapsource));
            enc.Save(outStream);
            bitmap = new System.Drawing.Bitmap(outStream);   
        }
        return bitmap;
    }
</code></pre>
",,2012-03-26 21:57:54,Kinect & EmguCV & GC,<c#><garbage-collection><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
11648,19758531,2013-11-03 21:45:28,,"<p>I'm trying to develop a uniform sizing application which will determine your size whether you are small, medium, large or x-large. The user will be standing in a fixed distance away from the camera and the system will capture a whole body image of the user, and from that image the system will get the measurements needed. My problem here is the getting of detecting of measurement the system detects the same measurement for all user even though their sizes are far from each other. How will I make the detection more accurate?</p>

<p>Here is my code:</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.Util;

namespace fitting
{
    public partial class Form1 : Form
    {
        HaarCascade UpperBody = new HaarCascade(""haarcascade_mcs_upperbody.xml"");
        HaarCascade LowerBody = new HaarCascade(""haarcascade_lowerbody.xml"");

        Capture camera;
        bool captureProcess = false;
        Image&lt;Bgr, Byte&gt; img;

        public Form1()
        {
            InitializeComponent();
        }

        void viewImage(object sender, EventArgs e)
        {
            img = camera.QueryFrame();
            if (img == null)
                return;
            CamImageBox.Image = img;
        }

        private void btnCapture_Click(object sender, EventArgs e)
        {
            if (captureProcess == true)
            {
                string data;

                Application.Idle -= viewImage;
                captureProcess = false;
                SaveFileDialog dlg = new SaveFileDialog();
                if (dlg.ShowDialog() == DialogResult.OK)
                {
                    img.ToBitmap().Save(dlg.FileName + "".jpg"", System.Drawing.Imaging.ImageFormat.Png);
                    data = dlg.FileName + "".jpg"";
                }
                measureImage();
            }
        }

        void measureImage()
        {
            OpenFileDialog dlg2 = new OpenFileDialog();
            dlg2.Filter = ""Image|*.jpg;*png"";
            if (dlg2.ShowDialog() == DialogResult.OK)
            {
                Image&lt;Bgr, Byte&gt; frame = new Image&lt;Bgr, byte&gt;(dlg2.FileName);
                Image&lt;Gray, Byte&gt; Gray_Frame = frame.Convert&lt;Gray, Byte&gt;();


/////////////////////////LOWER BODY DETECTION////////////////////////////////
                MCvAvgComp[][] LowerBodyDetect = Gray_Frame.DetectHaarCascade(
                    LowerBody,
                    1.985603925968,
                    0,
                    Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                    new Size());

///////////////////HERE IS THE UPPER BODY DETECTION/////////////////////////

                MCvAvgComp[][] UpperBodyDetect = Gray_Frame.DetectHaarCascade(
                    UpperBody,
                    1.3,
                    5,
                    Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                    new Size());


/////////////////////////DRAWING OF RECTANGLE ON DETECTED UPPER BODY///////////////////
                try
                {
                    frame.Draw(UpperBodyDetect[0][0].rect, new Bgr(Color.Red), 2);
                    double width = (UpperBodyDetect[0][0].rect.Width);
                    textBox1.Text = (Convert.ToString(width));
                }
                catch (Exception e)
                {
                    MessageBox.Show(e.Message);
                }
///////////////////////DRAWING OF RECTANGLE ON DETECTED LOWER BODY///////////////////
                try
                {
                    frame.Draw(LowerBodyDetect[0][0].rect, new Bgr(Color.Green), 2);
                }
                catch (Exception e)
                {
                    MessageBox.Show(e.Message);
                }
                CamImageBox.Image = frame;
            }
        }

        private void Form1_Load(object sender, EventArgs e)
        {
            bool useCam = false;

            if (!useCam)
                measureImage();
            else {
                try
                {
                    camera = new Capture();
                }
                catch (Exception exc)
                {
                    MessageBox.Show(exc.Message);
                    return;
                }
                Application.Idle += viewImage;
                captureProcess = true;
            }
        }
    }
}
</code></pre>
",2013-11-04 16:09:27,2013-11-04 16:09:27,Measuring sizes by using Emgu haarcascade,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
11658,22065577,2014-02-27 10:25:08,,"<p>I need your help and advice. The question consists of the following items: there are pictures from a chamber that stands in a room in the strictly fixed place(a chamber turns about the axis) . How to combine all these pictures in one so that there was an effect as though we see it with the eyes? There are all pictures of foreshortening (left, right, top, bottom and other foreshortening) of room from one point. I think that I need to use 3d calibration and reconstructionin emgu(opencv). Your help and advice are needed. And also some example of using. Maybe someone has already faced such problem. I’ll be grateful for your help.</p>
",,2014-05-10 08:28:23,2d images to 3d(reconstruction),<opencv><3d><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
11670,11838605,2012-08-07 02:51:38,,"<p>I want to make an app just like this <a href=""http://andybest.net/2009/02/processing-opencv-tutorial-2-bubbles/"" rel=""nofollow"">http://andybest.net/2009/02/processing-opencv-tutorial-2-bubbles/</a> does in EMGU CV</p>

<p>the problem is, that I don't know how to draw multiple image in specific coordinate in emgu CV(or overlaying multiple image on top of captured image/video)</p>

<p>any help would be appreciated...</p>

<p>thanks!!</p>
",,2012-08-07 12:17:47,Draw image in specific coordinate,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
11674,11842852,2012-08-07 09:21:46,,"<p>I'm in need of recording video from a 4 channel DVR from .net C#. I've looked at EMGU a Opencv .net wrapper as well as the DirectShow .net library to do this. I've decided to give EMGU a go and is quite happy with it when using webcams. Now I want to use a 4 channel H.264 Usb DVR for the same purpose, but I don't know how to select a video channel on the DVR. When running the sample capture application of EMGU I only get a black screen. I have the same problem with DirectShow. It picks up the DVR as a DR 3101_3104 Video Capture device, but is also showing me the black screen.
Note that the camera is working fine, when I use ""SuperDVR""(software that came included with the DVR).</p>

<p>I think there must be a way to specify the channel of which camera you want in both of these libraries, but I have no idea. Could someone shed some light on my problem please. </p>
",,2012-08-07 09:28:54,Video Recording from a DVR using EMGU or DirectShow C#,<video><opencv><directshow><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
11707,17660566,2013-07-15 17:48:47,,"<p>I'm trying to use EmguCV with WPF. I added the controls on the windows form
<img src=""https://i.stack.imgur.com/Zpwf3.png"" alt=""Toolbox""></p>

<p>General:</p>

<ul>
<li>Pointer</li>
<li>HistogramBox</li>
<li>ImageBox</li>
<li>MatrixBox</li>
<li>PanAndZoomPicture...</li>
</ul>

<p>But these controls don't appear on WPF.</p>

<p>Is there any way of enabling these controls on WPF?</p>

<p>Thanks</p>
",2013-07-15 17:55:38,2013-07-15 20:33:27,How to add EmguCV controls on WPF,<c#><wpf><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
11746,22071813,2014-02-27 14:43:29,,"<p>I want you to know the methods to get the image from array of bytes :</p>

<p>I'am using this code but it's throw an exception ,if the size is  more than 100  or the length of the arary,and if it's less than 50 it save a messay image </p>

<pre><code>Bitmap b = new Bitmap(@""C:/difflena.jpg"");

             byte[] pixels = lolo(b);
          MemoryStream stream = new MemoryStream(pixels, 0, pixels.Length);
          Bitmap bitmap = new Bitmap(stream);
          Image&lt;Gray, byte&gt; image = new Image&lt;Gray, byte&gt;(60, 60);
          image.Bytes = pixels;
          image.Save(file + ""face"" + ""t"" + "".bmp"");
          if (image != null) { Label1.Text = ""yes"";


 public byte[] lolo(Bitmap n)
      {

          /*ImageFormat imageFormat = n.RawFormat;

          byte[] Ret=null;
          try
          {
              using (MemoryStream ms = new MemoryStream())
              {
                  n.Save(ms, imageFormat);
                  Ret = ms.ToArray();
              }

          }
          catch (Exception) { Label1.Text = ""no""; }

          return Ret;}
</code></pre>
",2014-03-03 06:22:14,2014-03-03 06:22:14,convert Emgu image to array and from array to image,<image-processing><emgucv><itemgroup>,,,CC BY-SA 3.0,False,False,True,False,False
11775,17667083,2013-07-16 02:34:47,,"<p>I'm looking to write a perona malik anisotropic filter and it looks like I'll need to utilize the gpu for performance reasons. Long story short, I want to know how to use HLSL in xna to to GPGPU tasks.</p>

<p>I'm looking for some code snippets to move some data on to the GPU, process it frame by frame, then return it so I can do other stuff with it. </p>

<p>From what I've read, I need to use ""<a href=""http://www.gamedev.net/topic/512643-ping-ponging-using-directx-hlsl-and-c/"" rel=""nofollow"">ping-ponging</a>""</p>

<p><strong>EDIT</strong></p>

<p>This is what I have so far</p>

<p><strong>C#</strong></p>

<pre><code>using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;

using Microsoft.Xna.Framework;
using Microsoft.Xna.Framework.Graphics;
using Microsoft.Xna.Framework.Input;
using Microsoft.Xna.Framework.Content.Pipeline;
using Microsoft.Xna.Framework.Content.Pipeline.Graphics;
using Microsoft.Xna.Framework.Content.Pipeline.Processors;

namespace HotplateTest
{
    public class XNAClass : Microsoft.Xna.Framework.Game
    {
        GraphicsDeviceManager graphics;
        RenderTarget2D Target;
        RenderTarget2D Output;
        Effect physicsEffect;

        Vector4[] positions;

        public XNAClass()
        {
            graphics = new GraphicsDeviceManager(this);
        }

        protected override void Initialize()
        {
            Target = new RenderTarget2D(graphics.GraphicsDevice, 10, 10, false, SurfaceFormat.Vector4, DepthFormat.None);
            Output = new RenderTarget2D(graphics.GraphicsDevice, 10, 10, false, SurfaceFormat.Vector4, DepthFormat.None);

            positions = new Vector4[100];
            for (int i = 0; i &lt; positions.Length; i++)
            {
                positions[i] = new Vector4(i);
            }

            Target.SetData&lt;Vector4&gt;(positions);

            base.Initialize();
        }

        protected override void LoadContent()
        {
            base.LoadContent();
            physicsEffect = Content.Load&lt;Effect&gt;(""shader"");
        }

        protected override void Update(GameTime gameTime)
        {
            base.Update(gameTime);
        }

        protected override void Draw(GameTime gameTime)
        {

            GraphicsDevice.SetRenderTarget(Target); 
            GraphicsDevice.Clear(Color.Black);
            physicsEffect.Techniques[0].Passes[0].Apply();
            physicsEffect.Parameters[""oldPositionTexture""].SetValue(Output); 
            physicsEffect.CurrentTechnique.Passes[0].Apply();

            GraphicsDevice.SetRenderTarget(null);
            Target.GetData&lt;Vector4&gt;(positions);


            base.Draw(gameTime);
        }
    }
}
</code></pre>

<p><strong>HLSL</strong></p>

<pre><code>texture oldPositionTexture;

sampler oldPositionSampler = sampler_state
{
    Texture = &lt; oldPositionTexture &gt;;

    MipFilter = POINT;
    MinFilter = POINT;
    MagFilter = POINT;
    ADDRESSU = CLAMP;
    ADDRESSV = CLAMP;
};

struct VertexShaderInput
{
    float4 Position : POSITION;
    float2 Tex  : TEXCOORD0;
};

struct VertexShaderOutput
{
    float4 Position : POSITION;
    float2 Tex  : TEXCOORD0;
};

// input texture dimensions
static const float w = 10;
static const float h = 10;

static const float2 pixel = float2(1.0 / w, 1.0 / h);
static const float2 halfPixel = float2(pixel.x / 2, pixel.y / 2);

VertexShaderOutput VS(VertexShaderInput input)
{
    VertexShaderOutput output = (VertexShaderOutput)0;

    output.Tex = input.Tex; 

    return output;
}

float4 PS1(VertexShaderOutput input) : COLOR0
{
    float2 myV = input.Tex;
    float myPosAndMass = tex2D(oldPositionSampler, myV);

    return float4(myPosAndMass, myPosAndMass, myPosAndMass, myPosAndMass);
}

technique Technique1
{
    pass Pass0
    {
        VertexShader = compile vs_2_0 VS();
        PixelShader = compile ps_2_0 PS1();
    }
}
</code></pre>

<p>I get an error message </p>

<blockquote>
  <p>An unhandled exception of type 'System.ArgumentException' occurred in
  Microsoft.Xna.Framework.Graphics.dll</p>
  
  <p>Additional information: The type you are using for T in this method is
  an invalid size for this resource.</p>
</blockquote>

<p>Interestingly when I use Single instead of Vector4 in the C# code, the error message does not occur. Of course this means that the results calculated in the positions variable are now useless because they are interpreted as single when they are really vector4. </p>
",2013-07-17 06:32:11,2013-07-24 05:26:15,using HLSL in XNA,<c#><opencv><xna><hlsl><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
11849,11851832,2012-08-07 18:22:57,,"<p>There is a task of recognition red areas on an image and it requires maximum of accuracy. But the quality of a source image is quite bad. I'm trying to minimize a noise on a mask with detected red areas using cvThreshold. Unfortunately, there is no expected effect - gray artifacts stay.  </p>

<pre><code>//Converting from Bgr to Hsv
Image&lt;Hsv, Byte&gt; hsvimg = markedOrigRecImg.Convert&lt;Hsv, Byte&gt;();
Image&lt;Gray, Byte&gt;[] channels = hsvimg.Split();

Image&lt;Gray, Byte&gt; hue = channels[0];
Image&lt;Gray, Byte&gt; saturation = channels[1];
Image&lt;Gray, Byte&gt; value = channels[2];

Image&lt;Gray, Byte&gt; hueFilter = hue.InRange(new Gray(0), new Gray(30));
Image&lt;Gray, Byte&gt; satFilter = saturation.InRange(new Gray(100), new Gray(255));
Image&lt;Gray, Byte&gt; valFilter = value.InRange(new Gray(50), new Gray(255));

//Mask contains gray artifacts        
Image&lt;Gray,Byte&gt; mask = (hueFilter.And(satFilter)).And(valFilter);

//Gray artifacts stays even if threshold (the third param.) value is 0...
CvInvoke.cvThreshold(mask, mask, 100, 255, THRESH.CV_THRESH_BINARY);

mask.Save(""D:/img.jpg"");
</code></pre>

<p>In the same time here it works fine - saved image is purely white:</p>

<pre><code>#region test

Image&lt;Gray,Byte&gt; some = new Image&lt;Gray, byte&gt;(mask.Size);
some.SetValue(120);
CvInvoke.cvThreshold(some, some, 100, 255, THRESH.CV_THRESH_BINARY);
some.Save(""D:/some.jpg"");

#endregion
</code></pre>

<p>Mask before threshold example:
<a href=""http://dl.dropbox.com/u/52502108/input.jpg"" rel=""nofollow"">http://dl.dropbox.com/u/52502108/input.jpg</a></p>

<p>Mask after threshold example:
<a href=""http://dl.dropbox.com/u/52502108/output.jpg"" rel=""nofollow"">http://dl.dropbox.com/u/52502108/output.jpg</a></p>

<p>Thank You in advance.
Constantine B.</p>
",2012-08-07 18:46:17,2012-11-28 18:06:59,"C# EmguCV/OpenCV ""cvThreshold"" abnormal behaviour - no expected threshold result",<c#><opencv><emgucv><image-recognition><threshold>,,,CC BY-SA 3.0,True,False,True,False,False
11863,22082677,2014-02-27 23:09:13,,"<p>I have a question about input to neural network!</p>

<p>I want to recognize one kind of leaf.  </p>

<p>I have 3000 images with different sizes and angles.  I am using emgucv and visual studio 2010 c#. </p>

<p>First I convert all my training data to grayscale then I transform grayscale images to binary images. But to recognize leaves I decided to use some method based on shapes. </p>

<p>Is it a good idea??</p>
",2014-02-28 18:33:48,2014-02-28 18:33:48,Recognizing objects using artificial neural network,<c#><visual-studio-2010><emgucv>,2014-03-12 06:46:37,,CC BY-SA 3.0,False,False,True,False,False
11888,19782964,2013-11-05 06:15:58,,"<p>Im using Emgu.CV (OpenCV), to find delta in image, but sometimes I get Access violation exception that cause my app to crash.</p>

<p>After digging in the debug I find that (<code>blobs.Values</code>):</p>

<pre><code>List&lt;CvBlob&gt; listOfBlobs = blobs.Values.ToList();
</code></pre>

<p>return 1733 items, and when I do the following:</p>

<p>But when run through the list I get EXCEPTION:</p>

<pre><code> if (resultedRectangles[j].Contains(listOfBlobs[i].BoundingBox))
</code></pre>

<p>I check and find the exception occurred at: <strong>i = 418</strong> :</p>

<blockquote>
  <p>+BoundingBox  '(new System.Collections.Generic.Mscorlib_CollectionDebugView(listOfBlobs)).Items[418].BoundingBox'
  threw an exception of type
  'System.AccessViolationException' System.Drawing.Rectangle
  {System.AccessViolationException}</p>
</blockquote>

<p>As I see the last valid value in the list is in 417.</p>

<p>I have 2 questions:
1. Why <code>blobs.Values.ToList();</code> return such corrupt data?
2. How I can check the value before access it to prevent <code>System.AccessViolationException</code> ?</p>
",2013-11-05 06:21:58,2013-11-05 06:21:58,"Emgu.CV , CvBlob.BoundingBox throw System.AccessViolationException",<c#><opencv><access-violation><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
11898,22088147,2014-02-28 06:45:41,,"<h2>Latest Info :</h2>

<p>After reminded by <strong>@Michael</strong>, 
I <strong>successfully capture</strong> and <strong>decode</strong> the QR code by using the </p>

<blockquote>
  <p>zxingnet-88246\trunk\Clients\WindowsFormsDemo</p>
  
  <p>EmguCVDemo (successful decode QR code in camera frame today)</p>
</blockquote>

<p>I will try to compare the difference between the Demo code and my code. Thanks Michael, so happy to successfully decode it.</p>

<p>p/s: those sample codes work with <strong>net4.0</strong> zxing.dll but <strong>not</strong> the <strong>net4.5</strong> zxing.dll</p>

<hr>

<h2>Old questions:</h2>

<p>By using Zxing.Net, I can decode <strong>original</strong> image of the QR code encoded by ZXing.Net.</p>

<p>But when I obtain the image from <strong>Emgu.CV capture</strong>, it cannot be decoded by ZXing.Net even I<br>
try to <em>crop</em>, <em>resize</em> and add <em>canvas</em> size. </p>

<p>But, the magic is the <strong>Android QR code scanner</strong> CAN scan those QR code even directly from camera capture. I tried to analyzed the Android source code but I found nothing special.
I wonder if the Android version one is using camera auto-focus function? </p>

<p>Below is my code:</p>

<pre><code>DecoderResult decoderResult;
Bitmap bitmap = new Bitmap(@""C:\testfunny678.bmp"");
LuminanceSource source = new BitmapLuminanceSource(bitmap);
//
BinaryBitmap binBitmap = new BinaryBitmap(new GlobalHistogramBinarizer(source));

try
{
    //null Hashable Hints
    DetectorResult detectorResult = new Detector(binBitmap.BlackMatrix).detect(null);

    Result result = decoder.decode(binBitmap);

    //decoderResult = decoder.decode(detectorResult.Bits,null);
    //points = detectorResult.Points;
    //Result result = new Result(decoderResult.Text, decoderResult.RawBytes, points, BarcodeFormat.QR_CODE);

    if (result.Text != null)
    {
        //QR_CODE
        //MessageBox.Show(""format is: "" + result.BarcodeFormat);
        MessageBox.Show(""result is: "" + result.Text);
    }
    else
    {
        MessageBox.Show(""bitmap is null"");
    }
}
//com.google.zxing.ReaderException: Exception of type 'com.google.zxing.ReaderException' was thrown.
//   at com.google.zxing.qrcode.detector.FinderPatternFinder.selectBestPatterns() in d:\Temp\zxing-2.1\csharp\qrcode\detector\FinderPatternFinder.cs:line 602
//   at com.google.zxing.qrcode.detector.FinderPatternFinder.find(Hashtable hints) in d:\Temp\zxing-2.1\csharp\qrcode\detector\FinderPatternFinder.cs:line 238
//   at com.google.zxing.qrcode.detector.Detector.detect(Hashtable hints) in d:\Temp\zxing-2.1\csharp\qrcode\detector\Detector.cs:line 90
//   at qrcode.Form1.Decode3() in c:\Users\User\Documents\Visual Studio 2013\Projects\qrcode\qrcode\Form1.cs:line 139
catch (Exception e)
{
    //MessageBox.Show(e.ToString());
}
</code></pre>

<p>My code can decode this</p>

<p><img src=""https://i.stack.imgur.com/FQeor.jpg"" alt=""My code can decode this""></p>

<p><strong>Camera capture</strong> like this</p>

<p><img src=""https://i.stack.imgur.com/ujDWi.png"" alt=""Camera capture like this""></p>

<p>After <strong>crop,resize and add canvas</strong>, it becomes like this (<em>testfunny678.bmp</em>)</p>

<p><img src=""https://i.stack.imgur.com/sLc3v.png"" alt=""After crop,resize and add canvas""></p>

<p>I added canvas at the first QR code picture because I found of the QR code <strong>surrounded by black colour</strong>, it <strong>cannot be decoded</strong> even by Android QR code decoder.</p>

<p><strong>Old version</strong> of my code using <strong>HybridBinarizer</strong> cannot decode the first QR code.</p>

<pre><code>        LuminanceSource source = new RGBLuminanceSource(GetRGBValues(bitmap), bitmap.Width, bitmap.Height);
        BinaryBitmap binBitmap = new BinaryBitmap(new HybridBinarizer(source));
</code></pre>

<p>My ultimate target is decode the QR code directly from camera (2nd QR code), but if I can decode the third QR code, I also feel happy. My friend tell me to <strong>sharpen</strong> the third image so that ZXing decoder and decode the third QR code.</p>

<p>By the way, I <strong>can detect</strong> the QR code existence (Found at points (23.5, 76.5), (23.5, 23.5), (75, 24.5))
 of THIRD QR code via this two function</p>

<pre><code>    public string Detect(Bitmap bitmap)
    {
        try
        {
            ZXing.LuminanceSource source = new RGBLuminanceSource(GetRGBValues(bitmap), bitmap.Width, bitmap.Height);
            var binarizer = new HybridBinarizer(source);
            var binBitmap = new BinaryBitmap(binarizer);
            BitMatrix bm = binBitmap.BlackMatrix;
            Detector detector = new Detector(bm);
            DetectorResult result = detector.detect();

            string retStr = ""Found at points "";
            foreach (ResultPoint point in result.Points)
            {
                retStr += point.ToString() + "", "";
            }

            return retStr;
        }
        catch
        {
            return ""Failed to detect QR code."";
        }
    }

    private byte[] GetRGBValues(Bitmap bmp)
    {
        // Lock the bitmap's bits. 
        System.Drawing.Rectangle rect = new System.Drawing.Rectangle(0, 0, bmp.Width, bmp.Height);
        System.Drawing.Imaging.BitmapData bmpData = bmp.LockBits(rect, System.Drawing.Imaging.ImageLockMode.ReadOnly, bmp.PixelFormat);

        // Get the address of the first line.
        IntPtr ptr = bmpData.Scan0;

        // Declare an array to hold the bytes of the bitmap.
        int bytes = bmpData.Stride * bmp.Height;
        byte[] rgbValues = new byte[bytes];
        // Copy the RGB values into the array.
        System.Runtime.InteropServices.Marshal.Copy(ptr, rgbValues, 0, bytes);
        bmp.UnlockBits(bmpData);

        return rgbValues;
    }
</code></pre>

<p>But even I tried to use the DetectorResult.Points from Detect() function by <strong>changing</strong> <em>Detect() function</em> to <strong>return the DetectorResult</strong> for Decoder, it is still <strong>fail</strong> at the <strong>decoder part</strong> by having <strong>null decoderResult</strong>.</p>

<pre><code>    public DetectorResult Detect(Bitmap bitmap)
    //public string Detect(Bitmap bitmap)
    {
        try
        {
            ZXing.LuminanceSource source = new RGBLuminanceSource(GetRGBValues(bitmap), bitmap.Width, bitmap.Height);
            var binarizer = new HybridBinarizer(source);
            var binBitmap = new BinaryBitmap(binarizer);
            BitMatrix bm = binBitmap.BlackMatrix;
            Detector detector = new Detector(bm);
            DetectorResult result = detector.detect();
            return result;
            //string retStr = ""Found at points "";
            //foreach (ResultPoint point in result.Points)
            //{
            //    retStr += point.ToString() + "", "";
            //}

            //return retStr;
        }
        catch
        {
            //return ""Failed to detect QR code."";
            return null;
        }
    }

    void Decode3()
    {
        //System.Collections.Hashtable hints = null;
        DecoderResult decoderResult;
        Bitmap bitmap = new Bitmap(@""C:\testfunny678.bmp"");
        LuminanceSource source = new BitmapLuminanceSource(bitmap);
        BinaryBitmap binBitmap = new BinaryBitmap(new GlobalHistogramBinarizer(source));
        ResultPoint[] points;

        ZXing.QrCode.Internal.Decoder decoder = new ZXing.QrCode.Internal.Decoder();
        //ZXing.MultiFormatReader decoder = new ZXing.MultiFormatReader();

        try
        {
            DetectorResult detectorResult = new Detector(binBitmap.BlackMatrix).detect(null);
            //DetectorResult detectorResult = Detect(bitmap);
            //Result result = decoder.decode(binBitmap);
            //null decoderResult here
            decoderResult = decoder.decode(detectorResult.Bits,null);
            points = detectorResult.Points;
            Result result = new Result(decoderResult.Text, decoderResult.RawBytes, points, BarcodeFormat.QR_CODE);

            if (result.Text != null)
            {
                MessageBox.Show(""result is: "" + result.Text);
            }
            else
            {
                MessageBox.Show(""bitmap is null"");
            }
        }
        catch (Exception e)
        {
            //MessageBox.Show(e.ToString());
        }

    }
</code></pre>

<p>Any suggestion or correction to successfully <strong>decode</strong> the <strong>2nd QR</strong> code and <strong>3rd QR</strong> code with <strong>ZXing.NET</strong> QR code decoder is welcome, thank you.</p>
",2014-06-06 01:56:34,2014-06-06 01:56:34,ZXing.Net cannot decode the QR code captured by Camera,<c#><winforms><camera><zxing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
11946,22093331,2014-02-28 11:03:45,,"<p>My problem is following. I need precisely measure diameter of circles in bitmap.
I have Bitmap with several circles. Some of them are concentric. I need values of their diameters.
I tried OpenCV and EmguCV and their method HoughCircles. But this method find circles on the places where is are no circles (I tried a lot of combinations of input parameters). Ad if it finds them there is no case, when it found exatly same circle as in the bitmap. Their centers and diameters are different then circles on the original picture. So this method is only for some kind of game. Not for my purpose(precise measuring for industry). </p>

<p>Do you know some way or algorithm how to do it? (I prefer C#, but if it will be in pseudocode or different langueage, I will rewrite it)</p>

<p>Thanks in advance.</p>
",,2014-02-28 11:37:35,Get diameter of circle in bitmap,<c#><opencv><image-processing><pattern-matching><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
11954,17684766,2013-07-16 18:55:10,,"<p>I developed an algorithm for border tracing of objects in an image. The algorithm is capable of tracing all the objects in an image and returns the result so that you don't have to slice an image with multiple objects to use them with the algorithm.</p>

<p>So basically I begin by finding a threshold value, then get the binary image after threshold and then run the algorithm on it.</p>

<p>The algorithm is below:</p>

<ol>
<li>find the first pixel that belongs to any object.</li>
<li>Trace that object (has its own algorithm)</li>
<li>get the minimum area of the square that contains that object</li>
<li>mark all the pixels in that square as 0 (erase it from the binary image)</li>
<li>repeat from 1 until there isn't any objects left.</li>
</ol>

<p>This algorithm worked perfectly with objects that are far from each other, but when I tried with the image attached, I got the result attached also.</p>

<p>The problem is that, the square is near the circle and part of it lies in the square that contains the object, so this part is deleted because the program thinks that it is part of the first object.</p>

<p>I would appreciate it if anyone has a solution to this issue.</p>

<p>Thanks!<img src=""https://i.stack.imgur.com/ynyus.png"" alt=""enter image description here""></p>
",,2013-07-16 19:31:30,performing border tracing on multiple objects in an image,<opencv><image-processing><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
11987,16733772,2013-05-24 11:18:18,,"<p>I am new to EMGU.CV and I am struggling a bit. Let me start by giving some background of the project, i am trying to track a users fingers, i.e. calculate the users finger tips, but i am struggling a bit. I have created a set of code which filters the depth information to only a certain range and I generate a Bitmap image, tempBitmap, i then convert this image to a greyscale image using EMGU.CV which can be used by cvCanny. Once this is done i apply dilate filter to the canny image to thicken up the outline of the hand to better improve the chance of generating a successful contour, I then try to get the contours of the hand. Now what i have managed to do is to draw a box around the hand, but i am struggling to find a way to convert the contours generated by FindContours to a set of Points i can use to draw the contour with. the variable depthImage2 is a Bitmap image variable i use to draw on before assinging it to the picturebox variable on my C# form based application. any information or guidance you can provide me with will be greatly appreciated, also if my code isnt correct maybe guiding me in a direction where i can calculate the finger tips. I think i am almost there i am just missing something, so any help of any kind will be appreciated.</p>

<pre><code>Image&lt;Bgr, Byte&gt; currentFrame = new Image&lt;Bgr, Byte&gt;(tempBitmap);

Image&lt;Gray, Byte&gt; grayImage = currentFrame.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();
Image&lt;Gray, Byte&gt; cannyImage = new Image&lt;Gray, Byte&gt;(grayImage.Size);
CvInvoke.cvCanny(grayImage, cannyImage, 10, 60, 3);

StructuringElementEx kernel = new StructuringElementEx(
    3, 3, 1, 1, Emgu.CV.CvEnum.CV_ELEMENT_SHAPE.CV_SHAPE_ELLIPSE);

CvInvoke.cvDilate(cannyImage, cannyImage, kernel, 1);

IntPtr cont = IntPtr.Zero;

Graphics graphicsBitmap = Graphics.FromImage(depthImage2);

using (MemStorage storage = new MemStorage()) //allocate storage for contour approximation
    for (Contour&lt;Point&gt; contours =
        cannyImage.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,                               
            Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_EXTERNAL); 
                contours != null; contours = contours.HNext)
    {                                
        IntPtr seq = CvInvoke.cvConvexHull2(contours, storage.Ptr, Emgu.CV.CvEnum.ORIENTATION.CV_CLOCKWISE, 0);
        IntPtr defects = CvInvoke.cvConvexityDefects(contours, seq, storage);
        Seq&lt;Point&gt; tr = contours.GetConvexHull(Emgu.CV.CvEnum.ORIENTATION.CV_CLOCKWISE);

        Seq&lt;Emgu.CV.Structure.MCvConvexityDefect&gt; te = contours.GetConvexityDefacts(
            storage, Emgu.CV.CvEnum.ORIENTATION.CV_CLOCKWISE);

        graphicsBitmap.DrawRectangle(
            new Pen(new SolidBrush(Color.Red)), tr.BoundingRectangle);
    }
</code></pre>
",2016-10-22 10:18:40,2016-10-22 10:18:40,Converting contours found using EMGU.CV,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
12089,22106235,2014-02-28 21:31:46,,"<p>I'm working with Face Recognition project and I would like to know what is the difference between EigenFaceRecognizer and EigenObjectRecognizer and which is better to use.</p>
",2014-03-01 13:28:17,2014-09-17 16:44:19,Which is better between EigenObjectRecognizer vs. EigenFaceRecognizer,<c#><emgucv><face-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
12116,22111086,2014-03-01 06:39:47,,"<p>I have my code That consist: I open the images that I want to upload, then I convert it in grayscale and later in binary image. But I have a question. How do I get values (0,1) of binary image in order to create a matrix with that values with emgucv c#??</p>

<pre><code>      OpenFileDialog Openfile = new OpenFileDialog();
      if (Openfile.ShowDialog() == DialogResult.OK)
      {
          Image&lt;Gray, Byte&gt; My_Image = new Image&lt;Gray, byte&gt;(Openfile.FileName);
          pictureBox1.Image = My_Image.ToBitmap();

          My_Image = My_Image.ThresholdBinary(new Gray(69), new Gray(255));
          pictureBox2.Image = My_Image.ToBitmap();


      }
  }
</code></pre>
",,2014-03-01 08:36:57,Get values 1 or 0 of binary images,<visual-studio-2010><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
12136,23256226,2014-04-23 22:15:59,,"<p>I'm trying to convert a small opencv python script to emgu with C#.</p>

<p>In python the code</p>

<pre><code>COLOR_MIN = np.array([104, 34, 255], np.uint8)
COLOR_MAX = np.array([124, 34, 255], np.uint8)
frame_threshed = cv2.inRange(hsv_img, COLOR_MIN, COLOR_MAX)
cv2.imshow(""frame thresh"", frame_threshed)
</code></pre>

<p>correctly thresholds the image which is displayed by cv2.imshow.</p>

<p>I've converted the code to C# as follows:</p>

<pre><code>var min = new Hsv(104, 34, 255);
var max = new Hsv(124, 34, 255);
var thresh = hsvImg.InRange(min, max);
CvInvoke.cvShowImage(""thresh"", thresh);
</code></pre>

<p>Here only a black image is drawn - so nothing seems to be matching the threshold.</p>

<p>In both cases I'm using the same .PNG file as input. I wrote the python code on osx and the .net code is running inside a win8 VM - could this be something to do with color profiles?</p>

<p>Any tips or things to try to get the .NET version working would be greatly appreciated!! Thanks!</p>
",2014-04-24 05:41:23,2014-04-24 05:44:45,What is the difference between the InRange method in opencv with python/cv2 and c#/emgu?,<c#><python><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
12231,17711574,2013-07-17 22:46:05,,"<p>I'm using EmguCV to create a Histogram, to do this I need a <code>Bitmap</code> to create an <code>Image&lt;Gray, Byte&gt;</code>.</p>

<p>When I load an image from a file to a Bitmap variable like this:</p>

<p><code>Bitmap bmpImg = new Bitmap(filepath);</code></p>

<p><code>Image&lt;Gray, Byte&gt; emguImg = new Image&lt;Gray, byte&gt;(bmpImg);</code></p>

<p>The image creation works fine and I'm able to display the image. However, I need to create this image <code>Image&lt;Gray, Byte&gt; emguImg</code> from a structure that comes from my camera.</p>

<pre><code>public struct tFrame
{
    public IntPtr AncillaryBuffer;
    public uint AncillaryBufferSize;
    public uint AncillarySize;
    public tBayerPattern BayerPattern;
    public uint BitDepth;
    public tFrameCtx Context;
    public tImageFormat Format;
    public uint FrameCount;
    public uint Height;
    public IntPtr ImageBuffer;
    public uint ImageBufferSize;
    public uint ImageSize;
    public uint RegionX;
    public uint RegionY;
    public tErr Status;
    public uint TimestampHi;
    public uint TimestampLo;
    public uint Width;
}
</code></pre>

<p>When I create the Bitmap like this:</p>

<p><code>Bitmap bmpImg = new Bitmap((int)frame.Width, (int)frame.Height, stride, pxFormat, frame.ImageBuffer);</code></p>

<p>I'm able to display this image after converting it to BitmapSource, so I'm assuming that until this point my code is right.</p>

<p>When I try to do this:</p>

<p><code>Image&lt;Gray, Byte&gt; emguImg = Image&lt;Gray, byte&gt;(bmpImg);</code></p>

<p>I get an error, an exception from <code>Emgu.CV.CvInvoke</code></p>

<p>My question is .. Why on the first case, when I load the image to a <code>Bitmap</code> and pass this image to <code>Image&lt;Gray, Byte&gt;</code> every thing works fine but when I create the <code>Bitmap</code> from my structure and pass it to <code>Image&lt;Gray, Byte&gt;</code> I get this exception?</p>

<p>I also tried creating my Image like this:</p>

<p><code>Image&lt;Gray, Byte&gt; emguImg = new Image&lt;Gray, byte&gt;((int)frame.Width, (int)frame.Height, stride, frame.ImageBuffer);</code></p>

<p>the same error occurs. =\</p>

<p>Help please.</p>

<p>Thank you.</p>

<p><strong>[edit1]</strong></p>

<p>The problem was that one *.dll was missing.
If you look the tutorial on EmguCV wiki you'll see that they recomend you to copy a few *.dlls to your debug folder. Well I did that and more, there're 22 *.dlls in emgu's folder, I copied 21 .. and the problem was that missing *.dll
one noob move .. so don't forget to copy those *.dlls</p>
",2013-07-18 15:37:51,2013-07-18 15:37:51,Bitmap error when converting it,<c#><wpf><bitmap><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
12258,22121161,2014-03-01 22:21:27,,"<p>I´ve got several problems with my task. I want to implement an emotion recognizer. After my long search for methods, I think a combination of a feature extractor like SURF or PCA combined with SVM could be a good idea. I´ve implemented a detector for relevant parts of the face like mouth and eyes. And now I want to extract the features and store them as matrix.</p>

<p>I know I have to create a training set and a test set of my collected images and preprare the training set for SVM. And that´s my problem. </p>

<p>Which extractor will be the best? And does every extractor give a vector back with features?</p>

<p>I don´t know how to start:-( How I get the features as a vector and save them as a matrix....</p>

<p>Sorry, I don´t have enough experiences in machine learning. I´m searching for many days to find the answer and I hope someone can give me advice.....thanks a lot.</p>
",,2014-03-31 17:01:18,How can I create a trainingsset for SVM (EmguCV)?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
12266,22122183,2014-03-02 00:10:58,,"<p>That is my code   </p>

<pre><code>Image&lt;Gray, Byte&gt; image = new Image&lt;Gray, byte&gt;(Openfile.FileName);
pictureBox1.Image = image.ToBitmap();
image1 = image1.ThresholdBinary(new Gray(50), new Gray(255));
</code></pre>

<p>I open an image from my desktop and convert it to grayscale and then binary.
I want to get either the values 1 or 0 from binary images in order to storage in matrix.
How can I do that?? I am using emgucv.</p>
",2014-03-02 00:24:51,2014-03-11 08:12:44,How to get values 1 or 0 from binary images,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
12275,20986337,2014-01-08 03:12:34,,"<p>What is the difference between <code>clone</code>, <code>copy</code> and <code>copyto</code> of an image in EmguCV?. </p>

<p>I know similar questions has been asked before but I am asking this with regard to an <code>image object</code>.</p>
",2014-01-08 05:34:35,2014-01-08 23:05:11,"what is the difference between clone, copy and copyto of an image in EmguCV?",<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
12303,20987852,2014-01-08 05:43:07,,"<p>I have been trying to detect multiple people in a small space and hence track them. </p>

<p><strong>Input:</strong> CCTV feed from a camera mounted in a small room.</p>

<p><strong>Expected Output:</strong> Track and hence store the path that people take while moving from one end of the room to the other.</p>

<p>I tried to implement some of the basic methods like background subtraction and pedestrian detection. But the results are not as desired. </p>

<p>In the results obtained by implementing background subtraction, due to occlusion the blob is not one single entity(the blob of one person is broken into multiple small blobs) hence, detecting it as a single person is very difficult.
Now, consider the case when there are many people standing close to each other. In this case detecting people using simple background subtraction is a complete disaster.</p>

<p>Is there a better way to detect multiple people?
Or maybe is there a way to improve the result of background subtraction?</p>

<p>And please suggest a good way for tracking multiple people?</p>
",2014-01-08 06:30:34,2014-01-08 09:49:51,How do I detect multiple people and track them in opencv/emgucv,<opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
12355,19825572,2013-11-07 00:13:10,,"<p>OpenCL newbie question</p>

<p>I'm trying to write a kernel to perform some task over rectangular regions of an image. </p>

<p>OpenCL</p>

<pre><code>__kernel void GrayBlockSignalSeparation
(
    __global float * rhos
)
{
    const int neighbourhoodSize = 60;

    const int x = get_global_id(0);
    const int y = get_global_id(1);

    rhos[x - 1 + (y-1)*(neighbourhoodSize) ] = x;
}
</code></pre>

<p>C#</p>

<pre><code>private static void GraySignalSeparation
(                         
    ref Image&lt;Gray, float&gt; Signal
)
{
    float[] rhos = new float[(int)(image.Width / 60) * (int)(image.Height / 60)];                
    CLCalc.Program.Variable rhosVar = new CLCalc.Program.Variable(rhos);

    CLCalc.Program.MemoryObject[] args = new CLCalc.Program.MemoryObject[] 
    {                     
        rhosVar
    };
    GraySignalSeparationKernel.Execute(args, new int[] { (int)(image.Width / 60), (int)(image.Height / 60) });

    rhosVar.ReadFromDeviceTo(rhos);

}
</code></pre>

<p>When I inspect the rho values in the debugger I find that some of them appear to have been missed and are set to zero.</p>

<pre><code>[0] 1
[1] 2
[2] 3
[3] 4
[4] 5
[5] 6
[6] 7
[7] 8
[8] 9
[9] 10
[10]    11
[11]    12
[12]    13
[13]    14
[14]    15
[15]    16
[16]    17
[17]    18
[18]    19
[19]    20
[20]    21
[21]    22
[22]    23
[23]    24
[24]    25
[25]    26
[26]    27
[27]    28
[28]    29
[29]    30
[30]    31
[31]    0
[32]    0
[33]    0
[34]    0
[35]    0
[36]    0
[37]    0
[38]    0
[39]    0
[40]    0
[41]    0
[42]    0
[43]    0
[44]    0
[45]    0
[46]    0
[47]    0
[48]    0
[49]    0
[50]    0
[51]    0
[52]    0
[53]    0
[54]    0
[55]    0
[56]    0
[57]    0
[58]    0
[59]    0
[60]    1
[61]    2
[62]    3
[63]    4
[64]    5
[65]    6
[66]    7
[67]    8
[68]    9
[69]    10
[70]    11
[71]    12
[72]    13
[73]    14
[74]    15
[75]    16
[76]    17
[77]    18
[78]    19
[79]    20
[80]    21
[81]    22
[82]    23
[83]    24
[84]    25
[85]    26
[86]    27
[87]    28
[88]    29
[89]    30
[90]    31
[91]    0
[92]    0
[93]    0
[94]    0
[95]    0
[96]    0
[97]    0
[98]    0
[99]    0
[100]   0
[101]   0
[102]   0
[103]   0
[104]   0
[105]   0
[106]   0
[107]   0
[108]   0
[109]   0
[110]   0
[111]   0
[112]   0
[113]   0
[114]   0
[115]   0
[116]   0
[117]   0
[118]   0
[119]   0
[120]   1
[121]   2
[122]   3
[123]   4
[124]   5
[125]   6
[126]   7
[127]   8
[128]   9
[129]   10
[130]   11
[131]   12
[132]   13
[133]   14
[134]   15
[135]   16
[136]   17
[137]   18
[138]   19
[139]   20
[140]   21
[141]   22
[142]   23
[143]   24
[144]   25
[145]   26
[146]   27
[147]   28
[148]   29
[149]   30
[150]   31
[151]   0
[152]   0
[153]   0
[154]   0
[155]   0
[156]   0
[157]   0
[158]   0
[159]   0
[160]   0
[161]   0
[162]   0
[163]   0
[164]   0
[165]   0
[166]   0
[167]   0
[168]   0
[169]   0
[170]   0
[171]   0
[172]   0
[173]   0
[174]   0
[175]   0
[176]   0
[177]   0
[178]   0
[179]   0
[180]   1
[181]   2
[182]   3
[183]   4
[184]   5
[185]   6
[186]   7
[187]   8
[188]   9
[189]   10
[190]   11
[191]   12
[192]   13
[193]   14
[194]   15
[195]   16
[196]   17
[197]   18
[198]   19
[199]   20
[200]   21
[201]   22
[202]   23
[203]   24
[204]   25
[205]   26
[206]   27
[207]   28
[208]   29
[209]   30
[210]   31
[211]   0
[212]   0
[213]   0
[214]   0
[215]   0
[216]   0
[217]   0
[218]   0
[219]   0
[220]   0
[221]   0
[222]   0
[223]   0
[224]   0
[225]   0
[226]   0
[227]   0
[228]   0
[229]   0
[230]   0
[231]   0
[232]   0
[233]   0
[234]   0
[235]   0
[236]   0
[237]   0
[238]   0
[239]   0
[240]   1
[241]   2
[242]   3
[243]   4
[244]   5
[245]   6
[246]   7
[247]   8
[248]   9
[249]   10
[250]   11
[251]   12
[252]   13
[253]   14
[254]   15
[255]   16
[256]   17
[257]   18
[258]   19
[259]   20
[260]   21
[261]   22
[262]   23
[263]   24
[264]   25
[265]   26
[266]   27
[267]   28
[268]   29
[269]   30
[270]   31
[271]   0
[272]   0
[273]   0
[274]   0
[275]   0
[276]   0
[277]   0
[278]   0
[279]   0
[280]   0
[281]   0
[282]   0
[283]   0
[284]   0
[285]   0
[286]   0
[287]   0
[288]   0
[289]   0
[290]   0
[291]   0
[292]   0
[293]   0
[294]   0
[295]   0
[296]   0
[297]   0
[298]   0
[299]   0
[300]   1
[301]   2
[302]   3
[303]   4
[304]   5
[305]   6
[306]   7
[307]   8
[308]   9
[309]   10
[310]   11
[311]   12
[312]   13
[313]   14
[314]   15
[315]   16
[316]   17
[317]   18
[318]   19
[319]   20
[320]   21
[321]   22
[322]   23
[323]   24
[324]   25
[325]   26
[326]   27
[327]   28
[328]   29
[329]   30
[330]   31
[331]   0
[332]   0
[333]   0
[334]   0
[335]   0
[336]   0
[337]   0
[338]   0
[339]   0
[340]   0
[341]   0
[342]   0
[343]   0
[344]   0
[345]   0
[346]   0
[347]   0
[348]   0
[349]   0
[350]   0
[351]   0
[352]   0
[353]   0
[354]   0
[355]   0
[356]   0
[357]   0
[358]   0
[359]   0
[360]   1
[361]   2
[362]   3
[363]   4
[364]   5
[365]   6
[366]   7
[367]   8
[368]   9
[369]   10
[370]   11
[371]   12
[372]   13
[373]   14
[374]   15
[375]   16
[376]   17
[377]   18
[378]   19
[379]   20
[380]   21
[381]   22
[382]   23
[383]   24
[384]   25
[385]   26
[386]   27
[387]   28
[388]   29
[389]   30
[390]   31
[391]   0
[392]   0
[393]   0
[394]   0
[395]   0
[396]   0
[397]   0
[398]   0
[399]   0
[400]   0
[401]   0
[402]   0
[403]   0
[404]   0
[405]   0
[406]   0
[407]   0
[408]   0
[409]   0
[410]   0
[411]   0
[412]   0
[413]   0
[414]   0
[415]   0
[416]   0
[417]   0
[418]   0
[419]   0
[420]   1
[421]   2
[422]   3
[423]   4
[424]   5
[425]   6
[426]   7
[427]   8
[428]   9
[429]   10
[430]   11
[431]   12
[432]   13
[433]   14
[434]   15
[435]   16
[436]   17
[437]   18
[438]   19
[439]   20
[440]   21
[441]   22
[442]   23
[443]   24
[444]   25
[445]   26
[446]   27
[447]   28
[448]   29
[449]   30
[450]   31
[451]   0
[452]   0
[453]   0
[454]   0
[455]   0
[456]   0
[457]   0
[458]   0
[459]   0
[460]   0
[461]   0
[462]   0
[463]   0
[464]   0
[465]   0
[466]   0
[467]   0
[468]   0
[469]   0
[470]   0
[471]   0
[472]   0
[473]   0
[474]   0
[475]   0
[476]   0
[477]   0
[478]   0
[479]   0
[480]   1
[481]   2
[482]   3
[483]   4
[484]   5
[485]   6
[486]   7
[487]   8
[488]   9
[489]   10
[490]   11
[491]   12
[492]   13
[493]   14
[494]   15
[495]   16
[496]   17
[497]   18
[498]   19
[499]   20
[500]   21
[501]   22
[502]   23
[503]   24
[504]   25
[505]   26
[506]   27
[507]   28
[508]   29
[509]   30
[510]   31
[511]   0
[512]   0
[513]   0
[514]   0
[515]   0
[516]   0
[517]   0
[518]   0
[519]   0
[520]   0
[521]   0
[522]   0
[523]   0
[524]   0
[525]   0
[526]   0
[527]   0
[528]   0
[529]   0
[530]   0
[531]   0
[532]   0
[533]   0
[534]   0
[535]   0
[536]   0
[537]   0
[538]   0
[539]   0
[540]   1
[541]   2
[542]   3
[543]   4
[544]   5
[545]   6
[546]   7
[547]   8
[548]   9
[549]   10
[550]   11
[551]   12
[552]   13
[553]   14
[554]   15
[555]   16
[556]   17
[557]   18
[558]   19
[559]   20
[560]   21
[561]   22
[562]   23
[563]   24
[564]   25
[565]   26
[566]   27
[567]   28
[568]   29
[569]   30
[570]   31
[571]   0
[572]   0
[573]   0
[574]   0
[575]   0
</code></pre>
",,2013-11-07 10:15:05,Understanding behaviour of global id in OpenCL,<c#><opencl><emgucv><cloo>,,,CC BY-SA 3.0,False,False,True,False,False
12400,20992383,2014-01-08 10:02:55,,"<p>I need to convert a bitmap image to a Image format image so that I can display it in my image box. Please help thanks! </p>
",,2014-01-09 05:39:33,How do i convert a bitmap image to emgu image?,<image><converter><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
12442,18658415,2013-09-06 12:57:46,,"<p>I want to add an image over another image in emguCV at specific position. Addweighted() don't allow positioning. Is there any way i can position the image.</p>

<p>for example i have an image1 of 640x480 and i want to add a drop of water 10x30 on image1 at position 60x200. Is there any possible way to achieve this?</p>
",,2013-09-06 13:19:17,emguCV- how to position an Image over another image,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
12447,22134136,2014-03-02 22:00:35,,"<p>I am implementing an eye tracker using emgucv (openCV C# wrapper), So far i was able to detect iris center and eye corner accurately.</p>

<p>As the next step i want to get the screen coordinate where user is focusing (also known as gaze point),As a beginner to image processing , i am completely unaware of gaze mapping and gaze estimation.</p>

<p>I would be thankful , if you provide any code snippets or algoritms to perform gaze mapping to retrieve gaze coordinate on screen .</p>

<p>Thanks in advance</p>
",,2014-03-03 10:53:34,Retrieve gaze coordinate on screen,<c#><algorithm><opencv><image-processing><eye-tracking>,,,CC BY-SA 3.0,True,False,True,False,False
12454,24393654,2014-06-24 18:22:28,,"<p>I have two images I want to stitch together.  The images are two different sizes (one is the main image and the other is a small legend).  I'm currently doing:</p>

<pre><code>[STAThread]
static void Main()
{
    Application.EnableVisualStyles();
    Application.SetCompatibleTextRenderingDefault(false);
    long matchTime;
    string modelPath = ""C:/Emgu/emgucv-windows-universal-cuda 2.9.0.1922/Emgu.CV.Example/SURFFeature/model images"";
    using (Image&lt;Gray, Byte&gt; observedImage = new Image&lt;Gray, byte&gt;(""C:/Emgu/emgucv-windows-universal-cuda 2.9.0.1922/Emgu.CV.Example/SURFFeature/test images/fridge4.jpg""))
    {
        //returns two different sized images
        Image&lt;Bgr, byte&gt;[] results = DrawMatches.DrawAllMatches(modelPath, observedImage, out matchTime);
        ImageViewer.Show(results[0], String.Format(""Matched using {0} in {1} milliseconds"", GpuInvoke.HasCuda ? ""GPU"" : ""CPU"", matchTime));
        ImageViewer.Show(results[1], ""Legend"");

        using (Stitcher stitcher = new Stitcher(true))
        {
            Image&lt;Bgr, Byte&gt; stictchedResult = stitcher.Stitch(results);//exception here!
            ImageViewer.Show(stictchedResult, String.Format(""Matched using {0} in {1} milliseconds"", GpuInvoke.HasCuda ? ""GPU"" : ""CPU"", matchTime));
        }
    }
}
</code></pre>

<p>However, I get an <code>ArgumentException</code> at the commented line.  When I look at the <em>View Detail</em> section, it says <code>{""Requires more images""}</code>.  There are already 2 images in the <code>results</code> array.  Is there something obvious I'm missing?  Or am I misusing/misunderstanding the <code>Stitch</code> class?  There's nothing in <a href=""http://www.emgu.com/wiki/files/2.4.2/document/html/75cf18d9-4a41-6225-0242-3a0135e4e078.htm"" rel=""nofollow"">the API</a> that I see could be a problem.</p>
",2014-06-24 19:22:45,2014-06-24 19:22:45,Emgu CV stitching two images together of different sizes,<c#><emgucv><image-stitching>,,,CC BY-SA 3.0,False,False,True,False,False
12506,21002109,2014-01-08 17:09:40,,"<p>For an educational game i am developing, i need to capture webcam video, do real time face tracking, do marker detection, display augmentations and play sound. As this is a rebuild of an existing Silverlight game i decided to build it in WPF, so i could reuse the XAML.</p>

<p>All graphics related requirements (capture, detection, tracking, etc) have been successfully implemented using functions from the EmguCv library.</p>

<p>As far as i know, in order to play audio (mp3 files) from within a WPF app, i have a few options:</p>

<ol>
<li>Use the MediaElement (requires Windows Media Player)</li>
<li>Use the MediaPlayer class (requires Windows Media Player) &lt;== Preferred</li>
<li>Use a (the only?) 3rd party library like NAudio</li>
</ol>

<p>Now, all seems well. I can play mp3 files using any of the above method.</p>

<p>The problem is that playing the mp3 files, while capturing webcam frames causes the <code>Emgu.CV.Capture</code> to somehow always return the same frame. If i ask the Capture object to flip the frame horizontally by default (more natural) i keep getting the same frame flipped on every request (so ltr-rtl-ltr-rtl-ect.). Even after completing playback of the mp3 file, the Capture object is stuck in this apparent infinite loop.</p>

<p>It seems to me that the Capture is actually not capturing anything anymore, but just returns the last grabbed frame over and over again.</p>

<p>No exceptions are thrown but CPU spikes. The profiler (Jetbrains) tells me that the <code>Capture.QueryFrame</code> method uses most CPU cycles.</p>

<p>Below a small demo program to reproduce the issue:</p>

<pre><code>using System;
using System.Windows;
using System.Windows.Media;
using System.Windows.Threading;
using Emgu.CV;

namespace DI.Sandbox
{
    /// &lt;summary&gt;
    /// Interaction logic for MainWindow.xaml
    /// &lt;/summary&gt;
    public partial class MainWindow : Window
    {
        private readonly Capture _capture;
        private readonly MediaPlayer _player;
        private readonly DispatcherTimer _timer;

        public MainWindow()
        {
            InitializeComponent();

            _capture = new Capture { FlipHorizontal = true };
            _player = new MediaPlayer { Volume = 1 };
            _timer = new DispatcherTimer {Interval = TimeSpan.FromMilliseconds(1000/24)};
            _timer.Tick += GameLoop;
        }

        private void GameLoop(object sender, EventArgs e)
        {
            using (var grab = _capture.QueryFrame())
            {
                Capture.Source = BitmapSourceConvert.ToBitmapSource(grab);
            }
        }

        private void Start_Click(object sender, RoutedEventArgs e)
        {
            _timer.Start();
        }

        private void Play_Click(object sender, RoutedEventArgs e)
        {
            _player.Open(new Uri(""assets\\test.mp3"", UriKind.Relative));
            _player.Play();
        }

        private void Stop_Click(object sender, RoutedEventArgs e)
        {
            _player.Stop();
            _timer.Stop();
        }
    }
}
</code></pre>

<p>... and ...</p>

<pre><code>&lt;Window x:Class=""DI.Sandbox.MainWindow""
        xmlns=""http://schemas.microsoft.com/winfx/2006/xaml/presentation""
        xmlns:x=""http://schemas.microsoft.com/winfx/2006/xaml""
        Title=""OpenCV Face Tracking Experiment"" Width=""800"" Height=""600"" ResizeMode=""NoResize""&gt;

    &lt;Grid&gt;
        &lt;Grid.RowDefinitions&gt;
            &lt;RowDefinition Height=""Auto""&gt;&lt;/RowDefinition&gt;
            &lt;RowDefinition Height=""*""&gt;&lt;/RowDefinition&gt;
        &lt;/Grid.RowDefinitions&gt;

        &lt;Grid Grid.Row=""0"" Margin=""5""&gt;
            &lt;Grid.ColumnDefinitions&gt;
                &lt;ColumnDefinition Width=""Auto""&gt;&lt;/ColumnDefinition&gt;
                &lt;ColumnDefinition Width=""*""&gt;&lt;/ColumnDefinition&gt;
                &lt;ColumnDefinition Width=""Auto""&gt;&lt;/ColumnDefinition&gt;
            &lt;/Grid.ColumnDefinitions&gt;

            &lt;Button Name=""Start"" Width=""100"" Height=""25"" Click=""Start_Click"" Grid.Column=""0""&gt;Start&lt;/Button&gt;
            &lt;Button Name=""Play"" Width=""100"" Height=""25"" Click=""Play_Click"" Grid.Column=""1""&gt;Play&lt;/Button&gt;

            &lt;StackPanel Orientation=""Horizontal"" Grid.Column=""1""&gt;
                &lt;TextBlock Name=""Answer"" TextAlignment=""Center"" VerticalAlignment=""Center"" Width=""100""&gt;&lt;/TextBlock&gt;
                &lt;TextBlock Name=""Elapsed"" TextAlignment=""Center"" VerticalAlignment=""Center""&gt;&lt;/TextBlock&gt;
            &lt;/StackPanel&gt;
            &lt;Button Name=""Stop"" Width=""100"" Height=""25"" Click=""Stop_Click"" Grid.Column=""2""&gt;Stop&lt;/Button&gt;
        &lt;/Grid&gt;

        &lt;Image Name=""Capture"" Grid.Row=""1"" Width=""640"" Height=""480"" Margin=""5""&gt;&lt;/Image&gt;
    &lt;/Grid&gt;
&lt;/Window&gt;
</code></pre>

<p>Weirdest thing is that i can replicate the same problem by, running my app without playing audio, and then playing any mp3 file in the Windows Media Player!</p>

<p>Questions:</p>

<ol>
<li>Has anyone else experienced this issue? (i googled but found no similar reports)</li>
<li>Does anyone know a workaround?</li>
<li>What other alternatives do i have to play audio from within my WPF app?</li>
</ol>

<p><strong>Update:I have tested this on Windows 8 only</strong></p>
",2016-09-22 11:24:58,2016-09-22 11:24:58,EmguCv webcam capture conflicts with Windows Media Player,<c#><wpf><opencv><emgucv><windows-media-player>,,,CC BY-SA 3.0,True,False,True,False,False
12576,22145296,2014-03-03 11:15:31,,"<p>I managed integrating EmguCV into Unity3D and wrote a little converter that has some little problems</p>

<p><strong>Step 1</strong> Converting Unity3D Texture to OpenCV Image</p>

<pre><code>public static Image&lt;Bgr, byte&gt; UnityTextureToOpenCVImage(Texture2D tex){
    return UnityTextureToOpenCVImage(tex.GetPixels32 (), tex.width, tex.height);
}

public static Image&lt;Bgr, byte&gt; UnityTextureToOpenCVImage(Color32[] data, int width, int height){

    byte[,,] imageData = new byte[width, height, 3];


    int index = 0;
    for (int y = 0; y &lt; height; y++) {
        for (int x = 0; x &lt; width; x++) {
            imageData[x,y,0] = data[index].b;
            imageData[x,y,1] = data[index].g;
            imageData[x,y,2] = data[index].r;

            index++;
        }
    }

    Image&lt;Bgr, byte&gt; image = new Image&lt;Bgr, byte&gt;(imageData);

    return image;
}
</code></pre>

<p><strong>Step 2</strong> Converting OpenCV Image back to Unity3D Texture</p>

<pre><code>public static Texture2D OpenCVImageToUnityTexture(Image&lt;Bgr, byte&gt; openCVImage, GameObject check){
    return OpenCVImageToUnityTexture(openCVImage.Data, openCVImage.Width, openCVImage.Height, check);
}

public static Texture2D OpenCVImageToUnityTexture(byte[,,] data, int width, int height, GameObject check){

    Color32 [] imageData = new Color32[width*height];

    int index = 0;
    byte alpha = 255;

    for (int y = 0; y &lt; width; y++) {
        for (int x = 0; x &lt; height; x++) {
            imageData[index] = new Color32((data[x,y,2]),
                                           (data[x,y,1]),
                                           (data[x,y,0]),
                                           alpha);
            check.SetActive(true);
            index++;
        }
    }

    Texture2D toReturn = new Texture2D(width, height, TextureFormat.RGBA32, false);
    toReturn.SetPixels32(imageData);
    toReturn.Apply ();
    toReturn.wrapMode = TextureWrapMode.Clamp;

    return toReturn;
}
</code></pre>

<p>Compiler throws no errors but some goes wrong all the time. See yourself: <a href=""http://i.stack.imgur.com/qhRtT.png"" rel=""nofollow"">cats</a>.
On the left side is the original image, on the right side is the converted one. As you can see there are more cats then it should be...
Has anyone any clues?</p>

<p>Also it is slow as hell because of iterating twice through all pixels. Is there any better solution?</p>

<p><strong>EDIT</strong></p>

<p>This is the code where i draw my GUITextures:</p>

<pre><code>public GameObject catGO;

GUITexture guitex;
Texture catTex;

void Start () {
    guitex = GetComponent&lt;GUITexture&gt; ();
    catTex = catGO.GetComponent&lt;GUITexture&gt; ().texture;

    Image&lt;Bgr, byte&gt; cvImage = EmguCVUnityInterop.UnityTextureToOpenCVImage((Texture2D)catTex);

    Texture2D converted = EmguCVUnityInterop.OpenCVImageToUnityTexture(cvImage);
    guitex.texture = converted;
}
</code></pre>
",2014-03-03 13:54:50,2014-08-02 09:49:38,EmguCV and Unity3D Interoperation,<opencv><unity3d><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
12580,24402133,2014-06-25 06:58:13,,"<p>Hi in opencv c+ method <code>Findcontours</code> return the array hierarchy and to get the boundaries of the hole I can get the hierarchy .
how can i get these boundaries in emgu cv please any help?
how can i find holes in emgu cv?</p>
",2014-06-25 07:21:30,2014-06-27 06:25:44,Why is Opencv Findcontour behaving differently in Emgu c#?,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
12632,24406723,2014-06-25 10:54:50,,"<p>First of all I'm a total newbie in image processing, so please don't be too harsh on me.
That being said, I'm developing an application to analyse changes in blood flow in extremities using thermal images obtained by a camera. The user is able to define a region of interest by placing a shape (circle,rectangle,etc.) on the current image. The user should then be able to see how the average temperature changes from frame to frame inside the specified ROI.</p>

<p>The problem is that some of the images are not steady, due to (small) movement by the test subject. My question is how can I determine the movement between the frames, so that I can relocate the ROI accordingly?</p>

<p>I'm using the Emgu OpenCV .Net wrapper for image processing.
What I've tried so far is calculating the center of gravity using <code>GetMoments()</code> on the biggest contour found and calculating the direction vector between this and the previous center of gravity. The ROI is then translated using this vector but the results are not that promising yet.</p>

<p>Is this the right way to do it or am I totally barking up the wrong tree?</p>

<p>------Edit------</p>

<p><strong>Here are two sample images showing slight movement downwards to the right:</strong></p>

<p><a href=""http://postimg.org/image/wznf2r27n/"" rel=""nofollow"">http://postimg.org/image/wznf2r27n/</a></p>

<p><strong>Comparison between the contours:</strong></p>

<p><a href=""http://postimg.org/image/4ldez2di1/"" rel=""nofollow"">http://postimg.org/image/4ldez2di1/</a></p>

<p>As you can see the shape of the contour is pretty much the same, although there are some small differences near the toes.</p>
",2016-06-22 11:38:27,2016-06-22 11:38:27,Determine movement/motion (in pixels) between two frames,<opencv><emgucv><motion-detection>,,,CC BY-SA 3.0,True,False,True,False,False
12651,18675989,2013-09-07 17:28:20,,"<p>I need to crop sub-part from image.</p>
<p>For example,I have this image:</p>
<p><img src=""https://i.stack.imgur.com/Lu1Am.jpg"" alt=""enter image description here"" /></p>
<p>I need to crop the part of the image that in the red frame,
I have four coordinates of the frame corners,</p>
<p>Any idea how to implement it?</p>
<p>Thank you in advance.</p>
",2020-06-20 09:12:55,2019-07-25 15:21:18,How to crop sub-part of the image?,<c#><bitmap><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
12675,23295975,2014-04-25 14:29:32,,"<p>I am currently writing a stereo vision program in C# using the Emgu cv framework. The idea is to track a ball within a frame and display its actual distance from the cameras. The tasks I have completed so far are as follows:</p>

<p>1) I have the camera calibration operating with corners of the chessboard being marked by an array of coloured lines and circles.</p>

<p>2) I have added code in order to undistort each image so as to get accurate matches when the disparity map is created.</p>

<p>3) I have the disparity map displayed using stereo block matching and reprojection of image points using the reprojectImageTo3D() method in Emgu Cv</p>

<p>4) I have the ball being tracked in each cameras frame and the x and y coordinates of the balls centre being identified</p>

<p>The issue I am having at the moment however is how do I display the X, Y and Z values of the disparity map contained within the reprojectImageTo3D method? This variable is a type MCvPoint3D32f array which is part of the Emgu Cv class. I have tried the usual ways of retrieving a value from an point array with no success. Below is my method containing this code:</p>

<pre><code>private void Computer3DPointsFromStereoPair(Image&lt;Gray, Byte&gt; left, Image&lt;Gray, Byte&gt; right, out Image&lt;Gray, short&gt; disparityMap, out MCvPoint3D32f[] points)
{

    Size size = left.Size;

    disparityMap = new Image&lt;Gray, short&gt;(size);
    //thread safe calibration values


    using (StereoSGBM stereoSolver = new StereoSGBM(minDisparities, numDisparities, SAD, P1, P2, disp12MaxDiff, PreFilterCap, UniquenessRation, Speckle, SpeckleRange, fullDP))
    //using (StereoBM stereoSolver = new StereoBM(Emgu.CV.CvEnum.Stereo_BM_TYPE.BASIC, 0))
    {
        stereoSolver.FindStereoCorrespondence(left, right, disparityMap);

        points = PointCollection.ReprojectImageTo3D(disparityMap, Q);            
    }

}
</code></pre>

<p>Thanks in advance</p>

<p>Regards</p>

<p>Steve</p>
",2014-04-25 14:33:25,2014-04-25 15:29:35,"Return the X, Y and Z values of reprojectImageTo3D method in C# using emgu cv",<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
12797,24419963,2014-06-25 22:59:26,,"<p>I was looking at the API for EMGU and the <a href=""http://www.emgu.com/wiki/files/2.4.2/document/html/14c9beaa-1035-e076-5b67-8128ebb8c149.htm"" rel=""nofollow""><code>BrutheForceMatcher</code></a>.  If you create <code>BruteForceMatcher(T)(DistanceType)</code> constructor, it does not do cross check.  However, I do not know what cross check is, and it doesn't seem to be mentioned in the API.  In terms of this EMGU and computer vision, what is cross check?</p>
",,2014-06-27 10:34:36,What is cross check in computer vision?,<c#><computer-vision><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
12801,18687852,2013-09-08 19:37:51,,"<p>I can't find a solution to a simple problem I have:</p>

<p>In this code: </p>

<pre><code>private void ibOriginal_MouseClick(object sender, MouseEventArgs e)
{
    int mouse_get_X = (int)(e.Location.X);
    int mouse_get_Y = (int)(e.Location.Y);

    Byte byte_color = imgOriginal.Data[mouse_get_X, mouse_get_Y, 0];
}
</code></pre>

<p>I want to have an RGB value (in a 3-dimensional array of int) of a pixel with X,Y coordinates get by a Mouse Click.</p>

<p>Can I make a conversion of ""byte_color""? 
Is it correct?</p>

<p>I can't find anything in C# that can help me, I'm using EmguCV.</p>
",2013-09-29 14:42:00,2013-09-29 14:42:00,Get RGB color values on OpenCV and C#,<c#><visual-studio-2010><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
12833,19861398,2013-11-08 14:28:09,,"<p>I am using AbsDif as a way to determine the object that are present in the image that was not in the background. My problem is that AbsDif is very sensitive in lighting that's why I want to extract the background from the camera feeds. I can't get many backgrounds for different time interval because there are people always present in the camera's view. My objective is that to know the density or volume of how the object in the image.</p>

<p>For example there are plenty of people present in the image, I must be able to get the estimate congestion or crowded-ness in percentage basis like 85% congested something like that.</p>
",,2013-11-08 14:28:09,Does EmguCV BackgroundSubtractorMOG2 could extract background for background subtraction?,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
12968,22174419,2014-03-04 14:16:40,,"<p>I am trying to load set of images for training using KNN algorithm.Every time , when i try to load the image,NullReferenceException occurs.
I use OpenCV and EmguCV (.net Wrapper).I have attached the source code of the project with image dataset.
The training folder contains the images.
link to project: <a href=""http://goo.gl/z5dVLX"" rel=""nofollow"">http://goo.gl/z5dVLX</a>
what should i do to make it work?</p>

<pre><code>public void getData()
{
    CvMat row = new CvMat();
    CvMat data = new CvMat();
    string file;
    int i = 7, j = 0;
    for (i = 0; i &lt; classes; i++)
    {
        for (j = 0; j &lt; train_samples; j++)
        {
            if (j &lt; 10)
                file = file_path + i.ToString() + ""\\"" + i.ToString() + ""0"" + j.ToString() + "".pbm"";
            else
                file = file_path + i.ToString() + ""\\"" + i.ToString() + j.ToString() + "".pbm"";

            form.WriteLine(""Training..."" + file,true,true);

            // Exception occurs here
            src_image = highgui.CvLoadImage(file, highgui.CV_LOAD_IMAGE_GRAYSCALE);

            if (src_image.ptr == null)
            {
                form.WriteLine(""Error: Cant load image: "" + file + ""\n"", true, true);
            }

            // ...
        }
    }
}
</code></pre>

<p>I get the following exception:</p>

<blockquote>
  <p>An unhandled exception of type
  'System.NullReferenceException' occurred in cvlibcs.dll</p>
  
  <p>Additional
  information: Object reference not set to an instance of an object.'
  ....\Training\ ....\Training\0\000.pbm</p>
</blockquote>
",2014-03-05 22:30:25,2014-03-11 08:08:25,Nullreference Exception while loading an image using emgucv?,<c#><.net><opencv><emgucv><knn>,,,CC BY-SA 3.0,True,False,True,False,False
12997,24434740,2014-06-26 15:37:25,,"<p>I'm messing around with some object recognition samples for EMGU:</p>

<pre><code>Rectangle rect = modelImage.ROI;

PointF p1 = new PointF(rect.Left, rect.Bottom);
PointF p2 = new PointF(rect.Right, rect.Bottom);
PointF p3 = new PointF(rect.Right, rect.Top);
PointF p4 = new PointF(rect.Left, rect.Top);

//check if any opposite lines intersect
//if so, then don't add to final results
//we should never have 2 opposite sides intersecting
LineSegment2DF l1 = new LineSegment2DF(p1,p2);
LineSegment2DF l2 = new LineSegment2DF(p2, p3);
LineSegment2DF l3 = new LineSegment2DF(p3, p4);
LineSegment2DF l4 = new LineSegment2DF(p4, p1)

if (!(intersects(l1, l3) || intersects(l2, l4))) 
{
    //draw line
}
</code></pre>

<p>However, I get some fishy results such as this (grey ish):</p>

<p><img src=""https://i.stack.imgur.com/04B62.jpg"" alt=""enter image description here""></p>

<p>And (red):</p>

<p><img src=""https://i.stack.imgur.com/YA5LT.jpg"" alt=""enter image description here""></p>

<p>I get some other bad results too, but I notice a trend with these.  These rectangles (or technically trapezoids...?) have some lines that cross over or lay on top of each other.  I want to ignore drawing these results if that's the case. Is there a way to determine this given the 4 points?    </p>

<p><strong>UPDATE</strong>:  At request of user @Chris , I check out <a href=""https://stackoverflow.com/a/3838357/2498729"">this answer</a>.  I attempted to replicate the pseudo code.  However, I may be misunderstanding it.  It doesn't give the expected results.  It seems to always return <code>true</code>.   This may be because I translated the pseudo code wrong.</p>

<pre><code>public static bool intersects(LineSegment2DF l1, LineSegment2DF l2)
{
    float x1 = l1.P1.X;
    float x2 = l1.P2.X;
    float x3 = l2.P1.X;
    float x4 = l2.P2.X;
    float y1 = l1.P1.Y;
    float y2 = l1.P2.Y;
    float y3 = l2.P1.Y;
    float y4 = l2.P2.Y;

    float intervalAMin = Math.Min(x1, x2);
    float intervalAMax = Math.Max(x1, x2);
    float intervalBMin = Math.Min(x3, x4);
    float intervalBMax = Math.Max(x3, x4);

    //if (Math.Max(l1.P1.X, l1.P2.X) &lt; Math.Min(l2.P1.X, l2.P2.X)) return false;
    if(intervalAMax &lt; intervalBMin) return false;

    float a1 = (y1-y2)/(x1-x2); // Pay attention to not dividing by zero
    float a2 = (y3-y4)/(x3-x4); // Pay attention to not dividing by zero
    if (a1 == a2) return false; // Parallel segments

    float b1 = y1-a1*x1;// = y2-a1*x2;
    float b2 = y3-a2*x3;// = y4-a2*x4;

    float xa = (b2 - b1) / (a1 - a2);// Once again, pay attention to not dividing by zero
    float ya = a1 * xa + b1;
    //float ya = a2 * xa + b2;

    if ((xa &lt; Math.Max(Math.Min(x1, x2), Math.Min(x3, x4))) || (xa &gt; Math.Min(Math.Max(x1, x2), Math.Max(x3, x4)))) return false; // intersection is out of bound
    return true;
}
</code></pre>
",2017-05-23 12:30:42,2014-06-27 15:22:22,"Given 4 points of a rectangle, disregarding the 4 points, do any sides intersect?",<c#><geometry><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
13003,16812950,2013-05-29 11:42:43,,"<p>How can I compute the DFT of an image (using EMGU), display it and then compute the reverse to get back to the original?</p>

<p>I'm going to answer my own question here since it took me a while to figure out.</p>
",,2013-07-24 13:22:27,How do I compute DFT and its reverse with EMGU?,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
13024,16815977,2013-05-29 14:00:48,,"<p>I want to show images of my emgu processing while the program is running. Currently, if I use the emgu ImageViewer the program stops and waits until I close the viewer.
Is a way to update an emgu ImageViewer with a new image?
Or alternatively, is there a way to not have the program wait for the user to close a window before continuing?</p>

<p>Thanks in advance!
Regards,
Tom</p>
",,2013-05-29 14:19:53,Is there a Non-blocking emgu ImageViewer call?,<c#><computer-vision><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
13043,24437295,2014-06-26 18:06:01,,"<p>What I want to do from the following code is change the button2 click event to automatically add unrecognized faces to the database, thus requiring no button press.  I have tried various ideas but most return errors. Can a negative recognition result be used to run the button2 Click event.</p>

<pre><code>private void button2_Click(object sender, System.EventArgs e)
{
    try
    {

        //Trained face counter
        ContTrain = ContTrain + 1;

        //Get a gray frame from capture device
        gray = grabber.QueryGrayFrame().Resize(320, 240, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

        //Face Detector
        MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
        face,
        1.2,
        10,
        Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
        new Size(20, 20));

        //Action for each element detected
        foreach (MCvAvgComp f in facesDetected[0])
        {

            TrainedFace = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;();



            break;
        }

        //resize face detected image for force to compare the same size with the 
        //test image with cubic interpolation type method
        TrainedFace = result.Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
        named = DateTime.Now.ToString(""dd-MM-yy HH:mm:ss:ms"");
        TrainedFace.Save(Application.StartupPath + ""/Temp/face1.bmp"");

        string dated = DateTime.Now.ToString(""HH:mm:ss:ff dd-MM-yy"");
        label4.Text = dated;

        //Show face added in gray scale
        imageBox1.Image = TrainedFace;
        trainingImages.Add(TrainedFace);
        labels.Add(label4.Text);

        byte[] imagepic = null;
        FileStream fsstream = new FileStream(Application.StartupPath + ""/Temp/face1.bmp"", FileMode.Open, FileAccess.Read);
        BinaryReader br = new BinaryReader(fsstream);
        imagepic = br.ReadBytes((int)fsstream.Length);



        string myConnection = ""datasource=sql4.freemysqlhosting.net;port=3306;user=sql434250;password=lE3!lQ5*"";
        MySqlConnection myConn = new MySqlConnection(myConnection);
        MySqlCommand SelectCommand = new MySqlCommand(""INSERT INTO `sql434250`.`facialid` (`id`, `timeanddate`, `photo1`) VALUES (NULL, @dated, @IMG);"", myConn);
        MySqlDataReader myReader;


        myConn.Open();
        SelectCommand.Parameters.Add(new MySqlParameter(""@IMG"", imagepic));
        SelectCommand.Parameters.Add(new MySqlParameter(""@dated"", dated));
        myReader = SelectCommand.ExecuteReader();


        while (myReader.Read())
        {
        }
        Refresh();

    }
    catch (MySqlException ee)
    {

        MessageBox.Show(e.ToString());
        int errorcode = ee.Number;
    }

}




void FrameGrabber(object sender, EventArgs e)
{
    label3.Text = ""0"";
    //label4.Text = """";
    NamePersons.Add("""");


    //Get the current frame form capture device
    currentFrame = grabber.QueryFrame().Resize(320, 240, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

    //Convert it to Grayscale
    gray = currentFrame.Convert&lt;Gray, Byte&gt;();

    //Face Detector
    MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
        face,
        1.2,
        10,
        Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
        new Size(20, 20));

    //Action for each element detected
    foreach (MCvAvgComp f in facesDetected[0])
    {
        t = t + 1;
        result = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
        //draw the face detected in the 0th (gray) channel with blue color
        currentFrame.Draw(f.rect, new Bgr(Color.Red), 2);


        if (trainingImages.ToArray().Length != 0)
        {
            //TermCriteria for face recognition with numbers of trained images like maxIteration
            MCvTermCriteria termCrit = new MCvTermCriteria(ContTrain, 0.001);

            //Eigen face recognizer
            EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
                trainingImages.ToArray(),
                labels.ToArray(),
                3000,
                ref termCrit);

            name = recognizer.Recognize(result);

            //Draw the label for each face detected and recognized
            currentFrame.Draw(name, ref font, new Point(f.rect.X - 2, f.rect.Y - 2), new Bgr(Color.LightGreen));

        }

        NamePersons[t - 1] = name;
        NamePersons.Add("""");


        //Set the number of faces detected on the scene
        label3.Text = facesDetected[0].Length.ToString();

    }
    t = 0;

    //Names concatenation of persons recognized
    for (int nnn = 0; nnn &lt; facesDetected[0].Length; nnn++)
    {
        names = names + NamePersons[nnn] + "", "";
    }
    //Show the faces procesed and recognized
    imageBoxFrameGrabber.Image = currentFrame;


    //Clear the list(vector) of names
    NamePersons.Clear();

}
</code></pre>
",2014-06-26 18:20:03,2014-06-26 18:20:03,emgu automatically add an unrecognised face to database,<c#><emgucv><face-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
13083,23326513,2014-04-27 17:20:38,,"<p>Hi I am writing a program which retrieves the z coordinates of a ball from a disparity map. I am using the EmguCv wrapper class. At present I have a lot of elements working although admittedly not perfectly just yet but just need some tweaking. The steps completed so far are as follows:</p>

<ol>
<li><p>The two cameras operating at the same time with each cameras view displayed in an image box.</p></li>
<li><p>Camera calibration is carried out with the chessboard squares identified and the intrinsic and extrinsic parameters stored.</p></li>
<li><p>The images are rectified and undistorted in order to remove as much noise and distortion as possible.</p></li>
<li><p>I have the ball being identified in each image with the centre of the ball marked and the x and y coordinates retrieved.</p></li>
<li><p>The disparity map is created and displayed and the reprojectImageTo3D() method implemented to give the x, y and z coordinates of the pixels in the map.</p></li>
</ol>

<p>The issue I am having at present is how to isolate the ball in the disparity map in order to get only the x, y and especially z coordinates. I have seen instances where a single object is extracted from a disparity map, e.g. <a href=""http://disparity.wikidot.com/"" rel=""nofollow"">http://disparity.wikidot.com/</a>, under the heading ""Adding Color and Motion to Disparity Maps"".</p>

<p>Is there a method which could be used in identifying and extracting the ball or is the extraction performed by things such SURF or SIFT processes?</p>

<p>Thanks in advance</p>

<p>Steve</p>
",,2014-04-28 12:28:43,how to get the depth value of a ball from a disparity map,<c#><computer-vision><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
13176,19889298,2013-11-10 11:43:32,,"<p>I am using opencv now, I want to convert my code to emgucv because I am more familiar in C# windows forms. Does Emgucv have BackgroundSubtractorMOG and BackgroundSubtractorMOG2?</p>
",,2015-09-09 14:50:02,Does Emgucv have BackgroundSubtractorMOG and BackgroundSubtractorMOG2?,<c#><c++><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
13352,18727747,2013-09-10 19:58:17,,"<p>I'm using emgu cv in c#.</p>

<p>I need to know How I can get the video stream from my webcam(default webcam)in emgu cv?</p>
",2013-09-10 20:19:41,2017-08-23 08:46:01,How to get video stream from webcam in emgu cv?,<c#><webcam><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
13363,17796967,2013-07-22 20:39:18,,"<p>I am working on project in C#/Emgu CV, but answer in any language with OpenCv should be ok.</p>

<p>I have following image: <a href=""http://i42.tinypic.com/2z89h5g.jpg"" rel=""nofollow"">http://i42.tinypic.com/2z89h5g.jpg</a>
Or it might look like this: <a href=""http://i43.tinypic.com/122iwsk.jpg"" rel=""nofollow"">http://i43.tinypic.com/122iwsk.jpg</a></p>

<p>I am trying to do automatic calibration and I would like to know how to find corners of the field. They are marked by LEDs, but I would prefer to find it by color tags. If need I can replace all tags by same color tags. (Note that light in room is changing so the colors might be bit different next time)</p>

<p>Edge detection might be ok too, but I am afraid that I would not find the corner correctly.</p>

<p>Please help.
Thank you.</p>

<p><strong>Edit:</strong></p>

<p>Thanks aardvarkk for advice, but I think I need to give you little bit more info.
I am already able to detect and identify robots in field and get their position and rotation. But for that I have to set corners of field manually first. So I was looking for aa automatic way, but I was worried I would not be able to distinguish color tags from background because light in the room is changing quite often.</p>

<p>And as for the camera angle. Point of this is that camera can be every time from different (reasonable) angle.</p>
",2013-07-23 05:53:03,2013-07-23 05:53:03,Find corner of field,<opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
13370,24464378,2014-06-28 06:47:49,,"<pre><code>public class testEmguCV : MonoBehaviour
{
    private Capture capture;

    void Start() 
    {
        capture = new Capture();
    }

    void Update()
    {
        Image&lt;Gray, Byte&gt; currentFrame = capture.QueryGrayFrame();
        Bitmap bitmapCurrentFrame = currentFrame.ToBitmap();
        MemoryStream m = new MemoryStream();
        bitmapCurrentFrame.Save(m, bitmapCurrentFrame.RawFormat);

        Texture2D camera = new Texture2D(400, 400);
        if (currentFrame != null)
        {
            camera.LoadImage(m.ToArray());
            renderer.material.mainTexture = camera;
        }
     }
} 
</code></pre>

<p>I used above code to convert between camera feed from emgucv camera to texture2d in unity but i am having problem with <code>bitmapCurrentFrame.Save(m, bitmapCurrentFrame.RawFormat);</code> 
it is giving following errors</p>

<blockquote>
  <p>ArgumentNullException: Argument cannot be null. Parameter name:
  encoder System.Drawing.Image.Save (System.IO.Stream stream,
  System.Drawing.Imaging.ImageCodecInfo encoder,
  System.Drawing.Imaging.EncoderParameters encoderParams)
  System.Drawing.Image.Save (System.IO.Stream stream,
  System.Drawing.Imaging.ImageFormat format) (wrapper
  remoting-invoke-with-check) System.Drawing.Image:Save
  (System.IO.Stream,System.Drawing.Imaging.ImageFormat)
  WebcamUsingEmgucv.Update () (at Assets/WebcamUsingEmgucv.cs:51)</p>
</blockquote>

<p>After several hours of thinking and searching i dont know what is going on please help</p>
",2014-06-28 07:13:22,2015-01-13 20:24:56,Emgucv Image to texture2d on Unity,<unity3d><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
13390,21070096,2014-01-12 01:11:19,,"<p>I'm using Emgu CV to extract frame from video file in C#.</p>

<p>When I try to create a new <code>Capture</code> instance with file name, I get an error, probably because this file codec is unknown for Emgu CV.</p>

<p>How can I convert the codec of the file to codec which supported by Emgu CV programmatically?</p>
",,2014-01-12 01:21:51,Convert codec using Emgu CV,<c#><emgucv><codec>,,,CC BY-SA 3.0,False,False,True,False,False
13416,17803192,2013-07-23 06:46:19,,"<p>I started learning C# because I wanted to work on computer vision using Emgu CV, but when I installed  try to run a test program  with VS 2012 Ultimate, I get the error in the image below.</p>

<p>It runs well for ordinary c# programs. I have tried all I know, I have even reinstalled Emgu CV, four times and my visual studio as well.</p>

<p><img src=""https://i.stack.imgur.com/nYBL9.png"" alt=""Visual studio Error Message""></p>
",2013-07-23 06:53:29,2016-04-01 22:07:25,Unable to run Emgu CV,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
13556,16857027,2013-05-31 12:14:41,,"<p>I would like to do pose estimation of a chessboard target using emgu. I have already determined the camera intrinsics. However, I can't find the solvePnP function in emgu which I think should solve my problem.</p>

<p>Does anybody know how I could find this function in emgu?</p>

<p>Is there another way to do pose estimation using emgu? I suppose I could use the CalibrateCamera camera and use the extrinsics in some way... but I think this more computational heavy than needed. Or is it?</p>
",2013-06-01 00:04:17,2013-06-01 07:22:29,Pose estimation with emgu,<opencv><computer-vision><emgucv><photogrammetry>,,,CC BY-SA 3.0,True,False,True,False,False
13586,24478831,2014-06-29 18:13:00,,"<p>I just want to know how to extract some element in a list of contours points.</p>

<p>Basically, I have this: </p>

<pre><code>List&lt;Contour&lt;Point&gt;&gt; contoursList = new List&lt;Contour&lt;Point&gt;&gt;;
contourList.Add(contours); //that contours variable is a Contour&lt;Point&gt; that i receive in a .FindContour method.
</code></pre>

<p>then I need to select/extract/whatever one specific element of this list and find its coordinate. So how can I do this?</p>

<p>And please, any ideas.</p>
",2014-07-04 21:02:02,2014-07-12 07:46:53,EmguCV - How to find List<Contour<Point>> coordinates?,<list><point><emgucv><contour><area>,,,CC BY-SA 3.0,False,False,True,False,False
13630,24483690,2014-06-30 05:56:00,,"<p>I am having an issue with a System.StackOverflowException with the Capture function. Here is the code, please ignore the loadScript function but take a look at the constructor and FaceDetect function:</p>

<pre><code>    using System;
    using System.Collections.Generic;
    using System.Diagnostics;
    using System.Drawing;
    using System.Linq;
    using System.Text;
    using System.Data;
    using System.Threading.Tasks;
    using Emgu.CV;
    using Emgu.CV.Structure;
    using Emgu.Util;
    using System.Runtime.InteropServices;
    using PAD_SCRIPT;
    using Emgu.CV.GPU;
    using Emgu.CV.UI;



    namespace PAD_CORE_ENGINE
    {
        class VisionCore
        {
             private Capture capture;
             private HaarCascade haarCascade;

             double[,] faceData = new double[100, 5];
             double[,] eyeData = new double[100, 10];
             double[,] circleData = new double[100, 5];

             int numberOfFaces;
             private Image&lt;Bgr, Byte&gt; image;
             private System.Windows.Forms.Timer myTimer = new System.Windows.Forms.Timer();

             public VisionCore()
             {

                 capture = new Capture(0);
                 capture.ImageGrabbed += updateFaceDetect;
                 capture.Start();
                 //haarCascade = new HaarCascade(@""haarcascade_frontalface_default.xml"");
           }

           public double[,] getDetectFaceInfo()
           {
                return faceData;
           }

           public double[,] getEyeInfo()
           {
               return eyeData;
           }

           public double[,] getCircleData()
           {
               return circleData;
           }

           public double getDetectFaceX(int index)
           {
               return faceData[index, 0];
           }

           public double getDetectFaceY(int index)
           {
              return faceData[index, 1];
           }

           public double getDetectFaceWidth(int index)
           {
              return faceData[index, 2];
           }

           public double getDetectFaceHeight(int index)
           {
              return faceData[index, 3];
           }

           public double getEyeX(int index)
           {
              return eyeData[index, 0];
           }

           public double getEyeY(int index)
           {
              return eyeData[index, 1];
           }

           public double getEyeWidth(int index)
           {
              return eyeData[index, 2];
           }

           public double getEyeHeight(int index)
           {
              return eyeData[index, 3];
           }



           private void DetectFace(Image&lt;Bgr, Byte&gt; image, String faceFileName, String eyeFileName, List&lt;Rectangle&gt; faces, List&lt;Rectangle&gt; eyes, out long detectionTime)
           {

               Stopwatch watch;

               if (GpuInvoke.HasCuda)
               {
                    using (GpuCascadeClassifier face = new GpuCascadeClassifier(faceFileName))
                    using (GpuCascadeClassifier eye = new GpuCascadeClassifier(eyeFileName))
                    {
                        watch = Stopwatch.StartNew();
                        using (GpuImage&lt;Bgr, Byte&gt; gpuImage = new GpuImage&lt;Bgr, byte&gt;(image))
                        using (GpuImage&lt;Gray, Byte&gt; gpuGray = gpuImage.Convert&lt;Gray, Byte&gt;())
                        {
                             Rectangle[] faceRegion = face.DetectMultiScale(gpuGray, 1.1, 10, Size.Empty);
                             faces.AddRange(faceRegion);
                             foreach (Rectangle f in faceRegion)
                             {
                                 using (GpuImage&lt;Gray, Byte&gt; faceImg = gpuGray.GetSubRect(f))
                                 {
                                     //For some reason a clone is required.
                                     //Might be a bug of GpuCascadeClassifier in opencv
                                     using (GpuImage&lt;Gray, Byte&gt; clone = faceImg.Clone(null))
                                     {
                                          Rectangle[] eyeRegion = eye.DetectMultiScale(clone, 1.1, 10, Size.Empty);

                                          foreach (Rectangle e in eyeRegion)
                                          {
                                               Rectangle eyeRect = e;
                                               eyeRect.Offset(f.X, f.Y);
                                               eyes.Add(eyeRect);
                                          }
                                     }
                                 }
                             }
                         }
                         watch.Stop();
                     }

                 }
                 else
                 {
                    //Read the HaarCascade objects
                    using (CascadeClassifier face = new CascadeClassifier(faceFileName))
                    using (CascadeClassifier eye = new CascadeClassifier(eyeFileName))
                    {
                         watch = Stopwatch.StartNew();
                         using (Image&lt;Gray, Byte&gt; gray = image.Convert&lt;Gray, Byte&gt;()) //Convert it to Grayscale
                         {
                             //normalizes brightness and increases contrast of the image
                             gray._EqualizeHist();

                             //Detect the faces  from the gray scale image and store the locations as rectangle
                             //The first dimensional is the channel
                             //The second dimension is the index of the rectangle in the specific channel
                             Rectangle[] facesDetected = face.DetectMultiScale(
                             gray,
                             1.1,
                             10,
                             new Size(20, 20),
                             Size.Empty);
                             faces.AddRange(facesDetected);

                             foreach (Rectangle f in facesDetected)
                             {
                                  //Set the region of interest on the faces
                                  gray.ROI = f;
                                  Rectangle[] eyesDetected = eye.DetectMultiScale(
                                  gray,
                                  1.1,
                                  10,
                                  new Size(20, 20),
                                  Size.Empty);
                                  gray.ROI = Rectangle.Empty;

                                  foreach (Rectangle e in eyesDetected)
                                  {
                                       Rectangle eyeRect = e;
                                       eyeRect.Offset(f.X, f.Y);
                                       eyes.Add(eyeRect);
                                  }
                             }
                        }
                        watch.Stop();
                   }

                }
                detectionTime = watch.ElapsedMilliseconds;
                capture.QueryFrame();

            }


            protected void updateFaceDetect(object sender, EventArgs e)
            {
                 //Image&lt;Bgr, Byte&gt; image, String faceFileName, String eyeFileName, List&lt;Rectangle&gt; faces, List&lt;Rectangle&gt; eyes, out long detectionTime

                 Image&lt;Bgr, Byte&gt; image = capture.RetrieveBgrFrame();
                 string faceFileName = ""haarcascade_frontalface_default.xml"";
                 string eyeFileName = ""haarcascade_eye.xml"";
                 List&lt;Rectangle&gt; faces = new List&lt;Rectangle&gt;();
                 List&lt;Rectangle&gt; eyes = new List&lt;Rectangle&gt;();
                 long detectionTime = 0;
                 DetectFace(image, faceFileName, eyeFileName, faces, eyes, out detectionTime);
                 DisplayImage(image);
             }

             public Image&lt;Bgr, Byte&gt; getImage()
             {
                 return image;
             }

             public void DisplayImage(Image&lt;Bgr, Byte&gt; img)
             {
                 try
                 {
                     ImageViewer.Show(image, String.Format(
                     ""Completed face and eye detection using {0}"",
                     GpuInvoke.HasCuda ? ""GPU"" : ""CPU""
                     ));
        }
        catch (Exception i)
        {
            Console.WriteLine(i.Message);
        }
    }

    public Image&lt;Bgr, Byte&gt; processFaces(Image&lt;Bgr, Byte&gt; img, List&lt;Rectangle&gt; faces)
    {
        foreach (Rectangle face in faces)
            img.Draw(face, new Bgr(Color.Red), 2);

        return img;
    }

    public Image&lt;Bgr, Byte&gt; processEyes(Image&lt;Bgr, Byte&gt; img, List&lt;Rectangle&gt; eyes)
    {
        foreach (Rectangle eye in eyes)
            img.Draw(eye, new Bgr(Color.Blue), 2);

        return img;
    }

    public void testVision()
    {
        DisplayImage(capture.RetrieveBgrFrame());
    }

    public CircleF[] detectCircles(Image&lt;Bgr, Byte&gt; img)
    {
        Image&lt;Gray, Byte&gt; gray = img.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();
        Stopwatch watch = Stopwatch.StartNew();
        double cannyThreshold = 180.0;
        double circleAccumulatorThreshold = 120;
        CircleF[] circles = gray.HoughCircles(new Gray(cannyThreshold), new Gray(circleAccumulatorThreshold), 2.0, 20.0, 5, 0)[0];
        watch.Stop();
        return circles;
    }

    public Image&lt;Bgr, Byte&gt; ProcessCircles(Image&lt;Bgr, Byte&gt; img, CircleF[] circles)
    {
        foreach (CircleF circle in circles)
        {
            img.Draw(circle, new Bgr(Color.Brown), 2);
        }

        return img;
    }

    //display the image 


    public int getNumOfFaces()
    {
        return numberOfFaces;
    }

    public PADScript loadScript(PADScript l)
    {
        l.addLuaCommand(""getNumOfFaces"", this);
        l.addLuaCommand(""getDetectFaceInfo"", this);
        l.addLuaCommand(""getImage"", this);
        l.addLuaCommand(""getDetectFaceInfo"", this);
        l.addLuaCommand(""getEyeInfo"", this);
        l.addLuaCommand(""getDetectFaceX"", this);
        l.addLuaCommand(""getDetectFaceY"", this);
        l.addLuaCommand(""getDetectFaceWidth"", this);
        l.addLuaCommand(""getDetectFaceHeight"", this);
        l.addLuaCommand(""getEyeX"", this);
        l.addLuaCommand(""getEyeY"", this);
        l.addLuaCommand(""getEyeWidth"", this);
        l.addLuaCommand(""getEyeHeight"", this);
        l.addLuaCommand(""testVision"", this);

        return l;
    }
}
</code></pre>

<p>}</p>

<p>I am thinking that the capture is querying too many captures at once, but I also get the error in using (GpuCascadeClassifier face = new GpuCascadeClassifier(faceFileName)). I am not really for sure where this error is coming from. Thank you in advance for your help!</p>

<p>Edit: the exception is: An unhandled exception of type 'System.StackOverflowException' occurred in Emgu.CV.GPU.dll</p>
",2014-06-30 14:30:07,2014-06-30 14:30:07,Issue with emgucv C# and Capture,<c#><opencv><capture><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
13642,18751987,2013-09-11 21:57:01,,"<p>I'm working on a c# project. What is the best algorithm for head and eye tracking? 
Which one of OpenCVsharp or Emgu.cv is better?  How can I use it in linux?
Is source code available for this?</p>
",2013-09-11 22:32:52,2013-09-12 09:04:14,how can i track head and eyes in C#.net?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
13678,23374598,2014-04-29 20:26:00,,"<p>I have a project to create an application where the user can draw of region of interest (in this example, a rectangle around a vehicle to track) and it will automatically track the vehicle in the subsequent frames of the recorded video.</p>

<p>The method I have implemented so far using OpenCV is as follows:</p>

<blockquote>
  <p>(1) Get the user defined rectangle (Region of interest) from the<code>initial_frame</code>
  <img src=""https://i.stack.imgur.com/JRAse.png"" alt=""enter image description here""></p>
  
  <p>(2) Use<code>goodFeaturesToTrack</code>on the region of interest and store the<code>initial_features</code>
  <img src=""https://i.stack.imgur.com/pGiAd.png"" alt=""enter image description here""></p>
  
  <p>(3) Step through next frames in the video <code>
  </code>3.1: Get <code>next_frame</code> <code>
  </code>3.2: Call <code>calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, nextPts,...)</code> <code>
  </code> *where <code>prevImg</code> is always <code>initial_frame</code> and <code>prevPts</code> is always <code>initial_featues</code> <code>
  </code> and each time I only update <code>nextImg</code> with the next frame of video <code>
  </code>3.3: Get Bounding Rectangle for newly found features from <code>nextPts</code> <code>
  </code>3.4: Display frame with bounding rectangle <code>
  </code><img src=""https://i.stack.imgur.com/vJ7gD.png"" alt=""enter image description here""></p>
</blockquote>

<p>This method works in most of the 50 consecutive frames, except for a few times the tracking results in something like this:</p>

<p><img src=""https://i.stack.imgur.com/u344p.png"" alt=""enter image description here""></p>

<p>but beyond 50 frames, the results become less and less accurate:</p>

<p><img src=""https://i.stack.imgur.com/t9wDV.png"" alt=""enter image description here""></p>

<p>It does makes sense that the features found in the original image become less and less prevalent in the subsequent frames, so I am looking for ideas on how to improve this method of tracking or maybe finding a better method altogether.</p>

<p>One that has come up is using a Kalman Filter, however I do not have an idea of what parameters to use for the measurement and dynamic parameters, and how to update the measurements from the features found in the optical flow.
I'm open to any suggestions or even entirely different methods for object tracking in this kind of application.</p>

<p>*Note: This function is what I use to get the bounding rectangle of the array of features returned from the optical flow (I'm using EMGUCV here):</p>

<pre><code>    public Rectangle RectFromPoints(List&lt;PointF&gt; points)
    {
        using (MemStorage stor = new MemStorage())
        {
            Contour&lt;PointF&gt; contour = new Contour&lt;PointF&gt;(stor);

           // Remove points far outside the major grouping of all the other points
            var newPoints = RemoveOutlierPoints(points); 

            foreach(PointF pnt in newPoints)
            {
                contour.Push(pnt);
            }
            var contPoly = contour.ApproxPoly(3, stor);

            var rect = contPoly.BoundingRectangle;
            return rect;
        }
    }
</code></pre>
",2014-05-06 18:32:54,2017-03-18 07:38:05,Tracking in video sequence with user-defined target to track,<opencv><computer-vision><feature-detection>,,,CC BY-SA 3.0,True,False,True,False,False
13699,19932738,2013-11-12 15:09:11,,"<p>I have been using EMGU for a while now a couple of projects. Everything I have done so far is based on the examples, CameraCapture in particular). This has worked well for me but I am would like to package up the application so it can be used but others and it will require the user selecting a feed, saving results, etc. I would like to have a complete user interface but most of the examples are single purpose with no UI.</p>

<p>Are there any good examples out with of a standalone EMGU based app with a menu driven user interface? Thanks</p>
",,2013-11-12 15:09:11,create standalone app with EMGU,<c#><user-interface><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
13704,17824893,2013-07-24 03:49:47,,"<pre><code>Image&lt;Bgr, Byte&gt; video = cap.QueryFrame();
Texture2D t = new Texture2D(GraphicsDevice, video.Width, video.Height, false, SurfaceFormat.Color);
t.SetData&lt;byte&gt;(video.Bytes);
</code></pre>

<blockquote>
  <p>ArgumentException was unhandled</p>
  
  <p>The size of the data passed in is too large or too small for this resource.</p>
</blockquote>
",2013-07-24 04:02:17,2013-07-24 23:11:20,How to convert an emgu image to an XNA Texture2D?,<c#><.net><opencv><xna><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
13750,21100525,2014-01-13 20:15:57,,"<p>I am having a problem with EmguCV. I used a demo application, and edited it to my needs. 
It involves the following function:</p>

<pre><code>public override Image&lt;Gray, byte&gt; DetectSkin(Image&lt;Bgr, byte&gt; Img, IColor min, IColor max)
        {
            Image&lt;Hsv, Byte&gt; currentHsvFrame = Img.Convert&lt;Hsv, Byte&gt;();
            Image&lt;Gray, byte&gt; skin = new Image&lt;Gray, byte&gt;(Img.Width, Img.Height);
            skin = currentHsvFrame.InRange((Hsv)min,(Hsv)max);
            return skin;
        }
</code></pre>

<p>In the demo application, the Image comes from a video. The frame is capured from the video like this:</p>

<pre><code> Image&lt;Bgr, Byte&gt; currentFrame;
grabber = new Emgu.CV.Capture(@"".\..\..\..\M2U00253.MPG"");            
            grabber.QueryFrame();
currentFrame = grabber.QueryFrame();
</code></pre>

<p>In my application, the Image comes from a microsoft kinect stream. </p>

<p>I use the following function:</p>

<pre><code>private void SensorColorFrameReady(object sender, ColorImageFrameReadyEventArgs e)
        {
            using (ColorImageFrame colorFrame = e.OpenColorImageFrame())
            {
                if (colorFrame != null)
                {
                    // Copy the pixel data from the image to a temporary array
                    colorFrame.CopyPixelDataTo(this.colorPixels);

                    // Write the pixel data into our bitmap
                    this.colorBitmap.WritePixels(
                        new Int32Rect(0, 0, this.colorBitmap.PixelWidth, this.colorBitmap.PixelHeight),
                        this.colorPixels,
                        this.colorBitmap.PixelWidth * sizeof(int),
                        0);

                    Bitmap b = BitmapFromWriteableBitmap(this.colorBitmap);
                    currentFrame = new Image&lt;Bgr, byte&gt;(b);
                    currentFrameCopy = currentFrame.Copy();
                    skinDetector = new YCrCbSkinDetector();

                    Image&lt;Gray, Byte&gt; skin = skinDetector.DetectSkin(currentFrame, YCrCb_min, YCrCb_max);


                }
            }
        }
private static System.Drawing.Bitmap BitmapFromWriteableBitmap(WriteableBitmap writeBmp)
        {
            System.Drawing.Bitmap bmp;
            using (System.IO.MemoryStream outStream = new System.IO.MemoryStream())
            {
                BitmapEncoder enc = new BmpBitmapEncoder();
                enc.Frames.Add(BitmapFrame.Create((BitmapSource)writeBmp));
                enc.Save(outStream);
                bmp = new System.Drawing.Bitmap(outStream);
            }
            return bmp;
        }
</code></pre>

<p>Now, the demo application works, and mine doesn't. Mine gives the following exception:
<img src=""https://i.stack.imgur.com/KU67P.png"" alt=""exception""></p>

<p>And, the image here, contains the following:
<img src=""https://i.stack.imgur.com/0aOfn.png"" alt=""enter image description here""></p>

<p>I really don't understand this exception. And, now, when I run the demo, working aplication, the image, contains:
<img src=""https://i.stack.imgur.com/oIe3d.png"" alt=""enter image description here""></p>

<p>Which is, in my eyes, exactly the same. I really don't understand this. Help is very welcome!</p>
",2014-01-15 08:58:02,2014-02-27 13:29:43,"Emgucv Convert<Hsv, Byte>() image",<c#><opencv><image-processing><kinect><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
13769,17831161,2013-07-24 10:18:20,,"<p>I am using Windows 7 x64, EmguCV 2.4.9. When I run the code in my laptop it is showing this problem below. In my Desktop the code is working well. Can anyone please tell me what is the problem:</p>

<p>The Code is Given Below:</p>

<pre><code>    public MainWindow()
    {
        InitializeComponent();
    }

    void timer_Tick(object sender, EventArgs e)
    {
        Image&lt;Bgr, Byte&gt; currentFrame = capture.QueryFrame();

        if (currentFrame != null)
        {
            Image&lt;Gray, Byte&gt; grayFrame = currentFrame.Convert&lt;Gray, Byte&gt;();

            **var detectedFaces = grayFrame.DetectHaarCascade(haarCascade)[0];  ///Problem arises in this line::: SEHException was unhandeled**

            foreach (var face in detectedFaces)
                currentFrame.Draw(face.rect, new Bgr(0, double.MaxValue, 0), 3);

            image1.Source = ToBitmapSource(currentFrame);
        }
    }

    [DllImport(""gdi32"")]
    private static extern int DeleteObject(IntPtr o);

    public static BitmapSource ToBitmapSource(IImage image)
    {
        using (System.Drawing.Bitmap source = image.Bitmap)
        {
            IntPtr ptr = source.GetHbitmap(); //obtain the Hbitmap

            BitmapSource bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
                ptr,
                IntPtr.Zero,
                Int32Rect.Empty,
                System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions());

            DeleteObject(ptr); //release the HBitmap
            return bs;
        }
    }

    private void Window_Loaded(object sender, RoutedEventArgs e)
    {
        capture = new Capture();
        haarCascade = new HaarCascade(@""C:\Emgu\emgucv-windows-universal-gpu 2.4.9.1847\opencv\data\haarcascades\haarcascade_frontalface_default.xml"");
        timer = new DispatcherTimer();
        timer.Tick += new EventHandler(timer_Tick);
        timer.Interval = new TimeSpan(0, 0, 0);
        timer.Start();
    }
}
</code></pre>

<p>}</p>

<p>I have copied the opencv_xxx.dll in my bin\debug and system32. But still getting the problem. Some help will be appreciated. </p>
",,2013-07-24 10:18:20,SEHException was unhandeled,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
13977,21118507,2014-01-14 16:22:28,,"<p>i have been using EmguCV for some time by now, and it´s quite impressive the things we can do with. And i'm working in one particular project that consist in take one image of an webcam, and compare it with another stored image, and i'm willing achieve that by compare his respectives histograms. And this is going very well but i have this problem making me stuck for quite a while by now, the problem is</p>

<hr>

<p>this code snippet examines the layers of an image and normalizes and applies a threshold on the histogram</p>

<pre><code>Image&lt;Gray, Byte&gt;[] channels = webcamFrame.Split();
Image&lt;Gray, Byte&gt; ImgHue = channels[0];

DenseHistogram histo1 = new DenseHistogram(255, new RangeF(0, 255));
histo1.Calculate&lt;byte&gt;(new Image&lt;Gray, byte&gt;[] { ImgHue },false, null);
histo1.Normalize(10);
histo1.Threshold(0.5);
</code></pre>

<p>How can i iterate the bins of an <strong>DenseHistogram</strong> to compare it with another Histogram?</p>

<p><img src=""https://i.stack.imgur.com/8JVVM.png"" alt=""this code snippet generates this graph ""><em>This Histogram is
 generated by the code above</em></p>
",,2014-01-15 00:04:19,Iterate within bins of an histogram using EmguCV (C#),<c#><.net><opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
13980,21119144,2014-01-14 16:51:38,,"<p>I write an application that scan video files twice:</p>

<p>Firstly, it extracts frames from 4 video files by <code>Capture.QueryFrame()</code>, merge them to single frames (i.e. all 4 frames from different videos, merged to single frame), and display the result to the user.
Secondly, it needs to extract the frames and merge them again, and then to process the result.</p>

<p>I think about two options to do that:</p>

<ol>
<li><p>To extract the frames, merge them and save the result to new temporary video file by <code>VideoWriter</code>, and in the second time to extract only one frame from the temporary file.</p></li>
<li><p>To extract the frames from the source video files twice.</p></li>
</ol>

<p>Which way is more effectively? i.e. Which operation is more quickly- to extract frames (like in the second way) or to save frames to new video file (as the first way)?
Or maybe there is other way?</p>
",,2015-03-07 17:08:31,Most efficiency handling in Emgu CV,<c#><video-capture><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
13999,22254362,2014-03-07 15:38:13,,"<p>I'm new with EMGU and image processing and I have a project in C# that needs to detect a transparent object, specifically, a moth's wing inside a plastic bottle. Here are some examples.</p>

<p><img src=""https://i.stack.imgur.com/Q5am8.jpg"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/9Vbw3.jpg"" alt=""enter image description here""></p>

<p>I tried using YCbCr in EMGU but I can not detect it nor differentiate it from the background.</p>

<p>Another thing is that I tried to enclose it in a ""controlled environment"" (inside a box where no light can come in) and used LED back-light. Is this advisable? Or can light from the environment (fluorescent light) will do? Will this affect the detection rate? Do lighting play a factor in this kind of problem?</p>

<p>This is the idea of my project and what I use. Basically, my project is just a proof of concept about detecting a transparent object from an image using a webcam (Logitech C910). This is an example of an old industrial problem here in our country when bottling plant over stock their plastic bottle and it got contaminated before use. Moth body and moth wing are the contaminants that were given to us. Also, this is to see if a webcam can suffice as an alternative to an industrial camera for this application.</p>

<p>I place it inside a controlled environment and use LED lights as backlight (this is just made using a prototyping board and high intensity LED light that is diffused with a bond paper). The object (moth wing) will be placed inside a plastic bottle with water and will be tested into 2 parts. The first part is that the bottle is not moving and the second part is when the bottle is moved on a conveyor but at the same controlled environment. I did all the hardware required so that is not an issue anymore. The moth body is manageable (I think) to detect but the moth wing left me scratching my head.</p>

<p>Any help would be very much appreciated. Thank you in advance!</p>
",2014-03-09 04:22:48,2014-03-24 19:28:42,how to detect an object with the same color as the background,<c#><opencv><image-processing><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
14097,22262043,2014-03-07 22:37:25,,"<p>I am thinking about switching from using the C++ version of Open CV to using the emgu CV wrapper so that I can use C# to communicate with another C# program.</p>

<p>However, are there any features of Open CV that are not available in emgu cv?</p>
",,2014-03-12 13:19:30,Can emgu cv do everything that normal open CV can?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
14133,17861393,2013-07-25 14:49:09,,"<p>I'm working on an experimental project in which the challenge is to identify and extract an image of the icon or control that the user is has clicked on/touched. The method I'm trying is as follows (I need some help with step 3):</p>

<p>1) Take a screen shot when the user clicks/touches the screen:</p>

<p><img src=""https://i.stack.imgur.com/cJHxm.png"" alt=""enter image description here""></p>

<p>2) Apply edge detection:</p>

<p><img src=""https://i.stack.imgur.com/S7HQ4.png"" alt=""enter image description here""></p>

<p><strong>3) Extract the possible icon images around the Point associated with the user's cursor (Don't know how to do this)</strong></p>

<p><img src=""https://i.stack.imgur.com/15U75.png"" alt=""enter image description here""> <img src=""https://i.stack.imgur.com/bSpXR.png"" alt=""enter image description here""></p>

<p>There are easier cases in which the mouse-over event will highlight the icon/control, which allows me to identify the control with a simple screen shot comparison (before and after mouse-over). The above method is specifically for cases in which the icon is not highlighted. I'm new to emgu, so if anyone has any pointers on how to better achieve this, I'm all ears. </p>

<p>Cheers! Matt</p>
",2013-07-25 20:25:17,2013-07-27 16:28:08,Emgu - How to extract the images likely to represent an icon or control from a screenshot?,<c#><opencv><image-processing><ocr><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
14149,21132739,2014-01-15 08:49:15,,"<p>I am trying to use Decklink sdk to grab image from HDMI Input , I am using Windows 7 64bit , Visual Studio C# Express 2010 and EmguCV 2.4.0 .</p>

<p>My setting is </p>

<p>_BMDDisplayModeSupport displayModeSupport;
            IDeckLinkDisplayMode displayMode = null ;</p>

<pre><code>        _BMDDisplayMode setDisplayMode = _BMDDisplayMode .bmdModeHD720p60;
        _BMDPixelFormat setPixelFormat = _BMDPixelFormat .bmdFormat8BitYUV;
        _BMDVideoInputFlags setInputFlag = _BMDVideoInputFlags .bmdVideoInputFlagDefault;

        _deckLinkInput.DoesSupportVideoMode(setDisplayMode, setPixelFormat, setInputFlag, out displayModeSupport, out displayMode);
        _deckLinkInput.SetScreenPreviewCallback( this );

        try
        {
            _deckLinkInput.DisableAudioInput();
            _deckLinkInput.EnableVideoInput(setDisplayMode, setPixelFormat, setInputFlag);
        }
        catch (Exception em)
        {
            Console .WriteLine(""deck link init failed: "" + em.Message);
        }

        _deckLinkInput.SetCallback( this );
</code></pre>

<p>And I have enabled callback function and I may see frame come to my computer</p>

<pre><code>int frameCount = 0;
public void VideoInputFrameArrived( IDeckLinkVideoInputFrame video, IDeckLinkAudioInputPacket audio)
{
            IntPtr pData;
            video.GetBytes( out pData);
            frameCount++;
            System.Runtime.InteropServices. Marshal .ReleaseComObject(video);
}
</code></pre>

<p>Now I would like to transfer pData to a MIplimage , how may I do that ?
I guess I have to transfer the frame from YUV to RBGA , then transfer RBGA frame to MIplimage.
I saw the sample using DirectShow to solve the problem , but I am not familiar with it .
Any way to figure it out ? Thanks.</p>
",,2014-01-15 08:49:15,Questions About How to Save Image from BlackMagicDesign Intensity Pro Using Decklink sdk 9.7.7,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
14179,24527493,2014-07-02 09:28:24,,"<p>I want to run a camera calibration process for a project. I was able to successfully run the camera caliberation using EMGU CV. After tuning the code line,</p>

<pre><code>CameraCalibration.CalibrateCamera(corners_object_list, corners_points_list,Gray_Frame.Size, IC, Emgu.CV.CvEnum.CALIB_TYPE.CV_CALIB_RATIONAL_MODEL, out EX_Param);'
</code></pre>

<p>I was able to get the IntrinsicCameraParameters (IC). Now I am not sure which values I should save in a XML file so I can later use these values for calibrating the camera rather than running the process each time. Can anyone help please? Thanks a lot</p>
",,2014-07-02 09:28:24,What are the matrices that should be saved while chess board camera caliberation,<opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
14192,18797719,2013-09-14 02:33:37,,"<p>Hi sirs I'm trying to develop a program that will measure a person's height via WEBCAM</p>

<p>but I still don't have any idea on how am I going to do that all I got so far is accessing the webcam @_@</p>

<p>Can anyone teach me more on EMGU developing please :) thanks in advance</p>

<p>this is all I have T_T I hope anyone will be kind enough to teach me</p>

<pre><code>void ProcessFrame(object sender, EventArgs arg)
{
    Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
    imageBox1.Image = ImageFrame;
}

private void Fitting_Load(object sender, EventArgs e)
{
    try
    {
        capture = new Capture();
    }
    catch (NullReferenceException excpt)
    {
        textBox1.Text = excpt.Message;
        return;
    }
    Application.Idle += ProcessFrame;
    captureInProgress = true;
    btnRecord.Text = ""Pause"";
}

private void Fitting_FormClosed(object sender, FormClosedEventArgs e)
{
    if (capture != null)
    {
        capture.Dispose();
    }
}

private void btnRecord_Click(object sender, EventArgs e)
{
    if (captureInProgress == true)
    {
        Application.Idle -= ProcessFrame;
        captureInProgress = false;
        btnRecord.Text = ""Record"";
    }
    else
    {
        Application.Idle += ProcessFrame;
        captureInProgress = true;
        btnRecord.Text = ""Stop"";
    }
}
</code></pre>
",2016-12-25 18:02:21,2016-12-25 18:02:21,Height measuring system thru Webcam,<c#><winforms><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
14205,19972193,2013-11-14 07:43:11,,"<p>I have two images (scanned forms):  </p>

<p>The first image is the template image (blank form), and the second image is the image with data in it (form filled out).</p>

<p>I'm trying to align/overlay the image with data to the template image to produce a final image (aligning objects inside the two images to each other).  </p>

<p>I'm able to get the quadrilateral corners of both images, transform the quadrilateral corners, and deskew the resulting images (rectangles) but when I overlay the images, I get a double vision final image because the objects inside the two images are not aligned properly.</p>

<p>I've post a question with pictures and link to a video at AForge's forum <a href=""http://www.aforgenet.com/forum/viewtopic.php?f=4&amp;t=3013"" rel=""nofollow"">http://www.aforgenet.com/forum/viewtopic.php?f=4&amp;t=3013</a> but have not gotten any response.</p>

<p>I've also looked at Accord.Net's stitching example at <a href=""http://www.codeproject.com/Articles/95453/Automatic-Image-Stitching-with-Accord-NET"" rel=""nofollow"">http://www.codeproject.com/Articles/95453/Automatic-Image-Stitching-with-Accord-NET</a>, but it still doesn't resolve my issue.</p>

<p>Any help is appreciate it.</p>
",,2013-11-14 10:01:42,Align Two (2) Images and Objects Inside The Images Using C#,<c#><image-processing><emgucv><aforge><accord.net>,,,CC BY-SA 3.0,False,False,True,False,False
14212,22268967,2014-03-08 11:53:00,,"<p>I am working on a C# app that is using Emgu and OpenCV, both are version 2.9.0. I am a beginner with OpenCV/Emgu and I need some help to get me going.</p>

<p>I have a large image that contains multiple sub-images. Each of the sub-images contain a number of regions which needs to be processed with OpenCV in different ways.</p>

<p>The large image is updated several times per second. I am planning on using pInvoke and memcpy to update the bitmap of the large image. In order to avoid multiple copy operations, I want the sub-images to share pixel data with the large image, so they automatically get new pixel data when the large image is updated.</p>

<p>Sub-images will be processed simultaneously in multiple parallel threads.</p>

<p>What I need to know is the best way to organize the large image vs. sub-images and regions to be processed so I can update the pixels with one call to memcpy and then process regions in sub-images on different threads.</p>
",,2014-03-08 15:45:38,Best way to handle image with multiple sub-images in Emgu+OpenCV?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
14216,21136666,2014-01-15 11:51:12,,"<p>I'm trying to develop a program that measures the shoulder width of the user, and I have encountered multiple problems which I don't know how to solve.</p>

<ol>
<li>When I capture the whole body picture of the user using the laptop's webcam the system gives incorrect measurements </li>
<li>I tried capturing 3 images of the same user with the same distance and etc. but when I started measuring them it gives inconsistent measurement.</li>
</ol>

<p>Here is my code:</p>

<pre><code>    using System;
    using System.Collections.Generic;
    using System.ComponentModel;
    using System.Data;
    using System.Drawing;
    using System.Linq;
    using System.Text;
    using System.Windows.Forms;
    using Emgu.CV;
    using Emgu.CV.Structure;
    using Emgu.Util;

    namespace fitting
    {
        public partial class Form1 : Form
        {
            HaarCascade UpperBody = new HaarCascade(""haarcascade_mcs_upperbody.xml"");
            HaarCascade LowerBody = new HaarCascade(""haarcascade_lowerbody.xml"");
        Capture camera;
        bool captureProcess = false;
        Image&lt;Bgr, Byte&gt; img;

        public Form1()
        {
            InitializeComponent();
        }

        void viewImage(object sender, EventArgs e)
        {
            img = camera.QueryFrame();
            if (img == null)
                return;
            CamImageBox.Image = img;
        }

        private void btnCapture_Click(object sender, EventArgs e)
        {
            if (captureProcess == true)
            {
                string data;

                Application.Idle -= viewImage;
                captureProcess = false;
                SaveFileDialog dlg = new SaveFileDialog();
                if (dlg.ShowDialog() == DialogResult.OK)
                {
                    img.ToBitmap().Save(dlg.FileName + "".bmp"", System.Drawing.Imaging.ImageFormat.Bmp);
                    data = dlg.FileName + "".bmp"";
                }
                measureImage();
            }
        }

        void measureImage()
        {
            OpenFileDialog dlg2 = new OpenFileDialog();
            dlg2.Filter = ""Image|*.Bmp"";
            if (dlg2.ShowDialog() == DialogResult.OK)
            {
                Image&lt;Bgr, Byte&gt; frame = new Image&lt;Bgr, byte&gt;(dlg2.FileName);
                Image&lt;Gray, Byte&gt; Gray_Frame = frame.Convert&lt;Gray, Byte&gt;();


/////////////////////////LOWER BODY DETECTION////////////////////////////////
                MCvAvgComp[][] LowerBodyDetect = Gray_Frame.DetectHaarCascade(
                    LowerBody,
                    1.985603925968,
                    0,
                    Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                    new Size());

///////////////////HERE IS THE UPPER BODY DETECTION/////////////////////////

                MCvAvgComp[][] UpperBodyDetect = Gray_Frame.DetectHaarCascade(
                    UpperBody,
                    1.3,
                    5,
                    Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                    new Size());


/////////////////////////DRAWING OF RECTANGLE ON DETECTED UPPER BODY///////////////////
                try
                {
                    frame.Draw(UpperBodyDetect[0][0].rect, new Bgr(Color.Red), 2);
                    double width = (UpperBodyDetect[0][0].rect.Width);
                    textBox1.Text = (Convert.ToString(width));
                }
                catch (Exception e)
                {
                    MessageBox.Show(e.Message);
                }
///////////////////////DRAWING OF RECTANGLE ON DETECTED LOWER BODY///////////////////
                try
                {
                    frame.Draw(LowerBodyDetect[0][0].rect, new Bgr(Color.Green), 2);
                }
                catch (Exception e)
                {
                    MessageBox.Show(e.Message);
                }
                CamImageBox.Image = frame;
            }
        }

        private void Form1_Load(object sender, EventArgs e)
        {
            bool useCam = true;

            if (!useCam)
                measureImage();
            else {
                try
                {
                    camera = new Capture();
                }
                catch (Exception exc)
                {
                    MessageBox.Show(exc.Message);
                    return;
                }
                Application.Idle += viewImage;
                captureProcess = true;
            }
        }
    }
} 
</code></pre>
",,2014-01-15 11:51:12,measuring specific bodyparts using EmguCv HaarCascade,<c#><winforms><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
14242,18803172,2013-09-14 15:09:34,,"<p>For getting the pixels in the OpenCV I use this code:</p>

<pre><code>for( int y=0; y&lt;image-&gt;height; y++ ) {
            uchar* ptr = (uchar*) (image-&gt;imageData + y * image-&gt;widthStep);
            for( int x=0; x&lt;image-&gt;width; x++ ) {
                 byteArray[y*image-&gt;widthStep+3*x] =  ptr[3*x];     
                  byteArray[y*image-&gt;widthStep+3*x+1] =  ptr[3*x+1];   
                   byteArray[y*image-&gt;widthStep+3*x+2] =  ptr[3*x+2]; 

            }
    }
</code></pre>

<p>But I can't use code like this in EmguCV:</p>

<pre><code>for( int y=0; y&lt;rgb32Image-&gt;MIplImage.height; y++ ) {
 unsigned char* ptr = (unsigned char*) (rgb32Image-&gt;MIplImage.imageData + y*rgb32Image-&gt;MIplImage.widthStep); 
 //error C2678: binary '+' : no operator found which takes a left-hand operand of type 'System::IntPtr' (or there is no acceptable conversion)

             for( int x=0; x&lt;rgb32Image-&gt;MIplImage.widthStep; x++ ) {
                b[y*rgb32Image-&gt;MIplImage.widthStep+3*x] = ptr[3*x];     
                b[y*rgb32Image-&gt;MIplImage.widthStep+3*x+1] = ptr[3*x+1];  
                b[y*rgb32Image-&gt;MIplImage.widthStep+3*x+2] = ptr[3*x+2]; 

                }

        }
</code></pre>

<p><strong>What should I use instead MIplImage.imageData for getting pixels of the image in Emgu CV?</strong></p>

<p><strong>Thanks!</strong>  </p>
",,2013-09-14 15:50:13,Get the pixels of the image with emgu cv,<c++><visual-c++><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
14244,18804021,2013-09-14 16:43:27,,"<p>Hi sirs I'm just wondering if is it possible for me to measure the height or width of an object using canny edge?</p>

<p>and if there's other way?</p>
",,2013-09-15 09:31:15,is it possible for Canny Edge to measure?,<c#><winforms><emgucv>,2013-09-16 05:10:04,,CC BY-SA 3.0,False,False,True,False,False
14266,18805743,2013-09-14 19:45:01,,"<p>Suppose I have this image: 
<img src=""https://i.stack.imgur.com/dHqWs.png"" alt=""source""></p>

<p>How to automatically detect the outher box And Correct the corners of the destination image based on that outher box, so that the image looks like this?</p>

<p>Can somebody answer with C# code to do this task?</p>

<p><img src=""https://i.stack.imgur.com/A2131.png"" alt=""result""></p>
",2013-09-14 20:20:34,2013-10-03 14:46:32,Paper image correction,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
14267,19978108,2013-11-14 12:50:51,,"<p>I am quite new in image stitching techniques and algorithms. What I need is to stitch several images (from 2 to 20). Image size is around 4-5 MB and resolution is 4000x3000. </p>

<p>Since I have .NET background I tried EmguCV stitching sample application that goes with installation package. But all the time I am getting OutOfMemory exception or failed to allocate xxxxx bytes. After that I tried write native C++ console application that is using OpenCV and got same results. So problem is inside stitching implementation or maybe I need set some special settings for Stitcher class? </p>

<p>Tried different version of Emgu - 2.9, 2.4.2 and 2.4, OpenCV - 2.4.7</p>

<p>Resizing the images up to 800x600 doesn't help. When it is quite small library return 0 as result. </p>

<p>I tested it on two different machines Windows 8 x64 with 8 GB of RAM and Windows 7 x64 with 16 GB. In both cases application tries  to use all free memory and then crashes.</p>

<p>Does anyone know what maximum image size can this library process? What settings should I use to decrease memory usage? Does anyone was able to stitch big images? </p>

<p>Would appreciate any help or advice.</p>

<p>Thanks!</p>

<p>EmguCV C# code (it is actually code from EmguCV Image Stitching sample application)</p>

<pre><code>  private void selectImagesButton_Click(object sender, EventArgs e)
  {
     OpenFileDialog dlg = new OpenFileDialog();
     dlg.CheckFileExists = true;
     dlg.Multiselect = true;

     if (dlg.ShowDialog() == System.Windows.Forms.DialogResult.OK)
     {
        sourceImageDataGridView.Rows.Clear();

        Image&lt;Bgr, Byte&gt;[] sourceImages = new Image&lt;Bgr, byte&gt;[dlg.FileNames.Length];

        for (int i = 0; i &lt; sourceImages.Length; i++)
        {
           sourceImages[i] = new Image&lt;Bgr, byte&gt;(dlg.FileNames[i]);

           using (Image&lt;Bgr, byte&gt; thumbnail = sourceImages[i].Resize(200, 200, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC, true))
           {
              DataGridViewRow row = sourceImageDataGridView.Rows[sourceImageDataGridView.Rows.Add()];
              row.Cells[""FileNameColumn""].Value = dlg.FileNames[i];
              row.Cells[""ThumbnailColumn""].Value = thumbnail.ToBitmap();
              row.Height = 200;
           }
        }
        try
        {
           using (Stitcher stitcher = new Stitcher(true))
           {
              Image&lt;Bgr, Byte&gt; result = stitcher.Stitch(sourceImages);
              resultImageBox.Image = result;
           }
        }
        finally
        {
           foreach (Image&lt;Bgr, Byte&gt; img in sourceImages)
           {
              img.Dispose();
           }
        }
     }
  }
</code></pre>

<p>OpenCV C++ code:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;iostream&gt;
#include ""opencv2/core/core.hpp""
#include ""opencv2/features2d/features2d.hpp""
#include ""opencv2/highgui/highgui.hpp""
#include ""opencv2/calib3d/calib3d.hpp""
#include &lt;opencv2\stitching\stitcher.hpp&gt;

using namespace cv;
using namespace std;
int main()
{   
Stitcher stitcher = Stitcher::createDefault();

vector&lt;Mat&gt; images; 

Mat img1 = imread(""1.jpg""); 
Mat img2 = imread(""2.jpg""); 

if(!img1.data &amp;&amp; !img2.data)
{
    cout&lt;&lt;""Error!\n"";
    return -1;
}

Mat Result;

//add images to the array
images.push_back(img1);
images.push_back(img2);

cout&lt;&lt;""Stitching started...\n"";

Stitcher::Status status = stitcher.stitch(images, Result);
if (status != Stitcher::OK)
{
    cout &lt;&lt; ""Can't stitch images, error code = "" &lt;&lt; status &lt;&lt; endl;
}
imwrite(""result.jpg"",Result);
return 0;
}
</code></pre>

<p><strong>UPDATE:</strong></p>

<p>After disabling wave corerection in stitcher I was able to process larger files and it doesn't fill all free RAM.</p>

<p>I am also wondering what would be the best way to process several images. Stitch them one by another or put all images to array and give all responsibility of processing to OpenCV library?</p>

<p>Is there any description of stitching algorithm that is implemented in OpenCV library?
I just found this diagram <a href=""http://docs.opencv.org/modules/stitching/doc/introduction.html"" rel=""nofollow"">http://docs.opencv.org/modules/stitching/doc/introduction.html</a>
I want to know and understand all the details behind the scene because I will process different images with different resolution and size. So it is important for me to balance between performance and quality.</p>

<p>Thanks!</p>
",2013-11-14 18:16:52,2013-11-14 18:16:52,OpenCV/EmguCV big image stitching,<c#><c++><.net><opencv><image-stitching>,,,CC BY-SA 3.0,True,True,True,False,False
14365,22280191,2014-03-09 08:46:32,,"<p>I am trying to select and play a video file and detect face using ""haar cascade"". When i select a video file it shows exception ""ArgumentException was unhandled"" in this line<br>
<strong>int len = (int)memde.StreamLength;</strong><br>
This is the code I used: </p>

<pre><code>private void button1_Click(object sender, EventArgs e)
    {
        OpenFileDialog openFileDialog1 = new OpenFileDialog();
        if (openFileDialog1.ShowDialog() == System.Windows.Forms.DialogResult.OK)
        {
                memde = new MediaDetClass();
                System.IO.Directory.CreateDirectory(""temp"");
                int len = (int)memde.StreamLength;
                label1.Text = ""Length: "" + len.ToString();
                trackBar1.Minimum = 0;
                trackBar1.Maximum = len;
                trackBar1.Value = 0;
                counter = 0;
                Image img;
                memde.Filename = openFileDialog1.FileName;
                memde.CurrentStream = 0;
                float percent = 0.002f;
                Image&lt;Gray, byte&gt; gray;
                for (float i = 0.0f; i &lt; len; i = i + (float)(percent * len))
                {
                    counter++;
                    string fbitname = storagepath + counter.ToString();
                    memde.WriteBitmapBits(i, 850, 480, fbitname + "".bmp"");
                    pictureBox1.Image = new Bitmap(fbitname);
                    img = Image.FromFile(fbitname + "".bmp"");
                    img.Save(fbitname + "".bmp"", ImageFormat.Bmp);
                    System.IO.File.Delete(i + fbitname + "".bmp"");
                    Image&lt;Bgr, Byte&gt; image = new Image&lt;Bgr, Byte&gt;(new Bitmap(img));
                    gray = image.Convert&lt;Gray, Byte&gt;();
                    MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
                 face,
                 1.2,
                 10,
                 Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                 new Size(20, 20));
                    foreach (MCvAvgComp f in facesDetected[0])
                    {
                        result = image.Copy(f.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
                        image.Draw(f.rect, new Bgr(Color.Red), 2);
                    }
                }
        }
    }
</code></pre>
",2014-03-09 08:47:07,2014-03-09 08:56:45,ArgumentException was unhandled; Value does not fall within the expected range,<c#><asp.net><emgucv><face-detection>,,,CC BY-SA 3.0,False,False,True,False,False
14368,18812200,2013-09-15 12:09:05,,"<p>I'm writing interesting application where I want to get numbers out of a runner t-shirt. I was playing around with AForge.NET and emguCV to get the desired result and I think I'm very close to solving my problem, but still I would like to get opinion from the more experience users.
First I have this image: </p>

<p><img src=""https://i.stack.imgur.com/IFx2l.jpg"" alt=""enter image description here"">
After that I apply it a max contrast and some lightening and I get this result:</p>

<p><img src=""https://i.stack.imgur.com/RBoGh.jpg"" alt=""enter image description here"">
Next I binarize the image and get this final result:
<img src=""https://i.stack.imgur.com/oHBml.jpg"" alt=""enter image description here"">
[^]</p>

<p>Next I apply some basic filters to clear out the small blobs and the very big ones. Next I try to find blobs who have their height>width and after that I try to find similar blob sizes and shapes who are one next to another.
This is my approach and in most of the situations works for me. As addition I create histogram of the possible blobs that I may consider as a letter. This means that I look for 2 dominant colors in that rectangle. If the two dominant colors are black(ish) or white(ish) than I know it is a number on the runners shirt.
What I want to know, is there any different approach that you would do? Like mixing channels, converting to HSV space and maybe filtering black colors?
My whole idea is to get those numbers with small amount of blobs that aren't numbers.
I would appreciate any kind of suggestions.
Comments and ideas are just fine, if you want to write code please do.
Thank You...</p>
",2013-09-15 12:36:48,2016-03-25 19:38:47,Filter unwanted blobs (Detect numbers in image),<c#><algorithm><opencv><image-processing><aforge>,,,CC BY-SA 3.0,True,False,True,False,False
14382,22280812,2014-03-09 09:57:20,,"<p>I want to detect face from an input video file using ""haar cascade"". I have converted the video into frames using this code. Please tell me how to detect face from these frames and mark it in a rectangular border. </p>

<pre><code> private void button1_Click(object sender, EventArgs e)
    {
        OpenFileDialog openFileDialog1 = new OpenFileDialog();
        if (openFileDialog1.ShowDialog() == System.Windows.Forms.DialogResult.OK)
        {

                memde = new MediaDetClass();
                System.IO.Directory.CreateDirectory(""temp"");
                memde.Filename = openFileDialog1.FileName;
                int len = (int)memde.StreamLength;
                counter = 0;
                Image img;
                memde.Filename = openFileDialog1.FileName;
                memde.CurrentStream = 0;
                float percent = 0.002f;
                Image&lt;Gray, byte&gt; gray;
                for (float i = 0.0f; i &lt; len; i = i + (float)(percent * len))
                {
                    counter++;
                    string fbitname = storagepath + counter.ToString();
                    memde.WriteBitmapBits(i, 850, 480, fbitname + "".bmp"");

                    }
                }
        }
    }
</code></pre>
",,2020-06-01 11:04:03,Face Detection on a video file,<c#><asp.net><emgucv><face-detection>,,,CC BY-SA 3.0,False,False,True,False,False
14399,16925604,2013-06-04 19:08:23,,"<p>I'm trying to Draw a string that have more than one line at a EmguCV (OpenCV C# wraper) Image. But it seams that EmguCV doesn't recognize the new line ""\r\n"" characters.</p>

<p>How can achieve that? Alternatively, how can I get the text height, so I can set the location for the next string manually?</p>

<pre><code>StringBuilder imageComments = new StringBuilder();
imageComments.AppendLine(""Camera status"");
imageComments.AppendLine(""Shutter: "" + shutter);
Emgu.CV.Image&lt;Gray, Byte&gt; img = new Emgu.CV.Image&lt;Gray, byte&gt;(bmp);
Point location = new Point(30, 30);
MCvFont font = new MCvFont(Emgu.CV.CvEnum.FONT.CV_FONT_HERSHEY_SIMPLEX, 0.3f, 0.3f);
Gray color = new Gray(255);
img.Draw(imageComments.ToString(), ref font, location, color);
</code></pre>
",2013-06-05 13:55:08,2013-06-05 17:11:49,Draw / Write on an image more than one line - EmguCV (OpenCV) does not recognize new line char,<c#><opencv><draw><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
14446,16929190,2013-06-04 23:36:08,,"<p>What is the fastest way to get number of white pixels in a binary picture using OpenCV? Is there something faster than using two for loops and accessing the image pixel by pixel?</p>
",2013-11-19 06:38:40,2013-11-19 06:38:40,Fastest way to get number of white pixels in a binary image using OpenCV,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
14477,16933601,2013-06-05 07:07:12,,"<p>I'm trying to obtain the orientation of a shape (binary or contour). The shape is mostly rectangular but has a large hole on one side. I want my orientation to be consistent with this assymetry in the object.</p>

<p>I've been looking at several articles that use the spatial and central moments for this. E.g. 
<a href=""https://stackoverflow.com/questions/14720722/binary-image-orientation"">Binary Image Orientation</a>
but it seems that the orientation I get with this is sometimes off with a multiple of 90 degrees.</p>

<p>The following document states that there is some ambiguity:
<a href=""http://public.cranfield.ac.uk/c5354/teaching/dip/opencv/SimpleImageAnalysisbyMoments.pdf"" rel=""nofollow noreferrer"">http://public.cranfield.ac.uk/c5354/teaching/dip/opencv/SimpleImageAnalysisbyMoments.pdf</a></p>

<p>If I implement this using</p>

<pre><code>private void GetCenterAndOrientationViaMoments(Contour&lt;Point&gt; cont, Size imageSize)
{
    // obtain the orientation of the found object
    // first draw the binary blob in a separate image 
    // I do this for the hole(s) in the image, but I'm not sure if it is needed. 
    // Possibly I can tak the moments directly from the contour
    Image&lt;Gray, byte&gt; instanceImage = new Image&lt;Gray, byte&gt;(imageSize);
    instanceImage.FillConvexPoly(cont.ToArray(), new Gray(255));
    for (Contour&lt;Point&gt; hole = cont.VNext;
        hole != null;
        hole = hole.HNext)
            instanceImage.FillConvexPoly(hole.ToArray(), new Gray(0));

    // calculate the moments
    MCvMoments m = instanceImage.GetMoments(true);
//  MCvMoments m = cont.GetMoments();

    double m00 = m.GetSpatialMoment(0, 0);
    double m10 = m.GetSpatialMoment(1, 0);
    double m01 = m.GetSpatialMoment(0, 1);

    double mu11 = m.GetCentralMoment(1, 1);
    double mu20 = m.GetCentralMoment(2, 0);
    double mu02 = m.GetCentralMoment(0, 2);

    // calculate the center
    PointF center = new PointF((float)(m10 / m00), (float)(m01 / m00));

    // calculate the orientation
    // http://public.cranfield.ac.uk/c5354/teaching/dip/opencv/SimpleImageAnalysisbyMoments.pdf
    double theta = 0;
    double mu20_mu02 = (mu20 - mu02);
    if ((mu20_mu02 == 0) &amp; (mu11 == 0))
        theta = 0;
    else if ((mu20_mu02 == 0) &amp; (mu11 &gt; 0))
        theta = Math.PI / 4;
    else if ((mu20_mu02 == 0) &amp; (mu11 &lt; 0))
        theta = -Math.PI / 4;
    else if ((mu20_mu02 &gt; 0) &amp; (mu11 == 0))
        theta = 0;
    else if ((mu20_mu02 &lt; 0) &amp; (mu11 == 0))
        theta = -Math.PI / 2;
    else if ((mu20_mu02 &gt; 0) &amp; (mu11 &gt; 0))
        theta = 0.5 * Math.Atan((2 * mu11) / mu20_mu02);
    else if ((mu20_mu02 &gt; 0) &amp; (mu11 &lt; 0))
        theta = 0.5 * Math.Atan((2 * mu11) / mu20_mu02);
    else if ((mu20_mu02 &lt; 0) &amp; (mu11 &gt; 0))
        theta = 0.5 * Math.Atan((2 * mu11) / mu20_mu02) + Math.PI / 2;
    else if ((mu20_mu02 &lt; 0) &amp; (mu11 &lt; 0))
        theta = 0.5 * Math.Atan((2 * mu11) / mu20_mu02) - Math.PI / 2;

#if DEBUG
    int radius = 25;
    instanceImage.Draw(new CircleF(center, radius), new Gray(100), 2);
    instanceImage.Draw(
        new LineSegment2DF(
            center, 
            new PointF(
                (float)(center.X + radius * Math.Cos(theta)), 
                (float)(center.Y + radius * Math.Sin(theta)))), 
        new Gray(100), 
        2);
    ImageViewer.Show(instanceImage, string.Format(""Center and orientation""));
#endif
}
</code></pre>

<p>My orientation is correct, but does not always point to the same end of the object. In other words, I'm sometimes of by 180 degrees.</p>

<p>I'm guessing the method cannot provide exactly what I want because it uses the covariance of the distribution (<a href=""http://en.wikipedia.org/wiki/Image_moments#Examples_2"" rel=""nofollow noreferrer"">http://en.wikipedia.org/wiki/Image_moments#Examples_2</a>) which gives does not take into account the assymmetry caused by the hole, am I right? </p>

<p>Is there a way to resolve the 180 degrees ambiguity?</p>

<p>Regards,
Tom</p>
",2017-05-23 11:52:31,2013-06-05 07:16:04,Orientation of non symmetrical a shape in Emgu or OpenCv,<opencv><image-processing><computer-vision><shape><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
14520,24549885,2014-07-03 09:25:50,,"<p>i have a blood image and i applied watershed on it .. its works and determines the cells but i don't know how to put each cell in a separate image .. i'm working with emgu.cv can i get some help</p>

<p>here i segment the picture using my watershed method and then put the marker on the original image</p>

<pre><code>Image&lt;Gray, Int32&gt; boundaryImage = watershedSegmenter.Process(image);
Image&lt;Gray, Byte&gt; test = watershedSegmenter.GetWatersheds(); Image&lt;Bgr, byte&gt;dest=new Image&lt;Bgr, byte&gt;(image.Width, image.Height);
dest = image.And(image, test);            
pictureBox1.Width = boundaryImage.ToBitmap().Width;
pictureBox1.Height = boundaryImage.ToBitmap().Height;
pictureBox1.BackgroundImage = boundaryImage.ToBitmap();
</code></pre>
",,2014-07-04 12:21:18,separating image after watershed using emgu.cv,<c#><image-processing><emgucv><watershed>,,,CC BY-SA 3.0,False,False,True,False,False
14588,17895807,2013-07-27 08:24:45,,"<p>Is there any way to write H.264/MPEG-4 AVC videos using VideoWriter in EmguCV? I have attempted and it throws an InvalidOperationException where WriteFrame is invoked. By the way I am new to EmguCV. Please help.</p>

<p>here is my code </p>

<pre><code>Image&lt;Bgr, byte&gt; img0 = new Image&lt;Bgr, byte&gt;(""1.jpg"");

VideoWriter v = new VideoWriter(""5.mp4"",-1, 1, 1920, 1080, true);

v.WriteFrame(img0);
</code></pre>
",,2013-10-01 06:31:35,EmguCV write H.264/MPEG-4 AVC files using VideoWriter,<video><h.264><mp4><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
14621,22301008,2014-03-10 13:07:25,,"<p>I've been look ing for a method for connected component labeling in Emgu (c# wrapper for OpenCV). I've failed to find a direct method for such a basic CV strategy. However, I did come across many suggestions for doing it using FindContours and DrawContours but without code examples. So I had a go at it and it seems to work okay.</p>

<p>I'm dropping it here for two reasons. </p>

<ol>
<li>So people searching for it can find a code example. </li>
<li>More importantly, i'm wondering if there are suggestions for optimization and improvements of this function. E.g. is the chain approximation method for FindContours efficient/appropriate? </li>
</ol>

<pre class=""lang-cs prettyprint-override""><code>    public static Image&lt;Gray, byte&gt; LabelConnectedComponents(this Image&lt;Gray, byte&gt; binary, int startLabel)
    {
        Contour&lt;Point&gt; contours = binary.FindContours(
            CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_NONE, 
            RETR_TYPE.CV_RETR_CCOMP);

        int count = startLabel;
        for (Contour&lt;Point&gt; cont = contours;
                    cont != null;
                    cont = cont.HNext)
        {
            CvInvoke.cvDrawContours(
            binary,
            cont,
            new MCvScalar(count),
            new MCvScalar(0),
            2,
            -1,
            LINE_TYPE.FOUR_CONNECTED,
            new Point(0, 0));
            ++count;
        }
        return binary;
    }
</code></pre>
",,2014-04-04 07:49:30,Connected component labeling in Emgu / Opencv,<c#><opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
14645,22302801,2014-03-10 14:22:56,,"<p>on our current project we are using a depth camera mounted on top of the user's head to recognize fingers, hands and touch events. This works quite well and can already be used as a new type of input device.</p>

<p>Our next step is to use augmented reality glasses to display buttons/controls onto the user's palm. For this step we need a transformation of our recognized data (finger tip, corner points of palm quadrangle) to display them onto the correct location on the augmented reality glasses.
In the future we will use a real 3D output scene, but for now we are simply displaying a 2D image with our glasses.
You can imagine the whole setup as a stereo view with the depth camera and the users eyes as cameras.</p>

<p>To get the transformation matrix we successively display a random point on the output image and the user has to hold his finger tip onto that location. By that we get point correspondences between the input image (depth camera) and the output image (augmented reality glasses). We currently use 20 of these correspondences and then use Emgu's FindHomography() method to get the transformation matrix.</p>

<p>For our first effort this already works ok, but it's not perfect. How should we proceed to get better results?</p>

<p><strong>what we have</strong>:</p>

<ul>
<li>2D pixel coordinates in our input image (depth camera 320x240)</li>
<li>3D coordinates (relative to our depth camera)</li>
<li>(corresponding 2D pixel coordinates in output image)</li>
</ul>

<p><strong>what we need</strong>:<br>
A method that maps a 2D pixel coordinate or a 3D coordinate relative to our depth camera to our output image (2D for now, maybe 3D later).</p>

<p><strong>Question:</strong><br>
What type of transformation should we use here? FindHomography(), GetPerspectiveTransformation(), fundamentalMatrix?, essentialMatrix?</p>

<p>Any help/suggestion is greatly appreciated. Thank you in advance!</p>
",,2014-03-10 14:55:46,Augmented Reality Glasses + Depth Camera -> Stereo Vision,<computer-vision><augmented-reality><emgucv><coordinate-transformation><homography>,,,CC BY-SA 3.0,False,False,True,False,False
14651,23448776,2014-05-03 19:18:42,,"<p>Hi i tried compute disparity map using EmguCV, but there must be some bug when i try use StereoBM class, always when i call function FindStereoCorrespondence i will receive this error:</p>

<p>System.AccessViolationException: Attempted to read or write protected memory.</p>

<p>My code is simple:</p>

<pre><code>    private Image&lt;Gray, byte&gt; Computer3DPointsFromStereoPair0(Image&lt;Gray, byte&gt; left, Image&lt;Gray, byte&gt; right)
    {
        Size size = left.Size;
        Image&lt;Gray, short&gt; disparityMap = new Image&lt;Gray, short&gt;(size);
        using (StereoBM stereoSolver = new StereoBM(Emgu.CV.CvEnum.STEREO_BM_TYPE.BASIC, 0)){
            stereoSolver.FindStereoCorrespondence(left, right, disparityMap);
        } 
        return disparityMap.Convert&lt;Gray, byte&gt;();

    }
</code></pre>

<p>I think it can be somewere in OpenCV dll's...</p>

<p>Please if somebody know how to slove that problem!</p>
",,2014-05-03 19:18:42,EmguCV bug using StereoBM class AccessViolationException,<opencv><access-violation><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
14658,23452698,2014-05-04 04:41:13,,"<p>I'm trying to give certain colors to image based on their movement (like vector direction) in Emgu Cv. I have managed to calculate the dense optical flow to my video stream. I have used this</p>

<pre><code>OpticalFlow.Farneback(prev,NextFrame,velx,vely,0.5,1,1,2,5,1.1,Emgu.CV.CvEnum.OPTICALFLOW_FARNEBACK_FLAG.FARNEBACK_GAUSSIAN);
</code></pre>

<p>The variable vely and velx contains the velocity of vertical and horizontal directions.Does anyone know how to map colors to these. There are many algorithms that calculates the dense flow. HS also can be used, but I'm not sure what to use.
Any solution would be really appreciated.</p>

<p>EDIT:</p>

<p><a href=""https://stackoverflow.com/questions/20737580/optical-flow-color-map-in-opencv"">Optical Flow Color Map in OpenCV</a></p>

<p>This is the same thing that i wanted, since I'm using Emgu cv I tried to convert this code to c# but I cannot understand how to pass the dense flow to function ""colorflow"".</p>

<pre><code>public void colorflow(MCvMat imgColor)
  {
      MCvMat imgHsv = new MCvMat();
      double max_s = 0;
      double[] hsv_ptr = new double[3000];
      IntPtr[] color_ptr = new IntPtr[3000];
      int r = 0, g = 0, b = 0;
      double angle = 0;
      double h = 0, s = 0, v = 0;
      double deltaX = 0, deltaY = 0;
      int x = 0, y = 0;

      for (y = 0; y &lt; imgColor.rows; y++)
      {
          for (x = 0; x &lt; imgColor.cols; x++)
          {
              PointF fxy = new PointF(y, x);                  
              deltaX = fxy.X;
              deltaY = fxy.Y;
              angle = Math.Atan2(deltaX, deltaY);

              if (angle &lt; 0)
                  angle += 2 * Math.PI;

              hsv_ptr[3 * x] = angle * 180 / Math.PI;
              hsv_ptr[3 * x + 1] = Math.Sqrt(deltaX * deltaX + deltaY * deltaY);
              hsv_ptr[3 * x + 2] = 0.9;

              if (hsv_ptr[3 * x + 1] &gt; max_s)
                  max_s = hsv_ptr[3 * x + 1];
          }

      }
      for (y = 0; y &lt; imgColor.rows; y++)
      {
          //hsv_ptr=imgHsv.ptr&lt;float&gt;(y);
          //color_ptr=imgColor.ptr&lt;unsigned char&gt;(y);



          for (x = 0; x &lt; imgColor.cols; x++)
          {
              h = hsv_ptr[3 * x];
              s = hsv_ptr[3 * x + 1] / max_s;
              v = hsv_ptr[3 * x + 2];

              //hsv2rgb(h,s,v,r,g,b);
              Color c = ColorFromHSV(h, s, v);

              color_ptr[3 * x] = (IntPtr)c.B;
              color_ptr[3 * x + 1] = (IntPtr)c.G;
              color_ptr[3 * x + 2] = (IntPtr)c.R;
          }
      }


     drawLegendHSV(imgColor, 15, 25, 15);
  }
</code></pre>

<p>I having trouble how to covert the two commented lines in the code. Can anyone Help me with this.?</p>

<p>Another thing that the Farneback algorithm gives two  images velx and vely. It does not gives the flow( MCvMat). The colorFlow algorithms it takes the MCvMat type parameters.Did i done any wrong with the code. thanks</p>
",2017-05-23 12:03:52,2014-05-04 11:25:49,how to Color map to dense optical flow,<c#><emgucv><opticalflow>,,,CC BY-SA 3.0,True,False,True,False,False
14746,16958834,2013-06-06 09:45:16,,"<p>I´m trying to make some kind of image ranking depending on histogram similarities. I take an image, and need to compare its histogram with a database of images ordering them depending in how similar are to the source image. This should work like a filter, taking a subgroup with the most similar images and then compare them with other methods more accurate and computing expensive (Pattern match, SURF, etc...).</p>

<p>The idea behind this is that some images have, for example, lots of blue, and in the library there are 6 images with lots of blue, so it would rank those images the higher. Other images have lots of yellow (blue and green)...</p>

<p>At this point my code is this:</p>

<pre><code>Image&lt;Bgr, byte&gt; colorCard = frame.Copy();

DenseHistogram histBlue = new DenseHistogram(256, new RangeF(0.0f, 255.0f));
DenseHistogram histRed = new DenseHistogram(256, new RangeF(0.0f, 255.0f));
DenseHistogram histGreen = new DenseHistogram(256, new RangeF(0.0f, 255.0f));

Image&lt;Gray, byte&gt; imgBlue = colorCard[0];
Image&lt;Gray, byte&gt; imgRed = colorCard[1];
Image&lt;Gray, byte&gt; imgGreen = colorCard[2];
imgBlue._EqualizeHist();
imgRed._EqualizeHist();
imgGreen._EqualizeHist();
//Also tried whithout equalizing histograms

histBlue.Calculate(new Image&lt;Gray, byte&gt;[] { imgBlue }, true, null);
histRed.Calculate(new Image&lt;Gray, byte&gt;[] { imgRed }, true, null);
histGreen.Calculate(new Image&lt;Gray, byte&gt;[] { imgGreen }, true, null);

List&lt;Match&gt; matchList = new List&lt;Match&gt;();

foreach (String filename in image_paths)
{
    Image&lt;Bgr, byte&gt; imgToCompare = new Image&lt;Bgr, byte&gt;(filename);
    imgToCompare = imgToCompare.PyrDown().PyrUp().PyrDown().PyrUp();

    DenseHistogram histBlueToCompare = new DenseHistogram(256, new RangeF(0.0f, 255.0f));
    DenseHistogram histRedToCompare = new DenseHistogram(256, new RangeF(0.0f, 255.0f));
    DenseHistogram histGreenToCompare = new DenseHistogram(256, new RangeF(0.0f, 255.0f));

    Image&lt;Gray, byte&gt; imgBlueToCompare = colorCard[0];
    Image&lt;Gray, byte&gt; imgRedToCompare = colorCard[1];
    Image&lt;Gray, byte&gt; imgGreenToCompare = colorCard[2];
    imgBlueToCompare._EqualizeHist();
    imgRedToCompare._EqualizeHist();
    imgGreenToCompare._EqualizeHist();

    histBlueToCompare.Calculate(new Image&lt;Gray, byte&gt;[] { imgBlueToCompare }, true, null);
    histRedToCompare.Calculate(new Image&lt;Gray, byte&gt;[] { imgRedToCompare }, true, null);
    histGreenToCompare.Calculate(new Image&lt;Gray, byte&gt;[] { imgGreenToCompare }, true, null);

    double cBlue = CvInvoke.cvCompareHist(histBlue, histBlueToCompare, Emgu.CV.CvEnum.HISTOGRAM_COMP_METHOD.CV_COMP_CORREL);
    double cRed = CvInvoke.cvCompareHist(histRed, histRedToCompare, Emgu.CV.CvEnum.HISTOGRAM_COMP_METHOD.CV_COMP_CORREL);
    double cGreen = CvInvoke.cvCompareHist(histGreen, histGreenToCompare, Emgu.CV.CvEnum.HISTOGRAM_COMP_METHOD.CV_COMP_CORREL);

    double matchValue = (cBlue + cGreen + cRed) / 3.0;

    matchList.Add(new Match(matchValue, Path.GetFileNameWithoutExtension(filename)));
}

matchList = matchList.OrderBy(X =&gt; X.MatchValue).ToList&lt;Match&gt;();
foreach (Match m in matchList)
{
    Logger.Log(m.Card + "": "" + m.MatchValue);
}
</code></pre>

<p>I can compare each color histogram, but don't know how to merge this comparisons to get a single value. Witch <code>(cBlue + cGreen + cRed) / 3.0</code> I don't get good results.</p>

<p>I read a method to do this is the Earth Mover Distance (EMD). EmguCV has a function called <code>cvCalcEMD2</code>, but I have no idea how to use (what do the parameters mean) it and can't find an example of its usage.</p>
",,2017-12-21 07:45:58,BGR Histogram comparison using EmguCV,<c#><histogram><emgucv><bgr>,,,CC BY-SA 3.0,False,False,True,False,False
14834,22315838,2014-03-11 03:25:28,,"<p>I already know how to convert an image to grayscale using EMGU CV.</p>

<p>This is the example code:</p>

<pre><code>Image&lt;Gray, byte&gt; sourceimage = new Image&lt;Gray, byte&gt;(Group[i]);
</code></pre>

<p>This function converts the image to grayscale.</p>

<p>I want to know what calculation EMGU CV uses to convert an RGB image to grayscale, like Red * A + Green * B + Blue * C = Gray intensity.</p>

<p>So what are A, B and C?</p>
",2014-04-04 10:54:59,2014-04-04 10:54:59,How does EMGU CV convert an RGB image to grayscale?,<image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
14850,17916843,2013-07-29 05:48:22,,"<p>I am working on an algorithm to extract diffrences between two images with diffrent qualities for example you have a photoshop file which is created by a designer and then you print it out with some devices and you have scaned it and saved it as a bmp file.
the main question is how we can compare these two images?
it is not possible two compare pixel by pixel, because in scaned version many objects have changed for example lines become thicker.
my idea is to find any shapes in two images then compare them based on location and other shape featurs but the main problem is that in low quality images it become too difficult to compare.because in low quality we have noise and after noise canceling some shapes will be lost. for example when i use open and close or morphology filters i lose some characters such as ""i Q O 0"" or other shapes.what is your opinion ?</p>
",,2013-07-29 06:25:40,compare two images with low quality,<c#><image><opencv><compare><emgucv>,2013-07-29 09:37:39,,CC BY-SA 3.0,True,False,True,False,False
14880,24580940,2014-07-04 21:31:42,,"<p>I'm writing a simple OpenCV application using .NET which the goal is to render the webcam stream on a simple window.</p>

<p>Here's the code I use to do this:</p>

<pre><code>private static BitmapSource ToBitmapSource(IImage image)
{
    using (System.Drawing.Bitmap source = image.Bitmap)
    {
        IntPtr ptr = source.GetHbitmap();
        BitmapSource bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
            ptr,
            IntPtr.Zero,
            Int32Rect.Empty,
            System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions());
        DeleteObject(ptr);
        return bs;
    }
}

private void CameraShow()
{
    ImageViewer viewer = new Emgu.CV.UI.ImageViewer(); //create an image viewer
    Capture capture = new Capture(); //create a camera captue

    this.isCamOff = false;
    while (this.CamStat != eCamRun.CamStop)
    {
        Thread.Sleep(60);
        viewer.Image = capture.QueryFrame(); //draw the image obtained from camera
        System.Windows.Application.Current.Dispatcher.Invoke(
            DispatcherPriority.Normal,
            (ThreadStart)delegate
        {
            this.ImageStream.Source = ToBitmapSource(viewer.Image); //BitmapSource
        });
    }

    viewer.Dispose();
    capture.Dispose();
    this.isCamOff = true;
    Thread.CurrentThread.Interrupt();
}
</code></pre>

<p>But now I want to display on the console the content of the pixel buffer contained into the System.Drawing.Bitmap object (I know the void* native type is contained into the IntPtr variable into the Bitmap object). So according to my source code just below to recover the IntPtr variable I have to write the following line of code (into an 'unsafe' context):</p>

<pre><code>IntPtr buffer = viewer.Image.Bitmap.GetHbitmap();

byte[] pPixelBuffer = new byte[16]; //16 bytes allocation
Marshal.Copy(buffer, pPixelBuffer, 0, 9); //I copy the 9 first bytes into pPixelBuffer
</code></pre>

<p>Unfortunately, I have an Access Violation Exception into the method 'Copy'! And I don't understand why.</p>

<p>Does anyone can help me, please ?</p>

<p>Thanks a lot in advance for your help.</p>
",2014-07-05 00:48:41,2014-07-05 00:48:41,Access Violation Exception using the method Marshal.Copy(),<c#><emgucv><intptr><opencvsharp>,,,CC BY-SA 3.0,True,False,True,False,False
14891,20028788,2013-11-17 08:36:48,,"<p>How can I implement background subtraction to a static picture taken from a webcam?
I've read some post that says to take a look at the example &quot;Motion Detection&quot; of EmguCV</p>
<p>would it be still applicable if I used it in an image?</p>
<p>Example:</p>
<p><a href=""https://i.stack.imgur.com/0Mqnp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0Mqnp.png"" alt=""example pic"" /></a></p>

<p>(Sorry for poor English)</p>
",2020-06-20 09:12:55,2019-09-09 01:08:55,Image Background Subtraction using EmguCv,<image-processing><emgucv><background-subtraction>,,,CC BY-SA 4.0,False,False,True,False,False
14903,21188520,2014-01-17 14:41:09,,"<p>I'm working on a project with EmguCV (.NET-version of OpenCV) and I'm using the probabilistic Hough Transformation to find lines.</p>

<p>So at first I was performing the canny-operator. Afterwards doing the Hough-transformation.</p>

<pre><code>Gray cannyThreshold = new Gray(50);
Gray cannyThresholdLinking = new Gray(300);

Image&lt;Gray, Byte&gt; cannyEdges = gray.Canny(cannyThreshold, cannyThresholdLinking);

LineSegment2D[] linesFound_temporary = cannyEdges.HoughLines
(
    cannyThreshold,         // 1. Parameter
    cannyThresholdLinking,  // 2. Parameter
    1,                      // 3. Parameter
    Math.PI / 360.0,        // 4. Parameter
    gray.Width * 0.2,       // 5. Parameter
    gray.Width * 0.4,       // 6. Parameter
    gray.Width * 0.1        // 7. Parameter
)[0];
</code></pre>

<p>Later I realised that the HoughLines-Method already integrated the canny edge detection.</p>

<p>Nevertheless, my results in line-detection are better and more steady when I use the additional canny detection instead of leaving it out.</p>

<p>Can anyone explain to me, why this happens? Or has anyone experienced the same?</p>
",2017-03-03 05:17:35,2017-03-03 05:17:35,Perform Canny Edge Detection twice --> better line-detection?,<emgucv><edge-detection><hough-transform>,,,CC BY-SA 3.0,True,False,True,False,False
14929,20030962,2013-11-17 13:03:59,,"<p>i am feeling difficulty in applying sobel operator in c# using emguCv.
your kind comments would be quite valuable help for me in this regard.</p>

<p>here is the code::</p>

<pre><code>Image&lt;Bgr, Byte&gt; imOriginal;
Image&lt;Bgr, Byte&gt; imgProcessed;
Image&lt;Gray, Byte&gt; imgProcessed1;
Image&lt;Gray, Byte&gt; imEdge;



imgProcessed = imgProcessed.SmoothGaussian(9);
imgProcessed1= imgProcessed.Convert&lt;Gray,byte&gt;();
imEdge = (imgProcessed1.Sobel(1, 0, 3));
</code></pre>

<p>Error   2   </p>

<blockquote>
  <p>Cannot implicitly convert type
  '<code>Emgu.CV.Image&lt;emgu.cv.structure.gray,float&gt;</code>' to
  '<code>Emgu.CV.Image&lt;emgu.cv.structure.gray,byte&gt;</code></p>
</blockquote>

<p>thanx in advance.</p>

<p>regards 
baltee</p>
",2013-11-17 13:31:44,2014-03-23 14:51:32,How to use sobel operator in C# using emgu cv?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
14952,23476215,2014-05-05 15:26:49,,"<p>Does anyone know how to normalize angle to [0,360] and length to [0,1] in c#.</p>

<p>please refer the link below, I'm trying to implement the second step in the answer.</p>

<p><a href=""https://stackoverflow.com/questions/10014776/how-should-i-use-the-velx-vely-information-to-get-the-displacement-in-x-and-y-be"">how should I use the velX,velY information to get the displacement in X and Y between current frame and previous frame?</a></p>

<pre><code> angle1 = Math.Atan2(h.Intensity, g.Intensity);
 if(angle1 &lt; 0)
 {
       angle1 += 2 * Math.PI;
 }
</code></pre>

<p>Is this the right way, Any suggestions please? Can i use Math.round function instead?</p>
",2017-05-23 11:57:29,2014-05-05 15:36:06,Normalize angle and length in c#,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
14974,22329420,2014-03-11 14:56:07,,"<p>I am pretty new to EMGUCV . I want to make a face recognition system , I had implemented it but the results are not acceptable. Here is my code for the recognition :</p>

<pre><code>public List&lt;Person&gt; RecognizeFaces(List&lt;Image&lt;Bgr, byte&gt;&gt; faces)
{
        List&lt;Person&gt; RecognizedPersons = new List&lt;Person&gt;();
        MCvTermCriteria termCrit = new MCvTermCriteria(TrainDB.Count, 0.001);

        EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
         this.ToGrayList(this.TrainDB),
         labels.ToArray(),
         7000,  // I changed this argument many times but nothing has changed (1000, 2000, ...
         ref termCrit);

        string label = """";
        for (int i = 0; i &lt; faces.Count; i++)
        {
            label = recognizer.Recognize(faces[i].Convert&lt;Gray, byte&gt;());
            RecognizedPersons.Add(new Person(faces[i],!label.Equals("""") ? label : ""unknown""));
        }

        return RecognizedPersons;
}
</code></pre>

<p>This function takes a list of previously detected faces from an input image and returns a list of Type <code>Person</code> where each person contains an image and a label to the recognized person .
My Question is why the results are not good ? is there is something wrong with my code ? Or there is something wrong with the training set <code>TrainDB</code> , if so , what is the best guidelines to follow when creating the training set ?</p>

<p>I had collected the training set according to this :
1- Applying face detection (using EMGU) on an image that's contain a single person 
2- Then I resize the detected face to 200 : W, 200 : H </p>

<p>Some images from my training set :</p>

<p><img src=""https://i.stack.imgur.com/VRhZd.jpg"" alt=""enter image description here""></p>

<p><img src=""https://i.stack.imgur.com/wDS85.jpg"" alt=""enter image description here""></p>

<p>Some Examples of test images :</p>

<p><img src=""https://i.stack.imgur.com/cWWPe.jpg"" alt=""enter image description here""></p>

<ul>
<li>List item</li>
</ul>

<p><img src=""https://i.stack.imgur.com/wsQGx.png"" alt=""enter image description here""></p>

<p><img src=""https://i.stack.imgur.com/1K2Ox.jpg"" alt=""enter image description here""></p>

<p>My last question .. do Emgu/OpenCv are powerful tools to be used in face recognition ? or there is something else that could be more accurate in results ?</p>
",2014-03-13 00:42:51,2020-04-17 12:51:02,Face recognition Using EigenObjectRecognizer,<opencv><image-processing><computer-vision><emgucv><face-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
14987,16980195,2013-06-07 09:02:25,,"<p>I have written the code for face detection using OpenCV. I have video file and I am extracting images from the video based on specific given interval and running the face detection on each images. so there might be an instances where person is standing in front of camera for 5 minutes and image extraction interval is 1 min so for next 5 images the person would be the same. So how would i find out whether in each image person is same or the different one ? below is the code for face detect:</p>

<pre><code>private static Rectangle[] DetectFace(Image&lt;Bgr, Byte&gt; image, string faceFileName)
        {           
            if (GpuInvoke.HasCuda)
            {
                using (GpuCascadeClassifier face = new GpuCascadeClassifier(faceFileName))
                {
                    using (GpuImage&lt;Bgr, Byte&gt; gpuImage = new GpuImage&lt;Bgr, byte&gt;(image))
                    using (GpuImage&lt;Gray, Byte&gt; gpuGray = gpuImage.Convert&lt;Gray, Byte&gt;())
                    {
                        Rectangle[] faceRegion = face.DetectMultiScale(gpuGray, 1.1, 10, Size.Empty);

                        return faceRegion;
                    }
                }
            }
            else
            {
                //Read the HaarCascade objects
                using (CascadeClassifier face = new CascadeClassifier(faceFileName))
                {

                    using (Image&lt;Gray, Byte&gt; gray = image.Convert&lt;Gray, Byte&gt;()) //Convert it to Grayscale
                    {
                        //normalizes brightness and increases contrast of the image
                        gray._EqualizeHist();                       

                        //Detect the faces  from the gray scale image and store the locations as rectangle
                        //The first dimensional is the channel
                        //The second dimension is the index of the rectangle in the specific channel
                        Rectangle[] facesDetected = face.DetectMultiScale(
                           gray,
                           1.1,
                           10,
                           new Size(filterWidth, filterHeight),
                           Size.Empty);

                        return facesDetected;
                    }
                }
            }
        }
</code></pre>
",2014-03-06 17:33:31,2014-03-06 17:33:31,code to generate unique ID for face recognition using OpenCV,<opencv><image-processing><emgucv>,2013-06-07 13:38:30,,CC BY-SA 3.0,True,False,True,False,False
15077,23486253,2014-05-06 04:57:33,,"<p>I want to process image with pointer to make it faster.At first,I do it like this</p>

<pre><code>unsafe
    {
        double a = 288 / 55;
        double b = -215 * 288 / 55;
        MIplImage ss = diff.MIplImage;
        for (int i = 0; i &lt; ss.height; i++)
        {
            IntPtr ptr = ss.imageData + i * ss.widthStep;
            for (int j = 0; j &lt; ss.width; j++)
            {
                if (a * j - i + b &gt; 0)
                    ((byte*)(ptr))[j] = 0;
            }
        }
    }
</code></pre>

<p>and it performs well(0.5ms while 4ms without pointer).</p>

<p>Then I find that the managed objects should be fixed to prevent relocation.So I think it would be like this</p>

<pre><code>Image&lt;Gray, byte&gt; diff = new Image&lt;Gray, byte&gt;(frame.Width,frame.Height);
fixed (void* p_temp=diff.Ptr.ToPointer()){}
</code></pre>

<p>or</p>

<pre><code>fixed (byte* p_temp=(byte*)temp.Ptr){}
</code></pre>

<p>But it is wrong.So how to fix the Image? And how to use pointer with emgucv? I am really confused.Thanks!</p>

<pre><code>unsafe
        {
            var data = diff.Data;
            int stride = diff.MIplImage.widthStep;
            byte* p;
            fixed (byte* pData = data)
            {
                for (int i = 0; i &lt; diff.Height; i++)
                {
                    p = pData + i * stride;
                    for (int j = 0; j &lt; diff.Width; j++)
                    {
                        if (a * j - i + b &gt; 0)
                            *(p + j) = (byte)0;
                    }

                }
            }
        }
</code></pre>
",2014-05-06 12:42:59,2014-05-06 12:42:59,How to use pointer to process image with c# and emgucv?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
15099,16988713,2013-06-07 16:19:24,,"<p>I'm using OpenCV/EmguCV to perform a naive matching procedure. I've two images, img1 and img2, and I enumerate the translations and rotations of img1, and match against img2 to find the optimal matched difference.</p>

<p>Here's the code</p>

<pre><code>        for (int dx = -img2.Width / 2; dx &lt;= img1.Width - img2.Width / 2; dx++)
            for (int dy = -img2.Height / 2; dy &lt;= img1.Height - img2.Height / 2; dy++)
                for (float r = 0; r &lt; 2 * Math.PI; r += 0.1f)
                {
                    var img2r = img2.Rotate(r, new Gray(0));
                    img1.ROI = new Rectangle(Math.Max(0, dx), Math.Max(0, dy),
                        (Math.Min(dx + img2r.Width, img1.Width) - Math.Max(dx, 0)),
                        (Math.Min(dy + img2r.Height, img2.Height) - Math.Max(dy, 0))
                        );
                    img2.ROI = new Rectangle(Math.Max(0, -dx), Math.Max(0, -dy),
                        (Math.Min(dx + img2r.Width, img1.Width) - Math.Max(dx, 0)),
                        (Math.Min(dy + img2r.Height, img2.Height) - Math.Max(dy, 0))
                        );

                    var diff = img1.AbsDiff(img2);
                    var avg = diff.GetAverage();

                    img1.ROI = new Rectangle();
                    img2.ROI = new Rectangle();
                }
</code></pre>

<p>So my questions are</p>

<p>1) Do we have a built-in function to do this, For efficiency concerns?</p>

<p>2) How to perform a ""sub-pixel"" level of this matching?</p>

<p>3) Can we harness fft to accelerate the match to O(nlogn) by converting into frequency domain?</p>

<h1>Note</h1>

<p>cvMatchShape() won't make it because I'm doing naive matching. The two images are quite similar.</p>
",,2013-06-07 16:19:24,Opencv naive image match,<opencv><image-processing><fft><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
15100,16988985,2013-06-07 16:35:32,,"<p>I'm using EmguCV in VS2012. </p>

<p>Following <a href=""http://www.emgu.com/wiki/index.php/Debugger_Visualizer"" rel=""nofollow"">this tutorial</a>, I copied the dlls into VS debugger directory. However when I click the ""view"" icon on the variable, there's an error like this:</p>

<pre><code>Unable to load DLL 'opencv_core249'
</code></pre>

<p>And other parts of the program just works fine.</p>

<p>Any idea on this?</p>
",,2018-10-03 09:27:33,EmguCV vs2012 visualizer,<visual-studio-2012><visual-studio-debugging><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
15123,20046551,2013-11-18 11:23:33,,"<p>I want to develop an app for Face detection and recognition from a given photo based on the photos in trained set.</p>

<p>Will it possible to do it on windows phone 7 ?</p>

<p>Could you please tell me the Open CV support for windows?</p>

<p>Please help me</p>
",,2013-11-18 13:27:53,Is Face recognition possible in windows phone,<windows><windows-phone-7><windows-phone-8><emgucv><opencvsharp>,,,CC BY-SA 3.0,False,False,True,False,False
15136,17941980,2013-07-30 08:30:01,,"<p>i am running face detection in emgucv. I used this code but it is not working...
i mean that it doesnot detect ant face and returns ZERO faces.
its getting me crazy because i tried every thing.</p>

<p>my system is X64 and Win7.
""i thought there must be a bug in emgu code"".</p>

<p>please for the sake of god some on help me!</p>

<pre><code>namespace WindowsFormsApplication1
{
    public partial class Form1 : Form
    {
        public Form1()
        {
            InitializeComponent();
        }

        private void button1_Click(object sender, EventArgs e)
        {
            HaarCascade haar = new HaarCascade(""haarcascade_frontalface_alt_tree.xml"");

            Image&lt;Bgr, Byte&gt; image = new Image&lt;Bgr, byte&gt;(""lena.jpg"");

            Image&lt;Gray, Byte&gt; gray = image.Convert&lt;Gray, Byte&gt;();     

            var faces = gray.DetectHaarCascade(haar,1.4, 4,HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,new Size(30,30))[0];

            foreach (var face in faces)

                image.Draw(face, new Bgr(255, 0, 0), 3);

            MessageBox.Show(faces.Length.ToString());

            pictureBox1.Image = image.ToBitmap();

        }
    }
}
</code></pre>

<p>help,help,...</p>
",2013-07-30 09:42:54,2013-11-27 07:49:31,Face Detection in EmguCV ( a bug in X64 ),<c#><opencv><emgucv><face-detection>,,,CC BY-SA 3.0,True,False,True,False,False
15143,22341732,2014-03-12 03:57:12,,"<p>I have created an OCR using tesseract but it is not running on other systems. I made this app in windows 7 (x64) using x86 debug. Till now I was able to run it on windows 8 having at least intel hd graphics. I am unable to run it on windows 7(even with graphic card), windows xp.</p>

<p>I  get an error of initialize in incorrect format
I get an error type initializer for EMGU.CV.OCR.Tesseract threw an exception
Please help me out.
thank you in advance.</p>
",,2014-03-12 03:57:12,Tesseract application not running on other PC,<c#><tesseract><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
15214,17949666,2013-07-30 14:20:57,,"<p>I can get contours in Image with help of FindContours() EMGU function,
but I need to get from my image all kinds of contours , not just closed contours(lines, arcs, etc.)</p>

<p>Is there some sort of function that can perform strokes segmentation.</p>

<p>Thank you in advance.</p>
",,2013-07-30 14:20:57,Function that can perform segmentation on EMGU image,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
15234,17001324,2013-06-08 16:01:53,,"<p>i need to compare two images and identify differences on them as percentage. ""Absdiff"" function on emgucv doesn't help with that. i already done that compare example on emgucv wiki.  what i exactly want is how to get two image difference in numerical format?</p>

<pre><code>//emgucv wiki compare example

//acquire the frame
Frame = capture.RetrieveBgrFrame(); //aquire a frame
 Difference = Previous_Frame.AbsDiff(Frame);
//what i want is
double differenceValue=Previous_Frame.""SOMETHING"";
</code></pre>

<p>if you need more detail plz ask.
Thanks in advance.</p>
",2013-06-08 16:12:10,2020-08-04 17:20:36,Measure difference of two images using emgucv,<c#><image-processing><compare><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
15263,17004480,2013-06-08 22:25:35,,"<p>I am trying to get and set pixels of a gray scale image by using emgu Cv with C#. 
If I use a large image size this error message occurs: ""Index was outside the bounds of the array."" </p>

<p>If I use an image 200x200 or less then there is no error but I don't understand why. </p>

<p>Following is my code:</p>

<pre><code> Image&lt;Gray , byte&gt; grayImage;
--------------------------------------------------------------------

        for (int v = 0; v &lt; grayImage.Height; v++)
        {
            for (int u = 0; u &lt; grayImage.Width; u++)
            {
                byte a = grayImage.Data[u , v , 0]; //Get Pixel Color | fast way
                byte b = (byte)(myHist[a] * (K - 1) / M);
                grayImage.Data[u , v , 0] = b; //Set Pixel Color | fast way
            }
        }
--------------------------------------------------------------------
</code></pre>

<p><a href=""http://i306.photobucket.com/albums/nn262/neji1909/9-6-25565-10-39.png"" rel=""nofollow"">http://i306.photobucket.com/albums/nn262/neji1909/9-6-25565-10-39.png</a></p>

<p>Please help me and sorry I am not good at English.</p>
",2013-06-08 23:07:45,2013-06-30 11:18:20,Get and Set Pixel Gray scale image Using Emgu CV,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
15284,22354916,2014-03-12 14:39:36,,"<p>I am trying to use the Capture class from EmguCV on Unity Pro but everytime I call its constructor, I have the following error:</p>

<blockquote>
  <p>DllNotFoundException: opencv_core249
  Emgu.CV.CvInvoke..cctor ()
  Rethrow as TypeInitializationException: An exception was thrown by the type initializer for Emgu.CV.CvInvoke
  Emgu.CV.Capture..ctor (Int32 camIndex)</p>
</blockquote>

<p>I've read that to solve the problem on Visual Studio for example, you just have to copy and paste the opencv_coreXXX and opencv_highguiXXX to the output folder but this solution doesn't seem to work with Unity. </p>

<p>The problem is that Unity is searching in the right folder (the output folder where I put all the EmguCV dll's) but doesn't seem to find the dll.</p>

<p>To install EmguCV in Unity, I've just followed the steps described by this guy on the following link: <a href=""http://forum.unity3d.com/threads/182600-OpenCV-(EMGUCV-wrapper)-integration-in-Unity"" rel=""nofollow"">http://forum.unity3d.com/threads/182600-OpenCV-(EMGUCV-wrapper)-integration-in-Unity</a></p>
",2014-03-12 15:39:20,2014-03-13 08:10:09,DllNotFoundException with EmguCV on Unity,<c#><unity3d><emgucv><dllnotfoundexception>,,,CC BY-SA 3.0,True,False,True,False,False
15310,21226518,2014-01-20 04:56:44,,"<p>I'm working in image processing in C# and I have two major error:</p>

<ol>
<li>Error: Named argument specifications must appear after all fixed arguments have been specified  </li>
<li>Error: System.Drawing.Size' is a 'type' but is used like a 'variable'   </li>
</ol>

<p>This is my code:   </p>

<pre><code>using System;

using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.Util;
using Emgu.CV.CvEnum;
using Emgu.CV.GPU;
using Emgu.CV.UI;


namespace SNAKE_C_Sharp
{
    public partial class Form1 : Form
    {
        public Form1()
        {
            InitializeComponent();
        }

        private void imageBox1_Click(object sender, EventArgs e)
        {

         }

        private void Form1_Load(object sender, EventArgs e)
        {

       }

        private void button1_Click(object sender, EventArgs e)
        {
           using (OpenFileDialog dialog = new OpenFileDialog())
        {
                dialog.Filter =  ""(*.*)|*.*"";
                if (dialog.ShowDialog() == DialogResult.OK)
                {
                   pictureBox1.SizeMode = PictureBoxSizeMode.StretchImage;
                   Image image = Image.FromFile(dialog.FileName);

                    pictureBox1.Image = image;

               }
           }

       }

       private void button2_Click(object sender, EventArgs e)
       {
           this.Close();

        }
       struct parameter
       {
           public double alpha { get; set; }
           public double beta { get; set; }
           public double gamma { get; set; }
       };
       unsafe private void button3_Click(object sender, EventArgs e)
       {
        {

                int length = 1000;
                MCvPoint2D64f* contour;

                MCvPoint2D64f center = new MCvPoint2D64f();
                var snake_param = new List&lt;parameter&gt;();
                snake_param.Add(new parameter { alpha = 0.1, beta = 0.1, gamma = 0.1,          });
                //Image src_img = pictureBox1.Image;
                IntPtr dst_img = new IntPtr();
                //IntPtr src_img = Emgu.CV.CvInvoke.cvLoadImage(""pictureBox1.Image"",     Emgu.CV.CvEnum.LOAD_IMAGE_TYPE.CV_LOAD_IMAGE_COLOR);
                Bitmap bitmapp = new Bitmap(""pictureBox1.Image"");

                Image&lt;Bgr, byte&gt; image = new Image&lt;Bgr, byte&gt;(bitmapp);




                center.x = image.Width;
                center.y = image.Height;




                int i;
                for (i = 0; i &lt; length; i++)
                {
                    contour[i].x = (int)(center.x * Math.Cos(2 * Math.PI * i / length) + center.x);
                    contour[i].y = (int)(center.y * Math.Sin(2 * Math.PI * i / length) + center.y);
            }




               for (i = 0; i &lt; length - 1; i++)
                {
                CvInvoke.cvLine(dst_img, contour[i], contour[i + 1], new MCvScalar(255, 0, 0), 2, lineType: LINE_TYPE.EIGHT_CONNECTED,0);
            }


                CvInvoke.cvLine(dst_img, contour[length - 1], contour[0], new   MCvScalar(255, 0, 0), 2, lineType: LINE_TYPE.EIGHT_CONNECTED, 0);




                IntPtr src_img = image.Ptr;

                CvInvoke.cvSnakeImage(src_img, contour, length, snake_param[1].alpha,   snake_param[2].beta, snake_param[3].gamma, 1.0f, contour[i], System.Drawing.Size(15, 15),   new MCvTermCriteria(1, 0.0), true);

                CvInvoke.cvCvtColor(src_img, dst_img, COLOR_CONVERSION.GRAY2RGB);


                for (i = 0; i &lt; length - 1; i++)
                {
                    CvInvoke.cvLine(dst_img, contour[i], contour[i + 1], new MCvScalar(255, 0, 0), 2, lineType: LINE_TYPE.EIGHT_CONNECTED, 0);
                }
                CvInvoke.cvLine(dst_img, contour[length - 1], contour[0], new MCvScalar(255, 0, 0), 2, lineType: LINE_TYPE.EIGHT_CONNECTED, 0);
                pictureBox2.SizeMode = PictureBoxSizeMode.StretchImage;

                Bitmap bitmappbb = new Bitmap(""dst_img"");
                Image&lt;Bgr, byte&gt; imagee = new Image&lt;Bgr, byte&gt;(bitmapp);
                pictureBox2.Image = bitmappbb;
           }

        }

         private void imageBox1_Click_1(object sender, EventArgs e)
        {

        }

         private void panAndZoomPictureBox1_Click(object sender, EventArgs e)
        {

        }

        private void imageBox1_Click_2(object sender, EventArgs e)
        {

        }


    }
}    
</code></pre>

<p>How can i adjust above error?</p>
",,2014-01-21 06:24:43,Named argument specifications must appear after all fixed arguments have been specified,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
15395,18898436,2013-09-19 15:09:43,,"<p>""Attempted to read or write protected memory. This is often an indication that other memory is corrupt."" getting this error when i am trying to store the frame by calling <strong>RetrieveBgrFrame()</strong> method.
Actually i am trying to open a medial file and when ImageGrabbed event got file try to store it in image variable for further procesing 
File Type Dummy.avi
Here is my Code:</p>

<pre><code>public partial class CameraCapture : Form
{
  private Capture _capture = null;
  private bool _captureInProgress;


  public CameraCapture()
  {
     InitializeComponent();
     try
     {
        _capture = new Capture(@""D:\imageprocessing\CapturedImages\CameraSample-1.avi"");
        _capture.ImageGrabbed += ProcessFrame;
     }
     catch (NullReferenceException excpt)
     {
        MessageBox.Show(excpt.Message);
     }
  }

  private void ProcessFrame(object sender, EventArgs arg)
  {
     **Image&lt;Bgr, Byte&gt; frame = _capture.RetrieveBgrFrame();**
     *//Here is the Error*        

     Image&lt;Gray, Byte&gt; grayFrame = frame.Convert&lt;Gray, Byte&gt;();
     Image&lt;Gray, Byte&gt; smallGrayFrame = grayFrame.PyrDown();
     Image&lt;Gray, Byte&gt; smoothedGrayFrame = smallGrayFrame.PyrUp();
     Image&lt;Gray, Byte&gt; cannyFrame = smoothedGrayFrame.Canny(100, 60);

     captureImageBox.Image = frame;
     grayscaleImageBox.Image = grayFrame;
     smoothedGrayscaleImageBox.Image = smoothedGrayFrame;
     cannyImageBox.Image = cannyFrame;
  }

  private void captureButtonClick(object sender, EventArgs e)
  {
     if (_capture != null)
     {
        if (_captureInProgress)
        {  //stop the capture
           captureButton.Text = ""Start Capture"";
           _capture.Pause();
        }
        else
        {
           //start the capture
           captureButton.Text = ""Stop"";
           _capture.Start();
        }

        _captureInProgress = !_captureInProgress;
     }
  }

  private void ReleaseData()
  {
     if (_capture != null)
        _capture.Dispose();
  }
</code></pre>

<p>}</p>
",,2013-10-01 15:07:02,Attempted to read or write protected memory. while try to receive frame in image variable,<c#><emgucv><opencvsharp>,,,CC BY-SA 3.0,False,False,True,False,False
15426,22367162,2014-03-13 01:07:23,,"<p>IDE   : Visual Studio 2010 Express<br>
Lib   : Emgu CV 2.2
Level : Beginner</p>

<p>I've make Camera ON when Clicking PictureBox and viceversa, but it giving error :</p>

<pre><code>Object reference not set to an instance of an object
</code></pre>

<p>Here the Event Handler :</p>

<pre><code>private void pictureBoxCapture_Click(object sender, EventArgs e)
{
    try
    {
        if (Clicked == true) //i dont know how to make it right
        {
            Application.Idle -= ProcessFrame;
        }
        else
        {
            Application.Idle += ProcessFrame;
        }
    }
    catch (Exception ex)
    {
        MessageBox.Show(ex.Message);
    }
}
</code></pre>

<p>Calling from :</p>

<pre><code>private void ProcessFrame(object sender, EventArgs e)
{
    //Cap = new Emgu.CV.Capture();
    ImageFrame = Cap.QueryFrame();
    pictureBoxCapture.Image = ImageFrame.ToBitmap();
}
</code></pre>

<p>how to set if else parameter likely, any advice?</p>
",2014-03-13 02:05:44,2014-03-13 09:52:42,How to Make Camera ON / OFF with PictureBox,<c#><algorithm><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
15437,17019459,2013-06-10 08:10:51,,"<p>I was trying to study Face Recognition using Emgu CV wrapper in C#.I did the recognition fine.What i just want to know is how i do retrieve the calculated Eigenfaces and Average faces in a picture box.Can anyone show me how i do this? Many thanks.</p>
",2013-06-10 14:40:56,2015-04-24 03:14:10,C# - Emgu CV Retireve and display calculated Eigenfaces and Average faces on the GUI(Picture box or image box),<c#><wrapper><emgucv><face-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
15544,21247402,2014-01-21 01:19:59,,"<p>I have a very simple program for Emgu CV calling:</p>

<pre><code>        Capture mMovie = new Capture(""movie.mp4"");
        Image&lt;Bgr, byte&gt; img = mMovie.QueryFrame();
</code></pre>

<p>The problem is, that I get an exception for MP4 loading.</p>

<p><code>'System.NullPointerReference' occurs in Emgu.CV.dll</code>, and the application is unable to create <code>capture</code> from movie.mp4 file.</p>

<p>I've read that adding file - <code>opencv_ffmpeg242.dll</code> - into x86 (or x64) folder helps, I've done so and I still get an error. Anyone has experience with this? Why is this happening, when I have the opencv_ffmpeg library there?</p>

<p>Note that video was created using <code>ffmpeg</code> library and I'm able to play it in different players that use <code>ffmpeg</code>.</p>
",2014-01-21 05:27:20,2014-02-24 20:16:54,EmguCV and MP4 files,<c#><opencv><video><ffmpeg><emgucv>,,,CC BY-SA 3.0,True,False,True,False,True
15560,22377287,2014-03-13 11:31:54,,"<p>I'm tring to use, in an applcation (face recognition) in c#, to get real tine stream from my IP Camera ""geovision gv-cb220"", but I don't have success. 
Camera work fine while using IE browser.
I have access to camera at 192.168.0.10, and there are user settings and password for access.
Can anyone help me?<br>
Thanks in advance</p>
",2014-03-13 11:37:21,2014-03-13 11:37:21,emgu cv Ip camera geovision gv-cb220,<c#><visual-studio-2008><emgucv><ip-camera>,,,CC BY-SA 3.0,False,False,True,False,False
15578,20085682,2013-11-20 01:31:10,,"<p>I am using EMGU C#.</p>

<p>I have a bigger image A and smaller Image B. Image A has a part that has to be replaced by Image B. Using SIFT (Scale-invariant feature transform) on Image A, I have got the homography matrix of the part needed to be replaced. Now I want to use homography matrix and replace Image B on Image A.</p>

<p>How can I use homography matrix and replace just Image B?</p>

<p>Thank you</p>
",,2013-11-22 09:13:34,Replace a Part of a Image with another Image - EMGU(OpenCV),<opencv><image-processing><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
15597,21250929,2014-01-21 06:37:47,,"<p>I fixed the last error and that's my new code:</p>

<pre><code>    public partial class Form1 : Form
   {
       public Form1()
       {
        InitializeComponent();
         }

        private void button1_Click(object sender, System.EventArgs e)
        {
        using (OpenFileDialog dialog = new OpenFileDialog())
        {
            dialog.Filter = ""JPEG|*.jpg|PNG|*.PNG"";
            if (dialog.ShowDialog() == DialogResult.OK)
            {
                pictureBox1.SizeMode = PictureBoxSizeMode.StretchImage;

                Image image = Image.FromFile(dialog.FileName);

                pictureBox1.Image = image;

            }
        }

    }

    private void button2_Click(object sender, EventArgs e)
    {
        this.Close();
    }


    private void Form1_Load(object sender, EventArgs e)
    {

    }
    struct parameter
    {
        public float alpha { get; set; }
        public float beta { get; set; }
        public float gamma { get; set; }
    };




    unsafe private void button3_Click(object sender, EventArgs e)
    {
        {

        int length = 1000;

        Point *contour;

        Point center = new Point();

        var snake_param = new List&lt;parameter&gt;();

            snake_param.Add(new parameter { alpha=  0.1f , beta = 0.1f, gamma= 0.1f, });

        IntPtr dst_img= new IntPtr();

        Bitmap bitmap = new Bitmap(""pictureBox1.Image"");

        Image&lt;Bgr, byte&gt; image = new Image&lt;Bgr, byte&gt;(bitmap);




        center.X = image.Width;
        center.Y = image.Height;




        int i;
        for (i = 0; i &lt; length; i++)
        {
            contour[i].X = (int)(center.X * Math.Cos(2 * Math.PI * i / length) + center.X);
            contour[i].Y = (int)(center.Y * Math.Sin(2 * Math.PI * i / length) + center.Y);
        }

     LINE_TYPE lignetype = new LINE_TYPE();         


        for (i = 0; i &lt; length - 1; i++)
        {
            CvInvoke.cvLine(
                dst_img,
                contour[i],
                contour[i + 1],
                new MCvScalar(255,0,0),
                2, 
                LINE_TYPE.EIGHT_CONNECTED,
                0  );
        }


        CvInvoke.cvLine
            (
            dst_img,
            contour[length - 1],
            contour[0],
            new MCvScalar(255,0,0),
            2,
            LINE_TYPE.EIGHT_CONNECTED,
            0
            );


           IntPtr ctr =new IntPtr();
           //public void PixelToInkSpace(
            //IntPtr a 
            //ref Point contour
            //);          



        IntPtr src_img = image.Ptr;
        CvInvoke.cvSnakeImage(
            src_img,
            contour[i],
            length, 
            snake_param.[1].alfa,
            snake_param[2].beta,
            snake_param[3].gamma,
            1,
            new System.Drawing.Size(15, 15), 
            new MCvTermCriteria(1,0.0),
            1);



        CvInvoke.cvCvtColor(
            src_img,
            dst_img,
            COLOR_CONVERSION.GRAY2RGB );


            for (i = 0; i &lt; length - 1; i++)
        {
            CvInvoke.cvLine(
                dst_img,
                contour[i],
                contour[i + 1],
                new MCvScalar(255,0,0),
                2, 
                LINE_TYPE.EIGHT_CONNECTED,
                0 );
        }
            CvInvoke.cvLine(
                dst_img, 
                contour[length - 1],
                contour[0], 
                new MCvScalar(255,0,0),
                    2, 
                    LINE_TYPE.EIGHT_CONNECTED,
                    0);
             pictureBox2.SizeMode = PictureBoxSizeMode.StretchImage;

             Bitmap bitmappbb = new Bitmap(""dst_img"");
             Image&lt;Bgr, byte&gt; imagee = new Image&lt;Bgr, byte&gt;(bitmappbb);
             pictureBox2.Image = bitmappbb;
             }


          }
       }
   }
</code></pre>

<p>But my error now is different as I'm translating my code from c++ to c# ,
I discover that the  snake format is </p>

<pre><code>public static void cvSnakeImage(
IntPtr image,
IntPtr points,
int length,
float[] alpha,
float[] beta,
float[] gamma,
int coeffUsage,
Size win,
MCvTermCriteria criteria,
bool calcGradient
</code></pre>

<p>)</p>

<ol>
<li>I didn't find way to convert the variable ""contour"" with type ""Point"" to ""IntPtr"".</li>
<li>And a way to call alfa, beta et gamma as float[]; 
@Timothy Walters</li>
</ol>
",2014-01-21 07:42:06,2014-04-26 06:43:16,The best overloaded method match for 'Emgu.CV.CvInvoke.cvSnakeImage has some invalid arguments,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
15620,24637928,2014-07-08 17:20:42,,"<p>I'm trying to create a WPF app that will allow me to click through a video frame by frame. I'm using the Emgu.CV frameworks Capture class. I can click though 20 to 30 frame and then it stops working.</p>

<p>Basically what I am doing is to click a button which starts the capture, Capture.Start(). In the frame handler I grab the frame and them call Capture.Pause(). I click the buttom again to start the process again. I can do this for awhile and them it stops working. I can play the video all the way through if just start the capture and don't pause it and restart it. 
Here is the code I'm using.  </p>

<pre><code>    private void btnCapture_Click(object sender, RoutedEventArgs e) {
        capture = new Capture(""C:\\AAAAA\\testVideo.mp4"");
        capture.ImageGrabbed += ProcessFrame;
        webCamDisplay.DataContext = webCamManager;
        capture.Start();
    }
    private void btnNextFrame_Click(object sender, RoutedEventArgs e) {
        try {
            capture.Start();
        } catch (Exception ex ) {   
            string msg = ex.Message;
        }
    } 
    private void ProcessFrame(object sender, EventArgs arg) {
        try {
            Image&lt;Bgr, Byte&gt; frame = capture.RetrieveBgrFrame();
            try {
                this.Dispatcher.Invoke((Action)(() =&gt; {
                    webCamDisplay.Source = BitmapSourceConvert.ToBitmapSource(frame);
                    webCamManager.Update(frame);
                }));
            } catch (Exception ex) {
                string msg = ex.Message;
            }
            capture.Pause();
        } catch (Exception ex) {                
            string msg = ex.Message;
        }
    }

public class BitmapSourceConvert {
    public static BitmapImage ToBitmapSource(IImage image) {
        using (System.Drawing.Bitmap source = image.Bitmap) {
            System.Windows.Media.Imaging.BitmapImage bImg = new System.Windows.Media.Imaging.BitmapImage();
            try {
                MemoryStream ms = new MemoryStream();
                source.Save(ms, System.Drawing.Imaging.ImageFormat.Jpeg);
                bImg.BeginInit();
                bImg.StreamSource = new MemoryStream(ms.ToArray());
                bImg.EndInit();
                return bImg;
            } catch (Exception ex) {
                string ms = ex.Message;
                throw new Exception(ms);
            }
        }
    }
}
</code></pre>
",,2014-07-09 06:26:58,Emgu.CV Capture class throws exception,<c#><wpf><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
15655,24642818,2014-07-08 22:57:53,,"<p>I am currently trying to save not only the skeletal data, but also the color frame images for post processing reasons. Currently, this is the section of the code that handles the color video, and outputs a color image in the UI. I figure, this is where the saving of the color frame images has to take place. </p>

<pre><code>private void ColorFrameEvent(ColorImageFrameReadyEventArgs colorImageFrame)
{
    //Get raw image
    using (ColorImageFrame colorVideoFrame = colorImageFrame.OpenColorImageFrame())
    {
        if (colorVideoFrame != null)
        {
            //Create array for pixel data and copy it from the image frame
            Byte[] pixelData = new Byte[colorVideoFrame.PixelDataLength];
            colorVideoFrame.CopyPixelDataTo(pixelData);

            //Set alpha to 255
            for (int i = 3; i &lt; pixelData.Length; i += 4)
            {
                pixelData[i] = (byte)255;
            }

            using (colorImage.GetBitmapContext())
            {
                colorImage.FromByteArray(pixelData);
            }
        }
    }
}
</code></pre>

<p>I have tried reading up on OpenCV, EmguCV, and multithreading; but I am pretty confused. It would be nice to have a solid good explanation in one location. However, I feel like the best way to do this without losing frames per second, would be to save all the images in a List of arrays perhaps, and then when the program finishes do some post processing to convert arrays->images->video in Matlab. </p>

<p>Can someone comment on how I would go about implementing saving the color image stream into a file?</p>
",2014-07-08 23:17:30,2014-07-11 06:44:23,Saving color frames using Kinect C# VS 2013,<c#><visual-studio><opencv><visual-studio-2013><kinect>,,,CC BY-SA 3.0,True,True,True,False,False
15664,17037796,2013-06-11 06:29:35,,"<pre><code>private void CameraCapture_Load(object sender, EventArgs e)
 {
//Initialize the capture device
capture_face = new Capture();
capture_face.QueryFrame();
//Initialize the CapturedFrame event
Application.Idle += new EventHandler(CapturedFrame);
}

private void CapturedFrame(object sender, EventArgs e)
{            

current_Frame = capture_face.QueryFrame().Resize(400, 320, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

gray = current_Frame.Convert&lt;Gray, Byte&gt;();
}
</code></pre>

<blockquote>
  <p>AccessViolationException was unhandled.
  - Attempted to read or write protected memory.</p>
</blockquote>

<p>Can anyone help on my issue? </p>

<p>I'm getting this error when I try to get the frame as current when I execute the form. I use windows 7.</p>
",2013-06-11 06:52:44,2013-06-11 06:52:44,C#:Emgu CV: Get error when try to get frame from capture device. AccessViolationException was unhandled,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
15666,17038945,2013-06-11 07:45:31,,"<pre><code>using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using Emgu.CV;
using Emgu.CV.Structure;

namespace CrackleTest
{
    public static class Controller
    {
        public static Capture capture = new Capture();
        public static VideoWriter CaptureOutput;

        public static void Init()
        {
            capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, 1920);
            capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, 1080);

            CaptureOutput = new VideoWriter
            (
                ""output.avi"",
                -1, //CvInvoke.CV_FOURCC(""W"",""M"",""V"",""1""),
                30, //fps
                (int)capture.GetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH),
                (int)capture.GetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT),
                true
            );
            capture.ImageGrabbed += SaveFrame;

            capture.Start();
        }

        public static void Stop()
        {
            capture.Stop();
            CaptureOutput.Dispose();
        }

        public static void SaveFrame(Object sender, EventArgs e)
        {
            Image&lt;Bgr, Byte&gt; video = capture.RetrieveBgrFrame();
            CaptureOutput.WriteFrame(video);
        }
    }
}
</code></pre>

<p>When I call the stop function I get an error message</p>

<blockquote>
  <p>An unhandled exception of type 'System.AccessViolationException'
  occurred in Emgu.CV.dll</p>
  
  <p>Additional information: Attempted to read or write protected memory.
  This is often an indication that other memory is corrupt.</p>
</blockquote>

<p>I'm not sure what the best practices are for streaming video from usb webcam in opencv.</p>
",,2013-06-11 07:45:31,Access violation when streaming video with emgu opencv,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
15694,22388643,2014-03-13 19:13:39,,"<p>I am trying to improve the quality of an image.</p>

<p>I use emgu for this.</p>

<p>I use this code to change the contrast (I think!).</p>

<pre><code>Image&lt;Bgr, byte&gt; improveMe = new Image&lt;Bgr, byte&gt;(grid);
improveMe._EqualizeHist();
</code></pre>

<p>For a daytime image I get this:</p>

<p><img src=""https://i.stack.imgur.com/A8sWM.jpg"" alt=""enter image description here""></p>

<p>For a night time image I get this:</p>

<p><img src=""https://i.stack.imgur.com/4U5yz.jpg"" alt=""enter image description here""></p>

<p>Obviously, not so good!</p>

<p>The 1st image is nice and lush and the 2nd is as you can see could be descirbed as over-exposed.</p>

<p>Are there ways to avoid get such a poor image at night-time?  Is it because the image is now lower in color channels (if that makes sense)? Should I check for min/max color ranges of an image before deciding to apply this filter? Should I use a completely different filter?</p>

<p>Reading material links are welcome answers as well...</p>
",,2014-03-13 19:44:14,How to change the contrast of an image using emgu,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
15707,22389423,2014-03-13 19:51:23,,"<p>I am taking three images and saving them as Tiff images in order to preserve the data of the image for analysis. In my program I load these three images as <code>Emgu.CV.Image&lt;Rgb,ushort&gt;</code>. I need to add these three images together and return a final tiff image that is the average of the three seperate images. What would be the best way to go about doing this?</p>
",,2014-03-14 12:41:06,Adding and averaging Tiff images using Emgu.CV to create an averaged Tiff image,<c#><image-processing><tiff><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
15818,17051614,2013-06-11 18:52:34,,"<p>I am currently trying to write a C# app that will detect motion.  For a 'blob' motion, if the object is of high luminance then ignore it.  I do this to remove moths/bugs that come close up to a camera.  At nighttime this works well.  To distinguish whether the image has been taken at night I reduce the image to 1px by 1px and get the saturation and luminance.  I have said a low saturation then a darker image.  However, when I look at an image taken in the evening the saturation is also low and if I wear a white shirt, the motion code thinks the white shirt is of high luminance and rejects the image.</p>

<p>It seems that the color white is also mistaken for a high luminance.</p>

<p>Is my approach wrong?  Is HSV the correct way to determine objects of high luminance?</p>
",2013-06-11 20:20:20,2013-06-12 03:14:57,Ignoring bright motion from an image,<c#><opencv><graphics><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16016,22412767,2014-03-14 18:14:33,,"<p>I have a C# app and I am using <a href=""http://www.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow noreferrer"">Emgu</a>.</p>

<p>I want to brighten up dull images.  When I use EqualHist the detail is there but a bit too strong.  Are there ways to enhance the existing details of an image but not as vibrant as the EqualHist? Thanks..</p>

<p>Sample images:</p>

<p><img src=""https://i.stack.imgur.com/V25g7.jpg"" alt=""enter image description here""></p>
",2014-05-13 08:24:04,2014-05-13 08:24:04,Enhancing details of an image,<c#><image-processing><emgucv><image-enhancement>,,,CC BY-SA 3.0,False,False,True,False,False
16043,23564392,2014-05-09 12:13:07,,"<pre><code>// computing hu moments
  Moments moments2=moments(croppedImage,false);
  double hu[7];
  HuMoments(moments2,hu);
</code></pre>

<p>this code gives the hu moment for the contours. Can any body provide the equivalent code in  Emgucv C#? </p>

<p>partial C# code</p>

<pre><code> MCvMoments moments = contours.GetMoments();
 MCvHuMoments Humoments;
 CvInvoke.cvGetHuMoments(moments,.........);
</code></pre>

<p>struggling with 2nd parameter for cvGetHuMoments method. </p>
",2014-05-29 06:52:13,2014-05-30 01:54:23,compute humoments of contours in Emgucv,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
16055,22414490,2014-03-14 19:51:39,,"<p>I am implementing a face detection application using emguCV (an openCV Wrapper for C#). I decided to use active appearance model (AAM) for face detection . When i searched for active appearance model (AAM) libraries , i was able to find <a href=""https://code.google.com/p/aam-opencv/"" rel=""nofollow"">this</a> , i want to know whether this library can be using in emguCV ?
Are any other AAM libraries available for emguCV  ?</p>

<p>Thanks in advance</p>
",2014-03-15 16:58:24,2014-03-16 11:52:02,Detect face using active appearance model emguCV,<c#><c++><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16083,21292716,2014-01-22 19:57:39,,"<p>I am new to Image processing. In my application, I want detect and remove skin surrounding an eye.<img src=""https://i.stack.imgur.com/908Ti.jpg"" alt=""enter image description here""></p>

<p>In the above image I want to extract the eye area (and eye brow) without skin.</p>

<p>First, I tried to perform skin detection before removing skin from the image. I used the <code>AdaptiveSkinDetector</code> method in emgu cv, Here is my code</p>

<pre><code>AdaptiveSkinDetector a = new AdaptiveSkinDetector(1, AdaptiveSkinDetector.MorphingMethod.ERODE);
Image&lt;Gray, Byte&gt; skin = new Image&lt;Gray, Byte&gt;(ImageFramecolourrighteye.Width, ImageFramecolourrighteye.Height);

a.Process(ImageFramecolourrighteye, skin);

CvInvoke.cvShowImage(""Skin detection"", skin);
</code></pre>

<p>But the it is not detecting skin. Are there any errors in my code?
Is there any better way to perform skin detection? (using colors, perhaps?)
References / code sample would be useful.</p>

<p>Your help is highly appreciated</p>

<p>Thanks in advance </p>
",2014-01-22 20:06:55,2017-01-14 11:14:02,Skin detection and removal in Emgucv,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16127,24681933,2014-07-10 16:36:14,,"<p>Emgu.CV (Nuget package 2.4.2) doesn't as far as I can tell implement the gpu::alphaComp method available in OpenCV.</p>

<p>As such when trying to implement this specific type of composite it is incredible slow in C#, such that it takes up some 80% of the total cpu usage of my app.</p>

<p>This was my original solution that performs really badly.  </p>

<pre><code>    static public Image&lt;Bgra, Byte&gt; Overlay( Image&lt;Bgra, Byte&gt; image1, Image&lt;Bgra, Byte&gt; image2 )
    {

        Image&lt;Bgra, Byte&gt; result = image1.Copy();
        Image&lt;Bgra, Byte&gt; src = image2;
        Image&lt;Bgra, Byte&gt; dst = image1;

        int rows = result.Rows;
        int cols = result.Cols;
        for (int y = 0; y &lt; rows; ++y)
        {
            for (int x = 0; x &lt; cols; ++x)
            {
                // http://en.wikipedia.org/wiki/Alpha_compositing
                double  srcA = 1.0/255 * src.Data[y, x, 3];
                double dstA = 1.0/255 * dst.Data[y, x, 3];
                double outA = (srcA + (dstA - dstA * srcA));
                result.Data[y, x, 0] = (Byte)(((src.Data[y, x, 0] * srcA) + (dst.Data[y, x, 0] * (1 - srcA))) / outA);  // Blue
                result.Data[y, x, 1] = (Byte)(((src.Data[y, x, 1] * srcA) + (dst.Data[y, x, 1] * (1 - srcA))) / outA);  // Green
                result.Data[y, x, 2] = (Byte)(((src.Data[y, x, 2] * srcA) + (dst.Data[y, x, 2] * (1 - srcA))) / outA); // Red
                result.Data[y, x, 3] = (Byte)(outA*255);
            }
        }
        return result;
    }
</code></pre>

<p>Is there a way to optimise the above in C#?</p>

<p>I've additionally looked at using OpencvSharp, but that doesn't appear to provide access to gpu::alphaComp neither.</p>

<p>Is there any OpenCV C# wrapper library that can do alpha Compositing?</p>

<p>AddWeighted does not do what I need it to do.</p>

<p>Whilst similar, this <a href=""https://stackoverflow.com/questions/11958473/opencv-emgu-cv-compositing-images-with-alpha"">question</a> doesn't provide an answer</p>
",2017-05-23 12:31:17,2014-07-15 12:57:45,Alpha composite images using emgu.cv,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16167,21298801,2014-01-23 03:32:08,,"<p>I can only save 1 frame of a video with my current code. but I need to save the video for a longer period of time. Can some one help me with this? </p>

<pre><code> public void ProcessFrame(object sender, EventArgs e)
    {
           frame = _capture.QueryFrame();
           imageBox1.Image = frame;
           VideoW = new VideoWriter(@""temp.avi"", 
                                   CvInvoke.CV_FOURCC('M', 'P', '4', '2'), 
                                   (Convert.ToInt32(upDownFPS.Value)), 
                                   frame.Width, 
                                   frame.Height, 
                                   true);
           VideoW.WriteFrame(frame);
    }
</code></pre>
",2014-01-23 10:46:08,2016-06-19 21:51:35,Saving video with EMGU,<c#><image-processing><video-capture><video-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
16170,21300228,2014-01-23 05:37:26,,"<p>I understand that stackoverflow exceptions are usually infinite loops, but I've checked my logic and stepped through the code and cannot figure this out. There is no infinite loop because I mark every pixel with <code>locationID</code> as I process it!</p>

<pre><code>    private void setAttachedPixels(ref Image&lt;Gray, byte&gt; source, int X, int Y, byte locationID)  //recursively set a pixel, and all adjacent unmarked pixels, to a certain number
    {
        if (X &gt;= 0 &amp;&amp; Y &gt;= 0 &amp;&amp; X &lt; source.Rows &amp;&amp; Y &lt; source.Cols)
        {
            if (source.Data[X, Y, 0] == 1)   // 1 means unprocessed - locationID starts at 2 and increments elsewhere
            {

                source.Data[X, Y, 0] = locationID;  //mark origin pixel
                setAttachedPixels(ref source, X+1, Y-1, locationID); //down left pixel
                setAttachedPixels(ref source, X+1, Y, locationID);  //down
                setAttachedPixels(ref source, X+1, Y+1, locationID);  //down right
                setAttachedPixels(ref source, X, Y - 1, locationID);  //left
                setAttachedPixels(ref source, X, Y + 1, locationID);  //right
                setAttachedPixels(ref source, X - 1, Y - 1, locationID);//up left
                setAttachedPixels(ref source, X - 1, Y, locationID);  //up
                setAttachedPixels(ref source, X - 1, Y + 1, locationID);  //up right
            }
        }
        return;
    }
</code></pre>

<p>Code explanation: I'm trying to loop through an image (basically a 2-dimentional array) with some blobs in it and 'count' how many pixels are part of each blob. Hopefully you can see what I'm doing.</p>

<p>Here is a screenshot of the error.  It and the stack trace is of no help, but I know someone will ask.</p>

<p><img src=""https://i.stack.imgur.com/REFhn.png"" alt=""enter image description here""></p>
",2014-01-23 05:40:39,2014-01-23 06:06:14,"Why am I getting a stackoverflow exception (EMGU, openCV for C#, Visual Studio 2010 Express)",<c#><visual-studio-2010><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16182,17083320,2013-06-13 09:12:25,,"<p>I'm working on a project using WPF to display the Kinect ColorImageFrame and a skeleton representation. I also have to record those two videos.</p>

<p>I'm able to display and record (using EmguCV) those two images, but I have some performance issues. It seems that this part of my code is the reason of my loss of performance.</p>

<pre><code>private void DrawSkeleton(Skeleton[] skeletons)
    {
        using (System.Drawing.Bitmap skelBitmap = new System.Drawing.Bitmap(640, 480))
        {
            foreach (Skeleton S in skeletons)
            {
                if (S.TrackingState == SkeletonTrackingState.Tracked)
                {
                    DrawBonesAndJoints(S,skelBitmap);                        
                }
                else if (S.TrackingState == SkeletonTrackingState.PositionOnly)
                {

                }
            }
            _videoArraySkel.Add(ToOpenCVImage&lt;Bgr, Byte&gt;(skelBitmap));
            BitmapSource source = ToWpfBitmap(skelBitmap);
            this.skeletonStream.Source = source;       
        }            
    }
</code></pre>

<p>and more precisely from the ToWpfBitmap which allows me to display it in my Window:</p>

<pre><code>public static BitmapSource ToWpfBitmap(System.Drawing.Bitmap bitmap) 
    {
        using (MemoryStream stream = new MemoryStream()) 
        {
            bitmap.Save(stream, System.Drawing.Imaging.ImageFormat.Bmp);
            stream.Position = 0;
            BitmapImage result = new BitmapImage();
            result.BeginInit();
            // According to MSDN, ""The default OnDemand cache option retains access to the stream until the image is needed.""
            // Force the bitmap to load right now so we can dispose the stream.
            result.CacheOption = BitmapCacheOption.OnLoad;
            result.StreamSource = stream;
            result.EndInit();
            result.Freeze();
            return result;
        }
    }
</code></pre>

<p>The loss of performance is characterized by:
- The videos displayed on the Window are not fluent anymore
- The video recording seems to miss some frames which leads to a video going faster/lower than the normal.</p>

<p>Can you help me by telling me where this problem may come from?</p>
",2013-06-13 09:23:07,2016-02-15 15:00:04,C# MemoryStream slowing programme performance,<c#><wpf><bitmap><emgucv><memorystream>,,,CC BY-SA 3.0,False,False,True,False,False
16222,23582384,2014-05-10 14:42:11,,"<p>How can I implement a simple motion-detection method using EMGUCV? I have searched for applicable examples, but the only solutions I found were too complicated to implement.</p>

<p>Is there a way I can implement a simple method to detect motion in order to trigger something in my application?</p>
",2014-06-18 14:11:53,2019-07-24 15:29:35,Implement and trigger on detected motion,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
16347,18044465,2013-08-04 15:20:14,,"<p>I've been testing and searching for the help but could not resolve this issue:</p>

<p>In C# and with emgu I can't run this simplest code:</p>

<pre><code>... //**after these 3 dots HERE I GOT THE FIRST WARNING :a namespace cannot directly contain members such as fields or methods**

//Create an image of 400x200 of Blue color
using (Image&lt;Bgr, Byte&gt; img = new Image&lt;Bgr, byte&gt;(400, 200, new Bgr(255, 0, 0))) 
{
   //Create the font
   MCvFont f = new MCvFont(CvEnum.FONT.CV_FONT_HERSHEY_COMPLEX, 1.0, 1.0);

   //Draw ""Hello, world."" on the image using the specific font
   img.Draw(""Hello, world"", ref f, new Point(10, 80), new Bgr(0, 255, 0)); 

   //Show the image using ImageViewer from Emgu.CV.UI
   ImageViewer.Show(img, ""Test Window"");
}
</code></pre>

<p><strong>I get these errors:</strong></p>

<pre><code>error CS0116: A namespace cannot directly contain members such as fields or methods
error CS1518: Expected class, delegate, enum, interface, or struct
</code></pre>

<p><strong>PS :</strong> emgu cv has been correctly installed , in C# this code (much more complex) runs perfectly:</p>

<pre><code>namespace CameraCapture
{
    public partial class CameraCapture : Form
    {
        //declaring global variables
        private Capture capture;        //takes images from camera as image frames
        private bool captureInProgress;

        public CameraCapture()
        {
            InitializeComponent();
        }
        //------------------------------------------------------------------------------//
        //Process Frame() below is our user defined function in which we will create an EmguCv 
        //type image called ImageFrame. capture a frame from camera and allocate it to our 
        //ImageFrame. then show this image in ourEmguCV imageBox
        //------------------------------------------------------------------------------//
        private void ProcessFrame(object sender, EventArgs arg)
        {
            Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
            CamImageBox.Image = ImageFrame;
        }

        //btnStart_Click() function is the one that handles our ""Start!"" button' click 
        //event. it creates a new capture object if its not created already. e.g at first time
        //starting. once the capture is created, it checks if the capture is still in progress,
        //if so the
        private void btnStart_Click(object sender, EventArgs e)
        {
            #region if capture is not created, create it now
            if (capture == null)
            {
                try
                {
                    capture = new Capture();
                }
                catch (NullReferenceException excpt)
                {
                    MessageBox.Show(excpt.Message);
                }
            }
            #endregion

            if (capture != null)
            {
                if (captureInProgress)
                {  //if camera is getting frames then stop the capture and set button Text
                    // ""Start"" for resuming capture
                    btnStart.Text = ""Start!""; //
                    Application.Idle -= ProcessFrame;
                }
                else
                {
                    //if camera is NOT getting frames then start the capture and set button
                    // Text to ""Stop"" for pausing capture
                    btnStart.Text = ""Stop"";
                    Application.Idle += ProcessFrame;
                }

                captureInProgress = !captureInProgress;
            }
        }

        private void ReleaseData()
        {
            if (capture != null)
                capture.Dispose();
        }

        private void CameraCapture_Load(object sender, EventArgs e)
        {

        }
    }
}
</code></pre>

<p>Thank you for the help!</p>
",2014-05-12 00:18:55,2014-05-12 00:18:55,Emgu CV issue with a short code,<c#><computer-vision><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
16423,18986215,2013-09-24 15:44:22,,"<p>I'm trying to get the <a href=""https://github.com/artemisvision/emgu_openCV/tree/master/Emgu.CV.Example/MotionDetection"" rel=""nofollow noreferrer"">Motion Detection Emgu CV example</a> mentioned in <a href=""https://stackoverflow.com/a/18403594/575530"">the answer to ""Looking for a function for motion detection on emgucv""</a> working.</p>

<p>To get the example code working I first needed to </p>

<ol>
<li>add references to the Emgu CV DLLs <code>Emgu.CV</code>, <code>Emgu.CV.UI</code>, and <code>Emgu.Util</code> to the project </li>
<li>make sure that the relevant Open CV DLLs (listed on <a href=""http://www.emgu.com/wiki/index.php/Download_And_Installation#Have_you_copied_the_OpenCV_dlls_to_the_execution_directory.3F"" rel=""nofollow noreferrer"">the EMGU wiki</a> and found in <code>C:\Emgu\emgucv-windows-universal-gpu 2.4.9.1847\bin\x86</code>) are copied always to the output executable directory of the project</li>
<li>change the build target to x86</li>
</ol>

<p>When execution gets to the line in <code>Form1.cs</code></p>

<pre><code>_forgroundDetector = new BGStatModel&lt;Bgr&gt;(image, Emgu.CV.CvEnum.BG_STAT_TYPE.FGD_STAT_MODEL);
</code></pre>

<p>it throws the exception <code>Unable to load DLL 'opencv_legacy249': The specified module could not be found. (Exception from HRESULT: 0x8007007E)</code>. Looking at the execution directory the DLL <em>is</em> there:</p>

<p><img src=""https://i.stack.imgur.com/dtBU0.jpg"" alt=""Explorer screenshot showing required DLL&#39;s presence""></p>

<p>What's going on? How do I fix this?</p>
",2017-05-23 12:13:32,2013-10-29 14:57:53,Getting Emgu CV Motion Detection sample working: Unable to load DLL 'opencv_legacy249',<dll><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16463,18052019,2013-08-05 06:44:17,,"<p>How are images stored in emgu?</p>

<p><img src=""https://i.stack.imgur.com/Vd9ga.png"" alt=""enter image description here""></p>

<p>Those pixel values seem to be very large magnitude. ~ 9*10^9</p>

<p>Shouldn't pixels be [0 .. 255] ? </p>

<p>When I draw the image it seems to look ok. TemplateMatch is a grayscale float, ie:</p>

<pre><code>Image&lt;Gray, Single&gt; TemplateMatch;
</code></pre>

<p>also when I scale TemplateMatch, it seems to have no effect on its appearance.
ie: </p>

<p>TemplateMatch._Mul(<strong>somevalue</strong>);</p>
",,2013-08-06 03:47:40,How are images stored in EMGU?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16465,18052988,2013-08-05 07:44:46,,"<p>I just started to use EmguCV for Kinect image processing, and an ArgumentException occured when creating EmguCV image from depth stream like this:</p>

<pre><code>    private void DepthFrameReady(object sender, DepthImageFrameReadyEventArgs e)
    {
        DepthImageFrame df = e.OpenDepthImageFrame();
        if (df != null)
        {
            short[] data = new short[df.PixelDataLength];
            df.CopyPixelDataTo(data);
            Bitmap b = data.ToBitMap(df.Width, df.Height, System.Drawing.Imaging.PixelFormat.Format16bppGrayScale);
            Image&lt;Gray, short&gt; im = new Image&lt;Gray, short&gt;(b); //run-time exception here
</code></pre>

<p>The ToBitmap extension method is entirely copied from the Kinect SDK tutorial example:</p>

<pre><code>    public static Bitmap ToBitmap(this short[] data, int width, int height, System.Drawing.Imaging.PixelFormat format)
    {
        var bitmap = new Bitmap(width, height, format);

        var bitmapData = bitmap.LockBits(
            new System.Drawing.Rectangle(0, 0, bitmap.Width,
            bitmap.Height),
            ImageLockMode.WriteOnly,
            bitmap.PixelFormat);
        Marshal.Copy(data, 0, bitmapData.Scan0, data.Length);
        bitmap.UnlockBits(bitmapData);
        return bitmap;
    }
</code></pre>

<p>I checked that <code>b</code> had an valid value, not null. I wonder why this exception occured, is it some image format problem?</p>
",,2013-08-12 14:36:04,convert Kinect depth image to EmguCV image error,<c#><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
16483,23602130,2014-05-12 06:11:29,,"<p>I have some program on my 1st pc (everytinh works fine)
but when I copy my full project to another PC and try to run application I get this error :</p>

<pre><code>A first chance exception of type 'System.ArgumentException' occurred in mscorlib.dll

Additional information: Formaty identyfikatorów URI nie są obsługiwane.

If there is a handler for this exception, the program may be safely continued.
</code></pre>

<p>and than:</p>

<pre><code>A first chance exception of type 'System.BadImageFormatException' occurred in Emgu.CV.dll

Additional information: Próbowano załadować program w niepoprawnym formacie. (Wyjątek od HRESULT: 0x8007000B)

If there is a handler for this exception, the program may be safely continued.
</code></pre>

<p>in this  code:</p>

<pre><code>BackgroundSubtractorMOG2 pMog11 = new BackgroundSubtractorMOG2(0, 80, false);
</code></pre>

<p>I have really have no idea what to do with this. What is the problem with Emgu.CV in the 2nd pc?</p>
",2014-05-14 11:57:19,2014-05-14 11:57:19,Emgu.CV Not supported Uri format,<c#><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16503,17108564,2013-06-14 12:31:30,,"<p>The OpenCV x64 distribution (through emgucv) for Windows has almost half a gigabyte of DLLs, including a single 224Mb opencv_gpu.dll.  It seems unlikely that any human could have produced that amount of code, so what gives?  Large embedded resources? Code generation bloat (this doesn't seem likely given that it's a native c/c++ project)</p>

<p>I want to use it for face recognition, but it's a problem to have such a large binary dependency in git, and it's a hassle to manage outside of source control.</p>

<p>[Update]
There are no embedded resources (at least the kind Windows DLLs usually have, but since this is a cross-platform product, I'm not sure that's significant.)  Maybe lots of initialized C table structures to perform matrix operations?</p>
",2013-06-14 12:43:12,2013-06-15 15:06:21,What makes OpenCV so large on Windows? Anything I can do about it?,<windows><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16520,23604879,2014-05-12 09:00:43,,"<p>I am using emgu opencv version 2.4.2 to process a series of PNG images extracted from a 720p video. I use this code to read the image:</p>

<pre><code>image = new Image&lt;Bgr, byte&gt;(filename);
</code></pre>

<p>At a random image in my PNG sequence I get: </p>

<pre><code>Convertion from Image&lt;Emgu.CV.Structure.Bgra, System.Byte&gt; to
Image&lt;Emgu.CV.Structure.Bgr, System.Byte&gt; is not supported by OpenCV
</code></pre>

<p>Indicating the input image has an alpha channel, and cannot be read directly to a 24 bit image structure.</p>

<p>But, the exception never occurs on the same image. So, the next time I run the program it will probably be read just fine. The exception usually occur quite far into the PNG sequence, like frame 300. Other times it runs fine to a later frame. But it would be normally stop around frame 300-320.</p>

<p>I am not doing any kind of threading here that could potentially cause seemingly random issues, it is a very basic program reading one image, doing some basic modifications to it, then saving it to another file.</p>

<p>I guess a workaround is to simply catch the exception and try again, but that seems messy.</p>

<p>is there anything I am missing here?</p>
",2014-05-13 01:46:58,2014-05-13 01:46:58,OpenCV random image loading error,<.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16574,22460651,2014-03-17 17:03:29,,"<p>I am currently working on a project which we have a set of photos of trucks going by a camera. I need to detect what type of truck it is (how many wheels it has). So I am using EMGU to try to detect this. </p>

<p>Problem I have is I cannot seem to be able to detect the wheels using EMGU's HoughCircle detection, it doesn't detect all the wheels and will also detect random circles in the foliage.</p>

<p>So I don't know what I should try next, I tried implementing SURF algo to match wheels between them but this does not seem to work either since they aren't exactly the same, is there a way I could implement a ""loose"" SURF algo?</p>

<p>This is what I start with.</p>

<p>This is what I get after the Hough Circle detection. Many erroneous detections, has some are not even close to having a circle and the back wheels are detected as a single one for some reason.</p>

<p><img src=""https://imgur.com/t9dxDjr.png"" alt=""Hough Circles""></p>

<p>Would it be possible to either confirm that the detected circle are actually wheels using SURF and matching them between themselves? I am a bit lost on what I should do next, any help would be greatly appreciated.</p>

<p>(sorry for the bad English)</p>

<p><strong><em>UPDATE</em></strong></p>

<p>Here is what i did.
I used blob tracking to be able to find the blob in my set of photos. With this I effectively can locate the moving truck. Then i split the rectangle of the blob in two and take the lower half from there i know i get the zone that should contain the wheels which greatly increases the detection. I will then run a light intensity loose check on the wheels i get. Since they are in general more black i should get a decently low value for those and can discard anything that is too white, 180/255 and up. I also know that my circles radius cannot be greater than half the detection zone divided by half.</p>

<p><img src=""https://i.stack.imgur.com/fL2nH.png"" alt=""After dectection""></p>
",2014-04-02 17:53:34,2017-03-08 14:24:46,Detecting truck wheels,<c#><opencv><image-processing><emgucv><surf>,,,CC BY-SA 3.0,True,False,True,False,False
16586,23610631,2014-05-12 13:39:53,,"<p>Hi am using <strong>HoughLines Method</strong> to detect lines from a camera, i've filtered my image ""imgProcessed"" using <strong>ROI</strong> it means getting just the black objects to make the tracking simple, then when i intend to use the HoughLines method it gives me an error that my ""CannyEdges"" has some <strong>invalid arguments</strong>, here's my code :</p>

<pre><code>Image&lt;Gray, Byte&gt; gray = imgProcessed.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();
        Gray cannyThreshold = new Gray(180);
        Gray cannyThresholdLinking = new Gray(120);
        Gray circleAccumulatorThreshold = new Gray(120);
        Image&lt;Gray, Byte&gt; cannyEdges = gray.Canny(cannyThreshold, cannyThresholdLinking);


        LineSegment2D[] lines = imgProcessed.cannyEdges.HoughLines(
                                cannyThreshold,
                                cannyThresholdLinking,
                                1,                  //Distance resolution in pixel-related units
                                Math.PI / 45.0,     //Angle resolution measured in radians.
                                50,                 //threshold
                                100,                //min Line width
                                1                   //gap between lines
                                )[0];               //Get the lines from the first channel
</code></pre>
",2016-03-21 12:12:36,2016-03-21 12:12:36,HoughLines invalid arguments,<c#><.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
16666,17124795,2013-06-15 14:42:19,,"<p>Can I develop an application that is not Windows form, i.e. that is Console application using EMGU CV? I want to do the image processing on the desktop using C# and Emgu CV and send the result to an Android via Http. Can I do it as a console application using Emgu CV?</p>
",2013-06-15 20:53:22,2015-07-21 12:05:26,C# - Emgu CV -Can i use Emgu cv on a Console Application?,<c#><winforms><console-application><desktop-application><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
16680,20179120,2013-11-24 18:22:27,,"<p>I have Emgu image :</p>

<pre><code>Image&lt;Bgr,byte&gt; image = new Image&lt;Bgr,byte&gt;(""image.jpg""); 
</code></pre>

<p>Here is how the file(image.jpg) looks like:</p>

<p><img src=""https://i.stack.imgur.com/Nl7HX.png"" alt=""enter image description here""></p>

<p>All pixels that inside red-yellow triangle I want to copy to the new image called:</p>

<pre><code>Image&lt;Bgr,byte&gt; copiedSegment;
</code></pre>

<p>Any idea how to implement it if I have coordinates all coordinates of the triangle contour.</p>

<p>Thank you in advance.</p>
",,2016-10-28 01:11:29,How to copy segment from the image?,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16716,17128233,2013-06-15 21:51:30,,"<p>I am working on Emgu cv as a console application and I was trying to load an jpeg format image file from computer disk.I have tried the following ways but nothing is working?</p>

<pre><code>Image input = Image.FromFile(""C://Users//...//Image.jpg"");
Bitmap master = (Bitmap)input;
Image&lt;Gray,byte&gt; InputImage = new Image&lt;Gray,byte&gt;(master);
RecognizeFaces(InputImage);
</code></pre>

<p>And this way too</p>

<pre><code>Image&lt;Bgr,byte&gt; inputImage = new Image&lt;Bgr,byte&gt;(""C:\\Users\...\Image.jpeg"");
Image&lt;Gray,byte&gt; grayFrame = inputImage.Convert&lt;Gray,byte&gt;();
</code></pre>

<p>Both ways Its not working.Any other option? It stops running here </p>

<pre><code>    _ptr = CvInvoke.cvCreateImageHeader(new Size(cols, rows), CvDepth, numberOfChannels);
</code></pre>

<p>in a class known to be Image.cs of Emgu cv.And it throws type initializer for 'Emgu.CV.CvInvoke' Exception.The File path is perfect/correct.the error looks like this.
The inner exception is ""System.BadImageFormatException An attempt was made to load a program with an incorrect format Exception for hresult 0x8007000B."" Configuration manager and build target are the same both any cpu.
<a href=""http://www.mediafire.com/view/myfiles/#6557l4iwzpza7m5"" rel=""nofollow"">http://www.mediafire.com/view/myfiles/#6557l4iwzpza7m5</a>
 Could you please tell me what i am doing wrong here? Thanks</p>
",2013-06-16 10:18:26,2015-01-02 15:31:13,C# - TypeInitializationException when loading image files to Emgu cv for a C# console application?,<c#><winforms><console-application><desktop-application><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
16723,20181069,2013-11-24 21:11:40,,"<p>I am doing a project on panoramic stitching of Images using Emgu CV (Open CV for C#). Till now I have done some work that stitches images but the output is kinda weird. This is what I am getting: </p>

<p>My panorama:
<img src=""https://i.stack.imgur.com/N7S70.jpg"" alt=""enter image description here""></p>

<p>This is what the Emgu CV Stitcher.stitch method gives: 
Stiched by inbuilt stitcher</p>

<p><img src=""https://i.stack.imgur.com/YSbER.jpg"" alt=""enter image description here""></p>

<p>Clearly I am missing something. Moreover if I add more images, the output gets more stretchy like this one: </p>

<p><img src=""https://i.stack.imgur.com/R6wrf.jpg"" alt=""enter image description here""></p>

<p>I am not able to figure out what am i missing. Here is my code till now: </p>

<p><a href=""http://pastebin.com/Ke2Zz4m9"" rel=""nofollow noreferrer"">http://pastebin.com/Ke2Zz4m9</a></p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Features2D;
using Emgu.CV.Structure;
using Emgu.CV.UI;
using Emgu.CV.Util;
using Emgu.CV.GPU;


namespace Project
{
    public partial class Form1 : Form
    {
        public Form1()
        {
            InitializeComponent();
        }

        private void Form1_Load(object sender, EventArgs e)
        {
            Image&lt;Bgr, float&gt; one = new Image&lt;Bgr, float&gt;(""D:\\Venice_panorama_part_01.jpg"");
            Image&lt;Bgr, float&gt; two = new Image&lt;Bgr, float&gt;(""D:\\Venice_panorama_part_02.jpg"");
            Image&lt;Bgr, float&gt; third = new Image&lt;Bgr, float&gt;(""D:\\Venice_panorama_part_03.jpg"");
            Image&lt;Bgr, float&gt; fourth = new Image&lt;Bgr, float&gt;(""D:\\Venice_panorama_part_04.jpg"");
            Image&lt;Bgr, float&gt; fifth = new Image&lt;Bgr, float&gt;(""D:\\Venice_panorama_part_05.jpg"");
            Image&lt;Bgr, float&gt; sixth = new Image&lt;Bgr, float&gt;(""D:\\Venice_panorama_part_06.jpg"");
            Image&lt;Bgr, float&gt; seventh = new Image&lt;Bgr, float&gt;(""D:\\Venice_panorama_part_07.jpg"");
            Image&lt;Bgr, float&gt; eighth = new Image&lt;Bgr, float&gt;(""D:\\Venice_panorama_part_08.jpg"");



            Image&lt;Bgr, Byte&gt; result = FindMatch(two, third);
            result = convert(result);
            Image&lt;Bgr, float&gt; twoPlusThree = result.Convert&lt;Bgr, float&gt;();




            Image&lt;Bgr, Byte&gt; result2 = FindMatch(fourth, fifth);
            result2 = convert(result2);
            Image&lt;Bgr, float&gt; fourPlusFive = result2.Convert&lt;Bgr, float&gt;();



            Image&lt;Bgr, Byte&gt; result3 = FindMatch(sixth, seventh);
            result3 = convert(result3);
            Image&lt;Bgr, float&gt; sixPlusSeven = result3.Convert&lt;Bgr, float&gt;();



            Image&lt;Bgr, Byte&gt; result4 = FindMatch(one, twoPlusThree);
            result4 = convert(result4);
            Image&lt;Bgr, float&gt; oneTwoThree = result4.Convert&lt;Bgr, float&gt;();



            Image&lt;Bgr, Byte&gt; result5 = FindMatch(oneTwoThree, fourPlusFive);
            result5 = convert(result5);
            Image&lt;Bgr, float&gt; oneTwoThreeFourFive = result5.Convert&lt;Bgr, float&gt;();



            Image&lt;Bgr, Byte&gt; result6 = FindMatch(sixPlusSeven, eighth);
            result6 = convert(result6);
            Image&lt;Bgr, float&gt; sixSevenEigth = result6.Convert&lt;Bgr, float&gt;();



            Image&lt;Bgr, Byte&gt; result7 = FindMatch(oneTwoThreeFourFive, sixSevenEigth);

            result7 = convert(result7);

            result.Save(""D:\\result1.jpg"");
            result2.Save(""D:\\result2.jpg"");
            result3.Save(""D:\\result3.jpg"");
            result4.Save(""D:\\result4.jpg"");
            result5.Save(""D:\\result5.jpg"");
            result6.Save(""D:\\result6.jpg"");
            result7.Save(""D:\\result7.jpg"");
            this.Close();

        }

        public static Image&lt;Bgr, Byte&gt; FindMatch(Image&lt;Bgr, float&gt; fImage, Image&lt;Bgr, float&gt; lImage)
        {
            HomographyMatrix homography = null;
            SURFDetector surfCPU = new SURFDetector(500, false);


            int k = 2;
            double uniquenessThreshold = 0.8;
            Matrix&lt;int&gt; indices;

            Matrix&lt;byte&gt; mask;

            VectorOfKeyPoint modelKeyPoints;
            VectorOfKeyPoint observedKeyPoints;
            Image&lt;Gray, Byte&gt; fImageG = fImage.Convert&lt;Gray, Byte&gt;();
            Image&lt;Gray, Byte&gt; lImageG = lImage.Convert&lt;Gray, Byte&gt;();

            if (GpuInvoke.HasCuda)
            {
                GpuSURFDetector surfGPU = new GpuSURFDetector(surfCPU.SURFParams, 0.01f);
                using (GpuImage&lt;Gray, Byte&gt; gpuModelImage = new GpuImage&lt;Gray, byte&gt;(fImageG))
                //extract features from the object image
                using (GpuMat&lt;float&gt; gpuModelKeyPoints = surfGPU.DetectKeyPointsRaw(gpuModelImage, null))
                using (GpuMat&lt;float&gt; gpuModelDescriptors = surfGPU.ComputeDescriptorsRaw(gpuModelImage, null, gpuModelKeyPoints))
                using (GpuBruteForceMatcher&lt;float&gt; matcher = new GpuBruteForceMatcher&lt;float&gt;(DistanceType.L2))
                {
                    modelKeyPoints = new VectorOfKeyPoint();
                    surfGPU.DownloadKeypoints(gpuModelKeyPoints, modelKeyPoints);

                    // extract features from the observed image
                    using (GpuImage&lt;Gray, Byte&gt; gpuObservedImage = new GpuImage&lt;Gray, byte&gt;(lImageG))
                    using (GpuMat&lt;float&gt; gpuObservedKeyPoints = surfGPU.DetectKeyPointsRaw(gpuObservedImage, null))
                    using (GpuMat&lt;float&gt; gpuObservedDescriptors = surfGPU.ComputeDescriptorsRaw(gpuObservedImage, null, gpuObservedKeyPoints))
                    using (GpuMat&lt;int&gt; gpuMatchIndices = new GpuMat&lt;int&gt;(gpuObservedDescriptors.Size.Height, k, 1, true))
                    using (GpuMat&lt;float&gt; gpuMatchDist = new GpuMat&lt;float&gt;(gpuObservedDescriptors.Size.Height, k, 1, true))
                    using (GpuMat&lt;Byte&gt; gpuMask = new GpuMat&lt;byte&gt;(gpuMatchIndices.Size.Height, 1, 1))
                    using (Stream stream = new Stream())
                    {
                        matcher.KnnMatchSingle(gpuObservedDescriptors, gpuModelDescriptors, gpuMatchIndices, gpuMatchDist, k, null, stream);
                        indices = new Matrix&lt;int&gt;(gpuMatchIndices.Size);
                        mask = new Matrix&lt;byte&gt;(gpuMask.Size);

                        //gpu implementation of voteForUniquess
                        using (GpuMat&lt;float&gt; col0 = gpuMatchDist.Col(0))
                        using (GpuMat&lt;float&gt; col1 = gpuMatchDist.Col(1))
                        {
                            GpuInvoke.Multiply(col1, new MCvScalar(uniquenessThreshold), col1, stream);
                            GpuInvoke.Compare(col0, col1, gpuMask, CMP_TYPE.CV_CMP_LE, stream);
                        }

                        observedKeyPoints = new VectorOfKeyPoint();
                        surfGPU.DownloadKeypoints(gpuObservedKeyPoints, observedKeyPoints);

                        //wait for the stream to complete its tasks
                        //We can perform some other CPU intesive stuffs here while we are waiting for the stream to complete.
                        stream.WaitForCompletion();

                        gpuMask.Download(mask);
                        gpuMatchIndices.Download(indices);

                        if (GpuInvoke.CountNonZero(gpuMask) &gt;= 4)
                        {
                            int nonZeroCount = Features2DToolbox.VoteForSizeAndOrientation(modelKeyPoints, observedKeyPoints, indices, mask, 1.5, 20);
                            if (nonZeroCount &gt;= 4)
                                homography = Features2DToolbox.GetHomographyMatrixFromMatchedFeatures(modelKeyPoints, observedKeyPoints, indices, mask, 2);
                        }

                    }
                }
            }
            else
            {



                //extract features from the object image
                modelKeyPoints = new VectorOfKeyPoint();
                Matrix&lt;float&gt; modelDescriptors = surfCPU.DetectAndCompute(fImageG, null, modelKeyPoints);


                // extract features from the observed image
                observedKeyPoints = new VectorOfKeyPoint();
                Matrix&lt;float&gt; observedDescriptors = surfCPU.DetectAndCompute(lImageG, null, observedKeyPoints);
                BruteForceMatcher&lt;float&gt; matcher = new BruteForceMatcher&lt;float&gt;(DistanceType.L2);
                matcher.Add(modelDescriptors);

                indices = new Matrix&lt;int&gt;(observedDescriptors.Rows, k);
                using (Matrix&lt;float&gt; dist = new Matrix&lt;float&gt;(observedDescriptors.Rows, k))
                {
                    matcher.KnnMatch(observedDescriptors, indices, dist, k, null);
                    mask = new Matrix&lt;byte&gt;(dist.Rows, 1);
                    mask.SetValue(255);
                    Features2DToolbox.VoteForUniqueness(dist, uniquenessThreshold, mask);
                }

                int nonZeroCount = CvInvoke.cvCountNonZero(mask);
                if (nonZeroCount &gt;= 4)
                {
                    nonZeroCount = Features2DToolbox.VoteForSizeAndOrientation(modelKeyPoints, observedKeyPoints, indices, mask, 1.5, 20);
                    if (nonZeroCount &gt;= 4)
                        homography = Features2DToolbox.GetHomographyMatrixFromMatchedFeatures(modelKeyPoints, observedKeyPoints, indices, mask, 2);
                }
            }
            Image&lt;Bgr, Byte&gt; mImage = fImage.Convert&lt;Bgr, Byte&gt;();
            Image&lt;Bgr, Byte&gt; oImage = lImage.Convert&lt;Bgr, Byte&gt;();
            Image&lt;Bgr, Byte&gt; result = new Image&lt;Bgr, byte&gt;(mImage.Width + oImage.Width, mImage.Height);

            if (homography != null)
            {  //draw a rectangle along the projected model
                Rectangle rect = fImage.ROI;
                PointF[] pts = new PointF[] {
               new PointF(rect.Left, rect.Bottom),
               new PointF(rect.Right, rect.Bottom),
               new PointF(rect.Right, rect.Top),
               new PointF(rect.Left, rect.Top)};
                homography.ProjectPoints(pts);

                HomographyMatrix origin = new HomographyMatrix();                //I perform a copy of the left image with a not real shift operation on the origin
                origin.SetIdentity();
                origin.Data[0, 2] = 0;
                origin.Data[1, 2] = 0;
                Image&lt;Bgr, Byte&gt; mosaic = new Image&lt;Bgr, byte&gt;(mImage.Width + oImage.Width + 2000, mImage.Height*2);

                Image&lt;Bgr, byte&gt; warp_image = mosaic.Clone();

                mosaic = mImage.WarpPerspective(origin, mosaic.Width, mosaic.Height, Emgu.CV.CvEnum.INTER.CV_INTER_LINEAR, Emgu.CV.CvEnum.WARP.CV_WARP_DEFAULT, new Bgr(0, 0, 0));


                warp_image = oImage.WarpPerspective(homography, warp_image.Width, warp_image.Height, Emgu.CV.CvEnum.INTER.CV_INTER_LINEAR, Emgu.CV.CvEnum.WARP.CV_WARP_INVERSE_MAP, new Bgr(200, 0, 0));
                Image&lt;Gray, byte&gt; warp_image_mask = oImage.Convert&lt;Gray, byte&gt;();
                warp_image_mask.SetValue(new Gray(255));
                Image&lt;Gray, byte&gt; warp_mosaic_mask = mosaic.Convert&lt;Gray, byte&gt;();
                warp_mosaic_mask.SetZero();
                warp_mosaic_mask = warp_image_mask.WarpPerspective(homography, warp_mosaic_mask.Width, warp_mosaic_mask.Height, Emgu.CV.CvEnum.INTER.CV_INTER_LINEAR, Emgu.CV.CvEnum.WARP.CV_WARP_INVERSE_MAP, new Gray(0));
                warp_image.Copy(mosaic, warp_mosaic_mask);

                return mosaic;
            }
            return null;
        }

        private Image&lt;Bgr, Byte&gt; convert(Image&lt;Bgr, Byte&gt; img)
        {
            Image&lt;Gray, byte&gt; imgGray = img.Convert&lt;Gray, byte&gt;();
            Image&lt;Gray, byte&gt; mask = imgGray.CopyBlank();

            Contour&lt;Point&gt; largestContour = null;
            double largestarea = 0;

            for (var contours = imgGray.FindContours(CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
                RETR_TYPE.CV_RETR_EXTERNAL); contours != null; contours = contours.HNext)
            {
                if (contours.Area &gt; largestarea)
                {
                    largestarea = contours.Area;
                    largestContour = contours;
                }
            }
            CvInvoke.cvSetImageROI(img, largestContour.BoundingRectangle);
            return img;
        }
    }
}
</code></pre>
",2013-11-26 07:15:02,2016-09-25 09:30:47,Panoramic image stitching using EmguCV,<c#><opencv><image-processing><emgucv><panoramas>,,,CC BY-SA 3.0,True,False,True,False,False
16733,23623656,2014-05-13 05:49:31,,"<p>Got problems when trying to use opencv's function. The error returned is: <em>OpenCV: Both input images must have either 8uC1 or 8uC3 type</em></p>

<p>Here's the code:</p>

<pre><code>Image&lt;Gray, Byte&gt; prev_grey = frames.ElementAt(0).Convert&lt;Gray, Byte&gt;();
IntPtr prev = CvInvoke.cvCreateImage(prev_grey.Size, IPL_DEPTH.IPL_DEPTH_8U, 1);
CvInvoke.cvSetImageCOI(prev, 0); // Select the channel to copy into
CvInvoke.cvCopy(prev_grey, prev, IntPtr.Zero);
Matrix&lt;float&gt; prev2 = new Matrix&lt;float&gt;(prev_grey.Rows, prev_grey.Cols, prev);

curr_grey = frames.ElementAt(i).Convert&lt;Gray, Byte&gt;();
IntPtr curr = CvInvoke.cvCreateImage(curr_grey.Size, IPL_DEPTH.IPL_DEPTH_8U, 1);
CvInvoke.cvSetImageCOI(curr, 0); // Select the channel to copy into
CvInvoke.cvCopy(curr_grey, curr, IntPtr.Zero);
Matrix&lt;float&gt; curr2 = new Matrix&lt;float&gt;(curr_grey.Rows, curr_grey.Cols, curr);

Matrix&lt;double&gt; affine = new Matrix&lt;double&gt;(curr_grey.Rows, curr_grey.Cols);
CvInvoke.cvEstimateRigidTransform(prev2.Ptr, curr2.Ptr, affine.Ptr, false);
</code></pre>
",,2014-05-13 05:49:31,Emgu CV estimateRigidTransform,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16737,17129496,2013-06-16 01:54:12,,"<p>How to load an image from a specific folder using Emgu cv CvInvoke.cvLoadImage(...)?I am tryng to do it like this</p>

<pre><code>    IntPtr inputImage = CvInvoke.cvLoadImage(""C:\\Users\\...\\ClassPic1.jpg"");
</code></pre>

<p>Is that ok? If so, How am i gonna access it later as an Emgu.CV.Image file so that i will do my image processing on it?</p>
",2013-08-15 08:24:06,2020-07-13 15:39:08,"C# - Emgu cv How to load an image from a folder using CvInvoke.cvLoadImage(""ClassPic1.jpg"") as intptr and access it",<invoke><emgucv><intptr><loadimage>,,,CC BY-SA 3.0,False,False,True,False,False
16753,22473528,2014-03-18 08:04:51,,"<pre><code>using (MemStorage storage = new MemStorage()) //allocate storage for contour approximation
         for (Contour&lt;Point&gt; contours = grayImage.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST, storage); contours != null; contours = contours.HNext)
         {
             Contour&lt;Point&gt; currentContour = contours.ApproxPoly(contours.Perimeter * 0.05, storage);
            canny.Draw(new Rectangle(currentContour.BoundingRectangle.X, currentContour.BoundingRectangle.Y, currentContour.BoundingRectangle.Width, currentContour.BoundingRectangle.Height), new Gray(1), 1);
             canny.Draw(contours, new Gray(), 2);
         }
</code></pre>

<p>this code giving me the bounding boxes but not up to mark,in some cases contours is out of box.
unable to share sample output image because it require 10 reputation
if anybody have solution to this please reply!
thankyou.</p>
",2014-03-18 08:19:24,2014-03-19 07:16:51,Find bounding box for contours,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
16756,17131270,2013-06-16 07:57:04,,"<p>Any suggestions to convert image into binary and remove noise from it. Submit the coding plz. I'm trying to read characters in the image using tesseract function in Emgu CV.</p>
",,2013-06-30 11:02:02,How to convert image in to binary image using Image processing with Emgu CV,<c#><tesseract><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
16759,23625416,2014-05-13 07:41:19,,"<p>I try to detect and count circles in image (for example smarties)</p>

<p>I use HSL color space. But I am not able to distiguish colors od the same color if they are in touch. I try to erode and dilate picture. But result is the same, I have only some blobs(connected components) od the same color. Do you have some general algorithm for this problem?</p>

<p>(I try to do that with EMGUCV library)
I cant send image, because I have small reputation.
Thanks in advance.</p>
",,2014-05-13 22:34:16,"C#, EmguCV - Color and circle detection in image",<c#><opencv><image-processing><emgucv><image-segmentation>,,,CC BY-SA 3.0,True,False,True,False,False
16785,22475883,2014-03-18 10:00:50,,"<p>I have 2 IP cameras and they are different models and both from the same manufacturer. Lets call them <strong>Cam1</strong> and <strong>Cam2</strong>. I want to retrieve frames from these cameras by their network address but there are some problems. </p>

<p><em><strong>Cam1:</em></strong></p>

<p>When using <code>frame = capture.RetrieveBgrFrame();</code> <strong>frame</strong> is always <strong>null</strong>.</p>

<p>When using <code>frame = capture.QueryFrame();</code> <strong>frame</strong> is <strong>OK</strong>.</p>

<p><em><strong>Cam2</em></strong>(in the same network with my PC):</p>

<p>When using <code>frame = capture.RetrieveBgrFrame();</code> <strong>frame</strong> is always <strong>null</strong>.</p>

<p>When using <code>frame = capture.QueryFrame();</code> <strong>WinForm</strong> is frozen and computer(i7 3,3GHz, 6GB RAM) freezes.</p>

<p>Both stream addresses are OK. I tried to open them with VLC and also with OpenCV C++ platform.</p>

<p><strong>What could be a problem here?</strong></p>

<p>Here is the code:</p>

<pre><code>using Emgu.CV;
using Emgu.Util;
using Emgu.CV.Structure;
using Emgu.CV.UI;

namespace IPcamera
{
    public partial class Form1 : Form
    {
        private Capture capture;
        private Image&lt;Bgr, Byte&gt; frame;

        public Form1()
        {
            InitializeComponent();

            try
            {
                capture = new Capture(camera_address);
            }
            catch (NullReferenceException exception)
            {
                MessageBox.Show(exception.Message);
            }

            if (capture != null)
            {
                Application.Idle += ProcessFrame;
            }
        }

        void ProcessFrame(object sender, EventArgs e)
        {
            frame = capture.RetrieveBgrFrame();
            if (frame != null)
            {
                pictureBox1.Image = frame.ToBitmap();
            }
        }
    }
}
</code></pre>
",,2017-12-07 19:27:14,Various problems when retrieving frames from IP cameras,<c#><opencv><emgucv><ip-camera>,,,CC BY-SA 3.0,True,False,True,False,False
16908,17143469,2013-06-17 08:39:51,,"<p>I found this C# code snippet for calculating a histogram:</p>

<pre><code>    int hBins = 180;
    RangeF hRange = new RangeF(0f, 179f);       //hue's range
    int sBins = 256;
    RangeF sRange = new RangeF(0f, 255f);
    Image&lt;Bgr, Byte&gt; imageSource = new Image&lt;Bgr, Byte&gt;(originalImage.ToBitmap());
    Image&lt;Hsv, Byte&gt; imageHsv = imageSource.Convert&lt;Hsv, Byte&gt;();
    Image&lt;Gray, Byte&gt;[] imagesHsv = imageSource.Split();
    DenseHistogram hist = new DenseHistogram(new int[] { hBins, sBins }, new RangeF[] { hRange, sRange });
    hist.Calculate(new IImage[] { imagesHsv[0], imagesHsv[1], imagesHsv[2] }, false, null);
</code></pre>

<p>My question is: how can I get the result of histogram, as I need to get the number of the pixels for each bin)?</p>

<p>Thank you in advance.    </p>
",2013-08-31 18:24:58,2013-08-31 18:26:32,How can I get the result of histogram after calculation?,<.net><opencv><histogram><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
16944,19029424,2013-09-26 13:17:59,,"<p>in openCV I regularly use <code>cv::Mat</code> for almost everything. Now, I need to use emgu CV and use the <code>Matrix</code>-object in stat, but some functions are not supported?!... may I use the <code>image</code>-class instead? </p>

<p>When to use <code>image</code> and when to use <code>matrix</code> in emgu CV?</p>

<p>P.S.: Currently I'm looking for a way to define a ROI on a matrix but didn't find a way without copying the data.</p>

<p><em>Version: Emgu.CV-2.4.2</em></p>
",2013-10-01 14:32:26,2015-07-13 16:40:08,When to use `image` and when to use `Matrix` in Emgu CV?,<c#><opencv><coding-style><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
16956,23637916,2014-05-13 17:28:22,,"<p>I have tried hard But i am not able that how to find single point of interest in SURF Algorithm in Emgu CV. I wrote code for SURF. and I have problems that some times it goes in if statement near my numberd section ""1"" and some times it does not based on different images. why is that so? on the basis of that homography is calculated to not null. than I become able to draw circle or lines. which also have problem. circle or rectangle is drawn at 0,0 point on the image.
Please help me. I will be grateful.</p>

<pre><code>public Image&lt;Bgr, Byte&gt; Draw(Image&lt;Gray, byte&gt; conditionalImage, Image&lt;Gray, byte&gt; observedImage, out long matchTime)
    {
        //observedImage = observedImage.Resize(, INTER.CV_INTER_LINEAR);
        Stopwatch watch;
        HomographyMatrix homography = null;

        SURFDetector surfCPU = new SURFDetector(500, false);
        VectorOfKeyPoint modelKeyPoints;
        VectorOfKeyPoint observedKeyPoints;
        Matrix&lt;int&gt; indices;

        Matrix&lt;byte&gt; mask;
        int k = 2;
        double uniquenessThreshold = 0.8;
            //extract features from the object image
            modelKeyPoints = surfCPU.DetectKeyPointsRaw(conditionalImage, null);

            Matrix&lt;float&gt; modelDescriptors = surfCPU.ComputeDescriptorsRaw(conditionalImage, null, modelKeyPoints);

            watch = Stopwatch.StartNew();

            // extract features from the observed image
            observedKeyPoints = surfCPU.DetectKeyPointsRaw(observedImage, null);
            Matrix&lt;float&gt; observedDescriptors = surfCPU.ComputeDescriptorsRaw(observedImage, null, observedKeyPoints);
            BruteForceMatcher&lt;float&gt; matcher = new BruteForceMatcher&lt;float&gt;(DistanceType.L2);
            matcher.Add(modelDescriptors);

            indices = new Matrix&lt;int&gt;(observedDescriptors.Rows, k);
            using (Matrix&lt;float&gt; dist = new Matrix&lt;float&gt;(observedDescriptors.Rows, k))
            {
                matcher.KnnMatch(observedDescriptors, indices, dist, k, null);
                mask = new Matrix&lt;byte&gt;(dist.Rows, 1);
                mask.SetValue(255);
                Features2DToolbox.VoteForUniqueness(dist, uniquenessThreshold, mask);
            }

            int nonZeroCount = CvInvoke.cvCountNonZero(mask);

 //My Section number = 1
            if (nonZeroCount &gt;= 4)
            {
                nonZeroCount = Features2DToolbox.VoteForSizeAndOrientation(modelKeyPoints, observedKeyPoints, indices, mask, 1.5, 20);
                if (nonZeroCount &gt;= 4)
                    homography = Features2DToolbox.GetHomographyMatrixFromMatchedFeatures(modelKeyPoints, observedKeyPoints, indices, mask, 2);
            }

            watch.Stop();

        //Draw the matched keypoints
            Image&lt;Bgr, Byte&gt; result = Features2DToolbox.DrawMatches(conditionalImage,     modelKeyPoints, observedImage, observedKeyPoints,
                indices, new Bgr(Color.Blue), new Bgr(Color.Red), mask,     Features2DToolbox.KeypointDrawType.DEFAULT);






        #region draw the projected region on the image
        if (homography != null)
        {  //draw a rectangle along the projected model
            Rectangle rect = conditionalImage.ROI;
            PointF[] pts = new PointF[] { 
           new PointF(rect.Left, rect.Bottom),
           new PointF(rect.Right, rect.Bottom),
           new PointF(rect.Right, rect.Top),
           new PointF(rect.Left, rect.Top)};
            homography.ProjectPoints(pts);
            PointF _circleCenter = new PointF();
            _circleCenter.X = (pts[3].X + ((pts[2].X - pts[3].X) / 2));
            _circleCenter.Y = (pts[3].Y + ((pts[0].Y - pts[3].Y) / 2));

            result.Draw(new CircleF(_circleCenter, 15), new Bgr(Color.Red), 10);
            result.DrawPolyline(Array.ConvertAll&lt;PointF, Point&gt;(pts, Point.Round),     true, new Bgr(Color.Cyan), 5);
        }
        #endregion

        matchTime = watch.ElapsedMilliseconds;

        return result;
    }
</code></pre>
",,2014-05-16 18:40:40,Find interest point in surf Detector Algorithm,<opencv><image-processing><point><emgucv><surf>,,,CC BY-SA 3.0,True,False,True,False,False
17216,17166279,2013-06-18 10:13:59,,"<p>I have a problem with azure WCF project. I want to get file path to xml file which I add to project &lt;<strong>add</strong> -> <strong>existing item</strong>>. In its properties I set ""<strong>Copy if newer</strong>"" and when i deploy it on azure server I see that this file is beeing correctly copied to <strong>bin</strong>.
I have tried do use:</p>

<p>1) This one is working only locally on emulator:</p>

<pre><code>string filePath = Path.Combine(Environment.GetEnvironmentVariable(""RoleRoot""), @""approot"", @""bin"", @""myFile.xml"");
</code></pre>

<p>2) Is not working anywhere (on emulator and azure):</p>

<pre><code>string appRoot = HttpContext.Current.Server.MapPath(@""~\""); 
string filePath = Path.Combine(appRoot + @""\"", @""bin\myFile.xml"");
</code></pre>

<p>Maybe there is another way than adding xml file to output directory? I am using EmguCV and would like to load cascade xml file.</p>
",,2019-08-27 17:55:56,Path to file in azure project,<azure><filepath><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
17241,17169430,2013-06-18 12:54:50,,"<p>I´m using class <code>Capture</code> from EmguCV to take images from a WebCam. </p>

<p>According to the documentation of the class (<a href=""http://www.emgu.com/wiki/files/2.0.0.0/html/18b6eba7-f18b-fa87-8bf2-2acff68988cb.htm"" rel=""nofollow"">http://www.emgu.com/wiki/files/2.0.0.0/html/18b6eba7-f18b-fa87-8bf2-2acff68988cb.htm</a>), Capture has 3 constructors. </p>

<p>Using <code>public Capture()</code> its supposed to use the default camera and it works properly. </p>

<p>As I saw in one of the examples, seems that</p>

<pre><code>public Capture(string fileName) //takes a video file as the source for the captures.
</code></pre>

<p>The last constructor is </p>

<pre><code>public Capture(int camIndex) //which is supposed to ""Create a capture using the specific camera"" 
</code></pre>

<p>I tried to use this last constructor to allow the user to choose the device in case he has more than one camera (for example, the integrated camera in a laptop or a USB cam pluged in)</p>

<p>My problem is I don´t know how to get a list of available devices. Tried to create captures with index from 0 to 99 and try to grab a frame expecting an exception, but it just takes a black image with the 100 captures. Also, when I use the default camera, I don´t know how to get his index. </p>

<p>Any help?</p>

<p><strong>Edit:</strong> With the info in the answer of <strong>Shiva</strong> I got it working with this (I post it for future references):</p>

<pre><code>private void onLoad(object sender, RoutedEventArgs e)
{
    //Add the image processing to the dispatcher
    this.Dispatcher.Hooks.DispatcherInactive += new EventHandler(dispatcherTimer_Tick);

    //Get the information about the installed cameras and add the combobox items 
    DsDevice[] _SystemCamereas = DsDevice.GetDevicesOfCat(FilterCategory.VideoInputDevice);
    Video_Device[] WebCams = new Video_Device[_SystemCamereas.Length];
    for (int i = 0; i &lt; _SystemCamereas.Length; i++)
    {
        WebCams[i] = new Video_Device(i, _SystemCamereas[i].Name, _SystemCamereas[i].ClassID); //fill web cam array
        ComboBoxDevices.Items.Add(WebCams[i].ToString());
    }
}

private void dispatcherTimer_Tick(object sender, EventArgs e)
{
    if (capture != null)
    {
        //Capture an image
        Image&lt;Bgr, byte&gt; img = capture.QueryFrame();
        //Show the image in the window
        ImageOriginal.Source = ImageProcessor.ToBitmapSource(img);
    }
}

private void ComboBoxDevices_SelectionChanged(object sender, SelectionChangedEventArgs e)
{
    //If there is already a capture, dispose it
    if (capture != null)
    {
        capture.Dispose();
    }
    //Get the selected camera
    int selectedDevice = ComboBoxDevices.SelectedIndex;
    try
    {
        //Create new capture with the selected camera
        capture = new Capture(selectedDevice);
    }
    catch (Exception excpt)
    {
        MessageBox.Show(excpt.Message);
    }
}
</code></pre>
",2014-11-15 20:27:52,2014-11-15 20:27:52,Set capture device EmguCV,<c#><wpf><capture><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
17319,23669119,2014-05-15 04:11:48,,"<p>Hello I'm trying to apply point tracking to a scene. </p>

<p>Now I want to get the points only moving in horizontally. Anyone have any thoughts on this?
The arrays ""Actual"" and ""nextfeature"" contain the relevant x,y coordinates. I tried to get the difference from the two arrays, it did not work. I tried to get the optical flow using Farneback but it didn't gave me a satisfying result. I would really appreciate if anyone can give me any thoughts on how to get the points only moving in horizontal line. </p>

<p>thanks.</p>

<p>Here is the code.</p>

<pre><code>    private void ProcessFrame(object sender, EventArgs arg)
    {


        PointF[][] Actual = new PointF[0][];

        if (Frame == null) 
        {

            Frame = _capture.RetrieveBgrFrame();

            Previous_Frame = Frame.Copy();

        }

        else
        {

            Image&lt;Gray, byte&gt; grayf = Frame.Convert&lt;Gray, Byte&gt;();

            Actual = grayf.GoodFeaturesToTrack(300, 0.01d, 0.01d, 5);


            Image&lt;Gray, byte&gt; frame1 = Frame.Convert&lt;Gray, Byte&gt;();
            Image&lt;Gray, byte&gt; prev = Previous_Frame.Convert&lt;Gray, Byte&gt;();
            Image&lt;Gray, float&gt; velx = new Image&lt;Gray, float&gt;(Frame.Size);
            Image&lt;Gray, float&gt; vely = new Image&lt;Gray, float&gt;(Previous_Frame.Size);



            Frame = _capture.RetrieveBgrFrame().Resize(300,300,Emgu.CV.CvEnum.INTER.CV_INTER_AREA);

            Byte []status;
            Single[] trer;
            PointF[][] feature = Actual;
            PointF[] nextFeature = new PointF[300];



            Image&lt;Gray, Byte&gt; buf1 = new Image&lt;Gray, Byte&gt;(Frame.Size);
            Image&lt;Gray, Byte&gt; buf2 = new Image&lt;Gray, Byte&gt;(Frame.Size);
            opticalFlowFrame = new Image&lt;Bgr, Byte&gt;(prev.Size);

            Image&lt;Bgr, Byte&gt;  FlowFrame = new Image&lt;Bgr, Byte&gt;(prev.Size);


            OpticalFlow.PyrLK(prev, frame1, Actual[0], new System.Drawing.Size(10, 10), 0, new MCvTermCriteria(20, 0.03d),
                     out nextFeature, out status, out trer);




            for (int x = 0; x &lt; Actual[0].Length ; x++)
            {
                opticalFlowFrame.Draw(new CircleF(new PointF(nextFeature[x].X, nextFeature[x].Y), 1f), new Bgr(Color.Blue), 2);

            }

            new1 = old;
            old = nextFeature;

            Actual[0] = nextFeature;



            Previous_Frame = Frame.Copy();
            captureImageBox.Image = Frame;
            grayscaleImageBox.Image = opticalFlowFrame;


            //cannyImageBox.Image = velx;

            //smoothedGrayscaleImageBox.Image = vely;
        }
    }
</code></pre>
",2014-05-15 04:20:15,2014-05-15 05:11:55,Point Tracking using Optical Flow,<c#><opencv><image-processing><emgucv><opticalflow>,,,CC BY-SA 3.0,True,False,True,False,False
17331,18124646,2013-08-08 11:18:00,,"<p>I am using EMGU CV library in my application. How i can manually set camera focus to object? 
Now i'm using Capture class for grab images.</p>
",2013-08-08 11:29:56,2013-08-12 14:03:12,Manually focus camera in EMGU CV,<c#><.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
17385,22524306,2014-03-20 05:38:00,,"<p>I have noticed in MatLab you can call a function to measure entropy of an image.</p>

<p>I am using Emgu/C# and I have been looking for a way to do the same with that framework.</p>

<p>Does anyone know how it can be done please?</p>
",2014-03-20 05:44:43,2017-10-14 05:00:49,Measuring Entropy of an image,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
17390,20236956,2013-11-27 08:07:05,,"<p>I want to detect eyelid blinks in a video stream in C#, I am using a method mentioned in <a href=""http://www.nims.re.kr/include/file_down.php?dfile_name=20105007215049.pdf&amp;dfile_folder=TRE"" rel=""nofollow noreferrer"">this</a> paper. <p> <strong>Excerpt from the paper:</strong></p> </p>

<blockquote>
  <p>Therefore, a faster algorithm for solving this illumination variation problem is proposed, as follows: after the RGB input image is converted to an L<em>a</em>b* image, an illuminative component is acquired by applying a 31×31 median filter to the L image, as shown in Fig. 6(b). By applying median filtering, the illuminative component of the input image, excluding the detailed formation of the eye regions, can be approximated, as shown in Fig. 6(b).</p>
  
  <p>Here, the optimal size of the median filter is empirically determined experimentally in terms of the eye detection accuracy. Then,the inverted illuminative image is obtained, as shown in Fig. 6(c).
  The influence of the illuminative variation is compensated for by adding the inverted image to the original L image. Consequently, an illumination-compensated RGB image is acquired, as shown in Fig. 6(d).</p>
  
  <p>Fig. 7 shows the result of the binarized eye image using the proposed illumination normalization. In this binarization procedure, the threshold is automatically determined on the basis of the study byGonzalez and Woods (2002). The binarization result shown in
  Fig. 7(b) is much better than those shown in Fig. 5(b) and (c).</p>
  
  <p>Fig. 8 shows other examples of binarized eye images after illumination normalization </p>
</blockquote>

<p><strong>Edit:</strong></p>

<p><a href=""http://imageshack.com/a/img837/2086/w665.jpg"" rel=""nofollow noreferrer"">Fig.5 http://imageshack.com/a/img837/2086/w665.jpg</a></p>

<p><a href=""http://imageshack.com/a/img440/6157/kmo6.jpg"" rel=""nofollow noreferrer"">Fig.6 http://imageshack.com/a/img440/6157/kmo6.jpg</a></p>

<p><a href=""http://imageshack.com/a/img7/5584/rloq.jpg"" rel=""nofollow noreferrer"">Fig.7 http://imageshack.com/a/img7/5584/rloq.jpg</a></p>

<p>For color space conversion I am using code from <a href=""http://www.codeproject.com/Articles/19045/Manipulating-colors-in-NET-Part-1#xyz2"" rel=""nofollow noreferrer"">this</a> link.</p>

<p><strong>My code is:</strong></p>

<pre><code>void RGBtoXYZ(Bitmap bm, int row, int col, CIEXYZ[,] xyz)
{

    for (int i = 0; i &lt; row; i++)
    {
        for (int j = 0; j &lt; col; j++)
        {
            xyz[i, j] = ColorSpaceHelper.RGBtoXYZ(bm.GetPixel(j, i).R, bm.GetPixel(j, i).G, bm.GetPixel(j, i).B);
        }
    }
}

void XYZtoLAB(CIEXYZ[,] xyz, int row, int col, CIELab[,] lab)
{
    for (int i = 0; i &lt; row; i++)
    {
        for (int j = 0; j &lt; col; j++)
        {
            lab[i, j] = ColorSpaceHelper.XYZtoLab(xyz[i, j]);
        }
    }
}

void LABtoXYZ(CIEXYZ[,] xyz, int row, int col, CIELab[,] lab)
{
    for (int i = 0; i &lt; row; i++)
    {
        for (int j = 0; j &lt; col; j++)
        {
            xyz[i, j] = ColorSpaceHelper.LabtoXYZ(lab[i, j]);
        }
    }
}

void XYZtoRGB(Bitmap bm, int row, int col, CIEXYZ[,] xyz)
{
    Devcorp.Controls.Design.RGB rgb;
    for (int i = 0; i &lt; row; i++)
    {
        for (int j = 0; j &lt; col; j++)
        {
            rgb = ColorSpaceHelper.XYZtoRGB(xyz[i, j]);
            bm.SetPixel(j, i, Color.FromArgb(rgb.Red, rgb.Green, rgb.Blue));
        }
    }
}
void MedianLabImage(CIELab[,] lab, int row, int col, int filter_width)
{
    double value = 0;
    for (int i = 0; i &lt; row; i++)
    {
        for (int j = 0; j &lt; col; j++)
        {
            value = 0;
            for (int r = 0; r &lt; filter_width; r++)
            {
                for (int c = 0; c &lt; filter_width; c++)
                {
                    int image_r = Math.Min(Math.Max(i + r, 0), row - 1);
                    int image_c = Math.Min(Math.Max(j + c, 0), col - 1);

                    value += lab[image_r, image_c].L;
                }
            }

            value /= (filter_width * filter_width - 1);
            lab[i, j].L = value;
        }
    }
}
void MyFunction()
{
    System.Drawing.Bitmap img = new System.Drawing.Bitmap(@""C:\Users\Haseeb\Desktop\Untitled.bmp"");//@""C:\Users\Haseeb\Desktop\EyeBmp.bmp"");


    int imgRow, imgCol;
    imgRow = img.Height;
    imgCol = img.Width;


    CIEXYZ[,] xyzImage = new CIEXYZ[imgRow, imgCol];
    CIELab[,] labImage = new CIELab[imgRow, imgCol];

    RGBtoXYZ(img, imgRow, imgCol, xyzImage);
    XYZtoLAB(xyzImage, imgRow, imgCol, labImage);

    MedianLabImage(labImage, imgRow, imgCol, 9);//My confusion starts after this


    LABtoXYZ(xyzImage, imgRow, imgCol, labImage);
    XYZtoRGB(img, imgRow, imgCol, xyzImage);
}
</code></pre>

<p>Can anyone please confirm that I am doing this correctly? Also my main question is what do the authors mean by </p>

<blockquote>
  <p>""Then, the inverted illuminative image is obtained, as shown inFig. 6(c).""</p>
</blockquote>

<p>and </p>

<blockquote>
  <p>""The influence of the illuminative variation is compensated for by adding the inverted image to the original L image. Consequently, an illumination-compensated RGB image is acquired, as shown in Fig. 6(d)""</p>
</blockquote>

<p>Many thanks in advance.</p>
",2013-11-27 09:38:47,2013-11-27 09:38:47,Illumination normalization in C#,<c#><image-processing><normalization><aforge><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
17392,20237771,2013-11-27 08:57:28,,"<p>I am using Emgu with C#.</p>

<p>I have a stream of jepgs coming from a camera feed.  At the moment I use the absdiff between the 2 images to get the motion changes.</p>

<pre><code>Image&lt;Bgr, byte&gt; _diffBetweenCurrentAndPrevious = _currentFrame.Convert&lt;Bgr, Byte&gt;().AbsDiff(PreviousFrame.Convert&lt;Bgr, Byte&gt;());
</code></pre>

<p>I then enumerate through the data array of the image holding all the changes and  look for motion above a certain threshold.</p>

<pre><code> float diffCouner = 0;
 for (int y = 0; y &lt; 576; y++)
 {
    for (int x = 0; x &lt; 720; x++)
    {
       if (_diffBetweenCurrentAndPrevious.Data[y, x, 0] &gt;= 10
        || _diffBetweenCurrentAndPrevious.Data[y, x, 1] &gt;= 10 ||
         _diffBetweenCurrentAndPrevious.Data[y, x, 2] &gt;= 10)
         {
            BaseImage.Data[y, x, 0] = _currentFrame.Data[y, x, 0];
            BaseImage.Data[y, x, 1] = _currentFrame.Data[y, x, 1];
            BaseImage.Data[y, x, 2] = _currentFrame.Data[y, x, 2];
            diffCouner++;
          }
      }
  }
</code></pre>

<p>At the moment I am using BGR.</p>

<p>Is it better to use HSV or YCC or..?</p>

<p>I had noticed that I had to use a lower threshold when using YCC because the motion did not seem clear for a car passing by at night.  </p>

<p>I am interested in the best approach.</p>

<p>Or should I use <code>&lt;Gray,Byte&gt;</code> format?</p>

<p>The reason I am asking is that I have tried them all and them all seem to work.  But it may not be so good during different times of the day, for instant a dull or bright day.  Or a low contrast.</p>

<p>I could and will run tests over several days but I will be like a Red Indian praying for the seasons to change.</p>

<p>Any advice would be welcome.</p>

<p>Thanks</p>

<p>Just in case any one is following my question with interest I have found that using the <code>&lt;Gray,Byte&gt;</code> does not give good enough results for light changes.</p>

<p>I am now running the tests with <code>&lt;HSV,Byte&gt;</code></p>
",2013-11-27 11:06:54,2014-07-29 15:57:18,What is the best color space for motion detection,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
17394,21398136,2014-01-28 06:07:28,,"<p>I'm on my way to build program for control mouse pointer with hand recognition and tracking. I'm finished with my hand tracking use skin color segmentation. Now, I'm gonna tracking this hand and I choose <strong>camshift</strong> algorithm. But I'm a little bit confused how to implement camshift to my target (hand) use <strong>emgucv</strong> and <strong>c#</strong>.</p>

<p>Or can you give me recomendation what algorithm better to this kind of case? Such <strong>mean shift</strong> or any other.</p>
",2014-01-28 06:19:18,2014-01-28 09:16:28,How to implement camshift or mean shift for hand tracking in C# with EmguCV,<c#><opencv><image-processing><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
17481,22535311,2014-03-20 14:00:56,,"<p>I have a C# desktop application.</p>

<p>I am using emgu framework for image processing.</p>

<p>What I am trying to do is improve 'washed' out images and make them more vibrant.</p>

<p>Using myImage._EqualHist() works OK for when the picture has a rich array of colours (like during the day) but at night-time the white-balancing will distort after applying that emgu filter and I get a very bright/busy night-time image.  If I could just adjust the contrast that would be good - I think.</p>

<p>I have found some  code that will adjust the contrast for me.  I am now trying to find what value should I use to adjust the contrast by. Obviously, this value will vary during a 24hr cycle.</p>

<p>I have made a 1st stab at what relationship/formula I can use to auto-contrast an image.
Obviously, I am guessing and trying things out. Not very scientific//mathematical and I am searching the net for some logic I can apply.</p>

<p>Should I also consider the gamma of an image?</p>

<p>This is my code so far:</p>

<pre><code>           Image&lt;Bgr, Byte&gt; imgColor = new Image&lt;Bgr, byte&gt;(@""d:\20140320022038047.jpg"");
            Image&lt;Hsv,Byte&gt; hsv = new Image&lt;Hsv,byte&gt;(imgColor.ToBitmap());
            double averageHue = hsv[0].GetAverage().Intensity;
            double averageSat = hsv[1].GetAverage().Intensity;
            double averageLum = hsv[2].GetAverage().Intensity;

            //I am guessing here and playing around with the constants
            float adjustContrastBy =(float)( averageLum / averageHue);

            byte[, ,] data = imgColor.Data;
            //this part of the code enumertaes through the Image byte array
            for (int y = 0; y &lt; imgColor.Height ; y++)
            {
                for (int x = 0; x &lt; imgColor.Width; x++)
                {
                    byte B = data[y, x, 0];
                    byte G = data[y, x, 1];
                    byte R = data[y, x, 2];

                    float Red = R / 255.0f;
                    float Green = G / 255.0f;
                    float Blue = B / 255.0f;
                    Red = (((Red - 0.5f) * adjustContrastBy) + 0.5f) * 255.0f;
                    Green = (((Green - 0.5f) * adjustContrastBy) + 0.5f) * 255.0f;
                    Blue = (((Blue - 0.5f) * adjustContrastBy) + 0.5f) * 255.0f;

                    int iR = (int)Red;
                    iR = iR &gt; 255 ? 255 : iR;
                    iR = iR &lt; 0 ? 0 : iR;
                    int iG = (int)Green;
                    iG = iG &gt; 255 ? 255 : iG;
                    iG = iG &lt; 0 ? 0 : iG;
                    int iB = (int)Blue;
                    iB = iB &gt; 255 ? 255 : iB;
                    iB = iB &lt; 0 ? 0 : iB;

                    data[y, x, 0] = (byte)iB;
                    data[y, x, 1] = (byte)iG;
                    data[y, x, 2] = (byte)iR;
                }
            }
            pictureBox1.Image = imgColor.ToBitmap();
</code></pre>

<p>I also adjust the gamma using this method:</p>

<pre><code>double intensity = grayCurrent.GetAverage().Intensity;
double g = Math.Log(Shared.Optimum / 255) / Math.Log(intensity / 255);
grayCurrent._GammaCorrect(g);
</code></pre>

<p>This certainly helps me with the motion detection but want I am now focusing on is improving what the User 'sees' as opposed to what computer detects..</p>
",2014-03-20 14:52:31,2014-03-20 14:52:31,"Relationship between hue, saturation, luminance and contrast",<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
17487,19077422,2013-09-29 11:17:24,,"<p>I'm trying to develop an application that would detect the upper body and lower body of a person through a webcam. I tried to look at emgu's face detection and downloaded ""haarcascade_upperbody.xml"" and ""haarcascade_lowerbody.xml"". I tried to code something same with the face detection given</p>

<p>But the problem is that it won't detect my body and it's not in real-time any more. It delays by 3 seconds?</p>

<p>Here's my code. I hope someone can help me:</p>

<pre><code>private void ProcessFrame(object sender, EventArgs arg)
    {
        Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
        FittingBox.Image = ImageFrame;

        long detectionTime;

        List&lt;Rectangle&gt; upper = new List&lt;Rectangle&gt;();
        List&lt;Rectangle&gt; lower = new List&lt;Rectangle&gt;();
        Detect(ImageFrame,""haarcascade_upperbody.xml"",""haarcascade_lowerbody.xml"",upper,lower,out detectionTime);
        foreach (Rectangle up in upper)
            ImageFrame.Draw(up, new Bgr(Color.Red), 2);
        foreach (Rectangle low in lower)
            ImageFrame.Draw(low, new Bgr(Color.Blue), 2);
    }



 public static void Detect(Image&lt;Bgr, Byte&gt; image, String upperFileName, String lowerFileName, List&lt;Rectangle&gt; upperbody, List&lt;Rectangle&gt; lowerbody, out long detectionTime)
    {
        Stopwatch watch;

        if (GpuInvoke.HasCuda)
        {
            using (GpuCascadeClassifier upper = new GpuCascadeClassifier(upperFileName))
            using (GpuCascadeClassifier lower = new GpuCascadeClassifier(lowerFileName))
            {
                watch = Stopwatch.StartNew();
                using (GpuImage&lt;Bgr, Byte&gt; gpuImage = new GpuImage&lt;Bgr, byte&gt;(image))
                using (GpuImage&lt;Gray, Byte&gt; gpuGray = gpuImage.Convert&lt;Gray, Byte&gt;())
                {
                    Rectangle[] upperRegion = upper.DetectMultiScale(gpuGray, 1.1, 10, Size.Empty);
                    upperbody.AddRange(upperRegion);
                    foreach (Rectangle f in upperRegion)
                    {
                        using (GpuImage&lt;Gray, Byte&gt; upperImg = gpuGray.GetSubRect(f))
                        {
                            using (GpuImage&lt;Gray, Byte&gt; clone = upperImg.Clone())
                            {
                                Rectangle[] lowerRegion = lower.DetectMultiScale(clone, 1.1, 10, Size.Empty);

                                foreach (Rectangle e in lowerRegion)
                                {
                                    Rectangle lowerRect = e;
                                    lowerRect.Offset(f.X, f.Y);
                                    lowerbody.Add(lowerRect);
                                }
                            }
                        }
                    }
                }
                watch.Stop();
            }
        }
        else
        {
            using (CascadeClassifier upper = new CascadeClassifier(upperFileName))
            using (CascadeClassifier lower = new CascadeClassifier(lowerFileName))
            {
                watch = Stopwatch.StartNew();
                using (Image&lt;Gray, Byte&gt; gray = image.Convert&lt;Gray, Byte&gt;())
                {
                    gray._EqualizeHist();
                    Rectangle[] upperDeteced = upper.DetectMultiScale(
                        gray,
                        1.1,
                        10,
                        new Size(50, 50),
                        Size.Empty);

                    foreach (Rectangle f in upperDeteced)
                    {
                        gray.ROI = f;

                        Rectangle[] lowerDetected = lower.DetectMultiScale(
                            gray,
                            1.1,
                            10,
                            new Size(50, 50),
                            Size.Empty);
                        gray.ROI = Rectangle.Empty;

                        foreach (Rectangle e in lowerDetected)
                        {
                            Rectangle lowerRect = e;
                            lowerRect.Offset(f.X, f.Y);
                            lowerbody.Add(lowerRect);
                        }
                    }
                }
                watch.Stop();
            }
        }
        detectionTime = watch.ElapsedMilliseconds;
    }  
</code></pre>
",,2015-02-24 21:59:00,emgucv bodydetection using haarcascade,<c#><winforms><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
17522,22537594,2014-03-20 15:25:35,,"<p>I have an image and I want to find the most dominant lowest hue colour and the most dominant highest hue colour from an image.</p>

<p>It is possible that there are several colours/hues that are close to each other in populace to be dominant and if that is the case I would need to take an average of the most popular.</p>

<p>I am using emgu framework here.</p>

<p>I load an image into the HSV colour space.</p>

<p>I split the hue channel away from the main image.</p>

<p>I then use the DenseHistogram to return my ranges of 'buckets'.</p>

<p>Now, I could enumerate through the bin collection to get what I want but I am mindful of conserving memory when and wherever I can.</p>

<p>So, is there a way of getting what I need at all from the DenseHistogram 'object'?</p>

<p>i have tried MinMax (as shown below) and I have consider using linq but not sure if that is expensive to use and/or how to use it with just using a float array.</p>

<p>This is my code so far:</p>

<pre><code>            float[] GrayHist;

            Image&lt;Hsv, Byte&gt; hsvSample = new Image&lt;Hsv, byte&gt;(""An image file somewhere"");
            DenseHistogram Histo = new DenseHistogram(255, new RangeF(0, 255));
            Histo.Calculate(new Image&lt;Gray, Byte&gt;[] { hsvSample[0] }, true, null);
            GrayHist = new float[256];
            Histo.MatND.ManagedArray.CopyTo(GrayHist, 0);
            float mins;
            float maxs;
            int[] minVals;
            int[] maxVals;

            Histo.MinMax(out mins, out maxs, out minVals, out maxVals); //only gets lowest and highest and not most popular
            List&lt;float&gt; ranges= GrayHist.ToList().OrderBy( //not sure what to put here..
</code></pre>
",,2014-03-20 15:25:35,get the lowest and highest most popular hue color from an image,<c#><image-processing><histogram><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
17534,18144752,2013-08-09 10:33:34,,"<p>I'm creating a simple application in C# and I would like to be able to colour the roads on a map with different colours, a road map, not a satellite image. As you can see in the image below.
Do you know of any API or sample that would meet my needs? Thanks in advance. </p>

<p><img src=""https://i.stack.imgur.com/RzDOZ.png"" alt=""""></p>
",2013-08-09 10:48:15,2013-08-09 10:48:15,colouring the road with different colours on map,<c#><image-processing><emgucv>,2013-08-09 17:13:19,,CC BY-SA 3.0,False,False,True,False,False
17570,24794199,2014-07-17 03:03:05,,"<p>I use EmguCV  open webcam in unity. 
But it's fps is low much.</p>

<h2>this is my code ↓</h2>

<p><i></p>

<pre><code>private Texture2D texture;
private Capture capture;
private Color32[] color = new Color32[640*480];
// Use this for initialization
void Start () {
    texture = new Texture2D (640, 480);
    capture = new Capture ();
}

// Update is called once per frame
void Update () {

    Image&lt;Bgr, Byte&gt; currentFrame = capture.QueryFrame();
    Bitmap bitmapCurrentFrame = currentFrame.ToBitmap();
    Image&lt;Bgra, Byte&gt; img = new Image&lt;Bgra, Byte&gt; (bitmapCurrentFrame);


    for(int y=0; y&lt;480; y++){
        for(int x=0; x&lt;640; x++){

            int index = y+x*480;
            print(index+"";""+x+"";""+y);
            //byte b  = img.Data[x,y,0];
            color[index].r = img.Data[x,y,2];
            color[index].g = img.Data[x,y,1];
            color[index].b = img.Data[x,y,0];
            color[index].a = 0xff;
        }
    }
    texture.SetPixels32 (color);
    texture.Apply (false);
    renderer.material.mainTexture = texture;
}
</code></pre>

<h2></i></h2>

<p>i don't know why fps is so low...</p>

<p>and why my boss like EmguCV with Unity, why he don't use Unity-WebCamTexture...</p>

<p>OKAY,i really thank you for your read.</p>

<p>Hope, I can get some answer.</p>
",2014-07-17 06:16:25,2014-07-17 10:01:56,EmguCV + Unity Open WebCam is Error;,<unity3d><webcam><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
17597,19090449,2013-09-30 09:13:57,,"<h1>Work done</h1>

<p>I try to detect and read a license plate with these steps: <br><br>
1) Detect a quadrilateral by using houghlines (already got this problem with this step, sorry) <br> 
2) Correct the perspective of this quadrilateral to a rectangle <br>
3) Perform OCR on this rectangle <br></p>

<p>You can see the visual problem/effect of my code <a href=""http://snag.gy/8H4No.jpg"" rel=""nofollow"">here</a>. <br>
The code itself can be found <a href=""http://pastebin.com/q4KhhhyZ"" rel=""nofollow"">here</a>.</p>

<p><em>disclaimer:</em> I use Emgu CV for this, but if someone is kind enough to answer me, I don't want to bother him or her to give me an answer for this wrapper specifically.</p>

<pre><code>public string loadImage()
        {
            OpenFileDialog ofd = new OpenFileDialog();
            ofd.ShowDialog();
            String s = ofd.FileName.Normalize();
            return s;
        }

public void processImage()
        {
            String s = loadImage();
            Image&lt;Gray, Byte&gt; img = new Image&lt;Gray, byte&gt;(s);
            Console.WriteLine(""read file @"" + s);

            Image&lt;Gray, Byte&gt; tinyGrayImg = img.Resize(0.25, INTER.CV_INTER_NN);
            CvInvoke.cvShowImage(""original gray"", tinyGrayImg);
            Console.WriteLine(""converted "" + s + "" to grayscale"");

            Image&lt;Gray, Byte&gt; canny = new Image&lt;Gray, byte&gt;(CvInvoke.cvGetSize(tinyGrayImg));
            CvInvoke.cvCanny(tinyGrayImg, canny, 97, 225, 3);
            CvInvoke.cvShowImage(""canny"", canny);
            Console.WriteLine(""applied Canny to "" + s);

            try
            {
                MemStorage mem = new MemStorage();
                Image&lt;Bgr, byte&gt; linesImg = canny.Convert&lt;Bgr, byte&gt;();
                IntPtr lines = CvInvoke.cvHoughLines2(canny, mem.Ptr, HOUGH_TYPE.CV_HOUGH_PROBABILISTIC, 1, Math.PI /   180, 70, 30, 10);
                Seq&lt;LineSegment2D&gt; segments = new Seq&lt;LineSegment2D&gt;(lines, mem);
                LineSegment2D[] segArray = segments.ToArray();

                for (int i = 0; i &lt; segArray.Length; i++)
                {
                    linesImg.Draw(segArray[i], new Bgr(Color.Red), 1);
                }
                CvInvoke.cvShowImage(""lines"", linesImg);
            }
            catch (Exception e)
            {
                MessageBox.Show(e.Message);
            }
</code></pre>

<h1>Problem</h1>

<p>As you can see in the attached image (I don't have enough karma for direct adding images) the HOUGH_PROBABILISTIC filter does not work as I expected and I have no idea why the edges of the license plate aren't recognised. Any idea how to reach my goal is welcome. </p>
",2015-12-02 16:29:22,2015-12-02 16:29:22,houghLines doesn't detect the right lines. How to correct this?,<opencv><ocr><emgucv><hough-transform>,,,CC BY-SA 3.0,True,False,True,False,False
17606,21418493,2014-01-28 22:42:43,,"<p><strong>UPDATED QUESTION:</strong></p>

<p>Is it possible to binarize this image? I have a list of image, exactly the same with this picture.</p>

<p>I want the image to have black and white value only.</p>

<p><strong>UPDATE:</strong></p>

<p>I tried to binarize and remove noises from my images, but this is what I get. 
<img src=""https://i.stack.imgur.com/qtTuY.png"" alt=""enter image description here""></p>

<pre><code>for (int x = 0; x &lt; ExtractedBoxes.Count(); x++)
{
    FiltersSequence seq = new FiltersSequence();
    seq.Add(new Grayscale(0.2125, 0.7154, 0.0721));  //First add  GrayScaling filter
    seq.Add(new SISThreshold()); //Then add binarization(thresholding) filter
    ExtractedBoxes[x] = seq.Apply(ExtractedBoxes[x]); // Apply filters on source image
}
</code></pre>

<p>I tried to use that because it's the easiest way I found, but I think not efficient enough. It's from Aforge.net library. I used SISThreshold, because I can't get otsu threshold working, and Otsu is what I'm familiar the most.</p>

<p>Hoping you could give me better approach or other ways to clean them up. Thanks!</p>
",2014-02-05 22:37:30,2014-02-05 22:37:30,Binarize poor quality image,<c#><image><emgucv><threshold><adaptive-threshold>,,,CC BY-SA 3.0,False,False,True,False,False
17607,21419749,2014-01-29 00:25:36,,"<p>I'm new in computer vision.
I'm doing a project where I need to obtain a binary hand from a picture.
I uploaded an example. From <strong>picture 1</strong> I want to obtain <strong>picture 2</strong>.</p>

<p><img src=""https://i.stack.imgur.com/4ruGs.jpg"" alt=""Example""></p>

<p>I applied canny edge detector to <strong>picture 1</strong> but I obtained <strong>picture 3</strong> in the example.
I'm using EmguCV for it.</p>

<pre><code>Image&lt;Gray, Byte&gt; imgaux = new Image&lt;Gray, Byte&gt;(""example.bmp"");
imgaux = imgaux.Canny(100, 300);
</code></pre>

<p>My problem is that I don't have continuous edges, so I can't fill the hand to obtain <strong>picture 2</strong>.
What approach could be used to find a solution?</p>
",2014-01-29 00:31:59,2014-02-01 10:03:58,Deriving edges when not continuous,<computer-vision><emgucv><edge-detection>,,,CC BY-SA 3.0,False,False,True,False,False
17786,18166215,2013-08-10 20:50:32,,"<p>The JPEG compression steps are as follows:</p>

<p><strong>Raw image data</strong> -> forward DCT -> Quantization -> Entropy encoding -> <strong>JPEG image</strong></p>

<p>There are numbers of converters and APIs out there and the converting process is a single API call. I was unable to find a step by step code. My question is where can I find a code for each individual step, or can I perform these individual steps one by one and produce a standard JPEG image? I am using EmguCV for my image steganography project.</p>
",,2013-08-30 10:07:38,A code for step by step JPEG compression,<image><jpeg><emgucv><steganography><image-conversion>,,,CC BY-SA 3.0,False,False,True,False,False
17789,24813071,2014-07-17 20:36:30,,"<p>I know that this seems like a question that has been asked a million times, and it definitely helped, but I haven't been able to find anything that can help me with my specific problem. Overall, my project is centered about detecting a blinking LED that's blinking a Morse Code, and then translating that Morse Code. What I've done so far is I've thresholded an image so that only the LED will show up, everything else is black. The light from the LED is red. So what I want to do to start off is print out either a ""0"" or ""1"" depending on if the LED is on or off. However, I am not sure how to detect any color in an image. Here is the part of the code that I'm working on currently </p>

<pre><code>if(frameFromCamera-&gt;InRange(new Bgr(0, 0, 200),new Bgr(0, 0, 255)) == 255){
        tbMorse-&gt;Text =""1"";
    }
    else{
        tbMorse-&gt;Text = ""0"";
    }
</code></pre>

<p>But I am getting the following error. </p>

<pre><code>BAOTFISInterface.cpp(1010): error C2664: 'Emgu::CV::Image&lt;TColor,TDepth&gt;    ^Emgu::CV::Image&lt;TColor,unsigned short&gt;::InRange(Emgu::CV::Image&lt;TColor,unsigned short&gt; ^,Emgu::CV::Image&lt;TColor,unsigned short&gt; ^)' : cannot convert parameter 1 from 'Emgu::CV::Structure::Bgr *' to 'Emgu::CV::Image&lt;TColor,TDepth&gt; ^'
          with
          [
              TColor=Emgu::CV::Structure::Gray,
              TDepth=unsigned char
          ]
          and
          [
              TColor=Emgu::CV::Structure::Gray,
              TDepth=unsigned short
          ]
          No user-defined-conversion operator available, or
          Cannot convert an unmanaged type to a managed type
</code></pre>

<p>Does anyone know how to fix this? I'm using VS2010 so I have to use EMGU cv formatting to use the OpenCV library. This is all in Managed C++. I will take any pointers or suggestions that I can get.</p>
",2014-07-18 13:53:42,2014-07-18 13:53:42,Detecting color in video feed,<opencv><image-processing><colors><emgucv><managed-c++>,,,CC BY-SA 3.0,True,False,True,False,False
17803,22561466,2014-03-21 14:23:46,,"<p>I am using the Capture class from EmguCV to put the image from the camera on a Texture2D using LoadImage function. Before trying to do this, i was using the SetPixel function but it was too slow. </p>

<p>When I execute the code below, a red question mark on a white background appears instead of the image of the camera. </p>

<p>What am I doing wrong here ? </p>

<pre><code>public class testEmguCV : MonoBehaviour
{
    private Capture capture;

    void Start() 
    {
        capture = new Capture();
    }

    void Update()
    {
        Image&lt;Gray, Byte&gt; currentFrame = capture.QueryGrayFrame();
        Texture2D camera = new Texture2D(400, 400);
        if (currentFrame != null)
        {
            camera.LoadImage(currentFrame.Bytes);
            renderer.material.mainTexture = camera;
        }
     }
}
</code></pre>
",2014-12-29 09:08:57,2014-12-29 09:08:57,Texture2D.LoadImage() with EmguCV on Unity,<c#><unity3d><camera><emgucv><texture2d>,,,CC BY-SA 3.0,False,False,True,False,False
17836,22565092,2014-03-21 17:07:12,,"<p>Hi wlel I am doing a project to recognize a pen using ANN with emgucv C# visual studio 2010. I have a question about ANN. I must train ANN in order to recognize a pen. So I have one neuron in ouput layer for two classification(a pen or not pen) So I train ANN with 1100 image of pens and my question is: Do I need to train ANN with any images that is not a pen for the second class(first class is a pen) or If I show a image that ANN was not trained, ANN will assume that is not a pen?</p>
",,2014-03-21 18:03:35,Classification using ANN,<c#><artificial-intelligence><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
17855,20271572,2013-11-28 17:10:04,,"<p>I have two GUIs employing the same DLL (which I wrote) to process the same image. I have a strange issue where the image seems to be quantized by one of the GUIs despite the GUI not handling the image at all (the DLL does all the processing). I know this because I set a breakpoint immediately after the image is loaded within the DLL and then I write it to disk. When I create a histogram of the image I get different results for each GUI. Here's the first histogram (which is identical to the original image's histogram): <img src=""https://i.stack.imgur.com/FY4WC.png"" alt=""enter image description here""></p>

<p>And here's the second:
<img src=""https://i.stack.imgur.com/7e62T.png"" alt=""enter image description here""></p>

<p>My best guess is that it's a 32/64 bit issue. I'm running both GUIs on my 64 bit machine using OpenCV version 2.2 32 bit DLLs. The first GUI has platform x86 and the second has platform Active (x86). Any ideas on how to fix this?</p>
",,2013-11-28 17:10:04,"Image being quantized, but I have no idea why",<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
17871,19109973,2013-10-01 07:03:56,,"<p>i am new and got a job to build software to create a program to record videos from usb cameras and save it to the hard drive. I managed to get the dialog to work if i replace the fourcc method with -1 and use file extension to .avi. The file is being created but the recording is not present and the file size remains 0kb. dont know what to do. my code:</p>

<p>private Emgu.CV.Capture capture;<br>
        private bool captureInProgress;</p>

<pre><code>    public CameraCapture()
    {
        InitializeComponent();
    }
    //------------------------------------------------------------------------------//
    //Process Frame() below is our user defined function in which we will create an EmguCv 
    //type image called ImageFrame. capture a frame from camera and allocate it to our 
    //ImageFrame. then show this image in ourEmguCV imageBox
    //------------------------------------------------------------------------------//

    VideoWriter writer;
    private void ProcessFrame(object sender, EventArgs arg)
    {
        Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
        CamImageBox.Image = ImageFrame;

        writer = new VideoWriter(@""C:\Video.mpeg"", CvInvoke.CV_FOURCC('L','M','P','2'), (int)Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FPS, (int)Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, (int)Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, true);

    }

    //btnStart_Click() function is the one that handles our ""Start!"" button' click 
    //event. it creates a new capture object if its not created already. e.g at first time
    //starting. once the capture is created, it checks if the capture is still in progress,
    //if so the
    private void btnStart_Click(object sender, EventArgs e)
    {
        #region if capture is not created, create it now
        if (capture == null)
        {
            try
            {
                capture = new Emgu.CV.Capture();
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(excpt.Message);
            }
        }
        #endregion

        if (capture != null)
        {
            if (captureInProgress)
            {  //if camera is getting frames then stop the capture and set button Text
                // ""Start"" for resuming capture
                btnStart.Text = ""Start!""; //
                Application.Idle -= ProcessFrame;

            }
            else
            {
                //if camera is NOT getting frames then start the capture and set button
                // Text to ""Stop"" for pausing capture
                btnStart.Text = ""Stop"";
                Application.Idle += ProcessFrame;
            }

            captureInProgress = !captureInProgress;
        }


    }

    private void ReleaseData()
    {
        if (capture != null)
            capture.Dispose();
    }
</code></pre>

<hr>

<p>I Found my problem while using a messagebox. turns out the ProcessFrame keeps on working so i made some changes. this is my new code.private Emgu.CV.Capture capture;<br>
        private bool captureInProgress;</p>

<pre><code>    public CameraCapture()
    {
        InitializeComponent();
    }
    //------------------------------------------------------------------------------//
    //Process Frame() below is our user defined function in which we will create an EmguCv 
    //type image called ImageFrame. capture a frame from camera and allocate it to our 
    //ImageFrame. then show this image in ourEmguCV imageBox
    //------------------------------------------------------------------------------//

    VideoWriter writer;
    private void ProcessFrame(object sender, EventArgs arg)
    {
        Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
        CamImageBox.Image = ImageFrame;
        writer.WriteFrame(ImageFrame);
    }

    //btnStart_Click() function is the one that handles our ""Start!"" button' click 
    //event. it creates a new capture object if its not created already. e.g at first time
    //starting. once the capture is created, it checks if the capture is still in progress,
    //if so the
    private void btnStart_Click(object sender, EventArgs e)
    {
        #region if capture is not created, create it now
        if (capture == null)
        {
            try
            {
                capture = new Emgu.CV.Capture();
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(excpt.Message);
            }
        }
        #endregion

        if (capture != null)
        {
            if (captureInProgress)
            {   //if camera is getting frames then stop the capture and set button Text
                // ""Start"" for resuming capture
                btnStart.Text = ""Start!""; //
                writer.Dispose();
                writer = null;
                Application.Idle -= ProcessFrame;
            }
            else
            {
                //if camera is NOT getting frames then start the capture and set button
                // Text to ""Stop"" for pausing capture
                btnStart.Text = ""Stop"";
                writer = new VideoWriter(@""C:\Video.avi"", -1, (int)Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FPS, 640,480, true);
                Application.Idle += ProcessFrame;
            }
            captureInProgress = !captureInProgress;
        }
    }

    private void ReleaseData()
    {
        if (capture != null)
        {
            writer.Dispose();
            writer = null;
            capture.Dispose();
        }
    }
</code></pre>
",2013-10-01 07:43:22,2013-10-01 07:43:22,Emgu file size remains 0kb,<opencv><video><video-capture><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
17917,20276268,2013-11-28 23:38:39,,"<p>Here is OpenCV types:  </p>

<pre><code>vector&lt;Point&gt; vectorPoint;
Mat mat;
</code></pre>

<p>What is equivalent types in EMGU of the types above?</p>
",,2017-02-18 06:41:33,What is equivalent type of vector<Point> and Mat in EMGU?,<opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
17963,23725209,2014-05-18 18:05:30,,"<p>I have program that works fine in my windows 8 x64. But when i try to run it in my laptop with windows 7 x64 i have some problems.</p>

<p>errors:</p>

<pre><code>A first chance exception of type 'System.ArgumentException' occurred in mscorlib.dll
Additional information: URI formats are not supported.

A first chance exception of type 'System.BadImageFormatException' occurred in Emgu.CV.dll
Additional information: You tried to load the wrong format. (Excluded from the HRESULT: 0x8007000B)

A first chance exception of type 'System.Reflection.TargetInvocationException' occurred in mscorlib.dll
Additional information: Target call threw an exception.

A first chance exception of type 'System.Reflection.TargetInvocationException' occurred in mscorlib.dll
Additional information: Target call threw an exception.

'InzV2.vshost.exe' (CLR v4.0.30319: InzV2.vshost.exe): Loaded 'C:\Windows\Microsoft.Net\assembly\GAC_MSIL\System.Xaml.resources\v4.0_4.0.0.0_pl_b77a5c561934e089\System.Xaml.resources.dll'. Module was built without symbols.
A first chance exception of type 'System.Xaml.XamlObjectWriterException' occurred in System.Xaml.dll
Additional information:Calling the constructor for the type of „InzV2.MainWindow” compatible with specific binding constraints caused an exception.

A first chance exception of type 'System.Windows.Markup.XamlParseException' occurred in PresentationFramework.dll
Additional information: Calling the constructor for the type of „InzV2.MainWindow” compatible with specific binding constraints caused an exception., line number 3, position 9.

An unhandled exception of type 'System.Windows.Markup.XamlParseException' occurred in PresentationFramework.dll
Additional information: Calling the constructor for the type of „InzV2.MainWindow” compatible with specific binding constraints caused an exception., line number 3, position 9.
</code></pre>

<p>This errror looks like this: 
<img src=""https://i.stack.imgur.com/DDRE7.jpg"" alt=""enter image description here""></p>

<p>I'm using Emgu.CV lib from Nuget called: myEmguCV.Net.</p>

<p>even if i try just crete new project with only:</p>

<pre><code>BackgroundSubtractorMOG2 pMog11 = new BackgroundSubtractorMOG2(0, 80, false);
</code></pre>

<p>i have error..</p>
",2014-05-19 07:32:45,2014-05-19 07:37:24,Emgu.CV dont work on windows 7 x64,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
17970,24829162,2014-07-18 15:51:35,,"<p>so what I'm trying to do is output a certain string depending on the color I see in the video feed. For right now, what I've done is threshold the feed so that everything above a certain brightness shows up as Red. Now I want to have something that says if there's any red in the feed, then I output a ""1"" to a text box on my user interface that's showing the feed. If there is no red, then I output a ""0"" to the text box. I'm using Emgu CV Managed C++ with VS2010, can anyone help me? Thank you. </p>

<p>This is the code I have so far that isn't working correctly, it's giving me a compiler error. </p>

<pre><code>cvConvertScaleAbs(frameFromCamera-&gt;Ptr.ToPointer(),frameDisplay-&gt;Ptr.ToPointer(),double(1)/16,0);
    cvCvtColor(frameDisplay-&gt;Ptr.ToPointer(),frameColorDisplay-&gt;Ptr.ToPointer(),CV_GRAY2BGR);
    cvThreshold(frameDisplay-&gt;Ptr.ToPointer(),maskSaturated-&gt;Ptr.ToPointer(),200,255,CV_THRESH_BINARY);
    cvNot(maskSaturated-&gt;Ptr.ToPointer(),mask1-&gt;Ptr.ToPointer());
    cv::Scalar red(0,0,255);
    cvSet(frameColorDisplay-&gt;Ptr.ToPointer(),red,maskSaturated-&gt;Ptr.ToPointer());

    highColor = gcnew Emgu::CV::Image&lt;Bgr,UInt16&gt;(0, 0, 255);
    lowColor = gcnew Emgu::CV::Image&lt;Bgr,UInt16&gt;(0, 0, 200);

    if(maskSaturated-&gt;InRange(lowColor, highColor) == 255){
        tbMorse-&gt;Text =""1"";
    }
    else{
        tbMorse-&gt;Text = ""0"";
    }
    imageMain-&gt;Image=frameColorDisplay;
</code></pre>

<p>and i have highColor and lowColor initialized in my header as such</p>

<pre><code>Emgu::CV::Image&lt;Bgr,UInt16&gt; ^lowColor;
    Emgu::CV::Image&lt;Bgr,UInt16&gt; ^highColor;
</code></pre>

<p>and the error it's giving me is </p>

<pre><code> BAOTFISInterface.cpp(1010): error C2664: 'Emgu::CV::Image&lt;TColor,TDepth&gt;::Image(int,int,Emgu::CV::Structure::Bgr)' : cannot convert parameter 3 from 'int' to 'Emgu::CV::Structure::Bgr'
      with
      [
          TColor=Emgu::CV::Structure::Bgr,
          TDepth=unsigned short
      ]
      No user-defined-conversion operator available that can perform this conversion,         or the operator cannot be called
 BAOTFISInterface.cpp(1011): error C2664: 'Emgu::CV::Image&lt;TColor,TDepth&gt;::Image(int,int,Emgu::CV::Structure::Bgr)' : cannot convert parameter 3 from 'int' to 'Emgu::CV::Structure::Bgr'
      with
      [
          TColor=Emgu::CV::Structure::Bgr,
          TDepth=unsigned short
      ]
      No user-defined-conversion operator available that can perform this conversion, or the operator cannot be called
 BAOTFISInterface.cpp(1013): error C2664: 'Emgu::CV::Image&lt;TColor,TDepth&gt; ^Emgu::CV::Image&lt;TColor,TDepth&gt;::InRange(Emgu::CV::Image&lt;TColor,TDepth&gt; ^,Emgu::CV::Image&lt;TColor,TDepth&gt; ^)' : cannot convert parameter 1 from 'Emgu::CV::Image&lt;TColor,TDepth&gt; ^' to 'Emgu::CV::Image&lt;TColor,TDepth&gt; ^'
      with
      [
          TColor=Emgu::CV::Structure::Gray,
          TDepth=unsigned char
      ]
      and
      [
          TColor=Emgu::CV::Structure::Bgr,
          TDepth=unsigned short
      ]
      and
      [
          TColor=Emgu::CV::Structure::Gray,
          TDepth=unsigned char
      ]
      No user-defined-conversion operator available, or
      Types pointed to are unrelated; conversion requires reinterpret_cast, C-style cast or function-style cast
</code></pre>
",2014-07-18 16:56:47,2014-07-18 16:56:47,Outputting string depending on color detected in video feed,<opencv><c++-cli><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18046,22580807,2014-03-22 17:09:31,,"<p>I am new in this website. Well I am doing a project to recognize an apple using ANN emgucv, C# and visual studio 2010. I have 4000 images that contains different colors and rotations of apple. I have 2 classes that means I have 1 neuron in output layer(it is an apple and not). First class I will use 4000 image of apples but I do not know what images I must use to train second class. I want to use background images like rooms, bedrooms. is that a good idea? My project is about classfication is or not is an apple and I do not want to recognize grapes or other fruits .I give a images and I want to recgonize if that images contains an apple or not.</p>
",,2014-03-27 08:37:27,Training set to train artificial neural network,<c#><neural-network><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18053,22582221,2014-03-22 19:09:42,,"<p>I am  currently working with EmguCV in VB.NET.
My program can't open the image, and I don't understand why.</p>

<p>Note: the line to open the file was converted by a software from C# to VB.NET .</p>

<p>What might be the problem in the code?</p>

<pre><code>Imports Emgu.CV
Imports Emgu.CV.Util
Imports Emgu.CV.Structure

Module analyse

' module général d'analyse
' on assume que les images soient dans le dossier /images/...
' les images ont déjà été tresholdé par le backend

Sub detect_lines()

    Dim RhoRes As Double = 2
    Dim Threshold As Double = 100
    Dim MinLineWidth As Double = 1
    Dim linegap As Integer = 3
    Dim ThetaRes As Double = Math.PI / 180

    Dim image = CvInvoke.cvLoadImage(""frame3.jpg"", 1)
    Dim img As New Image(Of Bgr, Byte)(""frame3.jpg"")

    Dim Linez()() As LineSegment2D = img.HoughLinesBinary(RhoRes, ThetaRes, Threshold, 0, 0)

    If Linez(0).Length = 0 Then 'Greater than or equal to
        For i = 0 To Linez(0).Length - 1

            If Linez(0)(i).Length = 10 And Linez(0)(i).Length = 30 Then 'Greater than and less than or equal to
                img.Draw(Linez(0)(i), New Bgr(0, 255, 0), 3)
            End If

            If Linez(0)(i).Length = 30 And Linez(0)(i).Length = 60 Then 'Greater than and less than or equal to
                img.Draw(Linez(0)(i), New Bgr(255, 0, 0), 3)
            End If

            If Linez(0)(i).Length = 60 Then
                img.Draw(Linez(0)(i), New Bgr(0, 0, 255), 3)
            End If

        Next
    End If

    MsgBox(Linez.ToString)

End Sub
End Module
</code></pre>
",2014-03-24 08:43:15,2014-03-24 08:43:15,EMGU doesn't work for me - cannot open local image,<vb.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18118,20295557,2013-11-30 01:39:48,,"<p>I want to get and save all the frames from a ~30 second (30fps) video.</p>

<p>The program VirtualDub shows me that my movie has 930 frames, but my program saves only 474. My code is as follows:</p>

<pre><code>string name = @""D:\movie-01-no.avi"";
Capture _capture = new Capture(name);
int frame = 0;
while (_capture.Grab())
{
    frame++;
    Image&lt;Bgr, byte&gt; image = _capture.RetrieveBgrFrame();
    Bitmap bmp = new Bitmap(image.ToBitmap());
    bmp.Save(@""D:\"" + frame + "".bmp"");
    bmp.Dispose();
}
</code></pre>

<p>or</p>

<pre><code>string name = @""D:\movie-01-no.avi"";

Capture _capture = new Capture(name);
int frame = 0;
bool Reading = true;

while (Reading)
{
    frame++;
    Image&lt;Bgr, Byte&gt; image = _capture.QueryFrame();
    if (image != null)
    {
        Bitmap bmp = new Bitmap(image.ToBitmap());
        bmp.Save(@""D:\"" + frame + "".bmp"");
        bmp.Dispose();
    }
    else
    {
        Reading = false;
    }
}
</code></pre>

<p>In both cases it doesn't save 930 frames. Why? How I can fix it?</p>
",2014-04-07 15:38:34,2015-11-07 23:21:18,Emgu CV doesn't get all frames from video,<c#><save><emgucv><frames>,,,CC BY-SA 3.0,False,False,True,False,False
18152,18197885,2013-08-12 22:44:53,,"<p>I am currently working to get Emgu set up for use on my computer.  I have Downloaded a 32 bit installation from sourceforge and installed it.  I have created a console project and added the following dll's as references:
 - Emgu.CV
 - Emgu.CV.DebuggerVisualizers.VS2010
 - Emgu.CV.GPU 
 - Emgu.CV.ML
 - Emgu.CV.OCR
 - Emgu.CV.Stitching
 - Emgu.CV.UI
 - Emgu.CV.VideoStab
 - Emgu.Util
(I know that I don't need all of these for each project, but I put them in anyway)</p>

<p>I also added opencv_core242.dll as well as the other dll's in the same folder to the output folder as <a href=""https://stackoverflow.com/questions/13875514/unable-to-load-dll-opencv-core242-the-specified-module-could-not-be-found-em"">this</a> answer suggested.</p>

<p>I added the folder containing opencv_core242.dll to the as a path variable on my comp like <a href=""http://www.youtube.com/watch?v=vdjoutNR2DQ"" rel=""nofollow noreferrer"">this</a> video suggests.</p>

<p>However, I am still getting the following error</p>

<pre><code>'Emgu.CV.CVInvoke' threw an exception. ---&gt; System.DllNotFoundException: Unable to load DLL 'opencv_core242': The device is not ready. (Exception from HRESULT 0x80070015) ...
</code></pre>

<p>Any Ideas on what I am forgetting or what else I need to do?</p>
",2017-05-23 12:08:09,2016-08-11 14:30:32,Emgu: Unable to load DLL. Device is not ready,<dll><installation><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18220,20302616,2013-11-30 16:25:56,,"<p>I have image:</p>

<pre><code>Image&lt;Bgr,Byte&gt; someImage = new Image&lt;Bgr,Byte&gt;(someImage.jpg);   
</code></pre>

<p><img src=""https://i.stack.imgur.com/RmJ9k.jpg"" alt=""enter image description here""></p>

<p>How can I make all black pixels(black color) transparent?</p>

<p>Thank you in advance.</p>
",,2013-12-01 06:03:56,How can I make black color to transparent color?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18255,18204998,2013-08-13 09:10:04,,"<p>Can anyone tell me why EMGU throws an exception when trying to write out a greyscale image?  Here is what I do:</p>

<p>gCam.StartAcquisition();
            Debug.WriteLine(""recording..."");</p>

<pre><code>        //Bitmap safeImage = new Bitmap(xiImageWidth, xiImageHeight, 
        //System.Drawing.Imaging.PixelFormat.Format8bppIndexed);

        Bitmap safeImage = new Bitmap(xiImageWidth, xiImageHeight,
                                                               System.Drawing.Imaging.PixelFormat.Format16bppGrayScale );

        //Emgu.CV.Image&lt;Gray, Byte&gt; currentFrame;
        Emgu.CV.Image&lt;Gray, UInt16&gt; currentFrame;

        gCam.GetImage(safeImage, XI_CAPTURE_TIMEOUT);

        //currentFrame = new Image&lt;Gray, Byte&gt;(safeImage);
        currentFrame = new Image&lt;Gray, UInt16&gt;(safeImage);
        currentFrame.Save(""testImage.bmp"");

        startTime = DateTime.Now;

        if (emguVideoWriter.Ptr != IntPtr.Zero)
        {
                emguVideoWriter.WriteFrame(currentFrame);
        }
</code></pre>

<p>When I use MONO8 and Image I have no problem, but if I try to go 16-bit I get this exception:</p>

<pre><code>A first chance exception of type 'System.ArgumentException' occurred in System.Drawing.dll
exception caught while recording a frame! ex=System.ArgumentException: Parameter is not valid.
   at System.Drawing.Bitmap.GetPixel(Int32 x, Int32 y)
   at Emgu.CV.Image`2.set_Bitmap(Bitmap value) in C:\Emgu\emgucv-windows-x64 2.4.0.1717\Emgu.CV\Image.cs:line 2866
   at Emgu.CV.Image`2..ctor(Bitmap bmp) in C:\Emgu\emgucv-windows-x64 2.4.0.1717\Emgu.CV\Image.cs:line 213
</code></pre>

<p>This has been driving me crazy as I don't see why I cannot write out 16-bit images.  I was hoping VideoWriter would make my life easier but instead it is just complicating matters.  I almost feel like just writing out the raw bytes myself at this point!</p>
",,2013-08-13 09:21:27,EMGU crashes when trying to write out greyscale image to VideoWriter,<opencv><video-capture><emgucv><opencvdotnet>,,,CC BY-SA 3.0,True,False,True,False,False
18304,22598530,2014-03-23 23:28:50,,"<p>Hello everybody I have the error that said:The call is ambiguous between the followings method. This is my code</p>

<pre><code>      Matrix&lt;int&gt; layerSize = new Matrix&lt;int&gt;(new int[] { 400, 200,2  });

      MCvANN_MLP_TrainParams parameters = new MCvANN_MLP_TrainParams();
      parameters.term_crit = new MCvTermCriteria(10, 1.0e-8);
      parameters.train_method = Emgu.CV.ML.MlEnum.ANN_MLP_TRAIN_METHOD.BACKPROP;
      parameters.bp_dw_scale = 0.1;
      parameters.bp_moment_scale = 0.1;

      using (ANN_MLP network = new ANN_MLP(layerSize,   Emgu.CV.ML.MlEnum.ANN_MLP_ACTIVATION_FUNCTION.SIGMOID_SYM, 1.0, 1.0))
      {
          network.Train(train, clases, null, null, parameters, Emgu.CV.ML.MlEnum.ANN_MLP_TRAINING_FLAG.DEFAULT);


      }
</code></pre>

<p>I know that problem is that the compiler do not understand what method of property I want to use but using network.train() I have 3 options and the problem is that:</p>

<p>Train(
    Matrix trainData,
    Matrix responses,
    <strong>Matrix sampleWeights,
    Matrix sampleIdx,</strong>
    MCvANN_MLP_TrainParams parameters,
    ANN_MLP_TRAINING_FLAG flag
)</p>

<p>Train(
    Matrix trainData,
    Matrix responses,
    <strong>Matrix sampleWeights,
    Matrix sampleMask,</strong>
    MCvANN_MLP_TrainParams parameters,
    ANN_MLP_TRAINING_FLAG flag
)</p>

<p>I don't want to use Matrix sampleWeights,Matrix sampleMask for that reason I put null in both and so compiler do not know what constructor I want to use. Do you have any solution for that?</p>
",,2014-03-23 23:46:10,The call is ambiguous between the followings methods Train Neural network,<c#><neural-network><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18311,23753328,2014-05-20 07:20:49,,"<p>I'm trying to implement <a href=""http://perso.ensta-paristech.fr/~garrigues/video_extruder.html"" rel=""nofollow"">this</a> semi dense point tracking using Emgu cv. Can anyone help me to find the algorithms implemented in this <a href=""https://github.com/matt-42/cuimg.git"" rel=""nofollow"">https://github.com/matt-42/cuimg.git</a> c++ package. There are many header and cpp files i cannot figure out the relevant methods used. Or can someone guide me to compile the sample tracking file given inside c++ project using visual studio 2010 . it's in here <a href=""https://github.com/matt-42/cuimg/tree/master/samples/tracking"" rel=""nofollow"">https://github.com/matt-42/cuimg/tree/master/samples/tracking</a> </p>

<p>I'm trying to convert this c++ project because Optical flow in Emgu Cv doesn't give satisfying result when tracking motion a moving camera. I found above c++ project which tracks point in a scene very accurately.But I'm not very good at c++. Can someone guide me how to start. Your help is really appreciated.</p>
",,2014-05-20 07:20:49,Semi dense point tracking,<c++><opencv><image-processing><emgucv><opticalflow>,,,CC BY-SA 3.0,True,False,True,False,False
18333,18208222,2013-08-13 11:43:57,,"<p>I copy a part of an image to a new one:</p>

<pre><code>bigImage.ROI = SomeRectangle;
Emgu.CV.Image&lt;Emgu.CV.Structure.Rgb, byte&gt; roiImage = bigImage.Copy();
</code></pre>

<p>Now <code>roiImage.Cols==roiImage.Width==1</code> and <code>roiImage.Rows==roiImage.Height==106</code>; however size of <code>roiImage.Data</code> is <code>[106,4,3]</code>. So Width of image is not equal to the second dimension of the data.</p>

<p>Why does that occur?</p>
",,2013-08-13 12:26:49,EmguCV Image size different from Image.Data size,<c#><image><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18343,19146733,2013-10-02 20:59:58,,"<p>I would like to find a piece of an image inside another image. However, I have some regions pixels in both images that I don't want to take into account. So I was thinking of using some type of mask with zeros or ones to indicate the good pixels. </p>

<p>I am using the MatchTemplate method from emgu and it does not accept a mask. Is there any other way of doing what I would like to do? Thank you!</p>

<pre><code>ReferenceImage.MatchTemplate(templateImage, Emgu.CV.CvEnum.TM_TYPE.CV_TM_CCORR_NORMED);
</code></pre>
",,2013-10-08 03:03:45,Template matching usink mask in opencv (emgu),<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18358,20314148,2013-12-01 16:05:53,,"<p>I'm using EMGU wrapper.
I  split image to contours:</p>

<pre><code>  Contour&lt;Point&gt; contours = img.FindContours();
</code></pre>

<p>Is there any way to know whether the overlap between found contours.</p>
",,2018-07-26 14:45:33,overlap between found contours,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18395,19153938,2013-10-03 08:07:26,,"<p>I'm trying to create a program for webcam capture, in which I followed the online tutorial. I was able to debug it and deploy the program, but when I installed it on my PC the program failed to execute then gave an error message as follows </p>

<pre><code> Unhandled exception has occurred in your application. 
 The type initializer for Emgu.CV.CvInvoke' threw an exception. 
</code></pre>

<p>Has any one came across this kind of error? Please assist.
Thanks</p>
",2013-10-03 13:23:29,2013-10-03 13:23:29,Having issue with EmguCV,<c#><deployment><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18404,23759484,2014-05-20 12:12:02,,"<p>How can I track objects movement when the camera is moving. Example if the camera is inside a vehicle. So far I have tied the algorithms in Optical Flow in Emgu Cv. I want to get the horizontal movement of object. But they don't give enough results to detect a movement horizontally when camera is moving forward. </p>

<p>pyrLK is good point tracker but when i take the difference between new calculated point and previous points it doesn't make a sense, maybe for each frame there will be new points added. Is it possible with single camera or do i have to use stereo vision. Please someone suggest any help with this. I'll be really appreciated.  </p>

<p>thanks</p>

<p>(hope the question is not too broad)</p>
",,2014-06-18 14:00:27,Detect motion with moving camera,<c#><opencv><emgucv><opticalflow>,,,CC BY-SA 3.0,True,False,True,False,False
18496,20322315,2013-12-02 06:43:37,,"<p>how do i track points in a video in real time like in the below video.</p>

<p><a href=""https://www.youtube.com/watch?v=jg6Nz6BfoSQ"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=jg6Nz6BfoSQ</a> </p>

<p>I managed to use optical flow method to get this output to my video,
<img src=""https://i.stack.imgur.com/6Kr8c.png"" alt=""enter image description here""></p>

<p>But i couldn't find a way to point track with Emgu Cv. Can someone suggest what should I do?</p>

<p>In youTube video he used c++ as the language.Does the language type affect to the real time response of the system?</p>
",2014-04-17 09:56:15,2014-04-17 09:56:15,Point tracking Emgu cv?,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18507,17274372,2013-06-24 11:28:02,,"<p>I'm getting this error</p>

<blockquote>
  <p>The type initializer for 'Emgu.CV.CvInvoke' threw an exception.</p>
</blockquote>

<p>when I try to use Emgu CV. I've tried everything I can think of to fix this but it's still giving the same error, and when I click a button it shows</p>

<blockquote>
  <p>Object reference not set to an instance of an object.</p>
</blockquote>

<p>This is the code I'm trying:</p>

<pre><code>void ProcessFunction(object sender, EventArgs e)
{
    imgOrg = capturecam.QueryFrame();
    if (imgOrg == null) return;
    imgProc = imgOrg.InRange(new Bgr(50, 50, 50), new Bgr(255, 255, 255));
    imgProc = imgProc.SmoothGaussian(9);
    imageBox1.Image = imgOrg;
    imageBox2.Image = imgProc;
}
</code></pre>

<p>What might I have done wrong and how can I debug this further? Thanks!</p>
",2013-06-24 11:57:22,2020-07-11 22:37:42,The type initializer for 'Emgu.CV.CvInvoke' threw an exception,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18512,17277378,2013-06-24 14:00:09,,"<p>While carrying out EqualizeHist function invoked from EMGU, it throws the following error.</p>

<p>""Attempted to read or write protected memory. This is often an indication that other memory is corrupt.""</p>

<p>This error is happening for the images only with the following resolutions. For all other resolutions it is working fine. </p>

<pre><code>width = 1785 height = 1200
width = 1786 height = 1200
width = 1787 height = 1200
width = 1786 height = 1205
width = 1786 height = 1204
width = 1786 height = 1203
width = 1786 height = 1201
width = 1786 height = 1200
width = 1786 height = 1199
</code></pre>

<p>Following is the code </p>

<pre><code>Emgu.CV.Image&lt;Bgr, Byte&gt; imageCV = new Emgu.CV.Image&lt;Bgr, Byte&gt;(""file.jpg"");
Emgu.CV.Image&lt;Gray, byte&gt; grayframe = imageCV.Convert&lt;Gray, byte&gt;();
grayframe._EqualizeHist();
</code></pre>

<p>For example, width = 1786 height = 1200 throws error, while width = 1786 height = 1202 doesn't. You can easily recreate this error by resizing any image to the above mentioned resolution and it will throw the error.</p>

<p>I checked the above resolutions in C++ opencv and it works fine there.</p>

<p>Kindly let me know what could be the problem behind this error. </p>
",2013-06-24 23:13:11,2013-06-24 23:13:11,EMGU EqualizeHist throws error on specific image resolutions,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18535,24870167,2014-07-21 16:35:39,,"<p>I'm trying to get the difference between a thresholded image and the original image, both of which are grayscale. My logic is that if that there is no difference between the the thresholded image and the original image, then that means that there was nothing to threshold. </p>

<p>So I want to find the difference between the images, and if there is no difference, then I will output a ""0"" to the user interface I made with my camera, and if there is a difference, then I will output a ""1"". </p>

<p>I tried using the AbsDiff method and I tried using the MatchTemplate method, but neither of those worked, and I'm out of ideas. </p>

<p>I've searched around the internet and haven't found anything to be of much help. Has anyone does something like this before? Does anyone have any pointers as to what I should do? </p>
",2014-07-21 16:59:18,2014-07-22 14:50:00,Getting a boolean value for the difference between two images,<c++-cli><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18564,21496900,2014-02-01 10:30:36,,"<p>I have HSV type color and I want to convert it to BGR .It's not an image just an HSV object ?</p>

<pre><code>Hsv s = new Hsv((double)Hue, (double)Sat, (double)val);

//this is my HSV color object I need to convert it to BGR color object 
</code></pre>
",2014-02-03 06:30:31,2014-02-03 06:30:31,Emgu cv covent color from hsv to bgr,<c#><.net><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18610,21498426,2014-02-01 13:06:27,,"<p>well iam trying to make an object tracker i produced the filtered image which is tracking the object and convert it to white i used this to get the filtered image </p>

<pre><code> CvInvoke.cvInRangeS(HSVimg, low, high, THImg);
</code></pre>

<p>now iam trying to get the contours and get the center point so i used this (can't test it yet)</p>

<pre><code> using (Image&lt;Gray, Byte&gt; canny = smoothedRedMask.Canny(100.0, 50.0))
        using (MemStorage stor = new MemStorage())
        {
            Contour&lt;Point&gt; contours = canny.FindContours(
               Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
               Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_TREE,
               stor);

        }
</code></pre>

<p>so i have two questions what does canny method do ? 
how do i draw a shape around the tracked object then get the center point using moment or any other method ? 
u don't have to write code just give me reference to simple code that i can use </p>
",,2014-02-03 07:14:18,emgu c# object tracking moments,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18617,17285292,2013-06-24 21:18:23,,"<p>I have a Hue histogram for a specific image, as depicted in the following graph:</p>

<p><img src=""https://i.stack.imgur.com/Wdg9F.png"" alt=""enter image description here""></p>

<p>Here is the code that I use for calculating the Hue histogram (I'm using the EMGU wrapper):</p>

<pre><code>   Image&lt;Hsv, Byte&gt; hsvImage = originalImage.Convert&lt;Hsv, Byte&gt;();
   Image&lt;Gray, byte&gt;[] channels = hsvImage.Split();    
   DenseHistogram hist = new DenseHistogram(19, new RangeF(0,190));
   hist.Calculate(new IImage[1] { channel }, true, null);
</code></pre>

<p>I need to get the brightness histogram for the pixels which are located within the range between the red dotted lines.</p>

<p>Dos anyone have any ideas on how to implement this?</p>

<p>Thank you in advance.</p>
",2013-08-31 18:21:19,2013-08-31 18:21:19,How to calculate brightness histogram?,<opencv><histogram><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18634,17286609,2013-06-24 23:11:24,,"<p>I am Beginner in Emgu and I am trying to Build a Program that Controls Mouse by face Movments.i found a Program that Controls Mouse By Face motions in Emgu Examples.But ii work not Correctly and when debugging ends , program shows this error :
An attempt was made to load a program with an incorrect format. (Exception from HRESULT: 0x8007000B)</p>

<p>This Error showed when i was tried to Create a new object of HaarCascade by this instruction :
_face = new HaarCascade(""haarcascade_frontalface_default.xml"");</p>

<p>sorry,in can't wrie English well.</p>
",,2014-07-31 15:41:03,An attempt was made to load a program with an incorrect format. (Exception from HRESULT: 0x8007000B) Error,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18638,23778490,2014-05-21 08:57:24,,"<pre><code> Matrix&lt;float&gt; trainData = new Matrix&lt;float&gt;(150, 7);
</code></pre>

<p>this is the matrix Of 150x7 . now if i have a csv file containing 7 fields AND 150 rows(comma separated) that i want to load in this matrix. if any of done the same or related task then reply.. thank you </p>
",,2014-05-21 11:08:50,read CSV file and store data in matrix form using emgucv C#,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18681,24882350,2014-07-22 08:26:07,,"<p>I'm trying to find contours in the emgu image, but I discover that the number of found contours is not the same if the emgu image read from path or from bitmap.</p>

<p>Example........</p>

<pre><code>Image&lt;Bgr, byte&gt; emguPathImage = new Image&lt;Bgr, byte&gt;(path);
Image&lt;Gray, byte&gt; gray1 = emguPathImage .Convert&lt;Gray, Byte&gt;();


Bitmap bitmapImage = new Bitmap(path);
Image&lt;Bgr, byte&gt; emguBitmapImage = new Image&lt;Bgr, byte&gt;(bitmapImage);
Image&lt;Gray, byte&gt; gray2 = emguBitmapImage .Convert&lt;Gray, Byte&gt;();
</code></pre>

<p>Now when I tried to called findContours for gray1 and gray2, I get different number of contours</p>

<pre><code> var sourceContours1 = gray1.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_NONE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST);


 var sourceContours2 = gray2.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_NONE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST);
</code></pre>

<p>so is that possible to get exactly the same results, but why the results is different!</p>
",,2014-07-22 08:26:07,What's the difference between reading Emgu image from bitmap or path in find contours,<c#><bitmap><contour><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18750,19182299,2013-10-04 13:21:30,,"<blockquote>
  <p>object reference not set to an instance of an object</p>
</blockquote>

<p>My problem is that I try to use CV on a videofile (to simulate a camera) and I can't handle the frames, because RetrieveBgrFrame() doesn't return an image. Instead it gives the above error. My code is:</p>

<p><a href=""http://pastebin.com/DNEVwij8"" rel=""nofollow"">http://pastebin.com/DNEVwij8</a></p>

<p>Please tell me if you need additional details.</p>
",,2013-10-04 13:25:02,Why does RetrieveBgrFrame() return null?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18764,18245379,2013-08-15 02:25:00,,"<p>I have three Point A(a1,a2) , B (b1, b2) , C (c1, c2). How to draw arc through three point and calculate arc angle.</p>

<p>Thanks all.</p>

<p>[HERE] <a href=""http://photo.ssc.vn/view.php?filename=374df.png"" rel=""nofollow"">http://photo.ssc.vn/view.php?filename=374df.png</a></p>
",,2016-08-11 16:10:24,Draw arc through three point opencv,<emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18776,17299134,2013-06-25 13:49:41,,"<p>After using the HoughCircles method I have some trouble to get the center of the detected circles.
The documentation says I should use the public PointF Center { get; set; } method to get the center of the elements of a CircleF. But VS has a problem to convert the CicleF to an PointF.
I am not so familiar to C# so that I have no idea how to solve this problem. </p>

<p>Documentation Emgu CircleF[]: <a href=""http://www.emgu.com/wiki/files/2.0.0.0/html/9de6931a-17bc-4125-8b5e-e9f86e68889e.htm"" rel=""nofollow"">http://www.emgu.com/wiki/files/2.0.0.0/html/9de6931a-17bc-4125-8b5e-e9f86e68889e.htm</a>
Center of a CircleF: <a href=""http://www.emgu.com/wiki/files/2.0.0.0/html/b34b6d73-74c6-864e-a33a-1f9c6ce4cee9.htm"" rel=""nofollow"">http://www.emgu.com/wiki/files/2.0.0.0/html/b34b6d73-74c6-864e-a33a-1f9c6ce4cee9.htm</a></p>

<p>The documentation is for me very confusing, so can anybody help me with that problem?</p>
",2013-06-25 14:02:54,2013-06-25 14:02:54,How can i get the center of a circleF in Emgu (C#),<c#><center><geometry><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18791,23790666,2014-05-21 18:04:14,,"<p>I'm having problems with OpenCV SVM, specially the SVM from EmguCV, an OpenCV wrapper for C#. </p>

<p>I'm trying to find image regions using the SVM classifier. To do that, i'm using the image channels as points in a 3D coordinated space.</p>

<p><a href=""http://www.emgu.com/wiki/index.php/SVM_%28Support_Vector_Machine%29_in_CSharp"" rel=""nofollow"">The SVM example from emguCV</a> shows a 2-dimmensional classifier, but I need a 3-dimmensional classifier because of the 3 image channels: BGR.</p>

<p>The code bellow doesn't throws an exception:</p>

<pre><code>var trainData = new Matrix&lt;float&gt;(trainSampleCount, 2);
</code></pre>

<p>But, this code throws an exception in method TrainAuto:</p>

<pre><code>var trainData = new Matrix&lt;float&gt;(trainSampleCount, 3);
</code></pre>

<p>The exception is:</p>

<p><strong>the sample size is different from what has been used for training</strong></p>

<p>Can someone show me what is the problem?</p>

<p>Full code:</p>

<pre><code>public Image&lt;Bgr, byte&gt; Process(Image&lt;Bgr, byte&gt; image)
{
    const int kFold = 4;

    var svm = new SVM();

    var p = new SVMParams
    {
        KernelType = Emgu.CV.ML.MlEnum.SVM_KERNEL_TYPE.LINEAR,

        SVMType = Emgu.CV.ML.MlEnum.SVM_TYPE.C_SVC,

        C = 1,

        TermCrit = new MCvTermCriteria(100, 0.001)
    };

    RaVec3[] beach = {
                      new RaVec3(182, 240, 251),
                          new RaVec3(187, 210, 228),
                          new RaVec3(187, 210, 228),
                          new RaVec3(191, 215, 236)
                      };
    RaVec3[] montain = {
                      new RaVec3(44, 51, 52),
                          new RaVec3(43, 51, 52),
                          new RaVec3(84, 88, 69),
                          new RaVec3(36, 36, 26)
                      };
    RaVec3[] ocean = {
                      new RaVec3(149,148,101),
                          new RaVec3(245, 221, 195),
                          new RaVec3(149,147,101),
                          new RaVec3(148,145,92)
                      };
    RaVec3[] sky = {
                          new RaVec3(253,253,240),
                          new RaVec3(252,246,218),
                          new RaVec3(243, 253, 254),
                          new RaVec3(251,246,218)
                  };

    var trainSampleCount = 4 * 4;

    //Works with 2-dimmensional space, but throws an exceptions with 3-dimmensional space
    var trainData = new Matrix&lt;float&gt;(trainSampleCount, 3);
    var trainClasses = new Matrix&lt;float&gt;(trainSampleCount, 1);

        var count = 0;
        for (var i = 0; i &lt; 4; i++ ) {
            trainData[count, 0] = (float)beach[i].X;
            trainData[count, 1] = (float)beach[i].Y;
            trainData[count, 2] = (float)beach[i].Z;
            trainClasses[count, 0] = 0;
            count++;
        }
        for (var i = 0; i &lt; 4; i++) {
            trainData[count, 0] = (float)montain[i].X;
            trainData[count, 1] = (float)montain[i].Y;
            trainData[count, 2] = (float)montain[i].Z;
            trainClasses[count, 0] = 1;
            count++;
        }
        for (var i = 0; i &lt; 4; i++) {
            trainData[count, 0] = (float)ocean[i].X;
            trainData[count, 1] = (float)ocean[i].Y;
            trainData[count, 2] = (float)ocean[i].Z;
            trainClasses[count, 0] = 2;
            count++;
        }
        for (var i = 0; i &lt; 4; i++) {
            trainData[count, 0] = (float)sky[i].X;
            trainData[count, 1] = (float)sky[i].Y;
            trainData[count, 2] = (float)sky[i].Z;
            trainClasses[count, 0] = 3;
            count++;
        }

        //Here, the exception is thrown
        svm.TrainAuto(trainData, trainClasses, null, null, p.MCvSVMParams, kFold);

        for (var i = 0; i &lt; image.Height; i++)
        {
            for (var j = 0; j &lt; image.Width; j++)
            {
                var sample = new Matrix&lt;float&gt;(1, 2);
                sample.Data[0, 0] = j;
                sample.Data[0, 1] = i;

                var response = (int)svm.Predict(sample);

                image[i, j] =
                    response == 0 ? new Bgr(182, 240, 251) :
                    response == 1 ? new Bgr(44, 51, 52) :
                    response == 2 ? new Bgr(149, 148, 10) :
                    new Bgr(253, 253, 240);
            }
        }

        var c = svm.GetSupportVectorCount();
        for (var i = 0; i &lt; c; i++)
        {
            var v = svm.GetSupportVector(i);
            var p1 = new PointF(v[0], v[1]);
            image.Draw(new CircleF(p1, 4), new Bgr(128, 128, 128), 2);
        }

        return image;
    }
</code></pre>
",2014-05-23 11:46:02,2014-05-23 11:46:02,OpenCV SVM exception with BGR train sample,<c#><exception><opencv><svm><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18838,22642157,2014-03-25 17:33:32,,"<p>I made an application in C# following the EmguCV tutorials for capture of web camera.
Preview is working fine, but I can't change the camera properties like brightness,exposure etc. and I need to implement this in my application. In documention it's said I should do it with CAP_PROP Enumeration, but it's not working, here is my code where I change brightness:</p>

<pre><code>_capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_BRIGHTNESS, newBrightnessValue);
</code></pre>

<p>but nothing changes...</p>

<p>I found some responses on EmguCV forums, in which they say this should not be done with EmguCV, but I have done most of my project using EmguCV and I wouldn't like to start over with some other library just because of this :/</p>

<p>Is there some alternative way of doing this, but not too complicated like DirectShow?
Maybe some lib which could set these properties, without need to change the rest of code I have made using Emgu CV? </p>
",,2019-11-07 06:41:11,How to set webcam properties with EmguCV?,<c#><opencv><webcam><directshow><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18859,17303512,2013-06-25 17:14:41,,"<p>I'm working on veins detection from image using emgu CV and I have few questions. Is there any simple way to detect color or range of colors? Is there a simple way to replace this color with another (e.g. average color of the image)? How can I achive that without degrading the performance?</p>

<p>Thanks in advance!</p>
",,2016-07-29 06:10:30,Emgu CV color detection and replace,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
18879,18254651,2013-08-15 14:17:23,,"<p>I have OLED display and webcam Logitech C920 HD. What algorithms can I use for find broken pixels? Now I thresholding for finding broken pixels, but result is no good.</p>
",,2013-08-17 16:41:22,Find broken pixel in OLED,<opencv><computer-vision><webcam><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18902,20352929,2013-12-03 13:48:58,,"<p>I have an ASP.NET application that uses Emgu.CV for image processing.
All worked fine until today morning... Till then I am getting the error </p>

<blockquote>
  <p>{""Unable to load DLL 'opencv_core249': Das angegebene Modul wurde nicht gefunden. (Exception from HRESULT: 0x8007007E)""}</p>
</blockquote>

<p>That means something like ""Couldn't find the specified module""</p>

<p>when accessing a class from Emgu.CV. The ASP.NET application is beeing compiled as a x86 dll.
This is how the output folder looks like:
<img src=""https://i.stack.imgur.com/h1VTZ.png"" alt=""enter image description here""></p>

<p>the folder ""x86"" contains all 22 dll from opencv, while the folder lib contains the dll ""Emgu.CV.dll"".
Strange thing is it worked until now, so something must have changed that broke it. I have tried Clean solution, rebuild solution with no success. I've been on this problem the whole day now, I'm loosing patience :(</p>

<p>EDIT:
This is what DependencyWalker says:
<img src=""https://i.stack.imgur.com/2lHzl.png"" alt=""Missing dependencies""></p>
",2013-12-03 14:11:44,2014-01-21 13:22:43,Emgu.CV can't load dll's,<c#><asp.net><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
18919,18259465,2013-08-15 18:43:14,,"<p>I am trying to connect my camera with opencv, but window is showing a grey output screen with no image and output window of vc++ is showing the following error:</p>

<blockquote>
  <p>... 'opencv practice.exe': Loaded 'C:\Windows\SysWOW64\msyuv.dll',
  Cannot find or open the PDB file 'opencv practice.exe': Unloaded
  'C:\Windows\SysWOW64\msyuv.dll' ...</p>
</blockquote>

<p>i tried fining the msyuv.dll, and it is available there.</p>

<p>i have one further question, next to this, i want to implement this on unity3d, so should i stick with opencv or use emgucv?</p>

<pre><code>#include ""StdAfx.h""
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

#include &lt;opencv\cvaux.h&gt;
#include &lt;opencv\highgui.h&gt;
#include &lt;opencv\cxcore.h&gt;

using namespace std;

int main(int argc)
{
    CvCapture* cam = NULL;`
    cvNamedWindow(""hi"",CV_WINDOW_AUTOSIZE);

    IplImage* img = NULL;
    cam = cvCaptureFromCAM(-1);
    char a;
    while(1)
    {
        if(cam != NULL)
        {
            img = cvQueryFrame(cam);
        }
        else
        {
            printf(""erro1"");
            return -1;
        }

        cvShowImage(""hi"", img);
        a = cvWaitKey(20);
        if(a == 27)
            break;



    }

    cvReleaseCapture(&amp;cam);
    cvDestroyAllWindows();
    return 0;
}
</code></pre>
",2013-08-15 20:21:09,2013-08-15 20:21:09,OpenCV - can't get any output from camera,<c++><opencv><unity3d>,,,CC BY-SA 3.0,True,False,True,False,False
18937,19199305,2013-10-05 15:17:47,,"<p>I have been working on a fun coding project that uses emguCV along with C# and .NET . The problem I am having is trying to initialize the Capture() class in my code. Every time I try  to initialize Capture it throws an Exception:</p>

<pre><code>    The Type initializer for 'Emgu.CV.CvInvoke' threw an Exception
    Exception type: System.InitializationException from Emgu.CV.dll
</code></pre>

<p>here is the C# code I have:</p>

<pre><code>class Vision
{
    private Capture cap;
    private HaarCascade haar;
    private Form1 form;

    public Vision()
    {
            form = new Form1();
            cap = new Capture();
            haar = new HaarCascade(""C:\\haarcascade_frontalface_alt2.xml"");
    }
    public void faceDetect()
    {
        using(Image&lt;Bgr, Byte&gt; nextFrame = cap.QueryFrame())
        {
            if(nextFrame != null)
            {
                Image&lt;Gray, Byte&gt; grayframe = nextFrame.Convert&lt;Gray, Byte&gt;();
                var faces = grayframe.DetectHaarCascade(haar, 1.4, 4, HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(nextFrame.Width / 8, nextFrame.Height / 8))[0];
                foreach(var face in faces)
                {
                    nextFrame.Draw(face.rect, new Bgr(0, double.MaxValue, 0), 1);
                }
                form.setImage(nextFrame.ToBitmap());
            }
        }
    }
}
</code></pre>

<p>The references for the code are:</p>

<pre><code>    using System;
    using System.Collections.Generic;
    using System.Linq;
    using System.Text;
    using System.Threading.Tasks;
    using Emgu.CV;
    using Emgu.Util;
    using Emgu.CV.Structure;
    using Emgu.CV.CvEnum;
    using System.Drawing;
</code></pre>

<p>Everytime the Exception happens, it shows up at the
        cap = new Capture();</p>

<p>I have also tried to set the camera index for the Capture class as 0,1,2... and had no luck with that either. I also thought maybe that since I have windows running on a mac that it is not detecting the webcam, but then I did download the most up-to-date drivers for windows to access the camera. I thank everyone who helps in advance! :-)</p>
",,2017-01-28 16:28:09,emgu CV C# with Capture class,<c#><.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
19065,21539327,2014-02-03 22:39:56,,"<p>I am developing an eye tracker application in emgu CV, To track eyes i need to detect iris accurately ,So i used hough circles , but in some cases it fails because the shape of iris is not a perfect circle, So i decided to convert eye image in to binary and detect iris , </p>

<p>To convert it to binary i used </p>

<blockquote>
  <p>grayframeright_1 = grayframeright_1.ThresholdBinary(new
  Gray(threshold_value), new Gray(220));</p>
</blockquote>

<p>and the result is </p>

<p><img src=""https://i.stack.imgur.com/HXTvi.png"" alt=""enter image description here""></p>

<p>Now how can i detect iris in the above binary image ?Can i run blob detector to detect iris ?</p>

<p>Please help me to figure this out, your help will be highly appreciated , I am running out of time for my deadline.</p>

<p>Providing code sample would be useful</p>

<p>Thanks in advance</p>
",2014-02-03 22:46:43,2014-02-04 09:05:41,detect eye iris in a binary image,<c++><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
19089,18276509,2013-08-16 15:06:24,,"<p>I have a HD network camera that I am trying to grab frames over rtsp and using the following code:</p>

<pre><code>//in Form_Load
Application.Idle += getNextFrame;
</code></pre>

<p>And the Event Handler:</p>

<pre><code>private void getNextFrame(object sender, EventArgs ags)
{
        //where _imgCount is the total image Grabs
        lbl_Count.Text = _imgCount++.ToString(); 
        // and ibLive is a Emgu ImageBox
        ibLive.Image = capAxis.QueryFrame().Resize(640, 480, INTER.CV_INTER_AREA);
}
</code></pre>

<p>When I start the program, it'll grab 20-40 frames before the ""streakiness"" appears at the bottom of the screen. It's always on the bottom of the image, but some times it takes up half the screen.</p>

<p><img src=""https://i.stack.imgur.com/nYTrR.jpg"" alt=""enter image description here""></p>

<p>The stream resolution is 1920x1080 and it's using mjpeg. I tried switching to h.264 but had the same results. </p>

<p>I am using Emgu version x86-2.4.0.1717</p>

<p>Any Ideas?
Thanks.</p>
",2013-08-16 15:12:13,2017-07-04 23:06:09,"EMGU QueryFrame returns ""streaky"" Image over RTSP",<c#><opencv><rtsp><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
19106,22663303,2014-03-26 13:59:16,,"<p>I am looking to extract the feature points from the mouth I have detected. At the moment, I am using the DetectMultiScale() function from EmguCV to draw a rectangle around the mouth. It works fine but I need to get the positions of at least 4 points from the mouth : the left and the right extremity and the middle of the bottom and top lips. </p>

<p>Is there any function I can use directly with EmguCV or do I have to use another library to extract those points ? In the second case, which library would you recommend ? </p>
",,2014-03-26 13:59:16,Extract feature points from mouth with EmguCV,<c#><emgucv><feature-detection>,,,CC BY-SA 3.0,False,False,True,False,False
19112,20375327,2013-12-04 12:24:58,,"<p>I'm new to image processing, i have to process image file jpeg1 as following:</p>

<p>1.Detect the text as ""Text to detect!"" on jpeg1</p>

<p>2.Detect the rectangle region as ""Rectangle to be detected"" and merge another image seal.jpeg to the rectangle area.</p>

<p>I don't know how to achieve that with C#?</p>

<p>My image file jpeg1 as:
<img src=""https://i.stack.imgur.com/zPfdy.jpg"" alt=""jpeg1 to process""></p>

<p>The raw image jpeg1 as:
<img src=""https://i.stack.imgur.com/RoSt0.jpg"" alt=""jpeg1 to process"">
The seal image to be merged as:
<img src=""https://i.stack.imgur.com/PrcHw.jpg"" alt=""seal to merge""></p>
",2013-12-05 03:36:53,2013-12-05 03:36:53,How to detect rectangle region of one image and merge another image to that region,<c#><opencv><image-processing><emgucv><aforge>,2013-12-27 22:39:57,,CC BY-SA 3.0,True,False,True,False,False
19113,20377532,2013-12-04 14:07:53,,"<p>I'm currently using C# with Emgu CV to create a real-time face recognition programme in student registration system. 
Upon the process in developing it, I have several problems been spotted in accessing image data and assigning value on it. </p>

<p>My question is given as below: </p>

<p>May I know how to have a direct access to image data from the image i captured from web cam? Or perhaps how is the 'live image' from web cam can be connected to my image data to process the face image matching? </p>

<p>Any advice on getting this problem done are much welcome. </p>

<p>Thanks &amp; regards, </p>

<p>Caulson Chua </p>
",,2014-10-03 09:14:13,C# and EMgu CV in image data accessing & image matching‏,<c#><opencv><sqldatasource><emgucv><face-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
19149,22670253,2014-03-26 18:42:34,,"<p>Trying to upload an image into my image box and keep getting an exception, that breaks the code any ideas? (Type initialized Exception). This is the first time I have used the Emgu like this</p>

<pre><code>       private void btnload_Click(object sender, EventArgs e)
        {
        if (ofd.ShowDialog() == DialogResult.OK)
            {
                input = new Image&lt;Bgr, byte&gt;(ofd.FileName).Resize(500, 500,INTER.CV_INTER_CUBIC, false);
                imageBox1.Image = input;
                gray = input.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();
            }
            btnSet.Enabled = true;
        }
</code></pre>
",,2014-03-26 20:56:28,"Image Uploading in C# Emgu Open CV not working, giving an Exception every time I try and load",<c#><image><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
19155,24922752,2014-07-23 23:31:36,,"<p>I am using Emgu OpenCV wrapper and I need to support different types of images. However, I am trying to avoid declaring different image for each supported image type ( e.g. do the following)</p>

<pre><code>    private Image&lt;Gray, Byte&gt; m_GrayImage8;
    private Image&lt;Gray, UInt16&gt; m_GrayImage16;
    private Image&lt;Gray, UInt32&gt; m_GrayImage32;

    private Image&lt;Bgr, Byte&gt; m_BgrImage8;
    private Image&lt;Bgr, UInt16&gt; m_BgrImage16;

    private Image&lt;Bgra, Byte&gt; m_BgraImage8;
    private Image&lt;Bgra, UInt16&gt; m_BgraImage16;

    private Image&lt;Hsv, Byte&gt; m_HsvImage8;
    private Image&lt;Hsv, UInt16&gt; m_HsvImage16;

    private Image&lt;Hls, Byte&gt; m_HlsImage8;
    private Image&lt;Hls, UInt16&gt; m_HlsImage16;

    private Image&lt;Lab, Byte&gt; m_LabImage8;
    private Image&lt;Lab, UInt16&gt; m_LabImage16;

    private Image&lt;Luv, Byte&gt; m_LuvImage8;
    private Image&lt;Luv, UInt16&gt; m_LuvImage16;

    private Image&lt;Xyz, Byte&gt; m_XyzImage8;
    private Image&lt;Xyz, UInt16&gt; m_XyzImage16;

    private Image&lt;Ycc, Byte&gt; m_YccImage8;
    private Image&lt;Ycc, UInt16&gt; m_YccImage16;
</code></pre>

<p>Initially, doing the above was the easy way of implementing different types of images. However, I am looking for better approach. So, I tried doing the following </p>

<pre><code>Image&lt;IColor, Byte&gt; m_GrayImage8; 
</code></pre>

<p>However, I still need to do one for each pixel size.   Is there a way to get </p>

<pre><code>Image&lt;IColor, T&gt; m_GrayImage8; 
</code></pre>

<p>where T some interface that can be casted to different types.???  any help </p>
",,2014-07-23 23:52:16,Generic Image type emgu C#,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
19181,21550968,2014-02-04 11:17:19,,"<p>I'm developing a program which will capture images four times
and save it into a folder</p>

<p>what I did was to put my codes inside a for loop</p>

<p>but my problem is it only saves the first captured image four times instead of capturing four times</p>

<pre><code>private void Form1_Load(object sender, EventArgs e)
{
    string path = @""C:\Users\\Jake_PC\\Desktop\\fitting\\"";
    System.IO.Directory.CreateDirectory(path);
    bool useCam = true;

    if (!useCam)
        measureImage(null);
    else 
    {
        try
        {
            camera = new Capture();
        }
        catch (Exception exc)
        {
            MessageBox.Show(exc.Message);
            return;
        }

        Application.Idle += viewImage;
        captureProcess = true;
    }
}

private void btnCapture_Click(object sender, EventArgs e)
{
    if (btnCapture.Text == ""Back"")
    {
        Application.Restart();
    }
    else
    {
        if (captureProcess == true)
        {
            for (int cap = 0; cap &lt; 4; cap++)
            {
                string path = @""C:\\Users\\Jake_PC\\Desktop\\fitting\\"";
                System.IO.DirectoryInfo dir = new System.IO.DirectoryInfo(path);
                ctr = dir.GetFiles().Length;

                camera = new Capture();
                System.Threading.Thread.Sleep(500);
                Application.Idle -= viewImage;
                SaveFileDialog dlg = new SaveFileDialog();
                img.ToBitmap().Save(@""C:\\Users\\Jake_PC\\Desktop\\fitting\\"" + ctr + "".bmp"", System.Drawing.Imaging.ImageFormat.Bmp);
                camera.Dispose();

                Form1_Load(sender, e);
            }
        }
    }
}
</code></pre>
",2014-02-04 15:32:41,2014-02-05 08:32:21,image capturing using EmguCv,<c#><emgucv><image-capture>,,,CC BY-SA 3.0,False,False,True,False,False
19227,22675234,2014-03-26 23:28:12,,"<p>I am doing a project that consists in recognize a banana using haar features. I am using EMgucv and visual studio 2010 for that. I am using opencv_createsamples and opencv_traincascade.I have a question about parmeters. What happen if I increase those values?
I set:</p>

<p>-numPos 3800
-nunNeg 6000
-numStages 16
-minHitRate 0.999
-maxfalseAlarmRate 0.3
but I want to know What are maxWeakCount and maxdetph parameters? What means? I want and example to understand that</p>
",,2014-03-26 23:28:12,An advice about parameters in opencv_traincascade,<visual-studio-2010><emgucv><haar-classifier>,,,CC BY-SA 3.0,True,False,True,False,False
19298,23833586,2014-05-23 15:51:07,,"<p>I'm working on haar cascade for gesture recognition when i train xml for single gexture and use it in Emgucv C# it run fine no lag but when i trin 15 gexture and use xml it become lagging....
Here is the code:</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;
using System.Threading;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.Util;
using Emgu.CV.CvEnum;
namespace VideoCaptureDemo
{
    public partial class Form1 : Form
    {
        private Capture _capture = null;
        Image&lt;Bgr, Byte&gt; frame,roi_i;
        int threshold_value = 145; //0-255
        public HaarCascade haar=null;

        int cam = 0;

        public Form1()
        {
            InitializeComponent();
        }

        private void ReleaseData()
        {
            if (_capture != null)
                _capture.Dispose();
        }

        private void ProcessFrame(object sender, EventArgs arg)
        {
            try
            {

                frame = _capture.QueryFrame();

                if (frame != null)
                {
                         // var faces = frame.DetectHaarCascade(haar)[0];
                    Image&lt;Gray, byte&gt; grayframe = frame.Convert&lt;Gray, byte&gt;();
                    var faces = haar.Detect(grayframe, 1.4, 4, HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(frame.Width / 8, frame.Height / 8), new Size(frame.Width, frame.Height));
                    var pra = faces;
                    foreach (var face in faces)
                    {
                        frame.Draw(face.rect, new Bgr(255, double.MaxValue, 0), 2);
                        //roi_i.ROI = face.rect;
                    }
                    pictureBox1.Image = frame.ToBitmap();
                    roi_i = frame;
                    foreach (var face1 in pra)
                    {

                        frame.Draw(face1.rect, new Bgr(255, double.MaxValue, 0), 2);
                        frame.ROI = face1.rect;
                    }
                    /*Hsv lowerLimit = new Hsv(0, 50, 100);
                    Hsv upperLimit = new Hsv(250, 150, 100);

                    Image&lt;Hsv, Byte&gt; HsvFrame = frame.Convert&lt;Hsv, byte&gt;();
                    HsvFrame = HsvFrame.SmoothGaussian(5, 5, 0.1, 0.1);
                    Image&lt;Gray, byte&gt; InRageFrame = HsvFrame.InRange(lowerLimit, upperLimit);*/
               //     InRageFrame = InRageFrame.SmoothGaussian(3,3,1,1);
                    Image&lt;Gray,Byte&gt; img= frame.Convert&lt;Gray, Byte&gt;();
                    img = img.ThresholdBinary(new Gray(threshold_value), new Gray(255));
                    pictureBox2.Image = img.ToBitmap(); //display results in different picturebox
                   // pictureBox2.Image = InRageFrame.ToBitmap();
                }
            }
            catch (Exception ex)
            {
                MessageBox.Show(ex.Message.ToString());
            }
        }

        private void button1_Click(object sender, EventArgs e)
        {
            if (button1.Text == ""Play"")
                {
                    #region cameracapture
                      try
                        {

                            _capture = null;
                            _capture = new Capture(0);
                            haar = new HaarCascade(""C:\\Users\\Adeel\\Downloads\\hand.xml"");
                            if(haar==null)MessageBox.Show(""aasasas"");
                            _capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FPS, 30);
                            _capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, 240);
                            _capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, 320);
                            Application.Idle += ProcessFrame;
                            button1.Text = ""Stop"";

                        }
                        catch (NullReferenceException excpt)
                        {
                            MessageBox.Show(excpt.Message);
                        }
                    #endregion cameracapture
                }
                else
                    #region stopcapture
                    if (button1.Text == ""Stop"")
                    {
                        _capture.Stop();

                        Application.Idle -= ProcessFrame;
                        ReleaseData();
                        button1.Text = ""Play"";
                        pictureBox1.Image = Properties.Resources.blank;
                        pictureBox2.Image = Properties.Resources.blank;
                        if (cam == 1)
                        {
                            _capture.Dispose();
                            cam = 0;
                        }
                    }
                    #endregion stopcapture
        }
        private void close_Click(object sender, EventArgs e)
        {
            ReleaseData();
            this.Close();
        }

        private void label1_Click(object sender, EventArgs e)
        {

        }


    }
}
</code></pre>

<p>Any code better then it or link plz......</p>
",,2018-09-12 18:01:15,Haar Cascade for hand Detection Using Emgucv,<c#><image-processing><emgucv><haar-classifier>,,,CC BY-SA 3.0,False,False,True,False,False
19361,19237052,2013-10-08 00:19:47,,"<p>I'm new to <a href=""https://stackoverflow.com/tags/emgucv/info"">Emgu CV</a> and I have encountered an error (""access violation exception was unhandled"") trying to save an image. Here is the image path I have tried:</p>

<pre class=""lang-none prettyprint-override""><code>C:\\Users\crowds\Documents\Example\Sample.jpg
</code></pre>

<p>And here is my code. Can anyone help?</p>

<pre><code>//Form CameraCapture
private void button1_Click(object sender, EventArgs e)
{
    if (_capture != null)
    {
        captured FF = new captured();
        FF.Show();
        this.Hide();
    }
}

//Form captured
namespace CameraCapture
{
    public partial class captured : Form
    {
        public captured()
        {
            InitializeComponent();
        }

        private void captured_Load(object sender, EventArgs e)
        {
            var capture = new Emgu.CV.Capture();

            using (var ImageFrame = capture.QueryFrame())
            {
                if (ImageFrame != null)
                {
                    pictureBox1.Image = ImageFrame.ToBitmap();
                    ImageFrame.Save(
                    @""C:\\Users\crowds\Documents\Example\Sample.jpg"");
                }
            }            
        }

        private void button1_Click(object sender, EventArgs e)
        {
            CameraCapture CC = new CameraCapture();
            CC.Show();
            this.Close();
        }
    }
}
</code></pre>
",2017-05-23 11:52:13,2019-01-23 05:09:28,Access violation exception was unhandled trying to save an image,<c#><image><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
19392,20400120,2013-12-05 12:31:29,,"<p>I am trying to test face recognition program using EmguCV. I have my source code form this 
<a href=""http://www.codeproject.com/Articles/239849/Multiple-face-detection-and-recognition-in-real-ti"" rel=""nofollow"">http://www.codeproject.com/Articles/239849/Multiple-face-detection-and-recognition-in-real-ti</a>
I try to capture myself and it can recognize me. But when someone whose face isn't trained yet, it recognize as me. </p>

<p>can't anyone help me solve this issue?</p>
",,2020-07-31 17:05:55,How can I detect unknown face on face recognition Emgu CV,<c#><emgucv><face-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
19441,19241474,2013-10-08 07:18:18,,"<p>I an new in emgu cv c#. I want to create a camera only for simple photocapture from my laptop camera and other camera device connected to my laptop.I dont want video capture only simple photo capture.with one start and one capture button.and will save in particular location.helped would be appreciable.</p>

<pre><code>namespace camera
{
public partial class cameracaps : Form
{
    Capture capturecam=null;
    bool capturingprocess=false;
    Image&lt;Bgr,Byte&gt;imgOrg;
    Image&lt;Gray,Byte&gt;imgproc;



    public cameracaps()
    {
        InitializeComponent();
    }

    private void Form1_Load(object sender, EventArgs e)
    {
        try
        {

            Capture cam = new Capture();

        }
        catch (NullReferenceException exception)
        {
            MessageBox.Show(exception.Message);
            return;
        }
        Application.Idle += new EventHandler(processFunction);
        capturingprocess=true;

    }
    void processFunction(object sender,EventArgs e)
    {
       imgOrg=capturecam.QueryFrame();
        if(imgOrg ==null)return;
        imgproc=imgOrg.InRange(new Bgr(50,50,50),new Bgr(250,250,250));
        imgproc = imgproc.SmoothGaussian(9);
        original.Image=imgOrg;
        processed.Image=imgproc;
    }


    private void Button1_Click(object sender, EventArgs e)
    {
        if(capturingprocess==true)
        {
            Application.Idle-=processFunction;
            capturingprocess = false;
            Button1.Text=""play"";
        }
        else
        {
            Application.Idle+= processFunction;
            capturingprocess= true;
            Button1.Text=""pause"";


    }


}

}
}
</code></pre>

<p>showing..The type initializer for 'Emgu.CV.CvInvoke' threw an exception. error..indicating error in<code>
                Capture cam = new Capture();</code>
help me.</p>
",2013-10-11 07:16:13,2013-10-12 03:55:18,I write code for simple camera capture image.but application and camera not getting connected and one unhandle error is showing,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
19490,23850105,2014-05-24 22:06:47,,"<p>I have been using Emgu CV for 2 years to provide Facial Recognition to an open source project already using Kinect API. All the <strong>code is in C#</strong>.</p>

<p>Now I'd like to also provide Blob Tracking Learning Detection like <a href=""http://personal.ee.surrey.ac.uk/Personal/Z.Kalal/tld.html"" rel=""nofollow noreferrer"">Predator</a> or <a href=""http://www.gnebehay.com/cmt/"" rel=""nofollow noreferrer"">CMT</a> and don't know what library to use. I didn't find a Predator implementation in C#. I also didn't find a Blob library build on top of the Kinect SDK.</p>

<p>So should I keep <a href=""https://stackoverflow.com/questions/6174527/emgu-cv-blob-detection"">digging into Emgu CV</a>? Or looking for something new? Maybe using Kinect leverage?</p>
",2017-05-23 12:11:03,2014-05-26 17:58:57,Are there libraries like Predator or CMT for C#?,<c#><computer-vision><kinect><emgucv>,2014-05-28 06:18:03,,CC BY-SA 3.0,False,False,True,False,False
19494,17360647,2013-06-28 08:42:20,,"<p>I have two images, one normal image and another its denoised version. I want to extract noise from an image ,thus need to subtract the two images according to</p>

<p>NOISE = IMAGE - IMAGE(DENOISED)</p>

<p>I am not getting how to subtract two images such that no data will be lost.
Thanks in advance.</p>
",,2013-06-30 10:42:44,How to subtract two images in emgu cv,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
19511,20405186,2013-12-05 16:20:24,,"<p>I'm tying to change the ColorPalette of an EmguCV image, but the Palette does not change!</p>

<p>Sample code:</p>

<pre><code>var img = new Image&lt;Gray, byte&gt;(10, 10);
ColorPalette pal = img.Bitmap.Palette;
pal.Entries[0] = Color.FromArgb(255, 0, 0, 255);
img.Bitmap.Palette = pal;
//img.Bitmap.Palette.Entries[0] != pal.Entries[0];
</code></pre>
",,2013-12-13 07:12:06,How to change the ColorPalette of an EmguCV image,<c#><bitmap><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
19521,18310937,2013-08-19 09:53:49,,"<p>Here's the code when go into examination pages. I straight load the face from my folder to get to recognize who's the candidate and there's no problem to recognize each of the person who been enroll into the system but i have no idea to detect if the person is not the candidate. </p>

<p>My program is goes like : Login Form,Enroll Form and Exam Form (using emgucv in C#) I login with Kelvin's username and password (which already enroll into the system) and then goes to Exam Form, once exam start camera is on and face detected the person is Kelvin but even a third party who has been enroll oso or not, the face detect is still detect the person other then Kelvin or stranger. I hope to make it like if the person is not Kelvin and so system will pause or prompt message tell that ""wrong candidate detection,click ok to detect again"". Sorry if there's alot broken english or hard to understand my situation but appreciate with ur help.</p>

<pre><code>void FrameGrabber(object sender, EventArgs e)
    {
        label3.Text = ""0"";
        //label4.Text = """";
        NamePersons.Add("""");


        //Get the current frame form capture device
        currentFrame = grabber.QueryFrame().Resize(240, 240, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

        //Convert it to Grayscale
        gray = currentFrame.Convert&lt;Gray, Byte&gt;();

        //Face Detector
        MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
      face,
      1.2,
      10,
      Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
      new Size(20, 20));

        //Action for each element detected
        foreach (MCvAvgComp f in facesDetected[0])
        {
            t = t + 1;
            result = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
            //draw the face detected in the 0th (gray) channel with blue color
            currentFrame.Draw(f.rect, new Bgr(Color.LightGreen), 2);


            if (trainingImages.ToArray().Length != 0)
            {
                //TermCriteria for face recognition with numbers of trained images like maxIteration
                MCvTermCriteria termCrit = new MCvTermCriteria(ContTrain, 0.001);

                //Eigen face recognizer
                EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
                   trainingImages.ToArray(),
                   labels.ToArray(),
                   3000,
                   ref termCrit);

                name = recognizer.Recognize(result);

                //Draw the label for each face detected and recognized
                currentFrame.Draw(name, ref font, new Point(f.rect.X - 2, f.rect.Y - 2), new Bgr(Color.LightGreen));

            }

            NamePersons[t - 1] = name;
            NamePersons.Add("""");


            //Set the number of faces detected on the scene
            label3.Text = facesDetected[0].Length.ToString();



        }

        t = 0;
</code></pre>

<p>This is enrollment form</p>

<pre><code>    private void button2_Click(object sender, System.EventArgs e)
    {
        try
        {
            //Trained face counter
            ContTrain = ContTrain + 1;

            //Get a gray frame from capture device
            gray = grabber.QueryGrayFrame().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

            //Face Detector
            MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
            face,
            1.2,
            10,
            Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
            new Size(20, 20));

            //Action for each element detected
            foreach (MCvAvgComp f in facesDetected[0])
            {
                TrainedFace = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;();
                break;
            }

            //resize face detected image for force to compare the same size with the 
            //test image with cubic interpolation type method
            TrainedFace = result.Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
            trainingImages.Add(TrainedFace);
            labels.Add(textBox1.Text);

            //Show face added in gray scale
            imageBox1.Image = TrainedFace;

            //Write the number of triained faces in a file text for further load
            File.WriteAllText(Application.StartupPath + ""/TrainedFaces/TrainedLabels.txt"", trainingImages.ToArray().Length.ToString() + ""%"");

            //Write the labels of triained faces in a file text for further load
            for (int i = 1; i &lt; trainingImages.ToArray().Length + 1; i++)
            {
                trainingImages.ToArray()[i - 1].Save(Application.StartupPath + ""/TrainedFaces/face"" + i + "".bmp"");
                File.AppendAllText(Application.StartupPath + ""/TrainedFaces/TrainedLabels.txt"", labels.ToArray()[i - 1] + ""%"");
            }

            MessageBox.Show(textBox1.Text + ""Face detected and Added"", ""Training OK"", MessageBoxButtons.OK, MessageBoxIcon.Information);



            OleDbCommand cmd = new OleDbCommand();
            cmd.CommandType = CommandType.Text;
            cmd.CommandText = ""insert into Login (username,[password]) values ('"" + textBox1.Text + ""','"" + textBox4.Text + ""')"";
            cmd.Connection = conn;
            conn.Open();
            cmd.ExecuteNonQuery();
            MessageBox.Show(""User Account Succefully Created"", ""Caption"", MessageBoxButtons.OKCancel, MessageBoxIcon.Information);
            conn.Close();
            textBox1.Clear();
            textBox4.Clear();

            button2.Enabled = false;
            button3.Enabled = true;


        }
        catch
        {
            MessageBox.Show(""Enable the face detection first"", ""Training Fail"", MessageBoxButtons.OK, MessageBoxIcon.Exclamation);
        }
    }


    void FrameGrabber(object sender, EventArgs e)
    {
        label3.Text = ""0"";
        //label4.Text = """";
        NamePersons.Add("""");


        //Get the current frame form capture device
        currentFrame = grabber.QueryFrame().Resize(320, 240, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

                //Convert it to Grayscale
                gray = currentFrame.Convert&lt;Gray, Byte&gt;();

                //Face Detector
                MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
              face,
              1.2,
              10,
              Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
              new Size(20, 20));

                //Action for each element detected
                foreach (MCvAvgComp f in facesDetected[0])
                {
                    t = 1;
                    result = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
                    //draw the face detected in the 0th (gray) channel with blue color
                    currentFrame.Draw(f.rect, new Bgr(Color.LightGreen), 2);


                    if (trainingImages.ToArray().Length != 0)
                    {
                        //TermCriteria for face recognition with numbers of trained images like maxIteration
                    MCvTermCriteria termCrit = new MCvTermCriteria(ContTrain, 0.001);

                    //Eigen face recognizer
                    EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
                       trainingImages.ToArray(),
                       labels.ToArray(),
                       3000,
                       ref termCrit);

                    name = recognizer.Recognize(result);

                        //Draw the label for each face detected and recognized
                    currentFrame.Draw(name, ref font, new Point(f.rect.X - 2, f.rect.Y - 2), new Bgr(Color.LightGreen));

                    }

                        NamePersons[t-1] = name;
                        NamePersons.Add("""");


                    //Set the number of faces detected on the scene
                    label3.Text = facesDetected[0].Length.ToString();



                }

                    t = 0;

                    //Names concatenation of persons recognized
                for (int nnn = 0; nnn &lt; facesDetected[0].Length; nnn++)
                {
                    names = names + NamePersons[nnn] + "", "";
                }
                //Show the faces procesed and recognized
                imageBoxFrameGrabber.Image = currentFrame;
                label4.Text = names;
                names = """";
                //Clear the list(vector) of names
                NamePersons.Clear();

            }
</code></pre>
",2013-08-19 10:06:58,2016-09-07 12:03:21,how to detect the wrong person who are not in database and prompt error if no face are detected inside the image box?,<c#><computer-vision><face-detection><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
19529,22699901,2014-03-27 21:48:17,,"<p>I am trying to use snake active contour from EmguCV ,but i don't take anything.Here is my code:</p>

<pre><code>     Image&lt;Gray, Byte&gt; img = new Image&lt;Gray, Byte&gt;(300, 300, new Gray());

     Point center = new Point(100, 100);
     double width = 20;
     double height = 40;
     Rectangle rect = new Rectangle(center, new Size(20, 20));
     img.Draw(rect, new Gray(255.0), -1);

     using (MemStorage stor = new MemStorage())
     {
        Seq&lt;Point&gt; pts = new Seq&lt;Point&gt;((int)SEQ_TYPE.CV_SEQ_POLYGON, stor);
        pts.Push(new Point(20, 20));
        pts.Push(new Point(20, 280));
        pts.Push(new Point(280, 280));
        pts.Push(new Point(280, 20));

        //Image&lt;Gray, Byte&gt; canny = img.Canny(100.0, 40.0);
        Seq&lt;Point&gt; snake = img.Snake(pts, 0.1f, 0.5f, 0.4f, new Size(21, 21), new MCvTermCriteria(500, 0.1), stor);

        img.Draw(pts, new Gray(120), 1);
        img.Draw(snake, new Gray(80), 2);
</code></pre>

<p>What i am doing wrong?Any idea?</p>
",,2019-11-13 10:52:05,EmguCV snake function,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
19572,23855746,2014-05-25 13:24:01,,"<p>I have an disparity map then I want to measure the depth from the disparity map.</p>

<p>I use this code </p>

<pre><code> pointsd = PointCollection.ReprojectImageTo3D(disparity, Q);
</code></pre>

<p>The output is x:-42.92741  y:-24.21322  z:10000 ,but I want to get the output in cm.</p>

<p>What should I do?</p>
",,2014-10-22 22:40:14,How to measure the depth from disparity map?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
19655,17377501,2013-06-29 06:42:18,,"<p>I got this error when i try next:</p>

<pre><code>var openCVImg = new Image&lt;Bgr, byte&gt;(colorBitmap.ToBitmap());
</code></pre>

<p>Error details:</p>

<pre><code>{""Unable to load DLL 'opencv_core249': The specified module could not be found. (Exception from HRESULT: 0x8007007E)""}
</code></pre>

<p>I add to my Path directory in system to check form dlls on ~\Emgu\emgucv-windows-universal-gpu 2.4.9.1847\lib</p>

<p>Any idea?</p>
",,2013-06-29 07:16:38,Visual studio 2012 and EmguCV Issue,<c#><opencv><visual-studio-2012><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
19703,24970577,2014-07-26 11:32:45,,"<p>I am working with emguCV for finding contours essential points then saving this point in a file and user redraw this shape in future. so, my goal is this image:</p>

<p><a href=""http://www.csharp.somee.com/b11.jpg"" rel=""nofollow noreferrer"">example</a><br>
<img src=""https://i.stack.imgur.com/5fmjg.jpg"" alt=""example""></p>

<p>my solution is this:
1. import image to picturebox
2. edge detection with canny algorithm
3. finding contours and save points</p>

<p>I found a lot of points with below codes but i can't drawing first shape with this point!</p>

<pre><code>using Emgu.CV;
using Emgu.Util;

private void button1_Click(object sender, EventArgs e)          
{
    Bitmap bmp = new Bitmap(pictureBox1.Image);
    Image&lt;Bgr, Byte&gt; img = new Image&lt;Bgr, byte&gt;(bmp);

    Image&lt;Gray, Byte&gt; gray = img.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();

    Gray cannyThreshold = new Gray(80);
    Gray cannyThresholdLinking = new Gray(120);
    Gray circleAccumulatorThreshold = new Gray(120);

    Image&lt;Gray, Byte&gt; cannyEdges = gray.Canny(cannyThreshold, cannyThresholdLinking).Not();

    Bitmap color;
    Bitmap bgray;
    IdentifyContours(cannyEdges.Bitmap, 50, true, out bgray, out color);

    pictureBox1.Image = color;
}

public void IdentifyContours(Bitmap colorImage, int thresholdValue, bool invert, out Bitmap processedGray, out Bitmap processedColor)
{
    Image&lt;Gray, byte&gt; grayImage = new Image&lt;Gray, byte&gt;(colorImage);
    Image&lt;Bgr, byte&gt; color = new Image&lt;Bgr, byte&gt;(colorImage);

    grayImage = grayImage.ThresholdBinary(new Gray(thresholdValue), new Gray(255));

    if (invert)
    {
        grayImage._Not();
    }

    using (MemStorage storage = new MemStorage())
    {
        for (Contour&lt;Point&gt; contours = grayImage.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST, storage); contours != null; contours = contours.HNext)
        {
            Contour&lt;Point&gt; currentContour = contours.ApproxPoly(contours.Perimeter * 0.015, storage);
            if (currentContour.BoundingRectangle.Width &gt; 20)
            {
                CvInvoke.cvDrawContours(color, contours, new MCvScalar(255), new MCvScalar(255), -1, 1, Emgu.CV.CvEnum.LINE_TYPE.EIGHT_CONNECTED, new Point(0, 0));
                color.Draw(currentContour.BoundingRectangle, new Bgr(0, 255, 0), 1);
            }

            Point[] pts = currentContour.ToArray();
            foreach (Point p in pts)
            {
                //add points to listbox
                listBox1.Items.Add(p);
            }
       }
  }

   processedColor = color.ToBitmap();
   processedGray = grayImage.ToBitmap();
}
</code></pre>
",2019-12-15 15:54:25,2019-12-15 15:54:25,Finding contour points in emgucv,<c#><emgucv>,,,CC BY-SA 4.0,False,False,True,False,False
19709,20429116,2013-12-06 16:42:06,,"<p>I'm trying to implement DoG filter in emgu like this:</p>

<pre><code>Image &lt;Gray, byte&gt; temp  = inImage;
Image &lt;Gray, byte&gt; temp2 = inImage;
temp1._SmoothGaussian(1);
temp2._SmoothGaussian(3) 
result= temp2.Sub(temp);
result.ToBitmap().Save(""DoG.bmp"");
</code></pre>

<p>Problem is that result image is all black (I checked temp1 and temp2, they are different and both have gaussian filter correctly applied)</p>

<p>Do you have any hint, where could be problem?</p>
",,2014-02-26 08:36:03,emgu diffence of gaussian filter returns black image,<c#><filter><gaussian><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
19716,17382151,2013-06-29 16:11:31,,"<p>I have a little problem. I want to implement the Gaussian convolution in C#, but it has (for some purposes) to have the same result as the Gaussian blur of EmguCV (which also means the same as OpenCV). The computation of the kernel value should always be the same at a Gaussian convolution, the only thing I need to know is, how the OpenCV implementation computes the kernel size. I have had a closer look to the OpenCV source code, but I have only little experience in C++, which is why I haven't found this.
Perhaps anyone else can help me with this.
And are there any other changes of the OpenCV implementation to the ""original""?</p>
",2013-06-29 16:42:20,2013-06-30 10:55:25,Gaussian blur C# implementation (similar to OpenCV),<c#><c++><opencv><emgucv><gaussian>,,,CC BY-SA 3.0,True,False,True,False,False
19810,17392395,2013-06-30 16:20:54,,"<p>I need to know that is there <strong>a method to remove the background of a live streaming web cam.</strong>  There is a method called <strong>background Subtractor</strong>. If anyone knows to use that please help me out with the issue.. </p>
",,2013-07-27 16:29:59,Background Subtaction using Emgu cv,<c#><background><emgucv><background-subtraction>,,,CC BY-SA 3.0,False,False,True,False,False
19836,18340991,2013-08-20 17:06:13,,"<p>So i'm using emguCV to use the machine learning algorithms from OpenCV. My code is as follows, and when it enters the dtree.Train method it gives me exception (exc1) and if i wait ir gives me and error message (err1).If i try to debug and step into this method if gives me another exception (exc2) and the debugger doesn't advance.
exc1:
A first chance exception of type 'Emgu.CV.Util.CvException' occurred in Emgu.CV.dll</p>

<p>exc2:
Step into: Stepping over non-user code 'Emgu.CV.ML.RTrees.Train'
A first chance exception of type 'Emgu.CV.Util.CvException' occurred in Emgu.CV.dll
Step into: Stepping over non-user code 'MS.Internal.Threading.ExceptionFilterHelper.TryCatchWhen'</p>

<p>err1:
The CLR has been unable to transition from COM context 0x795fa8 to COM context 0x796118 . The thread that owns the destination context/apartment is most likely either doing a non pumping wait or processing a very long running operation without pumping Windows messages. This situation generally has a negative performance impact and may even lead to the application becoming non responsive or memory usage accumulating continually over time. To avoid this problem, all single threaded apartment (STA) threads should use pumping wait primitives (such as CoWaitForMultipleHandles) and routinely pump messages during long running operations.</p>

<p>My Code, using this example - <a href=""http://www.emgu.com/wiki/index.php/Mushroom_Poisonous_Prediction_(Decision_Tree)_in_CSharp"" rel=""nofollow"">http://www.emgu.com/wiki/index.php/Mushroom_Poisonous_Prediction_(Decision_Tree)_in_CSharp</a></p>

<pre><code>   public void train()
    {

        Matrix&lt;float&gt; data, response;
       // data = new Matrix&lt;float&gt;(15, 200);
       // response = new Matrix&lt;float&gt;(15, 200);
        Console.WriteLine(""reading shroom data"");
        ReadMushroomData(out data, out response);

        ///data = new Matrix&lt;float&gt;(1, 5);

        //Use the first 80% of data as training sample
        int trainingSampleCount = (int)(data.Rows * 0.8);

        Matrix&lt;Byte&gt; varType = new Matrix&lt;byte&gt;(data.Cols + 1, 1);
        varType.SetValue((byte)Emgu.CV.ML.MlEnum.VAR_TYPE.CATEGORICAL); //the data is categorical

        Matrix&lt;byte&gt; sampleIdx = new Matrix&lt;byte&gt;(data.Rows, 1);
        using (Matrix&lt;byte&gt; sampleRows = sampleIdx.GetRows(0, trainingSampleCount, 1))
            sampleRows.SetValue(255);

        float[] priors = new float[] { 1, 0.5f };
        GCHandle priorsHandle = GCHandle.Alloc(priors, GCHandleType.Pinned);

        MCvRTParams param = new MCvRTParams();
        param.maxDepth = 8;// max depth
        param.minSampleCount = 10;// min sample count
        param.regressionAccuracy = 0;// regression accuracy: N/A here
        param.useSurrogates = true; //compute surrogate split, no missing data
        param.maxCategories = 15;// max number of categories (use sub-optimal algorithm for larger numbers)
        param.cvFolds = 10;
        //param.use1seRule = true;
        param.truncatePrunedTree = true;
        param.priors = priorsHandle.AddrOfPinnedObject(); // the array of priors


        Console.WriteLine(""starting train"");
        using (RTrees dtree = new RTrees())
        {

            bool success = dtree.Train(data, 
                Emgu.CV.ML.MlEnum.DATA_LAYOUT_TYPE.ROW_SAMPLE, 
                response, 
                null, 
                sampleIdx, 
                varType, 
                null, 
                param);


            Console.WriteLine(""starting tests"");

            if (!success) return;
            double trainDataCorrectRatio = 0;
            double testDataCorrectRatio = 0;
            for (int i = 0; i &lt; data.Rows; i++)
            {
                using (Matrix&lt;float&gt; sample = data.GetRow(i))
                {
                    double r = dtree.Predict(sample, null);
                    r = Math.Abs(r - response[i, 0]);
                    if (r &lt; 1.0e-5)
                    {
                        if (i &lt; trainingSampleCount)
                            trainDataCorrectRatio++;
                        else
                            testDataCorrectRatio++;
                    }
                }
            }

            trainDataCorrectRatio /= trainingSampleCount;
            testDataCorrectRatio /= (data.Rows - trainingSampleCount);

            Console.WriteLine(String.Format(""Prediction accuracy for training data :{0}%"", trainDataCorrectRatio * 100));
            Console.WriteLine(String.Format(""Prediction accuracy for test data :{0}%"", testDataCorrectRatio * 100));
        }
    }
</code></pre>
",2013-08-23 15:35:14,2017-03-07 14:58:26,Example code from emgucv throwing exceptions??,<c#><opencv><machine-learning><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
19862,22731534,2014-03-29 13:12:14,,"<p>I want to preprocess a scanned image to do some OCR on it. My problem is that when I apply a given value of Threshold to  remove noise, the bold text become sharp,but the rest of the text disappears. </p>

<pre><code>CvInvoke.cvThreshold(img, img, 80, 255, THRESH.CV_THRESH_BINARY);
</code></pre>

<p><img src=""https://i.stack.imgur.com/0tRaQ.jpg"" alt=""enter image description here""></p>

<pre><code>CvInvoke.cvThreshold(img, img, 120, 255, THRESH.CV_THRESH_BINARY);
</code></pre>

<p><img src=""https://i.stack.imgur.com/dMvIU.jpg"" alt=""enter image description here""></p>

<p>I'm asking if there is a way to apply different values of Threshold depending on text form ?</p>
",2014-03-29 13:12:44,2014-04-10 09:58:06,Emgu OpenCV: Apply different Threshold values depending on text form[sharp/bold],<c#><c++><opencv><ocr><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
19871,21608319,2014-02-06 16:20:40,,"<p>I am new to image processing, In my application , i want to save the detected circles as a new image , The following code has been used to store the detected circle.</p>

<blockquote>
  <p>new CircleF(new PointF(circles[0].Center.X +
  grayframeright_1.ROI.Left, circles[0].Center.Y +
  grayframeright_1.ROI.Top), circles[0].Radius);</p>
</blockquote>

<p>Are there any methods available in emgu cv / open cv to save the circle as a new Image?</p>

<p>Please help me to figure this out, Code samples would be useful.</p>

<p>Thanks in advance</p>
",,2014-03-22 07:16:38,Emgu cv save CircleF as a image,<c#><opencv><image-processing><geometry><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
19907,20445695,2013-12-07 19:38:42,,"<p>I am new to Image processing , I am trying to implement a IRIS detection application fro my academics.</p>

<p>In the application i have successfully detected right eye from input stream .
After that i have to perform the iris detection operation so i was following the below link
<a href=""http://www.emgu.com/forum/viewtopic.php?f=7&amp;t=3356"" rel=""nofollow noreferrer"">http://www.emgu.com/forum/viewtopic.php?f=7&amp;t=3356</a></p>

<p>The application returns about 17 circles have been detected when giving an input image but when i give the web camera as input it returns 0.(I don't know the reason).
I want the to detect the iris perfectly and accurately. Please help me to solve this issue.</p>

<p>1.What should i do to detect the iris accurately? (Code samples would be useful)</p>

<p>2.Why application is not any circles form web camera input stream ?</p>

<p>Thanks in advance</p>

<p>This is the code i used to detect circles in the right eye picture<img src=""https://i.stack.imgur.com/0f8l9.png"" alt=""enter image description here""></p>

<pre><code>double cannyThreshold = 180.0;
            double circleAccumulatorThreshold = 20;
            int irisy = 0;

        //Taken from - http://www.emgu.com/forum/viewtopic.php?f=7&amp;t=3356
        CircleF[] circles = grayframeright.HoughCircles(
            new Gray(cannyThreshold),
            new Gray(circleAccumulatorThreshold),
            2.0, //Resolution of the accumulator used to detect centers of the circles
            20.0, //min distance
            5, //min radius
            0 //max radius
            )[0]; //Get the circles from the first channel


        MessageBox.Show(circles.Length + "" circle length"");

        CircleF Iris = new CircleF();

        foreach (CircleF circle in circles)
        {
                ImageFrame.Draw(circle, new Bgr(Color.Red), 2);
                grayframeright.ROI = new Rectangle();
                grayframeright.ROI = Rectangle.Empty;

                grayframeright.ROI = new Rectangle(10, 30, grayframeright.Width - 10, 55);
                Iris = circle;


         }
</code></pre>
",,2013-12-08 02:28:42,Iris detection is not working EMGUCV,<c#><image-processing><emgucv><hough-transform><iris-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
19921,22735017,2014-03-29 18:23:53,,"<p>How can I use Bitwise_and function in Emgu? I found it in Emgu wiki <a href=""http://www.emgu.com/wiki/files/1.5.0.0/Help/html/f5ad1313-323f-4ec1-cb9e-97f699ff2908.htm"" rel=""nofollow"">Bitwise_and</a> but I don't know how to call it !</p>

<p>I'm trying to convert that code from c++ to c# <a href=""http://felix.abecassis.me/2011/09/opencv-morphological-skeleton/"" rel=""nofollow"">Tuto</a></p>
",2014-03-29 18:38:19,2018-05-17 06:32:56,OpenCV Bitwise_and function in Emgu,<c#><.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
20036,19294171,2013-10-10 11:10:07,,"<p>I have huge collection of <strong>Emgu mcvpoint3d32f points.</strong> 
I am confused to write those point into a <strong>.ply file format</strong> .
Through those point i want to create a <strong>mesh</strong> using meshlab.
How do i write those points into an <strong>.ply file format</strong> .
How do i get <strong>vertex points</strong> and the <strong>faces</strong> from the Emgu mcvpoint3d32f points.</p>

<p>Any help ...</p>
",,2013-12-13 07:07:31,How do i write Emgu Mcvpoint3d32f points to .ply file format 3D recontruction and Mesh,<emgucv><mesh><3d-reconstruction><meshlab>,,,CC BY-SA 3.0,False,False,True,False,False
20055,18357255,2013-08-21 12:20:05,,"<p>I am trying to create small app in C# that will load a video file, that for example has 600 frames. I want to display frames and to set start frame (for example frame number 100) and end frame (for example frame number 500) and the output of the application should be new video from start point to end point. I am a newbie to EMGU so anyone help me achieve this.</p>

<p>I am planning to create simple UI that will enable user to move start marker (regarding start frame position) as well as end marker (regarding end frame position).</p>
",,2013-08-22 06:26:50,How extract part of the video with EMGU,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
20123,23903803,2014-05-28 05:57:43,,"<p>using C# and emgu.</p>

<p>I am working with jpegs which will ultimately end up in a browser.</p>

<p>I am already lowering the quality of the image (to 60%) to reduce the byte array size.</p>

<p>Whenever I get the chance I spend sometime looking around to find ideas to reduce the size of this byte array even more.  </p>

<p>I do know the brighter the image the more bytes it seems to hold and the more contrast the image has the more bytes it seems to hold.</p>

<p>Upon googling I came across this:</p>

<p><a href=""http://en.kioskea.net/download/download-666-greycstoration"" rel=""nofollow"">http://en.kioskea.net/download/download-666-greycstoration</a></p>

<p>It seemed to imply that by reducing minor pixel variations in an image that I can reduce the byte array defining these jpeg images.</p>

<p>So, to my approach (and understanding)...</p>

<p>Do I iterate through all the pixels and 'average' a group of pixels say on a 4x4 area? Or am I missing the meaning entirely here. I ask because I have already done this but it makes no difference to the image size (in bytes).</p>

<p>I could post my code (and will) but it was just a mock up and not fit for production code.</p>

<p>I am more interested in understanding the meaning/implementation of all this.  I can code it this myself as soon as this is clarified (and will post back with the code here)...</p>
",,2014-05-28 18:52:38,removing the minor variations in pixel intensities in an image,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
20130,18366853,2013-08-21 20:17:05,,"<p>I'm having problems with my person detection code. I'm using the Emgucv library, and it ends up picking up objects that have nothing to do with people ... Is something missing? How can I make it better?</p>

<pre><code>                Rectangle[] regions;
                int indexx = 0;
                using (HOGDescriptor des = new HOGDescriptor())
                {
                    des.SetSVMDetector(HOGDescriptor.GetDefaultPeopleDetector());
                    regions = des.DetectMultiScale(currentFrame.Copy());
                }

                foreach (Rectangle rect in regions)
                {
                    indexx++;
                    currentFrame.Draw(rect, new Bgr(Color.Red), 2);
                }

                if (regions.Count() &gt; 0)
                    currentFrame.Save(""pedestre\\pedestre0"" + indexx + "".jpg"");
</code></pre>
",2013-08-23 12:45:29,2013-12-13 08:18:21,Emgucv People Detection,<c#><image-processing><detection><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
20198,21636695,2014-02-07 19:59:18,,"<p>I am creating a camera based winforms application in which I used EmguCV.</p>

<p>I want to capture the image in portrait mode when i click the button.</p>

<p>I tried:</p>

<pre><code>cap.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, 190);
cap.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, 250);
</code></pre>

<p>but image is still remain in landscape mode only the dimension reduces from <code>640 x  480</code> to some <code>176 x 130</code> but i want portrait image.</p>

<p>So can anyone tell me how to cope up with this problem?</p>
",2014-02-08 20:03:29,2014-02-10 10:42:47,Portrait mode in Emgu CV,<c#><winforms><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
20223,23911279,2014-05-28 12:12:14,,"<pre><code> Image&lt;Gray, Byte&gt;[] trainingImages = new Image&lt;Gray,Byte&gt;[5];  

 trainingImages[0] = new Image&lt;Gray, byte&gt;(""MyPic.jpg"");

 String[] labels = new String[] { ""mine""}

  MCvTermCriteria termCrit = new MCvTermCriteria(1, 0.001);

 EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
       trainingImages,
       labels,
       1000,
       ref termCrit);

        Image&lt;Gray,Byte&gt; testImage = new Image&lt;Gray,Byte&gt;(""sample_photo.jpg"");

     var result= recognizer.Recognize(testImage);
</code></pre>

<p>result.label always returns string ""mine""(label of the training image) for every face it detects.
result.label must be the returned when the detected faces are same in the two images, instead it returns same label for every face.</p>

<p>What is the problem with my code.</p>
",2014-05-29 11:20:51,2014-05-29 11:20:51,Face Recognizer using EigenObjectRecognizer,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
20263,18377167,2013-08-22 09:55:07,,"<p>I am working On Emgu cv on windows 7 32 bit os and, System.TypeInitializationException Error occurs, i tried every solution;
When i run the Examples coming with Emgu it's Ok but when i create my own project the error occurs.</p>

<p>here is my code;</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.Util;

namespace WindowsFormsApplication1
{
    public partial class Form1 : Form
        {
        private Capture cap;
        private bool capinpro;

        public Form1()
        {
            InitializeComponent();
        }


    private void processframe(object o, EventArgs e)
    {

        Image&lt;Bgr, byte&gt; img = cap.QueryFrame();
        imageBox1.Image = img;
    }



    private void button1_Click(object sender, EventArgs e)
    {
        if(cap!=null)
        {

            try
            {
        if (capinpro)
        {   
            Application.Idle += processframe;       
            //i have also tried cap.start();
        }
        else
        {
             Application.Idle -= processframe;
        }


            }
            catch (Exception ex)
            {
                MessageBox.Show(ex.Message);
            }




        }
        else
        {
         cap= new Capure();   
        }
    }


}
</code></pre>

<p>}</p>
",2013-08-22 11:15:24,2014-12-04 17:12:48,Emgu System.TypeInitializationException on 32 bit windows 7 OS,<c#><windows-7><32-bit><emgucv><typeinitializeexception>,,,CC BY-SA 3.0,False,False,True,False,False
20320,19316851,2013-10-11 11:19:03,,"<p>I am using <em>EmguCV</em> version <em>2.4.9.1847</em> with <em>VS2012</em> and I have problems with <code>Emgu.CV.Capture</code> class. Its' throwing <code>""The type initializer for 'Emgu.CV.CvInvoke' threw an exception.""</code> </p>

<p>When I start the Capture sample I works fine , but when I try this <code>Capture camera = new Capture();</code> it's throwing the above exception. <em>CLR</em> and <em>OpenCV</em> are 64 bit.</p>

<p>Thanks in advance.</p>
",2013-10-11 11:30:09,2013-12-06 21:02:05,The type initializer for 'Emgu.CV.CvInvoke' threw an exception with VS 2012,<c#><visual-studio-2012><emgucv>,2014-10-07 12:32:37,,CC BY-SA 3.0,True,False,True,False,False
20328,22767902,2014-03-31 17:11:47,,"<p>I am attempting to create a classifier/predictor using SURF and a Naive Bayesian.  I am pretty much following the technique from ""Visual Categorization with Bags of Keypoints"" by Dance, Csurka... I am using SURF instead of SIFT.  </p>

<p>My results are pretty horrendous and I am not sure where my error lies.  I am using 20 car samples (ham) and 20 motorcycle samples(spam) from the CalTec set.  I suspect it is in the way I am creating my vocabulary.  What I can see is that the EMGU/OpenCV kmeans2 classifier is returning different results given the same SURF descriptor input.  That makes me suspicious.  Here is my code so far.</p>

<pre><code>public Matrix&lt;float&gt; Extract&lt;TColor, TDepth&gt;(Image&lt;TColor, TDepth&gt; image)
        where TColor : struct, Emgu.CV.IColor
        where TDepth : new()
    {            
        ImageFeature[] modelDescriptors;

        using (var imgGray = image.Convert&lt;Gray, byte&gt;())
        {
            var modelKeyPoints = surfCPU.DetectKeyPoints(imgGray, null);
            //the surf descriptor is a size 64 vector describing the intensity pattern surrounding
            //the corresponding modelKeyPoint
            modelDescriptors = surfCPU.ComputeDescriptors(imgGray, null, modelKeyPoints);
        }

        var samples = new Matrix&lt;float&gt;(modelDescriptors.Length, DESCRIPTOR_COUNT);//SURF Descriptors have 64 samples
        for (int k = 0; k &lt; modelDescriptors.Length; k++)
        {
            for (int i = 0; i &lt; modelDescriptors[k].Descriptor.Length; i++)
            {
                samples.Data[k, i] = modelDescriptors[k].Descriptor[i];
            }

        }

        //group descriptors into clusters using K-means to form the feature vectors
        //create ""vocabulary"" based on square-error partitioning K-means
        var centers = new Matrix&lt;float&gt;(CLUSTER_COUNT, samples.Cols, 1);
        var term = new MCvTermCriteria();
        var labelVector = new Matrix&lt;int&gt;(modelDescriptors.Length, 1);
        var cluster = CvInvoke.cvKMeans2(samples, CLUSTER_COUNT, labelVector, term, 3, IntPtr.Zero, 0, centers, IntPtr.Zero);

        //this is the quantized feature vector as described in Dance, Csurska Bag of Keypoints (2004)
        var keyPoints = new Matrix&lt;float&gt;(1, CLUSTER_COUNT);

        //quantize the vector into a feature vector
        //making a histogram of the result counts
        for (int i = 0; i &lt; labelVector.Rows; i++)
        {
            var value = labelVector.Data[i, 0];
            keyPoints.Data[0, value]++;
        }
        //normalize the histogram since it will have different amounts of points
        keyPoints = keyPoints / keyPoints.Norm;
        return keyPoints;
    }
</code></pre>

<p>The output gets fed into NormalBayesClassifier. This is how I train it.</p>

<pre><code>Parallel.For(0, hamCount, i =&gt;
            {
                using (var img = new Image&lt;Gray, byte&gt;(_hams[i].FullName))
                {
                    var features = _extractor.Extract(img);
                    features.CopyTo(trainingData.GetRow(i));
                    trainingClass.Data[i, 0] = 1;
                }
            });

        Parallel.For(0, spamCount, j =&gt;
        {
            using (var img = new Image&lt;Gray, byte&gt;(_spams[j].FullName))
            {
                var features = img.ClassifyFeatures(_extractor);
                features.CopyTo(trainingData.GetRow(j));
                trainingClass.Data[j + hamCount, 0] = 0;
            }
        });

        using (var classifier = new NormalBayesClassifier())
        {
            if (classifier.Train(trainingData, trainingClass, null, null, false))
            {

                classifier.Save(_statModelFilePath);
            }
        }
</code></pre>

<p>When I call Predict using the NormalBayesClassifier it returns 1(match) for all of the training samples...ham and spam.</p>

<p>Any help would be greatly appreciated.</p>

<p>Edit.
One other note is that I have chosen CLUSTER_COUNT from 5 to 500 all with the same result.</p>
",2014-03-31 23:14:00,2014-04-08 15:33:12,What is wrong with my SURF/KMeans classifer,<c#><opencv><emgucv><bayesian-networks>,,,CC BY-SA 3.0,True,False,True,False,False
20335,23920745,2014-05-28 19:58:09,,"<p>I am relativity new EmguCV but I have done a lot of research and read a few tutorials and look through this site for the answer. All of the other people with similar problems are told to add the unmangaged dll to the output folder. I have done this and I am still getting this error 'Emgu.CV.Invoke' threw an exception. </p>

<pre><code>using Emgu.CV;
using Emgu.Util;
using Emgu.CV.Structure;

using AForge;
using AForge.Video;
using AForge.Video.DirectShow;
using AForge.Video.VFW;
using System.Drawing.Imaging;
using System.IO;


namespace WindowsFormsApplication2
{
    public partial class SandBox : Form
    {
        private bool DeviceExist = false;
        public VideoCaptureDevice FinalVideoSource;
        public FilterInfoCollection VideoCaptureDevices;
        private Capture capture;
        private VideoWriter captureOutput;


        private void FinalVideoSource_NewFrame(object sender, AForge.Video.NewFrameEventArgseventArgs)
    {
        Bitmap image = (Bitmap)eventArgs.Frame.Clone();
        image.RotateFlip(RotateFlipType.Rotate180FlipY);
        pictureBox1.Image = image;
    }
    public SandBox()
    {
        InitializeComponent();

    }

    private void Form1_Load(object sender, EventArgs e)
    {
        label1.Text = "" "";
        FPS.Text = "" "";
        try
        {
            VideoCaptureDevices = new FilterInfoCollection(AForge.Video.DirectShow.FilterCategory.VideoInputDevice);
            DeviceExist = true;
            foreach (AForge.Video.DirectShow.FilterInfo VideoCaptureDevice in VideoCaptureDevices)
            {
                comboBox1.Items.Add(VideoCaptureDevice.Name);
            }
            comboBox1.SelectedIndex = 0;
        }
        catch (ApplicationException)
        {
            DeviceExist = false;
            comboBox1.Items.Add(""No device on your system"");
        }
    }

    private void Start_Click(object sender, EventArgs e)
    {
        FinalVideoSource = new VideoCaptureDevice(VideoCaptureDevices[comboBox1.SelectedIndex].MonikerString);
        FinalVideoSource.NewFrame += new NewFrameEventHandler(FinalVideoSource_NewFrame);
        FinalVideoSource.Start();

        label1.Text = ""Device running..."";
        Start.Enabled = false;
        Stop.Enabled = true;
        timer1.Enabled = true;

        capture = new Capture();
        captureOutput = new VideoWriter(""test.avi"", 30, 1280, 720, true);
        Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
        captureOutput.WriteFrame(ImageFrame);
    }
}
</code></pre>

<p>The error is being thrown in line <code>capture = new Capture();</code>. I cant figure out what is wrong with the project. Just to clarify I am only using EmguCV to record video not to display it on screen. Any help would be greatly appreciated.</p>
",2015-01-11 11:10:30,2015-01-11 11:10:30,'Emgu.CV.Invoke' threw an exception,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
20396,20480594,2013-12-09 20:56:30,,"<p>Currently, I am working on a real-time IRIS detection application.</p>

<p>I want to perform an invert operation to the frames taken from the web camera, like this:</p>

<p><img src=""https://i.stack.imgur.com/jamOe.png"" alt=""enter image description here""></p>

<p>I managed to get this line of code, but this is not giving the above results. Maybe parameters need to be changed, but I am not sure.</p>

<pre><code>CvInvoke.cvThreshold(grayframeright, grayframeright, 160, 255.0, Emgu.CV.CvEnum.THRESH.CV_THRESH_BINARY_INV);
</code></pre>
",2019-04-11 01:45:17,2019-04-11 01:45:17,How to change invert frames in EmguCV?,<c#><image-processing><computer-vision><emgucv>,,,CC BY-SA 4.0,False,False,True,False,False
20453,19330517,2013-10-12 04:23:49,,"<p>I wrote code for camera in emgu cv,no error is coming but when I am pressing the start button then camera is getting on but no image is capturing.other project image is getting captured.thanks a lot for helped.</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.CV.Util;

   namespace camstop
 {
       public partial class cameracapture : Form
    {
          private Capture capture;
           private bool captureinprogress;

    public cameracapture()
    {
        InitializeComponent();
    }

    private void processFrame(object sender, EventArgs e)
    {
        Image&lt;Bgr, Byte&gt; imageframe = capture.QueryFrame();
        cameraimagebox.Image = imageframe;
        pictureBox1.Image = imageframe.ToBitmap();
        imageframe.Save(@""E:\\photo\\Mypic.jpg"");

    }

    private void btnstart_Click(object sender, EventArgs e)
    {
        if (capture == null)
        {
            try
            {
                capture = new Capture();
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(excpt.Message);
            }
        }
        if (capture != null)
        {
            if (captureinprogress)
            {  //if camera is getting frames then stop the capture and set button Text
                // ""Start"" for resuming capture
                btnstart.Text = ""Start!""; //
                Application.Idle -= processFrame;
            }
        }
        else
        {
            //if camera is NOT getting frames then start the capture and set button
            // Text to ""Stop"" for pausing capture
            btnstart.Text = ""Stop!"";
            Application.Idle += processFrame;
        }
        captureinprogress = !captureinprogress;
    }
    private void ReleaseData()
    {
        if (capture != null)
            capture.Dispose();
    }

    private void cameracapture_Load(object sender, EventArgs e)
    {

    }




}
</code></pre>

<p>}</p>
",,2013-10-31 07:31:15,"camera in emgu cv,no error is coming but when I am pressing the start button then camera is getting on but no image is capturing",<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
20476,21660823,2014-02-09 15:15:09,,"<p>I am new to image processing, In my application , i want to save the detected circles as a new image , The following code has been used to store the detected circle.</p>

<pre><code>CircleF[] circles = grayframeright_1.HoughCircles(
                        new Gray(cannyThreshold),
                        new Gray(circleAccumulatorThreshold),
                        2.0, //Resolution of the accumulator used to detect centers of the circles
                        20.0, //min distance
                        5, //min radius
                        0 //max radius
                        )[0]; //Get the circles from the first channel
</code></pre>

<p>Are there any methods available in emgu cv / open cv to save the circle as a new Image?</p>

<p>Please help me to figure this out, Code samples would be useful.</p>

<p>Thanks in advance</p>
",,2014-02-10 00:13:01,Save circles form HoughCircles,<c#><c++><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
20502,21661778,2014-02-09 16:36:43,,"<p>Can anyone describe me about this code. This code is small part for count the number of finger after done some preprocessing and get contour, hull and defects:</p>

<blockquote>
  <p>if ((startCircle.Center.Y &lt; box.center.Y || depthCircle.Center.Y &lt; box.center.Y) &amp;&amp; (startCircle.Center.Y &lt; depthCircle.Center.Y) &amp;&amp; (Math.Sqrt(Math.Pow(startCircle.Center.X – depthCircle.Center.X, 2) + Math.Pow(startCircle.Center.Y – depthCircle.Center.Y, 2)) > box.size.Height / 6.5))</p>
</blockquote>

<p>I find that code here: <a href=""http://www.andol.info/hci/1984.htm"" rel=""nofollow"">http://www.andol.info/hci/1984.htm</a>
But how can be like that? especially at the end of code its devide 6.5, what is mean?</p>

<p>Thank you.</p>
",2014-02-10 02:28:19,2014-02-10 02:28:19,Need some explanation about this custom logical heuristic code,<c#><opencv><image-processing><emgucv><image-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
20536,21665029,2014-02-09 21:05:23,,"<p>I am new to image processing , In my application i am detecting eye iris using template matching , So i string a standard iris and performing template matching ,The code is given below</p>

<pre><code>CvInvoke.cvMatchTemplate(grayframeright_1.Ptr, templateimagegray.Ptr, templateimagesults.Ptr, TM_TYPE.CV_TM_CCORR_NORMED);

templateimagesults.MinMax(out min, out max, out Min_Loc, out MAX_Loc);

                            Location = new Point((MAX_Loc[0].X), (MAX_Loc[0].Y));
</code></pre>

<p>The problems is some times i get false positives , in order to eliminate false positive , i planned to calculate/get matching percentage value and use appropriate if condition.</p>

<p>1)So are there any functions in emgucv/opencv to get the matching percentage value?
for e.g - 50% , 80% and etc</p>

<p>2)Are there any other ways to eliminate false positives ?</p>

<p>Please help me to figure this out .</p>

<p>Thanks in advance</p>
",,2014-02-11 04:19:53,Get matching percentage value when using Template matching,<c#><c++><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
20549,21665809,2014-02-09 22:17:51,,"<p>I have the following sample from the emgu opencv wrapper</p>

<pre><code>HomographyMatrix homography = null;
SURFDetector surfCPU = new SURFDetector(500,true);
        VectorOfKeyPoint modelKeyPoints;
        VectorOfKeyPoint observedKeyPoints;
        Matrix&lt;int&gt; indices;

        Matrix&lt;byte&gt; mask;
        int k = 2;
        double uniquenessThreshold = 0.9; //0.8

        //extract features from the object image
        modelKeyPoints = surfCPU.DetectKeyPointsRaw(modelImage, null);
        Matrix&lt;float&gt; modelDescriptors = surfCPU.ComputeDescriptorsRaw(modelImage, null, modelKeyPoints);
        modelImage.Dispose();                     


        // extract features from the observed image
        observedKeyPoints = surfCPU.DetectKeyPointsRaw(observedImage, null);
        Matrix&lt;float&gt; observedDescriptors = surfCPU.ComputeDescriptorsRaw(observedImage, null, observedKeyPoints);
        observedImage.Dispose();
        BruteForceMatcher&lt;float&gt; matcher = new BruteForceMatcher&lt;float&gt;(DistanceType.L2);
        matcher.Add(modelDescriptors);

        indices = new Matrix&lt;int&gt;(observedDescriptors.Rows, k);
        using (Matrix&lt;float&gt; dist = new Matrix&lt;float&gt;(observedDescriptors.Rows, k))
        {
            matcher.KnnMatch(observedDescriptors, indices, dist, k, null);
            mask = new Matrix&lt;byte&gt;(dist.Rows, 1);
            mask.SetValue(255);
            Features2DToolbox.VoteForUniqueness(dist, uniquenessThreshold, mask);
        }
        //...
</code></pre>

<p>after applying the KnnMatch how can i get the number of matched key points and what does the non zero pixle count has to do with getting similarity between 2 images?</p>
",2018-08-01 03:39:38,2018-08-01 03:39:38,Returning similarity between 2 Images with KnnMatch,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
20612,20497798,2013-12-10 15:01:28,,"<p>How can I compute the hog descriptor vector of an image using EMGU CV and C#.</p>

<p>If i make something like this:</p>

<pre><code>float[] f;
Image&lt;Bgr, Byte&gt; img1 = new Image&lt;Bgr, Byte&gt;(fullPath);

f = hog.Compute(img1, Size.Empty, Size.Empty,null );
</code></pre>

<p>it doesn't work, it gives a </p>

<blockquote>
  <p>Object reference not set to an instance of an object.</p>
</blockquote>

<p>exception. I want to compute the hog descriptor with default parameters.</p>

<p>Does someone know how to do this ?</p>

<p>Emgu cv is very poorly documented.</p>

<p>I have modified the code and now I am getting the following error: ""External component has thrown an exception"" The code is listed below   </p>

<pre><code>public float[] GetVector(Image&lt;Bgr, Byte&gt; im)
    {
        HOGDescriptor hog = new HOGDescriptor();    // with defaults values
       // Image&lt;Bgr, Byte&gt; pImage = new Image&lt;Bgr, Byte&gt;(;
       //pImage.ROI = new Rectangle(new Point(0, 0), new Size(64, 128));
        Point[] p = new Point[im.Width * im.Height];
        int k = 0;
        for (int i = 0; i &lt; im.Width; i++)
        {
            for (int j = 0; j &lt; im.Height; j++)
            {
                Point p1 = new Point(i, j);
                p[k++] = p1;
            }
        }
        return hog.Compute(im, new Size(8, 8), new Size(0, 0), p);
    }
</code></pre>
",2013-12-13 10:57:54,2013-12-17 15:48:17,Taking the HOG descriptor of an image using HOGDescriptor from EMGU CV C#,<c#><image-processing><emgucv><pattern-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
20624,19345824,2013-10-13 13:33:48,,"<p>How to get information about a video file (ex: frames per second, bitrate, frame height, width etc) using emguCV or FFmpeg to a C# code. I am using C#.net for my project.</p>
",,2013-10-13 14:16:46,EmguCV/ FFmpeg get video information,<video><ffmpeg><emgucv>,,,CC BY-SA 3.0,False,False,True,False,True
20665,20501572,2013-12-10 17:44:27,,"<p>I am currently using </p>

<pre><code>Capture grabber = new Emgu.CV.Capture(@""M2U00253.wmv"");
grabber.QueryFrame();
</code></pre>

<p>I want to know that how can I use an image file(.jpg) instead of the video file(.mpg)?</p>
",2013-12-10 18:03:06,2013-12-11 06:15:50,Using static image in EmguCV capture,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
20729,25054912,2014-07-31 09:06:12,,"<p>I am using a class which implements <code>ISerializable</code> but does not have a parameterless constructor. The class is from <strong>EmguCV</strong> library:</p>

<pre><code>[Serializable]
public class DenseHistogram : UnmanagedObject, ISerializable, IEquatable&lt;DenseHistogram&gt;
{
    public DenseHistogram(int binSize, RangeF range);
    public DenseHistogram(int[] binSizes, RangeF[] ranges);
    public DenseHistogram(SerializationInfo info, StreamingContext context);
}
</code></pre>

<p>As you may guess I get a ""<em>Emgu.CV.DenseHistogram cannot be serialized because it does not have a parameterless constructor.</em>"" exception. I know that -and why- I need the parameterless constructor but it kind of makes me confused since the class implements <code>ISerializable</code>.</p>
",,2014-07-31 09:50:50,Serialize a ISerializable class without parameterless constructor,<c#><serialization><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
20754,22805842,2014-04-02 08:39:01,,"<p>Have searched on Stackoverflow.com and google. But didn't found any proper method to do so apart from the link shown below.</p>

<p><a href=""https://stackoverflow.com/questions/13651734/compare-two-images-and-extract-the-difference-using-emgu-cv-library"">compare two images and extract the difference using emgu cv library</a></p>

<p>Please suggest or give helpful feedback so that i can start up with the application.</p>
",2017-05-23 12:08:59,2020-05-18 13:58:28,How can I compare two still images using emgu cv in c#,<c#><winforms><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
20770,22806329,2014-04-02 08:59:02,,"<p>I am trying to capture images using webcam but I came across a null exception:</p>

<p><a href=""http://i89.photobucket.com/albums/k218/lololovelola/frame1null2_zps54bd24ce.png"" rel=""nofollow"">http://i89.photobucket.com/albums/k218/lololovelola/frame1null2_zps54bd24ce.png</a></p>

<p>Frame1 as shown during the debugging has <strong>null</strong> value. However, the fact that I put an error handler that if(frame1 != null) then it should not enter the condition because Frame1 is <strong>null</strong>.</p>

<p>What makes it even more odd is that frame2 accepts data from frame1 which in the previous image shows that it has null value and do not hold an image capture. Just to add, frame4 also accept the same image from frame1.</p>

<p><a href=""http://i89.photobucket.com/albums/k218/lololovelola/frame2null_zps2198fbb0.png"" rel=""nofollow"">http://i89.photobucket.com/albums/k218/lololovelola/frame2null_zps2198fbb0.png</a></p>

<p>Any help from above will be very much appreciated. Thank you in advance!</p>
",2014-04-02 14:33:43,2014-04-02 14:33:43,null reference exception in emgu c#,<c#><opencv><webcam><nullreferenceexception><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
20774,19358873,2013-10-14 11:10:48,,"<p>This is an embarrassingly daft question but I cannot find a class. I'm working on a motion tracking application to count cars passing a building and note their colour. I'm using <a href=""http://www.emgu.com/"" rel=""nofollow"">EmguCV</a>, a .Net managed wrapper around <a href=""http://opencv.org/"" rel=""nofollow"">OpenCV</a>.</p>

<p>In the EmguCV samples there is an application <code>Emgu.CV.Example\VideoSurveilance</code> which would be a great start for my application, but I would like to look at the underlying OpenCV classes to see what parameters they work with.</p>

<p>Here's a simple line from the EmguCV example code:</p>

<pre><code>_tracker = new BlobTrackerAuto&lt;Bgr&gt;();
</code></pre>

<p>then later:</p>

<pre><code>_tracker.Process(frame, forgroundMask);
foreach (MCvBlob blob in _tracker)
{
</code></pre>

<p>Tracing that code back into <a href=""http://sourceforge.net/p/emgucv/code/ci/master/tree/Emgu.CV/VideoSurveillance/BlobTrackerAuto.cs"" rel=""nofollow"">the EmguCV source-code</a> we find the following code in the <code>Emgu.CV.VideoSurveillance</code> namespace in the EmguCV core project:</p>

<pre><code>public void Process(Image&lt;TColor, Byte&gt; currentFrame, Image&lt;Gray, Byte&gt; foregroundMask)
{
    CvInvoke.CvBlobTrackerAutoProcess(_ptr, currentFrame.Ptr, foregroundMask == null ? IntPtr.Zero : foregroundMask.Ptr);
}

[DllImport(CvInvoke.EXTERN_LIBRARY, CallingConvention = CvInvoke.CvCallingConvention)]
internal extern static void CvBlobTrackerAutoProcess(IntPtr tracker, IntPtr pImg, IntPtr pMask);
</code></pre>

<p>So somewhere in <a href=""http://docs.opencv.org/2.4.6/modules/refman.html"" rel=""nofollow"">the OpenCV API reference</a> I should be able to find a method like <code>CvBlobTrackerAutoProcess</code>. But I cannot find anything to do with <code>BlobTrackerAuto</code> at all.</p>

<p>So this is a long-winded way of asking where in the OpenCV API hierarchy are the BlobTracker classes? </p>
",2013-10-14 11:19:45,2013-10-25 06:26:12,Where are OpenCV's Video Surveilance BlobTracker classes?,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
20810,25060687,2014-07-31 13:53:22,,"<p>I tried to adapt the example MotionDetection from Emgu examples folder. The only important thing I changed is that I don't capture images directly from webcam but create Image&lt;,> from Bitmap. Basically instead of</p>

<pre><code>using (Image&lt;Bgr, Byte&gt; image = _capture.RetrieveBgrFrame())
</code></pre>

<p>i use</p>

<pre><code>using (Image&lt;Bgr, Byte&gt; image = new Image&lt;Bgr, Byte&gt;(bmp))
</code></pre>

<p>where <code>bmp</code> is <code>Bitmap</code> that I captured from webcam using other methods.</p>

<p><a href=""https://github.com/artemisvision/emgu_openCV/tree/master/Emgu.CV.Example/MotionDetection"" rel=""nofollow"">Here's the full code.</a> </p>

<p>The part I used and adapted:</p>

<pre><code>public Bitmap ProcessFrame(Bitmap bmp)
    {
        using (Image&lt;Bgr, byte&gt; image = new Image&lt;Bgr, byte&gt;(bmp))
        using (MemStorage storage = new MemStorage())
        {
            if (_forgroundDetector == null)
            {
                _forgroundDetector = new BGStatModel&lt;Bgr&gt;(image, Emgu.CV.CvEnum.BG_STAT_TYPE.FGD_STAT_MODEL);
            }

            _forgroundDetector.Update(image);

            _motionHistory.Update(_forgroundDetector.ForegroundMask);

            #region get a copy of the motion mask and enhance its color
            double[] minValues, maxValues;
            Point[] minLoc, maxLoc;
            _motionHistory.Mask.MinMax(out minValues, out maxValues, out minLoc, out maxLoc);
            Image&lt;Gray, Byte&gt; motionMask = _motionHistory.Mask.Mul(255.0 / maxValues[0]);
            #endregion

            image[0] = motionMask;

            double minArea = 100;

            storage.Clear();
            Seq&lt;MCvConnectedComp&gt; motionComponents = _motionHistory.GetMotionComponents(storage);

            foreach (MCvConnectedComp comp in motionComponents)
            {
                if (comp.area &lt; minArea) continue;

                double angle, motionPixelCount;
                _motionHistory.MotionInfo(comp.rect, out angle, out motionPixelCount);

                if (motionPixelCount &lt; comp.area * 0.05) continue;

                DrawMotion(image, comp.rect, angle, new Bgr(Color.Red));
            }

            double overallAngle, overallMotionPixelCount;
            _motionHistory.MotionInfo(motionMask.ROI, out overallAngle, out overallMotionPixelCount);
            DrawMotion(image, motionMask.ROI, overallAngle, new Bgr(Color.Green));

            return image.ToBitmap();
        }
    }

private static void DrawMotion(Image&lt;Bgr, Byte&gt; image, Rectangle motionRegion, double angle, Bgr color)
  {
     float circleRadius = (motionRegion.Width + motionRegion.Height) &gt;&gt; 2;
     Point center = new Point(motionRegion.X + motionRegion.Width &gt;&gt; 1, motionRegion.Y + motionRegion.Height &gt;&gt; 1);

     CircleF circle = new CircleF(
        center,
        circleRadius);

     int xDirection = (int)(Math.Cos(angle * (Math.PI / 180.0)) * circleRadius);
     int yDirection = (int)(Math.Sin(angle * (Math.PI / 180.0)) * circleRadius);
     Point pointOnCircle = new Point(
         center.X + xDirection,
         center.Y - yDirection);
     LineSegment2D line = new LineSegment2D(center, pointOnCircle);

     image.Draw(circle, color, 1);
     image.Draw(line, color, 2);
  }
</code></pre>

<p>However, the program throws an exception:</p>

<p><code>An unhandled exception of type 'Emgu.CV.Util.CvException' occurred in Emgu.CV.dll. Additional information: OpenCV: Failed to allocate 121651200 bytes</code></p>

<p>here:</p>

<pre><code>_forgroundDetector = new BGStatModel&lt;Bgr&gt;(image, Emgu.CV.CvEnum.BG_STAT_TYPE.FGD_STAT_MODEL);
</code></pre>

<p>Windows 7, 64x, program is build as 'Any CPU', 'Prefer 32-bit'. I use the newest Emgu 2.4.9-beta.</p>

<p>It happens when I use 1920x1080 bitmaps (3MB). When I use two different cameras in app window (704x576 and 352x288, I modified program so I can have images from multiple cameras), it happens too (not with the single low-resolution one though). The program runs without problems when I don't detect motion with this method.</p>
",2014-07-31 14:02:49,2014-07-31 14:02:49,"EmguCV, failed to allocate memory",<c#><.net><opencv><memory><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
20845,21693264,2014-02-11 04:40:39,,"<p>I am developing an application to show video using webcam and IpCamera.
For <code>IpCamera</code>, it shows video stream for sometime but after that it stops streaming and application hangs.</p>

<p>I am using <a href=""http://www.emgu.com/wiki/index.php?title=Camera_Capture"" rel=""nofollow"">Emgu.CV Library</a> to grab frames and show it in the picture control.</p>

<p>I have tried below code for display of video by using function <code>QueryFrame()</code>. </p>

<p>for connecting Ip camera
<code>Capture capture = new Capture(URL);</code></p>

<p>for grabbing frames
<code>Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();</code></p>

<p>After some time the <code>QueryFrame()</code> provide <code>null</code> value and application hangs.</p>

<p>Can any one tell me why this is happening and how I can handle it?</p>

<p>Thank you in advance.</p>
",2014-02-11 04:57:43,2014-02-18 17:27:24,C# -Application hang after connected with IP Camera,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
20850,17482629,2013-07-05 06:41:32,,"<p>all,</p>

<p>I just tried the face detection example in latest version of Emgu CV, And my program works well, but i cannot have any faces from either image or the webcam live captures.</p>

<p>My OS is windows 8 Enterprise x64. And my IDE is VS2012. </p>

<p>BTW, I also tried HaarCascade and CascadeClassifier. Neither of them can get a result. The returned variable's value will always be {Emgu.CV.Structure.MCvAvgComp[0]}</p>

<pre><code>cap = new Capture(0);
// adjust path to find your xml
//ccf = new CascadeClassifier(""D:\\haarcascade_frontalface_alt_tree.xml"");
haar = new HaarCascade(""D:\\haarcascade_frontalface_alt_tree.xml"");
Image inputImg = Image.FromFile(@""D:\1.jpg"");

Image&lt;Bgr, byte&gt; imageFrame = new Image&lt;Bgr, byte&gt;(new Bitmap(inputImg));

if (imageFrame != null) {
    Image&lt;Gray, byte&gt; grayFrame = imageFrame.Convert&lt;Gray, byte&gt;();

var faces = grayFrame.DetectHaarCascade(haar, 1.1, 10, HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(20, 20))[0];

foreach (var face in faces) {
                imageFrame.Draw(face.rect, new Bgr(Color.Green), 3);
            }
}
pictureBox1.Image = imageFrame.ToBitmap();
</code></pre>

<p>Any thoughts or help? Thank you very much.</p>

<p>Solved thank you.</p>
",2017-12-13 10:22:29,2017-12-13 10:22:29,Cannot detect any faces in Face detection example,<graphics><computer-vision><emgucv><face-detection>,,,CC BY-SA 3.0,False,False,True,False,False
20866,23967919,2014-05-31 08:15:06,,"<pre><code>void FrameGrabber(object sender, EventArgs e)
        {
            NamePersons.Clear();
            NamePersons.Add("""");

            //Get the current frame form capture device
            currentFrame = grabber.QueryFrame().Resize(320, 240, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

            //Convert it to Grayscale
            gray = currentFrame.Convert&lt;Gray, Byte&gt;();

            //Face Detector
            MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
          face,
          1.4,
          4,
          Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
          new Size(20, 20));

            //Action for each element detected
            foreach (MCvAvgComp f in facesDetected[0])
            {
                t = t + 1;
                result = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
                //draw the face detected in the 0th (gray) channel with blue color
                currentFrame.Draw(f.rect, new Bgr(Color.Red), 2);


                //if (trainingImages.ToArray().Length != 0)
                //{
                    //TermCriteria for face recognition with numbers of trained images like maxIteration
                    MCvTermCriteria termCrit = new MCvTermCriteria(ContTrain, 0.001);

                    //Eigen face recognizer
                    EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
                       trainingImages.ToArray(),
                       labels.ToArray(),
                       5000,
                       ref termCrit);
                    name = recognizer.Recognize(result);
                    groupBox1.Visible = true;
                    label12.Text = name.Trim();
                    SqlCommand cmd = new SqlCommand(""select * from visitortb where name='""+name.Trim()+""'"",db.Connect());
                    SqlDataReader dr;
                    dr=cmd.ExecuteReader();
                    if (dr.Read())
                    {
                        label13.Text = dr[5].ToString().Trim(); 
                        label14.Text = dr[10].ToString().Trim();
                        label16.Text = dr[7].ToString().Trim();
                    }

                    //idcrd.showIDCard(name);
                    //Draw the label for each face detected and recognized
                    currentFrame.Draw(name, ref font, new Point(f.rect.X - 2, f.rect.Y - 2), new Bgr(Color.LightGreen));

                }

            NamePersons[t - 1] = name;
            NamePersons.Add("""");

           // }
            t = 0;

            //Names concatenation of persons recognized
            //for (int nnn = 0; nnn &lt; facesDetected[0].Length; nnn++)
            //{
            //    //names = names + NamePersons[nnn] + "", "";
            //}
            ////Show the faces procesed and recognized
            //imageBoxFrameGrabber.Image = currentFrame;
            ////label4.Text = names;
            //names = """";
            ////Clear the list(vector) of names
            //NamePersons.Clear();

        }
</code></pre>

<p>Trying to get the details of the faces detected from the database, but I have been getting this error ""Index was out of range. Must be non-negative and less than the size of the collection. Parameter name: index"" at the line</p>

<pre><code>NamePersons[t - 1] = name;
</code></pre>
",2015-06-11 20:55:39,2015-06-11 20:55:39,Index was out of range. Must be non-negative and less than the size of the collection. Parameter name: index Emgu CV,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
20882,25065701,2014-07-31 17:49:32,,"<p>I'm trying to make a face recognition plugin for <a href=""http://www.ispyconnect.com/"" rel=""nofollow"">iSpy</a> using the emgucv library. 
<br>I've been trying for the past few days and I keep getting the <a href=""http://www.emgu.com/wiki/index.php/Download_And_Installation#The_type_initializer_for_.27Emgu.CV.CvInvoke.27_threw_an_exception."" rel=""nofollow"">missing dlls error for CVInvoke</a> no matter what I try. The error comes up as soon as I try to use emgucv to generate an Image&lt;> from a Bitmap the plugin receives from iSpy for each frame.
<br>Any ideas on what can I do about it? 
All opencv dlls are where they are supposed to be and the required emgucv dlls have been added as references and being used.</p>

<p>The code is currently</p>

<pre><code>public Bitmap ProcessFrame(Bitmap frame)
{
    Bitmap drawCopy = new Bitmap(frame);

    try
    {
        using (Image&lt;Rgb, Byte&gt; currentFrame = new Image&lt;Rgb, Byte&gt;(drawCopy))
        {
        }
    }
    catch (Exception e)
    {
        Graphics g = Graphics.FromImage(drawCopy);
        g.DrawString(e.InnerException.Message, new Font(""Verdana"", 8), new SolidBrush(Color.Tomato), 0, 0);
        g.Dispose();
    }

    return drawCopy;
}
</code></pre>

<p>ProcessFrame is the standard name for the method that receives the frame from iSpy.
Currently it prints the error message over the frame since debugging the plugin is impossible because it's not a stand alone application, it has to be a class library in order to be used by iSpy.</p>

<p>Thank you</p>
",,2014-07-31 17:49:32,EmguCV plugin for iSpy,<c#><.net><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
20950,18436283,2013-08-26 03:43:40,,"<p>I am new to Emgu CV in C# and when I tried to set it up on my 64-bit laptop, I added the required EmguCV .dll files as reference and the related opencv .dll files to the project or put the opencv .dll files to bin/debug folder in my project folder, I got the following error (I've changed my targeted platform to x64 and downloaded the x64 package):</p>

<pre><code>System.TypeInitializationException was unhandled
  HResult=-2146233036
  Message=The type initializer for 'Emgu.CV.CvInvoke' threw an exception.
  Source=Emgu.CV
  TypeName=Emgu.CV.CvInvoke

  InnerException: System.DllNotFoundException
       HResult=-2146233052
       Message=Unable to load DLL 'opencv_core242': The specified module could not be found. (Exception from HRESULT: 0x8007007E)
       Source=Emgu.CV
       TypeName=""""
       StackTrace:
            at Emgu.CV.CvInvoke.cvRedirectError(CvErrorCallback errorHandler, IntPtr userdata, IntPtr prevUserdata)
            at Emgu.CV.CvInvoke..cctor()
       InnerException: 
</code></pre>

<p>I've been stuck to this for a few days and really appreciate any help.</p>

<p>Thank you.</p>
",,2013-09-01 02:43:11,"Unable to upload ""opencv_core242"" after adding the files to application output directory",<c#><opencv>,,,CC BY-SA 3.0,True,False,True,False,False
20971,19375481,2013-10-15 07:27:06,,"<p>How to save emgu CV camera capture image in folder and retrieve. Whenever I trying to save null reference exception error getting.</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.UI;
using Emgu.CV.Util;
using Emgu.CV.Structure;

namespace camerapart2
{
    public partial class Form1 : Form
    {
        private Capture capture;
        private bool captureinprogress;
        public Form1()
        {
            InitializeComponent();
        }

        private void ProcessFrame(object sender, EventArgs arg)

        Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
        cameraimage.Image = ImageFrame;
        pictureBox1.Image = ImageFrame.ToBitmap();
        ImageFrame.Save(@""E:\MyPic.jpg"");

        private void btnStart_Click(object sender, EventArgs e)
        {
            if (capture == null)
            {
                try
                {
                    capture = new Capture();
                }
                catch (NullReferenceException excpt)
                {
                    MessageBox.Show(excpt.Message);
                }
            }

            if (capture != null)
            {
                if (captureinprogress)
                {  //if camera is getting frames then stop the capture and set button Text
                    // ""Start"" for resuming capture
                    btnstart.Text = ""Start!""; //
                    Application.Idle -= ProcessFrame;
                }
                else
                {
                    //if camera is NOT getting frames then start the capture and set button
                    // Text to ""Stop"" for pausing capture
                    btnstart.Text = ""Stop"";
                    Application.Idle += ProcessFrame;
                }

                captureinprogress = !captureinprogress;
            }
        }

        private void ReleaseData()
        {
            if (capture != null)
                capture.Dispose();
        }
    }
}
</code></pre>

<p>In these two lines I'm getting nullrefference error:</p>

<pre><code>pictureBox1.Image = ImageFrame.ToBitmap();
ImageFrame.Save(@""E:\MyPic.jpg"");
</code></pre>
",2013-10-15 08:36:06,2019-09-28 08:02:35,how to save emgu camera capture image in folder and retrieve,<c#><.net><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
20979,25072623,2014-08-01 03:53:36,,"<p>i am trying to use 3 cameras to capture photos however i am unable to produce all 3 of it. i have 2 external webcam ( Microsoft Cinema Webcam ) and 1 internal laptop camera , i used my previous laptop and it works perfectly however when i tried to use another laptop it is unable to work.</p>

<p>I tried some ways like testing each camera and i found out that i can use only 2 webcam at the same time using my program despite having 3 at the other laptop.</p>

<p>I am unable to make my laptop camera work . Any idea how?</p>

<p>Any idea how to get this work?</p>

<blockquote>
<pre><code>namespace Camera
{
    public partial class CameraOutput : Form
    {
        private Capture _capture, _capture2, _capture3;
        private bool captureInProgress;
        private bool saveToFile;

        private Font font = new Font(""Calibri"", 14);

        public CameraOutput()
        {
            InitializeComponent();
        }

        private void ProcessFrame(Object sender, EventArgs arg)
        {
            Image&lt;Bgr, Byte&gt; ImageFrame = _capture.QueryFrame();
            Image&lt;Bgr, Byte&gt; ImageFrame2 = _capture2.QueryFrame();
            Image&lt;Bgr, Byte&gt; ImageFrame3 = _capture3.QueryFrame();

            CamImageBox.Image = ImageFrame;
            CamImageBox2.Image = ImageFrame3;
            CamImageBox3.Image = ImageFrame2;


            //image_Form1 = Image.FromFile(@""C:\center90\center90(1).jpg"");


            if (saveToFile)
            {
                ImageFrame.Save(@""C:\Users\L31101\Desktop\Camera\Camera\bin\Debug\left\left.jpg"");
                ImageFrame3.Save(@""C:\Users\L31101\Desktop\Camera\Camera\bin\Debug\center\center.jpg"");
                ImageFrame2.Save(@""C:\Users\L31101\Desktop\Camera\Camera\bin\Debug\right\right.jpg"");
                //System.Drawing.Image img = ImageFrame3.ToBitmap();
                //image_Form1 = img;
                CameraCoordinates form2 = new CameraCoordinates(ImageFrame3.ToBitmap(),ImageFrame.ToBitmap(),ImageFrame2.ToBitmap());
                form2.Show();
                saveToFile = !saveToFile;
            }


        }

        private void CameraOutput_Load(object sender, EventArgs e)
        {
            #region if capture is not created, create it now

            pictureBox1.Enabled = true;

            if (_capture == null)
            {
                try
                {
                    _capture = new Capture(1);
                }

                catch (NullReferenceException excpt)
                {
                    MessageBox.Show(excpt.Message);
                }
            }

            if (_capture2 == null)
            {
                try
                {
                    _capture2 = new Capture(2);
                }

                catch (NullReferenceException excpt)
                {
                    MessageBox.Show(excpt.Message);
                }
            }

            if (_capture3 == null)
            {
                try
                {
                    _capture3 = new Capture(3);
                }

                catch (NullReferenceException excpt)
                {
                    MessageBox.Show(excpt.Message);
                }
            }
            #endregion

            if (_capture != null)
            {
                if (pictureBox1.Enabled == false)
                {
                    Application.Idle -= ProcessFrame;
                }
                else
                {
                    Application.Idle += ProcessFrame;
                }

                captureInProgress = !captureInProgress;
            }

            if (_capture2 != null)
            {
                if (pictureBox1.Enabled == false)
                {
                    Application.Idle -= ProcessFrame;
                }
                else
                {
                    Application.Idle += ProcessFrame;
                }

                captureInProgress = !captureInProgress;
            }

            if (_capture3 != null)
            {
                if (pictureBox1.Enabled == false)
                {
                    Application.Idle -= ProcessFrame;
                }
                else
                {
                    Application.Idle += ProcessFrame;
                }

                captureInProgress = !captureInProgress;
            }
        }

        private void ReleaseData()
        {
            if (_capture != null)
            _capture.Dispose();

            if (_capture2 != null)
                _capture.Dispose();

            if (_capture3 != null)
                _capture.Dispose();
        }

        Image image_Form1;
        public Image Image_Form1
        {
            get { return image_Form1; }
            set { image_Form1 = value; }
        }

        private void pictureBox1_Click(object sender, EventArgs e)
        {
            saveToFile = !saveToFile;
            MessageBox.Show(""Done"");
        }
</code></pre>
</blockquote>
",2014-08-07 12:59:31,2014-11-21 01:34:19,EMGUCV Multiple webcam,<c#><webcam><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
21030,21709001,2014-02-11 17:36:00,,"<p>How to clear every frames that have been processed by tracking? because now in my application, it continues to increase the number of frames, consumes a lot of memory and makes my computer freeze.</p>

<p>Thank You.</p>

<p><strong>EDIT</strong></p>

<p>Start tracking with camshift algorithm with 3 method, update hue image, Hand tracker, and track hand.
1. convert image to hsv, get hue channel color, do histogram for hue channel
2. do back projection
3. do camshift-->meanshift algorithm</p>

<blockquote>
<pre><code>    public void HandTracker(Image&lt;Bgr, Byte&gt; ImageFrame, Rectangle currentrect)
    {

        hsv = Emgu.CV.CvInvoke.cvCreateImage(new Size(ImageFrame.Width, ImageFrame.Height), IPL_DEPTH.IPL_DEPTH_8U, 3);
        hue = Emgu.CV.CvInvoke.cvCreateImage(new Size(ImageFrame.Width, ImageFrame.Height), IPL_DEPTH.IPL_DEPTH_8U, 1);
        mask = Emgu.CV.CvInvoke.cvCreateImage(new Size(ImageFrame.Width, ImageFrame.Height), IPL_DEPTH.IPL_DEPTH_8U, 1);
        backproject = Emgu.CV.CvInvoke.cvCreateImage(new Size(ImageFrame.Width, ImageFrame.Height), IPL_DEPTH.IPL_DEPTH_8U, 1);
        histogram = new DenseHistogram(30, new RangeF(0, 180));

        previoushand = currentrect;

        UpdateHueImage(ImageFrame);

        //show how many frame detected
        frame = frame + 1;
        label_1.Text = frame.ToString();

        float vmax = 0;
        float vmin = 0;
        float scale = 0;
        x = new IntPtr[1] { hue };

        Emgu.CV.CvInvoke.cvSetImageROI(hue, currentrect);
        Emgu.CV.CvInvoke.cvSetImageROI(mask, currentrect);
        Emgu.CV.CvInvoke.cvCalcHist(x, histogram, false, mask);
        Emgu.CV.CvInvoke.cvGetMinMaxHistValue(histogram, ref vmin, ref vmax, null, null);

        if (vmax != 0)
        {
            scale = 255 / vmax;
        }
        Emgu.CV.CvInvoke.cvConvertScale(histogram.MCvHistogram.bins, histogram.MCvHistogram.bins, scale, 0);
        Emgu.CV.CvInvoke.cvResetImageROI(hue);
        Emgu.CV.CvInvoke.cvResetImageROI(mask);

        //if (ImageFrame != null) ImageFrame.Dispose();
        Debug.WriteLine(""hand tracker done!"");

    }


    public Rectangle TrackHand(Image&lt;Bgr, Byte&gt; ImageFrame)
    {
        MCvConnectedComp components = new MCvConnectedComp();

        UpdateHueImage(ImageFrame);

        //show how many frame detected
        frame = frame + 1;
        label_2.Text = frame.ToString();

        IntPtr[] x = { hue };
        Emgu.CV.CvInvoke.cvCalcBackProject(x, backproject, histogram);
        Emgu.CV.CvInvoke.cvAnd(backproject, mask, backproject, IntPtr.Zero);
        Emgu.CV.CvInvoke.cvCamShift(backproject, previoushand, new MCvTermCriteria(10, 1), out components, out handcomp);

        previoushand = components.rect;

        ImageFrame.Draw(previoushand, new Bgr(Color.Black), 2);

        Debug.WriteLine(""Track hand done!"");

        return currenthand;
    }


    private void UpdateHueImage(Image&lt;Bgr, Byte&gt; currentrect)
    {
        Emgu.CV.CvInvoke.cvCvtColor(currentrect, hsv, COLOR_CONVERSION.CV_BGR2HSV);

        int vmin = 65;
        int vmax = 256;
        int smin = 55;
        Emgu.CV.CvInvoke.cvInRangeS(hsv, new MCvScalar(0, smin, Math.Min(vmin, vmax), 0), 
            new MCvScalar(180, 256, Math.Max(vmin, vmax), 0), 
            mask);
        Emgu.CV.CvInvoke.cvSplit(hsv, hue, IntPtr.Zero, IntPtr.Zero, IntPtr.Zero);

        Debug.WriteLine(""UpdateHueImage done!"");

    }
</code></pre>
</blockquote>

<p>That is my code for camshift tracking, I found that it's consume too much memory and my pc freeze after 800++ frame detected. How I delete cache ImageFrame that already processed?</p>
",2014-02-12 16:23:52,2014-08-18 14:13:45,How to clear history frames after done tracking in life streaming video?,<c#><image-processing><computer-vision><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
21042,19380531,2013-10-15 11:52:45,,"<p>The code below takes multiple seconds and I would like to detect an object by color faster so it can be displayed realtime.</p>

<pre><code>grayImg = input.InRange(new Bgr(selectionRangeSlider1.SelectedMin,
                                selectionRangeSlider2.SelectedMin,
                                selectionRangeSlider3.SelectedMin),
                                new Bgr(selectionRangeSlider1.SelectedMax,
                                        selectionRangeSlider2.SelectedMax,
                                        selectionRangeSlider3.SelectedMax));  
</code></pre>

<p>selectionRangeSlider is a custom Control that has 2 sliders on 1 valueline</p>

<pre><code>Rectangle roi; //this rectangle is the product of rectangle recognition, now I want to check if the color of this recangle is at least 50% yellow

int whitePixels = 0;

for (int i = roi.X; (i &lt; (roi.X + roi.Width)); i++)
{
    for (int j = roi.Y; (j &lt; (roi.Y + roi.Height)); j++)
    {
        Byte currentVal = g.Data[i, j, 0];

        if (currentVal == 255) //255 means true: this pixel is yellow
        {
            Console.WriteLine(i + "","" + j + "" is yellow"");
            whitePixels++;
        }
    }
}

if (whitePixels &gt; ((roi.Width * roi.Height) / 2))
{
    // ""more that half is yellow"";
}
</code></pre>
",2013-10-15 11:59:21,2013-10-15 17:20:14,Is there a faster way to detect an object by color using Emgu CV (openCV wrapper)?,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
21066,25082567,2014-08-01 14:32:24,,"<p>I am new at EmguCV &amp; C# and I have a project that find circles' info (centers' X &amp; Y coordinates) from USB Camera. According to these coordinates, prototype machine moves rollers with stepper motor x-axis or y-axis.</p>

<p>I used CircleF with HoughCircles and found coordinates with this code:</p>

<blockquote>
  <blockquote>
    <p>CircleF[] circles = imgProcessed.HoughCircles(new Gray(100), new Gray(50), 2, imgProcessed.Height / 4, 30, 45)[0];</p>
  </blockquote>
</blockquote>

<p>I want to create 2d array from CircleF to apply array process and  apply mathematical operations to circles' X and Y values.</p>

<p>I thought that if I convert ""circles"" CircleF to array, these processes are easier.
I know CircleF is a kind of array, but I cannot apply some array process (like sorting) on it. I want to sort X values of circles' centers from small to large. I cannot do that like Array.Sort(circles)</p>

<p>Does anybody help me about this situation?</p>

<p>or if it is possible to apply array process on CircleF, how can I apply?</p>

<p>Code samples would be useful. Thanks for now.</p>
",2014-08-01 20:48:42,2014-09-17 06:22:06,how can I convert circleF object to array object using emgu c#,<c#><arrays><sorting><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
21086,18449721,2013-08-26 17:35:08,,"<p>I'm trying to build an Active Appearance Model like in this <a href=""http://www.isbe.man.ac.uk/~bim/software/am_tools_doc/build_aam.html"" rel=""nofollow"">guide</a>.
But some of the comments sounds to me abstract and incomprehensible. So can you upload the entire set of files needed to create a model or send a link which has it. Thanks and sorry for my english!</p>
",,2013-08-29 17:10:14,Building an Active Appearance Model,<opencv><emgucv><face-detection><face-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
21141,17506855,2013-07-06 20:30:39,,"<p>I need to get coordinates of facial features with <code>Emgu CV</code>. I know it is possible to train <code>Haar</code> classifier and it will recognize the objects, but I need exact coordinates, instead of squares with such objects.</p>

<p>For example, I must retrieve the coordinates of the left and right edges of the eye, instead of the square around it. How do I do so?</p>
",2013-07-07 00:57:56,2013-07-07 00:57:56,Face recognition with Emgu CV,<.net><opencv><face-recognition><emgucv>,2013-07-08 02:04:23,,CC BY-SA 3.0,True,False,True,False,False
21247,22846480,2014-04-03 18:54:06,,"<p>I am running a EmguCV example for Image Stitching. Here's the important code from that example:</p>

<pre><code>    try
    {
        using (Stitcher stitcher = new Stitcher(false))
        {
            Image&lt;Bgr, Byte&gt; result = stitcher.Stitch(sourceImages);
            IMGBXDisplayStitched.Image = result;
        }
    }
    finally
    {
        foreach (Image&lt;Bgr, Byte&gt; img in sourceImages)
        {
            img.Dispose();
        }
    }
</code></pre>

<p>It works well, but when I change the value of <code>Stitcher()</code> to true (I want to use GPU), it shows this error:</p>

<blockquote>
  <p>An unhandled exception of type 'Emgu.CV.Util.CvException' occurred in Emgu.CV.dll
  Additional information: OpenCV: You should explicitly call download method for gpu::GpuMat object</p>
</blockquote>

<p>How can I solve this?</p>
",2014-04-03 19:08:57,2014-08-19 19:20:27,Image Stitching Emgu CV with GPU,<c#><runtime-error><emgucv><image-stitching>,,,CC BY-SA 3.0,True,False,True,False,False
21354,18474480,2013-08-27 20:07:01,,"<p>I'm using emguCV to use OpenCV machine learning algorithms. I can successfully train a RTree(i get success) but when i try to predict it gives me always -1. Then i tried to get the Variable Importance matrix and the tree count and the matrix comes as null (i specified the params to built it) and the tree count comes as 0. </p>

<p>Does anyone has any thoughts on what i'm doing wrong? PS, if i use a decision tree i can get predictions. </p>

<p>I have 6 variables and about 11000 samples.
Below are the parameters i use:</p>

<pre><code>        MCvRTParams param = new MCvRTParams();
        param.maxDepth = 8;// max depth
        param.minSampleCount = 10;// min sample count
        param.regressionAccuracy = 0;// regression accuracy: N/A here
        param.useSurrogates = true; //compute surrogate split, no missing data
        param.maxCategories = 15;// max number of categories (use sub-optimal algorithm for larger numbers)
        param.cvFolds = 10;
        //param.use1seRule = true;
        param.truncatePrunedTree = true;
        //param.priors = priorsHandle.AddrOfPinnedObject(); // the array of priors
</code></pre>

<p>Thanks</p>
",2013-09-14 07:04:00,2014-07-29 20:45:26,Random Forest trains but tree count is zero?,<c#><opencv><machine-learning><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
21399,24016311,2014-06-03 13:20:48,,"<p>i am trying to convert images to text using Tesseract OCR text written on images in balochi </p>

<p>(balochi is much like persian language)  </p>

<p>i have created a Program which reads English text from images .. now i want to train it for balochi ..
what are the basics to train the Tesseract engine for right to left languages ..</p>

<p>is there any tool that can create traning data (Freeware / Shareware)</p>

<p>Here is my program .. waiting for your nicest suggestions .</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.Util;
using Emgu.CV.OCR;
using Emgu.CV.Structure;

namespace ReadingImageText
{
    public partial class Form1 : Form
    {
        Tesseract OCRz = new Tesseract(""tessdata"",""eng"", Tesseract.OcrEngineMode.OEM_TESSERACT_ONLY);

        private static Rectangle deviceN = Screen.PrimaryScreen.WorkingArea;
        public static System.Drawing.Bitmap img = new Bitmap(deviceN.Width, deviceN.Height);
        System.Drawing.Graphics gfx = Graphics.FromImage(img);
        Image azeem;
        public Form1()
        {
            InitializeComponent();

        }

        private void Form1_Load(object sender, EventArgs e)
        {

        }

        private void button1_Click(object sender, EventArgs e)
        {
            OCRz.Recognize(new Image&lt;Bgr, byte&gt;(img));
            richTextBox1.Text = OCRz.GetText();
            String text = OCRz.GetText();
            Int32 unixTimestamp = (Int32)(DateTime.UtcNow.Subtract(new DateTime(1970, 1, 1))).TotalSeconds;
            System.IO.File.WriteAllText(@""C:\azeemhassni\recognized_"" + unixTimestamp + "".inp"", text);
        }

        private void button2_Click(object sender, EventArgs e)
        {

            openFileDialog1.Filter = ""All Files (*.*) | *.*"";
            openFileDialog1.FileName = """";
            openFileDialog1.ShowDialog();
        }

        private void openFileDialog1_FileOk(object sender, CancelEventArgs e)
        {
            pictureBox1.Image = makeItImage(openFileDialog1.FileName);
        }


        public Image makeItImage(String filePath)
        {
            Image newImage = Image.FromFile(filePath);
            img = (Bitmap) newImage;
            return newImage;

        }


    }
}
</code></pre>
",,2014-06-10 03:50:47,How to train tesseract for Right to Left languages,<c#><opencv><ocr><tesseract><emgucv>,2014-06-25 03:04:26,,CC BY-SA 3.0,True,False,True,False,False
21411,17532917,2013-07-08 17:49:58,,"<p>I am on OpenCV 2.4.1 and need to detect if a video stream has any kind of noise. Noise such as the sample frames shown below:</p>

<p>What might be a simple, quick way to detect these kinds of noise. The issue is this noise could be intermittent, unpredictable and need detection</p>
",2013-07-08 19:08:40,2013-07-08 19:08:40,"Detecting ""noise"" in a video stream (""snow"", green blocks, partial frame distortion etc.)",<opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
21451,24018650,2014-06-03 15:07:22,,"<p>I am trying to make an colored object tracker which uses a binary image and blob detector to follow the target sort of like this: <a href=""https://www.youtube.com/watch?v=9qky6g8NRmI"" rel=""nofollow"">https://www.youtube.com/watch?v=9qky6g8NRmI</a> . However I can not figure out how the ThresholdBinary() method work and if it is even the right one.</p>

<p>Here is a relevant bit of the code:</p>

<pre><code>cam._SmoothGaussian(3);

blobDetector.Update(cam);
Image&lt;Bgr,byte&gt; binaryImage = cam.ThresholdBinary(new Bgr(145,0,145),new Bgr(0,0,0));
Image&lt;Gray,byte&gt; binaryImageGray = binaryImage.Conver&lt;Gray,byte&gt;();

blobTracker.Process(cam, binaryImageGray);

foreach (MCvBlob blob in blobTracker)
{
   cam.Draw((Rectangle)blob, new Bgr(0,0,255),2);
}
</code></pre>

<p>When I display the binaryImage I do not even get blobs. I just get a black image. </p>
",2014-06-03 15:09:27,2014-06-03 20:07:34,Color tracking using EMGUcv,<c#><video-processing><emgucv><video-tracking>,,,CC BY-SA 3.0,False,False,True,False,False
21455,21745309,2014-02-13 04:31:19,,"<p>I am working on one application where I want to use <code>IP camera</code> for displaying video streaming and and some other major operations on image captured by the <code>IP Camera</code>.</p>

<p><strong>Libraries used in Camera capture</strong>
For Camera Capture : <a href=""http://www.emgu.com/wiki/index.php?title=Camera_Capture"" rel=""nofollow"">Emgu.CV</a> Library</p>

<p>Below is the code which I am using in C#.</p>

<p><em>Variable Declaration</em></p>

<pre><code>    private Capture capture;        //takes images from camera as image frames
    private Emgu.CV.UI.ImageBox img; // Dynamic Picture Controls
    private int nCam;               // no of cameras   
</code></pre>

<p><em>Code for Processing Image</em></p>

<pre><code>  private void ProcessFrame(object sender, EventArgs arg)
  {
    try
          {                
      // Live Streaming Display
     Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();

    // If Ip camera try to reinitialize the IP camera
    if(ImageFrame == null)
   {
       capture.Dispose();
       capture = new Capture(URL);                              
        ImageFrame = capture.QueryFrame();
     }                
      ImageFrame = ImageFrame.Resize(img.Width, img.Height, Emgu.CV.CvEnum.INTER.CV_INTER_LINEAR); 

     img.Image = ImageFrame;

    // Here I am doing some other operations like 
    // 1. Save Image captured from the IP Camera
    // 2. Detect faces in Image 
    // 3. Draw Face markers on Image
    // 4. Some database based on result of Face Detection
    // 4. Delete image File 
    // continue Looping for other Ip Cameras        

     }
      catch (NullReferenceException e)
       {
       }
    }
</code></pre>

<p>Now, The Problem is after some time the <code>QueryFrame()</code> provide <code>null</code> value and camera Stop streaming.</p>

<p>Can any one tell me why this is happening?
How I can resolve this problem?
If any more information is needed Please Let me know.</p>

<p>Thanks in Advance.</p>
",2014-02-13 04:56:38,2014-02-20 15:20:19,IP Camera stop streaming after some time,<c#><opencv><emgucv><ip-camera>,,,CC BY-SA 3.0,True,False,True,False,False
21498,17539624,2013-07-09 03:57:01,,"<p>I'm using kinect camera for a new application, with Microsoft.Kinect sdk and EmguCV. </p>

<p>Is there any way to make zoom with the camera?</p>

<p>Thanks in advance.</p>
",,2013-07-09 16:41:07,Make zoom with Kinect camera,<c#><kinect><emgucv><kinect-sdk>,,,CC BY-SA 3.0,False,False,True,False,False
21544,21754866,2014-02-13 12:55:37,,"<p>I am trying to use object detection to recognise a post-it note within a video feed. I am using emguCV for detection. I tried using the Shape Detection approach but it couldn't recognise the post-it... maybe because I was holding it up in the air so my fingers were obstructing the vertices.</p>

<p>I've also tried using SURF detection but that did not work either I guess because it is a square so does not have any stand-out features.</p>

<p>I attempted to use HAAR/LBP classification but it was taking over 10 hours to train just for one stage for 48 positives and 80 negatives so I gave up.</p>

<p>Can anyway suggest a suitable method for detecting/recognising a post-it note within a video feed? Would be much appreciated.</p>
",,2014-02-13 13:14:35,Object detection for a post-it note,<opencv><detection><emgucv><feature-detection><object-detection>,,,CC BY-SA 3.0,True,False,True,False,False
21650,25129901,2014-08-05 01:19:09,,"<p>I want to create a depth histogram of an image to see how the distribution of the depth values vary. But I don’t know how to do it because there are too many possible depths and counting each one would result in a histogram with a lot of bins. Like 307,200 bins from an image of (480*640).</p>

<p>In the following webpage:</p>

<p><a href=""http://www.i-programmer.info/programming/hardware/2714-getting-started-with-microsoft-kinect-sdk-depth.html?start=2"" rel=""nofollow"">http://www.i-programmer.info/programming/hardware/2714-getting-started-with-microsoft-kinect-sdk-depth.html?start=2</a></p>

<p>They divided the number of depth values by 4 then the performed the bit shift adjustment on the data to create a reasonable looking display:</p>

<pre><code>for (int i = 0; i &lt; PImage.Bits.Length; i += 2)
{
 temp= (PImage.Bits[i+1]&lt;&lt;8 |
               PImage.Bits[i])&amp; 0x1FFF ;
 count[temp &gt;&gt; 2]++;
 temp &lt;&lt;= 2;
 PImage.Bits[i] = (byte) (temp &amp; 0xFF);
 PImage.Bits[i + 1] = (byte) (temp &gt;&gt; 8);
}
</code></pre>

<p>I understand the operations that they did but I don’t understand how this method shrinks the data to 1/4</p>

<p>So, how can I show that information to create a reasonable looking display without using too many bins?</p>

<p>Any ideas?</p>

<p>Best regards,</p>
",,2014-08-06 00:30:31,Create depth histogram without using too many bins,<c#><histogram><emgucv><color-depth><perceptual-sdk>,,,CC BY-SA 3.0,False,False,True,False,False
21708,19442185,2013-10-18 05:24:08,,"<pre><code>    public Object get()
    {
        switch (current_image_type)
        {
            case(image_type.Gray):
                return (Image&lt;Gray, Byte&gt;)image_object;
            case(image_type.Bgr):
                return (Image&lt;Bgr, Byte&gt;)image_object;
            default:
                throw new Exception(""No Image type set for ImageCV"");
        }
    }
</code></pre>

<p>So in this get function I won't know what object type to return until run time, so I just returned the Object super class. However, this isn't good because when I get the returned Object superclass I won't have access to <code>Image&lt;,&gt;</code> subclass functions, unless I know what to cast it to. Is there a way for me to check what type of object <code>current_image_type</code> is return the desired object type at runtime? Thanks.</p>
",2013-10-18 05:32:26,2013-10-18 05:39:02,C# returning the correct object type,<c#><generics><object><return><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
21789,17563958,2013-07-10 06:37:27,,"<p>I have been exhausted from this error from last 2 weeks.I tried a lot to find out and tried the code in different way but not succeeded yet.I think the main problem is with bitmap, may be i am not using in right way.I am sharing my code for help to understand what i am doing.</p>

<p>First i tell you the scenario.In this app, i am using dslr camera for live view.The main code area from camera class is here below :</p>

<pre><code>internal void Run()
{
    LVrunning = true;
    while (LVrunning)
    {
        Thread.Sleep(20);
        if (LVrunning)
            UpdatePicture();
    }
}

private void UpdatePicture()
{
    try
    {
        if (err == EDSDK.EDS_ERR_OK &amp;&amp; LVrunning)
        {
            inSide = true;

            // Download live view image data
            err = EDSDK.EdsDownloadEvfImage(cameraDev, EvfImageRef);

            if (err != EDSDK.EDS_ERR_OK)
            {
                Debug.WriteLine(String.Format(""Download of Evf Image: {0:X}"", err));
                return;
            }
            IntPtr ipData;
            err = EDSDK.EdsGetPointer(MemStreamRef, out ipData);
            if (err != EDSDK.EDS_ERR_OK)
            {
                Debug.WriteLine(String.Format(""EdsGetPointer failed: {0:X}"", err));
                return;
            }

            uint len;
            err = EDSDK.EdsGetLength(MemStreamRef, out len);
            if (err != EDSDK.EDS_ERR_OK)
            {
                Debug.WriteLine(String.Format(""EdsGetLength failed:{0:X}"", err));
                EDSDK.EdsRelease(ipData);
                return;
            }

            Byte[] data = new byte[len];
            Marshal.Copy(ipData, data, 0, (int)len);
            System.IO.MemoryStream memStream = new System.IO.MemoryStream(data);

            // get the bitmap
            Bitmap bitmap = null;
            try
            {
                bitmap = new Bitmap(memStream);
            }
            catch (OutOfMemoryException ex)
            {
                GC.WaitForPendingFinalizers();
                bitmap = new Bitmap(memStream); // sometimes error occur
            }

            NewFrame(bitmap, null); // this is event call back to form area.

            memStream.Dispose();
            EDSDK.EdsRelease(ipData);
        }
    }
    catch (Exception ex)
    {

    }
}
private void getCapturedItem(IntPtr directoryItem)
{
    uint err = EDSDK.EDS_ERR_OK;
    IntPtr stream = IntPtr.Zero;

    EDSDK.EdsDirectoryItemInfo dirItemInfo;

    err = EDSDK.EdsGetDirectoryItemInfo(directoryItem, out dirItemInfo);

    if (err != EDSDK.EDS_ERR_OK)
    {
        throw new CameraException(""Unable to get captured item info!"", err);
    }

    //  Fill the stream with the resulting image
    if (err == EDSDK.EDS_ERR_OK)
    {
        err = EDSDK.EdsCreateMemoryStream((uint)dirItemInfo.Size, out stream);
    }

    //  Copy the stream to a byte[] and
    if (err == EDSDK.EDS_ERR_OK)
    {
        err = EDSDK.EdsDownload(directoryItem, (uint)dirItemInfo.Size, stream);
    }

    //  Create the returned item
    //CapturedItem item = new CapturedItem();
    if (dirItemInfo.szFileName.ToString().ToLower().Contains(""jpg"") || dirItemInfo.szFileName.ToString().ToLower().Contains(""jpeg""))
    {
        if (err == EDSDK.EDS_ERR_OK)
        {
            IntPtr imageRef = IntPtr.Zero;

            err = EDSDK.EdsCreateImageRef(stream, out imageRef);

            if (err == EDSDK.EDS_ERR_OK)
            {
                EDSDK.EdsImageInfo info;
                err = EDSDK.EdsGetImageInfo(imageRef, EDSDK.EdsImageSource.FullView, out info);
            }
        }
    }

    if (err == EDSDK.EDS_ERR_OK)
    {
        try
        {
            byte[] buffer = new byte[(int)dirItemInfo.Size];
            GCHandle gcHandle = GCHandle.Alloc(buffer, GCHandleType.Pinned);
            IntPtr address = gcHandle.AddrOfPinnedObject();
            IntPtr streamPtr = IntPtr.Zero;
            err = EDSDK.EdsGetPointer(stream, out streamPtr);
            if (err != EDSDK.EDS_ERR_OK)
            {
                throw new CameraDownloadException(""Unable to get resultant image."", err);
            }

            try
            {
                Marshal.Copy(streamPtr, buffer, 0, (int)dirItemInfo.Size);//sometimes error comes here
                System.IO.MemoryStream memStream = new System.IO.MemoryStream(buffer);

                    Bitmap bitmap = null;
                    try
                    {
                        bitmap = new Bitmap(memStream);
                    }
                    catch (OutOfMemoryException ex)
                    {
                        GC.WaitForPendingFinalizers();
                        Bitmap b = new Bitmap(memStream);//sometimes error comes here
                    }

                    if (bitmap != null)
                    {


                            PhotoCaptured(bitmap, null);

                    }

            }
            catch (AccessViolationException ave)
            {
                throw new CameraDownloadException(""Error copying unmanaged stream to managed byte[]."", ave);
            }
            finally
            {
                gcHandle.Free();
                EDSDK.EdsRelease(stream);
                EDSDK.EdsRelease(streamPtr);
            }
        }
        catch (OutOfMemoryException ex)
        {
            GC.WaitForPendingFinalizers();
            IboothmeObject.minimizeMemory();
            getCapturedItem(directoryItem);
        }
    }
    else
    {
        throw new CameraDownloadException(""Unable to get resultant image."", err);
    }
}
</code></pre>

<p>On form side, image is updating in picture box simply </p>

<pre><code>private void StartLiveView()
    {
        if (this.liveView.Connected)
        {
            this.liveView.PhotoCaptured += new EventHandler(liveView_PhotoCaptured);
            this.liveView.NewFrame += new EventHandler(liveView_NewFrame);
            this.liveView.StartLiveView();

        }
    }

    void liveView_NewFrame(object sender, EventArgs e)
    {
        this.picMain.Image = sender as Image;
    }
    void liveView_PhotoCaptured(object sender, EventArgs e)
    {
        Image img = sender as Image;
        // this image is big in size like 5000x3000.
        Bitmap tempbitmap = new Bitmap(img.Width, img.Height);// now mostly error comes here
        tempbitmap.SetResolution(img.HorizontalResolution, img.VerticalResolution);
            using (Graphics g = Graphics.FromImage(tempbitmap))
            {
                g.DrawImage(img, new Rectangle(0, 0, img.Width, img.Height));
                g.Save();
            }
        picMain.Image = tempbitmap;
        tempbitmap.Save(path,ImageFormat.Jpeg);
    }
</code></pre>

<p>Another area of code which uses the bitmap and live view from camera.This code get the frame from camera and write some objects on frame..In my case, i am writing some ballons on the frame </p>

<pre><code>void liveView_NewFrame(object sender, EventArgs e)
    {
        using (Image&lt;Bgr, byte&gt; Frame = new Image&lt;Bgr, byte&gt;(new Bitmap(sender as Image)))
        {
            Frame._SmoothGaussian(3);
            IntPtr hsvImage = CvInvoke.cvCreateImage(CvInvoke.cvGetSize(Frame), Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_8U, 3);
            CvInvoke.cvCvtColor(Frame, hsvImage, Emgu.CV.CvEnum.COLOR_CONVERSION.CV_BGR2HSV);

            Image&lt;Gray, byte&gt; imgThresh = new Image&lt;Gray, byte&gt;(Frame.Size);
            imgThresh.Ptr = GetThresholdedImage(hsvImage);
            //CvInvoke.cvSmooth(imgThresh, imgThresh, Emgu.CV.CvEnum.SMOOTH_TYPE.CV_GAUSSIAN, 3, 3, 3, 3);

            #region Draw the contours of difference
            //this is tasken from the ShapeDetection Example
            Rectangle largest = new Rectangle();
            try
            {
                using (MemStorage storage = new MemStorage()) //allocate storage for contour approximation
                    //detect the contours and loop through each of them
                    for (Contour&lt;Point&gt; contours = imgThresh.Convert&lt;Gray, Byte&gt;().FindContours(
                          Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
                          Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_EXTERNAL,
                          storage);
                       contours != null;
                       contours = contours.HNext)
                    {
                        //Create a contour for the current variable for us to work with
                        Contour&lt;Point&gt; currentContour = contours.ApproxPoly(contours.Perimeter * 0.05, storage);

                        //Draw the detected contour on the image
                        if (currentContour.Area &gt; ContourThresh) //only consider contours with area greater than 100 as default then take from form control
                        {
                            if (currentContour.BoundingRectangle.Width &gt; largest.Width &amp;&amp; currentContour.BoundingRectangle.Height &gt; largest.Height)
                            {
                                largest = currentContour.BoundingRectangle;
                            }
                        }
                        //storage.Dispose();
                    }

            }
            catch (Exception)
            {

            }

            #endregion

            #region Draw Object
            Random r = new Random();
            //Bitmap bb = Frame.Bitmap;
            foreach (var item in objectList)
            {
                using (Graphics g = Graphics.FromImage(Frame.Bitmap))
                {
                    if (DrawAble(item, largest))
                    {
                        if (item.Y &lt; 0)
                        {
                            if (item.X &lt; picMain.Width)
                            {
                                g.DrawImage(item.image, new Rectangle(item.X, 0, item.image.Width, item.image.Height + item.Y),
                                    new Rectangle(), GraphicsUnit.Pixel);
                                item.X += r.Next(-5, 5);
                                item.Y += 15;
                            }
                        }
                        else
                        {
                            if (item.X &lt; picMain.Width &amp;&amp; item.Y &lt; picMain.Height)
                            {
                                g.DrawImage(item.image, new Rectangle(item.X, item.Y, item.image.Width, item.image.Height));
                                item.X += r.Next(-5, 5);
                                item.Y += 15;
                            }
                            else
                            {
                                item.X = r.Next(0, picMain.Width - 5);
                                item.Y = r.Next(-item.image.Height, -5);
                            }

                        }
                    }
                    else
                    {
                        item.X = r.Next(0, picMain.Width - 5);
                        item.Y = r.Next(-item.image.Height, -5);
                    }

                }
            }

            #endregion

            picMain.Image = Frame.ToBitmap();

        }

        minimizeMemory();
    }
</code></pre>

<p>Now i share the whole problem in detail.
First on all i created a form for live view and by using opencv(Emgu) library , i am drawing balloons on the frame.In live view these balloons are moving.The other form is for capture the picture from camera with high resolution.
I noticed that, my application memory was increasing with every frame and after 2 live-view and 2 pictures caputured, it goes to 1+ GB.If i tried to show first form again for live view, error occured in UpdatePicture() function.
then i add the code to minimize the memory of the current application.now i am calling this function after every frame in live-view.
After this solution when i checked the memory of application it does not go over 100mb or 200mb.
But problem was still there.after few captures, error occurred in UpdatePicture() when get bitmap from stream ( bitmap = new Bitmap(memStream);).The error was same out of memory.
After some search i found this solution.</p>

<pre><code>// get the bitmap
        Bitmap bitmap = null;
        try
        {
            bitmap = new Bitmap(memStream);
        }
        catch (OutOfMemoryException ex)
        {
            GC.WaitForPendingFinalizers();
            bitmap = new Bitmap(memStream);
        }
</code></pre>

<p>But not working error is still same.</p>

<p>Error sometimes shown in UpdatePicture() method, sometime occurred in liveView_NewFrame method.
Means problem is related to bitmap, bitmap size or memory is corrupt.
So please help me.I am worried, 2 weeks passed but i could not solve this.</p>
",2013-07-10 07:28:47,2013-07-10 10:17:51,Out of Memory error during stream capture from camera,<c#><out-of-memory><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
21796,25139310,2014-08-05 12:51:48,,"<p>I use EmguCV (various versions) and after running example application (LicensePlateRecognition), I noticed that even though I force garbage collection and dispose the license plate detector object, the program still uses 450MB memory while idling (after processing image, seen in Windows Resource Manager). It happens with other examples too. I guess it's a native memory leak. .Net Memory Profiler shows that most data is allocated in Kernel->HeapMemory.</p>

<p>Why Emgu allocates so much memory and can I somehow free that memory? All OpenCV ddls are ~400MB. Is it just bad wrapping? I used OpenCV library from the right package.</p>

<p>The thing is when I tried running, for example, face detection on multiple cameras simultaneously, I get error ""failed to allocate XXX bytes"". Can Emgu handle more than one (at least low resolution) cameras? I quickly run out of memory.</p>
",,2014-08-05 12:51:48,"EmguCV, native memory leaks",<c#><opencv><memory-leaks><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
21809,18510610,2013-08-29 12:09:37,,"<p>I have implented a face detection webapp using EmguCV 2.2.1.
The total dll file size for the webapp to run is just ~12MB.</p>

<p>But when I try to update my program using EmguCV 2.4.2 (I need new FaceRecognizer class in this version), the total dll size is too big.</p>

<p>opencv_gpu242.dll ~ 200MB  (In the 2.2.1 it's just 500KB)</p>

<p>cublas32_42_9.dll ~ 100MB</p>

<p>My webapp is hosted on a server, the storage disk is just about ~300MB so I can't upload my new version. Can anyone tell me how to reduce the size of the dll or use something else? </p>
",,2013-08-29 12:54:14,EmguCV 2.4.2 dll file size are too big,<c#><opencv><emgucv><face-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
21831,24050813,2014-06-05 02:46:07,,"<p>I have an <code>MVC</code> application where one of my controllers receives an uploaded file (image) as an <code>HttpPostedFileBase</code> object.</p>

<p>I am trying to process the image using <code>EmguCV</code>, but I'm having difficulty converting my <code>HttpPostedFileBase</code> to the <code>EmguCV</code> matrix object <code>Emgu.CV.Mat</code> (which is just a <code>C#</code> implementation of a <code>cv::Mat</code> object).</p>

<p>There is a constructor for <code>Mat</code> that looks like:</p>

<pre><code>public Mat(int rows, int cols, DepthType type, int channels, IntPtr data, int step);
</code></pre>

<p>but I'm not sure how to get the <code>type</code>, <code>data</code>, and <code>step</code> from my starting <code>HttpPostedFileBase</code> object. Is this possible?</p>

<p>I see <a href=""https://stackoverflow.com/questions/1171696/how-do-you-convert-a-httppostedfilebase-to-an-image"">here</a>, that I can convert an <code>HttpPostedFileBase</code> to an <code>Image</code> object (I think that's in the <code>System.Drawing</code> namespace), which allows me to see the height and width. <strong>But how can I use this information to get the rest of the required parameters to send the the <code>Mat()</code> constructor?</strong></p>
",2017-05-23 12:07:56,2014-06-13 12:46:35,C# / EmguCV - Convert an uploaded HttpPostedFileBase to a Emgu.CV.Mat,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
21860,20606473,2013-12-16 08:37:15,,"<p>I am very new to Emgu cv and C#. I am trying to use cvDilate method with structure element = [1 1 1] and then the error occurred. </p>

<p>Here is the code:</p>

<pre><code>private void btnRotate_Click(object sender, EventArgs e)
        {
            int[,] tempStructure = {{1,1,1}};
            StructuringElementEx s = new StructuringElementEx(tempStructure,1,0);
            Image&lt;Gray, Byte&gt; tempBinarized = binarizedPicture.Copy();
            binarizedPicture.Dispose();
            Image&lt;Gray, Byte&gt; destPtr = new Image&lt;Gray, byte&gt;(tempBinarized.Size);
            IntPtr src = tempBinarized.Ptr;
            IntPtr dst = destPtr.Ptr;
            IntPtr ele;
            GCHandle handle = GCHandle.Alloc(tempStructure, GCHandleType.Pinned);
            try
            {
                ele = handle.AddrOfPinnedObject();
            }
            finally
            {
                if (handle.IsAllocated)
                {
                    handle.Free();
                }
            }

            Emgu.CV.CvInvoke.cvDilate(src, dst, ele, ITERATE);               
            Emgu.CV.CvInvoke.cvCopy(dst, destPtr, IntPtr.Zero);
            actionBox.Image = destPtr.ToBitmap();
</code></pre>

<p>and Here is the Error Message:</p>

<pre><code>System.AccessViolationException was unhandled
  HResult=-2147467261
  Message=Attempted to read or write protected memory. This is often an indication that     other memory is corrupt.
  Source=Emgu.CV
  StackTrace:
       at Emgu.CV.CvInvoke.cvDilate(IntPtr src, IntPtr dst, IntPtr element, Int32     iterations)
       at testMaster.Form1.btnRotate_Click(Object sender, EventArgs e) in d:\Wep    API\Project\TestMaster\testMaster\testMaster\Form1.cs:line 91
       at System.Windows.Forms.Button.OnMouseUp(MouseEventArgs mevent)
       at System.Windows.Forms.Control.WmMouseUp(Message&amp; m, MouseButtons button, Int32  clicks)
       at System.Windows.Forms.Control.WndProc(Message&amp; m)
       at System.Windows.Forms.ButtonBase.WndProc(Message&amp; m)
       at System.Windows.Forms.Button.WndProc(Message&amp; m)
       at System.Windows.Forms.NativeWindow.DebuggableCallback(IntPtr hWnd, Int32 msg,  IntPtr wparam, IntPtr lparam)
       at System.Windows.Forms.UnsafeNativeMethods.DispatchMessageW(MSG&amp; msg)
       at     System.Windows.Forms.Application.ComponentManager.System.Windows.Forms.UnsafeNativeMethods. IMsoComponentManager.FPushMessageLoop(IntPtr dwComponentID, Int32 reason, Int32 pvLoopData)
       at System.Windows.Forms.Application.ThreadContext.RunMessageLoopInner(Int32 reason, ApplicationContext context)
       at System.Windows.Forms.Application.ThreadContext.RunMessageLoop(Int32 reason, ApplicationContext context)
       at testMaster.Program.Main() in d:\Wep API\Project\TestMaster\testMaster\testMaster\Program.cs:line 19
       at System.AppDomain._nExecuteAssembly(RuntimeAssembly assembly, String[] args)
       at Microsoft.VisualStudio.HostingProcess.HostProc.RunUsersAssembly()
       at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
       at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
       at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)
       at System.Threading.ThreadHelper.ThreadStart()
InnerException: 
</code></pre>

<p>When I changed the structure element to some other value (ex: [1 0 1]), it works fine. So I don't know why this happens. Please help. Thank you.</p>
",,2013-12-17 09:06:58,Cannot use cvDilate with some structure element,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
21875,22895839,2014-04-06 15:12:50,,"<p>Please guys help me for resolving the issue in the following statement:</p>

<pre><code>MCvAvgComp[][] Detector = IMAGEgray.DetectHaarCascade(face, 2.1, 10, 
 Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(20, 20));""
</code></pre>

<p>After debugging the solution The compiler show me the following Error:</p>

<p>Object reference not set to an instance of an object.</p>
",2014-04-06 15:13:35,2018-02-26 21:31:52,Object reference not set to an instance of an object. using Emgu CV,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
21884,20607997,2013-12-16 10:01:28,,"<p>When I run my code, I am getting an error like:</p>

<p>D:\ubunto\OpenCV\opencv\build\include\opencv2\imgproc\imgproc.hpp:50: error: opencv2/core/core.hpp: No such file or directory</p>

<p>I don't know the reason if this is because of the opencv linkage or something else.</p>

<p>You can find my code below.</p>

<p><em><strong>Form1.h</em></strong></p>

<pre><code>#ifndef FORM1_H
#define FORM1_H

#include &lt;QDialog&gt;

//#include&lt;highgui.h&gt;
//#include&lt;core/core.hpp&gt;
//#include&lt;cvwimage.h&gt;
#include&lt;opencv.hpp&gt;
#include&lt;imgproc/imgproc.hpp&gt;
//#include &lt;opencv_modules.hpp&gt;
//#include &lt;video/video.hpp&gt;
#include &lt;highgui/highgui.hpp&gt;



namespace Ui {
class Form1;
}

class Form1 : public QDialog
{
    Q_OBJECT

public:
    explicit Form1(QWidget *parent = 0);
    QImage getQImageFromFrame(cv::Mat frame);
    ~Form1();

private slots:
    void on_pushButton_clicked();
    void updatePicture();
private:
    Ui::Form1 *ui;
    cv::Mat *mt;
    cv::VideoCapture  *video;
    QTimer * timer;
    QImage *img;

};

#endif // FORM1_H
</code></pre>

<p><em><strong>Form1.cpp</em></strong></p>

<pre><code>#include ""form1.h""
#include ""ui_form1.h""
#include &lt;QtCore&gt;
#include &lt;QtGui&gt;
#include &lt;QGraphicsAnchorLayout&gt;
#include &lt;QGraphicsScene&gt;
#include &lt;QGraphicsView&gt;
#include &lt;QGraphicsWidget&gt;
#include ""qimage.h""
#include &lt;QFileDialog&gt;
#include &lt;QPixmap&gt;
#include ""qpixmap.h""

Form1::Form1(QWidget *parent) :
    QDialog(parent),
    ui(new Ui::Form1)
{
    ui-&gt;setupUi(this);

}

QImage Form1::getQImageFromFrame(cv::Mat frame) {
    //converts the color model of the image from RGB to BGR because OpenCV uses BGR
    cv::cvtColor(frame, frame, CV_RGB2BGR);
    return QImage((uchar*) (frame.data), frame.cols, frame.rows, frame.step, QImage::Format_RGB888);
}

Form1::~Form1()
{
    delete ui;
}

void Form1::updatePicture()
{
    video &gt;&gt; mt;
    img = getQImageFromFrame(mt);
    ui-&gt;label-&gt;setPixmap(QPixmap::fromImage(image));

}

void Form1::on_pushButton_clicked()
{
    fileName = QFileDialog::getOpenFileName(this,
        tr(""Open Image""), ""/elhandasya/Desktop"", tr(""Image Files (*.png *.jpg *.bmp)""));
    //QPixmap pix(fileName);
    video-&gt;open(filename);


    timer = new QTimer(this);
    connect(timer, SIGNAL(timeout()), this, SLOT(updatePicture());
    timer-&gt;start(20);

}
</code></pre>

<p>and this when i call my libraries and files </p>

<pre><code>#-------------------------------------------------
#
# Project created by QtCreator 2013-12-16T09:23:28
#
#-------------------------------------------------

QT       += core gui

greaterThan(QT_MAJOR_VERSION, 4): QT += widgets

TARGET = Video_Player
TEMPLATE = app


SOURCES += main.cpp\
        form1.cpp

HEADERS  += form1.h

FORMS    += form1.ui

INCLUDEPATH += -I""D:\ubunto\OpenCV\opencv\build\include\opencv2\imgproc""
INCLUDEPATH += -I""D:\ubunto\OpenCV\opencv\build\include\opencv2\core""
INCLUDEPATH += -I""D:\ubunto\OpenCV\opencv\build\include\opencv2""


LIBS += -LD:\ubunto\OpenCV\opencv\build\x86\mingw\bin
 -lopencv_core
 -lopencv_imgproc
 -lopencv_highgui
 -lopencv_legacy
 -lopencv_gpu
 -lopencv_video
 -lopencv_ml
 -lopencv_contrib

#LIBS += D:\ubunto\emgu\emgucv-windows-x86 2.4.0.1717\lib


#-opencv_calib3d240
#-opencv_videostab240
#-opencv_calib3d240
#-opencv_contrib240
#-opencv_core240
#-opencv_features2d240
#-opencv_flann240
#-opencv_gpu240
#-opencv_highgui240
#-opencv_imgproc240
#-opencv_legacy240
#-opencv_ml240
#-opencv_nonfree240
#-opencv_objdetect240
#-opencv_photo240
#-opencv_stitching240
#-opencv_video240
</code></pre>
",2013-12-17 07:37:46,2013-12-17 07:37:46,Error when linking OpenCV with Qt,<c++><qt><opencv>,,,CC BY-SA 3.0,True,True,True,False,False
21942,19459907,2013-10-18 22:17:19,,"<p>I'm trying to develop an automatic uniform fitting application using the library emgucv, where the user would be asked to stand in front of the camera to have their whole body pictured,  and from the picture the system will give their standard size (S, M, L, XL, ... , etc). So what I did was use haarcascade to detect the upper body of the user.</p>

<p>my problem is it does not detect precisely how can I improve the system's detecting performance?
(Sorry for my poor English)</p>

<p>here is my code:</p>

<pre><code>    void viewImage(object sender, EventArgs e)
    {
        img = camera.QueryFrame();
        if (img == null)
            return;
        CamImageBox.Image = img;
    }

    private void btnCapture_Click(object sender, EventArgs e)
    {
        if (captureProcess == true)
        {
            string data;

            Application.Idle -= viewImage;
            captureProcess = false;
            SaveFileDialog dlg = new SaveFileDialog();
            //dlg=""Image|*.jpg;*png"";
            if (dlg.ShowDialog() == DialogResult.OK)
            {
                img.ToBitmap().Save(dlg.FileName + "".jpg"");
                data = dlg.FileName + "".jpg"";
            }
            measureImage();
        }
    }

    void measureImage()
    {
        OpenFileDialog dlg2 = new OpenFileDialog();
        dlg2.Filter = ""Image|*.jpg;*png"";
        if (dlg2.ShowDialog() == DialogResult.OK)
        {
            Image&lt;Bgr, Byte&gt; frame = new Image&lt;Bgr, byte&gt;(dlg2.FileName);
            Image&lt;Gray, Byte&gt; Gray_Frame = frame.Convert&lt;Gray, Byte&gt;();

            MCvAvgComp[][] LowerBodyDetect = Gray_Frame.DetectHaarCascade(
                LowerBody,
                1.0,
                10,
                Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                new Size());

            MCvAvgComp[][] UpperBodyDetect = Gray_Frame.DetectHaarCascade(
                UpperBody,
                2.1,
                5,
                Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                new Size());


            foreach (MCvAvgComp Upp_Body in UpperBodyDetect[0])
            {
                frame.Draw(Upp_Body.rect, new Bgr(Color.Red), 2);
                double width=(Upp_Body.rect.Width*0.264583333);
                textBox1.Text = (Convert.ToString(width));
            }

            foreach (MCvAvgComp Low_Body in LowerBodyDetect[0])
            {
                frame.Draw(Low_Body.rect, new Bgr(Color.Green), 2);
            }
            CamImageBox.Image = frame;
        }

    }

    private void Form1_Load(object sender, EventArgs e)
    {
        try
        {
            camera = new Capture();
        }
        catch (Exception exc)
        {
            MessageBox.Show(exc.Message);
            return;
        }
        Application.Idle += viewImage;
        captureProcess = true;
    }
}
</code></pre>
",,2013-10-18 22:17:19,Measuring width of a person with camera,<c#><winforms><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
21967,22905702,2014-04-07 07:08:55,,"<p>I am doing my project regarding image processing in c#. Here I don't know, how to find face, eyes from image (not webcam). The image will be stored in a specific folder. I am installing EmguCv package, but it not at all work. What are my questions means, </p>

<p>Is Emgu CV works Window 8 OS?</p>

<p>I am searching via net, all the contents are related to find face through webcam. But I want to find a face from photo/image. Please tell the solution.</p>

<p>Which is compatible image processing library for windows 8 and Visual Studio 2010? </p>

<p>Is there any source code satisfies my certain condition. Please post here.</p>

<p>Thank you.</p>
",2014-04-07 07:19:42,2014-04-07 07:37:00,"How to find face, eyes from photo/image?",<c#><asp.net><vb.net><opencv><image-processing>,,,CC BY-SA 3.0,True,False,True,False,False
21990,19465263,2013-10-19 10:55:10,,"<p>This is my code to take an ArrayList of 8*8 blocks of an image (Bmp) and it's not working. What is the flaw of the logic here? 'rows' is the number of rows of the image. I am doing my video steganography project.</p>

<pre><code>        int x = 0;
        int colCount = 0;

        int yStart = 0;
        int yLimit = 8;

        for (x = 0;x &lt; rows; x++)
        {
            while (yStart&lt;yLimit)
            {
                imageBlock[x % 8, yStart % 8] = image_array[0].Data[x, yStart, 1];

                if (x % 8 == 7 &amp;&amp; yStart % 8 == 7)
                {
                    blockList.Add(ForwardDCT(imageBlock));
                }

                yStart++;
            }

            if (x == rows - 1)
            { 
                x = 0;
                yLimit = yLimit + 8;
                //yStart = yStart + 8;
                colCount++;

                if (colCount == 100)
                {
                    break;
                }
            }

            if (yStart % 8 == 7)
            {
                yStart = yLimit - 8;
            }
        }
</code></pre>
",2013-10-19 11:10:33,2013-10-19 11:10:33,Get 8*8 blocks of an image to an arrayList,<c#><image><jpeg><emgucv><bmp>,2014-03-01 13:05:16,,CC BY-SA 3.0,False,False,True,False,False
22027,22911757,2014-04-07 11:57:26,,"<p>I need a solution to compare two scanned images.
I have an image of an application form (unfilled), I need to compare that against other images of the same form, and want to detect whether there is any totally unfilled application form.</p>

<p>I just tried with Emgu CV AbsDiff, MatchTemplate etc, but none of them give me a 100 % match, even if I scanned the same form twice in the same scanner, could be because of the noise in the scanning, I can apply a tolerance but the problem is that I need to find out whether the user has filled anything in it. If I apply a tolerance then small changes in the form will not be detected.</p>

<p>I also had a look at the Python Image Libray, Accord.Net etc but couldn't find an approach for comparing this type of image.</p>

<p>Any suggestions on how to do this type of image comparison ?
Is there any free or paid library available for this ?</p>
",,2014-04-07 14:35:11,Compare Scanned Images and detect very small visible changes,<opencv><image-processing><python-imaging-library><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
22128,19474950,2013-10-20 07:28:32,,"<p>I am comparing jpeg to jpeg in a constant 'video-stream'. i am using EMGU/OpenCV to compare each pixels at the byte level.  There are 3 channels to each image (RGB).  I had heard that it is common practice to store only the pixels that have changed between frames as a way of conserving memory space. But, if for instance/example I say EVERY pixel has changed (pls note i am using an exaggerated example to make my point and i would normally discard such large changes) then the resultant bytes saved is 3 times larger than the original jpeg.  </p>

<p>How can I store such motion changes efficiently?</p>

<p>thanks</p>
",,2013-10-20 08:54:46,Best way to store motion changes to reduce memory,<emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
22131,19476702,2013-10-20 11:14:11,,"<p>whenever I am trying to save the webcamera capture image  automatically then then runtime error is coming in path.automaticaly name like 0.jpg,02.jpg,03.jpg like this way image will save in the particular mention folder.but giving run time error.
plz check this.</p>

<pre><code>namespace camera1
{
    public partial class Form1 : Form
    {
        private Capture capture;
        private bool captureinprogress;

        public Form1()
        {
            InitializeComponent();
        }
        private void ProcessFrame(object sender, EventArgs arg)
        {
           Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
           cameraimage.Image = ImageFrame;
           string root = ""C:\\photo\0""; // automatically saving image to c drive like       001.jpg,002.jpg;
           for (int i = 0; i &lt; 100; i++)
           {
               if (File.Exists("" ""))
               { }
               else
               {
                   string Path = root + i + "".jpg"";
                   ImageFrame.Save(Path);
               }

               {
                   if (ImageFrame != null)
                   {
                       pictureBox1.Image = ImageFrame.ToBitmap();
                   }
                   if (pictureBox1 != null)
                   {
                       pictureBox2.Image = ImageFrame.ToBitmap();
                   }
                   if (pictureBox2 != null)
                   {
                       pictureBox3.Image = ImageFrame.ToBitmap();
                   }
             }
         }
     }
     private void btnStart_Click(object sender, EventArgs e)
     {
        if (capture == null)
        {
            try
            {
                capture = new Capture();
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(excpt.Message);
            }
        }
        if (capture != null)
        {
            if (captureinprogress)
            {  //if camera is getting frames then stop the capture and set button Text
                // ""Start"" for resuming capture
                btnstart.Text = ""Start!""; //
                Application.Idle -= ProcessFrame;
            }
            else
            {
                //if camera is NOT getting frames then start the capture and set button
                // Text to ""Stop"" for pausing capture
                btnstart.Text = ""Stop"";
                Application.Idle += ProcessFrame;
            }

            captureinprogress = !captureinprogress;        
        }
    }

    private void ReleaseData()
    {
        if (capture != null)
            capture.Dispose();
    }

}

}
</code></pre>
",2013-10-20 11:39:21,2013-10-21 00:28:59,image save path giving runtime error,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
22134,20629919,2013-12-17 09:05:26,,"<p>I have about 15 errors, when I want to get a video capture to view it frame by frame in an image.</p>

<p>First I call my video from my link.</p>

<p>Then get from it my frame.</p>

<p>Then convert it into image.</p>

<p>Finally view it in pixmap.</p>

<p><em><strong>MY CODE</em></strong></p>

<pre><code>#include ""form1.h""
#include ""ui_form1.h""
#include &lt;QtCore&gt;
#include &lt;QtGui&gt;
#include &lt;QGraphicsAnchorLayout&gt;
#include &lt;QGraphicsScene&gt;
#include &lt;QGraphicsView&gt;
#include &lt;QGraphicsWidget&gt;
#include ""qimage.h""
#include &lt;QFileDialog&gt;
#include &lt;QPixmap&gt;
#include ""qpixmap.h""

Form1::Form1(QWidget *parent) :
    QDialog(parent),
    ui(new Ui::Form1)
{
    ui-&gt;setupUi(this);
    video-&gt;open(""D:/Downloads/DirectX/Zlatan Ibrahimovic ● Taekwondo Goals.mp4"");
    timer = new QTimer(this);
    connect(timer, SIGNAL(timeout()), this, SLOT(updatePicture()));
    timer-&gt;start(20);
}

QString fileName;

QImage Form1::getQImageFromFrame(cv::Mat frame) {
    //converts the color model of the image from RGB to BGR because OpenCV uses BGR
    cv::cvtColor(frame, frame, CV_RGB2BGR);
    return QImage((uchar*) (frame.data), frame.cols, frame.rows, frame.step, QImage::Format_RGB888);
}

Form1::~Form1()
{
    delete ui;
}

void Form1::updatePicture()
{
    cv::Mat frame1;
    video-&gt;operator &gt;&gt;( frame1);
    img = getQImageFromFrame(frame1);
    ui-&gt;label-&gt;setPixmap(QPixmap::fromImage(img));

}

void Form1::on_pushButton_clicked()
{
    //fileName = QFileDialog::getOpenFileName(this,
        //tr(""Open Image""), ""/elhandasya/Desktop"", tr(""Image Files (*.png *.jpg *.bmp)""));
    //QPixmap pix(fileName);

}
</code></pre>

<p>'</p>

<p>The errors like this:</p>

<pre><code>undefined reference to `cv::Mat::Mat()
D:\ubunto\QT5\Tools\QtCreator\bin\Video_Player-build-Desktop_Qt_5_0_1_MinGW_32bit-Debug\debug\form1.o:-1: In function `ZN5Form1D2Ev'
</code></pre>

<p><em><strong>My LIBS</em></strong></p>

<pre><code>#-------------------------------------------------
#
# Project created by QtCreator 2013-12-16T09:23:28
#
#-------------------------------------------------

QT       += core gui

greaterThan(QT_MAJOR_VERSION, 4): QT += widgets

TARGET = Video_Player
TEMPLATE = app


SOURCES += main.cpp\
        form1.cpp

HEADERS  += form1.h

FORMS    += form1.ui

INCLUDEPATH += -I""D:/ubunto/OpenCV/opencv/build/include/opencv2/imgproc""
INCLUDEPATH += -I""D:/ubunto/OpenCV/opencv/build/include/""
#INCLUDEPATH += ""D:/ubunto/OpenCV/opencv/build/include/""


LIBS += -LD:/ubunto/OpenCV/opencv/build/x86/mingw/bin
 -lopencv_core
 -lopencv_imgproc
 -lopencv_highgui
 -lopencv_legacy
 -lopencv_gpu
 -lopencv_video
 -lopencv_ml
 -lopencv_contrib


#LIBS += D:\ubunto\emgu\emgucv-windows-x86 2.4.0.1717\lib


#-opencv_calib3d240
#-opencv_videostab240
#-opencv_calib3d240
#-opencv_contrib240
#-opencv_core240
#-opencv_features2d240
#-opencv_flann240
#-opencv_gpu240
#-opencv_highgui240
#-opencv_imgproc240
#-opencv_legacy240
#-opencv_ml240
#-opencv_nonfree240
#-opencv_objdetect240
#-opencv_photo240
#-opencv_stitching240
#-opencv_video240
</code></pre>
",2013-12-17 10:47:52,2013-12-17 10:47:52,Error while opening a video with OpenCV and Qt,<c++><qt><opencv><qt-creator><qt5>,,,CC BY-SA 3.0,True,True,True,False,False
22193,24079923,2014-06-06 10:44:03,,"<p>The idea is to identify the darkest rows of grayscale image. I have two options:</p>

<p><strong>Option 1: manual calculation</strong></p>

<p>I can calculate row-wise intensiveness of pixels manually, but I can't properly construct DenseHistogram object. Size of bins is equal to number of rows, the ranges are between 0 and 255, but I don't understand how to set those manually calculated values to the histogram?</p>

<p><strong>Option 2: DenseHistogram.Calculate</strong></p>

<p>My DenseHistogram object is calculating occurences of each intensity in whole image. How to instruct DenseHistogram to calculate intensity row-wise?</p>

<p>Please, see the picture attached. I want to have similar histogram in the end.</p>

<p><img src=""https://i.stack.imgur.com/q2aK8.png"" alt=""enter image description here""></p>
",,2014-06-06 12:26:22,Row-wise intensiveness histogram,<opencv><image-processing><histogram><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
22240,25171967,2014-08-06 23:32:21,,"<p>I'm looking for a simple way to get data of an IP Camera RTSP Stream (using H264 Audio/Video) and get on the other side</p>

<ul>
<li>a frame by frame byte[]</li>
<li>a stream of the audio</li>
</ul>

<p>After many research</p>

<ul>
<li>EmguCV Capture seems hanging forever (no answer from forum)</li>
<li>There is many (too big) <a href=""https://net7mma.codeplex.com/"" rel=""nofollow"">RTSP Server</a> few decode H264</li>
<li>There is ""slow"" ffmpeg wrapper</li>
<li>There is some managed DirectShow wrapper</li>
</ul>

<p>So I don't know where to go ? And how to do this ?</p>

<p>It seems iSpyCamera is doing the job but it's a big project not a little library to query ip cameras.</p>
",2014-08-06 23:35:22,2020-06-28 17:02:47,RTSP Client for H264 Audio/Video Stream,<c#><camera><ffmpeg><emgucv>,,,CC BY-SA 3.0,False,False,True,False,True
22274,19487068,2013-10-21 05:49:00,,"<p>I have tried face detection using emgu in c#. What i am trying to do is detect face from image and crop it and save as a seperate image.</p>

<p>Right now after detecting the face i expand the rectangle to certain size so that it covers the full passport size photo. But this solution will not work for images of different sizes.</p>

<p>Please guide me how to detect passport size photo from image. I know of two image processing libraries emgu (open CV) and Aforge.net </p>
",,2013-10-21 05:49:00,Detect passport size photo from image using emgu or Aforge.net in c#,<image-processing><emgucv><aforge>,,,CC BY-SA 3.0,False,False,True,False,False
22403,25188050,2014-08-07 16:52:34,,"<p>There is an image which only has vertical lines and horizontal lines. But there are some lines that are the same or they are close to each other, but they should be combined to only one line. Also I wrote loop to add line in a new list, the speed is slow. So I wonder if there are some efficient way for me to combine these adjacent lines to one line. </p>

<p>The following is the code:</p>

<pre><code>for (int i = 0; i &lt; RecoverLine_list.Count; i++) {
        for (int j = 0; j &lt; RecoverLine_list.Count; j++) {
            for (int m = 0; m &lt; RecoverLine_list.Count; m++) {

                if (RecoverLine_list[i] != RecoverLine_list[j] 
                 &amp;&amp; RecoverLine_list[i] != RecoverLine_list[m] 
                 &amp;&amp; RecoverLine_list[j] != RecoverLine_list[m]) {

                    if (RecoverLine_list[i].orientation == 0 
                     &amp;&amp; RecoverLine_list[j].orientation == 0 
                     &amp;&amp; RecoverLine_list[m].orientation == 0) {

                        if (Math.Abs(RecoverLine_list[i].P1.Y - RecoverLine_list[j].P1.Y) &lt; 3 
                         &amp;&amp; Math.Abs(RecoverLine_list[i].P1.Y - RecoverLine_list[m].P1.Y) &lt; 3 
                         &amp;&amp; Math.Abs(RecoverLine_list[j].P1.Y - RecoverLine_list[m].P1.Y) &lt; 3) {
                            // define RecoverLine_list[i] as grid line
                            GridLine_list.Add(RecoverLine_list[i]);
                        }
                    }
                }
            }
        }
    }
</code></pre>
",2014-08-07 17:10:37,2014-08-07 18:08:50,combine adjacent parallel lines,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
22469,17617463,2013-07-12 14:36:43,,"<p>I need to draw the most perfect circle possible. EmguCV seems to lack an anti-aliasing option.</p>

<p>I'm trying to use SmoothGaussian, but the circle still does not look good/smooth enough.</p>

<p>Also, the circle line intensity should have Gaussian shape (i.e.: brighter in the center).</p>

<p>How can I achieve that?</p>

<p>Here is what I'm doing now:</p>

<pre><code>using (Image&lt;Gray, Byte&gt; img = new Image&lt;Gray, byte&gt;(800, 800, new Gray(0)))
{
    PointF center = new PointF(img.Width / 2, img.Height / 2);
    //Center line
    float r = 200.0f;
    CircleF circle = new CircleF(center, r);
    img.Draw(circle, new Gray(255), 1);
    img._SmoothGaussian(7, 7, 3, 3);
}
</code></pre>
",,2014-06-20 19:07:11,How can I draw a circle with antialiasing and gaussian line intensity using EmguCV (OpenCV)?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
22532,24108785,2014-06-08 17:25:52,,"<p>I'm processing depth image from Kinect sensor using OpenCV with Emgu wrapper for motion detection using background substraction technic. On frames from Kinect I've noticed places with white spots, which I would like to filter off, make them in color of background. Which OpenCV technic/function should be used for this purpose? </p>

<p>White places are presented on pic:
<img src=""https://i.stack.imgur.com/CmEbm.png"" alt=""enter image description here""></p>
",,2014-06-20 12:17:38,Remove white spots from depth image with OpenCV,<opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
22561,26628118,2014-10-29 10:35:31,,"<p>I was trying to create a large Matrix contain rows images of tablets to use PCA function in Emgucv.
I was success in reshaping the tablet image (let say MxN) to a matrix ( 1 row,MxN column).Now I want to copy it to row i of the large Matrix ( k row, MxN column).Here is my code:</p>

<pre><code>        Matrix&lt;byte&gt; largeMatrix= new  Matrix&lt;byte&gt; (k,M*N);
        Matrix&lt;byte&gt; temp = new Matrix&lt;byte&gt;(M,N);    //tablet image
        Matrix&lt;byte&gt; temp1 = new Matrix&lt;byte&gt;(1,M*N); //tablet image after reshaping into 1 row

        CvInvoke.cvConvert(src.Copy(),temp);
        CvInvoke.cvReshape(temp, temp1, 0, 1);
        //Written in C# using Emgucv
</code></pre>

<p>How to copy temp1 into exactly row i of matrix largeMatrix in Emgucv ( or Opencv ).</p>
",,2014-10-29 11:46:56,copy multiple 1D matrix into one large 1D matrix in Emgucv or Opencv,<opencv><matrix><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
22597,26634157,2014-10-29 15:19:14,,"<p>I use Emgu in a WinForm and works fine, now I try to make a mvc.net project using emguCV but don't work, I have the error:</p>

<p>The type initializer for 'Emgu.CV.CvInvoke' threw an exception.</p>

<p>I try to use the solutions of THE OFFICIAL WEBSITE <a href=""http://www.emgu.com/wiki/index.php/Download_And_Installation#The_type_initializer_for_.27Emgu.CV.CvInvoke.27_threw_an_exception."" rel=""nofollow"">emguCV</a> and I can't understand how make that for web, and implement the OpenCV librairies in IIS Express .</p>

<p>what is the correct way to use EmguCV in a web site?</p>
",2014-11-22 17:16:22,2014-11-22 17:19:00,How use EmguCV in a MVC.NET project,<asp.net-mvc><iis><iis-express><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
22621,20670538,2013-12-18 23:20:33,,"<p>I have a matrix,called coordinatePointPrev which is 1X3 and there is another matrix called coordinatePointCurrFrame which is 3X1. anf finally a matrix called fund which is 3X3; all are defined as Matrix. </p>

<p>Now I want to multiply <strong>coordinatePointPrev * fund * coordinatePointCurr</strong> and save the results in 'resultOfEq' but for the 6th line, I encountered error saying ""<strong>Cannot implicitly convert type 'Emgu.CV.Matrix' to 'double</strong>""; </p>

<p>Where I am going wrong</p>

<pre><code>   Matrix&lt;double&gt; resultOfEq = new Matrix&lt;double&gt;(1, n);    
        for (int i = 0; i &lt; n; i++)
                {
 Matrix&lt;double&gt; coordinatePointPrev = new Matrix&lt;double&gt;(new double[,] { { a,b, 1 } });
 Matrix&lt;double&gt; coordinatePointCurr = new Matrix&lt;double&gt;(new double[,] { {c, d, 1 } });
 resultOfEq[0, i] = coordinatePointPrev.Mul(fund).Mul(coordinatePointCurr);
                }
</code></pre>
",2013-12-19 00:29:16,2013-12-19 00:32:29,Cannot implicitly convert type 'Emgu.CV.Matrix<double>' to 'double,<c#><opencv><emgucv><opencvsharp>,,,CC BY-SA 3.0,True,False,True,False,False
22625,21844122,2014-02-18 04:04:47,,"<p>I am working on one application where I want to use <code>IP camera</code> for displaying video streaming and and some other major operations on image captured by the <code>IP Camera</code>.</p>

<p><strong>Libraries used in Camera capture</strong>
For Camera Capture : <a href=""http://www.emgu.com/wiki/index.php?title=Camera_Capture"" rel=""nofollow noreferrer"">Emgu.CV</a> Library</p>

<p>Below is the code which I am using in C#.</p>

<p><em>Variable Declaration</em></p>

<pre><code>    private Capture capture;        //takes images from camera as image frames
    private Emgu.CV.UI.ImageBox img; // Dynamic Picture Controls
    private int nCam;               // no of cameras   
</code></pre>

<p><em>Code for Processing Image</em></p>

<pre><code>  private void ProcessFrame(object sender, EventArgs arg)
  {
    try
          {                
      // Live Streaming Display
     Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();

    // If Ip camera try to reinitialize the IP camera
    if(ImageFrame == null)
   {
       capture.Dispose();
       capture = new Capture(URL);                              
        ImageFrame = capture.QueryFrame();
     }                
      ImageFrame = ImageFrame.Resize(img.Width, img.Height, Emgu.CV.CvEnum.INTER.CV_INTER_LINEAR); 

     img.Image = ImageFrame;

    // Here I am doing some other operations like 
    // 1. Save Image captured from the IP Camera
    // 2. Detect faces in Image 
    // 3. Draw Face markers on Image
    // 4. Some database based on result of Face Detection
    // 4. Delete image File 
    // continue Looping for other Ip Cameras        

     }
      catch (NullReferenceException e)
       {
       }
    }
</code></pre>

<p>Now, The Problem is after some time the <code>QueryFrame()</code> provide <code>null</code> value and camera Stop streaming.</p>

<p>Can any one tell me why this is happening?
How I can resolve this problem?
If any more information is needed Please Let me know.</p>

<p>It is a duplicate Question of <a href=""https://stackoverflow.com/q/21745309/3110262"">IP Camera stop streaming after some time</a>.</p>

<p>But, I was unable to get answer by this question.
Thanks in Advance.</p>
",2017-05-23 11:57:47,2014-02-18 06:17:26,Emgucv return null Image for QueryFrame for IP Camera,<c#><opencv><camera><emgucv>,2014-02-19 09:59:02,,CC BY-SA 3.0,True,False,True,False,False
22628,25206279,2014-08-08 14:52:37,,"<p>I have some Kinects placed in a big room.
I don't know their positions, but i placed a marker in a known positions.
I want to discover the positions of the kinects in world coordinates. </p>

<p>Example: Kinect1 sees marker1, and obviously can get the marker position in its own world coordinates, lets say (4, 5, 1)
Kinect2 sees marker1 at coordinates (9, 9, 8).</p>

<p>The marker's coordinates in the world are (3, 3, 0) where the last one is the height because the marker is on the floor.</p>

<p>I need to know how to get the kinects positions in the same world reference system of the marker. i've being trying this for a lot of time but i can't find a solution.</p>

<p>I'm using C# and EMGU wrapper for OpenCV</p>
",,2014-08-08 14:52:37,Getting the world coordinates of multiple kinects,<c#><coordinates><kinect><emgucv><markers>,,,CC BY-SA 3.0,True,False,True,False,False
22641,22961398,2014-04-09 11:41:18,,"<p>I'm using Emgu CV to create video player. it's working fine with small size video (&lt;500Kb) ,but when i try to play big size video (>20Mb), it shows this error</p>

<pre><code>An unhandled exception of type 'System.NullReferenceException' occurred in Emgu.CV.dll
Additional information: Unable to create capture from E:\Tugas Akhir\wiman\3a.avi
</code></pre>

<p>i have emgu cv reference in my project, also have opencv_ffmpeg290_64.dll and other opencv dll in my project.
this is line of code cause this error,</p>

<pre><code>string videodir=""E:\Tugas Akhir\wiman\3a.avi"";
capture = new Capture(@videodir);
</code></pre>

<p>How can i solve this?</p>
",,2016-12-31 13:38:26,Big Size Video EmguCV,<c#><nullreferenceexception><video-capture><emgucv>,,,CC BY-SA 3.0,True,False,True,False,True
22728,26646278,2014-10-30 06:17:28,,"<p>I am trying to OCR and extract the email form the images. The images are supposed to have one line of text which is the email address.</p>

<p>I am using EmguCV.OCR to extract the text (email address) from those images. The target is to have 100% accurate result. </p>

<p>We can fix the font and size of the text. For example Ariel, 12pt, so that all the images will have email written in Ariel 12pt with black on white background.</p>

<p>The problem is that Tesseract OCR in EmguCV is not recognizing the text properly. It recognizes only 80% of the characters accurately.</p>

<p>I am using preprocessing with Leptonica library.</p>

<p>Here are some sample images I am trying to recognize.<img src=""https://i.stack.imgur.com/CAZUh.png"" alt=""enter image description here""><img src=""https://i.stack.imgur.com/dbG2L.png"" alt=""enter image description here""><img src=""https://i.stack.imgur.com/9tLM7.png"" alt=""enter image description here""><img src=""https://i.stack.imgur.com/G6d1T.png"" alt=""enter image description here""><img src=""https://i.stack.imgur.com/c6udd.png"" alt=""enter image description here""></p>

<p>Is there any way to achieve the target of 100% accuracy</p>
",2014-10-30 12:30:16,2014-10-31 15:20:00,How to OCR email address,<c#><image-processing><ocr><tesseract><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
22955,19540660,2013-10-23 11:41:09,,"<p>As you can see in <a href=""http://snag.gy/wVqG4.jpg"" rel=""nofollow"">http://snag.gy/wVqG4.jpg</a> Inrange(0,0,0,255,255,255) does not return a completely white image and so it does not properly check if all colors are in range. What is wrong? <br><br> Full source: <a href=""https://mega.co.nz/#!s4BXzKja!SpLk2z9NI8V-fIZTK8oyT15lh-ZRj6HhJ1f61wxc358"" rel=""nofollow"">https://mega.co.nz/#!s4BXzKja!SpLk2z9NI8V-fIZTK8oyT15lh-ZRj6HhJ1f61wxc358</a></p>
",2013-10-25 10:23:06,2013-10-26 22:20:50,"Why does InRange(TColor lower, TColor higher) return the wrong ""value""?",<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
23060,25549908,2014-08-28 13:23:17,,"<pre><code>//----------------------------------------------------------------------------
//  Copyright (C) 2004-2013 by EMGU. All rights reserved.       
//----------------------------------------------------------------------------

using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Text;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.CV.VideoSurveillance;
using Emgu.Util;

namespace MotionDetection
{
   public partial class Form1 : Form
   {
      private Capture _capture;
      private MotionHistory _motionHistory;
      private IBGFGDetector&lt;Bgr&gt; _forgroundDetector;

      public Form1()
      {
         InitializeComponent();

         //try to create the capture
         if (_capture == null)
         {
            try
            {
               _capture = new Capture();
            }
            catch (NullReferenceException excpt)
            {   //show errors if there is any
               MessageBox.Show(excpt.Message);
            }
         }

         if (_capture != null) //if camera capture has been successfully created
         {
            _motionHistory = new MotionHistory(
                1.0, //in second, the duration of motion history you wants to keep
                0.05, //in second, maxDelta for cvCalcMotionGradient
                0.5); //in second, minDelta for cvCalcMotionGradient

            _capture.ImageGrabbed += ProcessFrame;
            _capture.Start();
         }
      }

      private void ProcessFrame(object sender, EventArgs e)
      {
         using (Image&lt;Bgr, Byte&gt; image = _capture.RetrieveBgrFrame())
         using (MemStorage storage = new MemStorage()) //create storage for motion components
         {
            if (_forgroundDetector == null)
            {
               //_forgroundDetector = new BGCodeBookModel&lt;Bgr&gt;();
               _forgroundDetector = new FGDetector&lt;Bgr&gt;(Emgu.CV.CvEnum.FORGROUND_DETECTOR_TYPE.FGD);
               //_forgroundDetector = new BGStatModel&lt;Bgr&gt;(image, Emgu.CV.CvEnum.BG_STAT_TYPE.FGD_STAT_MODEL);
            }

            _forgroundDetector.Update(image);

            capturedImageBox.Image = image;

            //update the motion history
            _motionHistory.Update(_forgroundDetector.ForegroundMask);

            forgroundImageBox.Image = _forgroundDetector.ForegroundMask;

            #region get a copy of the motion mask and enhance its color
            double[] minValues, maxValues;
            Point[] minLoc, maxLoc;
            _motionHistory.Mask.MinMax(out minValues, out maxValues, out minLoc, out maxLoc);
            Image&lt;Gray, Byte&gt; motionMask = _motionHistory.Mask.Mul(255.0 / maxValues[0]);
            #endregion

            //create the motion image 
            Image&lt;Bgr, Byte&gt; motionImage = new Image&lt;Bgr, byte&gt;(motionMask.Size);
            //display the motion pixels in blue (first channel)
            motionImage[0] = motionMask;

            //Threshold to define a motion area, reduce the value to detect smaller motion
            double minArea = 100;

            storage.Clear(); //clear the storage
            Seq&lt;MCvConnectedComp&gt; motionComponents = _motionHistory.GetMotionComponents(storage);

            //iterate through each of the motion component
            foreach (MCvConnectedComp comp in motionComponents)
            {
               //reject the components that have small area;
               if (comp.area &lt; minArea) continue;

               // find the angle and motion pixel count of the specific area
               double angle, motionPixelCount;
               _motionHistory.MotionInfo(comp.rect, out angle, out motionPixelCount);

               //reject the area that contains too few motion
               if (motionPixelCount &lt; comp.area * 0.05) continue;

               //Draw each individual motion in red
               DrawMotion(motionImage, comp.rect, angle, new Bgr(Color.Red));
            }

            // find and draw the overall motion angle
            double overallAngle, overallMotionPixelCount;
            _motionHistory.MotionInfo(motionMask.ROI, out overallAngle, out overallMotionPixelCount);
            DrawMotion(motionImage, motionMask.ROI, overallAngle, new Bgr(Color.Green));

            //Display the amount of motions found on the current image
            UpdateText(String.Format(""Total Motions found: {0}; Motion Pixel count: {1}"", motionComponents.Total, overallMotionPixelCount));

            //Display the image of the motion
            motionImageBox.Image = motionImage;
         }
      }

      private void UpdateText(String text)
      {
         if (InvokeRequired &amp;&amp; !IsDisposed)
         {
            Invoke((Action&lt;String&gt;)UpdateText, text);
         }
         else
         {
            label3.Text = text;
         }
      }

      private static void DrawMotion(Image&lt;Bgr, Byte&gt; image, Rectangle motionRegion, double angle, Bgr color)
      {
         float circleRadius = (motionRegion.Width + motionRegion.Height) &gt;&gt; 2;
         Point center = new Point(motionRegion.X + motionRegion.Width &gt;&gt; 1, motionRegion.Y + motionRegion.Height &gt;&gt; 1);

         CircleF circle = new CircleF(
            center,
            circleRadius);

         int xDirection = (int)(Math.Cos(angle * (Math.PI / 180.0)) * circleRadius);
         int yDirection = (int)(Math.Sin(angle * (Math.PI / 180.0)) * circleRadius);
         Point pointOnCircle = new Point(
             center.X + xDirection,
             center.Y - yDirection);
         LineSegment2D line = new LineSegment2D(center, pointOnCircle);

         image.Draw(circle, color, 1);
         image.Draw(line, color, 2);
      }

      /// &lt;summary&gt;
      /// Clean up any resources being used.
      /// &lt;/summary&gt;
      /// &lt;param name=""disposing""&gt;true if managed resources should be disposed; otherwise, false.&lt;/param&gt;
      protected override void Dispose(bool disposing)
      {

         if (disposing &amp;&amp; (components != null))
         {
            components.Dispose();
         }

         base.Dispose(disposing);
      }

      private void Form1_FormClosed(object sender, FormClosedEventArgs e)
      {
         _capture.Stop();
      }
   }
}
</code></pre>

<p>I have compiled emgu cv example</p>

<p>his name is <strong>MotionDetection</strong></p>

<p>But when i compile that example, the result is error and he gives me message</p>

<p><strong>The type initializer for 'Emgu.CV.CvInvoke' threw an exception.</strong></p>

<p>i stuck on this <code>_capture = new Capture();</code></p>

<p>I have add references to project
and i have copy opencv_core290.dll, opencv_highgui290.dll, and opencv_imgproc290.dll to project folder
but it still didnt work</p>

<p>the message still same
<strong>The type initializer for 'Emgu.CV.CvInvoke' threw an exception.</strong></p>

<p>i use Visual Studio 2012 Ultimate and Win 8.1
can anyone help me?</p>

<p>thanks :)</p>
",2015-01-11 10:33:22,2015-01-11 10:33:22,why emgu cv example didnt work?,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
23089,20711875,2013-12-20 21:01:08,,"<p>I have a question. Yesterday I started a project in VB.net 2010 Express. I used EmguCV in it, it worked perfect. Today I reopened the project to continue coding. I started the project by clicking the green play button (I did not change anything).</p>

<p>You probably already guessed it... It does not work. It returns a NullReference error. </p>

<p>My code:</p>

<pre><code>'
'  Copyright (C) 2004-2013 by EMGU. All rights reserved.
'

Imports Emgu.CV
Imports Emgu.CV.Structure
Imports Emgu.Util
Imports System.Windows.Forms
Imports System.Drawing
Imports System.Runtime.InteropServices

Module Module1
    Dim capturez As Capture = New Capture
    Sub LoadProcess()

        Dim img As Image(Of Bgr, Byte)
        img = capturez.RetrieveBgrFrame()

        'Load the object detector
        Dim faceDetector As New CascadeClassifier(""haarcascade_frontalface_default.xml"")

        'Convert the image to Grayscale
        Dim imgGray As Image(Of Gray, Byte) = img.Convert(Of Gray, Byte)()

        For Each face As Rectangle In faceDetector.DetectMultiScale( _
                           imgGray, _
                           1.1, _
                           10, _
                           Size.Empty, _
                           Size.Empty)
            img.Draw(face, New Bgr(Color.White), 1)
            Form1.Label1.Text = (face.Left / Form1.ImageBox1.Width) * 100
            Form1.Label2.Text = (face.Top / Form1.ImageBox1.Height) * 100
            If ((face.Left / Form1.ImageBox1.Width) * 100) &gt; 50 Then
                Form1.Label3.Text = ""Naar rechts""
            ElseIf ((face.Left / Form1.ImageBox1.Width) * 100) &lt; 50 Then
                Form1.Label3.Text = ""Naar links""
            End If

            If ((face.Top / Form1.ImageBox1.Height) * 100) &gt; 50 Then
                Form1.Label4.Text = ""Naar omlaag""
            ElseIf ((face.Top / Form1.ImageBox1.Height) * 100) &lt; 50 Then
                Form1.Label4.Text = ""Naar omhoog""
            End If
        Next

        'Show the image
        Form1.ImageBox1.Image = img
        Form1.ImageBox1.FunctionalMode = UI.ImageBox.FunctionalModeOption.Minimum
    End Sub

End Module
</code></pre>

<p>I added three references: Emgu.CV.dll, Emgu.CV.UI.dll and Emgu.Util.dll. 
My computer is a MacBook Pro with Windows 8.1 as a dual boot. </p>

<p>I do not think that there is something wrong with my code, side it worked yesterday!!!</p>

<p>The error occurs in:</p>

<pre><code>Dim imgGray As Image(Of Gray, Byte) = img.Convert(Of Gray, Byte)()
</code></pre>

<p>I hope anyone can help me.</p>

<p>Thanks in advance,<br />
Lars Jansen<br />
The Netherlands</p>
",,2013-12-20 21:01:08,EmguCV works sometimes,<vb.net><windows><macos><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
23095,25246795,2014-08-11 15:22:46,,"<p>I'm trying to decode Morse from a blinking light.
I have a camera that is looking at a light source, and the light source is blinking a certain letter or message in Morse Code.</p>

<p>I'm trying to count the number of frames that the light is on, and depending on that number, then it's a dot or dash. While the light is blinking I'm outputting whether it's a dot or dash to a textbox on the user interface, and then after I haven't received any blinks in a while, then it's safe to assume that's the end of the message so I can output the entire message into the text box.</p>

<p>For now I'm only doing letters, no complex messages yet, and it only works SOME of the time.
Problems that seem to occur randomly are</p>

<ol>
<li>it's saying its a dot when it's a dash,</li>
<li>after it outputs the letter to the text box, it won't recognize any consequent dots or dashes. </li>
</ol>

<p>How could I fix the above problems? And also I was wondering if anyone had some tips how to make this code more efficient?</p>

<p>Below is the code I have now. I'm using a 60fps(or so it says) camera, VS2010, with Emgu CV</p>

<pre><code>int led_on = 0;
    for(int i = x; i &lt; height; i+=pixeljump)
    {
        for(int j = y; j&lt; width; j+=pixeljump)
        {
            byte a = frameColorDisplay-&gt;Data[i,j,0]; //once i find the first spot of light, I'm only concerned with the pixels in the i
            if(a &gt; 225){                             //in the immediate vicinity because the camera and the light source are stationary
                frameOn++;
                frameOff = 0;
                led_on = 1;
                x = i;
                y = j;
                pixeljump = 1;
                height = i + 10;
                width = j + 10;
                //tbMorse-&gt;Text = ""I see the light"";
                break;
            }
        }
    }

    if(led_on == 0){
        frameOff++;
    }

    if((frameOff &gt; 15) &amp;&amp; ((frameOn &gt; 15) &amp;&amp; (frameOn &lt;=25))){      //if the number of frames the light is on is between 15 and 25, its a dot
        tbMorse-&gt;Text = ""That's a dot"";
        //tbMorse-&gt;Text=String::Format(""{0:F}"",frameOn);
        Morse+= ""."";
        frameOn = 0;
        frameOff = 0;
        signalreceived = 1;
    }else if((frameOff &gt; 15) &amp;&amp; (frameOn &gt; 25)){                    //if it's greater than 25, it's a dash
        tbMorse-&gt;Text = ""That's a dash"";
        //tbMorse-&gt;Text=String::Format(""{0:F}"",frameOn);
        Morse+= ""-"";
        frameOn = 0;
        frameOff = 0;
        signalreceived = 1;
    }
 if((frameOff &gt; 60) &amp;&amp; (signalreceived == 1)){ //if it's off for a full second, its safe to send the message
        text += Morse2Text(Morse);
        String ^managedString = marshal_as&lt;String^&gt;( text );
        //String ^managedString = marshal_as&lt;String^&gt;( Morse );
        tbMorse-&gt;Text = managedString;
        text.clear();
        Morse.clear();
        signalreceived = 0;
        frameOn = 0;
        frameOff = 0;
    }
</code></pre>

<p>and these are my declarations of global variables</p>

<pre><code> int frameOn = 0;
int frameOff = 0;
int x = 0;
int y = 0;
int pixeljump = 25;
int height;
int width;
int signalreceived = 0;
string Morse;
string text; 
string Morse2Text(string morse);
</code></pre>

<p>Height and Width are initialized to the height and width of the frame initially.
The Morse2Text function takes in a string of dots and dashes, goes through a massive block of if statements to see what the dots and dashes correspond to, and returns the alphabet value of the dots and dashes.</p>
",2014-08-11 22:33:04,2016-02-21 10:31:20,Decoding Morse from a blinking light,<opencv><image-processing><c++-cli><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
23120,21887153,2014-02-19 16:57:18,,"<p>I got a bitmap as a source;</p>

<p>I created a Emgu image with <code>Image&lt;Bgr,Byte&gt; img = new Image&lt;Bgr,Byte&gt;(bmp);</code></p>

<p>I converted it to a YCbCr image using <code>Image&lt;Ycc,Byte&gt; YCB = img.Convert&lt;Ycc,Byte&gt;();</code></p>

<p>I dragged a imagebox from the toolbox and assigned it with YCB -----> <code>imagebox1.Image=YCB;</code></p>

<p>but the result shows the image in RGB format just like source bitmap</p>

<p>I don't understand where went wrong</p>

<p>Could someone give me some clues?</p>
",2014-02-19 17:22:53,2014-02-20 08:27:27,How to show a YCbCr image using Emgu in C#?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
23136,25556980,2014-08-28 19:56:52,,"<p>I'm working on a project that requires capturing a region of the desktop and stream images to be altered and processed in realtime. When I used Aforge, I get roughly 12 frames after processing and 28 before. I'm aware that my processing will drop the performance, but is the Screencapture feature of a forge really slow?  Would openCV be faster?  Is there a faster alternative?  </p>
",2014-08-28 20:07:01,2014-08-29 00:31:09,Screen Capture APIs,<computer-vision><aforge><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
23183,25254829,2014-08-12 01:25:28,,"<p>I'm trying to use emgu.cv lib for contour function in vb.net. The problem is my var is not defined. This should come under lib emgu.cv which I have already imported.</p>

<pre><code>Dim borderPen As New Pen(Color.FromArgb(150, 0, 255, 0))
Dim processor As ImageProcessor

Private Sub PictureBox1_Paint(sender As Object, e As PaintEventArgs)
    Dim borderPen As New Pen(Color.FromArgb(150, 0, 255, 0))

    If RadioButton1.Checked = True Then
        For Each contour As var In processor.contours
            If contour.Total &gt; 1 Then
                e.Graphics.DrawLines(Pens.Red, contour.ToArray())
            End If
        Next
    End If

    SyncLock processor.foundTemplates
        For Each found As FoundTemplateDesc In processor.foundTemplates
            If found.template.name.EndsWith("".png"") OrElse    found.template.name.EndsWith("".jpg"") Then
                DrawAugmentedReality(found, e.Graphics)
                Continue For
            End If
        Next
    End SyncLock
End Sub

Private Sub DrawAugmentedReality(found As FoundTemplateDesc, gr As Graphics)
    Dim fileName As String = ""C:\Users\pnasguna\Desktop\A56.jpg""
    Dim AugmentedRealityImages As New Dictionary(Of String, Image)()
    Dim img As Image = AugmentedRealityImages(fileName)
    Dim p As Point = found.sample.contour.SourceBoundingRect.Center()
    Dim state = gr.Save()
    gr.TranslateTransform(p.X, p.Y)
    gr.RotateTransform(CSng(180.0F * found.angle / Math.PI))
    gr.ScaleTransform(CSng(found.scale), CSng(found.scale))
    gr.DrawImage(img, New Point(-img.Width / 2, -img.Height / 2))
    gr.Restore(state)
End Sub
</code></pre>

<p>I could not compile as var is not defined. How to fix this problem?</p>
",2014-08-14 21:06:28,2014-08-14 21:06:28,Code error for contour anlaysis in VB.net,<vb.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
23189,24166098,2014-06-11 14:52:53,,"<p>What is equivalent of this code in emgucv:</p>

<pre><code>    cv::Mat marker = cv::Mat::zeros(im.size(), CV_8UC1);
</code></pre>

<p>This is in opencv now!</p>

<p>I couldn't find a wrapper for Mat!</p>
",,2017-03-12 08:35:28,Equivalent in EmguCV,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
23194,19567267,2013-10-24 13:25:11,,"<p>I'm developing a uniform fitting application, the program will take a picture of you and from that picture it will give you your polo/blouse size (Small, Medium, Large, X-Large)</p>

<p>My problem is how will I know if the user using the program has the size of Small? Medium? or Large?</p>

<p>here's my code:</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.Util;

namespace fitting
{
    public partial class Form1 : Form
    {
        HaarCascade UpperBody = new HaarCascade(""haarcascade_mcs_upperbody.xml"");
        HaarCascade LowerBody = new HaarCascade(""haarcascade_lowerbody.xml"");

        Capture camera;
        bool captureProcess = false;
        Image&lt;Bgr, Byte&gt; img;

        public Form1()
        {
            InitializeComponent();
        }

        void viewImage(object sender, EventArgs e)
        {
            img = camera.QueryFrame();
            if (img == null)
                return;
            CamImageBox.Image = img;
        }

        private void btnCapture_Click(object sender, EventArgs e)
        {
            if (captureProcess == true)
            {
                string data;

                Application.Idle -= viewImage;
                captureProcess = false;
                SaveFileDialog dlg = new SaveFileDialog();
                //dlg=""Image|*.jpg;*png"";
                if (dlg.ShowDialog() == DialogResult.OK)
                {
                    img.ToBitmap().Save(dlg.FileName + "".jpg"", System.Drawing.Imaging.ImageFormat.Png);
                    data = dlg.FileName + "".jpg"";
                }
                measureImage();
            }
        }

        void measureImage()
        {
            OpenFileDialog dlg2 = new OpenFileDialog();
            dlg2.Filter = ""Image|*.jpg;*png"";
            if (dlg2.ShowDialog() == DialogResult.OK)
            {
                Image&lt;Bgr, Byte&gt; frame = new Image&lt;Bgr, byte&gt;(dlg2.FileName);
                Image&lt;Gray, Byte&gt; Gray_Frame = frame.Convert&lt;Gray, Byte&gt;();
                //1.985603925968
                MCvAvgComp[][] LowerBodyDetect = Gray_Frame.DetectHaarCascade(
                    LowerBody,
                    1.985603925968,
                    0,
                    Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                    new Size());

                MCvAvgComp[][] UpperBodyDetect = Gray_Frame.DetectHaarCascade(
                    UpperBody,
                    1.3,
                    5,
                    Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                    new Size());


                //foreach (MCvAvgComp Upp_Body in UpperBodyDetect[0])
                //{

                //    frame.Draw(Upp_Body.rect, new Bgr(Color.Red), 2);
                //    double width = (Upp_Body.rect.Width * 0.264583333);
                //    textBox1.Text = (Convert.ToString(width));
                //}
                try
                {
                    frame.Draw(UpperBodyDetect[0][0].rect, new Bgr(Color.Red), 2);
                    double width = (UpperBodyDetect[0][0].rect.Width);
                    textBox1.Text = (Convert.ToString(width));
                }
                catch (Exception e)
                {
                    MessageBox.Show(e.Message);
                }
                    //foreach (MCvAvgComp Low_Body in LowerBodyDetect[0])
                    //{
                    //    frame.Draw(Low_Body.rect, new Bgr(Color.Green), 2);
                    //}

                try
                {
                    frame.Draw(LowerBodyDetect[0][0].rect, new Bgr(Color.Green), 2);
                }
                catch (Exception e)
                {
                    MessageBox.Show(e.Message);
                }
                CamImageBox.Image = frame;
            }
        }

        private void Form1_Load(object sender, EventArgs e)
        {
            bool useCam = false;

            if (!useCam)
                measureImage();
            else {
                try
                {
                    camera = new Capture();
                }
                catch (Exception exc)
                {
                    MessageBox.Show(exc.Message);
                    return;
                }
                Application.Idle += viewImage;
                captureProcess = true;
            }
        }
    }
}
</code></pre>
",,2013-10-24 13:50:05,Emgu body measuring,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
23280,25572050,2014-08-29 16:06:25,,"<p>I'm using Visual Studio 2013. I create a new project Windows Form Application (C#), with target framework in tab Application in Properties of the my project: .NET Framework 3.5.
When I open NuGet and search EmguCV and click install show this error:</p>

<pre><code>Installing 'VVVV.EmguCV 2.4.2.1'.
Successfully installed 'VVVV.EmguCV 2.4.2.1'.
Adding 'VVVV.EmguCV 2.4.2.1' to RadarOCR.Desktop.
Uninstalling 'VVVV.EmguCV 2.4.2.1'.
Successfully uninstalled 'VVVV.EmguCV 2.4.2.1'.
Install failed. Rolling back...
Could not install package 'VVVV.EmguCV 2.4.2.1'. You are trying to install this package 
into a project that targets '.NETFramework,Version=v3.5', but the package does not contain 
any assembly references or content files that are compatible with that framework. 
For more information, contact the package author.
</code></pre>

<p>I do not know what's wrong! Help-me please!</p>
",2014-08-29 18:13:13,2014-08-29 18:13:13,NuGet: Could not install package VVVV.EmguCV 2.4.2.1,<c#><.net><visual-studio><nuget><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
23290,25573624,2014-08-29 17:50:49,,"<p>I have been going over many different resources trying to find a information on camera calibration for VB.</p>

<p>My best luck so far has been reading the example on the site for C#
<a href=""http://www.emgu.com/wiki/index.php?title=Camera_Calibration"" rel=""nofollow noreferrer"">shown in this link with pictures and source files.</a></p>

<p>I have converted as much of the code as I could from C# to VB, and tried to find as much working code for everything else. So far my MainWindow.vb code is:</p>

<pre><code>Imports System.Drawing
Imports System.Threading

Imports Emgu.CV
Imports Emgu.CV.Util
Imports Emgu.CV.Structure



Class MainWindow
'Private Sub MainWindow_Loaded(sender As Object, e As RoutedEventArgs) _
'       Handles Me.Loaded
'    Dim capturez As Capture = New Capture

'End Sub
#Region ""Class Variables""
Declare Sub Sleep Lib ""kernel32.dll"" (ByRef Milliseconds As Integer)
Dim capturez As Capture = New Capture
Dim Start_Flag As Boolean = False

Dim BoxUnitHeight As Integer = 9 'EDIT THESE VALUES BASED ON THE BOARD PATTERN
Dim BoxUnitWidth As Integer = 6

Dim Frame_array_buffer As Image(Of Gray, [Byte])() = New Image(Of Gray, Byte)(99) {}
Dim BufferSavePoint As Integer = 0
Dim Corner_Object_List As MCvPoint3D32f()() = New     MCvPoint3D32f(Frame_array_buffer.Length - 1)() {}
Dim Corner_Points_List As PointF()() = New PointF(Frame_array_buffer.Length - 1)() {}
Dim IC As New IntrinsicCameraParameters()
Dim EX_Param As ExtrinsicCameraParameters() = New ExtrinsicCameraParameters() {}

Dim patternSize As Size = New Size(BoxUnitHeight, BoxUnitWidth)

Dim Gray_Frame As Image(Of Gray, Byte) = capturez.QueryGrayFrame
Dim BGR_Frame As Image(Of Bgr, Byte) = capturez.RetrieveBgrFrame
Dim calImage As Image(Of Gray, Byte) = New Image(Of Gray, Byte)    (""C:\Users\\\\\\Image_Correction_Test_V2\OpenCV_Chessboard.png"")

Dim corners As PointF() = New PointF() {}
Dim newCornerz As PointF() = New PointF() {}

Dim difError As Double
Dim termCriteria As New MCvTermCriteria


Public Enum Mode
    SavingFrames
    Caluculating_Intrinsics
    Calibrated
End Enum
#End Region
Private currentMode As Mode = Mode.SavingFrames

Private Sub MainWindow_Loaded(sender As Object, e As RoutedEventArgs) _
    Handles Me.Loaded
    termCriteria.max_iter = 1
    termCriteria.epsilon = 0.0
    termCriteria.type = CvEnum.TERMCRIT.CV_TERMCRIT_ITER

End Sub
' Sink the ""Exit MenuItem"" click event
Private Sub mnuExit_Click(ByVal sender As Object, ByVal e As     System.Windows.RoutedEventArgs) _
        Handles mnuExit.Click
    Application.Current.Shutdown()
End Sub

Private Sub Button_Click(ByVal sender As Object, ByVal e As     System.Windows.RoutedEventArgs) _
    Handles Button.Click
    Start_Flag = True
End Sub

' Sink the ""Exit MenuItem"" click event
Private Sub mnuFix_Click(ByVal sender As Object, ByVal e As     System.Windows.RoutedEventArgs) _
        Handles mnuFix.Click
    Gray_Frame = capturez.RetrieveGrayFrame
    newCornerz = CameraCalibration.FindChessboardCorners(calImage, patternSize,      Emgu.CV.CvEnum.CALIB_CB_TYPE.ADAPTIVE_THRESH Or Emgu.CV.CvEnum.CALIB_CB_TYPE.FILTER_QUADS)

    corners = CameraCalibration.FindChessboardCorners(Gray_Frame, patternSize,     Emgu.CV.CvEnum.CALIB_CB_TYPE.ADAPTIVE_THRESH Or Emgu.CV.CvEnum.CALIB_CB_TYPE.FILTER_QUADS)

    If corners IsNot Nothing Then
        Dim perM As HomographyMatrix
        perM = CameraCalibration.FindHomography(corners, newCornerz,     CvEnum.HOMOGRAPHY_METHOD.DEFAULT, 1)
        Dim Test As Image(Of Gray, Byte) = Gray_Frame.WarpPerspective(perM,     CvEnum.INTER.CV_INTER_NN, CvEnum.WARP.CV_WARP_DEFAULT, New Gray)
        Cal1.Source = ToBitmapSource(Test)
    End If

End Sub


Public Sub StartTimer(ByVal o As Object, ByVal sender As RoutedEventArgs)
    Dim myDispatcherTimer As System.Windows.Threading.DispatcherTimer = New     System.Windows.Threading.DispatcherTimer
    myDispatcherTimer.Interval = New TimeSpan(0, 0, 0, 0, 30)
    ' 100 Milliseconds 
    AddHandler myDispatcherTimer.Tick, AddressOf Me.Each_Tick
    myDispatcherTimer.Start()
End Sub

' Raised every 100 miliseconds while the DispatcherTimer is active.
Public Sub Each_Tick(ByVal o As Object, ByVal sender As EventArgs)

    Dim imagez As Image(Of Bgr, Byte) = capturez.QueryFrame() 'Instead of QueryFrame, you may need to do RetrieveBgrFrame depending on the version of EmguCV you download.
    Stream.Source = ToBitmapSource(imagez)

    BGR_Frame = capturez.RetrieveBgrFrame
    Gray_Frame = BGR_Frame.Convert(Of Gray, Byte)()

    If currentMode = Mode.SavingFrames Then

        corners = CameraCalibration.FindChessboardCorners(Gray_Frame, patternSize, Emgu.CV.CvEnum.CALIB_CB_TYPE.ADAPTIVE_THRESH Or Emgu.CV.CvEnum.CALIB_CB_TYPE.FILTER_QUADS)

        If corners IsNot Nothing Then
            'Debug.Print(""Filling Array Buffer"")

            'The Find chessboardCorners will try to find them, but if it doesn't it still runs. If it fails DrawChessboard will fail and crash the program.

            If Start_Flag Then
                Gray_Frame.FindCornerSubPix(New PointF(0)() {corners}, New Size(11, 11), New Size(-1, -1), New MCvTermCriteria(30, 0.1))
                Frame_array_buffer(BufferSavePoint) = Gray_Frame.Copy
                BufferSavePoint = BufferSavePoint + 1
                If BufferSavePoint = Frame_array_buffer.Length Then currentMode = Mode.Caluculating_Intrinsics 'Buffer has been filled
            End If


            'Draw the reults

            CameraCalibration.DrawChessboardCorners(Gray_Frame, patternSize, corners)
            Cal2.Source = ToBitmapSource(Gray_Frame)
            Thread.Sleep(100)

        End If
        corners = Nothing
    End If

    If currentMode = Mode.Caluculating_Intrinsics Then
        'Debug.Print(""Filling Object and Point Arrays"")
        For k As Integer = 0 To Frame_array_buffer.Length - 1

            Corner_Points_List(k) = CameraCalibration.FindChessboardCorners(Frame_array_buffer(k), patternSize, Emgu.CV.CvEnum.CALIB_CB_TYPE.ADAPTIVE_THRESH)
            'for accuracy
            Gray_Frame.FindCornerSubPix(Corner_Points_List, New Size(11, 11), New Size(-1, -1), New MCvTermCriteria(30, 0.1))

            'Fill our objects list with the real world mesurments for the intrinsic calculations
            Dim object_list As New List(Of MCvPoint3D32f)()
            For i As Integer = 0 To BoxUnitHeight - 1
                For j As Integer = 0 To BoxUnitWidth - 1
                    object_list.Add(New MCvPoint3D32f(j * 20.0F, i * 20.0F, 0.0F))
                Next
            Next
            Corner_Object_List(k) = object_list.ToArray()
        Next
        Debug.Print(""Reached Calibration"")

        'our error should be as close to 0 as possible

        difError = CameraCalibration.CalibrateCamera(Corner_Object_List, Corner_Points_List, Gray_Frame.Size, IC, Emgu.CV.CvEnum.CALIB_TYPE.CV_CALIB_RATIONAL_MODEL, termCriteria, EX_Param)
        'If Emgu.CV.CvEnum.CALIB_TYPE == CV_CALIB_USE_INTRINSIC_GUESS and/or CV_CALIB_FIX_ASPECT_RATIO are specified, some or all of fx, fy, cx, cy must be initialized before calling the function
        'if you use FIX_ASPECT_RATIO and FIX_FOCAL_LEGNTH options, these values needs to be set in the intrinsic parameters before the CalibrateCamera function is called. Otherwise 0 values are used as default.
        'display the results to the user
        MsgBox(""Your calibration error is:"" &amp; difError)
        currentMode = Mode.Calibrated
    End If

    If currentMode = Mode.Calibrated Then
        'Debug.Print(""Attempting Picture fix"")


        'calculate the camera intrinsics
        Dim Map1 As Matrix(Of Single), Map2 As Matrix(Of Single)
        IC.InitUndistortMap(BGR_Frame.Width, BGR_Frame.Height, Map1, Map2)

        'remap the image to the particular intrinsics
        'In the current version of EMGU any pixel that is not corrected is set to transparent allowing the original image to be displayed if the same
        'image is mapped backed, in the future this should be controllable through the flag '0'
        Dim temp As Image(Of Bgr, [Byte]) = BGR_Frame.CopyBlank()
        CvInvoke.cvRemap(BGR_Frame, temp, Map1, Map2, 0, New MCvScalar(0))
        BGR_Frame = temp.Copy


        Imgz.Source = ToBitmapSource(BGR_Frame)
        Start_Flag = False
    End If

    Debug.Print(currentMode)
End Sub

''' &lt;summary&gt;
''' Delete a GDI object
''' &lt;/summary&gt;
''' &lt;param name=""o""&gt;The poniter to the GDI object to be deleted&lt;/param&gt;
''' &lt;returns&gt;&lt;/returns&gt;
&lt;DllImport(""gdi32"")&gt; _
Private Shared Function DeleteObject(o As IntPtr) As Integer
End Function

''' &lt;summary&gt;
''' Convert an IImage to a WPF BitmapSource. The result can be used in the Set Property of Image.Source
''' &lt;/summary&gt;
''' &lt;param name=""image""&gt;The Emgu CV Image&lt;/param&gt;
''' &lt;returns&gt;The equivalent BitmapSource&lt;/returns&gt;
Public Shared Function ToBitmapSource(image As IImage) As BitmapSource
    Using source As System.Drawing.Bitmap = image.Bitmap
        Dim ptr As IntPtr = source.GetHbitmap()
        'obtain the Hbitmap
        Dim bs As BitmapSource = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(ptr, IntPtr.Zero, Int32Rect.Empty, System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions())

        DeleteObject(ptr)
        'release the HBitmap
        Return bs
    End Using
End Function

End Class
</code></pre>

<p>Description: When the MainWindow.xaml is launched the main system parameters are initiated and the timer kicks in. Every 30 milliseconds (not 100) the main program loop runs. I copied most of the code from the example code here. Looks like a state machine set up, where they used Mode to switch between stages of calibration. A ""GO"" button is used right now to start the calibration by switch one flag, but the video feed runs continuously. The bottom function is to compensate for the fact that old picturebox.image liked .tobitmap(), but image.source does not which I am using.</p>

<p>So, hit GO button, wait for 100 images to be saved, calculate points and save all that data. Calculate extrinsics and intrinsics, find skewing maps, and apply maps to feed.</p>

<p>When CameraCalibration.CalibrateCamera is finished it spits out an error as double, and MsgBox shows what that is.
When MsgBox fires and tells me my error, I am seeing numbers as high as 85-105 where the guide is telling me it should be minimized as close to 0 as possible.</p>

<p>Then when the altered image appears it is heavily skewed.</p>

<p><img src=""https://i.stack.imgur.com/i15ov.jpg"" alt=""Video feed on the calibration""></p>

<p>Bottom left: Video Feed. Bottom Right: Grayed feed with corners found.
The Top Left image is supposed to be the corrected one. 
The last time I ran the program, it actually heavily distorted the image to look like a fishbowl.</p>

<p>Does anyone else have experience with this and can tell me what I am doing wrong?</p>

<p>Some additional info: 
All other code I have found online, when using .calibratecamera has not been in VB and in addition has taken one less argument. ""termCriteria"" is a variable that I had to figure out how to set, and I have never seen other code that had to use it.</p>

<p>For code conversion I used this site:
<a href=""http://www.developerfusion.com/tools/convert/csharp-to-vb/?batchId=c3d82aab-4c61-4b66-952f-840e51af3aa2#convert-again"" rel=""nofollow noreferrer"">Code converter.</a> </p>
",2014-08-29 18:02:08,2014-09-04 16:00:59,"EMGU CV, Visual Basic CameraCalibration.CalibrateCamera resulting in very high error",<c#><wpf><vb.net><emgucv><camera-calibration>,,,CC BY-SA 3.0,True,False,True,False,False
23357,23022327,2014-04-11 20:50:03,,"<p>I implemented a simple application to get video steam form a normal web camera , and show on a windows application using <code>CAPTURE</code> class.</p>

<p>The application works and i can see the video on the image box , but the frames in the video is flipped (my left side is shown in right side).</p>

<p>I tried with multiple cameras and the same problem remains.When i connect the same camera in other application such as skype, there is no flip problem.</p>

<p>Is it a normal behaviour in <code>capture</code> class?
How can solve this problem?</p>

<p>I followed <a href=""http://fewtutorials.bravesites.com/entries/emgu-cv-c/level-1---lets-make-a-camera-application"" rel=""nofollow"">this</a> tutorial</p>

<p>Thanks in advance</p>
",,2014-04-12 09:56:38,Emgu cv showing webcam stream as flipped image,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
23551,26715178,2014-11-03 13:15:17,,"<p>I want to implement Motion Blur Filter in C# using Emgu CV, what is the correct way to do this in fourier domain. I am currently stuck at how to perform multiply of Motion Blur filter and my Complex Fourier Image.  </p>
",2014-11-05 20:39:39,2014-11-05 20:39:39,Implement Motion Blur Filter Using EmguCv,<c#><visual-studio><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
23554,26715873,2014-11-03 13:59:52,,"<p>I'm using C# with EmguCV in combination with a Kinect to display a video captured by the Kinect. My application detects successfully feature points with the SURF algorithm and marks them as red points on the video. Now I need to find and approximately largest area WITHOUT any feature points to detect a blank surface (e.g. free space for projection etc.). Is this possible using the SURF algorithm or do better solutions exist for this kind of problem?</p>
",2014-11-04 20:50:50,2014-11-04 20:50:50,EmguCV and SURF: How to find largest area without any SURF point features?,<c#><image-processing><emgucv><surf>,,,CC BY-SA 3.0,False,False,True,False,False
23556,19597231,2013-10-25 18:40:50,,"<p>""The Principal Component Analysis (PCA), which is the core of the Eigenfaces method, finds a linear combination of features that maximizes the total variance in data. While this is clearly a powerful way to represent data, it doesn’t consider any classes and so a lot of discriminative information may be lost when throwing components away."" (Open CV)</p>

<p>What is mean by ""CLASSES"" here????</p>

<p>""
Linear Discriminant Analysis maximizes the ratio of between-classes to within-classes scatter, instead of maximizing the overall scatter. The idea is simple: same classes should cluster tightly together, while different classes are as far away as possible from each other in the lower-dimensional representation.</p>

<p>in here also what is mean by CLASSES????</p>

<p>Can some one please explain this in image processing view thanx</p>
",,2014-07-18 12:03:49,what is the main difference between linear discriminant analysis and pronciple component analysis,<opencv><image-processing><matching><emgucv><feature-extraction>,,,CC BY-SA 3.0,True,False,True,False,False
23577,25595405,2014-08-31 19:17:22,,"<p>I want to shift an image by lets say (100,50) using emgu cv.</p>

<p>In opencv, one can use cv2.warpaffine and pass the shift value using a numpy array.
However I can't find any corresponding wrapper function for the same in emgucv.</p>
",,2014-08-31 19:17:22,How to shift images in emgucv?,<opencv><visual-studio-2012><image-processing><emgucv><affinetransform>,,,CC BY-SA 3.0,True,False,True,False,False
23579,25596981,2014-08-31 22:49:41,,"<p><strong>As berak said in the comments, it seems this code is deprecated</strong></p>

<p>In Opencv there is a method ""cvmget"", the sample usage is:</p>

<pre><code>bool niceHomography(const CvMat * H)
{
  const double det = cvmGet(H, 0, 0) * cvmGet(H, 1, 1) - cvmGet(H, 1, 0) * cvmGet(H, 0, 1);
  if (det &lt; 0)
    return false;

  const double N1 = sqrt(cvmGet(H, 0, 0) * cvmGet(H, 0, 0) + cvmGet(H, 1, 0) * cvmGet(H, 1, 0));
  if (N1 &gt; 4 || N1 &lt; 0.1)
    return false;

  const double N2 = sqrt(cvmGet(H, 0, 1) * cvmGet(H, 0, 1) + cvmGet(H, 1, 1) * cvmGet(H, 1, 1));
  if (N2 &gt; 4 || N2 &lt; 0.1)
    return false;

  const double N3 = sqrt(cvmGet(H, 2, 0) * cvmGet(H, 2, 0) + cvmGet(H, 2, 1) * cvmGet(H, 2, 1));
  if (N3 &gt; 0.002)
    return false;

  return true;
}
</code></pre>

<p>is there any method in like <code>cvmget</code> in EmguCV?</p>
",2015-01-21 21:59:56,2015-11-30 18:53:07,OpenCv & EmguCv equavalent method?,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
23590,19598664,2013-10-25 20:13:33,,"<p>I am swapping from EmguCV to OpenCV so that I can try some of the OpenCV functions that are not yet wrapped by EmguCV. However I'm failing to load my simple test video file, which loads without issue in EmguCV. Looking at the EmguCV source code I notice that they call the OpenCV C functions rather than C++ to initialise capture from a file (or a webcam) so I wrote the following test code (with help from <a href=""https://stackoverflow.com/a/10260047/575530"">this answer</a>). Here is my simple code</p>

<pre><code>int _tmain()
{
    string filename = ""sample.wmv"";
    if (!FileExists(filename.c_str))
    {
        cout &lt;&lt; ""File does not exist"" &lt;&lt; endl;  
        return -1;
    }
    else
    {
        cout &lt;&lt; ""File exists"" &lt;&lt; endl;
        VideoCapture cap (filename);
        if(!cap.isOpened())
        {
            cout &lt;&lt; ""Failed to open file in OpenCV C++"" &lt;&lt; endl;
            //Trying C API too just-in-case
            CvCapture* capture = cvCreateFileCapture(filename.c_str());
            if (!capture)
            {
                cout &lt;&lt; ""Failed to open file in OpenCV C"" &lt;&lt; endl;  
            }
            else
            {
                //Grab frames and do stuff
                cvReleaseCapture(&amp;capture);
            }
            return -1;
        }
        else
        {
            //Grab frames and do stuff
        }
    }
    return 0;
}
</code></pre>

<p>When I run this I get the output </p>

<pre><code>File exists
Failed to open file in OpenCV C++
Failed to open file in OpenCV C
</code></pre>

<p>This happens regardless of the file, i.e. it happens for ""sample.wmv"", ""sample.avi"", and even one of the OpenCV sample files ""tree.avi"".</p>

<p>Why? What is going on?</p>

<p>(I'm running OpenCV 2.4.6 on a Windows 8 and a Windows 8.1 machine.)</p>
",2017-05-23 12:16:09,2013-10-28 12:52:08,Why would video files not open in OpenCV (both C & C++ APIs)?,<opencv><video>,,,CC BY-SA 3.0,True,False,True,False,False
23667,19601629,2013-10-26 00:54:39,,"<p>I'm creating a program which will get the width and length of the rectangle drawn on a whole body picture of the user. I can't seem to get the right scaleFactor, minNeighbor and size. how or what should I do to get the right info's...</p>

<p>Here is my code:</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.Util;

namespace fitting
{
    public partial class Form1 : Form
    {
        HaarCascade UpperBody = new HaarCascade(""haarcascade_mcs_upperbody.xml"");
        HaarCascade LowerBody = new HaarCascade(""haarcascade_lowerbody.xml"");

        Capture camera;
        bool captureProcess = false;
        Image&lt;Bgr, Byte&gt; img;

        public Form1()
        {
            InitializeComponent();
        }

        void viewImage(object sender, EventArgs e)
        {
            img = camera.QueryFrame();
            if (img == null)
                return;
            CamImageBox.Image = img;
        }

        private void btnCapture_Click(object sender, EventArgs e)
        {
            if (captureProcess == true)
            {
                string data;

                Application.Idle -= viewImage;
                captureProcess = false;
                SaveFileDialog dlg = new SaveFileDialog();
                //dlg=""Image|*.jpg;*png"";
                if (dlg.ShowDialog() == DialogResult.OK)
                {
                    img.ToBitmap().Save(dlg.FileName + "".jpg"", System.Drawing.Imaging.ImageFormat.Png);
                    data = dlg.FileName + "".jpg"";
                }
                measureImage();
            }
        }

        void measureImage()
        {
            OpenFileDialog dlg2 = new OpenFileDialog();
            dlg2.Filter = ""Image|*.jpg;*png"";
            if (dlg2.ShowDialog() == DialogResult.OK)
            {
                Image&lt;Bgr, Byte&gt; frame = new Image&lt;Bgr, byte&gt;(dlg2.FileName);
                Image&lt;Gray, Byte&gt; Gray_Frame = frame.Convert&lt;Gray, Byte&gt;();

                MCvAvgComp[][] LowerBodyDetect = Gray_Frame.DetectHaarCascade(
                    LowerBody,
                    1.985603925968,
                    0,
                    Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                    new Size());

                MCvAvgComp[][] UpperBodyDetect = Gray_Frame.DetectHaarCascade(
                    UpperBody,
                    1.3,
                    5,
                    Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                    new Size());


                //foreach (MCvAvgComp Upp_Body in UpperBodyDetect[0])
                //{

                //    frame.Draw(Upp_Body.rect, new Bgr(Color.Red), 2);
                //    double width = (Upp_Body.rect.Width * 0.264583333);
                //    textBox1.Text = (Convert.ToString(width));
                //}
                try
                {
                    frame.Draw(UpperBodyDetect[0][0].rect, new Bgr(Color.Red), 2);
                    double width = (UpperBodyDetect[0][0].rect.Width);
                    textBox1.Text = (Convert.ToString(width));
                }
                catch (Exception e)
                {
                    MessageBox.Show(e.Message);
                }
                    //foreach (MCvAvgComp Low_Body in LowerBodyDetect[0])
                    //{
                    //    frame.Draw(Low_Body.rect, new Bgr(Color.Green), 2);
                    //}

                try
                {
                    frame.Draw(LowerBodyDetect[0][0].rect, new Bgr(Color.Green), 2);
                }
                catch (Exception e)
                {
                    MessageBox.Show(e.Message);
                }
                CamImageBox.Image = frame;
            }
        }

        private void Form1_Load(object sender, EventArgs e)
        {
            bool useCam = false;

            if (!useCam)
                measureImage();
            else {
                try
                {
                    camera = new Capture();
                }
                catch (Exception exc)
                {
                    MessageBox.Show(exc.Message);
                    return;
                }
                Application.Idle += viewImage;
                captureProcess = true;
            }
        }
    }
}
</code></pre>
",,2013-10-26 10:04:52,"The right scaleFactor, minNeighbor and size for upperbody and lowerbody detection using haarcascade",<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
23697,21932861,2014-02-21 11:15:03,,"<p>Can someone explain me how does Features2DToolbox.VoteForUniqueness work?</p>

<p>This is the source code to use it :</p>

<pre><code>BruteForceMatcher&lt;float&gt; matcher = new BruteForceMatcher&lt;float&gt;(DistanceType.L2);
matcher.Add(modelfeature);
indices = new Matrix&lt;int&gt;(destfeature.Rows, 2);
dist = new Matrix&lt;float&gt;(destfeature.Rows, 2);
matcher.KnnMatch(destfeature, indices, dist, 2, null);
mask = new Matrix&lt;byte&gt;(dist.Rows, 1);
mask.SetValue(255);
Features2DToolbox.VoteForUniqueness(dist, 0.8, mask);
</code></pre>

<p>I want to make the manual one :</p>

<pre><code>indices = new Matrix&lt;int&gt;(destfeature.Rows, 2);
dist = new Matrix&lt;float&gt;(destfeature.Rows, 2);
for (int i = 0; i &lt; destfeature.Rows; i++)
{
    dist[i, 0] = float.MaxValue;
    dist[i, 1] = float.MaxValue;
    indices[i, 0] = -1;
    indices[i, 1] = -1;
    for (int j = 0; j &lt; modelfeature.Rows; j++)
    {
        float temp = 0;
        for (int k = 0; k &lt; 128; k++)
        {
             temp = temp +(float) Math.Pow(modelfeature[j, k] - destfeature[i, k], 2.0);
        }
        temp =(float) Math.Sqrt(temp);
        if (temp &lt; dist[i, 0])
        {
             dist[i, 1] = dist[i, 0];
             indices[i, 1] = indices[i, 0];
             dist[i, 0] = temp;
             indices[i, 0] = j;
        }
        else if (temp &lt; dist[i, 1])
        {
             dist[i, 1] = temp;
             indices[i, 1] = j;
        }
    }
}
mask = new Matrix&lt;byte&gt;(dist.Rows, 1);
for (int i = 0; i &lt; dist.Rows; i++)
{
    if (dist[i, 0] &lt; dist[i, 1] * 0.8)
    {
        mask[i, 0] = 255;
    }
    else
    {
        mask[i, 0] = 0;
    }
}
</code></pre>

<p>already edited
before my mistake is that i divided dist[i,1] with dist[i,0], if it is more than 0.8, it'true.</p>
",2014-02-26 09:14:21,2014-02-26 09:14:21,how does Features2DToolbox.VoteForUniqueness work?,<emgucv><sift>,,,CC BY-SA 3.0,False,False,True,False,False
23699,21933682,2014-02-21 11:49:46,,"<p>I am working on one project where I stuck on one point where I have to run two methods in parallel. </p>

<p><strong>In Function 1</strong> </p>

<p>In my application what I am doing is I am grabbing images from the IP cam and storing that image into the one folder.
This function is used for continues streaming of camera.</p>

<p>For this you can refer this question which I have asked <a href=""https://stackoverflow.com/q/21745309/3110262"">IP Camera stops streaming</a>.</p>

<p><strong>In Function 2</strong></p>

<p>I will pick images from the path where my <em>Function2</em> is dumping images.</p>

<p>Here I am doing some other operations like:</p>

<ol>
<li>Save Image captured from the IP Camera</li>
<li>Detect faces in Image </li>
<li>Draw Face markers on Image</li>
<li>Some database based on result of Face Detection</li>
<li>Delete image File </li>
</ol>

<p><em>Function 2</em> takes more execution time than <em>Function 1</em>.</p>

<p>So for this purpose after searching on google I get to know I can do this by multithreading.</p>

<p>So, I am little bit confused about this and as I am new in c# I am not that much aware of multithreading.</p>

<p>So, can anyone help me out on this?</p>
",2017-05-23 10:31:57,2014-02-21 12:08:12,creating multiple threads of a function,<c#><multithreading><thread-safety><emgucv>,2014-04-01 11:50:15,,CC BY-SA 3.0,False,False,True,False,False
23763,19613609,2013-10-27 01:07:49,,"<p>After saving a image in PNG format using</p>

<p><code>bitmap.save(filename, ImageFormat.PNG)</code>,</p>

<p>I now try to read the same image</p>

<p><code>Image&lt;Rgb, Byte&gt; inpImage = new Image&lt;Rgb, Byte&gt;(dir + fn_only + ""_ms.png"")</code> using emgu Image. On runtime I get a </p>

<blockquote>
  <p>System.TypeInitializationException occurred in Emgu.CV.dll</p>
</blockquote>

<p>Exception:</p>

<blockquote>
  <p>System.TypeInitializationException: The type initializer for 'Emgu.CV.CvInvoke'
  threw an exception. ---> System.DllNotFoundException: Unable to load DLL 'opencv
  _core242': The specified module could not be found. (Exception from HRESULT: 0x8
  007007E)
     at Emgu.CV.CvInvoke.cvRedirectError(CvErrorCallback errorHandler, IntPtr user
  data, IntPtr prevUserdata)
     at Emgu.CV.CvInvoke..cctor()
     --- End of inner exception stack trace ---
     at Emgu.CV.Image`2..ctor(String fileName)</p>
</blockquote>

<p>when opencv_242 is present. On dependency check it says NVCUDA is missing. I do not have a GPU, obv there wont be NVCUDA in that case.</p>

<p>I tried color type RGB and BGR.</p>
",2013-10-29 01:40:02,2014-10-21 15:55:34,read a PNG image using emgu Image,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
23860,20771125,2013-12-25 09:16:00,,"<p>I'm trying to build a program that would take a picture of a user 3 times and save those pictures in the desktop my problem is it only saves the picture instead of taking the picture 3 times.</p>

<pre><code>private void Form1_Load(object sender, EventArgs e)
{
     bool useCam = true;
     if (!useCam)
        measureImage(null);
     else 
     {
        try
        {
             camera = new Capture();
        }
        catch (Exception exc)
        {
           MessageBox.Show(exc.Message);
           return;
        }

        Application.Idle += viewImage;
        captureProcess = true;
     }
}
</code></pre>

<p>here is the capturing code...    </p>

<pre><code>private void btnCapture_Click(object sender, EventArgs e)
{
    for (int ctr = 0; ctr &lt; 3; ctr++)
    {
        if (captureProcess == true)
        {
            string data="""";
            Application.Idle -= viewImage;

            SaveFileDialog dlg = new SaveFileDialog();

            if (dlg.ShowDialog() == DialogResult.OK)
            {
               img.ToBitmap().Save(@""C:\\Users\\Julie\\Desktop\\"" + ctr + "".bmp"", System.Drawing.Imaging.ImageFormat.Bmp);

                        data = dlg.FileName + "".bmp"";
                        MessageBox.Show(data);
                        measureImage(data);
                        Form1_Load(sender, e);
            }
            else
            {
                Application.Exit();
            }

        }

    }
            captureProcess = false;
}
</code></pre>
",2013-12-26 07:47:53,2013-12-26 07:47:53,Multiple image capture using emgucv library,<c#><winforms><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
23902,24224501,2014-06-14 21:33:45,,"<p>I'm getting a problem with a project developed in C# with Emgu CV.</p>

<p>When I try tu run my program in one of my machines it works very well but, when i try to run at other machine (mine too) if doesnt work and show this error:</p>

<p>Can't find the entrance point at procedure clEnqueueCopyBufferRect at dll OpenCL.dll</p>

<p>This error only occurs in one machine.</p>

<p>Note: When i run the examples of EmguCV i get the same error.</p>

<p>Thanks</p>
",,2014-06-15 13:11:10,Can't find the entrance point at procedure clEnqueueCopyBufferRect at dll OpenCL.dll,<opencl><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
23926,24225912,2014-06-15 01:56:55,,"<p>I am currently doing a project which involves controlling couple of maxon DC motors, reading from force sensors, and image processing in windows OS. I am trying to find the right programming language or combination of them in order to get high speed communication rate with hardwares as well as real-time image processing. The application needs to have GUI. It also needs to be multi-threaded. My options that I am investigating are:</p>

<p>1) C++ and QT for GUI - I couldn't get Qt working with Opencv. I was unable to compile Opencv for Qt.</p>

<p>2) C# with Emgucv - I am still struggling to get what I want using Emgucv.</p>

<p>3) Making DLL for the image processing part in C++ with Opencv and use in c# for GUI - all of the hardwares are working in C# through DLLs. </p>

<p>4) Making DLL for the maxon DC motor controls in C++ and use in python for GUI - the good about this solution is that Opencv works very well with python. But I am not sure whether python is the right language for real-time hardware communication.</p>

<p>5) Matlab - very slow</p>

<p>I very much like to use just one language, and for doing so, my only choice is number 1 which I cannot get it running. So my questions:</p>

<p>Do you know any other solution?
If I have to choose another language as well as C++ to make GUI and also be able to have multi-threading easily (like python and backgroundworker in C#), which one do you recommend c# or python, or any other? Speed is important for this application.</p>

<p>Thanks in advance</p>
",,2014-06-15 15:24:55,c# or python for calling C++ DLLs for hardware control,<c#><python><opencv><visual-c++><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
23940,24226871,2014-06-15 05:37:22,,"<p>I am trying to make a Skeletonization in C# using EmguCV. I am using the sample at the bottom of this page which is in C++ and I tried that and it works: 
<a href=""http://felix.abecassis.me/2011/09/opencv-morphological-skeleton/"" rel=""nofollow"">http://felix.abecassis.me/2011/09/opencv-morphological-skeleton/</a></p>

<p>I have converted the cod to C# as follows:</p>

<pre><code>        Image&lt;Gray, Byte&gt; eroded = new Image&lt;Gray, byte&gt;(img2.Size);
        Image&lt;Gray, Byte&gt; temp = new Image&lt;Gray, byte&gt;(img2.Size);
        Image&lt;Gray, Byte&gt; skel = new Image&lt;Gray, byte&gt;(img2.Size);
        skel.SetValue(0);
        CvInvoke.cvThreshold(img2, img2, 127, 256, 0);
        StructuringElementEx element = new StructuringElementEx(3, 3, 1, 1, Emgu.CV.CvEnum.CV_ELEMENT_SHAPE.CV_SHAPE_CROSS);
        bool done = false;

        while (!done)
        {
            CvInvoke.cvErode(img2, eroded, element,1);
            CvInvoke.cvDilate(eroded, temp, element,1);
            temp = img2.Sub(temp);
            skel = skel | temp;
            img2 = eroded;
            if (CvInvoke.cvCountNonZero(img2) == 0) done = true;
        }
</code></pre>

<p>But this does not work! What is wrong?
In the beginning of the while loop, it erodes the image 'img2' and saves it to 'eroded', then it dilates 'eroded' and then saves it to 'temp'. In the above C# code, this results in 'temp=img2' which makes sense. So why this is working in the C++ code and not n C#? Is something wrong with the way 'element' is defined in the above C# code?</p>

<p>Thanks in advance!</p>
",,2015-01-29 10:38:24,Skeletonization using EmguCV,<c#><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
23978,26747070,2014-11-04 23:30:13,,"<p>I just switched from OpenCV to EmguCV because C++ applications can't be directly hosted on my target cloud platform -- now my Histogram code won't work after making the necessary changes for the conversion. </p>

<p>Here is a snippet of what I have done:</p>

<pre><code>Image&lt;Gray, Byte&gt; img_gray = new Image&lt;Gray, byte&gt;(frame1_hist.Rows, frame1_hist.Cols);
frame1_hist.CopyTo(img_gray, null);
DenseHistogram hist = new DenseHistogram(256, new RangeF(0, 256));
hist.Calculate(new Image&lt;Gray, Byte&gt;[] { img_gray }, true, null);
</code></pre>

<blockquote>
  <p>An unhandled exception of type 'System.NullReferenceException'
  occurred in Emgu.CV.dll</p>
</blockquote>

<p>I will appreciate your kind help if you may tell me how I can fix this. Also, how can I read the processed image from ""hist"" after the operation. I am using EmguCv 3.0.0. Thanks</p>
",,2015-05-06 14:35:05,EmguCV: Create Image Histogram - Error,<c#><histogram><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
23993,25629079,2014-09-02 17:30:37,,"<p>I needed an app that observed numbers in my screen and then make calculations with it, so after some days on researching the best and easiest method i found this video
(<a href=""https://www.youtube.com/watch?v=Kjdu8SjEtG0"" rel=""nofollow"">https://www.youtube.com/watch?v=Kjdu8SjEtG0</a>) that leaded me to OCR and EMGU-Tesseract on Visual Basic 2010 express. I understanded the video and I made my own variation of the code on the description of the video.</p>

<p>I imported:</p>

<pre><code>Imports Emgu.CV
Imports Emgu.Util
Imports Emgu.CV.OCR
Imports Emgu.CV.Structure
</code></pre>

<p>then i make this based on the original code:</p>

<pre><code>Dim OCRz As Tesseract = New Tesseract(""tessdata"", ""eng"", Tesseract.OcrEngineMode.OEM_TESSERACT_ONLY)
Dim picStc1 As Bitmap = New Bitmap(149, 28)
Dim gfxSTK1 As Graphics = Graphics.FromImage(picStc1)
Dim picNam1 As Bitmap = New Bitmap(149, 28)
Dim gfxNAM1 As Graphics = Graphics.FromImage(picNam1)


Private Sub Timer1_Tick(ByVal sender As System.Object, ByVal e As System.EventArgs) Handles Timer1.Tick

    gfxSTK1.CopyFromScreen(New Point(Me.Location.X + Stk1.Location.X + 5, Me.Location.Y + Stk1.Location.Y + 24), New Point(0, 0), picStc1.Size)
    Stk1.Image = picStc1

    gfxNAM1.CopyFromScreen(New Point(Me.Location.X + Nome1.Location.X + 5, Me.Location.Y + Nome1.Location.Y + 24), New Point(0, 0), picNam1.Size)
    Nome1.Image = picNam1
</code></pre>

<p>And when i pressed the button i get this :</p>

<pre><code>Private Sub Button1_Click(ByVal sender As System.Object, ByVal e As System.EventArgs) Handles Button1.Click

    OCRz.Recognize(New Image(Of Bgr, Byte)(picStc1))
    BOXSTK1.Text = OCRz.GetText

    OCRz.Recognize(New Image(Of Bgr, Byte)(picNam1))
    BoxNAME1.Text = OCRz.GetText
</code></pre>

<p>I now have the text read from the PictureBoxes (picStc1) and (picNam1) thru the OCR engine and its writen on the RichTextBoxes (BoxSTK1) and (NAME1) after i pressed the button. </p>

<p>The numbers on the RichTextBox (BoxSTK1) come with commas and other simbols but i just want to grab the numbers. So i found this (<a href=""https://code.google.com/p/tesseract-ocr/wiki/FAQ#How_do_I_recognize_only_digits"" rel=""nofollow"">https://code.google.com/p/tesseract-ocr/wiki/FAQ#How_do_I_recognize_only_digits</a>?) but i cant implement it on the project, any help on this?</p>

<p>(I´m using Emgu 2.9.0.1922, dont know how to see the version of Tesseract)</p>
",2018-03-07 02:57:52,2019-01-22 05:38:18,Only digits from tesseract - OCR on VB?,<vb.net><ocr><tesseract><digits><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
24044,24233313,2014-06-15 19:29:52,,"<p>I started programming with C# recently, for my studies. Right now I am diving into the world of Kinect and I am absolutely stunned of all the possibilities.</p>

<p>Currently I try to develop a program which is able to detect simple shapes. So far my Program works and is detecting basic shapes like triangles or rectangles. </p>

<p>But now I stumbled upon a problem with the detection of circles. The code from tutorial as seen here, doesn't work for my solution.</p>

<pre><code>Stopwatch watch = Stopwatch.StartNew();
double cannyThreshold = 180.0;
double circleAccumulatorThreshold = 120;

CircleF[] circles = gray.HoughCircles(
    new Gray(cannyThreshold),
    new Gray(circleAccumulatorThreshold),
    2.0,  // Resolution of the accumulator used to detect centers of the circles
    20.0, // min distance 
    5,    // min radius
    0     // max radius
    )[0]; // Get the circles from the first channel

watch.Stop();
msgBuilder.Append(String.Format(""Hough circles - {0} ms; "", watch.ElapsedMilliseconds));
</code></pre>

<p>I cannot find the reason, I do not get an error nor does debugging help me out (bear in mind I am a beginner). I use the helper class to ensure that EMGU works fine with the WPF-Image-Toolbox and as mentioned: the triangles and rectangles work. </p>

<p>For my code: I try to detect shapes in a certain depth area. For the I look at a ""slice"" of depth range and apply the following code:</p>

<pre><code>if(depthFrame != null)
{   
    depthSlice = depthFrame.SliceDepthImage(minVal, maxVal);
    Image&lt;Bgr, Byte&gt; sliced_img = new Image&lt;Bgr, byte&gt;(depthSlice.ToBitmap());
    Image&lt;Gray, byte&gt; buffer_img = sliced_img.Convert&lt;Gray, byte&gt;();

    List&lt;Triangle2DF&gt; triangleList = new List&lt;Triangle2DF&gt;();
    List&lt;MCvBox2D&gt; boxList = new List&lt;MCvBox2D&gt;();

    double cannyThreshold = 180.0;
    double circleAccumulatorThreshold = 120;

    CircleF[] circles = buffer_img.HoughCircles(
      new Gray(cannyThreshold),
      new Gray(circleAccumulatorThreshold),
      2.0,  // Resolution of the accumulator used to detect centers of the circles
      20.0, // min distance 
      5,    // min radius
      0     // max radius
      )[0]; // Get the circles from the first channel

    using(MemStorage storage = new MemStorage())
    {
        Contour&lt;System.Drawing.Point&gt; blobContours = buffer_img.FindContours(CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, RETR_TYPE.CV_RETR_EXTERNAL, storage);

        for(int i = 0; blobContours != null; blobContours = blobContours.HNext)
        {
           Contour&lt;System.Drawing.Point&gt; currentContours = blobContours.ApproxPoly(blobContours.Perimeter * 0.05, storage);

           if(currentContours.Area &gt; 200)
           {
              if (currentContours.Total == 3)
              {
                 System.Drawing.Point[] pts = currentContours.ToArray();
                 triangleList.Add(new Triangle2DF(pts[0], pts[1], pts[2]));
              }
              else if(currentContours.Total == 4)
              {
                 bool isRect = true;
                 System.Drawing.Point[] pts = currentContours.ToArray();
                 LineSegment2D[] edges = Emgu.CV.PointCollection.PolyLine(pts, true);

                 for (int a = 0; a &lt; edges.Length; a++)
                 {
                     double angle = Math.Abs(
                     edges[(a + 1) % edges.Length].GetExteriorAngleDegree(edges[a]));

                     if (angle &lt; 80 || angle &gt; 100)
                     {
                        isRect = false;
                        break;
                     }
                  }

                  if (isRect) 
                     boxList.Add(currentContours.GetMinAreaRect());
               }
            }

             /*  if(blobContours.Area &gt; 4000) // Generic Blob Detection
              *  {
              *      MCvBox2D contour_rectangle = blobContours.GetMinAreaRect();
              *      sliced_img.Draw(contour_rectangle, new Bgr(0, 255, 0), 4);
              *      blobCount++;
              *  }
              */
     }
}

foreach(Triangle2DF triangle in triangleList)
{
   sliced_img.Draw(triangle, new Bgr(0, 0, 255), 4);
}

foreach (MCvBox2D box in boxList)
{
   sliced_img.Draw(box, new Bgr(0, 255, 0), 4);
}

foreach (CircleF circle in circles)
{
   sliced_img.Draw(circle, new Bgr(255, 0, 0), 8);
   Console.WriteLine(circle.Center);
}

outImg2.Source = ImageHelpers.ToBitmapSource(sliced_img);
</code></pre>

<p>Am I doing something wrong? Or am I missing something? 
Greetings, and thanks in advance :)</p>
",2014-06-15 22:47:33,2016-11-10 12:49:46,Circle detection with Emgu and Kinect,<c#><geometry><shape><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
24058,25635764,2014-09-03 03:25:54,,"<p>I am creating a program that can dump individual frames from a video feed for a drones competition. I am having a problem where by the wireless video stream coming form the drone is flickering and flying all over the place.</p>

<p><img src=""https://i.stack.imgur.com/4wWkB.png"" alt=""Wireless Video Stream""></p>

<p>I am using this code to capture the video stream:</p>

<pre><code>Capture _capture;
Emgu.CV.Image&lt;Emgu.CV.Structure.Bgr,byte&gt; frame;

void StartCamera()
{
    _capture = null;
    _capture = new Capture((int)nudCamera.Value);
    _capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FPS, FrameRate);
    _capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, FrameHeight);
    _capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, FrameWidth);
    webcam_frm_cnt = 0;
    cam = 1;
    Video_seek = 0;
    System.Windows.Forms.Application.Idle += ProcessFrame;
}

private void ProcessFrame(object sender, EventArgs arg)
{
    try
    {
        Framesno = _capture.GetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_POS_FRAMES);
        frame = _capture.QueryFrame();
        if (frame != null)
        {
            pictureBox1.Image = frame.ToBitmap();
            if (cam == 0)
            {
                Video_seek = (int)(Framesno);
                double time_index = _capture.GetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_POS_MSEC);
                //Time_Label.Text = ""Time: "" + TimeSpan.FromMilliseconds(time_index).ToString().Substring(0, 8);
                double framenumber = _capture.GetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_POS_FRAMES);
                //Frame_lbl.Text = ""Frame: "" + framenumber.ToString();
                Thread.Sleep((int)(1000.0 / FrameRate));
            }
            if (cam == 1)
            {
                //Frame_lbl.Text = ""Frame: "" + (webcam_frm_cnt++).ToString();
            }
        }
    }
    catch (Exception ex)
    {
        MessageBox.Show(ex.Message.ToString());
    }
}
</code></pre>

<p>Is there a setting somewhere that I am missing?
This video stream flickering seems to happen in other programs too however it fixes itself when you fiddle with the video setting (NTSC/PAL settings)</p>

<p>Edit: So I need to be able to put the video stream into NTSC /M mode, is this possible with EmguCV? If so how do I do it?</p>

<p>Edit 2: All documents that I have read point towards it being completely and utterly impossible to change the video type and that there is no documentation on this topic. I would love to be proved wrong :)</p>

<p>Thanks in advanced</p>
",2018-02-08 16:32:55,2018-02-08 16:32:55,Video feed flickering/flying in C# using EmguCV,<c#><video-streaming><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
24063,23078488,2014-04-15 08:36:41,,"<p>I'm looking for help in solving my problem. I have a static camera, which is focus on one place. I download current view at every 1 second.</p>

<p>I would like to write a program which detects when someone moves the camera in a different direction. After that I would like to generate image with the shift. I am currently come up with this solution:</p>

<ol>
<li>Create a base frame, to which I compare all future frames.</li>
<li>Generate edge with Canny Edge algorithm.</li>
<li>Then I generate the corner points with Harris algorithm.</li>
<li>Then I want to compare the current frame with a base frame (picture, where are just corner points on black background) with calcOpticalFlowPyrLK (Lucas-Kanade method).</li>
</ol>

<p>Unfortunately I have problems, because depending on the lighting, the number of people, etc., the edges and corners are change. Because of this I don't know if there was a shift or not.</p>

<p>Can somebody give me some advices any solution how to detect shift?</p>

<p>Thanks for your help :)</p>
",2014-04-15 08:57:53,2014-04-15 09:36:29,How to detect shift in static camera?,<opencv><camera><emgucv><shift>,,,CC BY-SA 3.0,True,False,True,False,False
24066,24234635,2014-06-15 22:25:09,,"<p>There is a function called findNonZero to find the position of non-zero pixels in Opencv. I am wondering is there is something similar in Emgucv?</p>
",,2020-05-18 10:42:06,Is there a function in Emgucv to find non-zero pixels?,<opencv><pixel><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
24102,21968303,2014-02-23 12:39:49,,"<p>In the center of my room I have a camera.I have images from this camera from different angles like this <a href=""http://www.ex.ua/718372710658"" rel=""nofollow"">sample</a> where 1-camera,2,3,4-view from camera.
How to do 3d reconstruction from all this images?Need you help.I can not find good samle and turorial how to solve my trouble.I want to use emgu(opencv).But I am sure that it is correct.What can you advice?need all information </p>
",,2014-02-23 12:49:33,3d from 2d images emgu,<opencv><3d><2d><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
24126,25638280,2014-09-03 07:07:48,,"<p>I am trying <strong>to transform quadrilateral to rectangular plane</strong> And <strong>need to extract coordinate of 1 specific point (in quadrilateral plane), to that in respect to rectangular plane</strong>.. </p>

<p>I'm using EmguCV for image processing purpose in my .NET project</p>

<p>What I've tried is:</p>

<p>1) Calculate Homography matrix between quadrilateral and rectangular plane (specifying points in clockwise order from left top corner for both planes)</p>

<p>2) Multiply above Homography matrix by 3 x 1 matrix [x,y,1] to get final coordinates.</p>

<p>However, the resultant coordinate (x', y') does not seem in concordance with given point (x,y).</p>

<p><img src=""https://i.stack.imgur.com/pbnK7.jpg"" alt=""enter image description here""></p>
",2014-09-03 07:41:57,2014-09-03 10:48:50,"Perspective transform given point (x,y) in quadrilateral plane to Rectangle plane's point (x', y')?",<image><opencv><image-processing><emgucv><perspective>,,,CC BY-SA 3.0,True,False,True,False,False
24167,21975517,2014-02-23 22:26:02,,"<p>For a research project, I have to find the ellipses in a fossil image.
For each fossil image, I also have a CSV file containing the contour of the fossil, in cartesian coordinates.</p>

<p>I need help in determining the starting and ending points of each ellipses that are present in the fossil, so that I can apply a ellipse-fitting algorithm on them. </p>

<p>I started to look at the possibility of studying the variations in the different slopes of the contour.<br>
It somehow worked, until the point where I tried on fossils that have very low curve variations. As you can see on the image below (click the link), the pink points are where the variation of the slopes of the contours are the highest. However, it doesn't work for the bottom ellipse.</p>

<p><a href=""https://i.stack.imgur.com/B31Y5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/B31Y5.png"" alt=""fossil image""></a></p>

<p>So I need a new approach on that. Do you have any hints or ideas where I can look at ?</p>
",2016-01-06 07:33:23,2016-01-06 07:33:23,Intersecting ellipses recognition in image C#,<c#><image-processing><emgucv><bioinformatics><ellipse>,,,CC BY-SA 3.0,False,False,True,False,False
24229,20803615,2013-12-27 15:54:22,,"<p>I'm trying to write an application that detects coins in the image. I found a piece of code that uses the HoughCircles of Emgu CV. I can't, however, set the parameters so that I returned each coin (circles). Do you have any experience with this problem? Thank you for your advice.</p>

<p>This is code:</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Structure;

namespace INZO_Sem_Pr3_ST28605
{
public partial class Form1 : Form
{
    public Form1()
    {
        InitializeComponent();
        Bitmap bitmap = new Bitmap(pictureBox1.Image);

        //Load the image from file
        Image&lt;Bgr, Byte&gt; img = new Image&lt;Bgr, byte&gt;(bitmap);

        //Get and sharpen gray image (don't remember where I found this code; prob here on SO)
        Image&lt;Gray, Byte&gt; graySoft = img.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();
        Image&lt;Gray, Byte&gt; gray = graySoft.SmoothGaussian(3);
        gray = gray.AddWeighted(graySoft, 1.5, -0.5, 0);

        Image&lt;Gray, Byte&gt; bin = gray.ThresholdBinary(new Gray(70), new Gray(255));

        Gray cannyThreshold = new Gray(200);
        Gray cannyThresholdLinking = new Gray(100);
        Gray circleAccumulatorThreshold = new Gray(1000);

        Image&lt;Gray, Byte&gt; cannyEdges = bin.Canny(cannyThreshold.Intensity, cannyThresholdLinking.Intensity);

        pictureBox1.Image = cannyEdges.ToBitmap();

        //Circles
        CircleF[] circles = cannyEdges.HoughCircles(
            cannyThreshold,
            circleAccumulatorThreshold,
            1.0, //Resolution of the accumulator used to detect centers of the circles
            cannyEdges.Height / 8, //min distance 
            0, //min radius
            2000 //max radius
            )[0]; //Get the circles from the first channel

        //draw circles (on original image)
        foreach (CircleF circle in circles)
            img.Draw(circle, new Bgr(Color.Brown), 2);
    }
}
}
</code></pre>

<p>I read more explanations what these arguments mean, but i can't set good values.
This is result after use edge detection:
<img src=""https://i.stack.imgur.com/QbpfE.png"" alt=""enter image description here""></p>
",,2013-12-27 17:34:36,Wrong arguments in method HoughCircles from Emgu CV,<c#><emgucv><edge-detection>,,,CC BY-SA 3.0,False,False,True,False,False
24235,25649453,2014-09-03 16:34:33,,"<p>This is the code that I am using</p>

<pre><code>        int[] histogram = new int[256];
        for (int i = 0; i &lt; 256; i++)
        {
            histogram[i] = 0;
        }

        for (int i = 0; i &lt; img.Height; i++)
        {
            for (int j = 0; j &lt; img.Width; j++)
            {
                int n = (int)img.Data[i, j, 0];
                histogram[n] = histogram[n] + 1;
                //list.Add(n, hist[n]);
            }
        }

        float sum = 0;
        for (int i = 0; i &lt; 256; i++)
        {
            Console.WriteLine(""i = "" + i + "" hist = "" + histogram[i]);
        }
</code></pre>

<p>Could someone please help me as to why the values are being summed up at every 17 positions</p>

<pre><code>i = 0 hist = 52
i = 1 hist = 0  
i = 2 hist = 0
i = 3 hist = 0
i = 4 hist = 0  
i = 5 hist = 0
i = 6 hist = 0 
i = 7 hist = 0
i = 8 hist = 0
i = 9 hist = 0
i = 10 hist = 0
i = 11 hist = 0
i = 12 hist = 0 
i = 13 hist = 0 
i = 14 hist = 0 
i = 15 hist = 0
i = 16 hist = 0
i = 17 hist = 1025
</code></pre>

<p>And so on .....
Can someone please help me</p>
",,2014-09-03 16:34:33,Create black and white image pixel value histogram C# EmguCv,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
24251,24251677,2014-06-16 20:28:02,,"<p>Using EmguCV 2.4.2 I am getting a ""Video Source"" popup which prompts me to select a video device after instantiating a new instance of <code>Emgu.CV.Capture</code>. With earlier versions of EmguCV the constructor for <code>Emgu.CV.Capture</code> respected the <code>camIndex</code> parameter and activated the appropriate camera without further user interaction. This is pretty critical for my application where the user is not (and should not) be involved in the camera selection process. </p>

<p>The relevant code is below:</p>

<pre><code>var capture = new Emgu.CV.Capture(0);
</code></pre>

<p>Right after that line is called, the windows dialog pops up asking to pick the video device.</p>

<p>Has anyone else seen this and come up with a solution?</p>

<p>Thanks in advance.</p>

<p><strong>Edit 06/16/2014 @ 4:56PM CST</strong></p>

<p>I was able to get to a more meaningful error message under the covers. Basically what was happening is OpenCV was unable to create the Capture instance using camIndex 0. As a result, it was popping up the select video source dialog. </p>

<p>I was able to get this error message in version 2.9.0, version 2.4.2 and version 2.4.0. All of those versions give me an error “Error: Unable to create capture from camera 0”.</p>

<p>The only version that works with this device is version 2.3.1 and that is the version that does not allow me to change the resolution of the Capture instance.</p>
",2014-06-16 21:57:46,2014-06-16 21:57:46,Emgu CV Video Source Popup,<opencv><video><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
24335,25657886,2014-09-04 05:28:36,,"<p>I'm fairly new to image processing and that being said, I was hoping someone could tell me if I am on the right track and if not, point me in the right direction and/or provide some code samples.</p>

<p>The requirements I am working on:</p>

<ul>
<li>Detect the number of cookies on a baking sheet.</li>
<li>The cookies can be any color.</li>
<li>The cookies may be covered in chocolate (white or black) in which case they will have a mess of chocolate around each cookies meaning doing a simple contrast check probably won't work.</li>
<li>The cookies will not overlap but they may touch one another.</li>
</ul>

<p>I am trying to use the Emgu CV library with HoughCirlces but I am getting mixed results. Here is my code using winforms and C# in which I load an image of cookies on a baking sheet and run it on (I am not confident in my values).</p>

<p>Am I on the right track? Any ideas? Code samples?</p>

<p>Below are some test images:
<a href=""http://imgur.com/a/dJmU6"" rel=""nofollow noreferrer"">http://imgur.com/a/dJmU6</a>, followed by my code</p>

<p><img src=""https://i.imgur.com/RIcg6nn.jpg"" alt=""enter image description here""></p>

<p><img src=""https://i.imgur.com/rmtLHOZ.jpg"" alt=""enter image description here""></p>

<pre><code>private int GetHoughCircles(Image image)
    {
        Bitmap bitmap = new Bitmap(image);
        Image&lt;Bgr, Byte&gt; img = new Image&lt;Bgr, byte&gt;(bitmap).Resize(466, 345, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

        //Get and sharpen gray image (don't remember where I found this code; prob here on SO)
        Image&lt;Gray, Byte&gt; graySoft = img.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();
        Image&lt;Gray, Byte&gt; gray = graySoft.SmoothGaussian(3);
        gray = gray.AddWeighted(graySoft, 1.5, -0.5, 0);

        Image&lt;Gray, Byte&gt; bin = gray.ThresholdBinary(new Gray(149), new Gray(255));

        Gray cannyThreshold = new Gray(150);
        Gray cannyThresholdLinking = new Gray(120);
        Gray circleAccumulatorThreshold = new Gray(50);

        Image&lt;Gray, Byte&gt; cannyEdges = bin.Canny(cannyThreshold.Intensity, cannyThresholdLinking.Intensity);
        //Image&lt;Gray, Byte&gt; cannyEdges = bin.Canny(cannyThreshold, cannyThresholdLinking);

        //Circles
        CircleF[] circles = cannyEdges.HoughCircles(
            cannyThreshold,
            circleAccumulatorThreshold,
            3.0, //Resolution of the accumulator used to detect centers of the circles
            50.0, //min distance 
            20, //min radius
            30 //max radius
            )[0]; //Get the circles from the first channel

        //draw circles (on original image)
        foreach (CircleF circle in circles)
        {
            img.Draw(circle, new Bgr(Color.Brown), 2);
        }

        pictureBox1.Image = new Bitmap(img.ToBitmap());
        return circles.Count();
    }
</code></pre>
",2018-04-10 04:36:36,2018-04-10 04:36:36,Emgu CV to Detect Circular Cookies on a Baking Sheet,<c#><opencv><image-processing><emgucv><hough-transform>,,,CC BY-SA 3.0,True,False,True,False,False
24345,20812404,2013-12-28 08:07:56,,"<p>In my code, I'm receiving WriteableBitmaps from a byte array (in turn from a Kinect) and I'd like to turn them into bitmaps for use with EmguCV. Currently this is the code I have:</p>

<pre><code>                // Copy the pixel data from the image to a temporary array
                colorFrame.CopyPixelDataTo(this.colorPixels);

                // Write the pixel data into our bitmap
                this.colorBitmap.WritePixels(
                    new Int32Rect(0, 0, this.colorBitmap.PixelWidth, this.colorBitmap.PixelHeight),
                    this.colorPixels,
                    this.colorBitmap.PixelWidth * colorFrame.BytesPerPixel,
                    0);

                    BitmapEncoder encoder = new BmpBitmapEncoder();
                    encoder.Frames.Add(BitmapFrame.Create(colorBitmap));
                    MemoryStream ms = new MemoryStream();

                    encoder.Save(ms);
                    Bitmap b=new Bitmap(ms);

                    Image&lt;Gray, Byte&gt; img = new Image&lt;Gray, Byte&gt;(b);
                    img = img.ThresholdBinary(new Gray(200), new Gray(255));
</code></pre>

<p>I got the bottom half of the code from <a href=""https://stackoverflow.com/questions/10334110/how-to-convert-writeablebitmap-in-rgb24-pixel-format-into-a-emgucv-imagebgr-by"">here</a>.The code compiles and everything, but hangs when I'm trying to run the program (it's supposed to perform some operations on the image and then convert it back to a format that can be presented as an image.) Pausing my code and then using IntelliTrace in VS 2013, I get the following Exception  at <code>Image&lt;Gray, Byte&gt; img = new Image&lt;Gray, Byte&gt;(b);</code> ""A System.ArgumentException was thrown: URI formats are not supported."" Using alternate code, from where I go directly from byte to bitmap gives me the same error. (<a href=""https://stackoverflow.com/questions/11730373/byte-array-to-bitmap-image"">Code can be found here.</a>)</p>

<p>Anyone got tips on how to resolve this error, or alternate ways of casting to bitmap? I'm a newbie with C# &amp; EmguCV and I'd greatly appreciate it.</p>
",2017-05-23 12:19:09,2014-12-15 14:24:15,Converting WriteableBitmap to Bitmap for use in EmguCV,<c#><bitmap><kinect><emgucv><writeablebitmap>,,,CC BY-SA 3.0,False,False,True,False,False
24395,21994337,2014-02-24 17:12:50,,"<p>I need to be able to detect a variety of coloured post-it notes via a Microsoft Kinect video stream. I have tried using Emgucv for edge detection but it doesn't seem to locate the vertices/edges and also colour segmentation/detection however considering the variety of colours that may not be robust enough.</p>

<p>I am attempting to use HAAR classification. Can anyone suggest the best variety of positive/negative images to use. For example, for the positive images should I  take pictures of many different coloured post-it notes in various lighting conditions and orientations? Seeing as it is quite a simple shape ( a square) is using HAAR classification over-complicating things?</p>
",,2014-02-24 17:59:05,using HAAR training for post-it note recognition,<kinect><emgucv><object-detection><object-recognition><haar-classifier>,,,CC BY-SA 3.0,False,False,True,False,False
24404,20817685,2013-12-28 18:07:39,,"<p>In my winforms application I need to use some Emgu.CV libraries (I have installed Emgu 2.9).</p>

<p>Problem is that I get the following error: </p>

<pre><code>System.TypeInitializationException was unhandled
     HResult=-2146233036
     Message=The type initializer for 'Emgu.CV.OCR.Tesseract' threw an exception.
     Source=Emgu.CV.OCR
     TypeName=Emgu.CV.OCR.Tesseract
     StackTrace:
         at Emgu.CV.OCR.Tesseract..ctor(String dataPath, String language, OcrEngineMode mode)
         at ANPR.LicensePlateDetector..ctor(String dataPath) in c:\Users\blabla\Visual Studio 2012\Projects\ANPR\ANPR\LicensePlateDetector.cs:line 30
         at ANPR.Form1..ctor() in c:\Users\blabla\Visual Studio 2012\Projects\ANPR\ANPR\Form1.cs:line 22

   InnerException: System.TypeInitializationException
   HResult=-2146233036
   Message=The type initializer for 'Emgu.CV.CvInvoke' threw an exception.
   Source=Emgu.CV
   TypeName=Emgu.CV.CvInvoke
   StackTrace:
        at Emgu.CV.CvInvoke.CV_MAKETYPE(Int32 depth, Int32 cn)
        at Emgu.CV.OCR.Tesseract..cctor() in c:\Emgu\emgucv-windows-universal-cuda 2.9.0.1922\Emgu.CV.OCR\Tesseract.cs:line 26

   InnerException: System.DllNotFoundException
        HResult=-2146233052
        Message=Unable to load DLL 'opencv_core290': The specified module could not be found. (Exception from HRESULT: 0x8007007E)
        Source=Emgu.CV
        TypeName=""""
        StackTrace:
             at Emgu.CV.CvInvoke.cvRedirectError(CvErrorCallback errorHandler, IntPtr userdata, IntPtr prevUserdata)
             at Emgu.CV.CvInvoke..cctor() in c:\Emgu\emgucv-windows-universal-cuda 2.9.0.1922\Emgu.CV\PInvoke\CvInvoke.cs:line 266
</code></pre>

<p>This happens when trying to instantiate a new Tesseract object:</p>

<pre><code>var tesseract = new Tesseract("""", ""eng"", Tesseract.OcrEngineMode.OEM_TESSERACT_CUBE_COMBINED);
</code></pre>

<p>Since referencing ""opencv_core290"" does not work, I tried the workaround provided <a href=""http://www.codeproject.com/Articles/257502/Creating-Your-First-EMGU-Image-Processing-Project"" rel=""nofollow"">here</a>. Basically, I copied the .dll to my project, added it by using ""Add existing resource""
and modified it's property to ""Copy always"". This did not work however. Thanks for any help!</p>
",2013-12-28 22:54:55,2015-01-19 07:57:31,Unable to load DLL 'opencv_core290,<c#><winforms><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
24435,23112468,2014-04-16 14:31:53,,"<p>Based on below Part of  code, May i know how to passing the picturebox image in image cell iTextSharp in C# ? kindly advise. thank you</p>

<pre><code>Image&lt;Bgr, Byte&gt; img1 = new Image&lt;Bgr, Byte&gt;(Application.StartupPath + ""/TrainedFaces/"" + reader.GetString(11) + "".bmp"");
Application.Idle -= new EventHandler(ProcessFrame);
pictureBox1.Image = img1;
</code></pre>

<p>Shall I use string format ?</p>

<pre><code>cell = ImageCell(string.Format(""+ img1 +""), 25f, PdfPCell.ALIGN_CENTER);
</code></pre>
",2014-04-17 12:34:40,2014-04-17 12:34:40,How to pass the value in image cell in iTextSharp?,<c#><itextsharp><emgucv><opencvsharp>,,,CC BY-SA 3.0,False,False,True,False,False
24505,20825717,2013-12-29 13:42:27,,"<p>I'm trying to create a simple program that load a video file and show him in a ImageBox.</p>
<p>I'm using EMGU and OpenCV(for a later algorithm) in order to do it.</p>
<p>First I've got all the possible errors from EMGU, like</p>
<blockquote>
<p>Unable to load DLL 'opencv_core242'</p>
<p>The type initializer for 'Emgu.CV.CvInvoke' threw an exception.</p>
</blockquote>
<p>After I'm fixed them, a really strange thing is happened.</p>
<p>After the definition of the Capture, sometimes the program crashed and sometimes not.
It's not depend in the video, cause some video can be opened 1 time, but in the other time it can't.</p>
<p>This is my code(This is very basic code):</p>
<pre><code> public frmChild(String _url)
        {
            InitializeComponent();
            url = _url;



            if (_Capture != null)
                _Capture.Dispose();

            _Capture = new Capture(url);
         }
private void PlayButton_Click(object sender, EventArgs e)
        {

            if(Stopped || Paused)
                Application.Idle += ProcessFrame;

            Paused = false;
            Stopped = false;
        }

private void ProcessFrame(object sender, EventArgs arg)
        {
            imageBox1.Image = _Capture.QueryFrame();
        }
</code></pre>
<p>The program crashed in this line :</p>
<blockquote>
<p>_Capture = new Capture(url);</p>
</blockquote>
<p>This is the crash message:
<img src=""https://i.stack.imgur.com/4bCtC.png"" alt=""enter image description here"" /></p>
<p>What should I do?</p>
<p>Thanks</p>
",2020-06-20 09:12:55,2013-12-29 13:53:18,Program crashed after creating new EMGU.CV.Capture,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
24507,22002127,2014-02-25 00:27:32,,"<p>I am using kinect with emgucv in visual stdio 2010 with WPF!I want to get frame from kinect and convert it in grayscale using emgucv I have that!</p>

<p>void myKinect_ColorFrameReady(object sender, ColorImageFrameReadyEventArgs e)
        {</p>

<pre><code>        using (ColorImageFrame colorFrame = e.OpenColorImageFrame())
        {

            if (colorFrame == null) return;

            if (colorData == null)
                colorData = new byte[colorFrame.PixelDataLength];

            colorFrame.CopyPixelDataTo(colorData);

                if (colorImageBitmap == null)
                {
                    this.colorImageBitmap = new WriteableBitmap(
                        colorFrame.Width,
                        colorFrame.Height,
                        96,  // DpiX
                        96,  // DpiY
                        PixelFormats.Bgr32,
                        null);
                }

                this.colorImageBitmap.WritePixels(
                    new Int32Rect(0, 0, colorFrame.Width, colorFrame.Height),
                    colorData, // video data
                    colorFrame.Width * colorFrame.BytesPerPixel, // stride,
                    0   // offset into the array - start at 0
                    );


                Image&lt;Gray, Byte&gt; My_Image = new Image&lt;Gray, byte&gt;(BitmapFromSource(colorImageBitmap));
                kinectVideo.Source = ToBitmapSource(My_Image);


        }
    }


    private System.Drawing.Bitmap BitmapFromWriteableBitmap(WriteableBitmap writeBmp)
    {
        System.Drawing.Bitmap bmp;
        using (MemoryStream outStream = new MemoryStream())
        {
            BitmapEncoder enc = new BmpBitmapEncoder();
            enc.Frames.Add(BitmapFrame.Create((BitmapSource)writeBmp));
            enc.Save(outStream);
            bmp = new System.Drawing.Bitmap(outStream);
        }
        return bmp;
    }

    private System.Drawing.Bitmap BitmapFromSource(BitmapSource bitmapsource)
    {
        System.Drawing.Bitmap bitmap;
        using (MemoryStream outStream = new MemoryStream())
        {
            BitmapEncoder enc = new BmpBitmapEncoder();
            enc.Frames.Add(BitmapFrame.Create(bitmapsource));
            enc.Save(outStream);
            bitmap = new System.Drawing.Bitmap(outStream);

        }
        return bitmap;

    }

     [DllImport(""gdi32"")]
    private static extern int DeleteObject(IntPtr o);


     public static BitmapSource ToBitmapSource(IImage image)
    {
        using (System.Drawing.Bitmap source = image.Bitmap)
        {
            IntPtr ptr = source.GetHbitmap(); //obtain the Hbitmap

            BitmapSource bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
                ptr,
                IntPtr.Zero,
                Int32Rect.Empty,
                System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions());

            DeleteObject(ptr); //release the HBitmap
            return bs;
        }
    }
</code></pre>
",2014-02-25 23:58:18,2014-02-25 23:58:18,Convert ColorImageStream to Emgu cv Image,<c#><visual-studio-2010><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
24563,24270161,2014-06-17 17:42:51,,"<p>I am able to convert the emgu image format to a byte string and this does save on the MySQL database with this code, but the image is saved in a format not even recognized by windows image viewer</p>

<pre><code>            string myConnection = mydbconnection;

            MySqlConnection myConn = new MySqlConnection(myConnection);

            myConn.Open();

            Bitmap image = trained.ToBitmap();

            MemoryStream ms = new MemoryStream();

            image.Save(ms, System.Drawing.Imaging.ImageFormat.Bmp);

            byte[] picture = ms.ToArray();

            string formmattedPic = Convert.ToBase64String(picture);

            MySqlCommand cmd = new MySqlCommand(""INSERT INTO sql434250.facialid (timeanddate,photo1) VALUES(@named,@Trainedface)"",myConn);

            cmd.Parameters.Add(""@named"", MySqlDbType.VarChar).Value = named;
            cmd.Parameters.Add(""@Trainedface"", MySqlDbType.Blob);
            cmd.Parameters[""@Trainedface""].Value = formmattedPic;


                    cmd.ExecuteNonQuery();

                    label4.Text = named.ToString();

                    myConn.Close();
                }
</code></pre>

<p>My problem starts when I try to add the final image formatting I get a <code>system not supported</code> exception on the <code>fs = new FileStream(named, FileMode.Open, FileAccess.Read);</code> line, I am not sure how the filestream works, (new to C#) so please forgive me for any obvious mistakes in the code, for information I am on a windows 8 os, vs 2013</p>

<p>as here:</p>

<pre><code>            FileStream fs;

            BinaryReader br;


        byte[] ImageData;



       **fs = new FileStream(named, FileMode.Open, FileAccess.Read);**

        br = new BinaryReader(fs);

        ImageData = br.ReadBytes((int)fs.Length);

        br.Close();

        fs.Close();




            MySqlCommand cmd = new MySqlCommand(""INSERT INTO sql434250.facialid   (timeanddate,photo1) VALUES(@named,@Trainedface)"",myConn);

            cmd.Parameters.Add(""@named"", MySqlDbType.VarChar).Value = named;
            cmd.Parameters.Add(""@Trainedface"", MySqlDbType.Blob);
            cmd.Parameters[""@Trainedface""].Value = ImageData;


                    cmd.ExecuteNonQuery();
</code></pre>

<p>I am able to take converted  images saved on my pc and manually download via the MySQL site the images these images do work with the software, so to my shame I know its a coding error.</p>

<p>added database table as follows:</p>

<pre><code>CREATE TABLE `**yourdatabase**`.`facialid` (
`id` int( 11 ) NOT NULL AUTO_INCREMENT ,
`timeanddate` varchar( 30 ) NOT NULL ,
`photo1` longblob NOT NULL ,
`code1` varchar( 50 ) NOT NULL ,
`code2` varchar( 50 ) NOT NULL ,
`code3` varchar( 50 ) NOT NULL ,
 PRIMARY KEY ( `id` ) 
</code></pre>

<p>added full form code</p>

<pre><code>using System;
using System.Collections.Generic;
using System.Drawing;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.CV.CvEnum;
using System.IO;
using System.Diagnostics;
using MySql.Data.MySqlClient;
using System.Drawing.Imaging;


namespace MultiFaceRec
{
public partial class FrmPrincipal : Form
{
    //Declararation of all variables, vectors and haarcascades
    Image&lt;Bgr, Byte&gt; currentFrame;
    Capture grabber;
    HaarCascade face;
    HaarCascade eye;
    MCvFont font = new MCvFont(FONT.CV_FONT_HERSHEY_TRIPLEX, 0.5d, 0.5d);
    Image&lt;Gray, byte&gt; result, TrainedFace = null;
    Image&lt;Gray, byte&gt; gray = null;
    Image&lt;Gray, byte&gt; trained = null;
    Image image1 = null;
    List&lt;Image&lt;Gray, byte&gt;&gt; trainingImages = new List&lt;Image&lt;Gray, byte&gt;&gt;();
    List&lt;string&gt; labels= new List&lt;string&gt;();
    List&lt;string&gt; NamePersons = new List&lt;string&gt;();
    int ContTrain, t;
    string name, names = null;


    public FrmPrincipal()
    {
        InitializeComponent();
        //Load haarcascades for face detection
        face = new HaarCascade(""haarcascade_frontalface_default.xml"");
        //eye = new HaarCascade(""haarcascade_eye.xml"");
    }
    public void dbconnection()
    {

        grabber = new Capture();
        grabber.QueryFrame();
        //Initialize the FrameGraber event
        Application.Idle += new EventHandler(FrameGrabber);

        try
        {
            //Load of previus trainned faces and labels for each image

            string myConnection = **""youdbconnection""**
            MySqlConnection myConn = new MySqlConnection(myConnection);
            MySqlDataAdapter myAdapter = new MySqlDataAdapter();
            int totalrows = 0;
            int rownumber = 0;

  MySqlCommand SelectCommand = new MySqlCommand("" select * from     **yourdb**.facialid "", myConn);

             MySqlDataReader myReader;

            myConn.Open();

            myReader = SelectCommand.ExecuteReader();

            int count = 0;
            while (myReader.Read())
            {
                count = count + 1;

                string id = myReader.GetString(""id"");
                string Labelsinfo = myReader.GetString(""timeanddate"");
                string picdata = myReader.GetString(""photo1"");
                string LoadFaces;

                LoadFaces = myReader.GetString(""photo1"");
                byte[] picData = myReader[""photo1""] as byte[] ?? null;



               ImageConverter pic = new ImageConverter();
               Image img = (Image)pic.ConvertFrom(myReader[""photo1""]);
               Bitmap bitmap1 =  new Bitmap(img);


                trainingImages.Add(new Image&lt;Gray, byte&gt; (bitmap1));
                labels.Add(Labelsinfo);

                rownumber = count +1;
                totalrows = count;
                ContTrain = count;
                //string userid = myReader.GetString(""id"");
                //string useron = myReader.GetString(""user"");
}
            myReader.Close();
                myConn.Close();

            label2.Text = totalrows.ToString();


        }
        catch(MySqlException ex)
        {

            //MessageBox.Show(e.ToString());
          int errorcode = ex.Number;
            MessageBox.Show(""Nothing in binary database, please add at least a  face(Simply train the prototype with the Add Face Button)."", ""Triained faces load"",  MessageBoxButtons.OK, MessageBoxIcon.Exclamation);
        }

    }

    private void button2_Click(object sender, System.EventArgs e)
    {
        try
        {

            //Trained face counter
            ContTrain = ContTrain + 1;

            //Get a gray frame from capture device
            gray = grabber.QueryGrayFrame().Resize(320, 240,  Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

            //Face Detector
            MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
            face,
            1.2,
            10,
            Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
            new Size(20, 20));

            //Action for each element detected
            foreach (MCvAvgComp f in facesDetected[0])
            {

               trained =  currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;();
                TrainedFace = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;();

                break;
            }

            //resize face detected image for force to compare the same size with the 
            //test image with cubic interpolation type method
            TrainedFace = result.Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

            //string image;

            //Show face added in gray scale
            imageBox1.Image = TrainedFace;


            string named = DateTime.Now.ToString(""dd-MM-yy HH:mm:ss:ms"");

            string myConnection = **""your db connection""**

            MySqlConnection myConn = new MySqlConnection(myConnection);

            myConn.Open();

            Bitmap image = trained.ToBitmap();

            MemoryStream ms = new MemoryStream();

            image.Save(ms, System.Drawing.Imaging.ImageFormat.Bmp);

            byte[] picture = ms.ToArray();

            string formmattedPic = Convert.ToBase64String(picture);


            FileStream fs;

            BinaryReader br;


        byte[] ImageData;



       fs = new FileStream(named, FileMode.Open, FileAccess.Read);

        br = new BinaryReader(fs);

        ImageData = br.ReadBytes((int)fs.Length);

        br.Close();

        fs.Close();




            MySqlCommand cmd = new MySqlCommand(""INSERT INTO **yourdb**.facialid  (timeanddate,photo1) VALUES(@named,@Trainedface)"",myConn);

            cmd.Parameters.Add(""@named"", MySqlDbType.VarChar).Value = named;
            cmd.Parameters.Add(""@Trainedface"", MySqlDbType.Blob);
            cmd.Parameters[""@Trainedface""].Value = ImageData;


                    cmd.ExecuteNonQuery();

                    label4.Text = named.ToString();

                    myConn.Close();
                }


        catch (MySqlException ee)
        {
            int errorcode = ee.Number;

        }
        }


    void FrameGrabber(object sender, EventArgs e)
    {
        label3.Text = ""0"";
        //label4.Text = """";
        NamePersons.Add("""");


        //Get the current frame form capture device
        currentFrame = grabber.QueryFrame().Resize(320, 240,  Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

                //Convert it to Grayscale
                gray = currentFrame.Convert&lt;Gray, Byte&gt;();

                //Face Detector
                MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
              face,
              1.2,
              10,
              Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
              new Size(20, 20));

                //Action for each element detected
                foreach (MCvAvgComp f in facesDetected[0])
                {
                    t = t + 1;
                    result = currentFrame.Copy(f.rect).Convert&lt;Gray,  byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
                    //draw the face detected in the 0th (gray) channel with blue color
                    currentFrame.Draw(f.rect, new Bgr(Color.Red), 2);


                    if (trainingImages.ToArray().Length != 0)
                    {
                        //TermCriteria for face recognition with numbers of trained  images like maxIteration
                    MCvTermCriteria termCrit = new MCvTermCriteria(ContTrain, 0.001);

                    //Eigen face recognizer
                    EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
                       trainingImages.ToArray(),
                       labels.ToArray(),
                       1000,
                       ref termCrit);

                    name = recognizer.Recognize(result);

                        //Draw the label for each face detected and recognized
                    currentFrame.Draw(name, ref font, new Point(f.rect.X - 2, f.rect.Y - 2), new Bgr(Color.LightGreen));

                    }

                        NamePersons[t-1] = name;
                        NamePersons.Add("""");


                    //Set the number of faces detected on the scene
                    label3.Text = facesDetected[0].Length.ToString();

                    /*
                    //Set the region of interest on the faces

                    gray.ROI = f.rect;
                    MCvAvgComp[][] eyesDetected = gray.DetectHaarCascade(
                       eye,
                       1.1,
                       10,
                       Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                       new Size(20, 20));
                    gray.ROI = Rectangle.Empty;

                    foreach (MCvAvgComp ey in eyesDetected[0])
                    {
                        Rectangle eyeRect = ey.rect;
                        eyeRect.Offset(f.rect.X, f.rect.Y);
                        currentFrame.Draw(eyeRect, new Bgr(Color.Blue), 2);
                    }
                     */

                }
                    t = 0;

                    //Names concatenation of persons recognized
                for (int nnn = 0; nnn &lt; facesDetected[0].Length; nnn++)
                {
                    names = names + NamePersons[nnn] + "", "";
                }
                //Show the faces procesed and recognized
                imageBoxFrameGrabber.Image = currentFrame;


                //Clear the list(vector) of names
                NamePersons.Clear();

            }



    private void FrmPrincipal_Load(object sender, EventArgs e)
    {
        dbconnection();
    }

    private void label3_Click(object sender, EventArgs e)
    {

    }

    private void label4_Click(object sender, EventArgs e)
    {

    }

    private void label2_Click(object sender, EventArgs e)
    {

    }
  }

}
</code></pre>
",2014-06-17 18:43:39,2014-06-26 17:27:25,C# emgu saving an emgu captured image to a MySQL database,<c#><mysql><blob><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
24680,20840445,2013-12-30 13:22:35,,"<p>I have a question, I am using EmguCV for a school project to detect faces. It works.
But when I try to implement the EigenFace alogrithm, I find some thing that I don't understand. (I seached for it on the internet but it is only C# what I find).</p>

<p>My problem:</p>

<pre><code>Dim recognizer As New EigenFaceRecognizer(80, Double.PositiveInfinity)
recoginzer.train(..., ...)
</code></pre>

<p>The problem is that I don't know what I have to fill in at the ...
It says: images() as Emgu.CV.IImage
And: labels() as integer</p>

<p>So does anyone know what to fill in here?</p>

<p>Thanks in advance,
Lars Jansen
The Netherlands</p>
",,2013-12-30 21:37:22,EmguCV EigenFace recognizer VB.net IImage,<vb.net><opencv><emgucv><computer-vision>,,,CC BY-SA 3.0,True,False,True,False,False
24737,22021302,2014-02-25 17:10:02,,"<p>I'm trying to perform very basic blob detection with no success.  Simply using the VideoSurveillance example...it compiles and runs fine, but really doesn't detect blobs at all.  The FGDetector seems to work well, so I appear to get a good foreground, but the BlobTrackerAuto.Process hardly ever results in a blob being found...even when there appears to be a very prominent blob in the foregroundMask image.  Here is a code snippet showing how I capture and process the image.</p>

<pre><code>void ProcessFrame(object sender, EventArgs e)
  {
     Image&lt;Bgr, Byte&gt; frame = _cameraCapture.QueryFrame();

     frame._SmoothGaussian(3); //filter out noises

     _detector.Update(frame);

     Image&lt;Gray, Byte&gt; foregroundMask = _detector.ForegroundMask;                

     _tracker.Process(frame, foregroundMask);

     foreach (MCvBlob blob in _tracker)
     {
        frame.Draw((Rectangle)blob, new Bgr(255.0, 255.0, 255.0), 2);
        frame.Draw(blob.ID.ToString(), ref _font, Point.Round(blob.Center), new Bgr(255.0, 255.0, 255.0));
     }

     Image&lt;Bgr, Byte&gt; frameDisplay = frame.Resize(imageBox1.Width, imageBox1.Height, INTER.CV_INTER_LINEAR, false);
     Image&lt;Gray, Byte&gt; fgMaskDisplay = foregroundMask.Resize(imageBox2.Width, imageBox2.Height, INTER.CV_INTER_LINEAR, false);

     imageBox1.Image = frameDisplay;
     imageBox2.Image = fgMaskDisplay;
  }
</code></pre>

<p>And this is a sample image from the program, which shows (in my naive opinion) a very obvious blob that is not detected.</p>

<p><img src=""https://i.stack.imgur.com/XQJ3j.png"" alt=""Screen shot from my program""></p>

<p>It seems that there must be some way to configure the blob detection (threshold settings?) so that it knows how to discriminate foreground from background.</p>

<p>Any suggestions would be greatly appreciated.</p>
",,2020-09-07 13:53:29,Emgu CV Blob Detection -Video Surveillance Example,<opencv><blob><detection><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
24782,24292200,2014-06-18 18:00:41,,"<p>I'm trying to detect the circles in this image using EmguCV 2.2 with C#, but not having any luck.</p>

<p><img src=""https://i.stack.imgur.com/Ndh3z.png"" alt=""enter image description here""></p>

<p>Using OpenCV with the cv2 python package the following code correctly finds the 8 circles in the above image:</p>

<pre><code>img = cv2.imread('test2.png')   
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    circles = cv2.HoughCircles(gray, cv2.cv.CV_HOUGH_GRADIENT, 1, 10, param1=15, param2=10, minRadius=5, maxRadius=5)
</code></pre>

<p>For brevity I'll omit the code to draw the circles onto img, but for reference the output - assuming I use cv2.circle to fill each found circle with green, looks like:</p>

<p><img src=""https://i.stack.imgur.com/AS97h.png"" alt=""enter image description here""></p>

<p>However I can't seem to find those same circles using C#.</p>

<p>I've played around with the parameters quite, but trying code such as the following doesn't find any circles in the image:</p>

<pre><code>var gray = new Image&lt;Gray, byte&gt;(""test2.png"");
var circles = gray.HoughCircles(
                accumulatorThreshold: new Gray(16), dp: 1,
                cannyThreshold: new Gray(9),
                minDist: 10, minRadius: 4, maxRadius: 6)[0];
</code></pre>

<p>Any help finding those 8 circles with C# will be greatly appreciated!!</p>

<p>Thanks in advance for your help!</p>
",2014-06-18 18:07:34,2014-06-30 12:42:02,What are the differences between HoughCircles in EmguCV and OpenCV?,<c#><python><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
24802,22024646,2014-02-25 19:49:54,,"<p>I am using kinect!!I get a frame and then I convert it to bitmap in order to use Emgucv to convert frame in grayscale then convert bitmap to bitmpa source in order to show in window!I am usign C# visual studio WPF!But my program consume much CPU usage and in case the video is frozen for seconds!!I guess that is the conversion bitmpa source to bitmap and viceverse</p>

<pre><code>byte[] colorData = null;
WriteableBitmap colorImageBitmap = null;

void myKinect_ColorFrameReady(object sender, ColorImageFrameReadyEventArgs e)
{

    using (ColorImageFrame colorFrame = e.OpenColorImageFrame())
    {

        if (colorFrame == null) return;

        if (colorData == null)
            colorData = new byte[colorFrame.PixelDataLength];

        colorFrame.CopyPixelDataTo(colorData);

            if (colorImageBitmap == null)
            {
                this.colorImageBitmap = new WriteableBitmap(
                    colorFrame.Width,
                    colorFrame.Height,
                    96,  // DpiX
                    96,  // DpiY
                    PixelFormats.Bgr32,
                    null);
            }

            this.colorImageBitmap.WritePixels(
                new Int32Rect(0, 0, colorFrame.Width, colorFrame.Height),
                colorData, // video data
                colorFrame.Width * colorFrame.BytesPerPixel, // stride,
                0   // offset into the array - start at 0
                );


            Image&lt;Gray, Byte&gt; My_Image = new Image&lt;Gray, byte&gt;(BitmapFromSource(colorImageBitmap));
            kinectVideo.Source = ToBitmapSource(My_Image);


    }
}



private System.Drawing.Bitmap BitmapFromSource(BitmapSource bitmapsource)
{
    System.Drawing.Bitmap bitmap;
    using (MemoryStream outStream = new MemoryStream())
    {
        BitmapEncoder enc = new BmpBitmapEncoder();
        enc.Frames.Add(BitmapFrame.Create(bitmapsource));
        enc.Save(outStream);
        bitmap = new System.Drawing.Bitmap(outStream);

    }
    return bitmap;

}

 [DllImport(""gdi32"")]
private static extern int DeleteObject(IntPtr o);


 public static BitmapSource ToBitmapSource(IImage image)
{
    using (System.Drawing.Bitmap source = image.Bitmap)
    {
        IntPtr ptr = source.GetHbitmap(); //obtain the Hbitmap

        BitmapSource bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
            ptr,
            IntPtr.Zero,
            Int32Rect.Empty,
            System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions());

        DeleteObject(ptr); //release the HBitmap
        return bs;
    }
}
</code></pre>

<p>}</p>
",,2014-02-26 04:36:53,Convert Bitmap source to bitmap consume much CPU usage,<c#><wpf><c#-4.0><bitmap><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
24840,20852770,2013-12-31 06:17:36,,"<p>I've got the message above, while I'm trying to run my algorithm on more than 26 frames.</p>

<p>My program is in C#, with my experience with OpenCV in java(Android) I know that I need to release the matrix, do I need to do it here also?</p>

<p>this is the part with the problem:</p>

<pre><code> private void toolStripButton2_Click(object sender, EventArgs e)
        {  
            for (int i = 0; i &lt; FRAME_SIZE; i++)
            {
                ColorImage = _Capture.QueryFrame();
                if (ColorImage != null)
                {
                    GrayImage = ColorImage.Convert&lt;Gray, float&gt;();
                    toolStripProgressBar1.Value = i;
                    if (i == 0)
                    {
                        Max_G2 = new Image&lt;Gray, float&gt;(GrayImage.Width, GrayImage.Height);
                        mainimage = new Image&lt;Bgr, byte&gt;(GrayImage.Width, GrayImage.Height);
                    }
                    FindMax(GrayImage.Copy());
                }
                else
                {
                    toolStripStatusLabel1.Text = ""The video is too short!"";
                    break;
                }
            }
        }

private void FindMax(Image&lt;Gray, float&gt; CurrGray)
        {

            Image&lt;Gray, float&gt; TempImg = new Image&lt;Gray, float&gt;(CurrGray.Width, CurrGray.Height);

            Matrix&lt;float&gt; kernel1 = new Matrix&lt;float&gt;(new float[1, 2] { { -1, 1 } });
            Matrix&lt;float&gt; kernel2 = new Matrix&lt;float&gt;(new float[2, 1] { { -1 }, { 1 } });

            Point anchor = new Point(0, 0);

            CvInvoke.cvFilter2D(CurrGray, TempImg, kernel1, anchor);
            CvInvoke.cvFilter2D(CurrGray, CurrGray, kernel2, anchor);
            TempImg = TempImg.Pow(2);
            CurrGray = CurrGray.Pow(2);

            CurrGray = CurrGray.Add(TempImg);
            CurrGray = CurrGray.Pow(0.5);

            Max_G2._Max(CurrGray);
        }
</code></pre>

<p>1 more thing, I already tried to dispose all the matrix and images, but it doesn't work for me.
What do I miss here? </p>

<p>Thanks!</p>

<p><strong>EDIT 1: ( Code with dispose)</strong></p>

<pre><code>private void toolStripButton2_Click(object sender, EventArgs e)
        {
            for (int i = 0; i &lt; FRAME_SIZE; i++)
            {

                ColorImage = _Capture.QueryFrame();
                if (ColorImage != null)
                {
                    GrayImage = ColorImage.Convert&lt;Gray, float&gt;();

                    toolStripProgressBar1.Value = i;
                    if (i == 0)
                    {
                        Max_G2 = new Image&lt;Gray, float&gt;(GrayImage.Width, GrayImage.Height);
                        TempImg = new Image&lt;Gray, float&gt;(GrayImage.Width, GrayImage.Height);
                        mainimage = new Image&lt;Bgr, byte&gt;(GrayImage.Width, GrayImage.Height);
                    }
                    FindMax(GrayImage);

                    ColorImage.Dispose();
                    ColorImage = null;
                    GrayImage.Dispose();
                    GrayImage = null;

                    Thread.Sleep(100);
                }
                else
                {
                    toolStripStatusLabel1.Text = ""The video is too short!"";
                    break;
                }
            }

        }

private void FindMax(Image&lt;Gray, float&gt; CurrGray)
        {



            Matrix&lt;float&gt; kernel1 = new Matrix&lt;float&gt;(new float[1, 2] { { -1, 1 } });
            Matrix&lt;float&gt; kernel2 = new Matrix&lt;float&gt;(new float[2, 1] { { -1 }, { 1 } });

            Point anchor = new Point(0, 0);

            CvInvoke.cvFilter2D(CurrGray, TempImg, kernel1, anchor);
            CvInvoke.cvFilter2D(CurrGray, CurrGray, kernel2, anchor);

            TempImg.Pow(2);
            CurrGray.Pow(2);

            CurrGray.Add(TempImg);
            CurrGray.Pow(0.5);

            Max_G2._Max(CurrGray);

            CurrGray.Dispose();
            CurrGray = null;

        }
</code></pre>
",2013-12-31 08:09:31,2013-12-31 08:09:31,"EMGU -"" Exception of type 'System.OutOfMemoryException' was thrown.""",<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
24894,24299467,2014-06-19 05:39:00,,"<p>I have this code in my project:</p>

<pre><code>MCvFont font = new MCvFont(FONT.CV_FONT_HERSHEY_SCRIPT_SIMPLEX, 0.2d, 0.2d); 
</code></pre>

<p>When program runs, It gives an exception: </p>

<blockquote>
  <p>The type initializer for 'Emgu.CV.CvInvoke' threw an exception.</p>
</blockquote>

<p>So please help me with on this issue.</p>
",2014-06-19 05:43:36,2020-09-29 19:03:40,Error:The type initializer for 'Emgu.CV.CvInvoke' threw an exception,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
24922,24302085,2014-06-19 08:30:36,,"<p>I have two side by side Emgu imagebox and I want their size to be relative to that of the users screen size (33% of the screens width). I tried to set it using something like this in the main form:</p>

<pre><code>rectangle screen = Screen.PrimaryScreen.Bounds;
int screenHeight = (screen.Height/2);
int screenWidth = screenHeight;
</code></pre>

<p>and then setting the size to these in the designer form but that just led it to not load the imagebox at all. If anyone knows how to do it with a pictureBox, that may work too. </p>

<p>Here is a picture of my form to help get an idea of what I am trying to achieve. I would like to have these proportions on a screen of any size. Like the % feature in css.</p>

<p><a href=""http://oi59.tinypic.com/dwdf12.jpg"" rel=""nofollow"">http://oi59.tinypic.com/dwdf12.jpg</a> (I have linked it due to lack of reputation)</p>
",2014-06-19 09:19:19,2014-06-30 14:26:45,How to set a emgu imagebox size to a percentage of screen size,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
24935,19708635,2013-10-31 14:02:13,,"<p>I feel like I've tried a bunch of different things but I cannot get passed this error.</p>

<pre><code>An attempt was made to load a program with an incorrect format. (Exception from HRESULT: 0x8007000B)
</code></pre>

<p>Below is the VS2012 solution I am using to create an Image to Text spike using the EMGU engine.</p>

<p>Would someone please take a look and give my solution a try?</p>

<p><a href=""http://andrewherrick.com/spike/img2text.zip"" rel=""nofollow noreferrer"">http://andrewherrick.com/spike/img2text.zip</a></p>

<p><img src=""https://i.stack.imgur.com/WZdB5.png"" alt=""enter image description here""></p>
",2013-10-31 14:37:56,2013-10-31 14:49:20,Visual Studio 2012 Simple EMGU Image to Text Solution Error,<image-processing><ocr><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
24963,26827693,2014-11-09 11:30:25,,"<p>I want to init an array of contours. The foliwing works so far:</p>

<pre><code>Contour&lt;Point&gt; control_shapes1 = new Contour&lt;Point&gt;(new MemStorage());
Contour&lt;Point&gt;[] control_shapes = new Contour&lt;Point&gt;[13];
</code></pre>

<p>but this don't work:</p>

<pre><code>Contour&lt;Point&gt;[] control_shapes = new Contour&lt;Point&gt;(new MemStorage())[13];
</code></pre>

<p>nether this:</p>

<pre><code>Contour&lt;Point&gt;[] control_shapes = new Contour&lt;Point&gt;[13](new MemStorage());
</code></pre>

<p>(I should mention that all this is done in the global area for the first try. Later i will try to do it better, but for the moment ...)</p>

<p>How is the initialization done correctly ?</p>

<p>or is this impossible ?</p>

<p>Thanks for your help.</p>
",,2014-11-09 12:08:00,How to init an array of contours using memstorage,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
24990,22040658,2014-02-26 11:57:31,,"<p>I have a C# winform app.
I am utilising Emgu framework to help me to detect motion between frames.</p>

<p>I have 1 issue.  At night time or when it is a dull image due to a dull day and the object I want to detect has low value colours (like black and brown and dark green) it is sometimes difficult to detect this motion.</p>

<p>I had hit upon the idea of enhancing the image when it is a dull image frame.</p>

<p>I would 1st have to work out the 'average' contrast of an image to determine whether I need to increase the contrast of that image.</p>

<p>What would be the best way to do this?</p>

<p>I have converted the RGB image to an HSV image. But I am unsure which values/channels to use to perceive whether the overall image is low in contrast.</p>

<p>I have looked around for a formula that would measure this based on Hue, Saturation and Luminance/brightness,</p>

<p>So far I have this:</p>

<p>C = ((100.0 + T) / 100.0)2 taken from this site: <a href=""http://softwarebydefault.com/2013/04/20/image-contrast/"" rel=""nofollow"">enter link description here</a></p>

<p>'T' is defined as the variable Threshold.  Now this is where I come unstuck. 
What is this variable threshold? 
What should I base it on?  </p>

<p>Should I look elsewhere for an answer?</p>
",2014-02-26 12:02:22,2014-02-26 12:36:26,How to improve dull images,<c#><winforms><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
25020,22043911,2014-02-26 14:10:25,,"<p>I am doing some basic image processing to detect polygons and a bit of OCR to process a flow chart drawn on white boards using Emgu CV on C#.</p>

<p>But now, I am facing difficulties <b>detecting arrows</b> (straight lines with a pointed &lt; or >) in any direction.
I am wondering if anyone is aware of a method that I can use to detect arrows and their <b>pointing end</b>. From then, I can find nearby objects and go ahead with more processing.</p>

<p>I would <i>greatly</i> appreciate any suggestions anyone might have.</p>

<p>Thank you!</p>
",2014-08-05 11:44:10,2019-01-11 07:28:39,How do I use Emgu CV to detect arrows in an image?,<c#><opencv><detect><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
25040,20866563,2014-01-01 07:34:59,,"<p><img src=""https://i.stack.imgur.com/RWAG4.png"" alt=""enter image description here""></p>

<p>Basically what I want to do is to filter out only the liquid region of the bottle for further processing. So the next processes would apply only for that region.</p>

<p>I've tried various methods for months but didn't have any luck. I can filter out the region between the top liquid boundary and the top of the bottom dark region. But that doesn't serve my purpose as I need the areas at the sides of the dark region at the bottom of the bottles too. Im trying to do this in openCV/EmguCV. </p>

<p>help please...</p>
",,2014-01-03 23:58:34,Cropping the liquid region of a bottle for processing,<opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
25054,22047066,2014-02-26 16:16:40,,"<p>I'd like to be able to detect if a camera's line of sight has been changed, thus seeing a sudden change in the background.  Surely there's a clever way to do this?</p>

<p>When it comes to tracking changes in a video stream, it seems most of the work is related to separating the background from the foreground so that objects moving around in the image(s) can be identified using background subtraction or the like.</p>

<p>I'm using EmguCV (OpenCV) as my tool of choice...in case there's any particular suggestions around available algorithms in this tool set.  I've looked experimented with the background/foreground subtractors available in Emgu.  They're not bad for detecting foreground changes, but I don't see how to use them to watch for this type of event.  Surely I'm overlooking something obvious.</p>

<p>Thanks.</p>
",,2014-02-26 17:48:18,How to detect a background change in image processing?,<opencv><image-processing><emgucv><background-subtraction>,2014-02-27 08:57:56,,CC BY-SA 3.0,True,False,True,False,False
25159,26845796,2014-11-10 14:14:18,,"<p>Can you have TOO MUCH training data or not?
I am working on a system that will update training data when a user gives it feedback of a mistake it has made in an attempt to not make the same mistake again (i.e if the user looks a little different to their usual training images, it will add the new capture of them to training data). 
Will this decrease performance at all? Should there be a maximum? Would it be better just to have the same training set and just accept the fail rate instead of trying to improve it?</p>

<p>Cheers!</p>
",2014-11-10 14:18:10,2014-11-10 14:31:39,Eigenfaces facial recognition training data,<opencv><face-recognition><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
25160,26845877,2014-11-10 14:18:50,,"<p>I try to get some text of an image by using OCR. I have to initialize a Tesseract for that and this was my try:</p>

<pre><code>Imports Emgu.CV
Imports Emgu.Util
Imports Emgu.CV.Structure
Imports Emgu.CV.OCR
Imports Emgu.CV.UI
Imports Emgu.CV.CvEnum

Public Class Form1

    Private Sub Button1_Click(sender As Object, e As EventArgs) Handles Button1.Click

        Dim lolProcess() As Process = Process.GetProcessesByName(""lolClient"")
        Dim snap As New CScreenFromWindow

        Dim OCRz As Tesseract = New Tesseract(""tessdata"", ""eng"", Tesseract.OcrEngineMode.OEM_TESSERACT_ONLY)

        OCRz.Recognize(New Image(Of Bgr, Byte)(snap.GetFromAll(lolProcess(0))))
        MsgBox(OCRz.GetText())

    End Sub
End Class
</code></pre>

<p>When launching my code I get the following error:
""System.TypeInitializationException""
""Emgu.CV.OCR.Tesseract"" caused an exception</p>

<p>I have googled a lot, but can't find my mistake. I've downloaded EMGU from <a href=""http://sourceforge.net/projects/emgucv/files/emgucv/2.4.9-beta/"" rel=""nofollow"">this link</a> and installed the .exe. Then I added every .dll from the bin-directory as a reference to my project. I also added all opencv_XXXXX.dll-files to my project. Then I also added the tessdata-directory to my project. I've marked all the added dlls as ""Always copy to output-directory"". </p>

<p>There are opencv_XXXXXX.dll-files for x86 and x64. I tried to swap them to x64 but those also don't work.</p>

<p>Does anybody see my mistake? </p>

<p>This are the error-messages and stack-traces:</p>

<pre><code>   System.ArgumentException: Unable to create ocr model using Path tessdata and language eng.
   bei Emgu.CV.OCR.Tesseract.Init(String dataPath, String language, OcrEngineMode mode) in c:\Emgu\emgucv-windows-universal-gpu 2.4.9.1847\Emgu.CV.OCR\Tesseract.cs:Zeile 226.
   bei Emgu.CV.OCR.Tesseract..ctor(String dataPath, String language, OcrEngineMode mode) in c:\Emgu\emgucv-windows-universal-gpu 2.4.9.1847\Emgu.CV.OCR\Tesseract.cs:Zeile 118.
   bei Dodgemaster.Form1.Button1_Click(Object sender, EventArgs e) in X:\Dokumente\Visual Studio 2013\Projects\Dodgemaster\Dodgemaster\Form1.vb:Zeile 16.
</code></pre>

<p>A Hello World test-programm works fine. So it can't be something wrong with the references, right?</p>
",2014-11-10 17:44:19,2016-01-04 10:44:07,Initializing a Tesseract,<vb.net><ocr><tesseract>,,,CC BY-SA 3.0,True,False,True,False,False
25224,24325867,2014-06-20 11:07:04,,"<p>I need to find the rotation angle between two binary images. SO I can correct the rotation by rotating the images by the specified angle. Can someone help please? <img src=""https://i.stack.imgur.com/wIQyP.jpg"" alt=""image1""></p>

<p><img src=""https://i.stack.imgur.com/jjS08.jpg"" alt=""rotated image""></p>

<p>I already tried the Principle axis rotation angle but It doesn't give accurate result. Can some one suggest me a better method. And this image an be anything. It need not to be the image I uploaded here. But all the images are binary.</p>
",2014-06-20 11:15:40,2014-06-20 17:20:42,How to find the rotation between two binary images,<opencv><image-processing><rotation><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
25242,26852564,2014-11-10 20:38:04,,"<p>I have two versions of this app below.  This one, and a rewrite I wrote to work with 8 bit images.  8 bit images work fine.  16 bit images cause Image.Threshold to crash in the native OpenCV call for threshold, the only error returned:</p>

<p>A first chance exception of type 'Emgu.CV.Util.CvException' occurred in Emgu.CV.dll
Additional information: OpenCV: </p>

<p>The below causes a crash on my ""hand coded"" 16 bit image, it also crashes on a 16 bit TIF image, loaded via</p>

<pre><code>var img = new Image&lt;Gray,UInt16&gt;(""test.tif"");
</code></pre>

<p>The crashes are identical, with identical error messages.</p>

<p>Here's my app:</p>

<p>Thoughts?</p>

<pre><code>using System;
using System.Runtime.InteropServices;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.CV.UI;
using Microsoft.VisualStudio.TestTools.UnitTesting;

namespace MyUnitTest
{
    [TestClass]
    public class UnitTestOpenCV
    {
        // Set up an image with a solid rectangle in it.
        private IntPtr _smallImg;
        private const int Ncols = 500;
        private const int Nrows = 100;

        [TestInitialize]
        public void Init()
        {
            const int n = Ncols * Nrows;
            var pixels = new short[n];
            _smallImg = Marshal.AllocHGlobal(n * 2);
            Marshal.Copy(pixels, 0, _smallImg, pixels.Length);
            for (int col = 75; col &lt; 75 + 200; col++)
            {
                for (int row = 25; row &lt; 25 + 50; row++)
                {
                    Marshal.WriteInt16(_smallImg, 2 * (row * Ncols + col), 10000);
                }
            }
        }

        [TestCleanup]
        public void Cleanup()
        {
            Marshal.FreeHGlobal(_smallImg);
        }

        [TestMethod]
        public void FindingMinBoundingRectangle()
        {
            var img = new Image&lt;Gray, ushort&gt;(Ncols, Nrows, Ncols, _smallImg);
            var rotatedImg = img.Rotate(20, new Gray(0), false);
            var bwImg      = img.ThresholdBinary(new Gray(5000), new Gray(255));
            var contour    = bwImg.FindContours();
            var rect = contour.GetMinAreaRect();
            rotatedImg.Draw(rect, new Gray(30000), 50);
            rotatedImg.Save(""img.tif"");
            AOIAlgorithmsBase.SaveImage(""myImg.tif"", img.MIplImage.imageData, Ncols, Nrows, Ncols);
            ImageViewer.Show(rotatedImg, ""Image Viewer Window"");
        }
    }
}
</code></pre>
",2014-11-11 19:32:18,2014-11-11 19:48:23,16 bit image crashes Image.ThresholdBinary in EMGU.CV,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
25264,25414399,2014-08-20 21:04:45,,"<p>I'm unfortunately struggling with this. I have a project that is mixed with Emgu and OpenCvSharp.  Sounds odd but there are reasons.</p>

<p>At any rate, what I have is an EMGU.CV.Image that I'd like to use to populate an OpenCvSharp IplImage</p>

<p>I'm assuming this is possible, however I cannot wrap my head around it.</p>

<p>Relevant snippet of code (C#):</p>

<pre><code>            FrameCapture = Cv.CreateFileCapture(@""C:\test\vid1.mp4"");

            var frm = cap.QueryFrame();
            var frameBmp = frm.Bitmap;

            IplImage curFrame = ??? &lt;&lt;====== I'd like to create curFrame based on frameBmp
</code></pre>
",,2014-10-01 13:46:38,Convert Bitmap to OpenCvSharp IplImage,<c#><opencv><image-processing><emgucv><opencvsharp>,,,CC BY-SA 3.0,True,False,True,False,False
25276,25734576,2014-09-08 23:25:48,,"<p>I'm working with Emgu CV to determine whether or not an area of an image contains some arbitrary shape. I'm new to both the Open and Emgu libraries (and their communities), and fear am over my head, but here goes.</p>

<p>The images are scanned forms (paper documents), where the ""user"" circles/checks/blarfs a given area. For example, let's say i have a simple paper form which contains one group with three items. The group is ""gender"", and the available choices are ""male"", ""female"", and ""other"". User X writes a check mark through ""female""; user Y circles ""other""; and user Z draws a nice unicorn next to ""male"". </p>

<p>Now, I have examples of forms where no marks exist. I simply use a nested template match to 1) find the ""gender"" group, and 2) find the item (male, female, other) within the gender group's sub image (performance is secondary to accuracy right now). Then I blur (Gaussian) and binarize the resultant image(thresholding tuned per form), and take a 2 bin histogram. I compare the normalized template and observed histograms, and get a Boolean result (true: arbitrary shape present/false: shape not present).</p>

<p>This process is ok, but not great. I have 4 forms with ~500 fields, and a mean of 70% accuracy. The output of this program is feeding a predictive model, and the forms' fields are strong predictor candidates, so I'd like to bump the correct/total ratio up a few notches (ideally > .90).</p>

<p>I've tried contour comparison, but this has been inaccurate due to poor scan quality, low ink levels on the scanned image, different lengths of vectors between markings/form types, etc.</p>

<p>So (finally!) my question is: Are any Open/Emgu CV experts out there who have some better ideas about how to detect markings on a scanned document? If the scenario and question are too vague, I'll gladly clear them up. Code samples (C++, C#, Python) are welcome. </p>
",2014-09-08 23:48:35,2014-09-08 23:48:35,Detecting arbitrary shapes in a scanned image,<c#><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
25282,27605961,2014-12-22 15:49:44,,"<p>I am reading color frame from Kinect V2 sensor using Microsoft Kinect SDK v2. I am copying the frame data in a byte array, which is later on converted into EmguCV Image. Below is the snippet from the code-</p>

<pre><code>// A pixel buffer to hold image data from the incoming color frame
private byte[] pixels = null;
private KinectSensor kinectSensor = null;
private ColorFrameReader colorFrameReader = null;
public KinectForm()
{
    this.kinectSensor = KinectSensor.GetDefault();
    this.colorFrameReader = this.kinectSensor.ColorFrameSource.OpenReader();
    this.colorFrameReader.FrameArrived += this.Reader_ColorFrameArrived;
    // create the colorFrameDescription from the ColorFrameSource using Bgra format
    FrameDescription colorFrameDescription = this.kinectSensor.ColorFrameSource.CreateFrameDescription(ColorImageFormat.Bgra);
    // Create a pixel buffer to hold the frame's image data as a byte array
    this.pixels = new byte[colorFrameDescription.Width * colorFrameDescription.Height * colorFrameDescription.BytesPerPixel];
    // open the sensor
    this.kinectSensor.Open();
    InitializeComponent();
}

private void Reader_ColorFrameArrived(object sender, ColorFrameArrivedEventArgs e)
{
    using (ColorFrame colorFrame = e.FrameReference.AcquireFrame())
    {
        if (colorFrame != null)
        {
            FrameDescription colorFrameDescription = colorFrame.FrameDescription;
            if (colorFrame.RawColorImageFormat == ColorImageFormat.Bgra)
                colorFrame.CopyRawFrameDataToArray(pixels);
            else
                colorFrame.CopyConvertedFrameDataToArray(this.pixels, ColorImageFormat.Bgra);

            //Initialize Emgu CV image then assign byte array of pixels to it
            Image&lt;Bgr, byte&gt; img = new Image&lt;Bgr, byte&gt;(colorFrameDescription.Width, colorFrameDescription.Height);
            img.Bytes = pixels;

            imgBox.Image = img;//Show image in Emgu.CV.UI.ImageBox
        }
    }
}
</code></pre>

<p>The converted image is corrupted after zooming more than 25%. Please see below screenshots-</p>

<p>50% Zoom -
<img src=""https://i.stack.imgur.com/lsz8o.png"" alt=""50% Zoom""></p>

<p>25% Zoom -
<img src=""https://i.stack.imgur.com/bKHBm.png"" alt=""25% Zoom""></p>

<p>12.5% Zoom -
<img src=""https://i.stack.imgur.com/Q67ju.png"" alt=""12.5% Zoom""></p>
",,2015-05-19 06:02:54,Image corrupted after zooming,<image><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
25296,27709279,2014-12-30 16:48:34,,"<p>I am using EmguCV (a C# wrapper of OpenCV) and I can find contours using FindContours as:</p>

<pre><code>        Contour&lt;Point&gt; cnts;
        cnts = imgLineMask.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_NONE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST);

        for (; cnts != null; cnts = cnts.HNext)
        {
            double ar = cnts.Area;
        }
</code></pre>

<p>However, their area and moments are all zero if the contours are just one or two pixels big. Is there anyway to make it work with such small contours? Or it just simply can not work with very small contours?</p>

<p>Thanks</p>
",2015-01-17 00:14:57,2015-01-23 19:11:26,Finding small contours in OpenCV,<opencv><emgucv><contour>,,,CC BY-SA 3.0,True,False,True,False,False
25362,24339843,2014-06-21 08:36:44,,"<p>How to draw a minimum enclosing circle around a contour in EmguCV?. FindContours() method returns a set of points. But to draw the circle it asks for pointf. Is there a work around this? Thanks.</p>
",,2014-07-12 08:06:54,Draw minimum enclosing circle around a contour in EmguCV,<opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
25365,27609987,2014-12-22 20:31:55,,"<p>I have a rather large VS2012 solution consisting of several projects which utilize the EMGU libraries.</p>

<p>The projects run successfully on one computer. However, when I try to copy the whole solution directory I come across an error: ""The type initializer for 'Emgu.CV.CvInvoke' threw an exception""</p>

<p>Any advice on how to correct this issue?</p>
",,2014-12-22 20:31:55,Emgu error when trying to copy VS2012 solution to another computer,<visual-studio-2012><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
25387,20902323,2014-01-03 11:13:49,,"<p>I have a EmguCv.Capture in 'Movie' class.
I want to create a function that get a frame number and return this frame, like:</p>

<pre><code>using Emgu.CV;
using Emgu.CV.Structure;

Class Movie
{
   private Capture capture;
   public Movie(string FileName)
   {
     capture=new Capture(FileName);
     ...
   }
   public Image&lt;Bgr, byte&gt; GetFrame(int FrameNum)
   {
    //return the FrameNum frame
   }
}
</code></pre>

<p>I need to do that as quickly as possible.
Any ideas?</p>
",2014-01-03 11:20:19,2014-02-18 13:03:21,Get specific frames using EmguCv,<c#><video-capture><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
25507,24351785,2014-06-22 13:35:44,,"<p>I've tried to code a face recognition program and need some help from the community. The code posted below compiled with no error and the recognizer working if the <strong>threshold</strong> that i set is 0, if i set the threshold > 0 its display Unknown Face definitely. <br>
I am using 4 training image for a person. <br>
Face in Database : <br>
<strong>PersonA:</strong><br>
- PersonA1, PersonA2, PersonA3, PersonA4<br>
<strong>PersonB:</strong><br>
- PersonB1, PersonB2, PersonB3, PersonB4<br>
<strong>Scenario Example:</strong><br>
If new person (none in database) face detected lets called <strong>PersonC</strong>, but the program always display name from database between PersonA or PersonB.<br><br>
How to display new detected face / PersonC as Unknown Face if there are no face in database. Any idea on where have i gone wrong? Thanks in advance.</p>

<p>I'm using emgu cv 2.2.1.1150 with c# 2010 express<br>
<strong>imgRecognizer Initialization:</strong></p>

<pre><code>private void AttendanceForm_Load(object sender, EventArgs e)
{
    dbFA = new FRAttendance_DBDataContext();
    timer.Start();
    face = new HaarCascade(""haarcascade_frontalface_alt_tree.xml"");
    Scanner = new Capture();
    Scanner.QueryFrame();
    Application.Idle += new EventHandler(StartCamera);
    try
    {
    LoadData();
    ImageToList();
    MCvTermCriteria termCrit = new MCvTermCriteria(rowCount, 0.001);
    imgRecognizer = new EigenObjectRecognizer(trainingImages.ToArray(), personsLabel.ToArray(), 1000, ref termCrit);
    }
    catch (Exception err)
    {
        MessageBox.Show(err.ToString());
    }
}
</code></pre>

<p><strong>Recognizer Function :</strong></p>

<pre><code>private void btnScan_Click(object sender, EventArgs e)
{
    if (trainingImages.ToArray() != null)
    {
        try
        {
            faceImgLabel = imgRecognizer.Recognize(result);
            if (faceImgLabel.Trim().Equals(""""))
            {
                txtHSID.Text = ""Unknown"";
                txtHSName.Text = ""Unknown"";
                MessageBox.Show(""Unknown Face"", ""Information"", MessageBoxButtons.OK, MessageBoxIcon.Warning);
            }
            else
            {
                logMeIn(faceImgLabel);
            }
        }
        catch(Exception errScan)
        {
            MessageBox.Show(errScan.ToString());
            MessageBox.Show(""Wait until face detected"", ""Information"", MessageBoxButtons.OK, MessageBoxIcon.Information);
        }
    }
    else
        MessageBox.Show(""No image in collection list"", "" Information "", MessageBoxButtons.OK, MessageBoxIcon.Information);
        imgScan.Image = result;
}
</code></pre>
",2014-06-23 08:29:06,2014-06-23 08:29:06,How To Use EigenObjectRecognizer Threshold,<c#><opencv><face-recognition><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
25510,26874326,2014-11-11 20:51:37,,"<p>i wonder if it is possible with Emgu Cv to chnage image from BGR to binary image as i try to change the BGR to gray </p>

<pre><code> Image&lt;Bgr, byte&gt; image_pass = new Image&lt;Bgr, byte&gt;(bt1);
</code></pre>
",,2014-11-15 09:15:35,"change Image from BGR to binary image 0,1?",<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
25519,25754978,2014-09-09 23:17:09,,"<p>I'm trying to make a pixel count in the Channel H with EmguCV, most have this code in C ++ and would like to convert parts of EmguCV c ++ for C #, especially the part uchar tone = comp [0] .at  (i, j); that is giving me a lot of headache, thank you very much if you can help me? </p>

<p>This is the Code: </p>

<p>ProcessadorImagem::calculaHistograma(cv::Mat imagem, DadosImagem* dadosImagem) {</p>

<pre><code>cv::Mat hls;
cv::cvtColor(imagem, hls, CV_RGB2HLS_FULL);     
cv::Mat* comp = new cv::Mat[3];
cv::split(hls, comp);

for (int i = 0; i &lt; imagem.rows; i++)
    for (int j = 0; j &lt; imagem.cols; j++) {
        uchar tom = comp[0].at&lt;uchar&gt;(i, j);

        for (int k = 0; k &lt; dadosImagem-&gt;getHistograma().size(); k++) {
            uchar min = dadosImagem-&gt;getHistograma()[k]-&gt;getLimiteInicial();
            uchar max = dadosImagem-&gt;getHistograma()[k]-&gt;getLimiteFinal();

            if (tom &gt;= min &amp;&amp; tom &lt;= max) {

                int contagem = dadosImagem-&gt;getHistograma()[k]-&gt;getContagemPixels();
                dadosImagem-&gt;getHistograma()[k]-&gt;setContagemPixels(contagem + 1);

                break;
            }
        }
    }
</code></pre>

<p>}</p>
",,2020-02-28 07:06:08,EmguCV C++ to convert C# EmguCV,<c#><c++><c><opencv>,,,CC BY-SA 3.0,True,True,True,False,False
25524,27819882,2015-01-07 12:48:31,,"<p>i need to implement Skeletonization in Emgu CV but i not have success.
I have a code mentioned on the website below but it does not work :
<a href=""https://stackoverflow.com/questions/24226871/skeletonization-using-emgucv["">Skeletonization using EmguCV</a>^]</p>

<p><strong>This code below DONT work:</strong></p>

<pre><code>Image&lt;Gray, Byte&gt; eroded = new Image&lt;Gray, byte&gt;(img2.Size);
    Image&lt;Gray, Byte&gt; temp = new Image&lt;Gray, byte&gt;(img2.Size);
    Image&lt;Gray, Byte&gt; skel = new Image&lt;Gray, byte&gt;(img2.Size);
    skel.SetValue(0);
    CvInvoke.cvThreshold(img2, img2, 127, 256, 0);
    StructuringElementEx element = new StructuringElementEx(3, 3, 1, 1, Emgu.CV.CvEnum.CV_ELEMENT_SHAPE.CV_SHAPE_CROSS);
    bool done = false;

    while (!done)
    {
        CvInvoke.cvErode(img2, eroded, element,1);
        CvInvoke.cvDilate(eroded, temp, element,1);
        temp = img2.Sub(temp);
        skel = skel | temp;
        img2 = eroded;
        if (CvInvoke.cvCountNonZero(img2) == 0) done = true;
    }
</code></pre>

<p><strong>This code WORK but is very slow in video (sequential frames)</strong></p>

<pre><code>Image&lt;Gray, byte&gt; Skeleton(Image&lt;Gray, byte&gt; orgImg)
    {
        Image&lt;Gray, byte&gt; skel = new Image&lt;Gray, byte&gt;(orgImg.Size);
        for (int y = 0; y &lt; skel.Height; y++)
            for (int x = 0; x &lt; skel.Width; x++)
                skel.Data[y, x, 0] = 0;

        imageBoxOutputROI.Image = skel;

        Image&lt;Gray, byte&gt; img = skel.Copy();
        for (int y = 0; y &lt; skel.Height; y++)
            for (int x = 0; x &lt; skel.Width; x++)
                img.Data[y, x, 0] = orgImg.Data[y, x, 0];

        StructuringElementEx element;
        element = new StructuringElementEx(3, 3, 1, 1, Emgu.CV.CvEnum.CV_ELEMENT_SHAPE.CV_SHAPE_CROSS);
        Image&lt;Gray, byte&gt; temp;

        bool done = false;
        do
        {
            temp = img.MorphologyEx(element, Emgu.CV.CvEnum.CV_MORPH_OP.CV_MOP_OPEN, 1);
            temp = temp.Not();
            temp = temp.And(img);
            skel = skel.Or(temp);
            img = img.Erode(1);
            double[] min, max;
            Point[] pmin, pmax;
            img.MinMax(out min, out max, out pmin, out pmax);
            done = (max[0] == 0);
        } while (!done);

        return skel;
    }
</code></pre>

<p>Input image:</p>

<p><img src=""https://i.stack.imgur.com/OrP1q.png"" alt=""enter image description here""></p>

<p>I need a help to implement the skeletonization code.</p>

<p>A research in below sites but i not hace success:
<a href=""http://felix.abecassis.me/2011/09/opencv-morphological-skeleton/["" rel=""nofollow noreferrer"">http://felix.abecassis.me/2011/09/opencv-morphological-skeleton/[</a>^]</p>

<p><a href=""https://stackoverflow.com/questions/26850944/skeleton-of-an-image-in-emgucv["">https://stackoverflow.com/questions/26850944/skeleton-of-an-image-in-emgucv[</a>^]</p>

<p><a href=""https://stackoverflow.com/questions/26850944/skeleton-of-an-image-in-emgucv["">https://stackoverflow.com/questions/26850944/skeleton-of-an-image-in-emgucv[</a>^]</p>

<p>I am grateful for any help .</p>

<p>Richard J. Algarve</p>
",2017-05-23 12:24:17,2018-07-19 17:03:04,Emgu CV - Skeleton of an Image in EmguCV (Skeletonization),<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
25551,27734354,2015-01-01 20:25:14,,"<p>I'm looking for a simple way to create a car classifier for haarcascade (I understand there are some classifiers already allover the internet) I need to train it on front view since I'm working on a vehicle accident prevention that detect cars coming from behind</p>

<p>I've been searching for weeks for a great tutorial but they just don't work or there is something wrong(broken links)</p>

<p>I'm using Windows and c# (EmguCV) and I'm using the latest dll files (since lots of functions are deprecated)</p>

<p>Thanks in advance!</p>
",,2015-01-13 14:07:31,Creating a Haarcascade Classifier,<c#><emgucv><haar-classifier>,,,CC BY-SA 3.0,False,False,True,False,False
25599,27826754,2015-01-07 19:04:33,,"<p>Hi I can't seem to be able to even declare a point in Emgu CV currently. I'm trying to declare a new point so that I can use that point as the center of a rectangle which I will show on each frame of a video feed so that the user can see the Region of Interest. In my header file I have </p>

<pre><code>Emgu::CV::Point2D&lt;int,int&gt;^Center;
</code></pre>

<p>and in my Source file I have </p>

<pre><code>Center = gcnew Emgu::CV::Point2D&lt;int,int&gt;(120, 160);
</code></pre>

<p>The error that I'm getting is </p>

<pre><code>5&gt;c:\users\admin\desktop\swir source code\hyperspectral\baotfis\BAOTFISInterface.h(88): error C2039: 'Point2D' : is not a member of 'Emgu::CV'
</code></pre>

<p>which confuses me because how is it NOT a member of Emgu::CV? </p>

<p>Am I missing a namespace or am I just declaring it wrong? I'm using Microsoft Visual Studio 2010 Express. Any and all help is greatly appreciated thank you very much. </p>
",,2015-01-07 20:09:09,Declaring a new point using Emgu CV C++,<c++><image><opencv><visual-c++><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
25623,24361337,2014-06-23 08:20:24,,"<p>I am using <em>Emgu.CV</em> to extract frames from video files and extract faces from every frame, the problem is the application runs out of memory after a while. I think i release memory and dispose every object i create. Here is the method, any optimization, ideas will be appreciated.</p>

<pre><code>public List&lt;FileItem&gt; ExtractFacesFromImage(FileItem selectedFrame, string outputFolderPath, int minNeighbors, double scaleFactor, int widthIncrement = 80, int heightIncrement = 102)
{
    lock (lockObj)
    {
        _currentFrame = new Image&lt;Bgr, byte&gt;(selectedFrame.Path);
        _gray = _currentFrame.Convert&lt;Gray, Byte&gt;();
        var result = new List&lt;FileItem&gt;();

        using (_face = new HaarCascade(_xmlFilePath))
        {
            if (_gray != null)
            {
                var facesDetected = _gray.DetectHaarCascade(_face, scaleFactor, minNeighbors,Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_ROUGH_SEARCH,new Size(20, 20));

                for (int index = 0; index &lt; facesDetected[0].Length; index++)
                {
                    var imgName = SaveExtractedFace(outputFolderPath, facesDetected,
                                    index, widthIncrement, heightIncrement);
                    result.Add(new FileItem
                    {
                        IsSelected = true,
                        Path = imgName,
                        Name = Path.GetFileNameWithoutExtension(imgName)
                    });
                }
                DisposeObject(_gray);
                DisposeObject(_currentFrame);
            }
            return result;
        }
    }
}

private void DisposeObject(IDisposable disposable)
{
    if (disposable != null)
    {
        disposable.Dispose();
        disposable = null;
    }
}

private string SaveExtractedFace(string outputFolderPath, MCvAvgComp[][] facesDetected, int index, int widthIncrement, int heightIncrement)
{
    var f = facesDetected[0][index];

    var cropRectangle = GetNewRectangle(f.rect, _currentFrame.Width, _currentFrame.Height, widthIncrement, heightIncrement);

    _tempImage = _currentFrame.Copy(cropRectangle);
    string imgName = outputFolderPath + ""\\"" + UniqueNameManager.Generate() + "".jpg"";
    _tempImage.Save(imgName);
    DisposeObject(_tempImage);
    return imgName;
}
</code></pre>
",2014-06-23 10:28:28,2014-07-03 10:47:16,Failed to allocate bytes in OpenCV,<c#><opencv><memory-management><memory-leaks><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
25639,27741450,2015-01-02 11:28:51,,"<p>I`am using EmguCV houghines with edge detector app for detection of ablation rods (rod from wood with red and white stripes), and I need to know, how I get line length in pixels, like: <em>line one is 50px long</em>.</p>

<p>Sample of code</p>

<pre><code>class HoughTransform
{
    private Image&lt;Gray, Byte&gt; _sourceImage;
    private Image&lt;Gray, Byte&gt; _linesImage;
    private Image&lt;Gray, Byte&gt; _resultImage;

    public HoughTransform()
    {

    }

    public void applyTransform()
    {
        try
        {
            _linesImage = _sourceImage.CopyBlank();
            LineSegment2D [] lines = _sourceImage.HoughLinesBinary(1, Math.PI/ 0.0, 50, 100, 1)[0];
            foreach(LineSegment2D line in lines)
            {
                _linesImage.Draw(line,new Gray(200), 5);
            }
            _resultImage = _linesImage;
        }
        catch(Exception e)
        {
            MessageBox.Show(e.ToString());
        }
    }
</code></pre>
",2015-09-16 16:24:41,2016-10-29 23:58:36,Emgucv Houghlines length of line,<c#><opencv><emgucv><hough-transform>,,,CC BY-SA 3.0,True,False,True,False,False
25675,27745914,2015-01-02 17:17:43,,"<p>Is there a way to reduce the grayscales of an gray-image in openCv?</p>

<p>Normaly i have grayvalues from 0 to 256 for an </p>

<blockquote>
  <p><code>Image&lt;Gray, byte&gt; inputImage</code>.</p>
</blockquote>

<p>In my case i just need grayvalues from 0-10. Is there i good way to do that with OpenCV, especially for C# ?</p>
",,2015-01-03 11:30:04,EmguCv: Reduce the grayscales,<c#><opencv><image-processing><grayscale>,,,CC BY-SA 3.0,True,False,True,False,False
25799,27866646,2015-01-09 18:12:39,,"<p>I am having difficulties figuring out how to draw a simple rectangle on an image using emgu cv. I'm using VS 2010 Express. I have a User Interface in which I am displaying a live video feed in a picture box on a panel which I have created using the .net framework. Now I would like to draw a clear rectangle in the middle of this feed, as that is where my code is focused on, and I need the user to see how to line up the camera and the object of interest so that it is in the rectangle. This is what I have so far in terms of drawing the rectangle on the frames from the camera</p>

<pre><code>cv::Scalar red(0,0,255);
System::Drawing::Rectangle Rect = System::Drawing::Rectangle(120, 160, 150, 150);
frameColorDisplay-&gt;Draw(Rect, red, 2);
</code></pre>

<p>and this is the error that I'm receiving</p>

<pre><code>BAOTFISInterface.cpp(1067): error C2664: 'void     Emgu::CV::Image&lt;TColor,TDepth&gt;::Draw(Emgu::CV::Seq&lt;T&gt; ^,Emgu::CV::Structure::Bgr,int)' : cannot convert parameter 1 from 'System::Drawing::Rectangle' to 'Emgu::CV::Seq&lt;T&gt; ^'
5&gt;          with
5&gt;          [
5&gt;              TColor=Emgu::CV::Structure::Bgr,
5&gt;              TDepth=unsigned char,
5&gt;              T=System::Drawing::Point
5&gt;          ]
5&gt;          and
5&gt;          [
5&gt;              T=System::Drawing::Point
5&gt;          ]
5&gt;          No user-defined-conversion operator available, or
5&gt;          No user-defined-conversion operator available that can perform this conversion, or    

the operator cannot be called
</code></pre>

<p>I'm not sure why it's trying to convert from Rectangle to a Sequence? As far as I know, I'm calling the function properly according to the Emgu CV documentation. Does anyone have any insight into this issue? </p>
",2015-01-09 20:16:00,2015-02-05 22:05:45,Drawing on an image using emgu cv C++,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
25907,27902938,2015-01-12 13:20:23,,"<p>We are using OpenCV with Emgu 2.4.9 wrapper.</p>

<p>When we convert the <code>Image&lt;Gray,float&gt;</code> to <code>Image&lt;Gray,Byte&gt;</code> (using <code>convert&lt;Gray,Byte&gt;()</code>), the brightness/contrast is reduced.
We are using <code>Image&lt;Gray,Byte&gt;</code> for display purposes while <code>Image&lt;Gray,float&gt;</code> is used temporarily for processing (e.g. convolution).</p>

<p>However, when <code>Image&lt;Gray,float&gt;</code> is saved as JPEG, I see the required level of intensities/brightness.</p>

<p>When I checked the <code>Image.Save()</code> method, it looks like it finally ends up calling OpenCV imwrite_() function which in turn converts the Float image to byte format: ‘image.convertTo( temp, CV_8U );’</p>

<p>So, I would expect the intensity level to have reduced when <code>Image&lt;Gray,float&gt;</code> is saved to JPEG. But it does not (even though, the same convertTo() method, which in turn calls OpenCV cvt_() function).</p>

<p>But, when the float image converted to Byte and saved the brightness/contrast is reduced.</p>

<p>In both cases, I believe, <code>saturate_cast&lt;&gt;</code> would be called.</p>

<p>Related questions here: <a href=""https://stackoverflow.com/questions/27793886/emgu-image-conversion-from-imagegray-float-to-imagegray-byte-results-in-inte"">Emgu image conversion from Image&lt;Gray,float&gt; to Image&lt;Gray,Byte&gt; results in intensity loss?</a> </p>

<p>Would someone be able to describe what is going on and how to preserve the brightness/intensity when converting from <code>Image&lt;Gray,float&gt;</code> to <code>Image&lt;Gray,Byte&gt;</code>?</p>
",2017-05-23 11:58:22,2015-01-12 13:20:23,"Loss of brightness/contrast when converting from Image<Gray,float> to Image<Gray,Byte>",<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
25944,27905301,2015-01-12 15:23:03,,"<p>I would like to use some of the OpenCV routines (2D convolve, Region Labeling, and Centroiding) in a CudaFy.net project. </p>

<ol>
<li>Is this a stupid idea?</li>
<li>Would it be better just to implement the algorithms in C# from opensource examples?</li>
<li>Some of inputs to the OpenCV have will already be in global GPU memory, can you pass pointers to OpenCV GPU routines and say the matrix is already in the GPU?</li>
<li>Are there any simple examples of doing this</li>
</ol>

<p>I did see one person who used EMGU and openCV but did run into some issues. Is there an example around of someone doing this successfully? [ <a href=""https://cudafy.codeplex.com/discussions/356649"" rel=""nofollow"">https://cudafy.codeplex.com/discussions/356649</a> ]</p>
",,2015-01-12 15:23:03,CudaFy.net and OpenCV,<emgucv><cudafy.net>,,,CC BY-SA 3.0,True,False,True,False,False
26007,25484566,2014-08-25 11:09:10,,"<p>How can I detect the outer boundary of an iris in an eye image.
I tried using HoughCircles() method, </p>

<pre><code>        Gray cannyThreshold = new Gray(150);
        Gray cannyAccumulatorThreshold = new Gray(150);

        CircleF[] circles = grayscaledImg.HoughCircles(
                                     cannyThreshold,
                                     cannyAccumulatorThreshold,
                                     4,
                                     150,
                                     5,         //min radius
                                     0)[0];    //max radius



        foreach(CircleF circle in circles)
        {
            grayscaledImg.Draw(circle, new Gray(), 2);

        }
</code></pre>

<p>But the code draws the circle on the wrong places.
Need your help guys.</p>

<p>Output image:  </p>

<p><a href=""https://i.stack.imgur.com/Q3fN1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Q3fN1.png"" alt=""enter image description here""></a></p>
",2018-07-25 13:49:05,2018-07-25 13:49:05,Iris outer boundary(Circle) detection using Emgu CV,<c#><opencv><emgucv><iris-recognition>,,,CC BY-SA 4.0,True,False,True,False,False
26052,27914042,2015-01-13 02:26:43,,"<p>I try to render image from the Emgu's camera capture on new Unity3D UI system.
Till now, I used ImageToTexture2d from this repository: 
<a href=""https://github.com/neutmute/emgucv/blob/3ceb85cba71cf957d5e31ae0a70da4bbf746d0e8/Emgu.CV/PInvoke/Unity/TextureConvert.cs"" rel=""nofollow"">https://github.com/neutmute/emgucv/blob/3ceb85cba71cf957d5e31ae0a70da4bbf746d0e8/Emgu.CV/PInvoke/Unity/TextureConvert.cs</a> 
and then used Sprite.Create() to finally achieve the wanted result.</p>

<p>BUT! It appears there is some massive memory leak as after 2-3 minutes of my game running Unity editor suddenly takes about 3GB of RAM where it started with about 200MB.</p>

<p>I have two susspects:</p>

<ol>
<li>(More Probabble) The method I'm using does not clean the memory. It uses InterOp and creates some unsafe pointers - it smells leakage.</li>
<li>The Sprite.Create runned every frame holds old sprites in memory and does not remove them.</li>
</ol>

<p>Does any of You knows any other way to convert Emgu's Image to Sprite/Texture(without using an InterOp) or any other way I could show it on New Unity's UI. It has to be the Emgu's Image as I also do some operations on the images I recieve from camera.</p>

<p>Thanks in advance for responses and help. :D</p>
",,2019-04-13 14:04:30,How to convert EmguCV Image to Unity3D Sprite?,<c#><unity3d><emgucv><unity3d-gui>,,,CC BY-SA 3.0,False,False,True,False,False
26193,27691408,2014-12-29 15:15:19,,"<p>I want to make an application able to detect and track object using Kinect camera. </p>

<p>I used SURF algorithm to find an object, exactly as described on EmguCV's ""SURF feature detector in CSharp"" and in EmguCV's example ""SURFFeature"". I'm capturing an image from camera to detect and show it in small picture box, while camera image is in big picture box. But when I took a photo of the object SURF algorithm starts to do some totally random matching. Tracking objects should have a red rectangle around it, but nothing happens like that, and the matching vector lines are pointing to the totally different objects. </p>

<p>I'm using Visual Studio 2010 with Kinect for Windows SDK 1.8 and EmguCV 2.4.10. </p>

<p>Here are the pictures showing the situation:</p>

<p>Trying to capture a toy bulb on a rope.
<img src=""https://i.stack.imgur.com/QNOKc.png"" alt=""enter image description here""></p>

<p>Trying to capture a book.
<img src=""https://i.stack.imgur.com/Wz4HO.png"" alt=""enter image description here""></p>

<p>Can anyone help me to know why SURF isn't detecting that objects properly?  What am I doing wrong?</p>
",2014-12-29 15:25:25,2015-01-06 05:18:26,EmguCV SURF detection doesn't detect properly,<c#><kinect><emgucv><surf>,,,CC BY-SA 3.0,False,False,True,False,False
26198,27793886,2015-01-06 07:20:09,,"<p>We are performing image sharpening of a gray scale image of type Image by subtracting the Laplacian of the image from the original image. The result, if saved as a JPEG, has well defined edges and contrast. However, if the resultant image is converted to Bitmap OR ""<code>Image&lt;Gray, Byte&gt;</code>""
and saved as JPEG, the intensity is reduced and the sharpening effect is lost. I suspected that converting to Bitmap may be causing this problem. So, I saved some of the intermediate images and also converted the image to ""<code>Image&lt;Gray,Byte&gt;</code>"". This did not help. I also tried to scale the image using a simple method. This too did not help.</p>

<p>The above behaviour is also true when we perform Laplace and subtract the resultant image from the original image. Illustrations are below (code has been modified for simplicity):</p>

<pre><code>...

Image&lt;Gray, Byte&gt; sharpenedImage = Sharpen(filter, originalprocessedImage);
ProcessedImage = sharpenedImage.ToBitmap(); // Or ProcessedImage.Bitmap;
ProcessedImage.Save(""ProcessedImage.jpg"");  // results in intensity loss

...

public Image&lt;Gray, Byte&gt; Sharpen(Image&lt;Gray, Byte&gt; inputFrame)
{
    ConvolutionKernelF Sharpen1Kernel = new ConvolutionKernelF (new float[,] { { -1,-1,-1 }, { -1, 8,-1 }, { -1,-1,-1 } });
    Image&lt;Gray, float&gt; newFloatImage = inputFrame.Convert&lt;Gray, float&gt;();
    Image&lt;Gray, float&gt; newConvolutedImage = newFloatImage.Convolution(Sharpen1Kernel);    
    Image&lt;Gray, float&gt; convolutedScaledShiftedImage = newFloatImage.AddWeighted(newConvolutedImage, 1.0, 1.0, 0);

    // added for testing
    convolutedScaledShiftedImage .Save(""ConvolutedScaledShiftedImage .jpg"");

    //Now try to scale and save:
    Image&lt;Gray, float&gt; scaledImageFloat = convolutedScaledAddedImage.Clone();
    Image&lt;Gray, float&gt; scaledImageFloat2 = ScaleImage(scaledImageFloat);

    // added for testing
    scaledImageFloat.Save(""ScaledImage.jpg"");

    // added for testing
    scaledImageFloat2.Convert&lt;Gray,Byte&gt;().Save(""ScaledImage-8Bits.jpg"");

    // both of these return the images of lower intensity
    return scaledImageFloat2.Convert&lt;Gray,Byte&gt;();
    return convolutedScaledShiftedImage.Convert&lt;gray,Byte&gt;();
}
</code></pre>

<p>While the ConvolutedScaledShifteImage.jpeg is brighter and with better contrast, ""ScaledImage.jpeg"" and ""ScaledImage-8Bits.jpeg"" have lost the intensity levels as compared to ConvolutedScaledShifteImage.jpeg. The same is true for ProcessedImage.jpeg.</p>

<p>The ScaleImage is below. This was not really necessary. As the Convert was losing intensity, I tried to do the conversion and check:</p>

<pre><code>Image&lt;Gray, float&gt; ScaleImage(Image&lt;Gray, float&gt; inputImage)
{
    double[] minValue;
    double[] maxValue;
    Point[] minLocation;
    Point[] maxLocation;

    Image&lt;Gray, float&gt; scaledImage = inputImage.Clone();

    scaledImage.MinMax(out minValue, out maxValue, out minLocation, out maxLocation);

    double midValue = (minValue[0] + maxValue[0] ) / 2;
    double rangeValue = (maxValue[0]) - (minValue[0]);
    double scaleFactor = 1 / rangeValue;
    double shiftFactor = midValue;

    Image&lt;Gray, float&gt; scaledImage1 = scaledImage.ConvertScale&lt;float&gt;(1.0, Math.Abs(minValue[0]));
    Image&lt;Gray, float&gt; scaledImage2 = scaledImage1.ConvertScale&lt;float&gt;(scaleFactor * 255, 0);

    return scaledImage2;
}
</code></pre>

<p>Would anybody be able to suggest what could be going wrong and why the intensities are lost in the above operations? Thanks.</p>

<p>Edit: fixed the formatting issue... conversion was from <code>Image&lt;Gray, float&gt;</code> to <code>Image&lt;Gray, Byte&gt;</code></p>

<p>Edit 12-Jan: I further dug into OpenCV code and as I understand, when you save an image of type <code>Image&lt;Gray,float&gt;</code> to JPEG, <code>imwrite()</code> first converts the image to an 8-bit image <code>image.convertTo( )temp, CV_8U );</code> and writes to the file. When the same operation is performed with <code>Convert&lt;Gray,Byte&gt;()</code>, the intensities are not the same. So, It is not clear what is the difference between the two.</p>
",2015-01-12 10:49:42,2015-01-12 10:49:42,"Emgu image conversion from Image<Gray,float> to Image<Gray,Byte> results in intensity loss?",<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
26204,27942198,2015-01-14 11:45:03,,"<p>Image My_Image = new Image(Openfile.FileName);</p>

<pre><code>            pictureBox1.Image = My_Image.ToBitmap();
            Image&lt;Gray, Byte&gt; modelImage = My_Image.Convert&lt;Gray, byte&gt;();
            SIFTDetector siftCPU = new SIFTDetector();
            VectorOfKeyPoint modelKeyPoints = new VectorOfKeyPoint();


            MKeyPoint[] mKeyPoints = siftCPU.DetectKeyPoints(modelImage, null);
            modelKeyPoints.Push(mKeyPoints);
            ImageFeature&lt;float&gt;[] results = siftCPU.ComputeDescriptors(modelImage, null, mKeyPoints);
            Image&lt;Bgr, Byte&gt; image = Features2DToolbox.DrawKeypoints(modelImage, modelKeyPoints, new Bgr(Color.Red), Features2DToolbox.KeypointDrawType.DEFAULT);
            pictureBox1.Image = image.ToBitmap();
</code></pre>

<p>this program just find SIFT descriptors in one image. I want to compare to Image but I don't know which ImageFeature&lt;> I will use. I'm looking up the features of ImageFeature&lt;> I can't find it
please help me. </p>
",2015-01-27 19:29:44,2016-05-15 03:26:39,compare descriptors using SIFT in C#,<compare><emgucv><sift><feature-descriptor>,,,CC BY-SA 3.0,False,False,True,False,False
26224,27692253,2014-12-29 16:12:11,,"<p>I have an <code>Image&lt;Gray, Byte&gt;</code> and i want to calculate the covariance matrix for the image.</p>

<p>Therefore i use the function <code>CvInvoke.cvCalcCovarMatrix(imageptr, 2, cov, avg, COVAR_METHOD.CV_COVAR_NORMAL);</code></p>

<p>Here my code:</p>

<pre><code>       Image&lt;Gray, Byte&gt; image_gray = _image.Convert&lt;Gray, Byte&gt;();
       Matrix&lt;float&gt; cov = new Matrix&lt;float&gt;(image_gray.Rows, image_gray.Cols);
       Matrix&lt;float&gt; avg = new Matrix&lt;float&gt;(image_gray.Cols, 1);
       Matrix&lt;float&gt;[] input = new Matrix&lt;float&gt;[image_gray.Rows];
       float[] temp = new float[image_gray.Rows];


       for (int j = 0; j &lt;image_gray.Rows; j++)
       {
           for (int i = 0; i &lt; image_gray.Cols; i++)
           {
                temp[i] = (float)image_gray[j, i].Intensity;

            }

            input[j] =new Matrix&lt;float&gt;(temp);
       }

        IntPtr[] imageptr = Array.ConvertAll&lt;Matrix&lt;Single&gt;, IntPtr&gt;(input, delegate(Matrix&lt;Single&gt; mat) { return mat.Ptr; });
        CvInvoke.cvCalcCovarMatrix(imageptr, 2, cov, avg, COVAR_METHOD.CV_COVAR_NORMAL);
</code></pre>

<p>The problem is, that the result of the covariance matrix elements are always null.</p>
",2014-12-29 19:51:23,2014-12-29 19:51:23,EmguCV: How to create a covariation matrix from image?,<c#><matrix><emgucv><covariance>,,,CC BY-SA 3.0,False,True,True,False,False
26300,28024583,2015-01-19 12:23:05,,"<p>I downloaded EMGU Cv control , ImageBox 
Im trying to display a video stream in this control .
The control image object is IImage, 
how can i display image to the ImageBox? its accept IImage only, 
how can i create or convert image or bitmap to IImage , or create one ?</p>

<p>EDIT:
I've done this:</p>

<pre><code>                            Bitmap bmp = new Bitmap(picBuffer.FramesDicitionary[addr]);
                            Image&lt;Bgr, Byte&gt; img1 = new Image&lt;Bgr, Byte&gt;(bmp);
                            pbTopLeft.Image = img1; 
</code></pre>

<p>and when i run the app , its say: The type initializer for 'Emgu.CV.CvInvoke' threw an exception
How to fix this ? </p>
",2015-01-19 12:55:39,2015-03-03 00:31:17,C# winforms Emgu CV ImageBox IImage,<c#><computer-vision><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
26304,25824034,2014-09-13 14:11:16,,"<p>I use EmguCV in C# to for simple eye tect program.</p>

<p>but </p>

<pre><code>cap = new Capture(0); 
</code></pre>

<p>Always return null value.</p>

<p>It does not detect webcam. Why this happen and how to solve it ?emgucv</p>
",,2014-09-13 14:11:16,cap = new Capture(0); does not detect webcam?,<c#><webcam><emgucv><face-detection>,,,CC BY-SA 3.0,False,False,True,False,False
26321,27700498,2014-12-30 06:15:09,,"<p>I want to convert ColorFrame of Kinect V2 SDK into Image i.e. Image format of EmguCV. Converting ColorFrame into BitmapSource then BitmapSource into Bitmap and finally Bitmap into EmguCV Image seems to be unnecessary overhead to CPU.
Below is the code-</p>

<pre><code>private byte[] pixels = null;
this.pixels = new byte[colorFrameDescription.Width * colorFrameDescription.Height * colorFrameDescription.BytesPerPixel];

using (ColorFrame colorFrame = e.FrameReference.AcquireFrame())
{
    if (colorFrame != null)
    {
        FrameDescription colorFrameDescription = colorFrame.FrameDescription;
        if (colorFrame.RawColorImageFormat == ColorImageFormat.Bgra)
            colorFrame.CopyRawFrameDataToArray(pixels);
        else
            colorFrame.CopyConvertedFrameDataToArray(this.pixels, ColorImageFormat.Bgra);

        //Initialize Emgu CV image then assign byte array of pixels to it
        Image&lt;Bgr, byte&gt; img = new Image&lt;Bgr, byte&gt;(colorFrameDescription.Width, colorFrameDescription.Height);
        img.Bytes = pixels;

        imgBox.Image = img;//Show image in Emgu.CV.UI.ImageBox
    }
}
</code></pre>
",,2014-12-30 06:15:09,"Covert Kinect v2 ColorFrame into EmguCV Image<Bgr, byte>",<kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
26442,28018147,2015-01-19 04:53:10,,"<p>So here's my goal: I want to stop at each pixel on a line and do some processing on those pixels. Currently i'm using EmguCV for my image processing library. In openCV there is a method called LineIterator which you can use to iterate through the pixel in a line. However, I haven't found a method similar to this in EmguCV which is where I am getting stuck. </p>

<p>Currently, I can get the pixel values of all the pixels on a line between two predefined points using the <a href=""http://www.emgu.com/wiki/files/2.3.0/document/html/eaaf9cad-1fbc-73bb-b190-d216c4edf6f4.htm"" rel=""nofollow"">Image.Sample</a> method. For a grayscale image Image this returns a n-by-1 matrix with n being the number of pixels on that line. However, I am not able to get the coordinates of each pixel on that particular line corresponding to the pixel values in the n-by-1 matrix mentioned above. Hence, I am not able to do image processing on these pixels, even though I have their pixel values. Is there a way to do this on EmguCV?</p>

<p>Thank you.</p>
",,2020-05-06 15:51:01,EmguCV: Get coordinates of pixels in a line between two points,<c#><wpf><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
26532,26963908,2014-11-17 00:53:16,,"<p>I need to accentuate a word using Image  .Draw, however I am not getting. My code follows:</p>

<pre><code>MCvFont f = new MCvFont(Emgu.CV.CvEnum.FONT.CV_FONT_HERSHEY_COMPLEX_SMALL, 1.2, 1.2);
img.Draw(""Tietê - Barra Bonita"", ref f, new Point(12, 25), new Bgr(0, 0, 0));
</code></pre>

<p>The problem is in the word TIETÊ which is being viewed as TIET?</p>

<p>I am grateful for the help,</p>

<p>A Hug,</p>

<p>Richard J. Algarve</p>
",,2014-11-17 00:53:16,EmguCV - accentuation in text draw,<c#><opencv><draw><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
26675,28129105,2015-01-24 18:57:12,,"<p>I have some Emgu code that was working in both debug and release builds.  Somewhere along the way, it quit working, but I was deep into adding something else so I didn't pursue it at the time.</p>

<p>When I did finally getting around to trying to fix it, I find that a release build works, but not a debug build.  Between the time it was working, and not, I did not change any references or referenced DLLs. I spent some time investigating that anyhow as I had read somewhere that open CV has some trouble debug vs release somewhere, but never found anything.</p>

<p>I just applied the last version of Emgu, and the same problem exists;  works perfect in release, not at all in debug.</p>

<p>The relevant code snippet is;</p>

<pre><code> var filteredFrame =
            channels[0].SmoothGaussian(VisionData.SmoothGaussians)
                .Erode(VisionData.Erodes)
                .Dilate(VisionData.Dialates);

        using (MemStorage stor = new MemStorage())
            for (
                Contour&lt;System.Drawing.Point&gt; contour =
                    filteredFrame.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
                        Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_EXTERNAL, stor);
                contour != null;
                contour = contour.HNext)
                if ((contour.Area &gt; (VisionData.ContourMinArea * VisionData.ContourMinArea))
                    &amp;&amp; (contour.Area &lt; (VisionData.ContourMaxArea * VisionData.ContourMaxArea)))
                    CurrentFrame.Draw(contour.GetMinAreaRect(), RectBrush, 2);

        d.InvokeAsync(() =&gt;
        {
            DataModel.CameraImageSource = Emgu.CV.WPF.BitmapSourceConvert.ToBitmapSource(CurrentFrame);
            DataModel.FilteredImageSource = Emgu.CV.WPF.BitmapSourceConvert.ToBitmapSource(filteredFrame);                                
        });
</code></pre>

<p>The input filtered frame(image) looks identical in both debug and release.</p>
",,2015-01-24 18:57:12,emgu FindContours fails in debug build,<c#><wpf><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
26706,28162897,2015-01-27 03:47:24,,"<p><img src=""https://i.stack.imgur.com/oDwuG.jpg"" alt=""enter image description here""></p>

<p>In the above image I have a set of points (blue) and my goal is to get the green rectangle, specifically the right, left, top, and bottom coordinates of that rectangle. It is the non-rotated bounded rectangle of the ellipse. The ellipse is the least-square fit from the set of points. </p>

<p>Currently I am able to find the yellow rectangle, which is the non-rotated rectangle from the set of points using Emgu.CV.PointCollection.BoundingRectangle function, and also the red rectangle, which is the rotated rectangle representation of the ellipse from EmguCV's Ellipse.MCvBox2D function.</p>

<p>Any idea on how to find the green rectangle?</p>

<p>The code to get the ellipse, red, and yellow rectangle are below (the points are in an array of points called edgePA):</p>

<pre><code>//Get Least-Square Fit Ellipse
Ellipse elps = PointCollection.EllipseLeastSquareFitting(edgePA);

//Rotated Rectangle of Ellipse
MCvBox2D boundR2 = elps.MCvBox2D;

//Bounding Rectangle of Points
Rectangle boundR = PointCollection.BoundingRectangle(edgePA);
</code></pre>
",,2015-01-27 03:47:24,EmguCV: Bounding Rectangle of Ellipse,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
26752,28188897,2015-01-28 09:40:25,,"<p>I am totally new to emgu. I've been searching for a solution for this problem but I couldn't find any solution. I am trying to threshold a given Image using the built in adaptive threshold function but the program exits with no exception</p>

<p>Code :</p>

<pre><code> public Image&lt;Gray, byte&gt; AdaptiveThreshold(Image&lt;Bgr, byte&gt; bmp, int windowSize)
    {
        Image&lt;Gray, byte&gt; gray = new Image&lt;Gray, byte&gt;(bmp.ToBitmap());

        Image&lt;Gray, byte&gt; bw = gray.ThresholdAdaptive(new Gray(255), Emgu.CV.CvEnum.ADAPTIVE_THRESHOLD_TYPE.CV_ADAPTIVE_THRESH_MEAN_C, Emgu.CV.CvEnum.THRESH.CV_THRESH_OTSU, windowSize, new Gray(0.03));
        return bw;
    }
</code></pre>

<p>Function call :</p>

<pre><code>this.pictureBox1.Image = r.AdaptiveThreshold(this.bmp, 15).ToBitmap(); // here where the application exit with no error and with no output in pictureBox1
</code></pre>

<p><code>r is an object of class which contains AdaptiveThreshold defined above</code></p>

<p>I copied all un-manged binaries from bin folder emgucv-windows-universal-cuda 2.9.0.1922\bin\x86 to my debug folder, I also added Emgu Dlls to my project's references Emgu.CV, Emgu.CV.UI, Emgu.Util
I also set my target platform to x86 
I am working on visual studio 2013 under windows 8 . </p>
",2015-01-28 11:31:54,2016-06-21 17:25:33,Emgu exit unexpectedly after calling AdaptiveThreshold function,<c#><opencv><dll><build><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
26769,28244795,2015-01-30 21:18:52,,"<p>I am trying to remove distortion from a cropped version of my image. I know the x and y mapping matrixes for the full size image (1920X1080). The way I am trying to do this is to first create two new mappings that contain the part of the full size mappings corresponding to the crop rectangle and then apply them to the cropped image. However, the output is just a black image: </p>

<pre><code>Matrix&lt;float&gt; matCam1Map1, matCam1Map2;
Matrix&lt;float&gt; matCam1Map1Crp, matCam1Map2Crp;

matCam1Map1 = new Matrix&lt;float&gt;(1080, 1920);
matCam1Map2 = new Matrix&lt;float&gt;(1080, 1920);
CvInvoke.cvInitUndistortMap(itsCam1.IntrinsicMatrix.Ptr, itsCam1.DistortionCoeffs.Ptr, matCam1Map1.Ptr, matCam1Map2.Ptr);

matCam1Map1Crp = new Matrix&lt;float&gt;(rectCam1Crop.Height, rectCam1Crop.Width);
matCam1Map2Crp = new Matrix&lt;float&gt;(rectCam1Crop.Height, rectCam1Crop.Width);

for (int i = 0; i &lt; rectCam1Crop.Height; i++)
{
    for (int j = 0; j &lt; rectCam1Crop.Width; j++)
    {
        matCam1Map1Crp.Data[i, j] = matCam1Map1.Data[rectCam1Crop.Y + i, rectCam1Crop.X + j];
        matCam1Map2Crp.Data[i, j] = matCam1Map2.Data[rectCam1Crop.Y + i, rectCam1Crop.X + j];
    }
}

Capture capCam1;
Image&lt;Bgr, Byte&gt; imgCam1New = capCam1.QueryFrame().Copy(rectCam1Crop);
Image&lt;Bgr, Byte&gt; imgNoDistortion = new Image&lt;Bgr, byte&gt;(imgCam1New.Size);
CvInvoke.cvRemap(imgCam1New, imgNoDistortion, matCam1Map1Crp, matCam1Map2Crp, 0, new MCvScalar(0));
</code></pre>

<p>When I apply the full size mappings to the full size image, it works perfectly, but then I have to crop it. However, I am trying to make it faster by cropping it first, and then applying the mappings to the cropped image.</p>

<p>Does anyone know what may be the issue with my code?
Thanks</p>
",,2015-01-30 21:18:52,Remove camera distortion from part of image in C# using EmguCV,<c#><crop><emgucv><rectangles><distortion>,,,CC BY-SA 3.0,False,False,True,False,False
26777,25866486,2014-09-16 10:33:24,,"<p>How can i get the videos/frames from CCTV and DECODER box?</p>

<p>The CCTV camera connected to the Decoder box in the PC, how can i get the frames/videos from the decoder box using opencv and some other tools.</p>

<p>Help me.</p>
",,2014-09-16 10:33:24,How can i get the videos/frames from CCTV and DECODER box?,<opencv><emgucv><decoder><cctv>,,,CC BY-SA 3.0,True,False,True,False,False
26828,28232623,2015-01-30 09:18:20,,"<p>I am following Luca Del Tongo tutorial on youtube in order to track the eyes from face. I managed to do so using rectangle but I would like to track it using HoughCircle.
<a href=""https://www.youtube.com/watch?v=07QAhRJmcKQ"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=07QAhRJmcKQ</a></p>

<p>I am using the following code to track my eyes and it is creating multiple circles around my eyes. <img src=""https://i.stack.imgur.com/ipvjw.png"" alt=""enter image description here"">
I only converted the image to gray scale as he told us to do in the tutorial.  Can you please help? I am new to EMGU CV</p>

<pre><code>grayFrame.ROI = possibleROI_leftEye;
                MCvAvgComp[][] leftEyesDetected = grayFrame.DetectHaarCascade(_eyes, 1.15, 0, Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(20, 20));
                grayFrame.ROI = Rectangle.Empty;

                grayFrame.ROI = possibleROI_rightEye;
                MCvAvgComp[][] rightEyesDetected = grayFrame.DetectHaarCascade(_eyes, 1.15, 0, Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(20, 20));
                grayFrame.ROI = Rectangle.Empty;

                //If we are able to find eyes inside the possible face, it should be a face, maybe we find also a couple of eyes
                if (leftEyesDetected[0].Length != 0 &amp;&amp; rightEyesDetected[0].Length != 0)
                {
                    //draw the face
                    frame.Draw(face.rect, new Bgr(Color.Violet), 2);


                    #region Hough Circles Eye Detection

                    grayFrame.ROI = possibleROI_leftEye;
                    CircleF[] leftEyecircles = grayFrame.HoughCircles(new Gray(180), new Gray(70), 5.0, 10.0, 1, 200)[0];
                    grayFrame.ROI = Rectangle.Empty;
                    foreach (CircleF circle in leftEyecircles)
                    {
                        float x = circle.Center.X + startingLeftEyePointOptimized.X;
                        float y = circle.Center.Y + startingLeftEyePointOptimized.Y;
                        frame.Draw(new CircleF(new PointF(x, y), circle.Radius), new Bgr(Color.RoyalBlue), 4);
                    }

                    grayFrame.ROI = possibleROI_rightEye;
                    CircleF[] rightEyecircles = grayFrame.HoughCircles(new Gray(180), new Gray(70), 2.0, 20.0, 1, 5)[0];
                    grayFrame.ROI = Rectangle.Empty;

                    foreach (CircleF circle in rightEyecircles)
                    {
                        float x = circle.Center.X + startingPointSearchEyes.X;
                        float y = circle.Center.Y + startingPointSearchEyes.Y;
                        frame.Draw(new CircleF(new PointF(x, y), circle.Radius), new Bgr(Color.RoyalBlue), 4);
                    }

                    #endregion
</code></pre>

<hr>

<p>Now I changed the part where it finds the eyes to</p>

<pre><code> grayImageFrame.ROI = possibleROI_leftEye;
                CircleF[] leftEyecircles = grayImageFrame.HoughCircles(new Gray(180), new Gray(70), 5.0, 10.0, 1, 20)[0];
                if (leftEyecircles.Length &gt; 0)
                {
                    CircleF firstCircle = leftEyecircles[0]; // Pick first circle in list
                    float x = firstCircle.Center.X + startingPointSearchEyes.X;
                    float y = firstCircle.Center.Y + startingPointSearchEyes.Y;
                    ImageFrame.Draw(new CircleF(new PointF(x, y), firstCircle.Radius), new Bgr(Color.RoyalBlue), 4);
                }
                grayImageFrame.ROI = possibleROI_rightEye;
                CircleF[] rightEyecircles = grayImageFrame.HoughCircles(new Gray(180), new Gray(70), 5.0, 10.0, 1, 20)[0];
                grayImageFrame.ROI = Rectangle.Empty;

                if (rightEyecircles.Length &gt; 0)
                {
                    CircleF firstCircle = rightEyecircles[0]; // Pick first circle in list
                    float x = firstCircle.Center.X + startingPointSearchEyes.X;
                    float y = firstCircle.Center.Y + startingPointSearchEyes.Y;
                    ImageFrame.Draw(new CircleF(new PointF(x, y), firstCircle.Radius), new Bgr(Color.RoyalBlue), 4);
                }
</code></pre>

<p>Only one circle is showing but it is tracking parts around my eyes not my eyes :(</p>

<p><img src=""https://i.stack.imgur.com/J1HoY.png"" alt=""enter image description here""></p>
",2015-01-30 11:14:04,2015-10-27 07:46:58,EMGU CV real time Eye tracking using C#,<c#><opencv><emgucv><face-detection><eye-tracking>,,,CC BY-SA 3.0,True,False,True,False,False
26899,28290675,2015-02-03 03:05:33,,"<p>I made a camera calibration application following the emgu cv wiki tutorial in C#.
when I run the code several times, each time the intrinsic camera parameter matrix s different to the previous ones. Here I didn't change the camera orientation and neither the image plane. Camera setup is fixed as shown in the image CameraSetup.jpg in the following link.
<a href=""https://www.dropbox.com/sh/hic8i59s7hhiuwx/AACM87EI_hrGvE2ixsQ7NTlAa?dl=0"" rel=""nofollow"">CameraSetup.jpg</a></p>

<p>My code is as follows. I have no idea how to proceed further.
Regards!</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>namespace CameraCallibration
{
    public partial class Form1 : Form
    {
        #region variables

        Capture capture = new Capture(1);

        int bufferIndex;

        const int width = 9;//9 //width of chessboard no. squares in width - 1
        const int height = 6;//6 // heght of chess board no. squares in heigth - 1
        Size patternSize = new Size(width, height); //size of chess board to be detected

        Bgr[] line_colour_array = new Bgr[width * height]; // just for displaying coloured lines of detected chessboard
        static Image&lt;Gray, Byte&gt;[] Frame_array_buffer = new Image&lt;Gray, byte&gt;[100];
        MCvPoint3D32f[][] corners_object_list = new MCvPoint3D32f[Frame_array_buffer.Length][];
        PointF[][] corners_points_list = new PointF[Frame_array_buffer.Length][];

        IntrinsicCameraParameters IC = new IntrinsicCameraParameters();
        ExtrinsicCameraParameters[] EX_Param;

        enum mode
        {
            SavingFrames,
            Caluculating_Intrinsics,
            Calibrated
        };

        mode currentMode = new mode();

        #endregion

        public Form1()
        {
            InitializeComponent();
            timer1.Interval = 10;
            currentMode = mode.SavingFrames;
            bufferIndex = 0;
        }

        private void timer1_Tick(object sender, EventArgs e)
        {
            Image&lt;Bgr, Byte&gt; BgrFrame = capture.QueryFrame();
            imageBox1.Image = BgrFrame.Resize(320, 240, Emgu.CV.CvEnum.INTER.CV_INTER_NN);

            Image&lt;Gray, Byte&gt; GrayFrame = BgrFrame.Convert&lt;Gray, Byte&gt;();
            imageBox2.Image = GrayFrame.Resize(320, 240, Emgu.CV.CvEnum.INTER.CV_INTER_NN);

            if(currentMode == mode.SavingFrames)
            {
                Frame_array_buffer[bufferIndex] = GrayFrame.Copy();
                bufferIndex++;

                if(bufferIndex == Frame_array_buffer.Length)
                {
                    currentMode = mode.Caluculating_Intrinsics;
                    textBox1.Text = ""Frames Saved"";
                    timer1.Enabled = false;
                }
            }

            if(currentMode == mode.Caluculating_Intrinsics)
            {
                for(int i = 0; i &lt; Frame_array_buffer.Length ; i++)
                {
                    corners_points_list[i] = CameraCalibration.FindChessboardCorners(GrayFrame, patternSize, Emgu.CV.CvEnum.CALIB_CB_TYPE.ADAPTIVE_THRESH);

                    List&lt;MCvPoint3D32f&gt; object_list = new List&lt;MCvPoint3D32f&gt;();
                   
                    for(int j = 0; j &lt; height; j++)
                    {
                        for(int k = 0; k &lt; width; k++)
                        {
                            object_list.Add(new MCvPoint3D32f(k * 20.0F, j * 20.0F, 0.0F));
                        }
                    }

                    corners_object_list[i] = object_list.ToArray();
                }

                double difError =  CameraCalibration.CalibrateCamera(corners_object_list, corners_points_list, GrayFrame.Size, IC, Emgu.CV.CvEnum.CALIB_TYPE.CV_CALIB_RATIONAL_MODEL,out EX_Param);

                currentMode = mode.Calibrated;
                textBox1.Clear();
                textBox1.Text = ""Calculated"";
            }

            if(currentMode == mode.Calibrated)
            {
                //calculate the camera intrinsics
                Matrix&lt;Single&gt; Map1, Map2;
                IC.InitUndistortMap(BgrFrame.Width,BgrFrame.Height,out Map1,out Map2);
                //remap the image to the particular intrinsics
                //In the current version of EMGU any pixel that is not corrected is set to transparent allowing the original image to be displayed if the same
                //image is mapped backed, in the future this should be controllable through the flag '0'
                Image&lt;Bgr, Byte&gt; temp = BgrFrame.CopyBlank();
                CvInvoke.cvRemap(BgrFrame, temp, Map1, Map2,0,new MCvScalar(0) );
                imageBox3.Image = temp.Resize(320,240,Emgu.CV.CvEnum.INTER.CV_INTER_NN);
                textBox1.Clear();
                textBox1.Text = ""Calibrated"";

                Matrix&lt;double&gt; IntrParaMat = IC.IntrinsicMatrix;

                for(int i =0 ; i &lt; IntrParaMat.Rows ; i++)
                {
                    for(int j =0 ; j &lt; IntrParaMat.Cols; j++)
                    {
                        textBox2.Text += Convert.ToString( IntrParaMat[i, j]) + ""  "";
                    }
                    textBox2.Text += Environment.NewLine;
                }
            }
        }

        private void button1_Click(object sender, EventArgs e)
        {
                timer1.Enabled = true;
                button1.Enabled = false; 
        }
}</code></pre>
</div>
</div>
</p>
",,2019-01-01 11:32:54,Intrinsic Camera Parameter Matrix is not always same after calibrated the camera several times,<c#><emgucv><camera-calibration>,,,CC BY-SA 3.0,False,False,True,False,False
26994,25884241,2014-09-17 07:01:44,,"<p>I am a newbie in computer vision, can anyone help me to solve the error? I have an error in for loop condition. </p>

<pre><code>private void timer1_Tick(object sender, EventArgs e) 
{ 
    double cannyThreshold = 180.0; 
    double circleAccumulatorThreshold = 120; 
    double cannyThresholdLinking = 160;
    Image&lt;Bgr, Byte&gt; imagez5 = capturez.QueryFrame().Resize(400, 400, Emgu.CV.CvEnum.INTER.CV_INTER_LINEAR, true);
    pictureBox2.Image = imagez5.Bitmap;
    Image&lt;Gray, Byte&gt; gray = imagez5.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();
    Image&lt;Gray, byte&gt; imagez7 = gray.Canny(cannyThreshold, cannyThresholdLinking);
    CircleF[] circlez = imagez7.HoughCircles(new Gray(cannyThreshold), new Gray(circleAccumulatorThreshold), 1, 60, 3, 300)[0];
    Image&lt;Bgr, Byte&gt; circleImage = imagez5.CopyBlank();

    for (int i =0; i&lt;=circlez.Length; i++)
    {
        imagez7.Draw(circlez[i], new Gray(255), 3);
    }
    pictureBox1.Image = imagez7.Bitmap;
}
</code></pre>
",2017-01-29 07:25:42,2017-01-29 07:25:42,Index OutOfRange Exception was unhandled in opencv circle detection,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
27080,28323408,2015-02-04 14:07:28,,"<p>I created prove-of-concept console application, which is using EmguCV for template matching. Version of openCV is 2.4.</p>

<p>Now I have problems with my real-life asp.net mvc application. I have a runtime error:</p>

<blockquote>
  <p>The type initializer for 'Emgu.CV.CvInvoke' threw an exception.
  System.DllNotFoundException: Unable to load DLL 'opencv_core2410': The specified module could not be found.</p>
</blockquote>

<p>Saw several other question, but they are incomplete or don't have answers:</p>

<ol>
<li><p><a href=""https://stackoverflow.com/questions/26634157/how-use-emgucv-in-a-mvc-net-project"">How use EmguCV in a MVC.NET project</a></p></li>
<li><p><a href=""https://stackoverflow.com/questions/24299467/errorthe-type-initializer-for-emgu-cv-cvinvoke-threw-an-exception"">Error:The type initializer for &#39;Emgu.CV.CvInvoke&#39; threw an exception</a></p></li>
</ol>

<p>What I've already tried:</p>

<ol>
<li><p>Copied folders x64 and x86 from EmguCV installation into published bin folder(these folders contains opencv dlls)</p></li>
<li><p>Added opencv dlls to my web project and set them to ""Copy to output directory"" as described here: <a href=""http://www.codeproject.com/Articles/257502/Creating-Your-First-EMGU-Image-Processing-Project"" rel=""nofollow noreferrer"">http://www.codeproject.com/Articles/257502/Creating-Your-First-EMGU-Image-Processing-Project</a></p></li>
<li><p>Please note, it's working well in concole application, but not in mvc.</p></li>
</ol>
",2017-05-23 12:14:04,2015-08-11 23:35:51,Tutorial how to use EmguCV in Asp.Net MVC application,<c#><asp.net-mvc><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
27086,25889414,2014-09-17 11:31:34,,"<p>I am developing an OCR application in EmguCV. My target is to achieve the same results as done by Capture2Text. </p>

<p>Capture2Text uses Tesseract engine for OCR and Leptonica library for Preprocessing. As we know EmguCV is using Tesseract engine for OCR therefore we are left with Preprocessing.</p>

<p>Preprocessing in Capture2Text is done by calling the functions of Leptonica in the following order with specific values. The actual code file is available in the <a href=""http://sourceforge.net/projects/capture2text/files/Capture2Text/Capture2Text_v3.5/"" rel=""nofollow"">leptonica_util.c</a> uner the folder ...\Capture2Text_v3.5\Capture2Text\SourceCode\leptonica_util</p>

<p>Read in source image
Convert to grey scale
Perform auto negate image
Scale the image (linear interpolation)
Apply unsharp mask
Perform Otsu Binarize</p>

<p>Out of these two possible options, which one is better to follow and how ?</p>

<ol>
<li>Use Leptonica library in EmguCV by including it in the code and then calling the same functions with same parameters.</li>
<li>Try to find and use equivalent functions already available in EmguCV.</li>
</ol>

<p>I have tried to go for option 1, but could not do it properly. For 2nd option I am not sure where to look specifically in EmguCV.</p>
",,2014-10-07 05:39:28,How to preprocess in EmguCV with Leptonica as done in Capture2Text,<c#><emgucv><leptonica>,,,CC BY-SA 3.0,False,False,True,False,False
27093,28433826,2015-02-10 14:13:54,,"<p>I have a bitmap in BGR format and resolution 1920*1200 and want to scale it without changing the pixelformat. </p>

<pre><code>private Bitmap rescale(Size size, Bitmap origin)
{
    Bitmap scaled = new Bitmap(origin, size);
    return scaled;
}
</code></pre>

<p>the problem is, that scaled turns out to be a RGBA bitmap(all alphas at 255), which is not only useless to me, but also troubles me as later I am doing a AbsDiff (from EMGU) on different images and then, the alpha value always turns out zero..
Is there a way to not change the pixelformat when scaling or to do AbsDiff without the alpha-values? Because like this, when I load the image later, it is invisible..</p>
",,2015-02-10 15:20:36,C# Resizing Bitmap without changing the Pixelformat,<c#><bitmap><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
27113,28415161,2015-02-09 17:01:54,,"<p>I have created my own cascade classifier using opencv_traincascade, i am trying to use it in my C# emgu project but it does not work using HaarCascade. I did some reading and found that CascadeClassifier is required to load xml files obtained through opencv_traincascade, But i could not find the namespace where the class is located. How to use CascadeClassifier in emgu c# project?</p>
",,2015-02-10 07:42:31,How to load a CascadeClassifier using Emgu c#,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
27134,28398673,2015-02-08 19:57:18,,"<p>When I ran my C# WinForms executable outside of the Visual Studio IDE for the very first time, I received the following dialog:</p>

<pre><code>""&lt;Application&gt; has stopped working, Windows can check online...""
</code></pre>

<p>So I attached to the process using Visual Studio's Attach to Process, which showed that the program had suspended within <code>InitializeComponent()</code> (but did not provide further clues).</p>

<p>I edited the application, placed a try/catch block around the aforementioned code, which allowed me to print the following <code>MessageBox</code> output:</p>

<p><a href=""https://imgur.com/3KZKSwq"" rel=""nofollow noreferrer""><img src=""https://i.imgur.com/3KZKSwq.png"" title=""source: imgur.com"" /></a></p>

<p>As you can see, this showed that the application is not able to find a DLL it needs.</p>

<p>My question: Could I have achieved this result without modifying the application (that is, without the try/catch block printing out the specifics)?  Could Visual Studio Attach to Process functionality guide me to the specific problem being the missing DLL? If so, how?</p>
",2015-02-08 20:06:25,2015-02-08 20:10:04,Debugging .NET crash that does not happen within Visual Studio IDE,<c#><visual-studio><emgucv><attach-to-process>,,,CC BY-SA 3.0,False,False,True,False,False
27170,28400677,2015-02-08 23:36:06,,"<p>How to convert this C++ OpenCV code to C# Emgu CV code?   </p>

<pre><code>typedef Point3_&lt;double&gt; Point3d;
typedef DataType&lt;double&gt; Type1;
typedef Vec&lt;double, 2&gt; Type2;
typedef Mat_&lt;double&gt; Type3;
typedef Point_&lt;double&gt; Point2d;
</code></pre>

<p>Maybe it looks easy, but I could not find <strong>Point3_</strong> in Emgu CV.</p>
",2015-02-09 08:13:10,2015-02-09 08:13:10,Convert OpenCV code to Emgu CV,<c#><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
27172,28401217,2015-02-09 00:46:11,,"<p>I'm using the official Kinect SDK 2.0 and Emgu CV in order to recognize the colors of a Rubik's Cube.</p>

<p><img src=""https://i.stack.imgur.com/eB1a2.jpg"" alt=""enter image description here""></p>

<p>At first I use Canny Edge Extraction on the Infrared Camera since it handles different lightning conditions better than the RGB Camera and is much better to detect contours.</p>

<p>Then I use this code to convert the coordinates of the infrared sensor to the ones of the RGB camera.
As you can see the in the picture they are still off from what I am looking for. Since I already use the official <code>KinectSensor.CoordinateMapper.MapDepthFrameToColorSpace</code> I don't know how else I can improve the situation.</p>

<pre><code>using (var colorFrame = reference.ColorFrameReference.AcquireFrame())
using (var irFrame = reference.InfraredFrameReference.AcquireFrame())
{
    if (colorFrame == null || irFrame == null)
        return;

    // initialize depth frame data 
    FrameDescription depthDesc = irFrame.FrameDescription;

    if (_depthData == null)
    {
        uint depthSize = depthDesc.LengthInPixels;
        _depthData = new ushort[depthSize];
        _colorSpacePoints = new ColorSpacePoint[depthSize];

         // fill Array with max value so all pixels can be mapped
         for (int i = 0; i &lt; _depthData.Length; i++)
         {
             _depthData[i] = UInt16.MaxValue;
         }
         // didn't work so well with the actual depth-data
         //depthFrame.CopyFrameDataToArray(_depthData);

        _sensor.CoordinateMapper.MapDepthFrameToColorSpace(_depthData, _colorSpacePoints);
    }
}
</code></pre>

<p>This is a helper-function I created in order to convert Point-Arrays in Infrared-Space to Color-Space</p>

<pre><code>public static System.Drawing.Point[] DepthPointsToColorSpace(System.Drawing.Point[] depthPoints, ColorSpacePoint[] colorSpace){
        for (int i = 0; i &lt; depthPoints.Length; i++)
        {
            // 512 is the width of the depth/infrared image
            int index = 512 * depthPoints[i].Y + depthPoints[i].X;

            depthPoints[i].X = (int)Math.Floor(colorSpace[index].X + 0.5);
            depthPoints[i].Y = (int)Math.Floor(colorSpace[index].Y + 0.5);
        }
        return depthPoints;
    }
</code></pre>
",,2020-05-27 16:41:06,Kinect v2 Alignment of Infrared Sensor & RGB Image always slightly off,<c#><opencv><image-processing><kinect><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
27176,28384416,2015-02-07 16:19:40,,"<p>As the title suggest, I'm using Emgucv with Unity to perform a face detection. 
Inside the package downloaded from the website there is an example that, given a Texture2D, returns an image with a rectangle on the face of the subject represented.
Everything seems easy but when I try to detect a face in real time comes up a problem. Converting a WebCamTexture into a Texture2D everything seems to work fine but when I try to convert the Texture2D into an Image (class that wraps the IplImage of OpenCV) using TextureConverter (given from Emgucv) it gives me a grey image. 
Here is the simple code I use:</p>

<pre><code>void Start()
{
    WebCamDevice[] devices = WebCamTexture.devices;
    int cameraCount = devices.Length;

    if (cameraCount == 0)
    {
        Image&lt;Bgr, Byte&gt; img = new Image&lt;Bgr, byte&gt;(640, 240);
        CvInvoke.PutText(img, String.Format(""{0} camera found"", devices.Length), new System.Drawing.Point(10, 60),
                         Emgu.CV.CvEnum.FontFace.HersheyDuplex,
                         1.0, new MCvScalar(0, 255, 0));
        Texture2D texture = TextureConvert.ImageToTexture2D(img, FlipType.Vertical);

        this.guiTexture.texture = texture;
        this.guiTexture.pixelInset = new Rect(-img.Width/2, -img.Height/2, img.Width, img.Height);
    }
    else
    {
        webcamTexture = new WebCamTexture(devices[0].name);

        baseRotation = transform.rotation;
        webcamTexture.Play();
        data = new Color32[webcamTexture.width * webcamTexture.height];
        CvInvoke.CheckLibraryLoaded();
    }

    tx2d = new Texture2D(webcamTexture.width, webcamTexture.height);
    tx2d.UpdateExternalTexture(webcamTexture.GetNativeTexturePtr());

    String fileName = ""haarcascade_frontalface_alt2"";
    filePath = Path.Combine(Application.persistentDataPath, fileName + "".xml"");

    {
        //updateTextureWithString(""start move cascade xml"");
        TextAsset cascadeModel = Resources.Load&lt;TextAsset&gt;(fileName);

        #if UNITY_METRO
        UnityEngine.Windows.File.WriteAllBytes(filePath, cascadeModel.bytes);
        #else
        File.WriteAllBytes(filePath, cascadeModel.bytes);
        #endif
        //updateTextureWithString(""File size: "" + new FileInfo(filePath).Length);
    }
}

void Update()
{
    if (webcamTexture != null &amp;&amp; webcamTexture.didUpdateThisFrame &amp;&amp; tx2d != null)
    {           
        //OLD: this method is very expansive. Is preferable to use the reference to the array of pixels -&gt; tx2d.UpdateExternalTexture(webcamTexture.GetNativeTexturePtr());
        //tx2d.SetPixels(webcamTexture.GetPixels());
        //tx2d.Apply();

        img = TextureConvert.Texture2dToImage&lt;Rgba, Byte&gt;(tx2d, FlipType.Vertical);

        using (CascadeClassifier classifier = new CascadeClassifier(filePath))
        using (Image&lt;Gray, Byte&gt; gray = img.Convert&lt;Gray, byte&gt;())
        {
            //updateTextureWithString(""classifier create ok"");
            Rectangle[] faces = null;
            try
            {                       
                faces = classifier.DetectMultiScale(gray);
                Debug.Log(""faces: "" + faces.Length.ToString());

                //updateTextureWithString(""face detected"");
                foreach (Rectangle face in faces)
                {
                    CvInvoke.Rectangle(img, face, new MCvScalar(0, 255, 0));
                }

            }
            catch (Exception e)
            {
                Debug.Log (e.ToString());
                //updateTextureWithString(e.Message);
                return;
            }


            //updateTextureWithString(String.Format(""{0} face found on image of {1} x {2}"", faces.Length, img.Width, img.Height));
        }

        renderer.material.mainTexture = TextureConvert.ImageToTexture2D(img, FlipType.None);    
    }
</code></pre>

<p>Note that if I use the code commented as OLD, the Texture2D is converted fine.</p>

<p>I have a second question now. I noted that if I give an Image over than 512x512 to the Classifier Unity crashes and no errors are ""thrown out"".</p>

<p>Can someone help me?</p>
",2015-02-10 13:42:44,2015-02-10 13:42:44,Converting a WebCamTexture into IplImage of OpenCV gives me a grey image,<c#><unity3d><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
27181,28460035,2015-02-11 16:59:11,,"<p>I have the following EMGU CV code to create a histogram for a grayscale image:</p>

<pre><code>Image&lt;Bgr, Byte&gt; img = new Image&lt;Bgr,
    Byte&gt;(fileNameTextBox.Text).Resize(400, 400,
    Emgu.CV.CvEnum.INTER.CV_INTER_LINEAR, true);

// Convert to grayscale and filter out noise.
Image&lt;Gray, Byte&gt; gray = img.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();

DenseHistogram dh = new DenseHistogram(256, new RangeF(0, 255));
dh.Calculate(new Image&lt;Gray, Byte&gt;[] { gray }, false, null);
float[] valHist = new float[256];           // # of bins: 256
dh.MatND.ManagedArray.CopyTo(valHist, 0);
float total = 0F;
for (int ii = 0; ii &lt; 256; ii++)
{
    total += valHist[ii];
}
MessageBox.Show(""Bins total: "" + total);
</code></pre>

<p>I run the above code with the following image (the original image does not contain the border around it - I have added it here for demarcation):</p>

<p><a href=""https://imgur.com/Cr1OnFQ"" rel=""nofollow noreferrer""><img src=""https://i.imgur.com/Cr1OnFQ.png"" title=""source: imgur.com"" /></a></p>

<p>The image is 384 by 282, which makes 108,288 pixels.  But the total of the contents of the histogram's 256 bins is 4,724 (as shown by the <code>MessageBox</code> code).  Shouldn't the total be 108,288?  (Maybe I am missing the fundamentals for the concept of histograms?)</p>

<p>(Disclaimer: I am new to both image processing and EMGU CV, and although I have done research, there are relatively few EMGU questions here on SO, and all the other content on the web seems to be copies of questions here.)</p>
",2015-02-15 19:23:38,2015-02-16 12:56:50,Histogram bin totals do not equal to image pixel size,<opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
27199,28463326,2015-02-11 19:57:40,,"<p>Good day! I am having a problem in decoding a QR Code using ZXing and Emgu CV demo particularly in the Emgu CV invoke exception issue. I can perfectly run the program with the use of my computer(the terminal in which I tested it) but after transferring the program to another computer. I get this exception.</p>
<p><a href=""http://i61.tinypic.com/4grexc.png"" rel=""nofollow noreferrer"">http://i61.tinypic.com/4grexc.png</a></p>
<p>I searched the web for solutions but I can't seem to find a fitting solution.</p>
<p>Here's what I've tried so far:</p>
<blockquote>
<p>(1) Replace the DLLs with fresh ones from which the project contains and is referenced to.</p>
<p>(2) Double check the assembly version (x86) for the new terminal also.</p>
</blockquote>
<p>What I would like to know too:</p>
<blockquote>
<p>Should I install, download a new copy of Emgu CV libraries for the new terminal and every terminal if I were to distribute copies?</p>
</blockquote>
<p>Your ideas are very much appreciated!</p>
",2020-06-20 09:12:55,2018-10-03 09:40:48,EmguCV.CV.CvInvoke exception,<c#><visual-studio-2010><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
27260,28501980,2015-02-13 14:39:28,,"<p>I got a binary Image(from EMGU) A and I want to get out a bitmap that is transparent everywhere where A is black and a transparent red everywhere, where A is white. For the beginning I wanted to at least make the black part invisible, which already failed:</p>

<p>I tried to do so by the following:</p>

<pre><code>private Graphics graphics;
private Bitmap bitmap;
private Image&lt;Gray, Byte&gt; mask;

//graphic, bitmap and mask are being initialized in the constructor of the object
public Bitmap getMask()
{
    //...
    graphics.clear(Color.FromArgb(0,0,0,0);
    graphics.DrawImage(mask.ToBitmap(), 0, 0);
    bitmap.makeTransparent(255, 0, 0, 0);

    //...
}
</code></pre>

<p>how do I do it with the white to red - part?
is there a easier/more efficient way to do it maybe by using EMGU?</p>
",,2015-02-13 16:34:19,C# get from binary Image to transparent Bitmap,<c#><bitmap><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
27271,28503289,2015-02-13 15:44:40,,"<p>I'm using Visual Studio 11 and <code>EmguCV</code> libraries, and I'm trying to capture images from camera. The <code>Emgu.CV.Capture</code> function works perfectly, when I use in-build or usb RGB camera but when I want to capture from <code>See3CAM_10CUG_CBX</code> camera(which is a raw bayer camera) the Capture function had stopped working.
I already have installed the cameras driver.
When I enable native code debugging I get these errors: </p>

<pre><code>Bayer_Transform_Filter.dll 1, 0,13,e_CAMVIEW_SVN_VERSION
C:\Windows\SysWOW64\Bayer_Transform_Filter.pdb:Cannot find or open the PDB file.
E:\E-CAMView\Oct21(Solving Moniker issue in eCAM1M_CUGUSB)\Release\Bayer_Transform_Filter.pdb:Cannot find or open the PDB file.
C:\Windows\symbols\dll\Bayer_Transform_Filter.pdb:Cannot find or open the PDB file.
C:\Windows\dll\Bayer_Transform_Filter.pdb:Cannot find or open the PDB file.
C:\Windows\Bayer_Transform_Filter.pdb:Cannot find or open the PDB file.
</code></pre>

<p>Do you have any idea how can I fix this problem, or any idea how to capture frames from raw bayer in Visual Studio C# because EmguCV's Capture function doesnt work?</p>
",2015-02-14 02:17:39,2017-07-26 05:24:52,EmguCV video capture for raw bayer camera,<c#><opencv><video-capture>,,,CC BY-SA 3.0,True,False,True,False,False
27319,28505252,2015-02-13 17:26:53,,"<p>I'm newbie in using Emgu CV and started to create small sample projects, for example face detection, eye detection,..etc. It would be good if I could take the advantage of OpenCL to accelerate the process using gpu. Otherwise, it causes massive cpu utilization when I decrease the scaleFactor. How can I do that? Thanks.</p>
",,2015-08-16 14:00:52,How do I take the advantage of OpenCL in an Emgu CV project,<c#><parallel-processing><opencl><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
27355,28524097,2015-02-15 08:00:51,,"<p>this is my code:</p>

<pre><code>Capture cap = new Capture(""rtsp://192.168.226.201:554/profile1"");
fps = (int)cap.GetCaptureProperty(CAP_PROP.CV_CAP_PROP_FPS);
Application.Idle += process;
private void process(object sender, EventArgs e)
{
    frame = cap.QueryFrame();
    if (frame == null)
        return;
    imageBox1.Image = frame;
    System.Threading.Thread.Sleep(1000 /fps);
}
</code></pre>

<p>This code works correctly
But after a few seconds returns Damaged frame
like this:
<a href=""http://www.quranmp3.ir/images/1/1111.jpg"" rel=""nofollow"">http://www.quranmp3.ir/images/1/1111.jpg</a></p>

<p>The question is:
What is your solution for this problem.</p>
",2015-02-15 08:47:39,2015-02-16 09:12:46,returns Damaged frame,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
27366,28492502,2015-02-13 04:28:13,,"<p>I'm doing Web camera App in Visual Studio 2012. When I build my program, I got this type of error.An unhandled exception of type <code>System.TypeInitializationException</code> occurred in Emgu.CV.dll</p>

<p>Additional information: The type initializer for <code>Emgu.CV.CvInvoke</code> threw an exception.</p>

<p>Error Log:</p>

<pre><code>A first chance exception of type 'System.ArgumentException' occurred in mscorlib.dll
A first chance exception of type 'System.DllNotFoundException' occurred in Emgu.CV.dll
A first chance exception of type 'System.TypeInitializationException' occurred in Emgu.CV.dll
An unhandled exception of type 'System.TypeInitializationException' occurred in Emgu.CV.dll
Additional information: The type initializer for 'Emgu.CV.CvInvoke' threw an exception.
The thread '&lt;No Name&gt;' (0x19d4) has exited with code 0 (0x0).
The program '[8784] CameraApp.vshost.exe: Program Trace' has exited with code 0 (0x0).
The program '[8784] CameraApp.vshost.exe: Managed (v4.0.30319)' has exited with code 0 (0x0).
</code></pre>
",2015-07-30 05:21:41,2015-08-14 17:12:45,An unhandled exception of type 'System.TypeInitializationException' occurred in Emgu.CV.dll,<c#><.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
27409,28547346,2015-02-16 17:48:56,,"<p>When extracting a specific color channel from an image, the following code is used in EMGU CV:</p>

<pre><code>EMGU.CV.UI.ImageBox originalImage;
EMGU.CV.UI.ImageBox bChannel;
...
Image&lt;Bgra, Byte&gt; image = new Image&lt;Bgra, Byte&gt;(filename);
originalImage = image;
bChannel = image[0]; // Index 0 is the blue channel (for BGRA).
</code></pre>

<p>Unfortunately, the resulting image assigned to <code>ImageBox bChannel</code> is in grayscale, <em>not</em> blue.  How can I display the image in its own hue (in this case, in blue)?</p>

<p>Eventually I would like to come up w/ a UI similar to the following:</p>

<p><a href=""https://imgur.com/NNHS7V3"" rel=""nofollow noreferrer""><img src=""https://i.imgur.com/NNHS7V3.jpg"" title=""source: imgur.com"" /></a>
<br>
PS: Additionally tagging this question w/ the ""OpenCV"" tag, based on the reasoning that EMGU is a wrapper for that library. :)</p>
",,2015-02-20 23:26:18,How to display a color channel in its own hue?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
27474,28549530,2015-02-16 20:11:10,,"<p>Following is from the EMGU CV documentation (taken from <a href=""http://www.emgu.com/wiki/files/2.4.10/document/html/e0764906-a5b4-340e-0ed2-0dd969ff80ca.htm"" rel=""nofollow"">here</a>):</p>

<pre><code>DenseHistogram.Calculate&lt;TDepth&gt; Method (Image&lt;Gray, TDepth&gt;[], 
    Boolean, Image&lt;Gray, Byte&gt;)
</code></pre>

<p>And the following is sample usage from an actual application:</p>

<pre><code>dh.Calculate(new Image&lt;Gray, Byte&gt;[] { img[0] }, false, null);
</code></pre>

<p>where <code>dh</code> has been created as a <code>DenseHistogram</code>.</p>

<p>What purpose does the <code>&lt;TDepth&gt;</code> serve (immediately after <code>Calculate</code>)? It has not been used in the sample code, but does not seem to cause a problem, although nothing in the documentation indicates it is optional.</p>
",,2015-02-16 20:30:49,Trying to understand the signature of a C# method,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
27491,28572016,2015-02-17 22:05:37,,"<p>I am writing a C# application that is GPU accelerated using EMGU's GpuInvoke method.  I would like to profile my code and look at the load on the GPU and the amount of GPU memory I'm using, but I'm having trouble finding a good way to do that.  It seems like it should be simple, but I can't figure out what I'm missing.</p>

<p>Thank you</p>
",,2015-02-17 22:32:46,Profiling GPU usage in C#,<c#><gpu><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
27563,28559364,2015-02-17 10:04:12,,"<pre><code>private void ProcessFrame(object sender, EventArgs arg)
 {


            Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
            if (ImageFrame != null)
            {
                Image&lt;Gray, Byte&gt; grayframe = ImageFrame.Convert&lt;Gray, Byte&gt;();

                          var faces =  grayframe.DetectHaarCascade(haar)[0];

                foreach (var face in faces)
                {
                    ImageFrame.Draw(face.rect, new Bgr(Color.Green), 3);
                }
            }
            CamImageBox.Image = ImageFrame;

        }
</code></pre>

<p>I am having an exception on run-time. It says:</p>

<pre><code>NullReferenceException was unhandled
</code></pre>

<p>here: </p>

<pre><code>var faces = grayframe.DetectHaarCascade(haar, 1.4, 4, HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(25, 25))[0`];
</code></pre>
",2015-02-17 10:28:28,2015-02-17 10:28:28,Run time error in face detection in emguCV,<c#><emgucv>,2015-02-17 10:37:55,,CC BY-SA 3.0,False,False,True,False,False
27641,28652654,2015-02-21 23:29:32,,"<p>I can access all emgu libraries. VS finds the libraries and <code>using Emgu.CV.OCR</code> returns no errors.</p>

<p>When I try to create a <code>Tesseract</code> object, Program.cs throws a <code>FileLoadException</code>. in <code>System.Windows.Forms.dll</code>. </p>

<p>Removing the line of code that creates a tesseract lets the program run fine.</p>

<p>I have tried copying tessdata to my debug file and that also has not worked.</p>

<p>Here is my code:</p>

<pre><code>private void button1_Click(object sender, EventArgs e)
    {
        Tesseract _ocr;
        _ocr = new Tesseract(@""tessdata"", ""eng"", Tesseract.OcrEngineMode.OEM_TESSERACT_CUBE_COMBINED);

        OpenFileDialog Openfile = new OpenFileDialog();
        if (Openfile.ShowDialog() == DialogResult.OK)
        {
            Image&lt;Bgr, Byte&gt; My_Image = new Image&lt;Bgr, byte&gt;(Openfile.FileName);
            pictureBox1.Image = My_Image.ToBitmap();
        }
    }
</code></pre>
",,2019-02-07 15:57:26,Emgu CV C# Exception creating tesseract object,<c#-4.0><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
27725,28646606,2015-02-21 13:56:39,,"<p>I am currently working on a project where I have to do real-time video treatment.  The first step consists in binarizing the video.</p>

<p>I am using Visual studio with Emgu cv, I've never done c# before so I am struggling a little.</p>

<p>I have a problem with opening a video in a Windows Form. I found how to do it in a Windows Media Player but I can't binarize the video inside the Windows Media Player. </p>

<p>I found a tutorial on Youtube (<a href=""https://www.youtube.com/watch?v=vdjoutNR2DQ"" rel=""nofollow"">https://www.youtube.com/watch?v=vdjoutNR2DQ</a>) which explains how to binarize a Webcam feed in an ImageBox, but I can't find a way to do this with a video I have on my computer (.wmv).</p>

<p>Thank You for your help :)</p>
",,2015-02-22 18:53:07,Video treatment in Visual Studio with Emgu cv in c#,<c#><visual-studio><video><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
27766,28662181,2015-02-22 19:21:28,,"<p>I've finally figured out how to make my own classifier and I've managed to make a decent good one working, but the problem now is the accuracy</p>

<p>I have different angles for vehicles that I want to combine into one strong classifier so it'd be able to detect vehicles from front view and side view, the workaround I've concluded is making 2 regions of interest, each using different classifier (one working with front view, other is side view), is this the best workaround for it?</p>

<p>as far as I know the haarcascade classifier extracts features from a selected object and train on that feature.</p>

<p>I also need help with improving my classifiers, is it enough to feed positive/negative photos only to improve it? or I need to change scaling and stuff? and what's the best ratio [+ve/-ve] photos used for training and best stages level</p>

<p>Thanks in advance and sorry for the long post!</p>
",,2015-02-22 19:21:28,Making a Strong HaarCascade Classifier,<c#><emgucv><haar-classifier>,,,CC BY-SA 3.0,False,False,True,False,False
27789,27070002,2014-11-21 20:42:34,,"<p>I'm using EmguCV and trying to find polygons within an image.  Here are some facts about the problem:</p>

<p>1) The polygons are irregularly shaped, but the sides are always at one of two angles.</p>

<p>2) Often the polygons have gaps in their sides that need to be filled.</p>

<p>3) If a polygon is contained within another polygon, I want to ignore it.</p>

<p>Consider this image:</p>

<p><img src=""https://i.stack.imgur.com/OHBYO.png"" alt=""enter image description here""></p>

<p>And I want to find the polygons highlighted in red, omit the polygon highlighted in green and make connections across gaps as shown in blue here:</p>

<p><img src=""https://i.stack.imgur.com/k5FA0.png"" alt=""enter image description here""></p>

<p>I've had some success using HoughLinesBinary and then connecting the closest line segment end points to each other to bridge gaps to build a complete polygon, but this doesn't work when multiple polygons are involved since it will try to draw lines between polygons if they happen to be close to each other.  </p>

<p>Anybody have any ideas?</p>
",2014-11-23 01:29:26,2014-11-24 16:48:01,OpenCV find polygons,<opencv><polygon><detection><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
27790,28722472,2015-02-25 15:08:00,,"<p>In this image there are some lines and some elliptical (circular) patterns on these lines. </p>

<p>I want to detect these elliptical patterns in C# using <code>Emgu.CV</code> and <code>OpenCV</code> functions. Can any body please help me where should I start and what should I do first to detect these elliptical patterns?</p>

<p><img src=""https://dl.dropboxusercontent.com/u/71584543/image.png"" alt=""Image""></p>
",2015-02-25 15:11:02,2015-02-25 17:06:12,Detecting Elliptical patterns in image,<c#><opencv><image-processing><emgucv><feature-detection>,2015-02-25 23:51:53,,CC BY-SA 3.0,True,False,True,False,False
27803,28696897,2015-02-24 13:19:34,,"<p>I'm currently using Kinect SDK with C# ( WPF application). I need to get RGB stream and process the images with EMGU library.
The problem is when i try to process the image with EMGU ( like converting image's format and change the colour of some pixels ) the application slows down and takes too long to respond . 
I'm using 8GO RAM / Intel HD graphics 4000 / Intel core i7 . </p>

<p>Here's my simple code :
<a href=""http://pastebin.com/5frLRwMN"" rel=""nofollow"">http://pastebin.com/5frLRwMN</a></p>

<p>Please help me :'(</p>
",2015-02-24 13:31:01,2015-03-02 19:00:20,My application slows down when processing Kinect RGB images with EMGU library,<c#><wpf><sdk><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
27866,28727769,2015-02-25 19:21:00,,"<p>I try to detect faces on picture using emgu CV but i faced an exception</p>

<pre><code>SEHException was unhandled
</code></pre>

<p>on</p>

<p><code>Rectangle[] facesDetected = face.DetectMultiScale(gray, 1.1, 10, new Size(20, 20), Size.Empty);</code></p>

<p>Code:</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;
using Emgu.CV.Structure;
using Emgu.CV;
using System.Runtime.InteropServices;
using Emgu.CV.GPU;
using Emgu.CV.CvEnum;


namespace WindowsFormsApplication1
{
    public partial class Form1 : Form
    {
        Capture capture;
        Image&lt;Bgr, Byte&gt; image;
        bool captureInProgress;
        List&lt;Rectangle&gt; faces = new List&lt;Rectangle&gt;();

        public Form1()
        {
            InitializeComponent();
        }

        void ShowFromCam(object sender, EventArgs e){
            image = capture.QueryFrame();
        }

        private void button1_Click(object sender, EventArgs e)
        {
            if (capture == null)
            {
                try
                {
                    capture = new Capture();

                    CascadeClassifier face = new CascadeClassifier(""haarcascade_frontalface_default.xml"");
                    Image&lt;Gray, Byte&gt;  gray = capture.RetrieveGrayFrame();
                    Rectangle[] facesDetected = face.DetectMultiScale(
                        gray,               //image
                        1.1,                //scaleFactor
                        10,                 //minNeighbors
                        new Size(20, 20),   //minSize
                        Size.Empty);        //maxSize
                    faces.AddRange(facesDetected);
                    //Draw detected faces
                    foreach (Rectangle face1 in faces)
                        image.Draw(face1, new Bgr(Color.Red), 2);
                }
                catch (NullReferenceException excpt)
                {
                    MessageBox.Show(excpt.Message);
                }
            }

            if (capture != null)
            {
                if (captureInProgress)
                {  //if camera is getting frames then stop the capture and set button Text
                    // ""Start"" for resuming capture
                    button1.Text = ""Start!""; //
                    Application.Idle -= ShowFromCam;
                }
                else
                {
                    //if camera is NOT getting frames then start the capture and set button
                    // Text to ""Stop"" for pausing capture
                    button1.Text = ""Stop"";
                    Application.Idle += ShowFromCam;
                }
                captureInProgress = !captureInProgress;
            }
        }
}
</code></pre>

<p>detailed exception:</p>

<pre><code>System.Runtime.InteropServices.SEHException was unhandled
  Message=External component has thrown an exception.
  Source=Emgu.CV
  ErrorCode=-2147467259
  StackTrace:
       at Emgu.CV.CvInvoke.CvCascadeClassifierDetectMultiScale(IntPtr classifier, IntPtr image, IntPtr objects, Double scaleFactor, Int32 minNeighbors, Int32 flags, Size minSize, Size maxSize)
       at Emgu.CV.CascadeClassifier.DetectMultiScale(Image`2 image, Double scaleFactor, Int32 minNeighbors, Size minSize, Size maxSize)
       at WindowsFormsApplication1.Form1.button1_Click(Object sender, EventArgs e) in c:\users\moamen\documents\visual studio 2010\Projects\WindowsFormsApplication1\WindowsFormsApplication1\Form1.cs:line 44
       at System.Windows.Forms.Control.OnClick(EventArgs e)
       at System.Windows.Forms.Button.OnClick(EventArgs e)
       at System.Windows.Forms.Button.OnMouseUp(MouseEventArgs mevent)
       at System.Windows.Forms.Control.WmMouseUp(Message&amp; m, MouseButtons button, Int32 clicks)
       at System.Windows.Forms.Control.WndProc(Message&amp; m)
       at System.Windows.Forms.ButtonBase.WndProc(Message&amp; m)
       at System.Windows.Forms.Button.WndProc(Message&amp; m)
       at System.Windows.Forms.Control.ControlNativeWindow.OnMessage(Message&amp; m)
       at System.Windows.Forms.Control.ControlNativeWindow.WndProc(Message&amp; m)
       at System.Windows.Forms.NativeWindow.DebuggableCallback(IntPtr hWnd, Int32 msg, IntPtr wparam, IntPtr lparam)
       at System.Windows.Forms.UnsafeNativeMethods.DispatchMessageW(MSG&amp; msg)
       at System.Windows.Forms.Application.ComponentManager.System.Windows.Forms.UnsafeNativeMethods.IMsoComponentManager.FPushMessageLoop(IntPtr dwComponentID, Int32 reason, Int32 pvLoopData)
       at System.Windows.Forms.Application.ThreadContext.RunMessageLoopInner(Int32 reason, ApplicationContext context)
       at System.Windows.Forms.Application.ThreadContext.RunMessageLoop(Int32 reason, ApplicationContext context)
       at System.Windows.Forms.Application.Run(Form mainForm)
       at WindowsFormsApplication1.Program.Main() in c:\users\moamen\documents\visual studio 2010\Projects\WindowsFormsApplication1\WindowsFormsApplication1\Program.cs:line 18
       at System.AppDomain._nExecuteAssembly(RuntimeAssembly assembly, String[] args)
       at System.AppDomain.ExecuteAssembly(String assemblyFile, Evidence assemblySecurity, String[] args)
       at Microsoft.VisualStudio.HostingProcess.HostProc.RunUsersAssembly()
       at System.Threading.ThreadHelper.ThreadStart_Context(Object state)
       at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean ignoreSyncCtx)
       at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)
       at System.Threading.ThreadHelper.ThreadStart()
  InnerException: 
</code></pre>

<p>Thanks in advance :)</p>
",2015-02-26 14:49:06,2015-02-26 14:49:06,emgu cv - exception with DetectMultiScale,<c#><visual-studio-2010><opencv><emgucv><face-detection>,,,CC BY-SA 3.0,True,False,True,False,False
27935,28799430,2015-03-01 21:38:38,,"<p>I am running into a problem with setting up a C# environment to develop Emgu. I am trying to do a simple HelloWorld program and a load and display program following the example program and using some reference links. 
 <strong>First</strong>, I tried to build the Hello World and I had a working version by following Chris Johnson's article and stopped right before ""A Simple Program"" and then copied the Hello World program. I was able to build the solution. I then opened a new VS2012 and followed all the steps in Chris Johnson's article but I started running into the exception thrown problem</p>

<pre><code>An unhandled exception of type 'System.TypeInitializationException' occurred    in helloWorld.exe Additional information: The type initializer for 'Emgu.CV.CvInvoke' threw an exception.
</code></pre>

<p>I then went back to trying to build Hello World and that is throwing the same exception. I tried starting completely over with a new Hello World but am still having the same problem. I am able to run the example programs with no problem (from source and from Chris John's website). I am pretty much at a complete loss. Any help would be greatly appreciated. Please let me know if I am missing any information. Thanks!</p>

<p>Below are what I have tried following: </p>

<ul>
<li><p>From Chris Johnson on general set up: <a href=""http://www.codeproject.com/Articles/257502/Creating-Your-First-EMGU-Image-Processing-Project"" rel=""nofollow"">http://www.codeproject.com/Articles/257502/Creating-Your-First-EMGU-Image-Processing-Project</a></p></li>
<li><p>Hello World in C# tutorial from Emgu site: <a href=""http://www.emgu.com/wiki/index.php/Hello_World_in_CSharp"" rel=""nofollow"">http://www.emgu.com/wiki/index.php/Hello_World_in_CSharp</a></p></li>
<li><p>General installation from Emgu (Also tried section ""The type initializer for 'Emgu.CV.CvInvoke' threw an exception."": <a href=""http://www.emgu.com/wiki/index.php/Download_And_Installation"" rel=""nofollow"">http://www.emgu.com/wiki/index.php/Download_And_Installation</a></p></li>
<li><p>Youtube solution of someone with the same problem: <a href=""https://www.youtube.com/watch?v=gaAfi1KjaGM"" rel=""nofollow"">https://www.youtube.com/watch?v=gaAfi1KjaGM</a></p></li>
</ul>

<p>Hardware: Windows 7 Professional x64
Software: Visual Studio Express 2012
Library: emgucv-windows-universal-cuda 2.4.10.1940</p>
",,2015-03-01 21:38:38,Emgu.CV.CvInoke exception VS2012,<c#><opencv><exception><visual-studio-2012><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
27940,28784457,2015-02-28 17:08:09,,"<p>I'm not sure how can I get the histogram chart and display it using MVVM. I found an answer, which although very easy it doesn't fit the MVVM design pattern I have so far and want to keep:
<a href=""https://stackoverflow.com/questions/8204822/how-to-draw-histogram-using-emgucv-and-c-sharp][1]"">How to draw histogram using EmguCV and C#</a></p>

<p>Not very sure how to display this histogramBox control using MVVM. If there would be a proper solution not a workaround to make forms be displayed in MVVM I would be happy, if not the workaround will do it as well.</p>

<p>Can I get the histogram chart as an Image ?, and display it as an Image ? (I can handle that in MVVM).</p>
",2017-05-23 12:22:04,2018-01-29 09:34:55,Display Image Histogram using EmguCV in the context of MVVM WPF,<c#><wpf><mvvm><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
28034,28787306,2015-02-28 21:46:15,,"<p>I need to define a three dimensional matrix in EmguCV for storing the features of my training dataset which are floats. So I should have a matrix which the number of its rows is the size of the training set, the number of its columns is static 30 and its depth is the length of my feature vector(20). the pseudocode is:</p>

<pre><code>Matrix&lt;float[]&gt; TrainFeatures = new Matrix&lt;float&gt;(Trainset.Num, 30, 20);
</code></pre>

<p>As Matrix definition in Emgu is a bi-dimensional and I can't find any documentation for MatND in Emgu or OpenCV, How can I do that?</p>

<p>Thanks for your help</p>
",2015-03-01 07:56:02,2015-03-03 04:31:58,How define a three dimensional float matrix in Emgu,<c#><opencv><matrix><multidimensional-array><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
28103,27095483,2014-11-23 23:03:11,,"<p>I am trying to detect circles in my images. I have written the following code in C# using EmguCV. Most of the times it works, but there are some cases that it detects smaller or larger circles that are slightly shifted to a side. </p>

<p>Here is my code:</p>

<pre><code>        Thread.Sleep(1000);
        imgCrp.Save(DateTime.Now.ToString(""yyMMddHHmmss"") + "".jpg"");

        imgCrpLab = imgCrp.Convert&lt;Lab, Byte&gt;();
        imgIsolatedCathNTipBW = new Image&lt;Gray, Byte&gt;(imgCrp.Size);
        CvInvoke.cvInRangeS(imgCrpLab.Split()[2], new MCvScalar(0), new MCvScalar(100), imgIsolatedCathNTipBW);

        imgCrpNoBgrnd = imgCrp.Copy(imgIsolatedCathNTipBW.Not());
        imgCrpNoBgrndGray = imgCrpNoBgrnd.Convert&lt;Gray, Byte&gt;().PyrUp().PyrDown();
        Thread.Sleep(1000);
        imgCrpNoBgrndGray.Save(DateTime.Now.ToString(""yyMMddHHmmss"") + "".jpg"");

        Gray cannyThreshold = new Gray(150);
        Gray cannyThresholdLinking = new Gray(85);
        Gray circleAccumulatorThreshold = new Gray(15);

        imgCrpNoBgrndGrayCanny = imgCrpNoBgrndGray.Canny(cannyThreshold.Intensity, cannyThresholdLinking.Intensity);
        Thread.Sleep(1000);
        imgCrpNoBgrndGrayCanny.Save(DateTime.Now.ToString(""yyMMddHHmmss"") + "".jpg"");

        circarrTip = imgCrpNoBgrndGrayCanny.HoughCircles(
            cannyThreshold,
            circleAccumulatorThreshold,
            1, //Resolution of the accumulator used to detect centers of the circles
            500, //min distance 
            15, //min radius
            42 //max radius
            )[0]; //Get the circles from the first channel

        imgCathNoTip = imgIsolatedCathNTipBW.Copy().Not();
        foreach (CircleF circle in circarrTip)
        {
            circLarger2RemTip = circle;
            circLarger2RemTip.Radius = circle.Radius;
            imgCathNoTip.Draw(circLarger2RemTip, new Gray(140), 1); // -1 IS TO FILL THE CIRCLE
        }
        Thread.Sleep(1000);
        imgCathNoTip.Save(DateTime.Now.ToString(""yyMMddHHmmss"") + "".jpg"");
</code></pre>

<p>Sleep commands are just to make sure that the filenames will be different and will be removed later.
I have also attached the images that have been save by this code during the process. The last image shows the detected circle which is larger and also shifted to the right.</p>

<p>Can anyone kindly check my code and let me know how I can improve it to detect circles more accurately?</p>

<p>Thanks in advance.</p>

<p><img src=""https://i.stack.imgur.com/Pm6SJ.jpg"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/4RTn5.jpg"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/Da9jf.jpg"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/dkAza.jpg"" alt=""enter image description here""></p>
",2014-11-23 23:20:26,2019-01-21 08:06:54,Improving circle detection,<opencv><geometry><emgucv><hough-transform>,,,CC BY-SA 3.0,True,False,True,False,False
28141,28836345,2015-03-03 16:04:38,,"<p>I am detecting the whole body in c# using Emgucv . Please help i cannot detect anyone when human  sits. That is why i want to detect the upper portion of the body so that when human would sit on a chair then human could be detected.I also want to </p>

<ul>
<li>Count human being</li>
<li><p>Get to know in which portion of the image human is detected.</p>

<pre><code>public Image&lt;Bgr, Byte&gt; Search(Image&lt;Bgr, Byte&gt; image, out long processingTime)
{
    processingTime = 0;
    Stopwatch watch;
    Rectangle[] regions;

    check if there is a compatible GPU to run pedestrian detection
    if (GpuInvoke.HasCuda)
    {  //this is the GPU version
        using (GpuHOGDescriptor des = new GpuHOGDescriptor())
        {
            des.SetSVMDetector(GpuHOGDescriptor.GetDefaultPeopleDetector());

            watch = Stopwatch.StartNew();
            using (GpuImage&lt;Bgr, Byte&gt; gpuImg = new GpuImage&lt;Bgr, byte&gt;(image))
            using (GpuImage&lt;Bgra, Byte&gt; gpuBgra = gpuImg.Convert&lt;Bgra, Byte&gt;())
            {
                regions = des.DetectMultiScale(gpuBgra);
            }
        }
    }
    else
    {  //this is the CPU version
    using (Emgu.CV.HOGDescriptor des = new HOGDescriptor())
    {
        des.SetSVMDetector(HOGDescriptor.GetDefaultPeopleDetector());

        watch = Stopwatch.StartNew();
        regions = des.DetectMultiScale(image);
    }
    }
    watch.Stop();

    processingTime = watch.ElapsedMilliseconds;
    LblProcessingTime.Text = processingTime.ToString();
    foreach (Rectangle pedestrain in regions)
    {
        image.Draw(pedestrain, new Bgr(Color.Red), 6);
    }
    return image;

}
</code></pre></li>
</ul>
",,2015-05-23 11:04:00,How to detect the upper portion (shoulders and head) of body in HOG in Emgucv,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
28194,27101892,2014-11-24 09:50:36,,"<p>I am writing a program in C# using Visual Studio Express 2013 for Windows Desktop. I want to detect faces that are in profile, so just one eye is visible. I am using haarcascade_profileface.xml for the detection. Every time I try to debug my code I receive this error message:</p>

<blockquote>
  <p><em>Error of type ""Emgu.CV.Util.CvException"" has occurred in Emgu.CV.dll. Additional Information: OpenCV: The node does not represent a user
  object (unknown type?)</em></p>
</blockquote>

<p>I use the same code that I use with haarcascade_frontalface_default.xml and with this xml it works.</p>

<p>I really need help. Please help me.
Thanks, B</p>
",2014-11-24 09:58:39,2015-03-12 15:26:57,Error using haarcascade_profileface.xml,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
28218,28892249,2015-03-06 04:14:55,,"<pre><code>if (_capture == null)
        {
            try
            {
                _capture = new Capture(""video1.mpg"");
            }
            catch (NullReferenceException ex)
            {   //show errors if there is any
                MessageBox.Show(ex.Message);
            }
        }
</code></pre>

<p>video1.mpg file is in bin folder. <strong>I have converted an avi file to MPEG-1 format with any-video-converter.</strong> 
But still this format is not working. I have tried <strong>mencoder</strong> also. but still same error. </p>

<pre><code>Unable to create capture from video1.mpg
</code></pre>

<p>how to make it compatible with emgu <code>Capture</code>?</p>
",2015-03-07 01:13:38,2015-03-07 01:18:23,Unable to create capture from file in Emgucv,<opencv><emgucv><opencvdotnet>,,,CC BY-SA 3.0,True,False,True,False,False
28230,28948974,2015-03-09 18:13:30,,"<p>I have a Nikon D90 connected to my laptop via USB. I need to be able to simply trigger the camera to capture an image via C#.</p>

<p>This seems like it should be an easy problem but I have been drowning trying to figure it out...</p>

<p>Can anyone point me in the right direction?</p>
",,2015-03-09 18:23:29,Camera Capture with External Camera with C#,<c#><camera><aforge><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
28250,25989754,2014-09-23 07:51:40,,"<p>I don't need the thresholded image. I want the threshold. I found this in OpenCV.</p>

<pre><code>cv::threshold( orig_img, thres_img, 0, 255, CV_THRESH_BINARY+CV_THRESH_OTSU );
</code></pre>

<p>Is there an equivalent in EmguCv. Thanks in advance.</p>

<p>PS. I need to use this threshold for canny edge detector</p>
",2014-09-23 07:54:21,2014-09-23 12:01:29,what is the function to find otsu threshold in emgu cv?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
28317,28956600,2015-03-10 05:14:31,,"<p>Is findContours() in OpenCV or EMGUCV built-in with edge detection inside ? If it's yes, what is the algorithm ? </p>

<p>Because without calling any edge detection function, it can detect the edge of image. </p>
",,2015-03-10 08:05:07,Is findContours built in with edge detection?,<algorithm><opencv><emgucv>,2015-03-10 13:22:35,,CC BY-SA 3.0,True,False,True,False,False
28338,29009844,2015-03-12 12:30:46,,"<p>I am a beginner using OpenCV and EmguCV. I am having two issues finding contours (see picture below). Problem A is about how the different contours match with each other. Problem B is about how to obtain smoother contours.</p>

<p><img src=""https://i.stack.imgur.com/DISeh.png"" alt=""enter image description here""></p>

<p>To detect the contours I am using:</p>

<p>FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_NONE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST);</p>

<p>Can someone give some advice on this?</p>

<p>Many thanks!!</p>
",,2015-03-12 14:57:32,"Matching contours and smoothing them using OpenCV, EmguCV or other alternative library",<c#><python><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
28350,28911059,2015-03-07 03:29:27,,"<p>I'm very new in this field and lack of knowledge in coding. I need to create a new point and line in my coding and then combine it with each other. It's possible that this Optical Flow Lucas Kanade method can make a coding in emgucv C#? I need used this method to make a coding.</p>
",,2015-03-07 03:29:27,How to create a new point and line?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
28377,28911582,2015-03-07 05:01:52,,"<p>(RgbResolution640x480Fps30) have problom </p>

<pre><code>      public partial class TrainWPF : Window
{

    KinectSensor kinectSensor = null;
    ColorImageFormat imageFormat = ColorImageFormat.RgbResolution640x480Fps30;       
</code></pre>

<p>ColorImageFrame Originally kinect v1 can be used, but it can not be used in kinect v2 How to use the ColorImageFrame in KINECT v2 
/////stop&amp;ColorFrameReady&amp;Dispose can't be use         </p>

<pre><code>            private void DeActivateSensor()
    {
        if (kinectSensor != null)
        {
            kinectSensor.Stop();
            kinectSensor.ColorFrameReady -= new EventHandler&lt;ColorImageFrameReadyEventArgs&gt;(sensor_ColorFrameReady);
            kinectSensor.Dispose();
        }
    }

    private void SetupSensorVideoInput()
    {
        if (kinectSensor != null)
        {
            imageFormat = (ColorImageFormat)cmbDisplayMode.SelectedItem;
            kinectSensor.ColorStream.Enable(imageFormat);

            kinectSensor.ColorFrameReady += new EventHandler&lt;ColorImageFrameReadyEventArgs&gt;(sensor_ColorFrameReady);
            kinectSensor.Start();
        }
    }        
    void sensor_ColorFrameReady(object sender, ColorFrameArrivedEventArgs e)
    {
        using (ColorImageFrame image = e.OpenColorImageFrame())
        {
            if (image == null)
                return;

            Image&lt;Bgr, byte&gt; currentImage = EmguImageExtensions.ToOpenCVImage&lt;Bgr, byte&gt;(image);
            Image&lt;Gray, byte&gt; grayFrame = currentImage.Convert&lt;Gray, byte&gt;();

            System.Drawing.Rectangle[] facesDetected = Face.DetectMultiScale(grayFrame, 1.2, 10, new System.Drawing.Size(50, 50), System.Drawing.Size.Empty);

            for (int i = 0; i &lt; facesDetected.Length; i++)// (Rectangle face_found in facesDetected)
            {
                //This will focus in on the face from the haar results its not perfect but it will remove a majoriy
                //of the background noise

                facesDetected[i].X += (int)(facesDetected[i].Height * 0.15);
                facesDetected[i].Y += (int)(facesDetected[i].Width * 0.22);
                facesDetected[i].Height -= (int)(facesDetected[i].Height * 0.3);
                facesDetected[i].Width -= (int)(facesDetected[i].Width * 0.35);

                result = currentImage.Copy(facesDetected[i]).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
                result._EqualizeHist();
                face_PICBX.Source = result.ToBitmapSource();
            }

            if (colorBytes == null ||
                colorBytes.Length != image.PixelDataLength)
            {
                colorBytes = new byte[image.PixelDataLength];
            }

            image.CopyPixelDataTo(colorBytes);

            BitmapSource source = BitmapSource.Create(image.Width,
                image.Height,
                96,
                96,
                PixelFormats.Bgr32,
                null,
                colorBytes,
                image.Width * image.BytesPerPixel);
            picVideoDisplay.Source = source; 


        }
    }
    private Bitmap ImageToBitmap(ColorImageFrame Image)
    {
        byte[] pixeldata = new byte[Image.PixelDataLength];
        Image.CopyPixelDataTo(pixeldata);
        Bitmap bmap = new Bitmap(Image.Width, Image.Height,     System.Drawing.Imaging.PixelFormat.Format32bppRgb);
        BitmapData bmapdata = bmap.LockBits(
            new System.Drawing.Rectangle(0, 0, Image.Width, Image.Height),
            ImageLockMode.WriteOnly,
            bmap.PixelFormat);
        IntPtr ptr = bmapdata.Scan0;
        Marshal.Copy(pixeldata, 0, ptr, Image.PixelDataLength);
        bmap.UnlockBits(bmapdata);
        return bmap;
    }
</code></pre>
",,2015-03-07 05:01:52,ColorImageFrame can not be used in kinect v2 (VS2013 C# kinectSDK V2),<c#><opencv><kinect><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
28473,29003374,2015-03-12 06:42:28,,"<p>Memory reached to  one extreme and application stopped working. I called the Runcamera in a timer. for the resolution 640*480 but having problem with 1920*1080. What am I missing? </p>

<pre><code>  public void RunCamera() 
    {
       imgWeb.Visibility = Visibility.Visible;

      capture1.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, 1920);
      capture1.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, 1080);
       currentFrame = capture1.QueryFrame();
       imgWeb.Source = ToBitmapSource(currentFrame);
    }
</code></pre>

<p>ToBitmapSource defenition given below</p>

<pre><code>public static BitmapSource ToBitmapSource(IImage image)
    {
        BitmapSource bs = null;
        using (System.Drawing.Bitmap source = image.Bitmap)
        {
            try
            {

                IntPtr ptr = source.GetHbitmap(); //obtain the Hbitmap

                bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
                   ptr,
                   IntPtr.Zero,
                   Int32Rect.Empty,
                   System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions());

                DeleteObject(ptr); //release the HBitmap
            }
            catch (Exception ex)
            {
                GC.Collect();
                GC.WaitForFullGCComplete();
            }
            return bs;

        }
    }
</code></pre>
",,2015-03-17 09:42:04,Memory leak on camera capture for high resolution,<wpf><emgucv><webcam-capture>,,,CC BY-SA 3.0,False,False,True,False,False
28511,29075048,2015-03-16 10:53:16,,"<p>I have a Jquery Webcam plugin which saves an Image from the Webcam, this works perfectly fine and i can see it in my C drive.</p>

<p>Now ive add the Emgu CV library. when i press the ""capture QR Code"" to decode a QR code from the image saved, it wont display the QR's Url to the Viewbag.Result, any ideas what i am doing wrong? below is my code involving the webcam and Emgu CV</p>

<p>Webcam.cshtml</p>

<pre><code>  @{
    ViewBag.Title = ""Webcam"";
}
@section scripts
{
    &lt;script src=""@Url.Content(""~/Scripts/jquery.webcam.js"")""&gt;
    &lt;/script&gt;
    &lt;script&gt;
        $(""#Camera"").webcam({
             width: 400,
             height: 320,
             mode: ""save"",
             swffile: ""@Url.Content(""~/Scripts/jscam.swf"")"",
             onTick: function () { },
             onSave: function () { },
             onCapture: function () {
                 webcam.save(""@Url.Content(""~/QR/Capture"")/"");
             },
             debug: function () { },
             onLoad: function () { }
         });
     &lt;/script&gt; 
}

&lt;section id =""loginForm""&gt;
    &lt;input type=""button"" value=""Capture QR Code"" onclick=""webcam.capture();"" /&gt;

&lt;div id=""Camera""&gt;&lt;/div&gt;
&lt;p&gt;1. Take Picture of QR Code in front of the webcam&lt;/p&gt;


&lt;p&gt;@ViewBag.Result &lt;/p&gt;

&lt;/section&gt;
</code></pre>

<p>QR Controller</p>

<pre><code>    using System;
using System.Collections.Generic;
using System.Linq;
using System.Web;
using System.Web.Mvc;
using System.IO;
using Emgu.CV;
using ZXing;
using System.Drawing;



namespace JobTracker.Controllers
{
public class QRController : Controller
{
    //
    // GET: /QR/

    [Authorize]
    public ActionResult Webcam()
    {
        return View();
    }

    public void Capture()
    {
        var stream = Request.InputStream;
        string dump;

        using (var reader = new StreamReader(stream))
            dump = reader.ReadToEnd();

        var path = Server.MapPath(""~/QR.jpg"");
        System.IO.File.WriteAllBytes(path, String_To_Bytes2(dump));

        // create a barcode reader instance 
        IBarcodeReader reader1 = new BarcodeReader();
        reader1.Options.PossibleFormats = new BarcodeFormat[] { BarcodeFormat.QR_CODE };
        // load a bitmap
        var barcodeBitmap = (Bitmap)Bitmap.FromFile(""D:\\C# Web Application\\JobTracker-Dev2\\JobTracker\\QR.jpg"");
        // detect and decode the barcode inside the bitmap
        var result = reader1.Decode(barcodeBitmap);
        // do something with the result
        if (result != null)
        {
            ViewBag.Result = result.Text;
        }


    }

    private byte[] String_To_Bytes2(string strInput)
    {
        int numBytes = (strInput.Length) / 2;
        byte[] bytes = new byte[numBytes];

        for (int x = 0; x &lt; numBytes; ++x)
        {
            bytes[x] = Convert.ToByte(strInput.Substring(x * 2, 2), 16);
        }

        return bytes;
    }


}
}
</code></pre>

<p>jquery.webcam.js</p>

<pre><code>    (function ($) {

    var webcam = {

    ""extern"": null, // external select token to support jQuery dialogs
    ""append"": true, // append object instead of overwriting

    ""width"": 320,
    ""height"": 240,

    ""mode"": ""callback"", // callback | save | stream

    ""swffile"": ""jscam.swf"",
    ""quality"": 85,

    ""debug"":    function () {},
    ""onCapture"":    function () {},
    ""onTick"":   function () {},
    ""onSave"":   function () {},
    ""onLoad"":   function () {}
    };

    window[""webcam""] = webcam;

    $[""fn""][""webcam""] = function(options) {

    if (typeof options === ""object"") {
        for (var ndx in webcam) {
        if (options[ndx] !== undefined) {
            webcam[ndx] = options[ndx];
        }
        }
    }

    var source = '&lt;object id=""webcamobject"" type=""application/x-shockwave-flash"" data=""'+webcam[""swffile""]+'"" width=""'+webcam[""width""]+'"" height=""'+webcam[""height""]+'""&gt;&lt;param name=""movie"" value=""'+webcam[""swffile""]+'"" /&gt;&lt;param name=""FlashVars"" value=""mode='+webcam[""mode""]+'&amp;amp;quality='+webcam[""quality""]+'"" /&gt;&lt;param name=""allowScriptAccess"" value=""always"" /&gt;&lt;/object&gt;';

    if (null !== webcam[""extern""]) {
        $(webcam[""extern""])[webcam[""append""] ? ""append"" : ""html""](source);
    } else {
        this[webcam[""append""] ? ""append"" : ""html""](source);
    }

    var run = 3;
    (_register = function() {
        var cam = document.getElementById('webcamobject');

        if (cam &amp;&amp; cam[""capture""] !== undefined) {

        /* Simple callback methods are not allowed :-/ */
        webcam[""capture""] = function(x) {
            try {
            return cam[""capture""](x);
            } catch(e) {}
        }
        webcam[""save""] = function(x) {
            try {
            return cam[""save""](x);
            } catch(e) {}
        }
        webcam[""setCamera""] = function(x) {
            try {
            return cam[""setCamera""](x);
            } catch(e) {}
        }
        webcam[""getCameraList""] = function() {
            try {
            return cam[""getCameraList""]();
            } catch(e) {}
        }
        webcam[""pauseCamera""] = function() {
            try {
            return cam[""pauseCamera""]();
            } catch(e) {}
        }       
        webcam[""resumeCamera""] = function() {
            try {
            return cam[""resumeCamera""]();
            } catch(e) {}
        }
        webcam[""onLoad""]();
        } else if (0 == run) {
        webcam[""debug""](""error"", ""Flash movie not yet registered!"");
        } else {
        /* Flash interface not ready yet */
        run--;
        window.setTimeout(_register, 1000 * (4 - run));
        }
    })();
    }

})(jQuery);
</code></pre>
",2015-03-16 12:35:20,2015-03-22 17:36:05,reading a qr code from image C# MVC4,<c#><jquery><asp.net-mvc-4><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
28529,29058980,2015-03-15 09:06:47,,"<p>I can't play play video with Emgu CV</p>

<p>It's show error </p>

<blockquote>
  <p>Unable to create capture from 184.avi</p>
</blockquote>

<p>Here is the code:</p>

<pre><code>public partial class Form1 : Form
{
    //Set the name of pop-up window
    String winname = ""First Window"";
    Timer My_Time = new Timer();
    int FPS=30;
    Capture _capture;

    public Form1()
    {
        InitializeComponent();

    //Frame Rate
    My_Timer.Interval = 1000 / FPS;
    My_Timer.Tick += new EventHandler(My_Timer_Tick);
    My_Timer.Start();

    _capture = new Capture(""184.avi"");   // Error this line

    }

    private void My_Timer_Tick(object sender, EventArgs e)
    {
        imageBox.Image = _capture.QueryFrame().ToBitmap();
    }
</code></pre>

<p>I use windows 8 x64 and install <code>emgucv-windows-universal-cuda 2.4.10.1940</code> It have no <code>opencv_ffmpeg.dll</code> in bin. So I install opencv-2.4.11 and copy all dll from OpenCV bin to paste in Debug in my project. I paste 184.avi to Debug too. But when I run it show error like this. How to play video with Emgu CV?</p>
",2015-03-15 10:05:40,2016-07-14 08:38:06,Emgu CV can't play video,<c#><opencv><video><emgucv>,,,CC BY-SA 3.0,True,False,True,False,True
28586,29066156,2015-03-15 21:03:40,,"<p>I'm trying to improve a real time detection using haarcascade, I've digged into the haarcascade's file to see that the HasCuda is not working, or the gpucascadeclassifier is not working, making the application unresponsive, I'm using a Nvidia 980 GTX (so it's not a hardware problem)</p>

<p>Sample Code: </p>

<pre><code>if (GpuInvoke.HasCuda)
        {
           using (var car = new GpuCascadeClassifier(carFileName))
            {
                using (var gpuImage = new GpuImage&lt;Bgr, byte&gt;(image))
                using (var gpuGray = gpuImage.Convert&lt;Gray, Byte&gt;())
               {
                    var carRegion = car.DetectMultiScale(gpuGray, 1.1, 10, Size.Empty);
                    cars.AddRange(carRegion);
                }
            }
        }
</code></pre>
",2016-03-23 09:57:22,2016-03-23 09:57:22,EmguCV HasCuda Not working,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
28597,29101600,2015-03-17 14:23:00,,"<p>I have to display a video stream from an ethernet camera into a WinForm C# 4.0 application. I made some tests with the software of the camera and I saw that the image provided by the camera was distorted by lenses. 
I know that it's possible to correct the image using a calibration grid. 
Do you have any feedback about some image processing libraray that can  be use for this purpose? The library not necessary need to be free.
For some other projects I use Halcon or OpenCV, but I don't know witch one is the best for that.</p>

<p>Thanks in advance.</p>
",2015-03-17 14:41:47,2015-03-17 14:41:47,Display corrected video stream in .NET 4.0,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
28737,29202929,2015-03-23 03:40:08,,"<p>I'm using Visual Studio Community 2013 v12. I'm having problem while running some EmguCV code, I've copied exactly the same code from the ""A Basic Program"" but it doesn't works, when it arrives at some line (I believe is the ""Image My_Image = new Image(Openfile.FileName);"" line ), it gives the TypeInitalizationException, as you can see in the print </p>

<p><a href=""http://oi61.tinypic.com/29gcugm.jpg"" rel=""nofollow"">http://oi61.tinypic.com/29gcugm.jpg</a></p>

<p>The curious point is: when i open the original example project ""A basic program"" and run, it works fine.</p>

<p>I have followed all these instructions: <a href=""http://www.emgu.com/wiki/index.php/Setting_up_EMGU_C_Sharp"" rel=""nofollow"">http://www.emgu.com/wiki/index.php/Setting_up_EMGU_C_Sharp</a></p>

<p>But, just don't know what to do anymore...</p>

<p>I have installed emgucv 2.4.10</p>

<p>Thanks for now...</p>

<p>(Sorry about my english)</p>
",,2015-03-23 03:40:08,TypeInitalizationException C# EmguCV,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
28738,29166191,2015-03-20 12:09:55,,"<p>I am working on a very specific OCR using OpenCV to analyse a B/W image. I need to be able to distinct contours of elements which are touching each other.</p>

<p>I am searching for the best (fastest) way to ""split"" a single contour object in two new contours sliced at the thinner contact point.
The big part is finding this thinner point.</p>

<p>For example:</p>

<p>When using Times New Roman, the characters in the word <code>tu</code> are touching each other (the horizontal line of <code>t</code> is linked to the top of the <code>u</code>). I need to find the X value of the point between <code>t</code> and <code>u</code> in order to get two contours (from the X value I can ""easily"" get a bounding-box as ROI on each elements and get a contour from there).</p>

<p>I think this seems similar to finding a bottleneck shape on a tube image.
Anyone have an ideas? I already tried eroding the image, but that causes issues with the <code>r</code> characters.</p>
",2015-03-20 13:20:16,2015-03-20 13:20:16,How to find a contact location in a B/W image?,<c#><opencv><image-processing><ocr><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
28750,29112782,2015-03-18 01:39:13,,"<p>So basically i'm using Emgu.CV to detect contours, and after I get the contours of an image:</p>

<pre><code>Contour&lt;System.Drawing.Point&gt; contours;
using (var stor = new MemStorage())
{
     contours = gray_image.FindContours(
        Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
        Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_EXTERNAL,
        stor);
}
</code></pre>

<p>I basically iterate through them using:</p>

<pre><code>for (i = 0; 
    (context.Contours != null) &amp;&amp; (i &lt; this.config.MaxNumberContours); 
    context.Contours = context.Contours.HNext)
</code></pre>

<p>Can I iterate through them again afterwards? The documentation <a href=""http://www.emgu.com/wiki/files/2.0.0.0/html/9bee392d-b500-773f-aa59-41e3ffe4d663.htm"" rel=""nofollow"">says that it is similar to h_next pointer in OpenCV</a>, what does this means?</p>
",,2015-03-22 09:23:12,Going back to the first Contour in Emgu after iterating through them,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
28755,29203055,2015-03-23 03:57:21,,"<p>I have an ip camera in my local network with address <code>128.100.254.50</code> with http port <code>80</code> and rtsp port <code>554</code>. It is compro ip camera <code>ip540p</code>.</p>

<p>If I  type </p>

<pre><code>rtsp://128.100.254.50:554/medias1 
</code></pre>

<p>in browser it will redirecting to real player and will stream the current view of the ip webcam.</p>

<p>But when I try to put it in a vb.net</p>

<pre><code>capture = new Capture(""rtsp://128.100.254.50:554/medias1"")
</code></pre>

<p>It return exception unable to create capture from </p>

<pre><code>rtsp://128.100.254.50:554/medias1
</code></pre>

<p>I tried using </p>

<pre><code>rtsp://username:password@128.100.254.50:554/medias1 
</code></pre>

<p>yet the result end up to be same.</p>

<p>Wish to ask is there any step I had miss or the type return will affected the capture?</p>

<p>Had tried to research but many of similar situation didn't end of to have a fixed answer. Mostly is asking to ensure the address but I had successfully open it through real player...</p>
",2015-04-21 04:26:12,2015-05-21 05:50:21,"Emgu CV unable to create capture from RTSP stream(H264),ip camera",<vb.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
28756,29203516,2015-03-23 04:55:23,,"<p>Please have a look at the image attached. It's a small part of a matrix generated by reading in a larger 16bit image. 
I want to devise a filter so that all the non-zero values get the value of the most frequent number I was thinking to use a modal filter which will pick the mode(most frequent number in a kernel overlap) but it won't work for the non-zero numbers at the edges because then 0 would be the mode. Any ideas? It would be better if I find such a filter in Emgu CV library<img src=""https://i.stack.imgur.com/AcChU.png"" alt=""Showing only 8x7 pixels of a larger image""></p>
",,2015-03-23 16:20:20,Special ImageFilter,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
28774,29142286,2015-03-19 10:35:56,,"<p>I have a image. In this image there are some vertical lines and in these lines there appear some circular/elliptical or convex patterns. I want to detect the position of these circular/elliptical or convex patterns using EmguCV / OpenCV. Can any body of you help me in this regard? </p>

<p>This is the image in which i want to find the circular/elliptical patterns:
<img src=""https://dl.dropboxusercontent.com/u/71584543/image_1.png"" alt=""Input Image""></p>

<p>waiting for your help.</p>
",,2015-03-19 12:27:15,Detecting circular pattern in image,<c#><c++><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
28851,29228713,2015-03-24 09:13:48,,"<p>I'm writing a program to save some webcam video to a file. I'm using the x264 codec found here x264.</p>

<p>When I try writing frames to a file I get this warning message poping up. It still records the video. But I don't want this popup showing on the screen.</p>

<p>x264vfw [warning]: Few frames probably would be lost. Ways to fix this:</p>

<p>x264vfw [warning]: -if you use VirtualDub or its fork than you can enable 'VirtualDub Hack' option</p>

<p>x264vfw [warning]: -you can enable 'File' output mode</p>

<p>x264vfw [warning]: -you can enable 'Zero Latency' option</p>

<p><strong>Is there anyway to config ""File ouput mode"" or ""Zero Latency"" by using C# or C++ or command line?</strong></p>

<p>This is the code:</p>

<pre><code>public static void StartCapture()
{
    try
    {
        capture = new Capture();
        capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, 1920);  //1920
        capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, 1080); //1080

        CaptureOutput = new VideoWriter
        (
            ""capture output.avi"",
            CvInvoke.CV_FOURCC('X','2','6','4'),
            50, //fps
            (int)capture.GetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH), 
            (int)capture.GetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT), 
            true
        );

        if (capture != null)
        {
            capture.ImageGrabbed += SaveFrame;
            capture.Start();
        }
    }
    catch (Exception e)
    {
        MessageBox.Show(e.ToString());
    }
}

static void SaveFrame(System.Object sender, EventArgs e)
{
    Image&lt;Bgr, Byte&gt; video;
    video = capture.RetrieveBgrFrame();
    CaptureOutput.WriteFrame(video);
}
</code></pre>
",2015-03-24 09:29:04,2015-03-24 09:29:04,X264 recording video Emgucv C#,<c#><video><emgucv><video-recording>,,,CC BY-SA 3.0,False,False,True,False,False
28874,27162720,2014-11-27 03:43:39,,"<p>I have a project idea that check web usability using eye tracking. for that I needed to predict the focusing point on the screen(i.e. pixel points on screen) in specific time gap(0.5 second).</p>

<p>Here is some additional information:</p>

<p>I intended to use openCV or emguCV but it causing me a bit of trouble beacuse of my inexperience with OpenCV.</p>

<p>I am planning to ""flatten"" the eye so it appears to move on a plane. The obvious choice is to calibrate the camera to try to remove the radial distortion.</p>

<p>During the calibartion process the user looks at the corners of a grid on a screen. The moments of the pupil are stored in a Mat for each position during the calibration. So I have an image with the dots corresponding to a number of eye postions when looking at corners of a grid on the screen.</p>

<p>is there any article or example I can refer to get a good idea about this scenario and openCV eye prediction??</p>

<p>Thanks!</p>
",,2014-11-28 12:39:48,Camera calibration and predict the eye focusing point on screen OpenCV / EmguCV,<c#><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
28892,29153967,2015-03-19 20:06:31,,"<p>I have a byte array representing a greyscale image that I would like to use with openCV in C#, using the Emgu wrapper. I am trying to figure out how to convert this into an <code>Emu.CV.Image</code> without first converting it to a <code>System.Drawing.Bitmap</code>.</p>

<p>So far, <a href=""http://www.emgu.com/wiki/files/2.4.2/document/html/84dd94e7-f03f-ceb8-f629-8462326d13a6.htm"" rel=""nofollow"">this</a> constructor for <code>Image</code> appears promising. It looks like it takes the pixel rows, columns, and then the array with my data to construct an image. However, it wants them in a weird format and I'm struggling with how to correctly construct the <code>TDepth[,,] data</code> argument.</p>

<p>Here's what I have so far:</p>

<pre><code>// This gets initialized in the constructor and filled in with greyscale image data elsewhere in the code:
byte[] depthPixelData

// Once my depthPixelData is processed, I'm trying to convert it to an Image and this is where I'm having issues
Image&lt;Gray, Byte&gt; depthImage = new Image&lt;Gray, Byte&gt;([depthBitmap.PixelHeight, depthBitmap.pixelWidth, depthPixelData]);
</code></pre>

<p>Visual studio is making it obvious to me that just passing in an array isn't going to cut it, but I have no idea how to construct the requisite <code>TDepth[,,]</code> object with my pixel data to pass in to the <code>Image</code> constructor. </p>

<p>This code needs to run at ~30fps, so I'm trying to be as efficient as possible with object creation, memory allocation, etc. </p>
",,2015-03-21 16:28:40,Convert a byte[] into an Emgu/OpenCV Image,<c#><opencv><kinect><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
28911,29234288,2015-03-24 13:45:24,,"<p><strong><em>Edit: SOLVED!</em></strong> Please see my answer down below for details.
I was unable to find an answer to the original question but I found an alternate solution</p>

<p>This question may be asked somewhere else but I have been searching for days and can't find anything that helps.</p>

<p><strong><em>Question:</em></strong> I need to convert ""Stream"" to ""image(bgr, byte)"" in one go, Is there a way/command to convert directly from System.Drawing.Image.FromStream to Emgu.CV.Image(Bgr, Byte) without converting from <em>stream</em> to <em>image</em> to <em>bitmap</em> to <em>image(bgr, byte)</em>?</p>

<p><strong><em>Information:</em></strong> I'm coding in c# in Visual Studio 2010 as part of my dissertation project.
I am taking a image stream from an IP camera on a network and applying many algorithms to detect faces/extract facial features and recognise an individuals face. On my laptops local camera I can achieve FPS of about 25~ (give or take) including algorithms because I don't have to convert the image. For an IP camera stream I need to convert it many times to achieve the desired format and the result is around 5-8fps.</p>

<p>(I know my current method is extremely inefficient which is why I'm here, I'm actually converting an image 5 times total (even gray scaling too), actually only using half of my processors memory (i7, 8gb RAM)). It does have to be image(bgr, byte) as that is the only format the algorithms will function with.</p>

<p>The code I'm using to get the image:</p>

<pre><code>//headers
using System.IO
using System.Threading;
using System.Net;
//request a connection
req = (HttpWebRequest)HttpWebRequest.Create(cameraUrl);
//gives chance for timeout for errors to occur or loss of connection
req.AllowWriteStreamBuffering = true;
req.Timeout = 20000;
//retrieve response (if successfull)
res = req.GetResponse();
//image returned
stream = res.GetResponseStream();
</code></pre>

<p>I have alot of stuff in the background managing connections, data, security etc which I have shortened to the above code.
My current code to covert the image to the desired output:</p>

<pre><code>//Convert stream to image then to bitmap
Bitmap bmpImage = new Bitmap(System.Drawing.Image.FromStream(stream));                    
//Convert to emgu image (desired goal)
currentFrame = new Emgu.CV.Image&lt;Bgr, Byte&gt;(bmpImage);
//gray scale for other uses
gray = currentFrame.Convert&lt;Gray, Byte&gt;();
</code></pre>

<p>I understand there is a method to save an image locally temporarily but I would need to avoid that for security purposes. I'm looking more for a direct conversion to help save processing power.
Am I overlooking something? All help is appreciated.</p>

<p>Thanks for reading. (I will update this if anyone requests any more details)
-Dave</p>
",2015-03-26 21:16:36,2015-03-27 20:01:18,Converting Image in c#,<c#><image><emgucv><type-conversion>,,,CC BY-SA 3.0,False,False,True,False,False
28950,27169680,2014-11-27 11:31:01,,"<pre><code>Image&lt;Gray, float&gt; result = source.MatchTemplate(template, Emgu.CV.CvEnum.TM_TYPE.CV_TM_CCOEFF_NORMED)
</code></pre>

<p>I have millions of pictures as source . Its taking lot of time. Is there any solutions to make it quick?</p>
",2014-12-02 12:06:57,2014-12-02 12:06:57,Emgu Cv matchtemplate for millions of images in c#?,<opencv><image-processing><pattern-matching><emgucv><template-matching>,,,CC BY-SA 3.0,True,False,True,False,False
29039,29240915,2015-03-24 19:09:16,,"<p>What I am trying to do seems simple in concept. But, I am having a hard time with it (error message at the bottom). I figured out most of it using EMGU documentation and prior questions here. </p>

<p>I have a windows form with an Imagebox control and a button. On button click, I want to load a image (from file) and pass it to a C++ dll that can take the imagefile and pass the same file back to the C# program which can be displayed on the Imagebox control</p>

<p>C#</p>

<pre><code>    private void rbtnLoadImage_Click(object sender, EventArgs e)
    {
        Image&lt;Bgr, Int32&gt; img1 = new Image&lt;Bgr, Int32&gt;(""abc_color.jpg"");
        IntPtr pnt = CvInvoke.cvCreateImageHeader(new Size(img1.Width, img1.Height), IPL_DEPTH.IPL_DEPTH_32S , img1.NumberOfChannels);

        Marshal.StructureToPtr(img1.MIplImage, pnt, false);
        MIplImage mptr = (MIplImage)Marshal.PtrToStructure(testIplImagePass(pnt), typeof(MIplImage));
        Image&lt;Bgr, Int32&gt; img2 = Image&lt;Bgr, Int32&gt;.FromIplImagePtr(mptr.imageData);
        imgbox.Image = img2;
    }

    [DllImport(""xyz.dll"", CallingConvention = CallingConvention.Cdecl)]
    public static extern IntPtr testIplImagePass(IntPtr imagevar);
</code></pre>

<p>C++</p>

<pre><code>    extern ""C"" { __declspec(dllexport) IplImage* testIplImagePass(IplImage* imagevar); }

    IplImage* testIplImagePass(IplImage* imagevar)
    {
        return imagevar;
    }
</code></pre>

<p>The error message I got is ""An unhandled exception of type 'System.NotImplementedException' occurred in Emgu.CV.dll. Additional information: Loading of 239, 249 channel image is not implemented.""</p>

<p>It occurred on the line</p>

<pre><code>    Image&lt;Bgr, Int32&gt; img2 = Image&lt;Bgr, Int32&gt;.FromIplImagePtr(mptr.imageData);
</code></pre>

<p>What am I doing wrong here? Any advice is appreciated.</p>
",,2017-04-11 10:39:28,EMGU (openCV) Passing a image back and forth between C# & C++,<c#><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
29084,29244564,2015-03-24 23:06:27,,"<p>So basically i'm doing some image processing using EMGU wrapper of OpenCV in C#.</p>

<p>I have contours and I have to check, for specific areas of a image, what pixels are inside a contour that was detected. </p>

<p>The problem is that I need to do it quickly, and the contour.InContour(X,Y) function is just too damn slow. Is there any other way of doing it more quickly? </p>

<p>I'm currently doing something like that:</p>

<pre><code>for (int i = 0; i &lt; this.Width; i++)
    for (int j = 0; j &lt; this.Height; j++)
        if (contour.InContour(new PointF(TopLeft.X+i, TopLeft.Y+j)) &gt; 0)
           this.ContourMatrix[i, j] = depth[(int)TopLeft.X + i, (int)TopLeft.Y + j];
</code></pre>
",,2015-03-24 23:06:27,Is there any more efficient way of finding if a point is inside a contour in OpenCV,<opencv><emgucv><contour>,,,CC BY-SA 3.0,True,False,True,False,False
29092,27179770,2014-11-27 23:03:33,,"<p>I am trying to capture a video from a file using</p>

<pre><code>captureFrame = new Capture(FileName);
</code></pre>

<p>The program works fine with .mpg images, but when I want to capture a video from an .mp4 file I get the following error:</p>

<blockquote>
  <p>An unhandled exception of type 'System.AccessViolationException' occurred in Emgu.CV.dll</p>
  
  <p>Additional information: Attempted to read or write protected memory. This is often an indication 
      that other memory is corrupt.</p>
</blockquote>

<p>The weird thing is that this error occurrs only occasionally. Some time the program works just fine and then this error occurrs. </p>

<p>Do you have any ideas?</p>

<p>Thanks, B</p>
",2014-11-27 23:10:11,2014-11-27 23:10:11,System.AccessViolationException in Emgu.CV.dll,<c#><visual-studio><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
29123,29282434,2015-03-26 15:24:57,,"<p>I am trying to create simple application using emgu cv 2.4.10 for reading video from file and processing its frame.
I have istalled emgu cv 2.4.10 and used followin code to capture video from file.</p>

<p>Capture from web camera works fine. but capture from file gives error.
I tried opening .Mp4,*.avi and .wmv files but got the error saying ""Cannot capture video from &lt;>""</p>

<p>i have created basic as </p>

<pre><code>private Capture _capture;
_capture = new Capture(); 
openFileDialog1.Filter = ""MP4|*.mp4"";
openFileDialog1.FileName = """";
if (openFileDialog1.ShowDialog() == DialogResult.OK)
{
    _capture = new Capture(openFileDialog1.FileName);
    _capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, 240);
    _capture.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, 320);
}
</code></pre>
",,2015-04-17 04:47:13,capture video from file emgu cv 2.4.10,<c#><opencv><video><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
29259,29311017,2015-03-27 22:10:44,,"<p>Been spending the last two days trying to figure this out. I'm trying to use EmguCV to work with Unity3D on my Mac OS (Yosemite, 10.10.2). Using Mono as the editor for code. I've got emgucv installed, but I just can't seem to figure out the setup required for it to work with Unity. I'm currently trying to write a camera capture code, but I'm facing this error:</p>

<pre><code>Assets/Scripts/CameraTexture.cs(2,7): error CS0246: The type or namespace name `Emgu' could not be found. Are you missing a using directive or an assembly reference?
</code></pre>

<p>when I do this:</p>

<pre><code>using Emgu.CV;
</code></pre>

<p>I've tried different approaches of copying the various dlls files into the unity project assets folders, but it doesn't change anything.</p>

<p>If anyone has had luck with setting up Emgucv with Unity, please let me know, or point me in the right direction. I would really appreciate it.</p>

<p>Thanks in advance!</p>
",,2015-03-27 22:10:44,EmguCV integration with Unity3D on OSX,<c#><macos><unity3d><mono><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
29288,29346331,2015-03-30 12:31:21,,"<p>Hi I am trying to figure out whether edge detection depends on image conditions (features). </p>

<p>I know there is a huge mathematical basis for any edge detection operator. Also I know edge detection is sensitive for a noise on a picture. </p>

<p>What about brightness, contrast? The point is I am looking how to estimate quality of the image. Is quality of image important for edge detection?</p>
",,2015-04-17 19:27:53,Does edge detection depend on image features?,<image-processing><emgucv><edge-detection><canny-operator>,,,CC BY-SA 3.0,False,False,True,False,False
29308,29406312,2015-04-02 06:23:56,,"<p>I am showing a simple version of my project which i am trying to develop.I continuously getting error in haarCascade.cs that TypeIntilizationException was unhandled.This is my code </p>

<pre><code>    using System;
    using System.Collections.Generic;
    using System.ComponentModel;
    using System.Data;
    using System.Drawing;
    using System.Linq;
    using System.Text;
    using System.Windows.Forms;
    using Emgu.CV;
    using Emgu.CV.Structure;
    using Emgu.Util;
    using Emgu.CV.CvEnum;
    using System.IO;


    namespace Browseface
    {
    public partial class Form1 : Form
{
    private HaarCascade haar;
    public Form1()
    {
        InitializeComponent();
    }

    private void Form1_Load(object sender, EventArgs e)
    {
        try
        {
            haar = new HaarCascade(@""C:\Users\Balram\Desktop\Frontal Face HaarCascades\Frontal Face HaarCascades\haarcascade_frontalface_alt_tree.xml"");
        }
        catch (Exception ae)
        {
        }
    }

    private void button1_Click(object sender, EventArgs e)
    {
        try
        {
            Image inputimg = Image.FromFile(@""C:\Users\Balram\Desktop\ad.jpg"");
            Image&lt;Bgr, byte&gt; imageframe = new Image&lt;Bgr, byte&gt;(new Bitmap(inputimg));
            if (imageframe != null)
            {
                Image&lt;Gray, byte&gt; grayform = imageframe.Convert&lt;Gray, byte&gt;();
                var faces =
                    grayform.DetectHaarCascade(haar, 1.4, 4, HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(25, 25))[0];
                foreach (var face in faces)
                {
                    imageframe.Draw(face.rect, new Bgr(Color.Green), 3);
                }
                pictureBox1.Image = imageframe.ToBitmap();
            }
        }
        catch (Exception at)
        {
        }
    }
}
}
</code></pre>

<p>In my HaarCascade.cs file in this following line i getting an error</p>

<pre><code>     protected override void DisposeObject()
  {
     CvInvoke.cvReleaseHaarClassifierCascade(ref _ptr);
  }
</code></pre>

<p>That TypeIntilizationException was unhandled.
(I already add in references Emgu.CV ,Emgu.CV.UI and Emgu.util dll files</p>
",2015-04-02 06:28:11,2015-04-02 06:28:11,getting Exception in HaarCascade.cs file using Emgucv,<c#><emgucv><haar-classifier><opencv3.0>,,,CC BY-SA 3.0,False,False,True,False,False
29320,29436719,2015-04-03 17:14:13,,"<p>I've been looking for any updates regarding the robust Predator tracking algorithm that trains itself over time automatically</p>

<p>for those who are unfamiliar you can check <a href=""http://www.engadget.com/2011/03/31/zdenek-kalals-object-tracking-algorithm-learns-on-the-fly-like/"" rel=""nofollow"">this</a></p>

<p>I'm not sure if anyone was able to port it on C# since he originally developed it on matlab</p>

<p>here's the latest thing I came up to <a href=""http://sourceforge.net/p/qopentld/wiki/Home/"" rel=""nofollow"">TLD in OpenCV</a></p>

<p>I'm looking for a C# port if anybody successfully made it possible</p>

<p>Thanks in advance!</p>
",,2015-04-03 17:14:13,Predator TLK Algorithm in C#,<c#><opencv><tracking><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
29394,29427222,2015-04-03 06:23:43,,"<p>I am looking for a way to extract foreground (without shadow) from a video sequence using C# (EmguCV). I have tried several method such as KNN, MOG, and MOG2. At the end, MOG2 is the best which is very close to my desired result. However, it is still failed to eliminate shadow. </p>

<p>As I know, there are several properties that can be used to perform better shadow removal using MOG2, such as: fTau, but these properties are only available in OpenCV (not EmguCV). So is there anyone who has implemented this kind of feature using C#?</p>
",,2015-04-09 00:50:08,Background Subtraction with Shadow Removal with EmguCV,<c#><image-processing><emgucv><background-subtraction><shadow-removal>,,,CC BY-SA 3.0,True,False,True,False,False
29412,29429892,2015-04-03 09:52:59,,"<p>I'm encoding <code>ushort[]</code> to Gray16 png, each value in ushort represent one pixel and I'm using 14 bits from the 16 on ushort.</p>

<p>I search a faster way to encode my array into png:</p>

<pre><code>ushort[] bytes = getBytes();

bitmap.WritePixels(
    new Int32Rect(0, 0, width, height),
    bytes,
    width * MainWindow.BYTES_PER_BGR16_PIXEL, 0);

BitmapEncoder encoder = new PngBitmapEncoder();
encoder.Frames.Add(BitmapFrame.Create(bitmap));
var stream = new MemoryStream();
encoder.Save(stream);
</code></pre>

<p>Is there a faster way to do this encode (maybe using emgucv library)?</p>
",,2015-04-03 09:52:59,Is there a faster way to encode png then PngBitmapEncoder on c#,<c#><performance><encoding><png><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
29439,29322712,2015-03-28 21:15:17,,"<p>I tried to create my own haar cascade to detect licence plate recognition I used 99 positives images 140*45 and 2645 negatives images and I launch the training with:</p>

<pre><code>C:\Emgu\emgucv-windows-x86_2.4.0.1717\bin\x86\opencv_traincascade.exe -data classifier -vec samples1.vec -bg negative.txt -numStages 3 -minHitRate 0.999 -maxFalseAlarmRate 0.5 -numPos 50 -numNeg 100 -w 60 -h 40 -precalcValBuffSize 256 -precalcdxbufSize 256
</code></pre>

<p>and then I got this error</p>

<p>**  Opencv error : Assertion failed &lt;_img.rows * _img.cols ==vecSize> in unknown function file E:\work\emgucv_32bit_vc\opencv\apps\traincascade\imagestorage.cpp, line 151   **</p>

<p>please help</p>

<p>`</p>
",,2015-03-28 21:15:17,opencv_traincascade error message,<c#><visual-studio-2013><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
29445,29523103,2015-04-08 18:57:35,,"<p>I have two cameras mounted on some rig. </p>

<p>I want to get ""real world"" coordinates in millimeters of some object which center is at (x1, y1) on the left image and (x2, y2) on the right image.</p>

<p>What I've done so far:</p>

<ol>
<li>Printed out some chessboard image.</li>
<li>Detected corners of chessboard using <code>FindChessboardCorners</code> on ~20 frames with me holding chessboard in different angle and position.</li>
<li>Using results from <code>FindChessboardCorners</code> I calibrated my stereo camera using <code>StereoCalibrate</code> function.</li>
<li>Computed rectification transforms using <code>StereoRectify</code> function.</li>
<li>Using results from <code>StereoCalibrate</code> and <code>StereoRectify</code> I called <code>InitUndistortRectifyMap</code> to get maps for left and right cameras.</li>
<li>Remapped my original frames with <code>Remap</code> function using outputs from <code>InitUndistortRectifyMap</code>.</li>
</ol>

<p>What would be my next steps do actual calculation of real-world coordinates?</p>

<p>Matas</p>
",,2015-04-08 18:57:35,"OpenCV ""real world"" coordinates / measurements from stereo camera",<opencv><camera-calibration><emgucv><stereo-3d>,,,CC BY-SA 3.0,True,False,True,False,False
29462,29503774,2015-04-08 00:24:12,,"<p>my system is windows x64 operating system. then when I set system variable path how to do it. whether I need to set C:\Emgu\emgucv-windows-universal-cuda 2.4.10.1940\bin\x64 or C:\Emgu\emgucv-windows-universal-cuda 2.4.10.1940\bin\x86</p>
",,2015-04-08 00:41:32,how to modify system variable path win7 64bit emgu cv,<c#><emgucv>,2015-04-08 05:03:24,,CC BY-SA 3.0,False,False,True,False,False
29518,29488507,2015-04-07 09:41:46,,"<p>I have two images with different dimensions and I want to create another large image includes them vertically.</p>

<pre><code>private Image&lt;Gray, Byte&gt; newImage(Image&lt;Gray, Byte&gt; image1, Image&lt;Gray, Byte&gt; image2)
    {
        int ImageWidth = 0;
        int ImageHeight = 0;

   //get max width
        if (image1.Width &gt; image2.Width)
            ImageWidth = image1.Width;
        else
            ImageWidth = image2.Width;

  //calculate new height
        ImageHeight = image1.Height + image2.Height;

 //declare new image (large image).
        Image&lt;Gray, Byte&gt; imageResult = new Image&lt;Gray, Byte&gt;(ImageWidth, ImageHeight);


        imageResult.ROI = new Rectangle(0, 0, image1.Width, image1.Height);
        image1.CopyTo(imageResult);
        imageResult.ROI = new Rectangle(0, image1.Height, image2.Width, image2.Height);
        image2.CopyTo(imageResult);



        return imageResult;
    }
</code></pre>

<p>The returned image is a black image and doesn't contain the two images, please help me where's the problem?</p>

<p>Thanks.</p>
",2015-04-07 10:17:39,2016-09-22 15:43:40,Add two sub-images into one new image using emgu cv,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
29522,29446753,2015-04-04 13:05:05,,"<p>I've a problem with how to make rubber sheet model from circle in emgu cv , this is my code in <code>c#</code> :</p>

<pre><code>   // looking for iris

        CircleF[] circles = cannyEdges.HoughCircles(
                  cannyThreshold,
                  circleAccumulatorThreshold,
                  3.6, //Resolution of the accumulator used to detect centers of the circles
                  cannyEdges.Height / 2, //min distance 
                  2, //min radius
                  0 //max radius
               )[0]; //Get the circles from the first channel
        var img = myImage.Clone();
        var img2 = myImage.Clone();

        foreach (CircleF circle in circles)
            img.Draw(circle, new Bgr(Color.Brown), 10);
            pictureBox3.SizeMode = PictureBoxSizeMode.StretchImage;
            pictureBox3.Image = img.ToBitmap();
</code></pre>
",2015-04-04 15:19:51,2015-08-13 03:39:44,Perform Dougman't Method (Rubber Sheet Model) in Emgu CV,<c#><model><geometry><emgucv><rubber>,,,CC BY-SA 3.0,False,False,True,False,False
29547,29509133,2015-04-08 08:04:25,,"<p>I have used <strong>EmguCV Dll and OpenCV Dll</strong> to  trigger(<strong>switch on</strong>) my camera when a button is pressed. The application works fine while building and compiling. After building the setup file,the application.exe file works fine in my system.In any other system the application works fine till the Camera is triggered, <strong>the moment camera is triggered, the application crashes</strong> . First I thought maybe the issue is with 32 bit and 64 bit. I built two separate setup files specific for 64 bit and 32 bit and still the application crashes while triggering the camera. I also read that  <strong>Microsoft C++ Redistribute Package</strong> has to be installed and I tried installing that, Still the application failed and did not trigger the camera. Kindly help regarding this issue</p>

<p>These are my logs :-</p>

<p>Problem signature:
  Problem Event Name:   CLR20r3
  Problem Signature 01: aindrasmartattendance.exe
  Problem Signature 02: 1.0.0.0
  Problem Signature 03: 5523aef5
  Problem Signature 04: Emgu.CV
  Problem Signature 05: 2.4.10.1939
  Problem Signature 06: 548278fa
  Problem Signature 07: 3ac
  Problem Signature 08: 14
  Problem Signature 09: System.TypeInitialization
  OS Version:   6.1.7600.2.0.0.256.48
  Locale ID:    16393
  Additional Information 1: dac2
  Additional Information 2: dac2dba5ddc5d0577434255af55618b7
  Additional Information 3: f0bd
  Additional Information 4: f0bd2045bac4d1dc98365de98e6112a2</p>

<p>Thanks!</p>
",2015-04-08 11:31:53,2015-04-08 11:31:53,EmguCV DLL setup file works fine in my system but not in another system,<opencv><c#-4.0><visual-c++><emgucv><setup-wizard>,,,CC BY-SA 3.0,True,False,True,False,False
29654,29587546,2015-04-12 08:38:35,,"<p>I need to convert Bitmap image to vector image , this is my code:</p>
<pre><code>VectorImage = new Image&lt;Bgr, byte&gt;(CamImage);
</code></pre>
<p>where <code>CamImage</code> is Bitmap and I have this exception:</p>
<blockquote>
<p>An exception of type 'System.TypeInitializationException' occurred in Emgu.CV.dll but was not handled in user code</p>
<p>Additional information: The type initializer for 'Emgu.CV.CvInvoke' threw an exception.</p>
</blockquote>
",2020-06-20 09:12:55,2015-04-13 10:45:01,An exception in wpf application,<c#><wpf><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
29666,29497693,2015-04-07 17:38:13,,"<p>I've got torubles with appling gaussian blur to image in frequency domain.
For unknown reasons (probably I've dont something wrong) I recieve wired image instead of blurred one. </p>

<p>There's what i do step by step:</p>

<ol>
<li>Load the image.</li>
<li><p>Split image into separate channels.</p>

<pre><code>private static Bitmap[] separateColorChannels(Bitmap source, int channelCount)
{
    if (channelCount != 3 &amp;&amp; channelCount != 4)
    {
        throw new NotSupportedException(""Bitmap[] FFTServices.separateColorChannels(Bitmap, int): Only 3 and 4 channels are supported."");
    }

    Bitmap[] result = new Bitmap[channelCount];
    LockBitmap[] locks = new LockBitmap[channelCount];
    LockBitmap sourceLock = new LockBitmap(source);
    sourceLock.LockBits();

    for (int i = 0; i &lt; channelCount; ++i)
    {
        result[i] = new Bitmap(source.Width, source.Height, PixelFormat.Format8bppIndexed);
        locks[i] = new LockBitmap(result[i]);
        locks[i].LockBits();
    }

    for (int x = 0; x &lt; source.Width; x++)
    {
        for (int y = 0; y &lt; source.Height; y++)
        {
            switch (channelCount)
            {
                case 3:
                    locks[0].SetPixel(x, y, Color.FromArgb(sourceLock.GetPixel(x, y).R));
                    locks[1].SetPixel(x, y, Color.FromArgb(sourceLock.GetPixel(x, y).G));
                    locks[2].SetPixel(x, y, Color.FromArgb(sourceLock.GetPixel(x, y).B));

                    break;
                case 4:
                    locks[0].SetPixel(x, y, Color.FromArgb(sourceLock.GetPixel(x, y).A));
                    locks[1].SetPixel(x, y, Color.FromArgb(sourceLock.GetPixel(x, y).R));
                    locks[2].SetPixel(x, y, Color.FromArgb(sourceLock.GetPixel(x, y).G));
                    locks[3].SetPixel(x, y, Color.FromArgb(sourceLock.GetPixel(x, y).B));

                    break;
                default:
                    break;
            }
        }
    }

    for (int i = 0; i &lt; channelCount; ++i)
    {
        locks[i].UnlockBits();
    }

    sourceLock.UnlockBits();
}
</code></pre></li>
<li><p>Convert every channel into complex images (with AForge.NET).</p>

<pre><code>public static AForge.Imaging.ComplexImage[] convertColorChannelsToComplex(Emgu.CV.Image&lt;Emgu.CV.Structure.Gray, Byte&gt;[] channels)
{
    AForge.Imaging.ComplexImage[] result = new AForge.Imaging.ComplexImage[channels.Length];

    for (int i = 0; i &lt; channels.Length; ++i)
    {
        result[i] = AForge.Imaging.ComplexImage.FromBitmap(channels[i].Bitmap);
    }

    return result;
}
</code></pre></li>
<li><p>Apply Gaussian blur.</p>

<ol>
<li><p>First i create the kernel (For testing purposes kernel size is equal to image size, tho only center part of it is calculated with gaussian function, rest of kernel is equal to re=1 im=0).</p>

<pre><code>private ComplexImage makeGaussKernel(int side, double min, double max, double step, double std)
{
    // get value at top left corner
    double _0x0 = gauss2d(min, min, std);

    // top left corner should be 1, so making scaler for rest of the values
    double scaler = 1 / _0x0;

    int pow2 = SizeServices.getNextNearestPowerOf2(side);

    Bitmap bitmap = new Bitmap(pow2, pow2, PixelFormat.Format8bppIndexed);

    var result = AForge.Imaging.ComplexImage.FromBitmap(bitmap);

    // For test purposes my kernel is size of image, so first, filling with 1 only.
    for (int i = 0; i &lt; result.Data.GetLength(0); ++i)
    {
        for (int j = 0; j &lt; result.Data.GetLength(0); ++j)
        {
            result.Data[i, j].Re = 1;
            result.Data[i, j].Im = 0;
        }
    }

    // The real kernel's size.
    int count = (int)((Math.Abs(max) + Math.Abs(min)) / step);

    double h = min;
    // Calculating kernel's values and storing them somewhere in the center of kernel.
    for (int i = result.Data.GetLength(0) / 2 - count / 2; i &lt; result.Data.GetLength(0) / 2 + count / 2; ++i)
    {
        double w = min;
        for (int j = result.Data.GetLength(1) / 2 - count / 2; j &lt; result.Data.GetLength(1) / 2 + count / 2; ++j)
        {
            result.Data[i, j].Re = (scaler * gauss2d(w, h, std)) * 255;
            w += step;
        }
        h += step;
    }

    return result;
}

// The gauss function
private double gauss2d(double x, double y, double std)
{
    return ((1.0 / (2 * Math.PI * std * std)) * Math.Exp(-((x * x + y * y) / (2 * std * std))));
}
</code></pre></li>
<li><p>Apply FFT to every channel and kernel.</p></li>
<li><p>Multiply center part of every channel by kernel.</p>

<pre><code>void applyFilter(/*shortened*/)
{
    // Image's size is 512x512 that's why 512 is hardcoded here
    // min = -2.0; max = 2.0; step = 0.33; std = 11
    ComplexImage filter = makeGaussKernel(512, min, max, step, std);

    // Applies FFT (with AForge.NET) to every channel and filter
    applyFFT(complexImage);
    applyFFT(filter);

    for (int i = 0; i &lt; 3; ++i)
    {
        applyGauss(complexImage[i], filter, side);
    }

    // Applies IFFT to every channel
    applyIFFT(complexImage);
}

private void applyGauss(ComplexImage complexImage, ComplexImage filter, int side)
{
    int width = complexImage.Data.GetLength(1);
    int height = complexImage.Data.GetLength(0);

    for(int i = 0; i &lt; height; ++i)
    {
        for(int j = 0; j &lt; width; ++j)
        {
            complexImage.Data[i, j] = AForge.Math.Complex.Multiply(complexImage.Data[i, j], filter.Data[i, j]);
        }
    }
}
</code></pre></li>
</ol></li>
<li>Apply IFFT to every channel.</li>
<li><p>Convert every channel back to bitmaps (with AForge.NET).</p>

<pre><code>public static System.Drawing.Bitmap[] convertComplexColorChannelsToBitmap(AForge.Imaging.ComplexImage[] channels)
{
    System.Drawing.Bitmap[] result = new System.Drawing.Bitmap[channels.Length];

    for (int i = 0; i &lt; channels.Length; ++i)
    {
        result[i] = channels[i].ToBitmap();
    }

    return result;
}
</code></pre></li>
<li><p>Merge bitmaps into single bitmap</p>

<pre><code>public static Bitmap mergeColorChannels(Bitmap[] channels)
{
    Bitmap result = null;

    switch (channels.Length)
    {
        case 1:
            return channels[0];
        case 3:
            result = new Bitmap(channels[0].Width, channels[0].Height, PixelFormat.Format24bppRgb);
            break;
        case 4:
            result = new Bitmap(channels[0].Width, channels[0].Height, PixelFormat.Format32bppArgb);
            break;
        default:
            throw new NotSupportedException(""Bitmap FFTServices.mergeColorChannels(Bitmap[]): Only 1, 3 and 4 channels are supported."");
    }

    LockBitmap resultLock = new LockBitmap(result);
    resultLock.LockBits();

    LockBitmap red = new LockBitmap(channels[0]);
    LockBitmap green = new LockBitmap(channels[1]);
    LockBitmap blue = new LockBitmap(channels[2]);

    red.LockBits();
    green.LockBits();
    blue.LockBits();

    for (int y = 0; y &lt; result.Height; y++)
    {
        for (int x = 0; x &lt; result.Width; x++)
        {
            resultLock.SetPixel(x, y, Color.FromArgb((int)red.GetPixel(x, y).R, (int)green.GetPixel(x, y).G, (int)blue.GetPixel(x, y).B));
        }
    }

    red.UnlockBits();
    green.UnlockBits();
    blue.UnlockBits();

    resultLock.UnlockBits();

    return result;
}
</code></pre></li>
</ol>

<p>As a result I've got shifted, red-colored blurred version of image: <a href=""http://i.imgur.com/gLCMVd6.jpg"" rel=""nofollow"">link</a>.</p>

<p>@edit - Updated the question with several changes to the code.</p>
",2015-04-11 10:39:54,2015-04-12 16:46:55,Applying Gaussian blur to image in frequency domain,<c#><emgucv><gaussian><aforge><frequency-domain>,,,CC BY-SA 3.0,False,False,True,False,False
29671,29607995,2015-04-13 14:33:31,,"<p>I start my adventure with emguCV. I want to write a simple algorithm to detect moving objects. I try to subtract the background but the image is all black. </p>

<pre><code>public Form1()
{
   previous = grabber.QueryFrame();
   Application.Idle += new EventHandler(FrameGrabber27);
}

void FrameGrabber27(object sender, EventArgs e)
{
   Image&lt;Bgr, Byte&gt; output = new Image&lt;Bgr,Byte&gt;(300,300);
   Image&lt;Bgr, Byte&gt; actual = grabber.QueryFrame();

   int width = output.Width;
   int height = output.Height;

   image27.Image = grabber.QueryFrame();
   ibProcessed.Image = actual;
   for (int i = 0; i &lt; width; i++)
   {
       for (int j = 0; j &lt; height; j++)
       {                       
           if ((actual[j, i].Blue == previous[j, i].Blue) &amp;&amp; ( actual[j, i].Red == previous[j, i].Red)&amp;&amp;(actual[j, i].Green == previous[j, i].Green))                    
           {
               output[j, i] =newBgr(0,0,0);                             
           }
           else
           {                         
               output[j, i] = new Bgr(255, 255, 255);
           }
       }
   }
   im.Image = output;
</code></pre>
",2015-04-18 18:13:10,2015-04-18 18:13:10,Background Substraction c# emgucv,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
29674,29557197,2015-04-10 08:52:51,,"<p>i am using the new EmguCV 3.0.0 alpha to detect a chessboard with webcam and have an understanding problem with the corners matrix.</p>

<pre><code>        Size patternSize = new Size(5, 4);
        Matrix&lt;float&gt; corners = new Matrix&lt;float&gt;(1, 2);

        bool find = CvInvoke.FindChessboardCorners(grayFrame, patternSize, corners, CalibCbType.AdaptiveThresh | CalibCbType.FilterQuads);
        CvInvoke.DrawChessboardCorners(grayFrame, patternSize, corners, find);
        if (find)
        {
            Console.Write(corners.Size);
        }
</code></pre>

<p>The chessboard will be detected and shown correct!</p>

<p>But, how big must be the size of the corners matrix and how do i extract the corner positions?</p>

<p>All samples i found on internet are using older versions of EmguCV and there is a complete different syntax now. I would use the older version but the newer alpha is much faster and timing is a big issue in my app.</p>
",2015-04-10 10:33:04,2015-10-06 14:57:41,How to use FindChessboardCorners,<c#><emgucv><opencv3.0>,,,CC BY-SA 3.0,False,False,True,False,False
29785,27234806,2014-12-01 18:27:23,,"<p>Briefly, I'm developing a system that detect and track cars in real time using EmguCV, so far the detection works fine, I've used Haar Cascade and a decent classifier to detect the vehicles but the problem lies in the tracking algorithm to be used.</p>

<p>After 3 days of continuous research I've concluded that 
1- Blob tracking and Background subtraction are the best to eliminate false positives in each frame and increase tracking accuracy
2- I can't find any good documentation for camshift/blob tracking at all </p>

<p>my c# skills aren't ""that good"" so I'm having it really hard to build the tracker myself</p>

<p>I can't seem to get <a href=""https://www.behance.net/gallery/Vehicle-Detection-Tracking-and-Counting/4057777"" rel=""nofollow"">Vehicle Detection, Tracking and Counting</a> to work</p>

<p>Thanks in advance! :) </p>
",,2015-10-05 11:09:53,Vehicle Tracking in real time using EmguCV,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
29819,29601570,2015-04-13 09:05:41,,"<p>I'm looking for few days a solution to draw rectangle on image frame. Basically I'm using <code>CvInvoke.cvRectangle</code> method to draw rectangle on image because I need antialiased rect.
But problem is when I need to rotate a given shape for given angle. I can't find any good solution. 
I have tryed to draw rectangle on separate frame then rotate hole frame and apply this new image on top of my base frame. But in this solution there is a problem with antialiasing. It's not working.
I'm working on simple application that should allow draw few kinds of shape, resize them and rotation for given angle. 
Any idea how to achive this?</p>
",,2019-07-09 15:28:14,Emgu CV draw rotated rectangle,<rotation><draw><shape><emgucv><angle>,,,CC BY-SA 3.0,False,False,True,False,False
29837,27235943,2014-12-01 19:42:12,,"<p>Does anyone know how to zoom/pan (scroll) on the imagebox of EmguCV using C# code? It works just fine using mouse scroll, But I'd like to do it using code.</p>

<p>I tried this, but with no luck!</p>

<pre><code>ImageBox1.SetZoomScale(1, new Point(400, 400));
</code></pre>
",,2017-03-10 16:13:09,zoom/pan in Imagebox of EmguCV,<image><scroll><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
30005,29722491,2015-04-18 20:29:48,,"<p>I'm new to Emgu and was learning with a C# code tutorial off the Internet. In the code, I am getting that certain elements such as img[channel] (line 15) and NewImage(""Background segmented"", image) (line 21) are not referenced. But I have added the appropriate DLLs and references. Can you please let me know if I am missing anything here?</p>

<pre><code>using Emgu;
using Emgu.CV;
using Emgu.Util;
using Emgu.CV.CvEnum;
using Emgu.CV.Util;
using Emgu.CV.Structure;

private void CielabChannelMaskBGSubtraction(string filename, bool displayResult)
        {
        double threshold = double.Parse(max2textBox.Text);

        Image&lt;Bgr, byte&gt; rgb = new Image&lt;Bgr, byte&gt;(filename);
        Image&lt;Lab, Byte&gt; img = rgb.Convert&lt;Lab, Byte&gt;();

        //get the a* channel 
        Image&lt;Gray, Byte&gt; gray = img[channel];

        //threshold and invert
        gray = gray.ThresholdBinary(new Gray(threshold), new Gray(255)).Not();

        // display the result
        if (displayResult) this.NewImage(""Background segmented"", image);
    }
</code></pre>
",2015-04-18 20:30:15,2015-04-18 20:34:18,Error when using Emgu CV C#,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
30031,29723397,2015-04-18 22:03:47,,"<p>I'm trying to compare an image against a known set of images and find the closest match(es) using Emgu CV and Surf. I've found a lot of people trying to do the same thing but not a complete solution that uses the GPU for speed.</p>

<p>The closest I've gotten is the tutorial here:</p>

<p><a href=""http://romovs.github.io/blog/2013/07/05/matching-image-to-a-set-of-images-with-emgu-cv/"" rel=""nofollow"">http://romovs.github.io/blog/2013/07/05/matching-image-to-a-set-of-images-with-emgu-cv/</a></p>

<p>However that doesn't take advantage of the GPU and it's really slow for my application. I need something fast like the SurfFeature sample. </p>

<p>So I tried to refactor that tutorial code to match the SurfFeature logic that uses the GPU. Everything was going well with GpuMat's replacing Matrix here and there. But I ran into a major problem when I got to the core of the tutorial above, that is to say, the logic that concatenates all of the descriptors into one large matrix. I couldn't find a way to append GpuMat's to each other - even if I could do that, there's no guarantee that the FlannIndex search routine would even work with the Gpu-based code.</p>

<p>So now I'm stuck on something I thought would be relatively straight-forward. There are certainly a number of people trying to do this over the years so I'm really surprised that there isn't a published solution.</p>

<p>If you could help me, I'd be most appreciative. To summarize, I need to do the following:</p>

<p>Build a large in-memory (on the GPU) list of descriptors and keypoints for a known set of images using Surf (as per the SurfFeature sample). Given an unknown image, search against the in-memory stuff to find the closest match (if any).</p>

<p>Thanks in advance if you can help!</p>
",,2016-06-04 08:25:19,Emgu CV Surf picture detection against known database?,<opencv><surf><emgucv><opencv3.0>,,,CC BY-SA 3.0,True,False,True,False,False
30041,26135267,2014-10-01 06:21:38,,"<p>I am tying to use emguCV to detect circle on webcam. i don't have any experience in that and this is first time. i am trying to follow this tutorial <a href=""https://www.youtube.com/watch?v=vdjoutNR2DQ"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=vdjoutNR2DQ</a> but it seem he using different version </p>

<p>-In line 168 Error: Cannot implicitly convert type Emgu.CV.Mat'to 'Emgu.CV.Image'   </p>

<p>-In line 171     Error  Cannot implicitly convert type 'Emgu.CV.Image' to 'Emgu.CV.Image'</p>

<p>-In line 173 Error: The best overloaded method match for 'Emgu.CV.Image.HoughCircles(Emgu.CV.Structure.Bgr, Emgu.CV.Structure.Bgr,double, double, int, int)' has some invalid arguments</p>

<p>-In same line 173 Error :Argument 1 &amp;2: cannot convert from 'Emgu.CV.Structure.Gray' to 'Emgu.CV.Structure.Bgr</p>

<p>these the references I am using from emguCV</p>

<p><img src=""https://i.stack.imgur.com/kkX37.jpg"" alt=""enter image description here""></p>

<p>this is the code </p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.
using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Structure;
using Emgu.CV.UI;

namespace videosearch
{
public partial class detect : Form
{

    Capture cp = null;
    bool blac = false;
    Image&lt;Bgr, byte&gt; imageorgnal;
    Image&lt;Bgr, byte&gt; imgproc;

    public detect()
    {
        InitializeComponent();
    }

    private void button1_Click(object sender, EventArgs e)
    {
        if (blac == true)
        {
            Application.Idle -= procframdatGUI;
            blac = false;
            button1.Text = ""Resume"";
        }
        else
        {
            Application.Idle += procframdatGUI;
            button1.Text = ""pause"";
            blac = true;
        }
    }

    private void detect_Load(object sender, EventArgs e)
    {
        try
        {
            cp = new Capture(Emgu.CV.CvEnum.CaptureType.DShow);
        }
        catch (NullReferenceException ex)
        {
            MessageBox.Show(ex.Message);
            return;
        }
        Application.Idle += procframdatGUI;
        blac = true;
    }
    private void detect_Close(object sender, FormClosedEventArgs e)
    {
        if (cp!=null)
        {
            cp.Dispose();
        }
    }
    void procframdatGUI(object sender, EventArgs e)
    {

        imageorgnal = cp.QueryFrame();//line 168 Error: Cannot implicitly convert type Emgu.CV.Mat'to 'Emgu.CV.Image&lt;Emgu.CV.Structure.Bgr,byte&gt;'   

        if (imageorgnal == null)
            return;
        imgproc = imageorgnal.InRange(new Bgr(0, 0, 175), new Bgr(100, 100, 256));// line 171    Error  Cannot implicitly convert type 'Emgu.CV.Image&lt;Emgu.CV.Structure.Gray,byte&gt;' to 'Emgu.CV.Image&lt;Emgu.CV.Structure.Bgr,byte&gt;'
        imgproc = imgproc.SmoothGaussian(9);
        CircleF[] cir = imgproc.HoughCircles(new Gray(100), new Gray(50), 2, imgproc.Height / 4, 10, 400); //In line 173 Error: The best overloaded method match for 'Emgu.CV.Image&lt;Emgu.CV.Structure.Bgr,byte&gt;.HoughCircles(Emgu.CV.Structure.Bgr, Emgu.CV.Structure.Bgr,double, double, int, int)' has some invalid arguments
// in same line Error   :Argument 1 &amp;2: cannot convert from 'Emgu.CV.Structure.Gray' to 'Emgu.CV.Structure.Bgr'

        foreach (CircleF ci in cir)
        {
            if (textBox1.Text!="""")
            {
                textBox1.AppendText(Environment.NewLine);

            }

            textBox1.AppendText(""ball position x="" + ci.Center.X.ToString().PadLeft(4) + ""\n Y= "" + ci.Center.Y.ToString().PadLeft(4)+ ""\n ridius""+ci.Radius.ToString(""###.000"").PadLeft(7));
            textBox1.ScrollToCaret();
            CvInvoke.Circle(imgproc, new Point((int)ci.Center.X, (int)ci.Center.Y), 3, new MCvScalar(0, 255, 0), -1, 0, 0);
            imageorgnal.Draw(ci, new Bgr(Color.Red), 3);


        }
        imageBox1.Image = imageorgnal;
        imageBox2.Image = imgproc;
    }

}
}
</code></pre>
",2019-07-06 10:08:59,2019-07-06 10:08:59,emguCV with C# Cannot implicitly & Argument error,<c#><image-processing><emgucv>,,,CC BY-SA 4.0,False,True,True,False,False
30082,29727543,2015-04-19 08:22:42,,"<p>I use <em>Dll Rasteredge.Imaging.ORC</em> and I have exception <em>""ORCRuntimeException was unhandled""</em> Resource dictionary preparation failed. Links <a href=""http://www.rasteredge.com/"" rel=""nofollow"">http://www.rasteredge.com/</a></p>

<pre><code>Bitmap default_image = new Bitmap(pictureBox1.Image);
RasterEdge.Imaging.Basic.Core.REImage img = new RasterEdge.Imaging.Basic.Core.REImage(default_image);            RasterEdge.Imaging.OCR.OCRHandler.SetTrainResourcePath(@""C:\Source"");

img = img.Resize(new Size((int)img.Width * 2, (int)img.Height*2));
RasterEdge.Imaging.OCR.OCRPage page1 = RasterEdge.Imaging.OCR.OCRHandler.Import(img);      
page1.Recognize();
</code></pre>

<p>What is the problem here and how to make it working?</p>
",2015-04-22 06:51:49,2015-05-06 09:58:38,Exception when using Rasteredge.Imaging.ORC recognition image,<image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
30097,26139216,2014-10-01 10:24:26,,"<p>In my application I have to track the lecturer in a university lecture using a static camera. At the moment I'm using the default GPUHOGDescriptor from Emgu CV which works good if the whole body of the lecturer is visible. In the case where the lecturer is standing behind the desk, the detection works only around 20% of the time. My idea was to use a HOG detector which uses only the upper half of the body. I couldn't find any detector in the Internet but I'm sure that I'm not the first one with this problem. Or is there a fundamental problem that upper body detection does not work?</p>

<p>Can someone help me find one or share their descriptor? When I would want to train a HOG descriptor for myself, would it work to use a standard dataset like the INRIA and change only the size such that it takes only the upper half of the images?</p>
",,2018-05-25 08:21:55,Trained HOG descriptor for upper body detection,<opencv><svm><emgucv><object-detection>,,,CC BY-SA 3.0,True,False,True,False,False
30131,29767030,2015-04-21 08:39:09,,"<p>I managed to make License Plate Recognition example from emgucv worked. However I didn't get the desired OCR recognition to recognize the license plate number of vehicle at my place.</p>
<p>this is the code</p>
<pre><code>public class LicensePlateDetector : DisposableObject
{
    private Tesseract _ocr;

    /// &lt;summary&gt;
    /// Create a license plate detector
    /// &lt;/summary&gt;
    public LicensePlateDetector()
    {
        //create OCR
        _ocr = new Tesseract();

        _ocr.SetVariable(&quot;tessedit_char_whitelist&quot;, &quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890&quot;);
        _ocr.Init(@&quot;D:\tessdata&quot;, &quot;eng&quot;, false);            
    }

    public List&lt;String&gt; DetectLicensePlate(
     Image&lt;Bgr, byte&gt; img,
     List&lt;Image&lt;Gray, Byte&gt;&gt; licensePlateImagesList,
     List&lt;Image&lt;Gray, Byte&gt;&gt; filteredLicensePlateImagesList,
     List&lt;MCvBox2D&gt; detectedLicensePlateRegionList)
    {
        List&lt;String&gt; licenses = new List&lt;String&gt;();
        using (Image&lt;Gray, byte&gt; gray = img.Convert&lt;Gray, Byte&gt;())
        //using (Image&lt;Gray, byte&gt; gray = GetWhitePixelMask(img))
        using (Image&lt;Gray, Byte&gt; canny = new Image&lt;Gray, byte&gt;(gray.Size))  
        using (MemStorage stor = new MemStorage())
        {
            canny.ThresholdBinary(new Gray(50), new Gray(255));

            CvInvoke.cvCanny(gray, canny, 100, 50, 3);

            canny.Dilate(20);
            
            Contour&lt;Point&gt; contours = canny.FindContours(
                 Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
                 Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_TREE,
                 stor);
            FindLicensePlate(contours, gray, canny, licensePlateImagesList, filteredLicensePlateImagesList, detectedLicensePlateRegionList, licenses);
        }
        return licenses;
    }

    private void FindLicensePlate(
     Contour&lt;Point&gt; contours, Image&lt;Gray, Byte&gt; gray, Image&lt;Gray, Byte&gt; canny,
     List&lt;Image&lt;Gray, Byte&gt;&gt; licensePlateImagesList, List&lt;Image&lt;Gray, Byte&gt;&gt; filteredLicensePlateImagesList, List&lt;MCvBox2D&gt; detectedLicensePlateRegionList,
     List&lt;String&gt; licenses)
    {
        for (; contours != null; contours = contours.HNext)
        {
            //int numberOfChildren = GetNumberOfChildren(contours);
            //if it does not contains any children (charactor), it is not a license plate region
            //if (numberOfChildren == 0) continue;
            Contour&lt;Point&gt; approxContour = contours.ApproxPoly(contours.Perimeter * 0.05, contours.Storage);

            if (approxContour.Area &gt; 100 &amp;&amp; approxContour.Total == 4)
            {
                //img.Draw(contours, new Bgr(Color.Red), 1);
                if (!IsParallelogram(approxContour.ToArray()))
                {
                    Contour&lt;Point&gt; child = contours.VNext;
                    if (child != null)
                        FindLicensePlate(child, gray, canny, licensePlateImagesList, filteredLicensePlateImagesList, detectedLicensePlateRegionList, licenses);
                    continue;
                }

                MCvBox2D box = contours.GetMinAreaRect();
                if (box.angle &lt; -45.0)
                {
                    float tmp = box.size.Width;
                    box.size.Width = box.size.Height;
                    box.size.Height = tmp;
                    box.angle += 90.0f;
                }
                else if (box.angle &gt; 45.0)
                {
                    float tmp = box.size.Width;
                    box.size.Width = box.size.Height;
                    box.size.Height = tmp;
                    box.angle -= 90.0f;
                }

                double whRatio = (double)box.size.Width / box.size.Height;
                if (!(3.0 &lt; whRatio &amp;&amp; whRatio &lt; 8.0))
                //if (!(1.0 &lt; whRatio &amp;&amp; whRatio &lt; 2.0))
                {  //if the width height ratio is not in the specific range,it is not a license plate 
                    //However we should search the children of this contour to see if any of them is a license plate
                    Contour&lt;Point&gt; child = contours.VNext;
                    if (child != null)
                        FindLicensePlate(child, gray, canny, licensePlateImagesList, filteredLicensePlateImagesList, detectedLicensePlateRegionList, licenses);
                    continue;
                }

                using (Image&lt;Gray, Byte&gt; tmp1 = gray.Copy(box))
                //resize the license plate such that the front is ~ 10-12. This size of front results in better accuracy from tesseract
                using (Image&lt;Gray, Byte&gt; tmp2 = tmp1.Resize(240, 180, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC, true))
                {
                    //removes some pixels from the edge
                    int edgePixelSize = 2;
                    tmp2.ROI = new Rectangle(new Point(edgePixelSize, edgePixelSize), tmp2.Size - new Size(2 * edgePixelSize, 2 * edgePixelSize));
                    Image&lt;Gray, Byte&gt; plate = tmp2.Copy();

                    Image&lt;Gray, Byte&gt; filteredPlate = FilterPlate(plate);

                    
                    //Tesseract.Charactor[] words;
                    List&lt;Word&gt; words;
                    StringBuilder strBuilder = new StringBuilder();
                    using (Bitmap tmp = filteredPlate.Bitmap)
                    {
                        //_ocr.Recognize(tmp);
                        words = _ocr.DoOCR(tmp, filteredPlate.ROI);
                        
                        if (words.Count == 0) continue;

                        for (int i = 0; i &lt; words.Count; i++)
                        {
                            strBuilder.Append(words[i].Text);
                        }
                    }

                    licenses.Add(strBuilder.ToString());
                    licensePlateImagesList.Add(plate);
                    filteredLicensePlateImagesList.Add(filteredPlate);
                    detectedLicensePlateRegionList.Add(box);

                }
            }
        }
    }
    
    private static bool IsParallelogram(Point[] pts)
    {
        LineSegment2D[] edges = PointCollection.PolyLine(pts, true);

        double diff1 = Math.Abs(edges[0].Length - edges[2].Length);
        double diff2 = Math.Abs(edges[1].Length - edges[3].Length);
        if (diff1 / edges[0].Length &lt;= 0.05 &amp;&amp; diff1 / edges[2].Length &lt;= 0.05
           &amp;&amp; diff2 / edges[1].Length &lt;= 0.05 &amp;&amp; diff2 / edges[3].Length &lt;= 0.05)
        {
            return true;
        }
        return false;
    }

    private static Image&lt;Gray, Byte&gt; FilterPlate(Image&lt;Gray, Byte&gt; plate)
    {
        Image&lt;Gray, Byte&gt; thresh = plate.ThresholdBinaryInv(new Gray(120), new Gray(255));

        using (Image&lt;Gray, Byte&gt; plateMask = new Image&lt;Gray, byte&gt;(plate.Size))
        using (Image&lt;Gray, Byte&gt; plateCanny = plate.Canny(new Gray(100), new Gray(50)))
        using (MemStorage stor = new MemStorage())
        {
            plateMask.SetValue(255.0);
            for (
               Contour&lt;Point&gt; contours = plateCanny.FindContours(
                  Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
                  Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_EXTERNAL,
                  stor);
               contours != null; contours = contours.HNext)
            {
                Rectangle rect = contours.BoundingRectangle;
                if (rect.Height &gt; (plate.Height &gt;&gt; 1))
                {
                    rect.X -= 1; rect.Y -= 1; rect.Width += 2; rect.Height += 2;
                    rect.Intersect(plate.ROI);

                    plateMask.Draw(rect, new Gray(0.0), -1);
                }
            }

            thresh.SetValue(0, plateMask);
        }

        thresh._Erode(1);
        thresh._Dilate(1);

        return thresh;
    }

    private static int GetNumberOfChildren(Contour&lt;Point&gt; contours)
    {
        Contour&lt;Point&gt; child = contours.VNext;
        if (child == null) return 0;
        int count = 0;
        while (child != null)
        {
            count++;
            child = child.HNext;
        }
        return count;
    }
    protected override void DisposeObject()
    {
        _ocr.Dispose();
    }
}
</code></pre>
<p>this is the picture of the local car with standard license plate number. I used openfiledialog to obtain it.</p>
<p><a href=""https://flic.kr/p/rhMdUA"" rel=""nofollow noreferrer"">nissan plate recognition</a></p>
<p>However, my program failed to recognize any character add all. the closest that I got was for this picture. but this not kind of picture I want for recognition</p>
<p><a href=""https://flic.kr/p/rXc631"" rel=""nofollow noreferrer"">Bmw car plate recognition</a></p>
<p>was it due to image size or perhaps i need to do further image pre-processing. Thanks in advance</p>
",2020-06-20 09:12:55,2015-04-21 08:39:09,Can't make tessnet2 and tesseract worked to recognize license plate number,<tesseract><emgucv><pattern-recognition><tessnet2>,,,CC BY-SA 3.0,False,False,True,False,False
30177,29792277,2015-04-22 08:49:41,,"<p>I would like the system to pin point/highlight the deformed area to the user during video rendering. Lets say currently I have an image with a list of squares as shown in the image below, this is the original image without defects.</p>

<p><img src=""https://i.stack.imgur.com/LJqou.jpg"" alt=""enter image description here""></p>

<p>In the following image, is the sample image that consist of a defect, whereby there is an extra line in between the squares.</p>

<p><img src=""https://i.stack.imgur.com/8WWjE.jpg"" alt=""enter image description here""></p>

<p>I would like to have something as shown in the sample image below where by it will have a red square to highlight the ""extra line"" to inform the user that there is a defect and will pin point the defect to the user.</p>

<p><img src=""https://i.stack.imgur.com/LnGYg.jpg"" alt=""enter image description here""></p>

<p>The defects may appear in any kinds of shapes or forms, and I would like to pin point the defects to the user. So what kind of algorithm I should use in order to achieve this? </p>

<p>Also, is machine learning required in order to achieve this?</p>

<p>Currently I am using Emgucv in C#, but I am not sure what algorithm I should use that can achieve this. Any suggestions are appreciated.</p>

<p>Thank you.</p>
",,2015-04-22 10:28:53,Detection of defacts during video rendering ( which algorithm to use),<c#><opencv><image-processing><machine-learning><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
30362,27281427,2014-12-03 20:54:19,,"<p>Hello Dear Forum Members !</p>

<p>I am working on a project to detect change view from security camera. I mean, when someone try to move camera (some kind of sabotage...) I have to notice this. My idea is:</p>

<ul>
<li>capture images from camera every 10 sec and compare this two pictures ( Old and actual picture).</li>
</ul>

<p>There are almost 70 cameras which I need to control, so I can't use live streaming because it could occupy my internet connection. I use Emgu CV library to make this task, but during my work I stuck with some problem.. Here im piece of my code what I prepared:</p>

<pre><code>public class EmguCV
{
    static public Model Test(string BaseImagePath, string ActualImagePath)
    {        
        double noise = 0; 

        Mat curr64f = new Mat();
        Mat prev64f = new Mat();
        Mat hann = new Mat();

        Mat src1 = CvInvoke.Imread(BaseImagePath, 0);
        Mat src2 = CvInvoke.Imread(ActualImagePath, 0);
        Size size = new Size(50, 50);

        src1.ConvertTo(prev64f, Emgu.CV.CvEnum.DepthType.Cv64F);
        src2.ConvertTo(curr64f, Emgu.CV.CvEnum.DepthType.Cv64F);

        CvInvoke.CreateHanningWindow(hann, src1.Size, Emgu.CV.CvEnum.DepthType.Cv64F);

        MCvPoint2D64f shift = CvInvoke.PhaseCorrelate(curr64f, prev64f, hann, out noise );

        double value = noise ;

        double radius = Math.Sqrt(shift.X * shift.X + shift.Y * shift.Y);

        Model Test = new Model() { osX = shift.X, osY = shift.Y, noise = value };

        return Test;
    }
}
</code></pre>

<p>Therefore, I have two questions:</p>

<ol>
<li>How to convert Bitmap to Mat structure.</li>
</ol>

<p>At the moment I read my images to compare from disc according to file path. But I would like to send to compare collection of bitmaps without saving on my hard drive.</p>

<ol start=""2"">
<li>Do you know any another way to detect shift between two pictures ?. I would be really grateful for any other suggestion in this area.</li>
</ol>

<p>Regards,</p>

<p>Mariusz</p>
",,2020-08-20 14:53:18,How to convert Bitmap to Mat structur in EmguCV & How to detect two images shift,<c#><opencv><image-processing><bitmap><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
30363,29909944,2015-04-28 03:48:05,,"<p>I am using this sample code to do image matching (using the OpenCV .NET wrapper called Emgu CV, SURF, and FLANN): <a href=""http://romovs.github.io/blog/2013/07/05/matching-image-to-a-set-of-images-with-emgu-cv/"" rel=""nofollow"">http://romovs.github.io/blog/2013/07/05/matching-image-to-a-set-of-images-with-emgu-cv/</a></p>

<p>My question is, what is the proper way to save this FLANN index to disk and then reopen it for later use?</p>

<p>Also, I'd like to build my matrix directly to disk (as well as the index), so I don't use massive amounts of memory when going through 100,000+ images. Any suggestions?</p>
",,2015-08-09 14:42:41,How do I save a FLANN index to disk built from a matrix in C#?,<c#><opencv><matrix><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
30364,29910132,2015-04-28 04:06:14,,"<p>I'm having the hardest time trying to find a solution for something I think would be very simple. The Capture Constructor (String) in Emgu.CV should ""Create a capture from file or a video stream.""  </p>

<p>However, I cannot capture anything with my code in C# despite my IP camera (Axis) allowing a video stream as follows:
Request a Motion JPEG video stream ->
<a href=""http://myserver/axis-cgi/mjpg/video.cgi"" rel=""nofollow"">http://myserver/axis-cgi/mjpg/video.cgi</a>
(By the way, according to the manufacturer, ""A successful request returns a continuous flow of JPEG images. The content type is multipart/x-mixed-replace and each image ends with a boundary string ."")</p>

<p>FYI, the camera server does require a username and password login, which I haven't been able to figure out how to include with Capture yet, either...
Am I supposed to make a HTTPWebRequest first and then do Capture, or am I supposed to do something much more complicated?  Not sure if login may be an issue since I didn't get a specific error on this, but suspect a webrequest may be necessay, which I don't know how to include...</p>

<p>Stripped down code in my form.cs:</p>

<pre><code>Capture _capture = null; //Camera
string sourceURL = ""http://192.168.0.90/axis-cgi/mjpg/video.cgi"";
_capture = new Capture(sourceURL);
Image&lt;Bgr, Byte&gt; imgOriginal = new Image&lt;Bgr, byte&gt;(_capture.RetrieveBgrFrame().ToBitmap());
</code></pre>

<p>Then I try to display imgOriginal in an ImageBox.  However, at the last step above, it already generates an error that says ""unable to create capture..."" or something like this.</p>

<p>Shouldn't this be very simple with emguCV or am I mistaken?  If someone can help me figure out how to capture the image, I can take it from there with processing my images.  Thank you in advance!</p>
",,2016-12-29 01:27:45,How to capture video stream via http with an IP camera using emgucv in c#,<c#><video><stream><emgucv><capture>,,,CC BY-SA 3.0,False,False,True,False,False
30369,29871084,2015-04-25 21:44:52,,"<p>I am newbie in EmguCV and when I try to use <code>GPUInvoke.SwapChannel</code> and <code>GPU.Convolution</code> I get:</p>

<blockquote>
  <p>A first chance exception of type 'Emgu.CV.Util.CvException' occurred
  in Emgu.CV.dll</p>
</blockquote>

<p>This is my code</p>

<pre><code>Image&lt;Rgb, Byte&gt; img = new Image&lt;Rgb, byte&gt;(StringA);
GpuImage&lt;Rgb, Byte&gt; gpi = new GpuImage&lt;Rgb, byte&gt;(img);
int[] a = new int[4];
a[0] = 4;
a[1] = 3;
a[2] = 2;
a[3] = 1;
GpuInvoke.SwapChannels(gpi, a, IntPtr.Zero);
Image&lt;Rgb, Byte&gt; im = gpi.ToImage();
pictureBox2.Image = im.ToBitmap();
</code></pre>

<p>and this</p>

<pre><code>Image&lt;Rgb, Single&gt; img = new Image&lt;Rgb, Single&gt;(StringA);
GpuImage&lt;Rgb, Single&gt; gpi = new GpuImage&lt;Rgb, Single&gt;(img);
float[,] k = {{1,2,3,1,2},
              {2,4,5,4,2},
              {3,5,6,5,3},
              {2,4,5,4,2},
              {1,2,3,2,1}};
ConvolutionKernelF kernel = new ConvolutionKernelF(k);
GpuImage&lt;Rgb, Single&gt; gp = gpi.Convolution(kernel, new Emgu.CV.GPU.Stream());
Image&lt;Rgb, Single&gt; im = gp.ToImage();
pictureBox2.Image = im.ToBitmap();
</code></pre>
",2015-04-25 21:57:36,2015-04-25 21:57:36,A first chance exception of type 'Emgu.CV.Util.CvException' occurred in Emgu.CV.dll,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
30462,29896365,2015-04-27 12:52:38,,"<p>I try to capture video using Emgu-CV but I have an error. My code of the following:    </p>

<pre><code>Timer My_Time = new Timer();
int FPS = 30;

public Form1()
{
       InitializeComponent();

       //Frame Rate
       My_Timer.Interval = 1000 / FPS;
       My_Timer.Tick += new EventHandler(My_Timer_Tick);
       My_Timer.Start();
       _capture = new Capture(""test.avi"");   
}

private void My_Timer_Tick(object sender, EventArgs e)
{
       imageBox.Image = _capture.QueryFrame();
}
</code></pre>

<p>The error occurs at </p>

<pre><code>_capture = new Capture(""test.avi""); 
</code></pre>

<p><img src=""https://i.stack.imgur.com/tI008.jpg"" alt=""enter image description here""></p>

<p>Thanks.</p>

<p>Detail 
<img src=""https://i.stack.imgur.com/LO8MV.jpg"" alt=""enter image description here""></p>
",2015-04-27 13:03:46,2015-04-28 00:36:14,Attempted to read or write protected memory when capture video using Emgu-CV,<c#><visual-studio><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
30549,30006671,2015-05-02 19:40:47,,"<p>I am newbie to using svm for classification. I want to tune svm parameters by <code>.TrainAuto</code>function in EmguCV. But I don't know what are the range(min-max value) of below parameters that I should give to this function to search:</p>

<p>1- C (for poly and RBF kernels)</p>

<p>2- Gamma (for poly and RBF kernels)</p>

<p>3- Coeficient (for poly kernel)</p>

<p>4- Degree (for poly kernel)</p>

<p>What are the range of these parameters?</p>

<p>Do these ranges depends on the number of samples?</p>

<p>As I receive the out of memory allocation error, can I set step parameter to a large value and when I found optimal values approximately, set these range to a smaller one and search on the second range with smaller step?</p>
",,2015-05-02 20:34:03,SVM parameter tuning,<opencv><classification><svm><emgucv><libsvm>,,,CC BY-SA 3.0,True,False,True,False,False
30608,30030618,2015-05-04 12:49:17,,"<pre><code>Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();  //line 1
CamImageBox.Image = ImageFrame.ToBitmap();
</code></pre>

<p>I have used above code for <code>Display</code> an <code>EmguCV</code> image in Windows Form Picture Box,</p>

<p>But I have got an error:</p>

<blockquote>
  <p>cannot implicitly convert type 'system.drawing.bitmap' to
  'emgu.cv.image'</p>
</blockquote>

<p>This case also in Stackoverflow questions, but no one give proper answer for this.</p>
",2015-05-06 15:18:28,2017-03-23 10:54:08,Display an EmguCV image in Windows Form Picture Box,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
30627,26182117,2014-10-03 15:35:08,,"<p>I am getting video feed using DirectShow in my C# Web Form. Now i want to process the frames using OpenCV. (EmguCV Wrapper)</p>

<p>1) How would i collect frames from DirectShow feed.</p>

<p>2) Is there a Way to combine DS &amp; OpenCV.</p>

<p>Thanks.</p>
",,2014-10-23 20:31:16,Combine DirectShow with OpenCV,<c#><opencv><directshow><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
30765,27313826,2014-12-05 10:30:22,,"<p>I am implementing SURF to detect Digits inside a seven segment display using some template. But it is not working fine. Is there any way that can be slow but more effective. I am using Emgu Wrapper for OpenCV</p>
",,2014-12-08 17:13:14,Image recognition to read 7segment Display,<c#><opencv><image-processing><ocr><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
30769,26196330,2014-10-04 19:25:07,,"<p>Given a color pixel coordinate(x,y), is there a way to find the corresponding depth image co-ordinate?
I looked into co-ordinate mapping, using which you can map a skeleton pixel to a color pixel. I'm identifying objects in the color stream and I want to know how far they are using the depth stream. Am I overlooking something here?</p>
",,2014-10-10 09:15:04,Kinect color to depth mapping,<c#><image-processing><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
30773,30147050,2015-05-10 02:21:39,,"<p>I want to Circle line thickness calculation like this below:</p>

<p><img src=""https://i.stack.imgur.com/SHc3M.jpg"" alt=""enter image description here""></p>

<p>Which method can help me to do so?</p>

<p>Thanks for your reply David. I'm new to emgucv. So I do not know where I'll start. I can do the following image using canny edge. But I can not calculate distance, because I do not know what I would use the code. Which can I use code?</p>

<pre><code>private void button1_Click(object sender, EventArgs e)
{
    string strFileName = string.Empty;
    OpenFileDialog ofd = new OpenFileDialog();
    if (ofd.ShowDialog() == DialogResult.OK)
    {
        //Load image
        Image&lt;Bgr, Byte&gt; img1 = new Image&lt;Bgr, Byte&gt;(ofd.FileName);
        //Convert the img1 to grayscale and then filter out the noise
        Image&lt;Gray, Byte&gt; gray1 = img1.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();
        //Canny Edge Detector
        Image&lt;Gray, Byte&gt; cannyGray = gray1.Canny(120, 180);
        pictureBox1.Image = cannyGray.ToBitmap();
    }
}
</code></pre>
",2015-05-14 16:45:37,2015-05-16 14:54:14,C# EmguCV - Circle line thickness calculation,<c#><geometry><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
30818,30134769,2015-05-09 00:41:58,,"<p>I tried to display videos from 4 cameras using the Emgu CV framework. Only the first 2 cameras were displayed properly, for the other 2, the method RetrieveBgrFrame (of the Capture objects) always return null.</p>

<p>I tried swap the pluging order of the camera in the usb hub, always only the first two cameras in the list obtained by DirectShow are working). To make sure all cameras working I used another commercial programs to check, all cameras are working fine.</p>

<p>Have any body ever experienced this? Do you know what the cause is?</p>

<p>Any help or pointer to help is highly appreciated.</p>

<p>Please help!</p>

<p>Thanks,</p>

<p>TC</p>

<p>======== code ==========</p>

<p>//--------------- creating camera objects ---------------------------</p>

<pre><code>DsDevice[] _SystemCamereas = DsDevice.GetDevicesOfCat(FilterCategory.VideoInputDevice); ///// after this statement, _SystemCamereas contains 4 entries

            //Capture capture;
            Capture capture;
            capture = new Capture(2); ///// if I use '0' or '1', i.e. the ids of the first 2 cameras, picture box displayed correctly
            capture.ImageGrabbed += ProcessFrame;
            _captureImageBoxDict.Add(capture, imageBox1);
            imageBox1.SizeMode = PictureBoxSizeMode.StretchImage;
</code></pre>

<p>// ----------Callback method to process frame after Grab</p>

<pre><code>    private void ProcessFrame(object sender, EventArgs arg)
    {
        Capture capture = (Capture)sender;
        Image&lt;Bgr, Byte&gt; frame = capture.RetrieveBgrFrame(); // for camera id = 0 or 1, frame is not null and everythins goes smoothly, for id = 2 or 3, frame is null!!!!

        if (frame == null)
        {
            return;
        }
        // ......
     }
</code></pre>

<p>========== Other system info ====================</p>

<p>Microsoft Visual Studio Community 2013</p>

<p>Emgu CV version: 2.4.10.1939 (acquired through Visual Studio NuGet Manager)</p>

<p>.NET Framework 4.5</p>

<p>OS: Windows 7 Professional</p>

<p>Processor: Intel Core i7 CPU Q 720 @ 1.60GHz</p>

<p>Installed memory (RAM): 16.0 GB</p>
",,2015-05-09 00:41:58,Emgu CV C# Capture method RetrieveBgrFrame returns null with 4 cameras,<c#><opencv><camera><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
30902,30125654,2015-05-08 13:55:41,,"<p>I've been working with OpenCV before for C++ work and It was working great. Now, I'm developing a C# project and using EMGU CV for gender recognition. I've got problem with predict function. Every time I ran it, program crashed on Predict function, when I erased predict line, it is running. Here's my code:</p>

<pre><code>private void Window_Loaded(object sender, RoutedEventArgs e)
{
     FaceRecognizer face = new FisherFaceRecognizer(0, 3500);
     face.Load(""colorFisherFaceModel.yml"");                
     Image&lt;Bgr, Byte&gt; img1 = new Image&lt;Bgr, Byte&gt;(""C:\\Users\\sguthesis\\Pictures\\me.jpg"");
     cascade = new CascadeClassifier(""C:\\Users\\sguthesis\\documents\\visual studio 2013\\Projects\\EmguCV FFR with Image\\EmguCV FFR with Image\\haarcascade_frontalface_alt_tree.xml"");
     FaceRecognizer.PredictionResult predictedLabel = face.Predict(img1);
}
</code></pre>

<p>Also, I want to get an output, 1 or 2. 1 for male and 2 for female. I have trained many data that saved on colorFisherFaceModel.yml. It was run well on OpenCV. But I don't know how to use it in EMGU CV.</p>
",2015-05-08 14:30:28,2016-01-14 21:58:02,EMGU CV Face Recognition from Image,<c#><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
30903,30104010,2015-05-07 14:28:25,,"<p>After about two days of testing and researching I've come up with nothing. I'm using IronPython through Visual Studio 2013 and I'm trying to get a camera view on the window. I can't seem to find any libraries that actually work with what I've got to do this.  There are lots of tutorials on setting different libraries up, and I've tried all the ones I can find, but without any luck because they don't seem to be exactly aimed at what I'm using. I've tried OpenCV but that doesn't seem to work, emgu is the closest I've got by doing this;</p>

<pre><code>import clr
clr.AddReferenceToFile(""Emgu.Util.dll"")
clr.AddReferenceToFile(""Emgu.CV.dll"")
clr.AddReferenceToFile(""Emgu.CV.ML.dll"")
clr.AddReferenceToFile(""Emgu.CV.UI.dll"")
from Emgu.CV import *
from Emgu.CV.UI import *
from Emgu.CV.Structure import *
from System import *
</code></pre>

<p>And this seems to be the only method I've managed to get to work to do what I need, however, there's no API for python (Only VB.net, C#, etc.) so I have no idea what to do after this to get the camera to do anything.  So my question is pretty much, either, what do I need to do to get Emgu to give me the camera feed, or is there a better method that I've not found which works with IronPython and Visual Studio 2013?</p>
",,2015-05-07 14:28:25,Live camera feed with Iron Python on Visual Studio 2013,<python><visual-studio><visual-studio-2013><ironpython><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
30941,30125964,2015-05-08 14:12:54,,"<p>i've using emgu cv 2.4.10 to create a RTSP stream viewer that will eventually be used with IP cameras. as i don't have the camera/s as yet, i'm testing using VLC (the windows GUI) to create the stream from a video file. </p>

<pre><code>:sout=#duplicate{dst=rtp{sdp=rtsp://:8554/stream},dst=display} :sout-all :sout-keep
</code></pre>

<p>i'm doing this all testing on localhost.</p>

<p>here's my capture code:</p>

<pre><code>private void ProcessFrame(object sender, EventArgs arg) {
    try {
        frame = _capture.QueryFrame();
        pictureBox1.Image = frame.ToBitmap();
    }
    catch (Exception ex) {
        MessageBox.Show(ex.Message.ToString());
    }
}
</code></pre>

<p>this method is called using this eventhandler:</p>

<pre><code>_capture = new Capture(""rtsp://localhost:8554/stream"");
Application.Idle += ProcessFrame;
_capture.Start();
</code></pre>

<p>the capture is corrupted with random occurrences of ""smearing"" that always occurs in the lower portion of the frame:</p>

<p><img src=""https://i.stack.imgur.com/vH1lC.png"" alt=""screencapture showing smearing on the lower half of the captured video frame""></p>

<p>i've seen several others online have reported this problem as recently as last december but no solution has been found or that would work for me:</p>

<ul>
<li><a href=""http://workingwithcomputervision.blogspot.co.uk/2012/06/issues-with-opencv-and-rtsp.html"" rel=""nofollow noreferrer"">http://workingwithcomputervision.blogspot.co.uk/2012/06/issues-with-opencv-and-rtsp.html</a></li>
<li><a href=""https://stackoverflow.com/questions/18276509/emgu-queryframe-returns-streaky-image-over-rtsp"">EMGU QueryFrame returns &quot;streaky&quot; Image over RTSP</a></li>
<li><a href=""http://www.emgu.com/forum/viewtopic.php?f=7&amp;t=4882&amp;p=10110&amp;hilit=rtsp#p10069"" rel=""nofollow noreferrer"">http://www.emgu.com/forum/viewtopic.php?f=7&amp;t=4882&amp;p=10110&amp;hilit=rtsp#p10069</a></li>
</ul>

<p>to narrow down the problem, i've run ffplay from the commandline and the capture is perfect. i've run another instance of VLC to capture the RTSP stream and it displays perfectly. so this is clearly a problem in open cv/emgu cv.</p>

<p>on a whim, i changed VLC to stream using HTTP.</p>

<pre><code>:sout=#duplicate{dst=http{mux=ffmpeg{mux=flv},dst=:8080/stream},dst=display} :sout-all :sout-keep
</code></pre>

<p>this displays fine in my code, but at a noticeably lower frame rate that won't work for my application.  i'd really appreciate any tips to fixing this problem.  thanks.</p>
",2017-05-23 11:58:16,2015-06-25 08:41:04,smeared/corrupted capture of RTSP streams,<opencv><rtsp><emgucv><capture><corruption>,,,CC BY-SA 3.0,True,False,True,False,True
30970,30233458,2015-05-14 09:12:18,,"<p>Currently My Program is able to turn on the <code>webcam</code>, but right now I have no idea how to turn the webcam off by code.</p>

<p>Here's the code I use to capture some pictures:</p>

<pre><code>private void webcamStart_Click(object sender, EventArgs e)
{
    image = new Capture();
    image.QueryFrame();
    Application.Idle += new EventHandler(FrameGrabber);
}
</code></pre>

<p>PS: I using emguCV </p>
",2015-05-14 09:45:04,2015-05-14 09:45:04,Turn a webcam off,<c#><webcam><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
31129,30227795,2015-05-14 01:23:13,,"<p>I am trying to run this code using c# and emgucv to draw a histogram for an image but it keeps giving me an error that 'The name   'InitializeComponent()' does not exist in the current context'. I tried to add references but it is not working.</p>

<pre><code>using ZedGraph;
using System;

using System.Linq;
using System.Text;
using System.Drawing;
using System.Runtime.InteropServices;
using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.UI;
using Emgu.Util;
using Emgu.CV.Structure;
using System.Windows.Forms;
using System.ComponentModel;
using System.Data;
using System.IO;
using System.Windows.Markup;
using System.Windows;
using System.Windows.Input;
using System.Windows.Threading;
using System.Xaml;
using System.Xml;
;



namespace My_EMGU_Program
{
  public partial class Form1 : Form
  {
    public Form1()
    {
      InitializeComponent();

    }

    private void button1_Click(object sender, EventArgs e)
    {
      OpenFileDialog Openfile = new OpenFileDialog();
      if (Openfile.ShowDialog() == DialogResult.OK)
      {
        Image&lt;Bgr, byte&gt; img = new Image&lt;Bgr, byte&gt;(Openfile.FileName);
        float[] BlueHist;
        float[] GreenHist;
        float[] RedHist;
        DenseHistogram Histo = new DenseHistogram(255, new RangeF(0, 255));
        Image&lt;Gray, Byte&gt; img2Blue = img[0];
        Image&lt;Gray, Byte&gt; img2Green = img[1];
        Image&lt;Gray, Byte&gt; img2Red = img[2];

        Histo.Calculate(new Image&lt;Gray, Byte&gt;[] { img2Blue }, true, null);
        //The data is here
        //Histo.MatND.ManagedArray
        BlueHist = new float[256];
        Histo.MatND.ManagedArray.CopyTo(BlueHist, 0);

        Histo.Clear();

        Histo.Calculate(new Image&lt;Gray, Byte&gt;[] { img2Green }, true, null);
        GreenHist = new float[256];
        Histo.MatND.ManagedArray.CopyTo(GreenHist, 0);

        Histo.Clear();

        Histo.Calculate(new Image&lt;Gray, Byte&gt;[] { img2Red }, true, null);
        RedHist = new float[256];
        Histo.MatND.ManagedArray.CopyTo(RedHist, 0);

        float[] GrayHist;

        Image&lt;Gray, Byte&gt; img_gray = new Image&lt;Gray, byte&gt;                (Openfile.FileName);

        Histo.Calculate(new Image&lt;Gray, Byte&gt;[] { img_gray }, true, null);
        //The data is here
        //Histo.MatND.ManagedArray
        GrayHist = new float[256];
        Histo.MatND.ManagedArray.CopyTo(GrayHist, 0);


        /*This Methof call will produced the Histograms for you*/
        Add_Histogram(GrayHist, ""Gray Histogram"");
        Add_Histogram(BlueHist, ""Blue Histogram"");
        Add_Histogram(GreenHist, ""Green Histogram"");
        Add_Histogram(RedHist, ""Red Histogram"");
      }
    }

    /* You can extend this method to set line colour x and y  titles quite easily */
    //Global X Y locations to stack Histograms
    int X = 10, Y = 10;
    Panel panel1 = new Panel();
    void Add_Histogram(float[] Histo_dat, string Histo_Title = ""Histogram Title"")
    {

      //Create the Control
      ZedGraphControl zgc = new ZedGraphControl();
      zgc.Location = new Point(Y, X);
      zgc.Size = new Size(panel1.Width - 20, 200);
      X += (zgc.Size.Height + 20); //increas X for next Graph

      GraphPane myPane = zgc.GraphPane;

      myPane.Title.Text = Histo_Title;
      myPane.XAxis.Title.Text = ""X Axis - Pixel Bin Values"";
      myPane.YAxis.Title.Text = ""Y Axis - Total Number of Pixels"";

      //Create an array that Zedgraph can use
      PointPairList list1 = new PointPairList();
      for (int i = 0; i &lt; Histo_dat.Length; i++)
      {
        list1.Add(new PointPair(i, Histo_dat[i]));
      }

      //Add the data to the control
      LineItem myCurve = myPane.AddCurve(""Title"", list1, Color.Blue, SymbolType.Circle);
      zgc.AxisChange();

      //Add the controll and refresh form
      panel1.Controls.Add(zgc);
      this.Refresh();


    }

    //In case you wish to restart and draw newly calculated histograms
    void Clear_Histograms()
    {

      panel1.Controls.Clear();
      X = 10;
    }
  }
}
</code></pre>
",2015-05-16 07:14:46,2015-05-16 07:22:50,"The name 'InitializeComponent()' does not exist in the current context (c#, emgucv)",<c#-4.0><c#-3.0><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
31141,30266079,2015-05-15 18:08:29,,"<p>I have a problem with EmguCV in Unity 5. I followed the instructions of other Threads and copied the EmguCV dlls in the Plugin-folder and do some more steps. </p>

<p>When I'm running a small test program where I use EmguCV everything is ok. But when I try to get my own EmguCV project running into Unity there are a lot of errors because of missing .dll files or because it is not able to load some classes. </p>

<p>For example it has problems with the PresentationCore. If I add the Assembly to the PresentationCore in Visual Studio it still don't know the classes I'm using out of the PresentationCore. </p>

<p>I've copied the <code>PresentationCore.dll</code> into the Plugin folder of my Unity project. Now it can compile the Scripts but running the program I get Errors like these:  </p>

<blockquote>
  <p>SpritePacker failed to get types from PresentationCore,
  Version=3.0.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35. 
  Error: The classes in the module cannot be loaded.
  UnityEditor.Sprites.Packer:GetSelectedPolicyId()  </p>
  
  <p>DllNotFoundException: MSVCR80.dll .?A0xe96b2b07.clock_wrapper
  ()</p>
  
  <p>TypeLoadException: A type load exception has occurred.</p>
  
  <p>DllNotFoundException: wpfgfx_v0300.dll
  System.Windows.Media.FactoryMaker..ctor ()</p>
  
  <p>FileNotFoundException: Could not load file or assembly
  'UIAutomationTypes, Version=3.0.0.0, Culture=neutral,
  PublicKeyToken=31bf3856ad364e35' or one of its dependencies.</p>
</blockquote>

<p>Has anyone here had similar problems and knows how to solve them? Or any ideas what I'm doing wrong?</p>

<p>Thanks for your help</p>
",2015-05-15 20:10:55,2015-11-30 22:46:57,EmguCV in Unity 5. Problems with dll-files,<.net><dll><unity3d><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
31148,26231683,2014-10-07 08:27:36,,"<p>We're using Emgu CV to detect face and recognize gender, but my boss said that there is something wrong and i don't know why. I'm using Emgu CV version 2.4.9 and I'm using default haar-cascade xml file. The thing that is so wrong is in the following image that is captured by webcam.</p>

<p><img src=""https://i.stack.imgur.com/hNvxa.png"" alt=""enter image description here""></p>

<p>There is no face in the picture but there is a group rectangles which has many rectangle, I set minNeighbour = 0 because I wanted to display all the rectangle that predicts to contain face. Please give me some opinions or some idea to eliminate this situation. I'm sure that my code is correct. Very thank for your help. </p>

<p>Sorry about my English.</p>
",,2014-10-15 02:45:57,Face detection wrong object,<opencv><emgucv><face-detection>,,,CC BY-SA 3.0,True,False,True,False,False
31201,30291023,2015-05-17 19:11:50,,"<p>I have got a problem when using EmguCV. Everytime I try to create SIFT or SURF detector I get exception ""The type initializer for 'Emgu.CV.CvInvoke' threw an exception"".
I've already: installed MSVCRT, copied OpenCV and Emgu dlls to the execution directory, added to solution OpenCV and Emgu dlls, added to solution Emgu.CV, Emgu.CV.GPU, Emgu.CV.ML, Emgu.CV.UI, Emgu.Util references.
Unfortunately I still got exception. I've tried to build SURFFeature example and it worked perfectly. It actually means that I make some mistake, but I can't find it... Please help...</p>

<p>Here's the code:</p>

<pre><code>using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Runtime.InteropServices;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Features2D;
using Emgu.CV.Structure;
using Emgu.CV.UI;
using Emgu.CV.Util;
using Emgu.CV.GPU;

namespace blablabla
{
    public partial class Form1 : Form
    {
        public Form1()
        {
            InitializeComponent();
        }

        private void button1_Click(object sender, EventArgs e)
        {
            try
            {
                Bitmap waveform_to_file = new Bitmap(2, 2);

                //Emgu.CV.Features2D.SIFTDetector detector = new Emgu.CV.Features2D.SIFTDetector();//(0, 3, 0.04, 10, 1.6);//(400, true, 3, 4);//
                SURFDetector surfCPU = new SURFDetector(500, false);//I got exception on these lines

                Emgu.CV.Util.VectorOfKeyPoint keypoints = new Emgu.CV.Util.VectorOfKeyPoint();

                Emgu.CV.Image&lt;Emgu.CV.Structure.Gray, Byte&gt; waveform_to_file_gray = new Emgu.CV.Image&lt;Emgu.CV.Structure.Gray, byte&gt;(waveform_to_file);

                Emgu.CV.Features2D.ImageFeature&lt;float&gt;[] modKeyPointsArray = surfCPU/*detector*/.DetectFeatures(waveform_to_file_gray, null);

                List&lt;Emgu.CV.Features2D.ImageFeature&lt;float&gt;&gt; modKeyPointsList = new List&lt;Emgu.CV.Features2D.ImageFeature&lt;float&gt;&gt;();
            }
            catch(Exception ex)
            {
                MessageBox.Show(ex.Message + ex.StackTrace);
            }
        }
    }
}
</code></pre>

<p>Solution explorer:</p>

<p><a href=""http://ifotos.pl/zobacz/4JPG_wwaerwh.jpg"" rel=""nofollow"">http://ifotos.pl/zobacz/4JPG_wwaerwh.jpg</a></p>

<p>bin/debug:</p>

<p><a href=""http://ifotos.pl/zobacz/3JPG_wwaereh.jpg"" rel=""nofollow"">http://ifotos.pl/zobacz/3JPG_wwaereh.jpg</a></p>
",,2015-05-17 19:11:50,"EmguCV ""The type initializer for 'Emgu.CV.CvInvoke' threw an exception""",<c#><opencv><exception><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
31264,30204058,2015-05-13 01:22:41,,"<p>I am trying to extract RGB color Histogram for an image using C# (or C++) and Emgu CV. Current:</p>

<pre><code>static double[] colorHistogram(Image&lt;Bgr, Byte&gt; img, int rStep, int gStep, int bStep)
{
     double[] histogram = null;
     return histogram;
}
</code></pre>
",2015-05-13 01:33:50,2015-05-13 01:51:47,Extracting RGB color histogram for an image using C# and EmguCV,<c#><c++><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
31336,30331784,2015-05-19 17:00:47,,"<p>Here I used this:</p>

<pre><code>pictureBox1.Image = My_Image.ToBitmap();
byte Red_val = My_Image.Data[0, 0, 2];
MessageBox.Show(Red_val.ToString());
</code></pre>

<p>Does this give the average intensity of the red area? How do I get the average intensity value?</p>
",2015-05-19 17:11:01,2016-06-27 08:51:27,How to get the average intensity value of the red color area in C# using EMGU CV library?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
31443,30464676,2015-05-26 16:59:13,,"<p>I am doing a project on C# and emgu library.</p>

<p>My code works fine on my computer but when I try to run it on other computers it gives exception here:</p>

<pre><code>  haar = new HaarCascade(""detector_best.xml"");
</code></pre>

<p><em>exception is Unhandled type of exception in Sytem.Typeinitaialization occured in Emgu.CV.</em></p>

<p>Kindly help me I am giving system environment path and working on Windows. also my file detector_best.xml is in my project's debug folder.</p>
",2015-05-26 17:12:20,2015-05-30 04:30:55,EMGU in handled exception of initializing haarcascade.XML in C#,<c#><portability><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
31517,30489566,2015-05-27 17:42:59,,"<p>I am using <strong>EMGU.CV</strong> for a vehicle counting project. </p>

<hr>

<p>The capture method of Capture.cs can take the video file name as argument and process the video, frame by frame. The vehicle counting, which is based on background subtraction and moving object detection, is working fine.</p>

<p><strong>Problem:</strong> </p>

<p>Capture method only can read a raw formatted (fully decompressed) file. Where I have <strong>173mb video footage of 1 hour</strong> to analyze, if I <strong>convert it in RAW format with original specs (720*480 px &amp; 29.7 fps)</strong> the converted file size increases to <strong>~50 GB</strong>. </p>

<p><strong>173 MB file after Raw conversion ~50 GB.</strong> Which is too expensive for me.</p>

<p>But no other encodings are supported in EMGU.CV to analyze frame by frame (as far I know). But there are several solutions on vehicle counting, which don't need extra memory. </p>

<p><strong>Are there any processes regarding emgu.cv capture or any other process to analyse a compressed video frame by frame?</strong></p>
",2015-05-28 07:05:37,2015-05-28 07:05:37,Video analysis frame by frame without decompressing the video file,<c#><video-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
31529,30413815,2015-05-23 14:25:00,,"<p>Suppose one image has different objects of different sizes(50pixel,100pixels and 200pixel) in it. How can i Label only those objects which have 100pixels OR Greater than 100pixels &amp; less than 200pixels.</p>

<p>I have labeled all objects in image by using AForge's Connected Components Labeling Method. But I don't know how to do same for specific size objects.</p>

<pre><code>ConnectedComponentsLabeling Labeling = new ConnectedComponentsLabeling();

Bitmap labeledImage = Labeling.Apply(BinaryImage);

int Objects =Labeling.ObjectCount;
</code></pre>

<p>Solution </p>

<pre><code> ""// Applying Blob Filter
        BlobsFiltering filter = new BlobsFiltering();
        filter.CoupledSizeFiltering = true;
        filter.MinHeight = 4;
        filter.MinWidth = 4;
        Bitmap FilterImage = filter.Apply(BinaryImage);

        // Counting Ojects
        ConnectedComponentsLabeling Labeling = new ConnectedComponentsLabeling();
        Bitmap labeledImage = Labeling.Apply(FilterImage);
         int TotalNumberofTeeth = Labeling.ObjectCount;
</code></pre>
",2015-06-05 10:53:38,2015-06-05 10:53:38,Connected component Labeling of specific Size objects,<c#><image-processing><emgucv><connected-components>,,,CC BY-SA 3.0,False,False,True,False,False
31547,30513371,2015-05-28 17:31:40,,"<p>I am trying to create and Emgu <code>Image&lt;TColor, TDepth&gt;</code> and cannot seem to correctly specify the <code>TColor</code> for my image. So far I have loaded my image from a file into a .Net <code>Image</code>. I am now trying to do the following to convert that image to an OpenCV image representation.</p>

<pre><code>Image&lt;Bgr, Byte&gt; cvTestImage = new Image&lt;Bgr, Byte&gt;(new Bitmap(testImage));
</code></pre>

<p>In Visual Studio both <code>Bgr</code>'s are underlined in red, though it seems to accept the <code>Byte</code> parameters (But I would assume that I need to use the OpenCV <code>TDepth</code> definitions?). Though the <code>Image&lt;TColor, TDepth&gt;</code> type is recognized and I have added <code>using Emgu.CV</code> and <code>using Emgu.Util</code> to my class. </p>

<p>I have searched the Emgu documentation website and found the documentation for both <a href=""http://www.emgu.com/wiki/files/1.4.0.0/html/561c7c68-fa5e-6bd9-b29c-2f8c7fd41b08.htm"" rel=""nofollow noreferrer""><code>ColorType</code></a> and <a href=""http://www.emgu.com/wiki/files/1.4.0.0/html/f6682fa1-90bf-e2b0-50d5-084e3e8d1307.htm"" rel=""nofollow noreferrer""><code>Bgr</code></a> but I cannot get my IDE to recognize either or find them in Emgu.</p>

<p>I have Emgu version 2.4.10.</p>

<p>From what I can tell from the documentation the type <code>Bgr</code> is located at <code>Emgu.CV.Bgr</code> but Visual Studio will not autocomplete to it. Also when I mouse over the <code>Byte</code> parameter to <code>Image&lt;&gt;</code> Visual Studio shows that it is of type <code>System.Byte</code> and not something like <code>Emgu.CV.TDepth.Byte</code>.</p>

<p>If it helps here is a view from Visual Studio</p>

<p><img src=""https://i.stack.imgur.com/gjUZp.png"" alt=""enter image description here""></p>

<p><strong>EDIT:</strong> Ok I am not sure what is going on now...</p>

<p>I am not sure if this issue started happened before or after I tried to install the <a href=""https://www.microsoft.com/en-ca/download/details.aspx?id=13523"" rel=""nofollow noreferrer"">MVSCRT</a> as recommended by the <a href=""http://www.emgu.com/wiki/index.php/Download_And_Installation#The_type_initializer_for_.27Emgu.CV.CvInvoke.27_threw_an_exception."" rel=""nofollow noreferrer"">Emgu documentation</a>. But now when I try to call code from the Emgu library I receive the following error. </p>

<p><img src=""https://i.stack.imgur.com/qr1OV.png"" alt=""enter image description here""></p>

<p>I have reinstalled the Emgu library along with reinstalling the MVSCRT. Whenever I try to call any Emgu code this exception is thrown. I am not sure where to go from here..</p>

<p><strong>EDIT2:</strong></p>

<p>I am not sure why but by removing the <code>using Emgu.Util</code> statement from the code the issue above has solved itself. It would be interesting to know what happened..</p>

<p>So I am now back the the semi-original issue.
<img src=""https://i.stack.imgur.com/QWFoc.png"" alt=""enter image description here""></p>

<p>I have installed the MSVCRT <a href=""http://www.emgu.com/wiki/index.php/Download_And_Installation#The_type_initializer_for_.27Emgu.CV.CvInvoke.27_threw_an_exception."" rel=""nofollow noreferrer"">as instructed</a> by the Emgu website. 
<img src=""https://i.stack.imgur.com/lgK6n.png"" alt=""enter image description here""></p>

<p><strong>EDIT3:</strong></p>

<p>It looks like I finally got it working by moving the x86 and x64 directories to the execution folder. Now I am just waiting for the call to the function to return...</p>
",2015-05-28 20:31:11,2015-05-28 20:31:11,Where is TColor defined in Emgu OpenCV .Net wrapper?,<c#><.net><image><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
31593,27389316,2014-12-09 21:37:11,,"<p>I have 4 cameras connected to my computer (one is the built-in webcam, others are generic usb cameras). I'm using EMGU to connect to them at the same time without user interaction.</p>

<p>I'm creating a new instance of Capture() for each camera, but it errors out on the 3rd camera (index 2). I've tried switching out each camera with another camera (I have a few extras), and I've tried switching the ports that each one is plugged in to. It's always index 2 that does not connect, causing a Null Reference Exception.</p>

<p>Here is my code. It fails on the third line of this.</p>

<pre><code>Capture0 = New Capture(0)
Capture1 = New Capture(1)
Capture2 = New Capture(2)
Capture3 = New Capture(3)
</code></pre>

<p>Does anyone know why this is happening?</p>
",,2014-12-09 21:37:11,EMGU - Unable to create capture from camera 2 - VB.net,<vb.net><camera><nullreferenceexception><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
31665,30521595,2015-05-29 05:13:15,,"<p>I want to compute histogram of oriented gradient on my image. But I don't want to divide the image to regular square blocks. I'm going to divide the image to uniform log polar bins(like bins in shape context or bins like <a href=""https://stackoverflow.com/questions/5258740/drawing-shape-context-logpolar-bins-in-matlab/"" title=""Here"">here</a> ) and then on each bin(block) the histogram of gradient with 8 orientation is computed. </p>

<p>But
1) I don't know how to divide the image to log polar bins. Can I use shape context? Or even the above link for partitioning to these bins?</p>

<p>2) how can I compute HOG on this bins since available codes(in matlab, OpenCV and EmguCV) use square bins? I have no idea. </p>
",2017-05-23 11:58:33,2015-05-29 08:01:44,computing Histogram of oriented gradients on log polar bins,<matlab><opencv><image-processing><computer-vision><emgucv>,2015-06-09 13:13:24,,CC BY-SA 3.0,True,True,True,False,False
31776,30557198,2015-05-31 12:03:38,,"<p>i am at the point, where i just would want to know if <strong>anybody out there has emguCV.unity running inside unity in osx?</strong></p>

<p>there are many tips concerning DllNotFoundExceptions and unity. all of them do not work in my case. i spent allmost four days searching and trying out everything.</p>

<p>the exact error is:</p>

<blockquote>
  <p>System.TypeInitializationException: An exception was thrown by the type initializer for Emgu.CV.OCR.OcrInvoke ---> System.TypeInitializationException: An exception was thrown by the type initializer for Emgu.CV.CvInvoke ---> System.DllNotFoundException: Assets/Plugins/emgucv.bundle/Contents/MacOS/libopencv_core.3.0.0.dylib
    at (wrapper managed-to-native) Emgu.CV.CvInvoke:cvRedirectError (Emgu.CV.CvInvoke/CvErrorCallback,intptr,intptr)
    at Emgu.CV.CvInvoke..cctor () [0x001f7] in /Users/Lev/Documents/workspace/Text_Scanner/Assets/Emgu.CV/Emgu.CV/PInvoke/CvInvoke.cs:353 
    --- End of inner exception stack trace ---
    at Emgu.CV.OCR.OcrInvoke..cctor () [0x00006] in /Users/Lev/Documents/workspace/Text_Scanner/Assets/Emgu.CV/Emgu.CV.OCR/OcrInvoke.cs:26 
    --- End of inner exception stack trace ---
    at Emgu.CV.OCR.Tesseract..ctor () [0x00011] in /Users/Lev/Documents/workspace/Text_Scanner/Assets/Emgu.CV/Emgu.CV.OCR/Tesseract.cs:45 </p>
</blockquote>

<p>(there is the emgucv.bundle in Assets/Plugins/ with the libopencv_core.3.0.0.dylib inside at the correct position. i copied the dylibs and the whole bundle to alle possible positions. including the project folder, unity-editor folder, ...)</p>

<p>there is no compilition error. the error happens after starting play in editor and in standallone mac as well.
i built emgucv with the cmake settings in emgucv.unity from emgucv 3.0.0.</p>

<p>(i even tried opencvsharp did not work neither)</p>

<p>i am desperate. please help me or just tell me, there is no way. 
thanks in advance,
lev</p>
",2015-06-02 06:02:22,2015-08-03 06:59:27,opencv (emgucv) not working in unity in osx?,<unity3d><osx-yosemite><emgucv><opencv3.0>,,,CC BY-SA 3.0,True,False,True,False,False
31796,30576915,2015-06-01 15:04:49,,"<p>We want to compare with pictures in database through face features to can recognize the faces through live camera </p>

<p>For example:
I have program, and admin has permissions to insert employees pictures(on SQL server) and when employee1 passes in front of the camera, The camera detect the face and take a picture of employee1 face and compare it with another employees and print the employee1 name in label</p>

<p>our problem is how can we compare employee1 face with another employees in database through face features
we are using OpenCV, EmguCV, SQL server and c#</p>
",2015-06-01 23:14:32,2015-06-01 23:14:32,compare with pictures in database through face features SQL serve,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
31846,30579529,2015-06-01 17:25:02,,"<p>I am doing project on face recognition using <a href=""http://www.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow"">emgu cv</a>. My development environment includes visual studio 10 with c#. 
I have found a <a href=""http://www.codeproject.com/Articles/239849/Multiple-face-detection-and-recognition-in-real"" rel=""nofollow"">tutorial</a> which is easy and i can replicate it on my laptop.</p>

<p>This tutorial uses local directory on windows to store images and a text file for store label corresponding to image. </p>

<p>I want to use mysql for image storage/retrieval such that my application can use images to recognize from that database only.</p>

<p>Some pointers will be appreciated!</p>
",2015-06-01 21:57:21,2015-06-01 21:59:27,Store and retrieve Images in MySQL Database,<c#><mysql><image><visual-studio-2010><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
31875,30599502,2015-06-02 14:52:41,,"<p>Below is the code for a method which I am using for detecting faces from Kinect Feed and then setting the pixels from the face into a new image. . It is triggered by a Gesture which is done by <code>GestureFlag</code> . The <code>Detect</code> method which I am calling from the <code>FaceDetection</code> class is taken from the EMGU CV sample. </p>

<pre><code> public string Detect(WriteableBitmap colorBitmap, int GestureFlag)
    {
        if(GestureFlag!=0)
        {
            List&lt;Rectangle&gt; faces = new List&lt;Rectangle&gt;();               
            Bitmap bitface = BitmapFromSource(colorBitmap);
            Image&lt;Bgr, Byte&gt; image = new Image&lt;Bgr, Byte&gt;(bitface);
            FaceDetection.Detect(image, ""haarcascade_frontalface_default.xml"",faces);
             Bitmap img = new Bitmap(@""C:\Users\rama\Downloads\kinect-2-background-removal-master\KinectBackgroundRemoval\Assets\emptyimage.png"");
            img = ResizeImage(img, 1540, 1980);
            int high = image.Height;
            int width = image.Width;                
            for (int i = 0; i &lt; width; i++)
            {
                for (int j = 0; j &lt; high; j++)
                {
                    Bgr pixel = image[j,i];
                    System.Drawing.Point p = new System.Drawing.Point(j,i);                    
                        if (faces[0].Contains(p) &amp;&amp; i&lt;1540 &amp;&amp; j&lt;1980)
                        {
                            img.SetPixel(i, j, System.Drawing.Color.FromArgb(255, (int)pixel.Blue, (int)pixel.Green,(int) pixel.Red));
                        }                   
                }
            }
            count++;
            key = count.ToString() + ""rich.jpg"";
            image.Save(@""C:\Users\rama\Downloads\kinect-2-background-removal-master\KinectBackgroundRemoval\Assets\""+key);
            img.Save(@""C:\Users\rama\Downloads\kinect-2-background-removal-master\KinectBackgroundRemoval\""+key);
            bool status = UploadToS3(""nitish2"", key, @""C:\Users\rama\Downloads\kinect-2-background-removal-master\KinectBackgroundRemoval\""+key);
            var FBClient = new FacebookClient();
            var UploadToFacebook = new FacebookUpload(FBClient, key);
            UploadToFacebook.Show();
            GestureFlag = 0;                      
         }
        return key;
    }
</code></pre>

<p>The problem I'm running into is that an entirely different set of pixels gets printed on the new image which I'm saving. </p>

<p>Basically i think that the problem is here:</p>

<pre><code>FaceDetection.Detect(image, ""haarcascade_frontalface_default.xml"",faces);
for (int i = 0; i &lt; width; i++)
            {
                for (int j = 0; j &lt; high; j++)
                {
                    Bgr pixel = image[j,i];
                    System.Drawing.Point p = new System.Drawing.Point(j,i);
                    if (faces[0].Contains(p) &amp;&amp; i&lt;1540 &amp;&amp; j&lt;1980)
                        {
                            img.SetPixel(i, j, System.Drawing.Color.FromArgb(255, (int)pixel.Blue, (int)pixel.Green,(int) pixel.Red));
                        }

                 }
            }
</code></pre>

<p>So can someone please point out where I'm going wrong?
Thank you very much.</p>

<p>EDITS : I've tried putting flags like <code>faces[0]!=null</code> which should take care of whether <code>FaceDetection.Detect</code> is actually returning anything but still I'm getting the same result. </p>

<p>I've also tried saving the <code>ColorBitmap</code> and testing it against the EMGU CV sample and it detects the faces in the image easily.</p>

<p>EDIT 2: So I've cross checked the co-ordinates of the rectangle which is being printed with the co-ordinates of the face being detected and the values of the <code>Rectangle()</code> being populated. They turn out to be almost same as far as I can see. So no luck there.</p>

<p>I don't know what else I can try for debugging.</p>

<p>If someone could point that out that would be great.</p>

<p>Thanks!</p>
",2015-06-02 16:13:46,2015-06-03 09:26:18,Faces not getting detected from Kinect Feed,<c#><kinect><emgucv><face-detection>,,,CC BY-SA 3.0,False,False,True,False,False
32016,30648657,2015-06-04 15:57:59,,"<p>I mean posts per sentence, not per letter. Such a doctor's prescription handwriting which hard to read. Not just a normal handwriting. </p>

<p>In example :</p>

<blockquote>
  <ol>
  <li><p>I use a data mining or machine learning for doing a training from
  paper handwrited.</p></li>
  <li><p>User scanning a paper with hard to read writing.</p></li>
  <li><p>The application doing an image processing.</p></li>
  <li><p>And the output is some sentence from paper.</p></li>
  </ol>
</blockquote>

<p>And what device to use? (Scanner or webcam)</p>

<p>I am newbie. If could i need some example in vb.net with emguCV/openCV and researches journals.</p>

<p>Any help would be appreciated.</p>
",2015-06-04 16:12:23,2015-06-04 16:54:14,What methods to recognize sentence handwriting?,<vb.net><image-processing><image-recognition><handwriting-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
32036,30651370,2015-06-04 18:24:37,,"<p>I'm trying to write some image detection code for a pick and place machine.  I'm new to OpenCV and have been going through a lot of examples - but still ahve two outstanding questions.  The first one I think I have a solution for but I'm lost on the second.</p>

<p>I'm trying to detect the offset and angle of the bottom of a part. Essentially, how far is the object from the cross (just an indicator of the center of the frame), and what the angle of rotation the part has about the part's center. I've used filters to show the pads of the components.</p>

<p><img src=""https://i.stack.imgur.com/3KM2l.jpg"" alt=""bottom pads of surface mount part""></p>

<p>I'm pretty sure that I want to implement something like this <a href=""http://felix.abecassis.me/2011/10/opencv-bounding-box-skew-angle/"" rel=""nofollow noreferrer"">http://felix.abecassis.me/2011/10/opencv-bounding-box-skew-angle/</a> - but I'm not sure how to translate the code into C# (<a href=""http://www.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow noreferrer"">http://www.emgu.com/wiki/index.php/Main_Page</a>).  Any pointers would be helpful.</p>

<p>One issue is if the part is smaller than the needle that's holding it and you can see both the part and the needle.</p>

<p><img src=""https://i.stack.imgur.com/P4HiD.jpg"" alt=""0402 resistor and needle""></p>

<p>The square bit is the part I want to detect.  The round part is part of the needle that is still exposed.  I've got no clue how to approach this - I'm thinking something along the lines of detecting the straight lines and discarding the curved ones to generate a shape.  Again, I'm interested in the offset from the center and the angle of rotation.</p>
",,2015-06-05 07:57:37,OpenCV/EMGU (C#) detection of objects,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
32055,30680726,2015-06-06 08:37:14,,"<p>I am working on an project where I want to use Kinect camera 2 (SDK v2), with Emgu library (2.4.10.1940).</p>

<p>First I converted the Kinect <code>ColorFrame</code> to <code>BitmapSource</code> and then from <code>BitmapSource</code> to <code>Drawing.Bitmap</code>. When I try to convert from <code>Drawing.Bitmap</code> to <code>Image&lt;Bgr, Byte&gt;</code>, I get an ""A first chance exception of type 'System.ArgumentException' occurred in mscorlib.dll. Additional information: URI formats are not supported"".</p>

<p>Does anyone has an idea, or can someone prompt me of how I can do it with another way?</p>

<p>Below you will find the code I used.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>    public MainWindow()
    {
        InitializeComponent();

        kinectSensor = KinectSensor.GetDefault();

        if (kinectSensor == null)
            return;

        FrameDescription colorFrameDescription = kinectSensor.ColorFrameSource.FrameDescription;

        colorReader = kinectSensor.ColorFrameSource.OpenReader();

        colorPixels = new byte[colorFrameDescription.Width * colorFrameDescription.Height * BytePerPixel];

        colorBitmap = new WriteableBitmap(colorFrameDescription.Width, colorFrameDescription.Height, 96.0, 96.0, PixelFormats.Bgr32, null);
        kinectSensor.Open();

        colorReader.FrameArrived += colorReader_FrameArrived;

        kinectSensor.IsAvailableChanged += kinectSensor_IsAvailableChanged;
        StatusText = kinectSensor.IsAvailable ? ""Running"" : ""Kinect sensor not available"";
    }

        void colorReader_FrameArrived(object sender, ColorFrameArrivedEventArgs e)
        {
            using (ColorFrame colorFrame = e.FrameReference.AcquireFrame())
            {
                if (colorFrame == null)
                    return;

                FrameDescription colorFrameDesc = colorFrame.FrameDescription;
                // Check if the pixelWidth and pixelHeight is right
                if ((colorFrameDesc.Width == colorBitmap.PixelWidth) &amp;&amp; (colorFrameDesc.Height == colorBitmap.PixelHeight))
                {
                    // Check if the image format is right.
                    if (colorFrame.RawColorImageFormat == ColorImageFormat.Bgra)
                        colorFrame.CopyRawFrameDataToArray(this.colorPixels);
                    else
                        colorFrame.CopyConvertedFrameDataToArray(this.colorPixels, ColorImageFormat.Bgra);
                    // Write pixels to BitmapSource format
                    colorBitmap.WritePixels(new Int32Rect(0, 0, colorFrameDesc.Width, colorFrameDesc.Height),
                        colorPixels,
                        colorFrameDesc.Width * BytePerPixel,
                        0);
                    // Convert to Drawing.Bitmap image
                    System.Drawing.Bitmap bmap = BitmapImage2Bitmap(colorBitmap);
                    // Convert to Emgu image (This is where I get my error).
                    Emgu.CV.Image&lt;Bgr, byte&gt; imageFrame = new Image&lt;Bgr,byte&gt;(bmap);
                }
            }
        }

        private System.Drawing.Bitmap BitmapImage2Bitmap(BitmapSource bitmapImage)
        {
            using (MemoryStream outStream = new MemoryStream())
            {
                BitmapEncoder enc = new BmpBitmapEncoder();
                enc.Frames.Add(BitmapFrame.Create(bitmapImage));
                enc.Save(outStream);
                System.Drawing.Bitmap bitmap = new System.Drawing.Bitmap(outStream);

                return new System.Drawing.Bitmap(bitmap);
            }
        }</code></pre>
</div>
</div>
</p>
",2015-06-08 07:03:03,2015-06-11 07:39:00,"""URI formats are not supported"" when converting Bitmap image (Kinect v2) to Emgu Image",<c#><bitmap><kinect><emgucv><bitmapsource>,,,CC BY-SA 3.0,False,False,True,False,False
32074,30744432,2015-06-09 23:13:25,,"<p>I would like to do motion detection in C# (using EmguCV 3.0) to remove object in motion or in foreground to draw an overlay.</p>

<p>Here is a sample test I done with a Kinect (because It's a depth camera)
<img src=""https://i.stack.imgur.com/4MoGX.jpg"" alt=""Démo with Kinect""></p>

<p>How can I get started with EmguCV 3.0 ? </p>

<ul>
<li>I tried many background removal code that do not work</li>
<li>It seems OpticalFlow is a good start but there si no example in EmguCV 3.0</li>
<li>If I find the largest blob how can I find its contours ?</li>
</ul>

<p>Can someone help me to get started ?</p>

<p><strong>EDIT: 17/06/2015</strong></p>

<p>In EmguCV3.0.0 RC I don't see OpticalFlow in the package and documentation:
<a href=""http://www.emgu.com/wiki/files/3.0.0-rc1/document/html/b72c032d-59ae-c36f-5e00-12f8d621dfb8.htm"" rel=""noreferrer"">http://www.emgu.com/wiki/files/3.0.0-rc1/document/html/b72c032d-59ae-c36f-5e00-12f8d621dfb8.htm</a></p>

<p>There is only : DenseOpticalFlow, OpticalFlowDualTVL1 ???</p>

<p>This is a AbsDiff Code:</p>

<pre><code>var grayFrame = frame.Convert&lt;Gray, Byte&gt;();
var motionFrame = grayFrame.AbsDiff(backFrame)
                           .ThresholdBinary(new Gray(20), new Gray(255))
                           .Erode(2) 
                           .Dilate(2);
</code></pre>

<p>Result:
<img src=""https://i.stack.imgur.com/Bgr5N.jpg"" alt=""Demo Diff""></p>

<p>I don't know how to get the motion in white ?</p>

<p>This is the Blob Code:</p>

<pre><code>Image&lt;Bgr, Byte&gt; smoothedFrame = new Image&lt;Bgr, byte&gt;(frame.Size);
CvInvoke.GaussianBlur(frame, smoothedFrame, new Size(3, 3), 1); //filter out noises

Mat forgroundMask = new Mat();
fgDetector.Apply(smoothedFrame, forgroundMask);

CvBlobs blobs = new CvBlobs();
blobDetector.Detect(forgroundMask.ToImage&lt;Gray, byte&gt;(), blobs);
blobs.FilterByArea(400, int.MaxValue);
blobTracker.Update(blobs, 1.0, 0, 1);

foreach (var pair in blobs) {
  CvBlob b = pair.Value;
  CvInvoke.Rectangle(frame, b.BoundingBox, new MCvScalar(255.0, 255.0, 255.0), 2);
}
</code></pre>

<p>Result:
<img src=""https://i.stack.imgur.com/kLHm9.jpg"" alt=""Blob Demo""></p>

<p>Why so much false positive ?</p>

<p>This is a MOG2 Code:</p>

<pre><code>forgroundDetector.Apply(frame, forgroundMask);
motionHistory.Update(forgroundMask);
var motionMask = GetMotionMask();
Image&lt;Bgr, Byte&gt; motionImage = new Image&lt;Bgr, byte&gt;(motionMask.Size);
CvInvoke.InsertChannel(motionMask, motionImage, 0);

Rectangle[] rects;
using (VectorOfRect boundingRect = new VectorOfRect()) {
  motionHistory.GetMotionComponents(segMask, boundingRect);
  rects = boundingRect.ToArray();
}

foreach (Rectangle comp in rects) { ...
</code></pre>

<p>Result:
<img src=""https://i.stack.imgur.com/PQWpo.jpg"" alt=""MOG2 Demo""></p>

<p>If I select the biggest Area how can I get the contour of the object ?</p>
",2015-06-17 14:53:49,2015-06-17 14:53:49,EmguCV: Draw contour on object in Motion using Optical Flow?,<c#><computer-vision><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
32106,30704817,2015-06-08 08:52:15,,"<p>I was running my computer vision project which is implemented in EmguCV(.Net Wrapper to the OpenCV) in Visual Studion 2010 (in C#). It was calculating my features from images for training and save them in a float array. After about one day of running, this error is appeared: </p>

<pre><code>OutOfMemoryException was unhandled
Insufficient memory to continue the execution of the program
</code></pre>

<p>As my Training Set is too big, 
how can I save these features in an array? considering that It was less than half of my program that I got this error and my array will have much more data.</p>

<p>the size of my array is now {float[199897, 88]}, is it normal that I get this error? </p>
",,2015-06-08 08:52:15,Insufficient memory to continue the execution of the program Visual Studio 2010,<.net><visual-studio><opencv><out-of-memory><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
32165,30709706,2015-06-08 12:53:38,,"<p>Can anybody please explain me how to train EmguCV Tesseract Engine to recognize a specific or a little bit ""unusual"" font correctly ( digits only ) ?
I'm using Tesseract on Visual Basic and get frustrating with that problem.</p>
",2015-06-08 13:40:08,2015-06-08 13:40:08,How to train Tesseract for specific font digits only,<vb.net><ocr><tesseract><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
32200,30691204,2015-06-07 07:39:52,,"<p>I want to enlarge a mcvbox2d object to a rectangle object</p>

<p>First what I did was getting a box-shaped contour from a contour object. Then, I extracted all corners of the box. Did sorting of all of the corners. After that, offset 5 pixel from the corners and enlarged width and height to 10 pixel bigger</p>

<pre><code>MCvBox2D box = approxContour.GetMinAreaRect();

PointF[] corners = box.GetVertices();

corners = corners.OrderBy(s =&gt; s.X).ThenBy(s =&gt; s.Y).ToArray();

Rectangle enlargedROI = new Rectangle((int)Math.Round(corners[0].X), (int)Math.Round(corners[0].Y), (int) Math.Round(box.size.Width), (int)Math.Round(box.size.Height));

enlargedROI.X -= 5; 
enlargedROI.Y -= 5;
enlargedROI.Width += 10;    
enlargedROI.Height += 10;                    
</code></pre>

<p>moreover I need to also check, whether the enlarged box must be within the image size. Not fulfilling this condition the box will be removed from this checking.</p>

<p>However, the thing which bothered me was getting negative values of the corners. This made me wondering whether Mcvbox2d (0,0) point starts from the center of the box.</p>

<p>Have anyone got any clue about this? </p>
",2016-02-18 16:38:44,2016-02-18 16:38:44,Enlarge emgucv object mcvbox2d to a rectangle object,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
32201,30692082,2015-06-07 09:41:59,,"<p>I'm using Emgucv to do face recognition, but the Predict method of FaceRecognizer doesn't work. Every time when I ran these codes below, I got no result. Does any one know how to fix it? Thanks in advance. The Emgucv version is Emgu.CV-3.0.0-rc1     </p>

<pre><code>using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Drawing;

using Emgu.CV.UI;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.CV.CvEnum;

namespace ConsoleFaceRecognition
{
class Program
{
    static void Main(string[] args)
    {
        //training variables             
        Image&lt;Bgr, Byte&gt;[] images = new Image&lt;Bgr, Byte&gt;[20];
        int[] labels = new int[20];


        for (int i = 0; i &lt; 10; i++)
        {
            images[i] = new Image&lt;Bgr, Byte&gt;(""D:/visual studio 2013 projects/ConsoleFaceRecognition/ConsoleFaceRecognition/trainingImages/s1/11"" + i.ToString() + "".png"");
            images[i + 10] = new Image&lt;Bgr, Byte&gt;(""D:/visual studio 2013 projects/ConsoleFaceRecognition/ConsoleFaceRecognition/trainingImages/s2/21"" + i.ToString() + "".png"");
            labels[i] = 1;
            labels[i + 10] = 2;
        }

        FaceRecognizer recognizer = new FisherFaceRecognizer(0, 3500);
        recognizer.Train(images, labels);

        Image&lt;Bgr, Byte&gt; testImage = new Image&lt;Bgr, Byte&gt;(""D:/visual studio 2013 projects/ConsoleFaceRecognition/ConsoleFaceRecognition/trainingImages/s2/213.png"");
        FaceRecognizer.PredictionResult result = recognizer.Predict(testImage);


        Console.Write(result.Label);
    }
}
}
</code></pre>
",2015-06-07 10:51:17,2015-06-07 10:51:17,"Use Emgucv to do face recognition, show no predict result",<c#><emgucv><face-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
32233,27443458,2014-12-12 12:13:46,,"<pre><code>       // Fourier transform of Image&lt;Bgr,byte&gt; orig object.
       // output is matrix&lt;float&gt; with 2 channels.

        private Matrix&lt;float&gt; fourier()
    {
        Image&lt;Gray, float&gt; image = orig.Convert&lt;Gray, float&gt;();
        IntPtr complexImage = CvInvoke.cvCreateImage(image.Size,Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_32F, 2);

        CvInvoke.cvSetZero(complexImage);  // Initialize all elements to Zero
        CvInvoke.cvSetImageCOI(complexImage, 1);
        CvInvoke.cvCopy(image, complexImage, IntPtr.Zero);
        CvInvoke.cvSetImageCOI(complexImage, 0);

        Matrix&lt;float&gt; dft = new Matrix&lt;float&gt;(image.Rows, image.Cols, 2);
        CvInvoke.cvDFT(complexImage, dft, Emgu.CV.CvEnum.CV_DXT.CV_DXT_FORWARD, 0);

        //The Real part of the Fourier Transform
        Matrix&lt;float&gt; outReal = new Matrix&lt;float&gt;(image.Size);
        //The imaginary part of the Fourier Transform
        Matrix&lt;float&gt; outIm = new Matrix&lt;float&gt;(image.Size);
        CvInvoke.cvSplit(dft, outReal, outIm, IntPtr.Zero, IntPtr.Zero);
        return dft;
    }

    // butterworth filter with Do frequency and order n.
    // Filter is returned as matrix&lt;float&gt; with 2 channels. 

    private Matrix&lt;float&gt; make_butterworth(int Do, int n)
    {
        Matrix&lt;float&gt; ff = fourier();
        Matrix&lt;float&gt; tmp = new Matrix&lt;float&gt;(ff.Rows, ff.Cols, 2);

        Point center=new Point(tmp.Rows/2,tmp.Cols/2);

        for (int i=0;i&lt;orig.Rows;i++)
            for (int j = 0; j &lt; orig.Cols; j++)
            {
                  int Duv= (int) (Math.Sqrt( Math.Pow(i-center.X,2) + Math.Pow(j-center.Y,2)));
                  tmp[i, j] = (float) (1 / (1 + Math.Pow((Duv / Do), 2 * n)));
            }

        return tmp;
    }


    // The click event which will trigger fourier() and
       make_butterworth() takes Do and n order input from user
       and applies filter on orig image.

    private void lowPassToolStripMenuItem2_Click(object sender, EventArgs e)
    {
        dialog_input d1 = new dialog_input(""Enter values of Do and order n seperated by space:\n"");
        d1.ShowDialog();
        string[] s = d1.t.Split(new char[] { ' ', ',' });
        int fc = Convert.ToInt32(s[0]);
        int order = Convert.ToInt32(s[1]);

        Matrix&lt;float&gt; filter= make_butterworth(fc, order); // 2 channels
        Matrix&lt;float&gt; m = fourier(); // 2 channels
        m._Mul(filter);
        // filter * with fourier image.
        CvInvoke.cvDFT(m,m,CV_DXT.CV_DXT_INVERSE, 0);

        IntPtr cmplx = CvInvoke.cvCreateImage(m.Size, IPL_DEPTH.IPL_DEPTH_32F, 2);
        CvInvoke.cvSetZero(cmplx);
        CvInvoke.cvSetImageCOI(cmplx, 0);
        CvInvoke.cvCopy(m, cmplx, IntPtr.Zero);

        Bitmap bm = new Bitmap(m.Width, m.Height);

        BitmapData bd = bm.LockBits(new Rectangle
            (0, 0, bm.Width, bm.Height),
            ImageLockMode.ReadWrite,
            PixelFormat.Canonical);

        bd.Scan0 = cmplx;

        bm.UnlockBits(bd);
        pictureBox2.Image = bm;
      }
</code></pre>

<p>One thing i am taking fourier() as 2 channels instead of only taking real channel. i am not sure if i am wrong in this regard. Also thats why i had to take filter as 2 channels also where 2 channels are used to represent data of Gray and Alpha in both cases.</p>

<p>Problem occurs at bitmapdata object initialization due to pixelFormat.Canonical parameter. The result of multiply of fourier matrix and filter matrix is in matrix float. All i want to do is to take its IDFT and display the filtered image. Not sure about the PixelFormat. Any help would be great.</p>
",2014-12-13 09:34:53,2014-12-14 15:16:56,Filtering on Fourier image and then taking its Inverse fourier to get the image,<image-processing><filtering><emgucv><frequency-domain>,,,CC BY-SA 3.0,False,False,True,False,False
32287,26330322,2014-10-12 21:44:36,,"<p>I have a question about speeding up a couple of emguCV calls. Currently I have a capture card that takes in a camera at 1920x1080@30Hz. Using directshow with a sample grabber I capture each frame and display it on a form. Now I have written an image stabilizer but the fastest I can run it is about 20Hz.</p>

<p>The first thing I do in my stabilizer is scale the 1920x1080 down to 640x480 beacuse it makes the feature track much faster.</p>

<p>Then I use goodFeaturesToTrack</p>

<pre><code>previousFrameGray.GoodFeaturesToTrack(sampleSize, sampleQuality, minimumDistance, blockSize)[0]);
</code></pre>

<p>which takes about 12-15ms.</p>

<p>The next thing I do is an optical flow calculation using this</p>

<pre><code>OpticalFlow.PyrLK(previousFrameGray, frame_gray, prev_corner.ToArray(), new Size(15, 15), 5, new MCvTermCriteria(5), out temp, out status, out err);
</code></pre>

<p>and that takes about 15-18ms.</p>

<p>The last time consuming method I call is the warpAffine function</p>

<pre><code> Image&lt;Bgr, byte&gt; warped_frame = frame.WarpAffine(T, interpMethod, Emgu.CV.CvEnum.WARP.CV_WARP_DEFAULT, new Bgr(BackgroundColor));
</code></pre>

<p>this takes about 10-12ms.</p>

<p>The rest of the calculations, image scaling and what not take a total of around 7-8ms.</p>

<p>So the total time for a frame calculation is about 48ms or about 21Hz.</p>

<p>Somehow I need to get the total time under 33ms.
So now for my questions.</p>

<p><strong>First:</strong> If I switch to using the GPU for goodFeatures and opticalFlow will that provide the nessesary increase in speed if any?</p>

<p><strong>Second:</strong> Are there any other methods besides using the GPU that could speed up these calculations?</p>
",,2014-10-16 18:45:02,Speeding up emguCV methods,<c#><opencv><gpu><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
32310,27447673,2014-12-12 16:15:03,,"<p>I have many b/w images with black little objects.
I use FindContour using c# with EmguCV V2.4.10 to detect each blob, so far so good, but how can i group blobs of nearest distance to each other.</p>

<p>I heard about Watershed segmentation but i don't know how to accomplish this task.
I would appreciate any solution approaches...</p>

<p>Result Sample of grouped Blobs:</p>

<pre><code>|* * *    |          |   ** **** ** |
| *  *  * |          |****          |
| *     * |          |*   *** ***   |
| *  *  * |          |****        **|



      |*** ** *|
      |** *** *|
      |** ** **|
</code></pre>
",2015-01-10 04:27:50,2015-01-10 04:27:50,How to group nearest blobs using EmguCV,<c#><opencv><computer-vision><emgucv><imaging>,,,CC BY-SA 3.0,True,False,True,False,False
32318,30867391,2015-06-16 12:18:46,,"<p>I'm trying to get the template's position on the image using <a href=""https://github.com/shimat/opencvsharp"" rel=""nofollow"">OpenCVSharp</a> library from <a href=""https://www.nuget.org/packages/OpenCvSharp-AnyCPU/"" rel=""nofollow"">NuGet</a>. Here is the code I've wrote:</p>

<pre><code>var image = Cv.LoadImage(""Image.png"");
var template = Cv.LoadImage(""Template.png"");
var w = (image.Width - template.Width) + 1;
var h = (image.Height - template.Height) + 1;
IplImage result = new IplImage(w, h, BitDepth.F32, 1);

Console.WriteLine(""Image: {0} {1}"", image.GetSize(), image.ElemType);
Console.WriteLine(""Template: {0} {1}"", template.GetSize(), template.ElemType);
Console.WriteLine(""Result: {0} {1}"", result.GetSize(), result.ElemType);

image.MatchTemplate(image, result, MatchTemplateMethod.CCoeffNormed); // throws exception

double minVal, maxVal;
CvPoint minLoc, maxLoc;
result.MinMaxLoc(out minVal, out maxVal, out minLoc, out maxLoc);
Console.WriteLine(maxLoc);
</code></pre>

<p>Output:</p>

<pre><code>Image: CvSize (Width:2048 Height:1536) U8C3
Template: CvSize (Width:169 Height:128) U8C3
Result: CvSize (Width:1880 Height:1409) F32C1
</code></pre>

<p>Exception:</p>

<blockquote>
  <p>OpenCvSharp.OpenCVException : result.size() == cv::Size(std::abs(img.cols - templ.cols) + 1, std::abs(img.rows - templ.rows) + 1) &amp;&amp; result.type() == CV_32F</p>
</blockquote>

<p>What's wrong? Where is the error? The size, bit depth and channel number of the result array look correct, but the method still rises the exception.</p>
",,2016-09-21 09:42:02,How to call OpenCV's MatchTemplate method from C#,<c#><opencv><image-processing><emgucv><opencvsharp>,,,CC BY-SA 3.0,True,False,True,False,False
32403,30833096,2015-06-14 18:35:53,,"<p>i just downloaded emgucv library and installed it,followed a tutorial on youtube -added the right dll's refrences to my project but im getting an error when intializing an <code>emgucv image</code></p>

<pre><code>Image&lt;Bgr,Byte&gt; img=new Image&lt;Bgr,Byte&gt;(@""C:\Users\pro\Desktop\Itamar\LolTools\Autologin\Resources\Logo.png"");
</code></pre>

<p>the most common exception in that library:<code>The type initializer for 'Emgu.CV.CvInvoke' threw an exception</code></p>

<p>i've searched for many solution over the net,to copy the dll files to 64x directory in my project,add the dlls and set <code>always copy</code> still nothing works.
im probably breaking my head about this so i would be realy happy if someone could help.</p>
",,2018-10-03 09:37:19,Emgu cv invoke exception c#,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
32423,27458995,2014-12-13 12:52:49,,"<p>Also i want to ask when we convert any image to grayscale does it have two channels(gray and alpha) or one (gray only)?</p>

<p>I want to store image data from 2 channeled matrix(float) object to Image(gray,float) object. what is the easiest way? Thanks.</p>
",,2014-12-13 12:52:49,"How can i store image data from matrix<float> to Image<gray,float> object?",<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
32467,30881211,2015-06-17 02:11:38,,"<p>I am using the Emgu CV when I come across this code:</p>

<pre><code>Image&lt;Bgr, byte&gt; image = new Image&lt;Bgr, byte&gt;(""test.jpg"");
Image&lt;Bgr, byte&gt; image2 = new Image&lt;Bgr, byte&gt;(""test2.jpg"");
CvInvoke.cvSmooth(image, image2, SMOOTH_TYPE.CV_GAUSSIAN, 5, 5, 9, 9);
</code></pre>

<p>According to the definition of <code>cvSmooth()</code>, the first 2 parameters are <code>IntPtr</code>. </p>

<p>My question is that why is it valid to pass in a type of <code>Image&lt;Bgr, byte&gt;</code> into this? </p>
",,2015-06-17 03:01:25,Passing a class as IntPtr,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
32526,30900322,2015-06-17 19:09:14,,"<p>I am trying to get images from different cameras using capture class.
I have three ports in the laptop but i have to use four cameras or may be more . I am using a usb hub and connecting the camera with it but it isn't working.</p>

<pre><code>Capture capture1 = new Capture(0);
    Capture capture2 = new Capture(1);
    Capture capture3 = new Capture(2);
    Capture capture4 = new Capture(3);
</code></pre>

<p>But it is giving an exception of Couldnot capture from camera 3 ! 
Please help.</p>
",,2015-06-17 19:09:14,How to capture image from four cameras when you have only three usb ports in the laptop using C# and Emgucv?,<c#><image><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
32549,30988892,2015-06-22 20:07:11,,"<p>I am doing my project about hand gesture recognition so, I want to capture video stream using web cam. </p>

<p>Currently I am using emgu cv wrapper for open cv image processing library. </p>

<p>any solution to capture video stream in to image? </p>

<p>My emgu cv version is 2.4.10</p>

<p>Thanks...</p>
",2015-06-23 06:19:38,2015-06-23 06:19:38,How to capture video stream using emgu cv,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
32557,30932955,2015-06-19 07:58:35,,"<p>I have a self-defined struct of a point (as opposed to <code>System.Drawing.Point</code>):</p>

<pre><code>struct PointD
{
    public double X,Y;
}
</code></pre>

<p>I want to get a <code>Seq</code> of points, and from there extract the minimum area rectangle:</p>

<pre><code>using (MemStorage stor = new MemStorage())
{
    Seq&lt;PointD&gt; seq = new Seq&lt;PointD&gt;(CvInvoke.CV_MAKETYPE(6, 2), stor);
    seq.Push(new PointD(0.5, 0));
    seq.Push(new PointD(1.0, 0));
    seq.Push(new PointD(0, 1.0));
    seq.Push(new PointD(1.0, 1.0));
    var output = seq.GetMinAreaRect();
}
</code></pre>

<p>However, this code throws an exception at <code>GetMinAreaRect()</code>, saying that the input sequence must be 2d points. My question is there a way to get my data format through correctly? I was thinking that I just lack a bit of something, as this code can work for a <code>System.Drawing.Point</code>.</p>
",,2015-06-19 08:14:54,Using Seq in emgu c#,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
32698,30944998,2015-06-19 18:30:56,,"<p>Given the following image, How can I detect black bullets (90 bullet) in this image using C#, EmguCV or AForge?</p>

<p><img src=""https://i.stack.imgur.com/sbro6.png"" alt=""enter image description here""></p>

<p>I tried to use <code>GetPixel(x,y)</code> method but it checks only pixel by pixel, it is very slow and I need to detect the bullets not pixels.</p>
",2015-06-23 03:01:17,2015-06-23 03:01:17,How to detect black Bullets in Image?,<c#><c#-4.0><image-processing><emgucv><aforge>,,,CC BY-SA 3.0,False,False,True,False,False
32711,30983057,2015-06-22 14:50:00,,"<p>Reading EmgCV docs cant quite understand: what detectors can be used with which DescriptorExtractors?</p>

<p><a href=""http://www.emgu.com/wiki/index.php/FAST_feature_detector_in_CSharp"">Here</a> it is said:</p>

<pre><code>You can use it with the FREAK descriptor that is scale invariant. Just replace the BriefDescriptorExtractor with Freak and it should do the trick.
</code></pre>

<p>does it mean that not all detectors are compatable to DescriptorExtractors? If yes where one can find comparisons and documentation on topic?</p>
",,2015-07-01 01:52:58,How do EmguCV detectors relate to EmguCV DescriptorExtractors?,<c#><.net><opencv><emgucv><feature-detection>,,,CC BY-SA 3.0,True,False,True,False,False
32763,31008457,2015-06-23 16:32:55,,"<p>I need to calculate the covariance matrix from an input image.
I'm using Emgu cv with visual basic.
The problem is the covariance matrix output only have 0 values. </p>

<pre><code>Dim str As String =""C:\Users\PC\ahhh.png""
Dim original As Image(Of Bgr, Byte) = New Emgu.CV.Image(Of Bgr, Byte)(str)

Dim thresholdoriginal As Image(Of Gray, Byte)
thresholdoriginal = original.Convert(Of Gray, Byte)().ThresholdBinary(New Gray(5), New Gray(255))


Dim covar_Exp As System.IntPtr
Dim matrizOUT As Matrix(Of Single)
matrizOUT = New Matrix(Of Single)(thresholdoriginal.Rows, thresholdoriginal.Cols)
covar_Exp = matrizOUT

Dim avg_Exp As System.IntPtr
Dim p_avg As Matrix(Of Single) = New Matrix(Of Single)(1, thresholdoriginal.Cols)
avg_Exp = p_avg

Dim inputPtr_Sample() As System.IntPtr = {}
inputPtr_Sample.Initialize()
ReDim inputPtr_Sample(0)
inputPtr_Sample(0) = thresholdoriginal

cvCalcCovarMatrix(inputPtr_Sample, 1, covar_Exp, avg_Exp, COVAR_METHOD.CV_COVAR_NORMAL Or COVAR_METHOD.CV_COVAR_ROWS)
</code></pre>

<p>How can i solve this problem??
thanks in advance!!</p>
",,2015-06-23 16:32:55,Emgu vb.net cvCalcCovarMatrix - covariance matrix empty,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
32779,31025284,2015-06-24 11:26:43,,"<p>I want to extract the squares from a chessboard and label each one of them according to their coordinates i.e. a1, a2, ... h8. My goal is to create a 'mask' to check the presence of a piece for each square. I am currently writing a program to do this in C# using Emgu CV.</p>

<p>The image used for testing can be found <a href=""http://www.sjgames.com/proteus/img/chessboard.jpg"" rel=""nofollow noreferrer"">here</a>.</p>

<p><img src=""https://i.stack.imgur.com/IDssw.jpg"" alt=""enter image description here""></p>

<p>With no experience in computer vision, I have only been following simple code examples guided by basic ideas. My first lead was this <a href=""http://www.emgu.com/wiki/index.php/Shape_(Triangle,_Rectangle,_Circle,_Line)_Detection_in_CSharp"" rel=""nofollow noreferrer"">tutorial</a> which tells me how to make a simple shape detector. It was not very accurate though as the test image is more complex than the example image.</p>

<p><em>Inaccurate square detection (with a slightly different image)</em></p>

<p><img src=""https://i.stack.imgur.com/Zim7Z.jpg"" alt=""Example"">  </p>

<p>There were two problems with the results: 1) not all of the squares were detected as squares; 2) 91 boxes (instead of 64) were created to visualise the detected squares.</p>

<p>To solve problem #1, I used a binary threshold with dilation and median smoothing to further 'simplify' the image and the results were much better but not complete (due to noise):</p>

<p><em>After applying a binary threshold, dilating, median smoothing and eroding</em></p>

<p><img src=""https://i.stack.imgur.com/2mOZN.jpg"" alt=""binary threshold""></p>

<p><em>Visualizing and counting the squares</em></p>

<p><img src=""https://i.stack.imgur.com/0HVS2.jpg"" alt=""enter image description here""></p>

<p>It appears that the same square(s) is detected multiple times (i.e. problem #2) for reasons unknown to me and I have no idea how to fix this. My initial idea was to give each square a label as soon as they were detected but it doesn't seem practical now.</p>

<h2>Questions</h2>

<ol>
<li>What method(s) can I use to remove the post-filter noise on squares b3 and g6?  </li>
<li>What method(s) can I use to properly count and sort the squares in row-by-row order?</li>
<li>Assuming that I manage to label each square, how do I then 'save' the region of the square to be reused as a mask for newer frames? Is it computationally expensive to have 64 unique masks?</li>
<li>How can I maximize the detection rate of squares?</li>
</ol>
",,2015-06-27 18:29:56,Creating a chessboard mask to check the status of the squares on a chessboard,<opencv><image-processing><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
32791,31041266,2015-06-25 04:33:56,,"<p>I'm really stumped on this one, any assistance would be greatly appreciated.  I'm attempting to translate the following:</p>

<p><a href=""https://github.com/MicrocontrollersAndMore/OpenCV_KNN_Character_Recognition_Machine_Learning/blob/master/generate_data.cpp"" rel=""nofollow"">https://github.com/MicrocontrollersAndMore/OpenCV_KNN_Character_Recognition_Machine_Learning/blob/master/generate_data.cpp</a></p>

<p>which is written in C++ OpenCV, to Emgu CV, preferably using VB, but C# would be fine as well.  I'm using Emgu CV 2.4.10 currently (holding off on moving to >= 3.X until Emgu 3.X is passed release candidate stage).</p>

<p>Where I'm having trouble is towards the end, where the training images have to be added to a OpenCV Matrix before this Matrix is passed into the KNN call to train.  Here is what I have so far in the button click event to open the file with the training numbers:</p>

<pre><code>Dim imgTrainingNumbers As Image(Of Bgr, Byte)
imgTrainingNumbers = New Image(Of Bgr, Byte)(ofdOpenFile.FileName)             'open image
'some error checking for verifying the image opened omitted here, its in the actual program


Dim imgGrayscale As Image(Of Gray, Byte)
Dim imgBlurred As Image(Of Gray, Byte)
Dim imgThresh As Image(Of Gray, Byte) = Nothing
Dim imgThreshCopy As Image(Of Gray, Byte)
Dim imgContours As Image(Of Gray, Byte)

Dim contours As Contour(Of Point)

Dim mtxClassificationInts As Matrix(Of Single) = New Matrix(Of Single)(NUMBER_OF_TRAINING_SAMPLES, 1)
Dim mtxTrainingImages As Matrix(Of Single) = New Matrix(Of Single)(RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT * NUMBER_OF_TRAINING_SAMPLES, 1)

Dim intValidChars As New List(Of Integer)(New Integer() { 48, 49, 50, 51, 52, 53, 54, 55, 56, 57 })

imgGrayscale = imgTrainingNumbers.Convert(Of Gray, Byte)()             'convert to grayscale
imgBlurred = imgGrayscale.SmoothGaussian(5)

CvInvoke.cvShowImage(""imgBlurred"", imgBlurred)

imgThresh = imgBlurred.ThresholdAdaptive(New Gray(255), ADAPTIVE_THRESHOLD_TYPE.CV_ADAPTIVE_THRESH_GAUSSIAN_C, THRESH.CV_THRESH_BINARY_INV, 11, New Gray(2))

imgThreshCopy = imgThresh.Clone()

contours = imgThreshCopy.FindContours(CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, RETR_TYPE.CV_RETR_EXTERNAL)

imgContours = New Image(Of Gray, Byte)(imgThresh.Size())

CvInvoke.cvDrawContours(imgContours, contours, New MCvScalar(255), New MCvScalar(255), 100, 1, LINE_TYPE.CV_AA, New Point(0, 0))

CvInvoke.cvShowImage(""imgThresh"", imgThresh)
CvInvoke.cvShowImage(""imgContours"", imgContours)

While(Not contours Is Nothing)
    If (contours.Area &gt; MIN_CONTOUR_AREA) Then
        Dim rect As Rectangle = contours.BoundingRectangle()            'get the bounding rect
        imgTrainingNumbers.Draw(rect, New Bgr(Color.Red), 2)            'draw red rect around the current char
        Dim imgROI As Image(Of Gray, Byte) = imgThresh.Copy(rect)

        Dim imgROIResized As Image(Of Gray, Byte) = imgROI.Resize(RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT, INTER.CV_INTER_LINEAR)


        CvInvoke.cvShowImage(""imgROI"", imgROI)
        CvInvoke.cvShowImage(""imgROIResized"", imgROIResized)
        CvInvoke.cvShowImage(""imgTrainingNumbers"", imgTrainingNumbers)

        Dim intChar As Integer = CvInvoke.cvWaitKey(0)

        If (intChar = 27) Then
            'add code to exit program here if Esc is pressed
        ElseIf (intValidChars.Contains(intChar)) Then
            mtxClassificationInts.Add(intChar)      'append classification char to matrix of integers (we will convert later before writing to file)

            'now add the training image (some conversion is necessary first) . . .

            Dim mtxTemp As Matrix(Of Single) = New Matrix(Of Single)(imgROIResized.Size())
            Dim mtxTempReshaped As Matrix(Of Single) = New Matrix(Of Single)(imgROIResized.Size())

            CvInvoke.cvConvert(imgROIResized, mtxTemp)

            mtxTempReshaped = mtxTemp.Reshape(1, 1)

            Try
                mtxTrainingImages.Add(mtxTempReshaped)
            Catch ex As Exception
                txtInfo.Text = txtInfo.Text + ex.Message + vbCrLf
            End Try

        End If

    End If
    contours = contours.HNext
End While

Me.Text = ""training complete !!""

'write mtxClassificationInts to file here
'write mtxTrainingImages to file here

'separate write and read into two separate programs when all this is working

'read mtxClassificationInts to file
'read mtxTrainingImages to file    

Dim kNearest As KNearest = New KNearest()                   'instantiate KNN object

kNearest.Train(mtxTrainingImages, mtxClassificationInts, Nothing, False, 1,False)       'call to train

'rest of program here when training is successful
</code></pre>

<p>In the Try . . . Catch block, on the line:</p>

<pre><code>mtxTrainingImages.Add(mtxTempReshaped)
</code></pre>

<p>I'm getting the following error:</p>

<pre><code>OpenCV: The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array'
</code></pre>

<p>I've tried about every type of format change I can find but can't seem to get past an error on this line.</p>

<p>I should probably mention a few other things:</p>

<p>-The KNN call to train only accepts Matrix of type Single (float if using #C, same thing), so it has to be in this format</p>

<p>-I got the example:</p>

<p><a href=""http://www.emgu.com/wiki/index.php/K_Nearest_Neighbors_in_CSharp"" rel=""nofollow"">http://www.emgu.com/wiki/index.php/K_Nearest_Neighbors_in_CSharp</a></p>

<p>to work in both C# and VB, but I'm not sure how to apply this to using actual images rather than made up random numbers</p>

<p>-Yes, I'm aware Emgu has Tesseract built in for character recognition, but I plan on moving onto other machine learning in Emgu and would like to get this working first as a relatively easy example</p>

<p>Any help would be great.</p>
",,2015-08-10 13:29:37,"Emgu CV, unable to add Image to Matrix for KNN training",<vb.net><opencv><matrix><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
32798,31025497,2015-06-24 11:36:06,,"<p>I have an image like this:</p>

<p><img src=""https://i.stack.imgur.com/wEeJm.png"" alt=""Original Image""></p>

<p>Next i use some techniques to get the contours of the sudoku grid. for demonstration, here's a picture: (green=boundingbox, red=contour)</p>

<p><img src=""https://i.stack.imgur.com/yp1v1.png"" alt=""enter image description here""></p>

<p>Now my question; How can i warp this to a perfect square? I have tried to use cvWarpPerspective but i can't seem to figure out how to get the corners from the contours(red line).</p>

<p>Any help would be greatly appreciated!</p>
",,2015-06-24 13:08:22,Find corners from contour and warp perspective,<c#><opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
32800,31027117,2015-06-24 12:51:50,,"<p>hello I am working on person recognition, I would like to get the score for each tested sample (image) from a multi-class SVM classification. I am using c# and EmguCv.
Any help will be appreciated.</p>
",2015-06-24 19:54:41,2015-08-24 13:56:38,get the score from a multi-class SVM classifier using emgu cv and c#,<c#><svm><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
32820,31118128,2015-06-29 14:21:07,,"<p>I am trying to compare two images, where image 2 has little diffrence than image 1
but i am not getting result as =both images are same</p>

<pre><code>    private void button1_Click(object sender, EventArgs e)
    {
        Bitmap img = new Bitmap(200, 120);
        Rectangle rect = new Rectangle();
        Image&lt;Gray, Byte&gt; templateImage = new Image&lt;Gray, Byte&gt;(@""D:\IMG1\TestCase1-256.bmp"");
        Image&lt;Gray, Byte&gt; sourceImage = new Image&lt;Gray, Byte&gt;(@""D:\IMG1\TestCase1-256.bmp"");
        Image&lt;Bgr, Byte&gt; ImageSource = new Image&lt;Bgr, Byte&gt;(100,100);
        int x1, y1, hei, wid;
        Image&lt;Gray, float&gt; imgMatch = sourceImage.MatchTemplate(templateImage, Emgu.CV.CvEnum.TM_TYPE.CV_TM_CCOEFF_NORMED);
        float[, ,] matches = imgMatch.Data;
        for (int y = 0; y &lt; matches.GetLength(0); y++)
        {
            for (int x = 0; x &lt; matches.GetLength(1); x++)
            {
                double matchScore = matches[y, x, 0];
                //0.75
                if (matchScore &gt; 0.99)
                {
                    rect = new Rectangle(new Point(x - templateImage.Width, y - templateImage.Height), new Size(1, 1));
                    ImageSource.Draw(rect, new Bgr(Color.Blue), 1);

                }

            }

        }
        pictureBox1.Image = ImageSource.Bitmap;
    }
</code></pre>

<p>Image-1 and Image-2 varies in slight font variation. am i following the right approach or any pointer will be helpful.</p>
",,2015-06-29 14:21:07,emgu cv near image matching (c#) result not correct,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
32829,27496058,2014-12-16 01:23:58,,"<p>I am building an application which compares the timescale of computing sets of 1,000, 10,000 and 100,000 frames from a webcam using CPU and GPU approaches.</p>

<p>So far I have written the CPU implementation but I now need to integrate my GPU algorithm into my project.  </p>

<p>I chose Emgu after doing research and finding it allows support for Open-CV and CUDA with C#. However I am now facing the problem that VS2012 is not noticing my <code>__global__</code> calls in my program.</p>

<p>Below are the namespaces I am using:</p>

<pre><code>using Emgu.CV;
using Emgu.Util;
using Emgu.CV.Structure;
using Emgu.CV.GPU;

using DirectShowLib;
</code></pre>

<p>And I have successfully linked to what I think are all of the applicable libraries to get CUDA working with Emgu:</p>

<p><img src=""https://i.stack.imgur.com/47Cmx.png"" alt=""enter image description here""></p>

<p>With this in mind, what is it that I am doing wrong?</p>
",2014-12-16 01:55:56,2014-12-16 10:58:10,Emgu: Setting up CUDA with C#,<c#><opencv><cuda><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
32920,27502670,2014-12-16 10:39:36,,"<p>I'm new on c# i want to translate this code from c++ to c#. The program consist on  determinig if the image is white or not that's why i try to get the value of all the pixel and comparing it with the 0.</p>

<pre><code>     int image_blanche(char * str, double prctage){
   Mat img=imread(str);
   int compt=0;
   for(int i=0;i&lt;img.rows;i++){
        for(int j=0;j&lt;img.cols;j++){
            if (img.at&lt;uchar&gt;(i,j)==0){
            compt=compt+1;
           }
       }
    }

    if (compt&lt; img.rows*img.cols*prctage)
    {   
        return 1;
    }
   else if (compt&gt; img.rows*img.cols*prctage){
        return 0;
   }
}
</code></pre>

<p>i proced like this but it still don't working </p>

<pre><code>      int Image_blanche(String str,int prctge)
    {
        Image&lt;Bgr, Byte&gt; img = new Image&lt;Bgr, Byte&gt;(str);
        int compt = 0;
        int i;
        int j;
        for (  i = 0; i &lt; img.Width; i++)
        {
            for ( j = 0; j &lt; img.Height; j++)
            {
                Bgr color = img[i, j];
                if ((Math.Abs(color.Green - 0) &lt; 0) &amp;&amp;(Math.Abs(color.Blue - 0) &lt; 0)&amp;&amp;(Math.Abs(color.Red - 0) &lt; 0))
                {
                    compt = compt + 1;
                }
            }
        }

        return compt &lt;= img.Width*img.Height*prctge ? 1 : 0;
    }
</code></pre>

<p>Any help please.</p>
",,2014-12-16 11:05:29,moving from c++ opencv to c# emgu cv?,<c#><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
32954,31109243,2015-06-29 06:38:25,,"<p>i am trying to do some image processing with <strong>Emgu CV</strong>.</p>

<p>I have raw pixel data of a gray image in an <strong>byte[]</strong>. I know the size of the image and the type.</p>

<p>I first create an image width the known size an type and then i want to load the date to the image (I have often done this in <strong>C++ OpenCV</strong>).</p>

<pre><code>Image&lt;Gray, Byte&gt; image = new Image&lt;Gray, byte&gt;(width, height);   
image.Bytes = data;
</code></pre>

<p>But the image is always kind of ""cut through and puzzled together"". It works with an image which <strong>width%4 = 0</strong>. That is why i assume it is some kind of ""<strong>memory alignment</strong>"" issue.</p>

<p>Has someone of you run into this problem and knows how to fix it?</p>

<p>Thanks,
Sebastian</p>
",2015-06-29 07:26:38,2015-07-02 05:59:39,Emgu CV Image width not multiple of 4,<image><opencv><image-processing><alignment><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
32991,31149249,2015-06-30 21:57:51,,"<p>i'd want to add mask on my recognised face during live video capturing with EMGU CV, C#, WPF, I've already done live video capturing and had a PNG mask, 
how to impose PNG image to my video?
faces are recognised and imposed by small non-filled rectangles, so I can easily get coordinates of faces center</p>
",,2015-07-01 17:27:57,How to mask on emgu cv C#,<c#><wpf><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
32992,31178283,2015-07-02 07:35:35,,"<p>I have made an application where I apply HSV filters to an image and then try to track a specific color. I want to use UMat because I need the computation of the image to be in the GPU and not in the CPU instead.</p>

<p>In the code below first I take an <code>Image&lt;Bgra, Byte&gt;</code> and then convert to <code>UMat</code> format with HSV color format. However, when I split the channels I get 3 channels for each channel (ex. the the hsvChannels[0] has three channels; I don't know why this is happening). Finally I can't apply the filters because when I use the <code>inRangeImage</code> method I get an image with one channel and error form <code>CvInvoke.Copy</code> ""Unknown array format"".</p>

<p>The application is not the best, but I want first to understand how UMat image format works and then try to improve it.</p>

<pre><code>        private UMat CvAndHsvImage(Image&lt;Bgra, Byte&gt; imgFrame, byte lowerHue, byte upperHue, byte lowerSat, byte upperSat, byte lowerBright, byte upperBright,
        byte erosion = 0, byte dilate = 0, bool hue = false, bool sat = false, bool bright = false, bool invert = false)
    {
        // First convert the input image to hsv so we can change the channels
        //Image&lt;Hsv, Byte&gt; hsvImage = imgFrame.Convert&lt;Hsv, Byte&gt;();
        UMat hsvImage = new UMat();
        UMat bgrImage = new UMat();
        CvInvoke.CvtColor(imgFrame, bgrImage, ColorConversion.Bgra2Bgr);
        CvInvoke.CvtColor(bgrImage, hsvImage, ColorConversion.Bgr2Hsv);

        // Final image that will be returned.
        UMat ResultImage = new UMat();
        UMat ResultImageH = new UMat();
        UMat ResultImageS = new UMat();
        UMat ResultImageV = new UMat();

        UMat[] hsvChannels = new UMat[3];
        hsvChannels = hsvImage.Split();

        UMat img1 = inRangeImage(hsvChannels[0], lowerHue, upperHue);
        UMat img2 = inRangeImage(hsvChannels[1], lowerSat, upperSat);
        UMat img3 = inRangeImage(hsvChannels[2], lowerBright, upperBright);


        #region checkBox Color Mode
        // Evaluation of the check box for each filter. Return the right image
        if (hue)
        {
            CvInvoke.cvCopy(img1, ResultImageH, IntPtr.Zero);
        }
        if (sat)
            //ResultImageS = img2;
            CvInvoke.cvCopy(img2, ResultImageS, IntPtr.Zero);
        if (bright)
            //ResultImageV = img3;
            CvInvoke.cvCopy(img3, ResultImageS, IntPtr.Zero);

        if (hue &amp;&amp; !sat &amp;&amp; !bright)
            ResultImage = ResultImageH;
        if (!hue &amp;&amp; sat &amp;&amp; !bright)
            ResultImage = ResultImageS;
        if (!hue &amp;&amp; !sat &amp;&amp; bright)
            ResultImage = ResultImageV;

        if (hue &amp;&amp; sat &amp;&amp; !bright)
        {
            CvInvoke.BitwiseAnd(ResultImageH, ResultImageS, ResultImageH);
            ResultImage = ResultImageH;
        }

        if (hue &amp;&amp; !sat &amp;&amp; bright)
        {
            CvInvoke.BitwiseAnd(ResultImageH, ResultImageV, ResultImageH);
            ResultImage = ResultImageH;
        }

        if (!hue &amp;&amp; sat &amp;&amp; bright)
        {
            CvInvoke.BitwiseAnd(ResultImageS, ResultImageV, ResultImageS);
            ResultImage = ResultImageS;
        }

        if (hue &amp;&amp; sat &amp;&amp; bright)
        {
            CvInvoke.BitwiseAnd(ResultImageH, ResultImageS, ResultImageH);
            CvInvoke.BitwiseAnd(ResultImageH, ResultImageV, ResultImageH);
            ResultImage = ResultImageH;
        }
        #endregion

        UMat grayImage = new UMat();

        CvInvoke.CvtColor(ResultImage, bgrImage, ColorConversion.Hsv2Bgr);
        CvInvoke.CvtColor(bgrImage, grayImage, ColorConversion.Bgr2Gray);

        hsvImage.Dispose();
        bgrImage.Dispose();

        return grayImage;

    }

    /// &lt;summary&gt;
    /// Method to define the upper and lower values of the channels of HSV image
    /// &lt;/summary&gt;
    /// &lt;param name=""hsvImage""&gt;Image in HSV and Byte format&lt;/param&gt;
    /// &lt;param name=""lower""&gt;Lower value to be applied&lt;/param&gt;
    /// &lt;param name=""upper""&gt;Upper value to be applied&lt;/param&gt;
    /// &lt;returns&gt;Grayscale image with the applied range&lt;/returns&gt;
    private UMat inRangeImage(UMat hsvImage, int lower, int upper)
    {
        UMat resultImage = new UMat();
        UMat lowerBorder = new UMat(hsvImage.Rows, hsvImage.Cols, DepthType.Cv8U, 3);
        UMat upperBorder = new UMat(hsvImage.Rows, hsvImage.Cols, DepthType.Cv8U, 3);

        lowerBorder.SetTo(new Gray(lower).MCvScalar);
        upperBorder.SetTo(new Gray(upper).MCvScalar);

        CvInvoke.InRange(hsvImage, lowerBorder, upperBorder, resultImage);

        // Dispose the image due to causing memory leaking.
        lowerBorder.Dispose();
        upperBorder.Dispose();

        return resultImage;

    }
</code></pre>
",,2015-08-09 08:07:13,Working with UMat in Emgu wrapper,<c#><emgucv><hsv>,,,CC BY-SA 3.0,False,False,True,False,False
33091,31154879,2015-07-01 07:18:36,,"<p>Does anybody know an up-to-date camera calibration project like <a href=""http://www.emgu.com/wiki/index.php/Camera_Calibration"" rel=""nofollow"">http://www.emgu.com/wiki/index.php/Camera_Calibration</a> for the current version of EmguCV (3.0.0)? I need to figure out the coefficients of distortion of a special camera. <strong>It would be okay to have a standalone binary.</strong> It would also be nice, if there is a documentation about which camera-distorion-model is used. </p>

<p>The problem behind the project above is, that it is not up-to-date with current EmguCv, so I can't build it.</p>

<p>The target is to correct the lense-distorsion in my own 3D engine for a constant camera. I tried to use the formulas at <a href=""https://en.wikipedia.org/wiki/Distortion_%28optics%29"" rel=""nofollow"">https://en.wikipedia.org/wiki/Distortion_%28optics%29</a> with guessed parameters, but the result is still not satisfying.</p>
",2015-07-01 07:23:07,2015-07-08 00:53:22,EmguCv up-to-date camera calibration project,<c#><camera-calibration><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
33092,31155151,2015-07-01 07:31:48,,"<p>I am using EmguCV and C# on MS VisualStudio 2013
I had made an XML file containing the descriptors of several images and then I am matching this descriptors (as observed image) with the observed image descriptors (as model image) in order to see which KeyPoints are being used. (kind of inverse matching).</p>

<p>I have the following code working for some images as input and for some I get the exception:
A first chance exception of type 'System.ArgumentException' occurred in mscorlib.dll </p>

<p>As I make a breakpoint on the line where XX is assigned, all the variables are correct but after some iterations the Exception is thrown. 
That is my main question: <strong>why does it happen to some pictures?</strong> (not depending on the picture format)
And one more thing strange here is that the color of the KeyPoints on the resulting picture is not pure Red (0,0,255) as I expect it to be. Can anyone tell me why?</p>

<p>Here is my code:</p>

<pre><code>SURFDetector surfCPU = new SURFDetector(500, false);  
Emgu.CV.Util.VectorOfKeyPoint observedKeyPoints;
Matrix&lt;int&gt; indices;
int k = 1;
// extract features from the observed image
observedKeyPoints = surfCPU.DetectKeyPointsRaw(imgGray, null);
Matrix&lt;float&gt; observedDescriptors = surfCPU.ComputeDescriptorsRaw(imgGray, null, observedKeyPoints);
BruteForceMatcher&lt;float&gt; matcher55 = new BruteForceMatcher&lt;float&gt;(DistanceType.L2);

matcher55.Add(observedDescriptors);
indices = new Matrix&lt;int&gt;(AgrObjectDescriptors.Rows, k);

using (Matrix&lt;float&gt; dist = new Matrix&lt;float&gt;(AgrObjectDescriptors.Rows, k))
{
    matcher55.KnnMatch(AgrObjectDescriptors, indices, dist, k, null);
    Debug.Write(matcher55);
}

/*The following is the problem part  */
int XX,YY;
Emgu.CV.Structure.Bgr KeyPointColor =  new Bgr(0, 0, 255);
MKeyPoint[] usedKeyP = observedKeyPoints.ToArray();
for (int i = 0; i &lt; indices.Rows; i++) {
    XX = Convert.ToInt32(usedKeyP[indices[i, 0]].Point.X);
    YY = Convert.ToInt32(usedKeyP[indices[i, 0]].Point.Y);
    img99[XX, YY] = KeyPointColor;
}
/*Draw the image on WPF component image1*/
 image1.Source = BitmapSourceConvert.ToBitmapSource(img99);
</code></pre>
",2015-07-02 02:56:05,2015-07-02 17:22:40,drawing keypoints with emgucv,<c#><debugging><matching><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
33101,26398076,2014-10-16 06:59:51,,"<p>I would like to get the histogram of an image using Emgu.</p>

<p>I have a Gray scale double image </p>

<pre><code>Image&lt;Gray, double&gt; Crop;
</code></pre>

<p>I can get a histogram using</p>

<pre><code>Image&lt;Gray, byte&gt; CropByte = Crop.Convert&lt;Gray, byte&gt;(); 
DenseHistogram hist = new DenseHistogram(BinCount, new RangeF(0.0f, 255.0f));
hist.Calculate&lt;Byte&gt;(new Image&lt;Gray, byte&gt;[] { CropByte }, true, null);
</code></pre>

<p>The problem is, doing it this way I needed to convert to a byte Image. This is problematic because it skews my results. This gives a slightly different histogram to what I would get if it were possible to use a double image.</p>

<p>I have tried using CvInvoke to use the internal opencv function to compute a histogram.</p>

<pre><code>IntPtr[] x = { Crop }; 

DenseHistogram cropHist = new DenseHistogram  
( 
    BinCount,  
    new RangeF 
    (
        MinCrop,
        MaxCrop
    ) 
); 

CvInvoke.cvCalcArrHist(x, cropHist, false, IntPtr.Zero); 
</code></pre>

<p>The trouble is I'm finding it hard to find how to use this function correctly</p>

<p><img src=""https://i.stack.imgur.com/RE2t8.png"" alt=""Error""></p>

<p>Does emgu/opencv allow me to do this? Do I need to write the function myself? </p>
",2014-10-16 07:10:09,2014-10-16 23:12:11,Histogram computation with Emgu OpenCV,<c#><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
33111,31155349,2015-07-01 07:41:46,,"<p>I am trying to load a small TIFF image using Emgu.CV (2.4.10). The image is a 32bit (float32) single band image, but when loading it using Emgu it opens it as a <code>&lt;Bgra, Single&gt;</code> image.</p>

<p>Is Emgu misinterpreting the image or are there some method to force Emgu to load the image as a <code>&lt;Gray, Single&gt;</code>?</p>
",,2015-07-15 16:48:23,"Emgu.CV load grayscale float32 image as <Bgra, Single>",<image><tiff><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
33123,31226020,2015-07-04 23:45:59,,"<p>I am using EmguCV with C#, I am facing a problem when I want to grab frames from my web cam, red underline appears on statement:</p>

<pre><code>imgOrg = capturecam.QueryFrame();
</code></pre>

<blockquote>
  <p>error: Cannot implicitly convert type 'Emgu.CV.Mat' to 'Emgu.CV.Image</p>
</blockquote>

<p>how can I solve this problem?</p>

<p>my code:</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;

using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Structure;
using Emgu.CV.UI;

namespace test2
{
    public partial class Form1 : Form
    {
        Image&lt;Bgr, Byte&gt; imgOrg; //image type RGB (or Bgr as we say in Open CV)
        private Capture capturecam;

        public Form1()
        {
            InitializeComponent();
        }

        private void Form1_Load(object sender, EventArgs e)
        {
            try
            {
                capturecam = new Capture();
            }
            catch (NullReferenceException exception)
            {
                MessageBox.Show(exception.Message);
                return;
            }
            Application.Idle += new EventHandler(ProcessFunction);

        }
        private void ProcessFunction(object sender, EventArgs arg)
        {
            imgOrg = capturecam.QueryFrame(); // error line
            imageBox1.Image = imgOrg;
        }
    }
}
</code></pre>
",2015-07-06 17:21:35,2019-10-11 22:28:14,"EmguCV capture error: Cannot implicitly convert type 'Emgu.CV.Mat' to 'Emgu.CV.Image<Emgu.CV.Structure.Bgr,byte>",<c#><emgucv><webcam-capture>,,,CC BY-SA 3.0,False,True,True,False,False
33129,31206179,2015-07-03 11:51:18,,"<p>I am using emgu cv version 3. I try to load image to process. but it will provide error for me. According to the error it will say image cannot be read. But i have a image under that location.</p>

<p>This is my code line..</p>

<pre><code>Image&lt;Bgr, Byte&gt; image = new Image&lt;Bgr, Byte&gt;(""image.jpg"");
</code></pre>
",,2015-07-03 12:03:43,Emgu CV image load notworking,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
33197,31281696,2015-07-08 00:39:06,,"<p>I'm trying to extend the example below to allow for matching against more than one reference image. Does anyone know how to do this?</p>

<p>I'm not sure how to concat multiple sets of gpuModelDescriptors into something that the detector can use. Surely there must be a way to compare an image against an entire set of reference images and not one at a time?</p>

<p>The goal is to load a big set of reference images to the GPU, and then compare observed images against the references looking for a (close) match with adjustable tolerance/precision. Thanks in advance for any light you can shed on this. I've been struggling with it for many months.</p>

<p>Example: <a href=""http://www.emgu.com/wiki/index.php/SURF_feature_detector_in_CSharp"" rel=""nofollow"">http://www.emgu.com/wiki/index.php/SURF_feature_detector_in_CSharp</a></p>
",,2015-07-09 00:46:20,Emgu.CV GpuSURFDetector against n-images?,<opencv><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
33240,31217410,2015-07-04 05:53:42,,"<p>I was trying to capture video using Emgu CV VideoWriter but it shows:</p>

<blockquote>
  <p>Unable to create VideoWriter. Make sure you have the specific codec
  installed</p>
</blockquote>

<p>How do I deal with this?<br>
This is what my code looks like:<br></p>

<pre><code>Bitmap back = new Bitmap(""jpg image path"");
Image&lt;Bgr, Byte&gt; bg;
bg = new Image(Bgr, byte)(back);
vw = new VideoWriter(""c://work//test1.mp4"",CvInvoke.CV_FOURCC('M','S','V','C'), 17, 640, 480, true);
</code></pre>

<p>
It works fine for .avi extensions but the size is pretty huge for some seconds only so I want to compress it more. Please suggest any workarounds or  changes to the code/library.</p>
",2018-04-18 09:37:42,2020-04-30 15:42:03,EMGU CV videowriter is unable to make video,<c#><opencv><bitmap><emgucv><image-compression>,,,CC BY-SA 3.0,True,False,True,False,False
33246,26410932,2014-10-16 17:59:45,,"<p>I am attempting to make an iSpy plugin using opencv in order to process the image data.<br>
iSpy is written in C#.NET and so must be their plugins, therefore I need a wrapper for OpenCV(which is written in C++). I tried using EMGUCV and OpenCVSharp; emgu based plugin didn't even run as a plugin(also it's very outdated) and ocvsharp has some big performance issues I can't bare for this project.</p>

<p>Since using C# wrappers wasn't an option anymore, I started making an unmanaged C++ project that implements the functionality I need for the plugin and built it as an x64 dll and tried to make a wrapper for this methods and functions to C# in order to use it on the plugin. So far, so good, the wrap works just fine when outside iSpy.<br>
When I try to run the plugin that incorporates this projects via iSpy I get:</p>

<pre><code>System.BadImageFormatException was unhandled by user code
HResult=-2147024885
Message=An attempt was made to load a program with an incorrect format. (Exception from HRESULT: 0x8007000B)
Source=ImageProcessing
StackTrace:
   at ImageProcessing.WrappingMiddleman.Pootis()
   at ImageProcessing.ObjectsFinder..ctor(String path, FinderTypes finderType) in c:\Users\Matias Lopez\Documents\GitHub\CCAddons-Testing\FaceSurveillance\ImageProcessing\ObjectsFinder.cs:line 63
   at CCAddons.Main.InitConfig() in c:\Users\Matias Lopez\Documents\GitHub\CCAddons-Testing\FaceSurveillance\FaceSurveillance\Main.cs:line 162
   at CCAddons.Main.set_Configuration(String value) in c:\Users\Matias Lopez\Documents\GitHub\CCAddons-Testing\FaceSurveillance\FaceSurveillance\Main.cs:line 155
InnerException: 
</code></pre>

<p>which, from what I've seen, means there is a problem with the solution platforms not matching or something.<br>
Now, the problem is, I need the plugin to be built for AnyCPU, not x64, since iSpy won't even accept it as a valid plugin if not. What can I do to get my C++ dll to be run from the plugin?</p>
",,2014-10-23 16:16:06,Building iSpy plugin that uses opencv,<c#><.net><opencv><visual-c++>,,,CC BY-SA 3.0,True,False,True,False,False
33254,31256599,2015-07-06 22:16:07,,"<p>I am using emgu/opencv to find the position of some flat blobs. I can currently find their positions in pixels and would like to convert this to world coordinates (in/mm). I have looked at emgu's camera calibration <a href=""http://www.emgu.com/wiki/index.php?title=Camera_Calibration"" rel=""nofollow"">example</a>, but I am having trouble actually applying it to get what I want. Using the example, I believe I can get the intrinsic matrix, but I am not really sure what to do with it. My camera is fixed and is looking down at the fixed plane the blobs are on. Any help would be appreciated. Thank you.</p>
",,2016-01-15 20:45:58,Emgu Camera Calibration,<c#><opencv><camera-calibration><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
33403,31354165,2015-07-11 06:27:19,,"<p>now I am working with Face detecting using <code>Emgucv</code> library.
I am beginner for that. I have not idea about this line  </p>

<pre><code>result = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
</code></pre>

<p>Can you please tell me?</p>
",2016-10-04 12:17:41,2016-10-04 12:17:41,Emgucv library currentFrame.Copy,<emgucv><detection><face-detection>,,,CC BY-SA 3.0,False,False,True,False,False
33408,27541875,2014-12-18 08:12:44,,"<p>I work with EmguCV 2.9.0.1922 (x86, x64) and try to play a video file. I took one of Emgu-video-example from internet (EmguCV 2.4.2...) and can't even compile it: 'Emgu.CV.Capture' does not contain a definition for <code>GrabProcessState</code>. (Does Emgu.CV.dll crucially change between version 2.4 and 2.9??)</p>

<p>In the case I go to the EmguCV 2.4.2 compilation is OK, but runtime error is:
""A first chance exception of type <code>System.DllNotFoundException</code> occurred in Emgu.CV.dll
A first chance exception of type <code>System.TypeInitializationException</code> occurred in Emgu.CV.dll
An unhandled exception of type <code>System.TypeInitializationException</code> occurred in Emgu.CV.dll</p>

<p>Additional information: The type initializer for <code>Emgu.CV.CvInvoke</code> threw an exception.""</p>
",2014-12-29 19:48:50,2014-12-29 19:48:50,'Emgu.CV.Capture' does not contain a definition for 'GrabProcessState',<c#><dll><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
33411,31372523,2015-07-12 20:58:29,,"<p>lets go with the idea that i know nothing about nothing...</p>

<p><a href=""https://www.youtube.com/watch?v=37l6-O0T6EA"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=37l6-O0T6EA</a></p>

<p>I was following this vids, all going well. but failing on ""capturez.QueryFrame""</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""false"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>Imports Emgu.CV
Imports Emgu.CV.Util
Imports Emgu.CV.Structure

Public Class Form1

    Dim capturez As Capture = New Capture

    Private Sub Timer1_Tick(ByVal sender As System.Object, ByVal e As System.EventArgs) Handles Timer1.Tick

        Dim imagez As Image(Of Bgr, Byte) = capturez.Retrieve() 'Instead of QueryFrame, you may need to do RetrieveBgrFrame depending on the version of EmguCV you download.

        PictureBox1.Image = imagez.ToBitmap()

    End Sub
End Class</code></pre>
</div>
</div>
</p>
",2017-08-13 14:38:49,2017-08-13 14:38:49,Emgu webcam in VB beginner,<vb.net><webcam><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
33440,31355758,2015-07-11 09:43:56,,"<p>I want code to match two pictures on basis of SIFT keypoints.?</p>

<p>I have the following code for SIFT</p>

<pre><code>public static Image&lt;Bgr, Byte&gt; siftFunction(Bitmap sourceBitmap)
    {
        Image&lt;Gray, Byte&gt; modelImage = new Image&lt;Gray, byte&gt;(sourceBitmap);
        SIFTDetector siftCPU = new SIFTDetector();
        VectorOfKeyPoint modelKeyPoints = new VectorOfKeyPoint();
        MKeyPoint[] mKeyPoints = siftCPU.DetectKeyPoints(modelImage, null);
        modelKeyPoints.Push(mKeyPoints);
        ImageFeature&lt;float&gt;[] reulst = siftCPU.ComputeDescriptors(modelImage, null, mKeyPoints);
        Image&lt;Bgr, Byte&gt; result = Features2DToolbox.DrawKeypoints(modelImage, modelKeyPoints, new Bgr(Color.Red), Features2DToolbox.KeypointDrawType.DEFAULT);
        return result;
    }
</code></pre>

<hr>
",2015-07-11 09:44:24,2015-07-16 03:08:03,How to match EMGU CV SIFT keypoints of two images?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
33451,31301127,2015-07-08 18:44:35,,"<p>Specifically, I'm working with <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/a8929aab-99c5-79cf-385c-dcec7769fea1.htm"" rel=""nofollow"">EmguCV's <code>Image</code> type</a>.</p>

<p>I've defined an interface <code>ITransformation</code> with a method <code>ApplyFrom</code> that takes an <code>Image</code> and returns an <code>Image</code>:</p>

<pre><code>public interface ITransformation
{
    Image&lt;TColor, TDepth&gt; ApplyFrom&lt;TColor, TDepth&gt;(Image&lt;TColor, TDepth&gt; sourceImage);
}
</code></pre>

<p>But this seems awfully verbose with type parameters, especially when that method gets used.  Ideally, the interface would look like this:</p>

<pre><code>public interface ITransformation
{
    Image ApplyFrom(Image sourceImage);
}
</code></pre>

<p>But Visual Studio complains about <code>Image</code> requiring 2 type parameters.  I don't want to bind the <code>ApplyFrom()</code> method to a specific color or depth</p>

<p><strong>Do I <em>need</em> to use the generic, verbose first version above?</strong></p>

<p><strong>Or am I missing some possible middle ground between the two versions?</strong></p>
",2015-07-08 19:47:45,2015-07-08 19:47:45,Does a parameterized return type require a generic method signature?,<c#><generics><methods><types><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
33468,27546130,2014-12-18 12:01:05,,"<p>I am currently working on my project for Windows Phone 8.1 Face Detection in C#. I have already finished face detection but now I have a serious problem with Face Tracking and extraction of face signs from image.  I would like to use for this LBP method, but LBP method in library OpenCV and EmguCV is still not supported for windows phone 8.1 . I also tried to use  Face SDK Beta from Microsoft, but it is supported only for windows phone 7. Has anybody have some experience with some libraries or methods in windows phone 8.1 in C# .</p>

<p>Thanks for help.</p>
",,2015-06-15 09:22:26,Windows phone 8.1 Face Detection C#,<c#><opencv><windows-phone-8.1><emgucv><lbph-algorithm>,,,CC BY-SA 3.0,True,False,True,False,False
33485,31375843,2015-07-13 05:20:32,,"<p>I am new to EmguCV and OpenCV. I want to detect the text Regions from an Image using EmguCV.</p>

<p>There are already some solutions posted on Stack using OpenCV.</p>

<ol>
<li><a href=""https://stackoverflow.com/questions/23506105/extracting-text-opencv?lq=1"">Extracting text OpenCV</a></li>
</ol>

<p>But unable to convert that OpenCV code to EmguCV.</p>
",,2015-07-17 02:13:31,Detecting Text Regions from image using EmguCV,<c#><opencv><ocr><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
33496,27548961,2014-12-18 14:34:49,,"<p>I'm working on a project with Kinect Sensor and Emgu CV.
I'm taking the person detected into a rectangle and divide it into smaller pieces. I send each piece into Emgu CV's HoG fuction and I'm waiting for a float array as a result for each sent piece.</p>

<p>Problem is when I send an Image into my HoG function, program exits without warnin/exception on Compute method.</p>

<p>My Hog function is: (taken from: <a href=""https://stackoverflow.com/questions/20497798/taking-the-hog-descriptor-of-an-image-using-hogdescriptor-from-emgu-cv-c-sharp"">Taking the HOG descriptor of an image using HOGDescriptor from EMGU CV C#</a>)</p>

<pre><code>    public Image&lt;Bgr, Byte&gt; Resize(Image&lt;Bgr, Byte&gt; im)
    {
        return im.Resize(64, 128, Emgu.CV.CvEnum.INTER.CV_INTER_LINEAR);
    }
    public float[] GetVector(Image&lt;Bgr, Byte&gt; im)
    {
        HOGDescriptor hog = new HOGDescriptor();    // with defaults values
        Image&lt;Bgr, Byte&gt; imageOfInterest = Resize(im);
        System.Drawing.Point[] p = new System.Drawing.Point[imageOfInterest.Width * imageOfInterest.Height];
        int k = 0;
        for (int i = 0; i &lt; imageOfInterest.Width; i++)
        {
            for (int j = 0; j &lt; imageOfInterest.Height; j++)
            {
                System.Drawing.Point p1 = new System.Drawing.Point(i, j);
                p[k++] = p1;
            }
        }
        float[] result = hog.Compute(imageOfInterest, new System.Drawing.Size(16, 16), new System.Drawing.Size(0, 0), p);
        return result;
    }
</code></pre>

<p>I tried to catch a dump with Procdump but its exiting without catching anything when my program crashes.</p>
",2017-05-23 11:43:33,2015-04-30 10:57:37,Hog descriptor emgu cv,<c#><wpf><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
33500,31338389,2015-07-10 10:22:29,,"<p>I am new to C# so please forgive me if the answer to my question is very easy.</p>

<p>My goal is to capture and store from my camera 10 frames so i can do some post prossesing. I am using a Gige Basler scout monochrome camera.
I know how to acquire the 10 images with a while loop.</p>

<p>So my question is how to save in each iteration of the while loop each image into the same jagged array? </p>

<p>My goal is to save the 10 images into one single 3D jagged array. I declare the jagged array as:</p>

<p><code>UInt16[][,] jaggedArray = new UInt16[10][,];</code> </p>

<p>The camera give the the image into a bitmap format (m_bitmap).</p>

<p>Using Emgu i can convert the bitmat to image (Not sure if i have to do this):</p>

<pre><code>Image&lt;Gray, UInt16&gt; IMA = new Image&lt;Gray, UInt16&gt;(m_bitmap);
</code></pre>

<p>What i want to do is that in each iteration i can save the acquired image in the jagged array:</p>

<pre><code>itteration 1 :&gt;&gt;      jaggedArray[0] = 1st Image

itteration 2 :&gt;&gt;      jaggedArray[1] = 2nd Image
</code></pre>

<p>...</p>

<pre><code>itteration 10 :&gt;&gt;      jaggedArray[9] = 10th Image
</code></pre>

<p>But i don't know how to save the acquired Image or Bitmap inside the jagged array (jaggedArray[i] = ???????????). </p>

<p>In what i have to convert my image or Bitmap to be able to store it inside the jagged array?</p>

<p>Please if you know any better approach to this problem feel free to tell me that.</p>

<p>The captured images have size of (1280,960).</p>

<p>Thank you in advance! </p>
",,2015-07-10 17:36:49,Save Several Images to a Jagged Array,<c#><image><bitmap><emgucv><jagged-arrays>,,,CC BY-SA 3.0,False,False,True,False,False
33504,31302408,2015-07-08 19:53:01,,"<p>Here is a class signature from the popular EmguCV package.  It's the <code>Image</code> class - not all of it is important:</p>

<pre><code>/// &lt;summary&gt;
/// An Image is a wrapper to IplImage of OpenCV. 
/// &lt;/summary&gt;
/// &lt;typeparam name=""TColor""&gt;Color type of this image (either Gray, Bgr, Bgra, Hsv, Hls, Lab, Luv, Xyz, Ycc, Rgb or Rbga)&lt;/typeparam&gt;
/// &lt;typeparam name=""TDepth""&gt;Depth of this image (either Byte, SByte, Single, double, UInt16, Int16 or Int32)&lt;/typeparam&gt;
public partial class Image&lt;TColor, TDepth&gt;
  : CvArray&lt;TDepth&gt;, IImage, IEquatable&lt;Image&lt;TColor, TDepth&gt;&gt;
  where TColor : struct, IColor
  where TDepth : new()
</code></pre>

<p>Specifically, note </p>

<pre><code>  ...
  where TDepth : new()  // &lt;-- either Byte, SByte, Single, double, UInt16, Int16 or Int32
</code></pre>

<p><strong>How does <code>new()</code> constrain the type parameter <code>TDepth</code> to the .NET integral types?</strong></p>
",,2015-07-08 19:56:37,What does it mean to constrain a type parameter with `new()`?,<c#><generics><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
33597,31413529,2015-07-14 17:34:38,,"<h3>Context</h3>

<p>I'm using the <a href=""http://www.emgu.com/wiki/index.php/Tutorial"" rel=""nofollow"">EmguCV wrapper</a> around OpenCV.  As you can imagine, Emgu is full of classes with <a href=""https://msdn.microsoft.com/en-us/library/system.intptr(v=vs.110).aspx"" rel=""nofollow""><code>IntPtr</code></a> pointers to unmanaged memory, like <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/728cc968-ac7c-1429-43d8-dde43a037be5.htm"" rel=""nofollow"">this property of the <code>IImage</code> interface</a>, which is implemented by <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/2ec33afb-1d2b-cac1-ea60-0b4775e4574c.htm"" rel=""nofollow""><code>Mat</code></a>, <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/54fae358-0713-57d1-9195-fd47e5c82659.htm"" rel=""nofollow""><code>UMat</code></a>, and <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/a8929aab-99c5-79cf-385c-dcec7769fea1.htm"" rel=""nofollow""><code>Image&lt;,&gt;</code></a>.</p>

<p>I don't know if this is related, but those all also inherit from Emgu's own <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/1a248c0b-75ce-eae1-d650-521f24d4d308.htm"" rel=""nofollow""><code>DisposableObject</code></a> and <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/f7d6df34-2ee0-1ad2-b53f-4b95f3f7d12f.htm"" rel=""nofollow""><code>UnmanagedObject</code></a> abstract classes.</p>

<ul>
<li>I'm comfortable working in Java, Python, and Ruby whose garbage collectors are pretty smart.</li>
<li>I'm comfortable working in C, where my heap arrays and structs are my own problem.</li>
</ul>

<p>In the Java-calling-C flavored JNI native interop that I've done, arrays are explicitly extracted and converted from the JVM heap using JNI functions.  Then you can mess with the array in C, but you have to use JNI functions again to either copy the array to a Java returnable, or to an output parameter.  This isolates C memory management and Java memory management - they aren't concerned with each other.</p>

<p>But in the C# native interop world, I see that you can just use <code>IntPtr</code> pointers directly!  That's convenient if I want to do something clever/dangerous  with fast dereferencing and pointer arithmetic, but I'm pretty squeamish about manipulating them or even storing references to them.</p>

<h1>Question</h1>

<p>If I do something like this</p>

<pre><code>var img = new Image&lt;RGB, byte&gt;(""filename.jpg"");
IntPtr myPtr = img.Ptr;
</code></pre>

<p>Does that mess with the garbage collector for the unmanaged memory and cause memory leaks?  Or is <code>myPtr</code> just another link in the reference graph keeping <code>img</code> from being automatically disposed?</p>

<p>Or does it depend on the native code and its wrapper?  (Open/EmguCV in my case).</p>
",2015-07-14 20:20:26,2015-07-14 20:20:26,Can I copy references to unmanaged memory without causing memory leaks?,<c#><pointers><unmanaged><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
33681,31494897,2015-07-18 19:41:39,,"<p>I have next code</p>

<pre><code>private void crop_image(int i, int x, int y, int w, int h)
{
   Image&lt;Bgr, Byte&gt; loaded_image = new Image&lt;Bgr, byte&gt;(Environment.CurrentDirectory + ""\\currentvideo\\image"" + (i + 1) + "".jpg"");
   Image&lt;Bgr, Byte&gt; croped_image = loaded_image.Copy(new Rectanle(x,y,w,h));
}
</code></pre>

<p>When i calling crop_image function, all works well.</p>

<pre><code>for (int i = 0; i &lt; crop_images_num; i++)
{
   crop_image(i, x,y,w,h);
}
</code></pre>

<p>But when i trying to use Task.Factory, i have exception</p>

<pre><code>for (int i = 0; i &lt; crop_images_num; i++)
{
   running.Add(Task.Factory.StartNew(() =&gt; crop_image(i, x,y,w,h)));
   Task.WaitAll(running.ToArray());
}
</code></pre>

<p>I don't understand, what did i do wrong?</p>
",,2015-07-18 19:41:39,OpenCV: src.depth() == dst.depth() && src.size == dst.size exception in task,<c#><multithreading><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
33736,31500855,2015-07-19 11:47:26,,"<p>I download sift implementation from : <a href=""https://sites.google.com/site/btabibian/projects/3d-reconstruction/code"" rel=""nofollow"">https://sites.google.com/site/btabibian/projects/3d-reconstruction/code</a>
but i get the error : 'INVERT METHOD' does not exist in the namespace 'Emgu.CV.CvEnum'. from code line : <code>CvInvoke.cvInvert(H, H_inv.Ptr, Emgu.CV.CvEnum.INVERT_METHOD.CV_SVD);</code> any suggestion to solve my problem? </p>
",,2017-04-12 21:45:03,SIFT with Emgu : How can I solve error : 'INVERT METHOD' does not exist in the namespace 'Emgu.CV.CvEnum',<emgucv><sift>,,,CC BY-SA 3.0,False,False,True,False,False
33826,31572999,2015-07-22 20:07:10,,"<p>For example, in this method:</p>

<p><a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/2528290c-8802-d51b-116b-79f0bc9acba6.htm"" rel=""nofollow""><code>Image.Copy(Rectangle roi)</code></a></p>

<p>A new <code>Image</code> is returned, cropped according to the <code>System.Drawing.Rectangle</code> parameter.  An example usage is:</p>

<pre><code>var image = new Image&lt;Gray, Byte&gt;(""filename.jpg"");
var cropRectangle = new Rectangle(0, 200, 100, 10);
var cropped = image.Copy(cropRectangle);
</code></pre>

<p>OpenCV, EmguCV, and, hence, the <code>Image</code> class all operate with the coordinate system <code>(Row, Column)</code>, but <code>Rectangle</code> operates with the more conventional <code>(x, y)</code> coordinate system.</p>

<p>How do those two coordinate systems map between each other?  Should I create a <code>Rectangle</code> with <code>x == 100</code> and <code>y == 10</code> to crop starting at the 100th row and 10th column?</p>
",,2015-07-22 20:23:15,"Is EmguCV's System.Drawing.Rectangle usage by (Row,Column) or (X,Y)?",<c#><opencv><coordinate-systems><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
33850,31534817,2015-07-21 09:09:12,,"<p>I'm using a multi-class SVM classifier in EmguCV. I need confidence score of SVM for each of the classes. for example I don't need that SVM just declares class number, I need it tells me P(classnumbers| input) for different Classes.
How can I obtain this probability or score in EmguCV?(multi-class)</p>

<p>if there is no way, Is any solution for multi-class SVM classifier in matlab?</p>
",,2015-07-21 14:09:54,Confidence score or probability in SVM,<matlab><opencv><svm><emgucv><libsvm>,,,CC BY-SA 3.0,True,True,True,False,False
33928,31543444,2015-07-21 15:30:55,,"<p>I'm trying to use the Hough Transform from EmguCV 3.0 to detect lines, but then, I'm only interested by some line ""angles"".
Basically, I just want to see almost 90/270º and 0/180º lines (with a margin of a few degrees). And of course, I just want those who reach a certain treshold.
I was thinking finding those lines using the accumulator and only looking at some  angles values (85 to 95º for instance)... but no way to access to this accumulator :/
Is there some smart way to do it? Or should I look at angles of the top lines from the Hough Transform and then just keeping the ones I'm interested in...?</p>

<p>Thanks =)</p>
",,2015-07-21 15:30:55,Access to Hough Transform accumulator,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
33959,31583946,2015-07-23 09:54:41,,"<p>The Image.FindContours method is missing, using the latest 3.0 version of Emgu CV. (i guess that is not the only one)</p>

<p>Where can I find them?</p>

<p>Update:</p>

<p>I want to accomplish the same under C#</p>

<pre><code>Mat edges; //from canny
vector&lt;vector&lt;Point&gt; &gt; contours;
vector&lt;Vec4i&gt; hierarchy;
findContours(edges, contours, hierarchy, RETR_TREE, CHAIN_APPROX_SIMPLE);
</code></pre>
",2015-08-06 12:00:46,2015-08-06 12:00:46,"Image<TColor, TDepth>.FindContours missing from EmguCV 3.0",<c#><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
34109,31682865,2015-07-28 17:06:16,,"<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;

namespace WebcamTest
{
    public partial class Form1 : Form
    {

        private Capture c;

        public Form1()
        {
            InitializeComponent();
        }

        private void Form1_Load(object sender, EventArgs e)
        {

            c = new Capture();
            c.ImageGrabbed += ProcessFrame;
            c.Start();

        }

        public void ProcessFrame(object sender, EventArgs e)
        {

            Image&lt;Bgr, byte&gt; image = c.QueryFrame();

            c.ImageGrabbed -= ProcessFrame;
            c.Stop();
            c.Dispose();

        }

    }
}
</code></pre>

<p>So I have this really simple code to grab a webcam image and store it, just one time. It does nothing else currently, but I'm having a weird issue. In my file, one line seems to cause the issue:</p>

<pre><code>Image&lt;Bgr, byte&gt; image = c.QueryFrame();
</code></pre>

<p><strong>EDIT</strong>: I have tried changing this line to this as the wiki suggests:</p>

<pre><code>Image&lt;Bgr, byte&gt; image = new Image&lt;Bgr, byte&gt;(c.RetreiveBgrFrame().ToBitmap());
</code></pre>

<p>This one always gives a null reference exception the first time; afterwards it acts the same as the other line. Every pixel's combined values are 0's after the first run.</p>

<p>Then I go a bit deeper into the problem,
I found that I keep getting a StackOverflowException in the Emgu.CV.dll itself. It continously says it is line 240 in this file: <a href=""http://pastebin.com/Fgq3JxWD"" rel=""nofollow"">Capture.cs</a></p>

<p>The line is this:</p>

<pre><code>bool grabbed = CvInvoke.cvGrabFrame(_ptr);
</code></pre>

<p>I have ran through their examples before and actually had them working before. I have never really had this issue before since it's coming from inside their dll. Why would this line keep causing this error? Is the pointer way off point for some unknown reason? The only thing I could think was that it was trying to access a memory location outside the actual bounds. It's always the very first run it does this. Then when it crashes, the camera stays on and so next time it runs. Though the image pixels are all 0's every time after that.</p>
",2015-07-28 18:28:38,2015-07-28 18:28:38,Why is EmguCV throwing this StackOverFlowException when capturing?,<c#><exception><dll><emgucv><capture>,,,CC BY-SA 3.0,False,False,True,False,False
34124,31648576,2015-07-27 08:44:21,,"<p>I am currently using the EmguCV <code>QueryFrame</code> method to capture frames. The code is something like this, inside my <code>processFrame</code> method:</p>

<pre><code>using(Image&lt;Bgr, Byte&gt; imgOriginal = _capture.QueryFrame()){
    if(imgOriginal == null) return;
        using(Image&lt;Gray, Byte&gt; grayImg = imgOriginal.Convert&lt;Gray, Byte&gt;()){
            //some stuff with grayImg
        }
}
</code></pre>

<p>The problem I'm facing is that I keep getting an <code>OutOfMemory</code> exception. Upon further inspection with <code>MemProfiler</code>, I find that a <code>Byte[,,]</code> object of namespace <code>System</code> uses up exponentially more memory than anything else. The only <code>Byte[,,]</code> I can think of is the <code>Bgr</code> frame <code>imgOriginal</code> that is captured. </p>

<p>This leads me to believe that the <code>Capture</code> object keeps on querying new frames even if the code within the using block has not finished executing. Is this true? Or is there some other reason? Is there any way to solve this?</p>

<p>Any help would be appreciated. Thank you.</p>
",2016-11-28 22:31:16,2016-11-28 22:31:16,Is Emgu CV QueryFrame method asynchronous?,<c#><out-of-memory><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
34184,31745453,2015-07-31 11:48:12,,"<p>My code is divided in three parts: PART 1) Drawing in a bitmap, PART 2) Saving the bitmap as a jpg image, PART 3) Reading the jpg file and find contours using Emgu.</p>

<p>These three parts work separately but I cannot make them work together. Particularly, my problem is how to input the <code>System.Drawing.Bitmap</code> of PART 1 into PART 3 which input is an <code>Image&lt;Bgr, Byte&gt;</code>.
So far I have tried to read the Bitmap ""target"" in Part 1 directly into Part 3 doing <code>Image&lt;Bgr, Byte&gt; imageFrame = new Image&lt;Bgr, Byte&gt;(target)</code> with no success (it doen't identify any contours)
I have also tried to create an intermediate .jpg file (Part 2) they can share with no success either (it doen't identify any contours either).  </p>

<p>The only way that I can make this work is:</p>

<p>i) Run Part 1 and Part 2</p>

<p>ii) Open the resultant jpg image using Paint, hit ""Save"" and close Paint. I have done this manually.</p>

<p>iii) Run Part 3. </p>

<p>Doing this the contour is identified. However this is not a valid solutions since the step ii) is not automated. However this might help illustrating what the problem is. </p>

<p>Can someone help?</p>

<pre><code>using System;
using System.Collections.Generic;
using System.Drawing;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;

namespace Contouring
{

class Program
{
    static void Main(string[] args)
    {

        //--------------------------------------PART 1 : DRAWING STUFF IN A BITMAP------------------------------------------------------------------------------------
        Pen blackPen = new Pen(Color.FromArgb(255, 0, 0, 0), 1);
        Bitmap bmp = new Bitmap(1000, 1000);
        Graphics g = Graphics.FromImage(bmp);

            //This is just an example using three rectangles for illustration purposes. 
            //In reality I have a set of arbitrary lines defining complex polygons.
            g.DrawRectangle(blackPen, new Rectangle(10, 10, 200, 100)); //rectangle 1
            g.DrawRectangle(blackPen, new Rectangle(20, 20, 50, 30)); //rectangle 2
            g.DrawRectangle(blackPen, new Rectangle(200, 10, 25, 25)); //rectangle 3

        Rectangle r = new Rectangle(10, 10, 250, 250); //bounding box of the 3 rectangles
        Rectangle rcrop = new Rectangle(r.X, r.Y, r.Width + 10, r.Height + 10);//This is the cropping rectangle (bonding box adding 10 extra units width and height)

        //Crop the model from the bmp
        Bitmap src = bmp;
        Bitmap target = new Bitmap(r.Width, r.Height);
        using (Graphics gs = Graphics.FromImage(target))
        {
            gs.DrawImage(src, new Rectangle(5, 5, 250, 250), rcrop, GraphicsUnit.Pixel);
            gs.Dispose();
        }


        //--------------------------------------PART 2 : SAVING THE BMP AS JPG------------------------------------------------------------------------------------
        target.Save(""test.jpg"");


        //--------------------------------------PART 3 : USING THE SAVED PICTURE AND FIND CONTOURS ----------------------------------------------------------------
        Image&lt;Bgr, Byte&gt; imageFrame = new Image&lt;Bgr, Byte&gt;(""test.jpg"");
            //Image&lt;Bgr, Byte&gt; imageFrame = new Image&lt;Bgr, Byte&gt;(target);

        //Find contours
        Image&lt;Gray, byte&gt; grayFrame = imageFrame.Convert&lt;Gray, byte&gt;();
        List&lt;Contour&lt;Point&gt;&gt; result = new List&lt;Contour&lt;Point&gt;&gt;();
        using (MemStorage storage = new MemStorage()) //allocate storage for contour approximation
        for (Contour&lt;Point&gt; contours = grayFrame.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST, storage); contours != null; contours = contours.HNext)
        {
            //here i do stuff with the contours and add them to the list result
            result.Add(contours);
        }

        //Write to console
        Console.WriteLine(result.Count + "" NO. contours have been identified"");

    }//endmain

}//endprogram

}//endNamespace
</code></pre>
",,2015-08-03 06:49:50,Reading System.Drawing.Bitmap into OpenCV / Emgu to find contours,<c#><opencv><drawing><paint><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
34229,31783528,2015-08-03 09:12:22,,"<p>I'm trying to get emgu cv working with unity3d on osx. I followed the steps on <a href=""http://www.emgu.com/wiki/index.php/Download_And_Installation#OSX"" rel=""nofollow noreferrer"">http://www.emgu.com/wiki/index.php/Download_And_Installation#OSX</a> and <a href=""https://stackoverflow.com/questions/30557198/opencv-emgucv-not-working-in-unity-in-osx"">opencv (emgucv) not working in unity in osx?</a></p>

<p>Unfortunately I keep running into DllNotFoundException errors:</p>

<pre><code>DllNotFoundException: Assets/Emgu.CV/Plugins/emgucv.bundle/Contents/MacOS/libcvextern.dylib
Emgu.CV.CvInvoke..cctor () (at Assets/Emgu.CV/Emgu.CV/PInvoke/CvInvoke.cs:464)
Rethrow as TypeInitializationException: An exception was thrown by the type initializer for Emgu.CV.CvInvoke
CameraTexture.Start () (at Assets/Emgu.CV/Emgu.CV.Demo/CameraTexture.cs:49)
</code></pre>

<p>and</p>

<pre><code>DllNotFoundException: Assets/Emgu.CV/Plugins/emgucv.bundle/Contents/MacOS/libcvextern.dylib
Emgu.CV.CvInvoke..cctor () (at Assets/Emgu.CV/Emgu.CV/PInvoke/CvInvoke.cs:464)
Rethrow as TypeInitializationException: An exception was thrown by the type initializer for Emgu.CV.CvInvoke
Emgu.CV.Image`2[Emgu.CV.Structure.Bgr,System.Byte].AllocateData (Int32 rows, Int32 cols, Int32 numberOfChannels) (at Assets/Emgu.CV/Emgu.CV/Image.cs:331)
Emgu.CV.Image`2[Emgu.CV.Structure.Bgr,System.Byte]..ctor (Int32 width, Int32 height) (at Assets/Emgu.CV/Emgu.CV/Image.cs:281)
HelloTexture.Start () (at Assets/Emgu.CV/Emgu.CV.Demo/HelloTexture.cs:19)
</code></pre>

<p>Does anyone know if any additional steps are needed or the files should be in different folders?</p>
",2017-05-23 12:23:57,2018-03-29 12:42:31,Unity3d DllNotFoundException for EmguCV plugin,<opencv><dll><unity3d><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
34234,31731648,2015-07-30 18:42:14,,"<p>I'm trying to make a simple <code>openCV</code> camera application with <code>c#</code> on windows x64Bit.</p>

<p>To do so, I copied <code>cvextern.dll</code>, <code>Emgu.CV.dll</code>, <code>Emgu.CV.UI.dll</code>, <code>Emgu.Util.dll</code> and all <code>opencv_*.dll</code> files to the solution's debug folder.<br>
I add the files <code>Emgu.CV.dll</code>, <code>Emgu.CV.UI.dll</code> and <code>Emgu.Util.dll</code> as refrence.</p>

<p>In the form <code>CameraCapture</code> when I click the button <code>btnStart</code> the camera frames shoud be displayed in the Imagebox <code>CamImageBox</code>.</p>

<p>here's my code</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.Util;

namespace CameraCapture
{
    public partial class CameraCapture : Form
    {
        private Capture capture;
        private bool captureInProgress;

        public CameraCapture()
        {
            InitializeComponent();
        }
        private void ProcessFrame(object sender, EventArgs arg)
        {
            Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
            CamImageBox.Image = ImageFrame;
        }

        private void btnStart_Click(object sender, EventArgs e)
        {
            #region if capture is not created, create it now
            if (capture == null)
            {
                try
                {
                    capture = new Capture();
                }
                catch (NullReferenceException excpt)
                {
                    MessageBox.Show(excpt.Message);
                }
            }
            #endregion

            if (capture != null)
            {
                if (captureInProgress)
                {  

                    btnStart.Text = ""Start!""; //
                    Application.Idle -= ProcessFrame;
                }
                else
                {
                    btnStart.Text = ""Stop"";
                    Application.Idle += ProcessFrame;
                }

                captureInProgress = !captureInProgress;
            }
        }

        private void ReleaseData()
        {
            if (capture != null)
                capture.Dispose();
        }
    }
}
</code></pre>

<p>This code doesn't show any error while building the project. The problem is that when I run the project and press the button <code>btnStart</code> nothing is displayed in the Imagebox <code>CamImageBox</code>.</p>

<p>The code shows me no errors. The camera is working fine. When I run the project My camera's light turn on ""camera starts working when I run the project"" But I don't recieve any picture in the Imagebox.</p>

<p>Is there something I'm missing with the files, project configration?</p>
",,2015-08-07 12:20:21,EmguCV opens the camera but doesn't view frames in ImageBox,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
34249,31732340,2015-07-30 19:21:42,,"<p>i have an (x,y) point, a 3x3 camera matrix, and 4 distortion coefficients and i want to get the undistorted point.  my code looks like this...</p>

<pre><code>double distorted_point_x = 10;
double_distorted_point_y = 20;

Emgu.CV.Matrix&lt;double&gt; distorted_point = new Emgu.CV.Matrix&lt;double&gt;(new double[,] {{distorted_point_x,distorted_point_y}});
Emgu.CV.Matrix&lt;double&gt; undistorted_point = new Emgu.CV.Matrix&lt;double&gt;(new double[,] {{-1,-1}}); // init to -1
Emgu.CV.Matrix&lt;double&gt; distortion_coefficients = new Matrix&lt;double&gt;(new double[] {0,0,0,0});
Emgu.CV.Matrix&lt;double&gt; camera_matrix = new Matrix&lt;double&gt;(new double[,] {{0,0,0},{0,0,0},{0,0,0}});

// copy the stuff; there's probably a more elegant way to copy but this works
for (int row = 0; row &lt; 3; row++) {
    for (int col = 0; col &lt; 3; col++) {
        camera_matrix[row, col] = my_calibrated_camera_matrix[row, col];  
    }
}

CvInvoke.UndistortPoints(distorted_point, undistorted_point, camera_matrix, distortion_coefficients);

undistorted_point_x = undistorted_point[0, 0];
undistorted_point_y = undistorted_point[0, 1];
</code></pre>

<p>when i run (VS2010), i get this exception dumped out to exception log file:</p>

<pre><code>UnhandledException: OpenCV: CV_IS_MAT(_src) &amp;&amp; CV_IS_MAT(_dst) &amp;&amp;
(_src-&gt;rows == 1 || _src-&gt;cols == 1) &amp;&amp; (_dst-&gt;rows == 1 || _dst-&gt;cols
== 1) &amp;&amp; _src-&gt;cols + _src-&gt;rows - 1 == _dst-&gt;rows + _dst-&gt;cols - 1 &amp;&amp;
(CV_MAT_TYPE(_src-&gt;type) == CV_32FC2 || CV_MAT_TYPE(_src-&gt;type) ==
CV_64FC2) &amp;&amp; (CV_MAT_TYPE(_dst-&gt;type) == CV_32FC2 ||
CV_MAT_TYPE(_dst-&gt;type) == CV_64FC2)
</code></pre>

<p>i have the undistort.cpp from opencv and i know that this is coming from a CV_ASSERT in cvUndistortPoints(). i wonder if it's bombing on the CV_MAT_TYPE() tests where it looks like it's expecting the matrix to have 2 channels.  (why would this be needed when the input is not image data?)  if it does need to be 2-channel, how do i specify that in the Matrix??  i tried using Mat, but i don't know how to initialize the content of a Mat.  i'd really appreciate any pointers.  thanks.</p>
",,2019-01-07 06:29:18,how to call UndistortPoints,<opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
34259,31774529,2015-08-02 17:24:00,,"<p>i have a problem with k_fold value for SVM class in c# (using emgucv). all of number value just making exception as below :</p>

<blockquote>
  <p>Emgu.CV.Util.CvException was unhandled   HResult=-2146233088<br>
  Message=OpenCV: While cross-validation one or more of the classes have
  been fell out of the sample. Try to enlarge <br>
  Source=Emgu.CV   ErrorMessage=While cross-validation one or more of
  the classes have been fell out of the sample. Try to enlarge
  </p>
</blockquote>

<p>enlarge/ change k_fold value is useless. please help me to fix them?</p>
",,2015-08-13 03:35:26,k_fold value making fell out of the sample SVM class,<c#><visual-studio-2010><opencv><svm><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
34263,31714730,2015-07-30 03:28:17,,"<p>I have problem when connect IP of camera like <code>http://192.168.1.101</code>.</p>

<p>I've seen in emgu document the url must like: </p>

<pre><code>Capture cap = new Capture(""rtsp://username:password@[IP Address]/mpeg4/media.amp"");
</code></pre>

<p>But my camera use in LAN.</p>

<p>How to connect camera with IP <code>http://</code>? If it impossible, I hope anybody can say any solution for that.</p>

<p>Like convert <code>http:// protocol</code> to <code>rtsp:// protocol</code>.</p>

<p>Thank you very much!!!</p>
",,2015-07-31 11:19:35,Can't connect camera ip with Emgu,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
34329,26498983,2014-10-22 01:22:20,,"<p>I am using Tesseract OCR in EmguCV. I have developed one simple C# application and now I want to deploy/distribute it. </p>

<p>The problem I see is that it requires me to have x86 folder of OpenCV dlls in the bin folder in order to run the application. This folder is about 381 MBs. Do I need to include this folder while giving the application to someone else. Or is there any other way to elegantly give my application to be used by end user.</p>
",,2014-10-22 06:21:12,EmguCV Tesseract application deployment and distribution,<c#><deployment><ocr><tesseract><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
34334,26502728,2014-10-22 07:58:07,,"<p>I am trying to view in a pictureBox a tif raw file uncompressed. that was generated with 
""matrox imaging library""
I am using emgu.cv</p>

<p>I am doing:</p>

<pre><code>Image&lt;Gray, ushort&gt; My_Image = new Image&lt;Gray, ushort&gt;(imgN);
Image&lt;Gray, byte&gt; My_Image1 = new Image&lt;Gray, byte&gt;(imgN);
</code></pre>

<p>and slso: </p>

<pre><code>Image&lt;Gray, byte&gt; My_Image3 = My_Image.Convert&lt;Gray, byte&gt;();
</code></pre>

<p>I keep seeing black image,
any solutions?
I have also tried more combination  resulting in black ...</p>
",2014-10-22 07:58:20,2016-01-18 18:51:27,Reading 16bit matrox imaging library with emgu,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
34345,31794247,2015-08-03 18:26:45,,"<p>I'm new to EmguCV, OpenCV and machine vision in general. I translated the code from <a href=""https://stackoverflow.com/questions/13840013/opencv-how-to-visualize-a-depth-image"">this</a> stack overflow question from C++ to C#. I also copied their sample image to help myself understand if the code is working as expected or not. </p>

<pre><code>Mat map = CvInvoke.Imread(""C:/Users/Cindy/Desktop/coffee_mug.png"", Emgu.CV.CvEnum.LoadImageType.AnyColor | Emgu.CV.CvEnum.LoadImageType.AnyDepth);
CvInvoke.Imshow(""window"", map);
Image&lt;Gray, Byte&gt; imageGray = map.ToImage&lt;Gray, Byte&gt;();

double min = 0, max = 0; 
int[] minIndex = new int[5], maxIndex = new int[5];

CvInvoke.MinMaxIdx(imageGray, out min, out max, minIndex, maxIndex, null);
imageGray -= min;
Mat adjMap = new Mat();
CvInvoke.ConvertScaleAbs(imageGray, adjMap, 255/(max-min), 0);
CvInvoke.Imshow(""Out"", adjMap);
</code></pre>

<p>Original Image:</p>

<p><a href=""https://i.stack.imgur.com/w0tsI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/w0tsI.png"" alt=""Original Image""></a> </p>

<p>After Processing: </p>

<p><a href=""https://i.stack.imgur.com/tQity.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tQity.png"" alt=""After processing""></a></p>

<p>This doesn't look like a depth map to me, it just looks like a slightly modified grayscale image, so I'm curious where I went wrong in my code. MinMaxIdx() doesn't work without converting the image to grayscale first, unlike the code I linked above. Ultimately, what I'd like to do is to be able to generate relative depth maps from a single webcamera.</p>
",2017-05-23 12:23:34,2015-08-03 18:36:39,Visualize depth for a single image,<c#><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
34388,31834096,2015-08-05 13:34:00,,"<p>I am trying to detect a piece of paper from an image. Well I have had help from posts like <a href=""https://stackoverflow.com/questions/8667818/opencv-c-obj-c-detecting-a-sheet-of-paper-square-detection"">this</a> . But one difference is that my background color is almost same as the paper color, and I am getting wrong result.</p>

<p>[edit]
By wrong result I mean the paper outline contour is not detected at all. instead the largest contour covers the whole image.</p>

<p><a href=""http://www.imageno.com/ai7b91pm9fcspic.html"" rel=""nofollow noreferrer"">image1</a></p>

<p><a href=""http://www.imageno.com/k99c9xpd6phspic.html"" rel=""nofollow noreferrer"">image2</a></p>

<p>My code so far (using emgu cv and c#)</p>

<pre><code>MemStorage storage = new MemStorage();
        List&lt;Contour&lt;Point&gt;&gt; candidateList = new List&lt;Contour&lt;Point&gt;&gt;();
        List&lt;double&gt; areaList = new List&lt;double&gt;();

        Image&lt;Bgr, Byte&gt; inputImage = new Image&lt;Bgr, Byte&gt;(image);
        //Rectangle roi = new Rectangle(15, 15, image.Width - 15, image.Height - 15);
        //inputImage.ROI = roi;
        //inputImage = inputImage.Copy();

        double threshHeight = inputImage.Size.Height * 0.50;
        double threshWidth = inputImage.Size.Width * 0.50;


        //std::vector&lt;std::vector&lt;cv::Point&gt; &gt; squares;
        //cv::Mat pyr, timg, gray0(_image.size(), CV_8U), gray;
        int thresh = 50, N = 5;
        //cv::pyrDown(_image, pyr, cv::Size(_image.cols/2, _image.rows/2));
        //cv::pyrUp(pyr, timg, _image.size());
        //std::vector&lt;std::vector&lt;cv::Point&gt; &gt; contours;

        Image&lt;Gray, Byte&gt; [] gray0 = new Image&lt;Gray,byte&gt;[3];


        for( int c = 0; c &lt; 3; c++ ) {
            try{
                int [] ch = {c, 0};
                gray0[c] = new Image&lt;Gray,byte&gt;(inputImage.Size);
                CvInvoke.cvMixChannels(new IntPtr[] { inputImage }, 1, new IntPtr[]{gray0[c]}, 1, ch, 1);
                Image&lt;Gray, Byte&gt; gray = new Image&lt;Gray,byte&gt;(inputImage.Size);
                for (int l = 0 ; l &lt; N ; l++){
                    if (l == 0){
                        Image&lt;Gray, Byte&gt; cannyImage = gray0[c].Canny(0, thresh, 5);
                        CvInvoke.cvDilate(cannyImage, gray, IntPtr.Zero, 1);
                        //CvInvoke.cvShowImage(""ch "" + c + ""-"" + l, gray);
                    }else{
                        CvInvoke.cvThreshold(gray0[c], gray, (l + 1)*255/N, 255, Emgu.CV.CvEnum.THRESH.CV_THRESH_BINARY);
                        //CvInvoke.cvShowImage(""ch "" + c + ""-"" + l, gray0[c]);
                    }

                    //CvInvoke.cvShowImage(""image"", gray);    

                    for (Contour&lt;Point&gt; contours = gray.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST, storage); contours != null; contours = contours.HNext){
                        Contour&lt;Point&gt; currentContour = contours.ApproxPoly(contours.Perimeter * 0.02, storage);
                        if (currentContour.Count() &gt;= 4){
                            if (currentContour.Area &gt; 3000){
                            //if (currentContour.BoundingRectangle.Width &gt;= threshWidth &amp;&amp; currentContour.BoundingRectangle.Height &gt; threshHeight){
                                candidateList.Add(currentContour);
                                areaList.Add(currentContour.Area);
                                inputImage.Draw(currentContour, new Bgr(255, 0, 0), 1);
                            }
                        }
                    }
                }




            }catch(Exception ex){
                Debug.WriteLine(ex.Message);
            }


        }

        /* finding the biggest one */
        double area = -1.0;
        Contour&lt;Point&gt; paper = null;
        for (int i = 0 ; i &lt; candidateList.Count ; i++){
            if (areaList[i] &gt; area){
                area = areaList[i];
                paper = candidateList[i];
            }
        }

        if (paper != null){
            if (paper.BoundingRectangle.Width &gt;= threshWidth &amp;&amp; paper.BoundingRectangle.Height &gt; threshHeight){
                inputImage.Draw(paper, new Bgr(0, 0, 255), 2);

            }
        }
        return inputImage.ToBitmap();
</code></pre>

<p>Please let me know how to process these images.</p>
",2017-05-23 11:44:07,2015-08-08 02:17:54,detect paper from background almost same as paper color,<image-processing><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
34423,31926672,2015-08-10 18:32:07,,"<p>I'm having a very difficult problem with EMGU 3.0 and canny edge.</p>

<p>I am trying to use the Canny method to detect edges, but it becomes so slow that it is unusable. </p>

<p>Everything works well <em>and real-time</em> without the Canny line (which is commented out below), but then, if I un-comment the ""CvInvoke.Canny..."". line basically the whole program comes to a brutal stop!!! I have the latest emgu 3.0 installed and properly referenced with dll's and cvextern.dll. </p>

<p>There are <strong>no errors</strong> when building solution.</p>

<p>FYI i'm capturing images from a microscope camera (using toupcam.dll) which works perfectly fine.</p>

<p>Here is the code snippet of the problem. Again, this works perfectly <strong><em>until</em></strong> I un-comment the CvInvoke.Canny line below. Then, it basically stops... 
s
What the heck??</p>

<pre><code>        private void OnEventImage()
    {
        if (bmp_ != null)
        {
            BitmapData bmpdata = bmp_.LockBits(new Rectangle(0, 0, bmp_.Width, bmp_.Height), ImageLockMode.WriteOnly, bmp_.PixelFormat);

            uint nWidth = 0, nHeight = 0;
            toupcam_.PullImage(bmpdata.Scan0, 24, out nWidth, out nHeight);

            bmp_.UnlockBits(bmpdata);

            pictureBox1.Image = bmp_;
            pictureBox1.Invalidate();

            Image&lt;Bgr, Byte&gt; frameimg = new Image&lt;Bgr, Byte&gt;(bmp_);
            iboxEdge.Image = frameimg;
            iboxEdge.Invalidate();

            Image&lt;Gray, Byte&gt; grayimg = new Image&lt;Gray, byte&gt;(frameimg.Bitmap);
            Mat edgeimg = grayimg.Mat;

            //CvInvoke.Canny(edgeimg, edgeimg, 100, 200, 3, false);

            iboxCanny.Image = edgeimg;
            iboxCanny.Invalidate();
        }
    }
</code></pre>
",,2015-08-10 18:32:07,Emgu Canny very slow. What to do?,<emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
34429,31914229,2015-08-10 07:49:26,,"<p>Currrently, I am trying to get my face image from the database but I cannot get it. Its saying my I cannot convert System.Drawing.Image to EmguCV Gray Byte. Can I know whats my mistake on it. This is my first time I am using EmguCV.</p>

<pre><code> //Eigen face recognizer
 EigenObjectRecognizer recognizer = new 
 GetFaceFromDB(), //database
 labels.ToArray(), //facename list
 3000,
 ref termCrit);

 name = recognizer.Recognize(result);
</code></pre>

<p>This is my DB code:</p>

<pre><code>private Image GetFaceFromDB()
    {
        Image FetchImg;
        if (rowNumber &gt;= 0)
        {
            byte[] FetchImgBytes = ((byte[])TSTable.Rows[rowNumber][""FaceImage""]);
            System.IO.MemoryStream stream = new System.IO.MemoryStream(FetchImgBytes);
            FetchImg = Image.FromStream(stream);
            return FetchImg;
        }
        else
        {
            MessageBox.Show(""No Image yet. Add image into database"");
            return null;
        }
    }
</code></pre>

<p>Thank you.</p>
",,2015-08-10 09:13:23,Cannot convert System.Drawing.Image to EmguCV,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
34434,31817939,2015-08-04 19:45:51,,"<p>I'm trying to get a webcam capture with Unity3d and EmguCV 3.0, but I'm stumbling into some weird problems. To start off, I'm trying to get a simple capture going by doing:</p>

<pre><code>Capture cap = new Capture(0);
Mat currentFrame = cap.QueryFrame();
</code></pre>

<p>But unfortunately this throws an error:</p>

<pre><code>error CS0029: Cannot implicitly convert type `Emgu.CV.Mat' to `Emgu.CV.Mat'
</code></pre>

<p>That doesn't really make any sense to me, I tried to cast it, but that doesn't work either. The documentation shows the <code>QueryFrame</code> returns a <code>Mat</code>: <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/18b6eba7-f18b-fa87-8bf2-2acff68988cb.htm"" rel=""nofollow"">http://www.emgu.com/wiki/files/3.0.0/document/html/18b6eba7-f18b-fa87-8bf2-2acff68988cb.htm</a></p>
",2015-08-04 20:31:21,2015-08-10 13:12:19,EmguCV Capture Mat error in Unity3D,<c#><unity3d><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
34444,31893944,2015-08-08 14:10:51,,"<p>I'm trying to compile Emgu CV 2.4.9 from git source. I followed the instructions given in the site.</p>

<p>I cloned <code>git://git.code.sf.net/p/emgucv/code</code> this repo, switched to 2.4.9 branch, then I ran <code>git submodule update --init --recursive</code></p>

<p>After that I ran <code>Build_Binary_x86.bat</code> to create the visual studio solution. I opened up the solution in Visual Studio 2013, but when I tried to build the project, I'm getting the following errors.</p>

<p><a href=""https://i.stack.imgur.com/7hora.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7hora.jpg"" alt=""enter image description here""></a></p>

<p>I haven't made any changes in the source code, but still I'm unable to build the project. Is there something I'm doing wrong?</p>
",,2015-08-08 14:10:51,Errors while compiling Emgu CV from source,<c++><opencv><visual-studio-2013><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
34452,31916476,2015-08-10 09:51:34,,"<p>I am working in C# and I have a monochromatic camera returning to me two successive images. I want to subtract these images.</p>

<p>The camera is set to MONO-16 with resolution 1980x960.</p>

<p>The camera returns to me a vector of 2457600 elements, because each pixel is represented by two bytes so <code>{1980x960 = 1228800} * 2 bytes / pixel = 2457600</code>.</p>

<p>The problem is that I have to convert the two 2457600 element vectors to two 1228800 vectors in order to do the subtraction.</p>

<p>So I need to combine two successive elements of the 2457600  into one element  so that I end up with a vector of 1228800 elements, where its element have 16bit range (0-65536).</p>

<p>I will probably have to create a loop to iterate 1228800 times and in each iteration take two elements from the 2457600 vector:</p>

<pre><code>  for(int i = 0 ; i &lt; 2457600 ; i = i + 2)
  {
     byte BYTE1 = newGrabResultInternal2.ImageData.Buffer[i];
     byte BYTE2 = newGrabResultInternal2.ImageData.Buffer[i+1];        
     // What to do next to combine the 2 bytes into one???
  }
</code></pre>

<p>When I have the two bytes which represent 1 pixel, how do I combine them together to give me an intensity value of 16bit depth (0-65536)?  </p>

<p>Also, if you can suggest a different approach it would be helpful.</p>
",2015-08-10 09:59:20,2015-08-10 09:59:59,Convert MONO-16bit image with 2bytes per pixel to MONO-16bit with 1 byte per pixel in C#,<c#><.net><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
34484,31918751,2015-08-10 11:48:41,,"<p>Currently, I am facing problem with my EmguCV c# code. I am trying to recognize my images from the database, but its not working. Once my face is detected, its crashing and then this error shows up </p>

<blockquote>
  <p>Additional information: OpenCV: Different sizes of objects. </p>
</blockquote>

<p>I tried searching for this error but I am clueless. </p>

<p>This is my code:</p>

<pre><code>//Action for each element detected
foreach (MCvAvgComp f in facesDetected[0])
{
   t = t + 1;
   result = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
   //draw the face detected in the 0th (gray) channel with blue color
   currentFrame.Draw(f.rect, new Bgr(Color.Green), 2);

   //Database select the image row and pass to the eigenobjectrecognizer

   //ConnectToDatabase();
   if (Connection.State.Equals(ConnectionState.Open))
   {
      Connection.Close();
      TSTable.Clear();
      ConnectToDatabase();
   }
   //Connection.Open();
   OleDbCommand OledbSelect = new OleDbCommand(""Select FaceName, FaceImage From TrainingSet1"",Connection);
   OleDbDataReader reader = OledbSelect.ExecuteReader();

   while (reader.Read())
   {
      labels.Add(reader.GetValue(1).ToString()); 
      trainingImages.Add(gray);
   }

   if (TSTable.Rows.Count != 0)
   {
      //TermCriteria for face recognition with numbers of trained images like maxIteration
      MCvTermCriteria termCrit = new MCvTermCriteria(ContTrain, 0.001);

      //Eigen face recognizer
      EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
                trainingImages.ToArray(), //database faceimage list
                labels.ToArray(), //facename list
                3000,
                ref termCrit);

      name = recognizer.Recognize(result);

      //Draw the label for each face detected and recognized
      currentFrame.Draw(name, ref font, new Point(f.rect.X - 2, f.rect.Y - 2), new Bgr(Color.LightGreen));

   }
</code></pre>

<p>I currently still new to EmguCV and C#. So some of the exceptions I don't understand. Can anyone help me with this. </p>

<p>And once the code breaks, it goes to the <code>EigenObjectRecognizer.cs</code>. This is the code where it breaks:</p>

<pre><code> public static float[] EigenDecomposite(Image&lt;Gray, Byte&gt; src, Image&lt;Gray, Single&gt;[] eigenImages, Image&lt;Gray, Single&gt; avg)
  {
     return CvInvoke.cvEigenDecomposite(
         src.Ptr,
         Array.ConvertAll&lt;Image&lt;Gray, Single&gt;, IntPtr&gt;(eigenImages, delegate(Image&lt;Gray, Single&gt; img) { return img.Ptr; }),
         avg.Ptr);
  }
</code></pre>
",2015-08-10 12:14:54,2018-09-08 08:40:08,Additional information: OpenCV: Different sizes of objects using c#,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
34552,31935939,2015-08-11 07:41:44,,"<p>Currently, I am trying to get my faces from the database to used it for face recognition. But now the problem I am facing is, any image it detects also its showing my name. </p>

<p>This is my <code>C#</code> code:</p>

<pre><code> while (reader.Read())
 {
    labels.Add(reader.GetValue(0).ToString());
    trainingImages.Add(gray);
 }
</code></pre>

<p>This is my <code>EmguCV</code> image conversion code:</p>

<pre><code>currentFrame = grabber.QueryFrame().Resize(320, 240, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC); //dont disturb this part

    //Convert it to Grayscale
    gray = currentFrame.Convert&lt;Gray, Byte&gt;();

    //Face Detector
    MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
    face,
    1.2,
    10,
    Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
    new Size(25, 25));
</code></pre>

<p>It sounds like problem is at the <code>trainingImages.Add(gray)</code> just that I don't know how to get it from the database. At the same time, once the face is detected then my whole program becomes too slow. </p>

<p>Can someone help me on this?</p>
",2016-03-29 03:35:50,2016-03-29 03:35:50,Retrieve Image from database for face recognition using c#,<c#><image-processing><emgucv><face-detection><face-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
34572,31955248,2015-08-12 02:50:39,,"<p>I am trying to read my images from my MS Access database into my eigenobjectrecognizer. But now, I am getting an error which is </p>

<blockquote>
  <p>Unable to cast object of type 'System.Byte[]' to type 'Emgu.CV.Image`2[Emgu.CV.Structure.Gray,System.Byte]'.</p>
</blockquote>

<p>I dont know what is this error is about. Below is my code.</p>

<pre><code>int count = reader.FieldCount;

while (reader.Read())
{
    labels.Add(reader[""FaceName""].ToString());
    trainingImages.Add((Image&lt;Gray,byte&gt;)reader[""FaceImage""]);
}   
if (TSTable.Rows.Count != 0)
{
    ////    //TermCriteria for face recognition with numbers of trained images like maxIteration
    MCvTermCriteria termCrit = new MCvTermCriteria(ContTrain, 0.001);

    ////Eigen face recognizer
    EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
        trainingImages.ToArray(), //database faceimage list
        labels.ToArray(), //facename list
        3000,
        ref termCrit);
</code></pre>

<p>Can someone help me with this. I am trying this for more than a week already but still I cant get any solution. Thank you.</p>
",2015-08-12 03:52:26,2015-08-12 09:06:15,Unable to cast object of type in C#,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
34646,31981758,2015-08-13 07:12:19,,"<p>I'm new to emguCV. I need to access web camera and detect the hand.then I need to recognize the sign  of the hand and add some controls according to the hand sign. first of all I need to detect hand from web camera stream. I have no idea how to start this process. I have some ideas got from research papers. I know that I need to train images but couldn't find any proper process. Are there any tutorials under this topic?? there were some tutorials which were not user friendly and complete.</p>
",2015-08-13 08:58:06,2018-01-12 15:55:00,Hand Detection using EmguCV,<c#><image-processing><emgucv><haar-classifier>,,,CC BY-SA 3.0,False,False,True,False,False
34658,31946021,2015-08-11 15:31:18,,"<ul>
<li>Is it possible to block accessing particular pixel in an image, once
we satisfy a condition inside a nested for loop? I need to skip that
pixel in the next iteration through the image.</li>
<li><p>Provided nested for loop tests for 2 images. Once the absolute diff
between pixel matches the if condition, i wants to block accessing
that pixel in the next iteration.</p>

<pre><code>byte[,,] watermark_arr = watermark_img.Data;
byte[,,] cover_arr = cover.Data;

//iterate through watermark image
for (int x = 0; x &lt; watermark_img.Height; x++)
{
    for (int y = 0; y &lt; watermark_img.Width; y++)
    {
        //iterate through cover image
        for (int i = 0; i &lt; cover.Height; i++)
        {
            for (int j = 0; j &lt; cover.Width; j++)
            {
                if ((Math.Abs(watermark_arr[x, y, 0] - cover_arr[i, j, 0]) &lt;= threshold)  //[x,y,0] --&gt; r
                    &amp;&amp; (Math.Abs(watermark_arr[x, y, 1] - cover_arr[i, j, 1]) &lt;= threshold)     //[x,y,1] --&gt; g
                        &amp;&amp; (Math.Abs(watermark_arr[x, y, 2] - cover_arr[i, j, 2]) &lt;= threshold))     //[x,y,2] --&gt; b
                {
                    flag = true;
                    count_hit[cnt - 1]++;
                }
</code></pre></li>
</ul>
",2015-08-11 15:37:14,2015-08-11 16:29:31,Skip accessing an image pixel value within a for loop C#,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
34682,31965436,2015-08-12 12:36:17,,"<p>I have developed a working C# face recognition program using EmguCV. </p>

<p>However, if I load <strong>""haarcascade_fullbody.xml""</strong> instead of <strong>""haarcascade_frontalface_alt_tree.xml""</strong> I get the almighty Access Violation.</p>

<p>This is the code;</p>

<pre><code>public Bitmap detection(Bitmap Source)
    {
        List&lt;Image&lt;Gray, byte&gt;&gt; TrainedImages = this.TrainedImages;
        List&lt;String&gt; Names = this.Names;
        Image&lt;Bgr, byte&gt; ImageFrame = new Image&lt;Bgr, byte&gt;(Source);
        Image&lt;Gray, byte&gt; grayFrame = ImageFrame.Convert&lt;Gray, byte&gt;();
        Image&lt;Bgr, byte&gt; overlay = new Image&lt;Bgr, byte&gt;(Source.Width, Source.Height);
        Graphics FaceCanvas;

        List&lt;String&gt; finimg = new List&lt;String&gt;();

        //HaarCascade haar = new HaarCascade(""haarcascade_frontalface_alt_tree.xml"");
        HaarCascade haar = new HaarCascade(""haarcascade_fullbody.xml"");

        var faces = grayFrame.DetectHaarCascade(haar, 1.1, 3, HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new System.Drawing.Size(25, 25))[0];

        foreach (var face in faces)
        {                
            overlay.Draw(face.rect, new Bgr(System.Drawing.Color.Green), 3);
            tempbmp = new Bitmap(100, 100);

            FaceCanvas = Graphics.FromImage(tempbmp);
            FaceCanvas.DrawImage(grayFrame.ToBitmap(), 0, 0, face.rect, GraphicsUnit.Pixel);
            detected.Add(tempbmp);
            if (doit)
            {
                saveBitmap(tempbmp, trainpath, trainnamer.Text);
                doit = false;
            }

            if (doit10)
            {
                for (int k = 1; k &lt;= 10; k++)
                    saveBitmap(tempbmp, trainpath, trainnamer.Text);
                doit10 = false;
            }


            try
            {
                MCvTermCriteria termCrit = new MCvTermCriteria(TrainedImages.ToArray().Length, 0.001);//????????????
                EigenObjectRecognizer recognizer = new EigenObjectRecognizer(TrainedImages.ToArray(), Names.ToArray(), 2500, ref termCrit);
                MCvFont font = new MCvFont(FONT.CV_FONT_HERSHEY_TRIPLEX, 0.5d, 0.5d);

                String name = recognizer.Recognize(new Image&lt;Gray, byte&gt;(tempbmp));
                if (Names.Contains(name) == false)
                    name = ""Stranger"";
                else
                    name = removeformat(name);

                overlay.Draw(name, ref font, new System.Drawing.Point(face.rect.Left, face.rect.Top - 5), new Bgr(System.Drawing.Color.Green));
                finimg.Add(name);
            }
            catch (IndexOutOfRangeException)
            {
                MCvFont font = new MCvFont(FONT.CV_FONT_HERSHEY_TRIPLEX, 0.5d, 0.5d);
                ImageFrame.Draw(""Stranger"", ref font, new System.Drawing.Point(face.rect.Left, face.rect.Top - 5), new Bgr(color));
                continue;

            }

        }


        detected.Clear();

        Bitmap supra = overlay.ToBitmap();

        supra.MakeTransparent(System.Drawing.Color.Black);

        return supra;
    }
</code></pre>
",2015-08-12 12:42:26,2015-08-13 08:13:07,EmguCV HaarCascade issue,<c#><detection><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
34686,31985545,2015-08-13 10:22:34,,"<p>I am trying to convert my mediumblob data which is in MySQL to Bitmap image, but I cannot do it. I am getting an error which is </p>

<blockquote>
  <p>Parameter is not valid.</p>
</blockquote>

<p>This is my c# code:</p>

<pre><code> MySqlCommand select = new MySqlCommand(""Select FaceName, FaceImage From TrainingSet1"", conn);
                MySqlDataReader reader = select.ExecuteReader();



                while (reader.Read())
                {
                    labels.Add(reader[""FaceName""].ToString());


                    byte[] buffer = (byte[])reader[""FaceImage""];
                    MessageBox.Show(""kw"");

                    MemoryStream ms = new MemoryStream(buffer);

                    ms.Write(buffer, 0, buffer.Length);
                    Bitmap bmp = new Bitmap(ms); //prb is here
                    MessageBox.Show(""remy"");
                    Image&lt;Gray, byte&gt; image = new Image&lt;Gray, byte&gt;(bmp);
                    trainingImages.Add(image);
                }

                reader.Close();
</code></pre>

<p>This is my image adding functionality into the database:</p>

<pre><code> private byte[] ConvertToDBFormat(IImage InputImage)
    {
        Bitmap BmpImage = new Bitmap(InputImage.Bitmap);
        MemoryStream MyStream = new MemoryStream();
        BmpImage.Save(MyStream, System.Drawing.Imaging.ImageFormat.Jpeg);
        byte[] ImageAsBytes = MyStream.ToArray();
        return ImageAsBytes;
    }
</code></pre>

<p>Can someone help me with this. Thank you.</p>
",2015-08-13 10:40:09,2015-08-13 10:40:09,Converting MediumBlob data into an Bitmap Image using C#,<c#><mysql><bitmap><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
34696,31966514,2015-08-12 13:22:47,,"<p>I have been using EMGU 2.9.0 in the Visual basic environment to open a video file,  read the frames sequentially, analyse them and close the video.</p>

<p>This was accomplished by:</p>

<pre><code>Private Sub BW_SBD_DoWork(ByVal sender As System.Object, ByVal e As System.ComponentModel.DoWorkEventArgs) Handles BW_SBD.DoWork
    'Background Worker - Do Work Thread

    Dim currentFrame As New Image(Of Gray, Byte)(FrameHeight, FrameWidh) 'Declare image objects to hold current and previous frame 
    Dim frameCount As Integer = 1
    Dim numFrames As Integer  'number of frame for the video

    For Each file As String In lstbSelectedVideoList.Items
        ' For Each file As String In files - Loop through the list of files 
        Dim previousFrame As New Image(Of Gray, Byte)(FrameHeight, FrameWidh)

        Using fingerprintCapture As New Capture(file)  ' Create a capture from file 
            numFrames = CType(Math.Round(fingerprintCapture.GetCaptureProperty(CAP_PROP.CV_CAP_PROP_FRAME_COUNT)), Integer)     ' Get video's total number of frames

            frameCount = 1

            fingerprintCapture.SetCaptureProperty(CAP_PROP.CV_CAP_PROP_POS_FRAMES, 0)                                   ' Jump to start frame
            currentFrame = fingerprintCapture.QueryGrayFrame()                                                          ' get a frame

            While fingerprintCapture.GetCaptureProperty(CAP_PROP.CV_CAP_PROP_POS_FRAMES) &lt; 0.0                          ' Make sure the start frame was found (codecs create problems with the set frame pos function)
                currentFrame = fingerprintCapture.QueryGrayFrame()                                                      ' get a frame
            End While

            While currentFrame IsNot Nothing

            'The analysis procedure requires the frames from the video
                If MyFrameAnalysisFunction(currentFrame, previousFrame) = 1 Then
                    MessageBox.Show('This part is irrelevant')
                End If


                previousFrame = currentFrame.Clone()               ' Update frame objects by saving previous frame and querying a new one
                currentFrame = fingerprintCapture.QueryGrayFrame() ' get new frame

                frameCount += 1
            End While

        End Using
    Next
End Sub
</code></pre>

<p>When updating the code to the newer version of Emgu 3.0.0, I have been struggling to get it to work again.  It seems that the new version has moved away from working with Image classes and prefer the Mat class.  </p>

<p>The updated code compiles but the frames I try to retrieve stays NOTHING.  The adapted code is as follow:</p>

<pre><code>    Private Sub BW_JSD_DoWork(sender As Object, e As System.ComponentModel.DoWorkEventArgs) Handles BW_JSD.DoWork
    Dim CurrentFrameMAT As New Mat()

    Dim frameCount As Integer = 1
    Dim numFrames As Integer                                                 ' video identifier, percentage complete, and number of frame for the video

    Dim filenr As Long = 0

    For Each file As String In lstbAnalysisList.Items
        Dim previousFrameMAT As New Mat()

        filenr += 1

        Using fingerprintCapture As New Capture(file)                                                                   ' Create a capture from file 
            numFrames = CType(Math.Round(fingerprintCapture.GetCaptureProperty(CapProp.FrameCount)), Integer)     ' Get video's total number of frames

            frameCount = 1

            fingerprintCapture.SetCaptureProperty(CapProp.PosFrames, 0)                                   ' Jump to start frame
            CurrentFrameMAT = fingerprintCapture.QueryFrame()

            While fingerprintCapture.GetCaptureProperty(CapProp.PosFrames) &lt; 0.0                          ' Make sure the start frame was found (codecs create problems with the set frame pos function)
                CurrentFrameMAT = fingerprintCapture.QueryFrame()
            End While

            While CurrentFrameMAT IsNot Nothing                                                                            

                If MyFrameAnalysisFunction(currentFrameMAT, previousFrameMAT) = 1 Then
                    MessageBox.Show('This part is irrelevant')
                End If

                previousFrameMAT = CurrentFrameMAT.Clone()     ' Update frame objects by saving previous frame and querying a new one
                CurrentFrameMAT = fingerprintCapture.QueryFrame()

                frameCount += 1
            End While

        End Using
    Next

End Sub
</code></pre>

<p>While debugging,  the CurrentFrameMAT stays nothing.</p>

<p>Any advice on how to read the frames sequentially?</p>

<p>I have seen a function called Grab() and retrieve pertaining to the capture object but could not get it to work.  Where would one start the process?</p>

<pre><code>fingerprintCapture.Start()
fingerprintCapture.Grab() 'Grab a frame
fingerprintCapture.Retrieve() 'Gray image after Grab()
</code></pre>

<p>Any advice or a link to an implementation of the new Emgu version on video / webcam capture would be greatly appreciated!</p>
",,2015-08-12 13:22:47,Analysing frames from a video file using EMGU 3.0.0 in visual basic 2013,<vba><video><video-capture><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
34733,32044741,2015-08-17 07:19:44,,"<p>I am newbie in image processing. I want to do homography my image that I get from capturing camera. Can anyone help me to do homography to my capture image ? Thank so much</p>

<p>This is what I've done and It doesn't work. I'm stuck</p>

<pre><code>Image&lt;Bgr, Byte&gt; RGB_Image = CaptureKamera1.QueryFrame();
Image&lt;Bgr, Byte&gt; destImage = new Image&lt;Bgr, Byte&gt;(352, 288);

imageBox1.Image = RGB_Image;

double[,] srcp = { { 74, 82 }, { 281, 81 }, { 281, 211 }, { 68, 205 } };
double[,] dstp = { { 81, 7 }, { 160, 7 }, { 36, 158 }, { 207, 158 } };
double[,] homog = new double[3, 3];

Matrix&lt;double&gt; srcpm = new Matrix&lt;double&gt;(RGB_Image);
Matrix&lt;double&gt; dstpm = new Matrix&lt;double&gt;(destImage);
Matrix&lt;double&gt; homogm = new Matrix&lt;double&gt;(homog);

CvInvoke.cvGetAffineTransform(srcpm.Ptr, dstpm.Ptr, homogm.Ptr);
CvInvoke.cvPerspectiveTransform(RGB_Image.Ptr, destImage.Ptr, homogm.Ptr);

imageBox2.Image = destImage;
</code></pre>
",,2015-08-25 23:25:34,Homography in Emgu CV 3.0,<emgucv><projection><homography>,,,CC BY-SA 3.0,False,False,True,False,False
34742,32008894,2015-08-14 11:23:55,,"<p>I am using The sobel operator to detect edges in a grayscale image with EmguCV 3.0 (the .NET Wrapper for OpenCV).</p>

<p>The code I am using is</p>

<pre><code>Image&lt;Gray, byte&gt; gray = new Image&lt;Gray, byte&gt;(@""C:\gray.bmp"");
Image&lt;Gray, float&gt; sobel = gray.Sobel(0, 1, 3).Add(gray.Sobel(1, 0, 3)).AbsDiff(new Gray(0.0));
</code></pre>

<p>This is the preprocessed image (gray) <img src=""https://i.stack.imgur.com/5dRfE.jpg"" alt=""""></p>

<p>And this is what I get out (sobel) <img src=""https://i.stack.imgur.com/YOhzU.jpg"" alt=""""></p>

<p>As you can see, the edges in the top-right and the bottom-left corner are very weak. I first thought, it could have something to do with the original image, so I rotated it by 180 degrees and ran the sobel-filter again. The result still has very weak edges in the top-right and the bottom-left corner (unfortunately I am not allowed to post more than two links here, so I can´t show it to you).</p>

<p>So My question is: Is this a bug, or am I using the sobel filter wrong? Should´t it be rotation-invariant, when ran in two dimensions? And how can I fix it, to see these two edges as strong as the other ones?</p>
",2015-08-14 11:26:47,2015-08-14 12:13:27,OpenCV: Sobel filter not rotation invariant,<c#><opencv><image-manipulation><emgucv><sobel>,,,CC BY-SA 3.0,True,False,True,False,False
34777,32158605,2015-08-22 16:57:21,,"<p>I'm using emgu cv 3.0.0 and I would like to capture frames from a USB cam. 
Unfortunately, I get an error while calling <code>Image&lt;Bgr, Byte&gt; image = capture.QueryFrame();</code>
It says, I can't convert from <code>Emgu.CV.Mat</code> to <code>Emgu.CV.Image</code>.</p>
",2015-08-22 17:15:41,2017-02-15 06:03:58,EmguCV capture frames QueryFrame(),<emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
34878,32285200,2015-08-29 10:51:25,,"<p>I do not know the real name of this type of ""QR"" they are used in augmented reality and other tracking applications.
Here is a image of what it looks like.</p>

<p><a href=""https://i.stack.imgur.com/xruir.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xruir.gif"" alt=""http://iplimage.com/blog/approach-encodedecode-black-white-marker/""></a></p>

<p>I want to build a vb.net program that finds as many of this in a image. I do not need to get angels and so. Only a number.
The marker need to handler +10K of numbers and tolerate rotation.</p>
",2015-09-13 12:33:26,2015-09-23 18:42:29,Read code markers of a images,<vb.net><augmented-reality><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
34879,32286024,2015-08-29 12:25:58,,"<p>I want to find outliers in sets of keypoints from matches of consecutive frames. I use EmguCV - a wrapper of <code>OpenCV</code> and <code>Visual Studio Express 2012</code> on Windows 7 64bits.</p>
<p>I tried to use this function</p>
<pre><code>Features2DToolbox.GetHomographyMatrixFromMatchedFeatures, 
</code></pre>
<p>and I get an exception which is shown below: Sometimes this happens after few seconds, Sometimes almost immediately.
<br>Another wierd thing is that even if the function is in <code>try-catch block</code> I can't catch an exception</p>
<p>Here is part of my code:</p>
<pre><code>        m_foundedPreviousSkyKeyPoints = new VectorOfKeyPoint(m_foundedCurrentSkyKeyPoints.ToArray());
        m_matcherSky.Add(m_descriptorsSky);          
        m_detector.DetectAndCompute(m_currentFrame, m_maskForSky, m_foundedCurrentSkyKeyPoints, m_descriptorsSky, false);
        m_maskMatchesSky = new Mat(m_descriptorsSky.Rows, 1, DepthType.Cv8U,1);
        m_matcherSky.KnnMatch(m_descriptorsSky, m_matchesSky, neighboursNumber, null);
        try
        {   
                Features2DToolbox.GetHomographyMatrixFromMatchedFeatures(
                m_foundedPreviousSkyKeyPoints,
                m_foundedCurrentSkyKeyPoints,
                m_matchesSky,
                m_maskMatchesSky,
                10.0d);
        }
        catch (System.AccessViolationException e) //does not catch exception 
        {
            Console.WriteLine(e.Message);
        }
</code></pre>
<p>And the exception I get:</p>
<blockquote>
<p>An unhandled exception of type <code>'System.AccessViolationException'</code> occurred in <code>Emgu.CV.dll</code></p>
<p>Additional information: Attempted to read or write protected memory. This is often an indication that other memory is corrupt.</p>
</blockquote>
<p>I have no idea what is the reason, any help is appreciated</p>
",2020-06-20 09:12:55,2015-08-29 13:13:18,System.AccessViolationException using EmguCV,<c#><opencv><exception><emgucv><access-violation>,,,CC BY-SA 3.0,True,True,True,False,False
34910,32099618,2015-08-19 15:21:24,,"<p>I am trying to implement the SVM example code found 
<a href=""http://www.emgu.com/wiki/index.php/SVM_%28Support_Vector_Machine%29_in_CSharp"" rel=""nofollow"">Here</a>. It is the official example provided at the Emgu CV documentation, but it is for version 1.5 (at least). 
Unless I have been very mistaken, a lot of the classes in this example either work differently in version 3.0.0 or don't exist at all and have been substituted.<br>
One example is the <code>SVMParams</code> class which as shown <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/b1771ec1-9e4b-1cd4-f6fb-ad89643dd50b.htm"" rel=""nofollow"">Here</a> doesn't exist anymore.<br>
Also, the <code>TrainData</code> class has been developed which is the new input of the <code>TrainAuto</code> method of an SVM object, having substituted the <code>Matrix&lt;single&gt;</code> class.
I have tried to implement the example after changing what I believe needed change but the code reaches the <code>bool trained = model.TrainAuto(td, 5);</code> line and returns a Divide by zero exception.</p>

<p>Maybe there are more issues after this line but this is as far as my code compiles.
Here is what I am trying to execute:</p>

<pre><code>private void Classify()
    {
        int trainingSampleCount = 150;
        int sigma = 60;

        #region Generate the training data and classes

        Matrix&lt;float&gt; trainData = new Matrix&lt;float&gt;(trainingSampleCount, 2);
        Matrix&lt;float&gt; trainClasses = new Matrix&lt;float&gt;(trainingSampleCount, 1);

        Image&lt;Bgr, Byte&gt; img = new Image&lt;Bgr, Byte&gt;(500, 500);

        Matrix&lt;float&gt; sample = new Matrix&lt;float&gt;(1, 2);

        Matrix&lt;float&gt; trainData1 = trainData.GetRows(0, trainingSampleCount / 3, 1);
        trainData1.GetCols(0, 1).SetRandNormal(new MCvScalar(100), new MCvScalar(sigma));
        trainData1.GetCols(1, 2).SetRandNormal(new MCvScalar(300), new MCvScalar(sigma));


        Matrix&lt;float&gt; trainData2 = trainData.GetRows(trainingSampleCount / 3, 2 * trainingSampleCount / 3, 1);
        trainData2.SetRandNormal(new MCvScalar(400), new MCvScalar(sigma));

        Matrix&lt;float&gt; trainData3 = trainData.GetRows(2 * trainingSampleCount / 3, trainingSampleCount, 1);
        trainData3.GetCols(0, 1).SetRandNormal(new MCvScalar(300), new MCvScalar(sigma));
        trainData3.GetCols(1, 2).SetRandNormal(new MCvScalar(100), new MCvScalar(sigma));

        Matrix&lt;float&gt; trainClasses1 = trainClasses.GetRows(0, trainingSampleCount / 3, 1);
        trainClasses1.SetValue(1);
        Matrix&lt;float&gt; trainClasses2 = trainClasses.GetRows(trainingSampleCount / 3, 2 * trainingSampleCount / 3, 1);
        trainClasses2.SetValue(2);
        Matrix&lt;float&gt; trainClasses3 = trainClasses.GetRows(2 * trainingSampleCount / 3, trainingSampleCount, 1);
        trainClasses3.SetValue(3);

        #endregion

        using (SVM model = new SVM())
        {
            //changed from example
            model.SetKernel(Emgu.CV.ML.SVM.SvmKernelType.Linear);
            model.Type = SVM.SvmType.CSvc;
            model.C = 1;
            model.TermCriteria = new MCvTermCriteria(100, 0.00001);

            TrainData td = new TrainData(trainData, Emgu.CV.ML.MlEnum.DataLayoutType.RowSample, trainClasses);
            bool trained = model.TrainAuto(td, 5);
            //changes up to this point

            for (int i = 0; i &lt; img.Height; i++)
            {
                for (int j = 0; j &lt; img.Width; j++)
                {
                    sample.Data[0, 0] = j;
                    sample.Data[0, 1] = i;

                    float response = model.Predict(sample);

                    img[i, j] =
                        response == 1 ? new Bgr(90, 0, 0) :
                        response == 2 ? new Bgr(0, 90, 0) :
                        new Bgr(0, 0, 90);
                }
            }
            // changed the GetSupportVectors()
            Mat supvec = model.GetSupportVectors();
            int c = supvec.Height;

            for (int i = 0; i &lt; c; i++)
            {
                // The way the data is received changed as well 
                byte[] b = supvec.GetData(i);
                float[] v = new float[] { (float)b[0], (float)b[1] };

                PointF p1 = new PointF(v[0], v[1]);
                img.Draw(new CircleF(p1, 4), new Bgr(128, 128, 128), 2);
            }
        }

        //display the original training samples
        for (int i = 0; i &lt; (trainingSampleCount / 3); i++)
        {
            PointF p1 = new PointF(trainData1[i, 0], trainData1[i, 1]);
            img.Draw(new CircleF(p1, 2.0f), new Bgr(255, 100, 100), -1);
            PointF p2 = new PointF(trainData2[i, 0], trainData2[i, 1]);
            img.Draw(new CircleF(p2, 2.0f), new Bgr(100, 255, 100), -1);
            PointF p3 = new PointF(trainData3[i, 0], trainData3[i, 1]);
            img.Draw(new CircleF(p3, 2.0f), new Bgr(100, 100, 255), -1);
        }

        Emgu.CV.UI.ImageViewer.Show(img);
    }
</code></pre>

<p>Here is part of the stacktrace that describes the exception</p>

<pre><code>at Emgu.CV.ML.MlInvoke.CvSVMTrainAuto(IntPtr model, IntPtr trainData, Int32 kFold, MCvParamGrid&amp; cGrid, MCvParamGrid&amp; gammaGrid, MCvParamGrid&amp; pGrid, MCvParamGrid&amp; nuGrid, MCvParamGrid&amp; coefGrid, MCvParamGrid&amp; degreeGrid, Boolean balanced)
at Emgu.CV.ML.SVM.TrainAuto(TrainData trainData, Int32 kFold, MCvParamGrid cGrid, MCvParamGrid gammaGrid, MCvParamGrid pGrid, MCvParamGrid nuGrid, MCvParamGrid coefGrid, MCvParamGrid degreeGrid, Boolean balanced)
at Emgu.CV.ML.SVM.TrainAuto(TrainData trainData, Int32 kFold)
</code></pre>

<p>I have no idea why the exception occurs as the data that is used for the method are created as per the example. </p>

<p>Any help will be greatly appreciated.</p>
",2018-01-26 13:28:10,2018-01-26 13:28:10,Emgu CV SVM example not working on version 3.0.0,<c#><svm><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
34951,32255440,2015-08-27 17:04:27,,"<p>I'm using the EmguCV 3.0.0 wrapper to the OpenCV 3.0 library.  I'm using the <code>Mat</code> class in a few places.  Here's an example of a single channel, 8x8 image made of <code>double</code> values:</p>

<pre><code>Mat image = new Mat(8, 8, DepthType.Cv64F, 1);
</code></pre>

<p>The <a href=""http://www.emgu.com/wiki/index.php/Working_with_Images#Getting_or_Setting_Pixels""><code>Image&lt;&gt;</code></a> class provides <a href=""http://www.emgu.com/wiki/index.php/Working_with_Images#Getting_or_Setting_Pixels"">reasonable means for getting and setting pixel values</a>, and the method is identical for the <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/ec1c8c3f-a99c-a082-e794-bb74db961c60.htm""><code>Matrix&lt;&gt;</code></a> class, but it doesn't seem as obvious for the <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/2ec33afb-1d2b-cac1-ea60-0b4775e4574c.htm""><code>Mat</code></a> class.  The only way I've figured out how to set individual pixel is using a mask:</p>

<pre><code>// set two pixel values, (0,0) to 9.0, (2, 3) to 42.0

Matrix&lt;byte&gt; mask = new Matrix&lt;byte&gt;(8,8);
mask.Data[0, 0] = 1;
image.SetTo(new MCvScalar(9.0), mask);

mask = new Matrix&lt;byte&gt;(8,8);
mask.Data[2, 3] = 1;
image.SetTo(new MCvScalar(42.0), mask);
</code></pre>

<p>This is <em>feels</em> like it should be two lines, not six, so I feel like I'm missing something.  Things get even more complicated when the <code>Mat</code> is more than one channel, because <code>Matrix&lt;&gt;</code> is only 2D, so the mask must be used to set the pixel on each channel.</p>

<p>I cannot afford the time or memory to set pixels this way.  <strong>How can I set pixels with a single method call?</strong></p>
",,2017-01-26 16:14:16,How can I get and set pixel values of an EmguCV Mat image?,<c#><image-processing><mat><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
34967,32064351,2015-08-18 05:41:09,,"<p>I have a program on .NET 4 for Windows. I'm trying to port it for Mac computers with mono and Xamarin studio.
I have third-part library <code>EmguCV</code> (it's a wrapper for <code>OpenCV</code> library). I'm using <a href=""http://www.emgu.com/wiki/index.php/Download_And_Installation#Getting_ready"" rel=""nofollow"">official manual</a> to install it. It installs both <code>OpenCV</code> and <code>EmguCV</code> to </p>

<blockquote>
  <p>Library/Python/2.7/site-packages/emgucv/lib</p>
</blockquote>

<p>When I start program in Debug mode from Xamarin - all works fine. It founds all libraries and use it. But when I make program as ""pak"" and run on computer without installed <code>EmguCV</code> - I got ""DLL not found"" exception.</p>

<p>I make my program with this command:</p>

<pre><code>macpack -m:1 -o:. -r:/Library/Frameworks/Mono.framework/Versions/Current/lib/ -r:/Library/Python/2.7/site-packages/emgucv/lib -r:/Library/Python/2.7/site-packages/emgucv/bin -r:Assimp32.dll -r:Assimp64.dll -r:cvextern.dll -r:Emgu.CV.dll -r:Emgu.Util.dll -r:libegl.dll -r:libglesv2.dll -r:OpenTK.dll -r:OpenTK.GLControl.dll -r:RH.AssimpNet.dll -r:RH.HeadEditor.dll -r:RH.ImageListView.dll -r:RH.HeadShop.exe -r:blending.fs -r:blending.vs -r:blendingPl.vs -r:idle.fs -r:idle.vs -r:skelet.vs -r:sprite.png -r:./Libraries -r:./Models -r:./Plugin -r:./Resources -r:./Stages -r:./""Haar Cascades"" -n:HeadShop -a:RH.HeadShop.exe
</code></pre>

<p>My second and third params should attached <code>EmguCV</code> libraries to my pak:</p>

<ul>
<li>-r:/Library/Python/2.7/site-packages/emgucv/lib</li>
<li>-r:/Library/Python/2.7/site-packages/emgucv/bin</li>
</ul>

<p>And when I'm looking inside pak - I find this libraries. However the program still not found it..</p>

<p>I guess trouble in <code>openCV</code> native libraries, but I can't realize what is wrong :( </p>
",2015-08-24 16:30:04,2015-08-24 16:30:04,How to attach third-part libraries in release version,<c#><macos><opencv><xamarin><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
35062,32300790,2015-08-30 20:25:04,,"<p>To classify a large collection of various documents images, Usually two methods are used.
For achieve better performance these methods used GPU programming.</p>

<p><strong>First Method: based on template</strong></p>

<p>In this method, a fixed pattern is extracted from the image and other images are compared with it.
If the similarity is greater than a threshold value, the image will be correctly classified.</p>

<p><em>code:</em></p>

<pre><code>GpuInvoke.MatchTemplate(source, template, imageresult, `Emgu.CV.CvEnum.TM_TYPE.CV_TM_CCOEFF_NORMED, IntPtr.Zero, IntPtr.Zero);`
</code></pre>

<blockquote>
  <p>Problems of First Method:</p>
  
  <p>This method is not invariant to rotate more than 10 degrees. The
  selected pattern in the image may be destroyed. (For example, damage
  caused by punching the document.) If the pattern is too many, the
  performance was reduced.</p>
</blockquote>

<p><strong>The second method: based on image features</strong></p>

<p>In this way certain points of the image selected that are resistant to the changes.
If exist similar points in the other image, the image was classified.</p>

<p><em>code:</em></p>

<pre><code>GpuBruteForceMatcher matcher = new GpuBruteForceMatcher(GpuBruteForceMatcher.DistanceType.L2);

matcher.KnnMatch(gpuObservedDescriptors, gpuModelDescriptors, gpuMatchIndices, gpuMatchDist, 2, null);
</code></pre>

<blockquote>
  <p>Problems of Second Method:</p>
  
  <p>There are similar areas in other images with same feature vector. This
  method have large False Positive A small change in the structure of
  documents makes similar points were destroyed.</p>
</blockquote>

<p>The first method has a high accuracy but for the characterization, has less efficiency.
The second method has low accuracy but for finding the right spots has high performance algorithm.</p>

<p><strong>Questions:</strong></p>

<p>To achieve best accuracy and efficiency focus on which method?
Is there a better approach to classify images of documents?</p>

<p><strong>Considerations:</strong></p>

<p>Because the resolution of document images is 100 dots per inch, using methods based on contour matching and OCR is not useful.
We use OpenCV or Emgu_CV library for image classification.
Images may be rotated more than 10 degrees.</p>

<p><em>samples:</em></p>

<p><a href=""https://i.stack.imgur.com/Hhl99.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Hhl99.jpg"" alt=""sample1""></a></p>

<p><a href=""https://i.stack.imgur.com/JuMA2.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JuMA2.jpg"" alt=""sample2""></a></p>
",,2015-08-30 20:25:04,template matching vs feature matching for document image calssification,<image><opencv><pattern-matching><emgucv><document-classification>,,,CC BY-SA 3.0,True,False,True,False,False
35166,32233838,2015-08-26 18:15:08,,"<p>I use canny on image of a house and then <code>HoughLinesBinary</code> on result.</p>

<p><strong>Original image:</strong></p>

<p><a href=""https://i.stack.imgur.com/70Y44.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/70Y44.png"" alt=""enter image description here""></a></p>

<p><strong>Image after canny:</strong></p>

<p><a href=""https://i.stack.imgur.com/Kzycq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Kzycq.png"" alt=""enter image description here""></a></p>

<p><strong>Lines found by HoughLinesBinary:</strong> </p>

<p><a href=""https://i.stack.imgur.com/A8gmi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/A8gmi.png"" alt=""enter image description here""></a></p>

<p>As you can see it produced many artifacts, but didn't mark straight lines, like the left side of the door</p>

<p>Source:</p>

<pre><code>public static Image&lt;Bgr, byte&gt; split_to_patterns(Image&lt;Bgr, byte&gt; original)
{
    Image&lt;Bgr, byte&gt; res = original.Copy();
    LineSegment2D[] lines =
        original
        .Convert&lt;Gray, byte&gt;()
        .Canny(16, 16)
        .HoughLinesBinary(1,Math.PI/16,1,10,1)[0];
    foreach (LineSegment2D line in lines)
    {
        res.Draw(line,new Bgr(Color.Red),2);
    }
    return res;
}
</code></pre>
",,2015-08-26 18:15:08,HoughLinesBinary doesn't find lines,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
35167,32233918,2015-08-26 18:19:17,,"<p>I'm using the EmguCV 3.0.0 wrapper to OpenCV 3.0.  The EmguCV <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/c3a0fa3e-8fca-3713-1441-330c090a7234.htm"" rel=""nofollow""><code>PCACompute</code></a> method wraps the OpenCV <a href=""http://docs.opencv.org/modules/core/doc/operations_on_arrays.html#pca-operator"" rel=""nofollow""><code>PCA::operator()</code></a> method.</p>

<p>The following code compiles and runs.  The comments should explain the intent just fine.</p>

<pre><code>// Populate the 5 row by 8 column input array (5 samples of 8 dimensions).
// The sample dimensions (columns) vary like this:
//   - low variance: 0, 1, 4, 5, 6, 7
//   - high variance: 2, 3
Matrix&lt;double&gt; input = new Matrix&lt;double&gt;(5, 8);
var r = new Random();
for (int row = 0; row &lt; 5; row++) {
    input.Data[row,0] = r.Next(0, 10);     // low variance
    input.Data[row,1] = r.Next(0, 20);     // low variance
    input.Data[row,2] = r.Next(80, 210);   // high variance
    input.Data[row,3] = r.Next(0, 240);    // highest variance
    input.Data[row,4] = r.Next(20, 21);    // very low variance
    input.Data[row,5] = r.Next(0, 10);     // low variance
    input.Data[row,6] = r.Next(0, 10);     // low variance
    input.Data[row,7] = r.Next(200, 210);  // low variance
}

// create output array for PCACompute()
var eigenvectors = new Matrix&lt;double&gt;(8, 8);

// create *empty* mean array so that PCACompute() calculates its own means
var means = new Mat();

// HERE IS THE MAGIC.
CvInvoke.PCACompute(input, means, eigenvectors);
</code></pre>

<p>But the magic is broken.  <code>eigenvectors</code> is all zeros after all that.  This pretty print code:</p>

<pre><code>// print each eigenvector on its own line
for (int vectorIdx = 0; vectorIdx &lt; eigenvectors.Rows; vectorIdx++) {
    string vectorStr = """";
    for(int dimension = 0; dimension &lt; eigenvectors.Cols; dimension++) {
        vectorStr += eigenvectors.Data[vectorIdx, dimension].ToString() + "", "";
    }
    Console.WriteLine(""{ "" + vectorStr.Substring(0, vectorStr.Length - 2) + "" }"");
}
</code></pre>

<p>gives this output:</p>

<pre><code>{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
</code></pre>

<hr>

<p>In fact, if I set a member of <code>eigenvectors</code> <em>before</em> passing it to <code>PCACompute</code>:</p>

<pre><code>eigenvectors.Data[1,1] = 42;

CvInvoke.PCACompute(input, means, eigenvectors);
</code></pre>

<p>the pretty print shows that <strong><code>eigenvectors</code> was completely untouched by <code>PCACompute</code>:</strong></p>

<pre><code>{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 42, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
{ 0, 0, 0, 0, 0, 0, 0, 0 }
</code></pre>

<p><strong>Is this a bug, or am I doing this wrong?</strong></p>
",2015-08-26 21:36:59,2015-08-26 21:50:11,PCACompute() does not touch the Matrix<> ouput array parameter,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
35238,32449194,2015-09-08 04:15:36,,"<p>I am trying to convert Bitmap to EmguCV Image to load my pictures in ImageBox.</p>

<p>But I got this error:
Cannot implicitly convert type 'System.Drawing.Bitmap' to 'Emgu.CV.IImage'</p>

<p>Then I tried the below syntax after doing some research in SO:</p>

<pre><code>Bitmap masterImage = (Bitmap)pbxMaster.Image;
Image&lt;Gray, Byte&gt; normalizedMasterImage = new Image&lt;Gray, Byte&gt;(masterImage);
</code></pre>

<p>But got these errors:</p>

<ol>
<li><p>The name 'pbxMaster' does not exist in the current context.</p></li>
<li><p>A field initializer cannot reference the non-static field, method, or property 'ContourAnalysisDemo.MainForm.masterImage'</p></li>
</ol>

<p>What did I miss here?</p>
",2015-10-12 07:30:21,2015-10-12 07:30:21,Why conversion from Bitmap to EmguCV Image not working?,<c#><image><bitmap><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
35242,32529451,2015-09-11 17:56:50,,"<p>I'm developing an image recognition application and something is bugging me. </p>

<p>I am working with bitonal images (documents). If I make a copy of the same image file and compare both (actually comparing a sub-region of both [the same sub region]), i don't get 100% matches using SURF. Here's part of my code:</p>

<pre><code>public double FindPercentMatch(Bitmap obj, Bitmap scene)
{

    // get scene key points
    VectorOfKeyPoint scenePoints = GetKeyPoints((Bitmap)scene.Clone());

    // if no scene points found, no need to go any further
    if (scenePoints == null || scenePoints.Size == 0) { return 0; }

    // get object key points
    VectorOfKeyPoint objectPoints = GetKeyPoints((Bitmap)obj.Clone());            

    // if not enough object key points found vs scene key points, then match can't be close enough (since
    // you can't have more matches than scene points anyway, so don't even try to match
    if (objectPoints == null || objectPoints.Size == 0 || (scenePoints.Size / objectPoints.Size &lt; .15)) { return 0; }

    // we have enough key points, so compute descriptors for scene and object
    Matrix&lt;float&gt; objectDescriptors = GetDescriptors(objectPoints,(Bitmap)obj.Clone());
    Matrix&lt;float&gt; sceneDescriptors = GetDescriptors(scenePoints, (Bitmap)scene.Clone());
    int objectDescriptorCount = objectDescriptors == null ? 0 : objectDescriptors.Size.Height;
    int sceneDescriptorCount = sceneDescriptors == null ? 0 : sceneDescriptors.Size.Height;

    // find matches
    int sim = FindMatches(objectDescriptors, sceneDescriptors);

    // for testing so we know how many were found so we can monitor it
    log.Debug(""descriptors1 = "" + objectDescriptorCount + "", 2 = "" + sceneDescriptorCount + "", matches="" + sim);

    double percent = 0;
    if (sim != 0)
    {
        percent = objectDescriptorCount != 0 ? (double)sim / (double)objectDescriptorCount : 0;
        log.Debug(percent * 100 + ""%"");
    }
    return percent;

}

public int FindMatches(Matrix&lt;float&gt; dbDescriptors, Matrix&lt;float&gt; queryDescriptors)
{

    double uniquenessThreshold = 0.6;

    if (dbDescriptors == null || queryDescriptors == null)
    {
        return 0;
    }
    var indices = new Matrix&lt;int&gt;(queryDescriptors.Rows, 2); // matrix that will contain indices of the 2-nearest neighbors found
    var dists = new Matrix&lt;float&gt;(queryDescriptors.Rows, 2); // matrix that will contain distances to the 2-nearest neighbors found

    // create FLANN index with 4 kd-trees and perform KNN search over it look for 2 nearest neighbours
    var flannIndex = new Index(dbDescriptors, 4);

    flannIndex.KnnSearch(queryDescriptors, indices, dists, 2, 24);

    // for eatch match over a certain threshold, add +1 to the number of 'good' matches
    int sim = 0;
    for (int i = 0; i &lt; indices.Rows; i++)
    {
        // filter out all inadequate pairs based on distance between pairs
        if (dists.Data[i, 0] &lt; (uniquenessThreshold * dists.Data[i, 1]))
        {
            sim++;
        }
    }
    return sim;
}
</code></pre>

<p>The expected outcome when using FindPercentMatch on the same sub-region of an image would be 100%, but depending on the image, it may be 70%, 99%, and I've even seen 101%.</p>
",2015-09-15 21:06:31,2015-10-01 04:08:29,Why do exact images not have exact descriptors?,<c#><opencv><image-processing><emgucv><surf>,,,CC BY-SA 3.0,True,False,True,False,False
35290,32339859,2015-09-01 19:53:14,,"<p>I'm using OpenCV 3.0, but my question should be version agnostic.   I'm wondering which of <a href=""https://en.wikipedia.org/wiki/RGB_color_space#Specifications"" rel=""nofollow"">the many</a> RGB color space OpenCV uses by default.
That is, <strong>for images in the <a href=""http://docs.opencv.org/doc/tutorials/core/how_to_scan_images/how_to_scan_images.html#how-the-image-matrix-is-stored-in-the-memory"" rel=""nofollow"">default representation, <code>BGR</code></a>, which RGB space does OpenCV use</strong>?</p>

<p>I suspect they are either the <a href=""https://en.wikipedia.org/wiki/File:CIE_1931_XYZ_Color_Matching_Functions.svg"" rel=""nofollow"">CIE 1931 XYZ functions</a>:</p>

<p><img src=""https://upload.wikimedia.org/wikipedia/commons/8/8f/CIE_1931_XYZ_Color_Matching_Functions.svg"" alt=""CIE XYZ""></p>

<p>or the <a href=""https://commons.wikimedia.org/wiki/File:CIE1931_RGBCMF.svg"" rel=""nofollow"">CIE 1931 RGB functions</a>:</p>

<p><img src=""https://upload.wikimedia.org/wikipedia/commons/6/69/CIE1931_RGBCMF.svg"" alt=""CIE RGB""></p>

<hr>

<p>Heads up: this question is mirrored <a href=""http://answers.opencv.org/question/69902/which-color-matching-functions-does-opencv-use-for-its-rgbbgr-color-space/"" rel=""nofollow"">here</a> (awaiting moderation, as of right now).  I'll make sure any knowledge is shared between them.</p>
",2015-09-01 20:52:28,2017-06-15 15:03:13,Which color matching functions does OpenCV use for its RGB/BGR color space?,<opencv><colors><rgb><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
35323,32417025,2015-09-05 19:44:22,,"<p>I'm trying to create and HSV Histogram using the following code</p>

<pre><code>Mat image = new Mat(file, LoadImageType.Color);
int hBins = 16;
int sBins = 16;
int vBins = 16;
RangeF hRange = new RangeF(0F, 180F); 
RangeF sRange = new RangeF(0f, 255f);
RangeF vRange = new RangeF(0f, 255f);

Image&lt;Bgr, Byte&gt; imageSource = new Image&lt;Bgr, Byte&gt;(image.Bitmap);
Image&lt;Hsv, Byte&gt; imageHsv = imageSource.Convert&lt;Hsv, Byte&gt;(); 

DenseHistogram hist = new DenseHistogram(new int[] { hBins, sBins, vBins }, new RangeF[] { hRange, sRange, vRange });
hist.Calculate&lt;byte&gt;(imageHsv.Split(), false, null); 
</code></pre>

<p>Problem is though, that when calling <code>hist.GetBinValues()</code>, all the values of the bins are zero</p>
",,2015-09-23 17:17:45,HSV Histogram bins equal zero,<emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
35467,32469345,2015-09-09 00:55:51,,"<p>I want to copy an image from camera to anothe imagebox using ROI. I have searched a lot references about ROI but it still doesn't work. Anybody can help me, please ?
These are what I have done</p>

<pre><code>Image&lt;Bgr, Byte&gt; sourceImage1 = CaptureCam1.QueryFrame();
SourceImageBox.Image = sourceImage1;
ImageCopy = new Image&lt;Bgr, Byte&gt;(Template_Box.Width, Template_Box.Height);
sourceImage1.ROI = new Rectangle(SourceImageBox.Location.X, SourceImageBox.Location.Y, SourceImageBox.Width, SourceImageBox.Height);
sourceImage1.CopyTo(ImageCopy);
Template_Box.Image = ImageCopy;
</code></pre>
",,2016-09-12 10:48:35,Copying an Image to PictureBox using ROI EmguCV C#,<emgucv><roi>,,,CC BY-SA 3.0,False,False,True,False,False
35481,32587942,2015-09-15 13:53:34,,"<p>I have been trying to get coordinates as described in:
<a href=""https://stackoverflow.com/questions/16589713/how-to-get-coordinates-of-pixel-after-shape-was-rectified"">How to get coordinates of pixel after shape was rectified?</a>
In Emgu CV 3.0.0.
I am able to warp the image with the following code (stolen from the above link)</p>

<pre><code> Image&lt;Bgr, byte&gt; theWarpedImage = new Image&lt;Bgr, byte&gt;(@""C:\myImage.jpg"");
        PointF[] srcs = new PointF[4];
        srcs[0] = new PointF(1533, 2393);
        srcs[1] = new PointF(4169, 1817);
        srcs[2] = new PointF(1765, 1177);
        srcs[3] = new PointF(3717, 621);

        PointF[] dsts = new PointF[4];
        dsts[0] = new PointF(0, 0);
        dsts[1] = new PointF(2950, 0);
        dsts[2] = new PointF(0, 2100);
        dsts[3] = new PointF(2950, 2100);

        PointF[] test = new PointF[4];

        Mat mywarpmat = CvInvoke.GetPerspectiveTransform(srcs, dsts);
        Image&lt;Bgr, byte&gt; theWarpedImage2 = new Image&lt;Bgr, byte&gt;(@""C:\myImage.jpg"");
        CvInvoke.WarpPerspective(theWarpedImage, theWarpedImage2, mywarpmat, theWarpedImage2.Size, Emgu.CV.CvEnum.Inter.Linear, Emgu.CV.CvEnum.Warp.Default, Emgu.CV.CvEnum.BorderType.Constant, new MCvScalar(0));
</code></pre>

<p>But I can not get the solution given by Luca Del Tongo to work in version 3.0.0.0</p>

<p>Do you have any suggestions?</p>

<p>And Thanks to MIKI:</p>

<pre><code> var test2=CvInvoke.PerspectiveTransform(srcs, mywarpmat);
</code></pre>

<p>Works. </p>
",2017-05-23 12:13:54,2015-09-15 15:44:35,How to get coordinates of pixel after shape was rectified in emgu 3.0.0.0?,<c#><.net><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
35594,32598237,2015-09-16 01:23:02,,"<p>I have an error when I try to start the webcam:
System.TypeInitializationException</p>

<p>When try to:</p>

<pre><code>Dim capWebcam As Capture


 Try
            capWebcam = New Capture()   &lt;&lt;&lt;&lt;&lt;&lt;&lt;here
        Catch ex As Exception
            Me.Text = ex.Message
            Return
        End Try
</code></pre>

<p>I have this DLL added to the project:</p>

<pre><code>opencv -
calib3d240
contrib240
core240
features2d240
ffmpeg240_64
flann240
gpu240
highgui240
imgproc240
legacy240
ml240
nonfree240
objdetect240
photo240
stitching240
videostab240

 And ENGU:
 CV.Stitching
 CV.UI
 CV.GPU
 CV.DebuggerVIsualizers.VS2010
 CV.ML
 CV.OCR
 Util
 CV
</code></pre>

<p>I tried one hundred possibilities and nothing :(</p>

<p>The project has a form that the person can choose an image file or a webcam, choosing colors RGB options and will detect circles, lines and polys.
It is a Big code, but is here (EDIT -> I try to make the code smaller so I delete the code that have no changes in the webcam, if appear some IF that is not closed, maybe is because I edited it):</p>

<pre><code>Option Strict On

Imports Emgu.CV
Imports Emgu.CV.CvEnum
Imports Emgu.CV.Structure
Imports Emgu.CV.UI


Public Class frmForm

'Variaveis

Dim capWebcam As Capture
Dim blnWebcamCapturingInProcess As Boolean = False


'Construtor 
Sub New()
    InitializeComponent()        ' Metodo necessario para instanciar o Design

    intOrigFormWidth = Me.Width
    intOrigFormHeight = Me.Height
    intOrigTableLayoutPanelWidth = tlpLabelsAndImageBoxes.Width
    intOrigTableLayoutPanelHeight = tlpLabelsAndImageBoxes.Height


End Sub


' Metodos dos componentes _____

Private Sub frmForm_Load(sender As Object, e As EventArgs) Handles MyBase.Load, MyBase.Resize


End Sub

Private Sub frmForm_Resize(sender As System.Object, e As System.EventArgs) Handles MyBase.Resize
    'This If Else statement is necessary to throw out the first time the Form1_Resize event is called.
    'For some reason, in VB.NET the Resize event is called once before the constructor, then the constructor is called,
    'then the Resize event is called each time the form is resized.  The first time the Resize event is called
    '(i.e. before the constructor is called) the coordinates of the components on the form all read zero,
    'therefore we have to throw out this first call, then the constructor will run and get the correct initial
    'component location data, then every time after that we can let the Resize event run as expected
    If (blnFirstTimeInResizeEvent = True) Then
        blnFirstTimeInResizeEvent = False
    Else
        tlpLabelsAndImageBoxes.Width = Me.Width - (intOrigFormWidth - intOrigTableLayoutPanelWidth)
        tlpLabelsAndImageBoxes.Height = Me.Height - (intOrigFormHeight - intOrigTableLayoutPanelHeight)
    End If
End Sub


Private Sub rdoImageFile_CheckedChanged(sender As Object, e As EventArgs) Handles rdoImageFile.CheckedChanged
    If (rdoImageFile.Checked = True) Then
        If (blnWebcamCapturingInProcess = True) Then
            RemoveHandler Application.Idle, New EventHandler(AddressOf Me.ProcessImageAndUpdateGUI)
            blnWebcamCapturingInProcess = False
        End If

        ibOriginal.Image = Nothing
        ibGrayColorFiltered.Image = Nothing
        ibCanny.Image = Nothing
        ibCircles.Image = Nothing
        ibLines.Image = Nothing
        ibTrisRectsPolys.Image = Nothing

        lblFile.Visible = True
        txtFile.Visible = True
        btnFile.Visible = True
    End If
End Sub

Private Sub rdoWebCam_CheckedChanged(sender As Object, e As EventArgs) Handles rdoWebCam.CheckedChanged
    If (rdoWebCam.Checked = True) Then
        Try
            capWebcam = New Capture()
        Catch ex As Exception
            Me.Text = ex.Message
            Return
        End Try

        AddHandler Application.Idle, New EventHandler(AddressOf Me.ProcessImageAndUpdateGUI)
        blnWebcamCapturingInProcess = True

        lblFile.Visible = False
        txtFile.Visible = False
        btnFile.Visible = False
    End If
End Sub

Private Sub frmForm_FormClosed(sender As Object, e As FormClosedEventArgs) Handles MyBase.FormClosed
    If (Not capWebcam Is Nothing) Then
        capWebcam.Dispose()
    End If
End Sub

Private Sub btnFile_Click(sender As Object, e As EventArgs) Handles btnFile.Click
    Dim drDialogResult As DialogResult = ofdFile.ShowDialog()

    If (drDialogResult = Windows.Forms.DialogResult.OK Or drDialogResult = Windows.Forms.DialogResult.Yes) Then
        txtFile.Text = ofdFile.FileName
        If (txtFile.Text &lt;&gt; String.Empty) Then
            ProcessImageAndUpdateGUI(New Object(), New EventArgs())
        End If
    End If
End Sub


End Sub


End Class
</code></pre>
",2015-09-16 01:37:06,2015-09-16 01:37:06,System.TypeInitializationException when try -> capWebcam = New Capture(),<vb.net><opencv><visual-studio-2013><64-bit><emgucv>,,,CC BY-SA 3.0,True,False,True,False,True
35599,32479544,2015-09-09 12:26:58,,"<p>I want use EmguCV for image processing.I take camera preview with this code.</p>

<pre><code>   CLEyeCameraImage kamera = new CLEyeCameraImage();
            kamera.ColorMode = CLEyeCameraColorMode.CLEYE_COLOR_PROCESSED;

            kamera.Device.Create(CLEyeCameraDevice.CameraUUID(i));


            kamera.Device.Start();
            kamera.Width = 500;
            kamera.Height = 500;
            InteropBitmap b = kamera.Device.BitmapSource;
            image.Source = b;
</code></pre>

<p>But i can't find how can i use this InteropBitmap in EmguCV for processing.How can i use interopbitmap in EmguCV ?</p>
",,2015-09-16 15:13:47,Use InteropImage in WPF EmguCV,<wpf><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
35689,32603330,2015-09-16 08:26:41,,"<p>I am using EmguCV in C#.NET, and am trying to isolate or detect a white rectangle in an image (photo). We have no control over the quality of the photo's we receive. The plan is to find this rectangle and perform a number of processing steps to increase the chances of the ocr working (we are trying to detect the line of text above the big black box).</p>

<p>Sample image available here:
<a href=""http://imgur.com/Qa0Rzmu"" rel=""nofollow"">http://imgur.com/Qa0Rzmu</a></p>

<p>I have tried many of the tutorials and sample projects - edge detection, sample splitting, LicensePlateRecognition, ShapeDetection, SURFFeature, TrafficSignRecognition. But with no success.</p>

<p>The requirement for this is not real-time, but it can't take 3 hours to process one image either. </p>

<p>I am hoping to pre-process the image, such that a Canny Edge detect and HoughLines and FindContours will return me shapes, and I can find this rectangle based on a minimum size and width-height ratio.</p>

<p>Any help on a strategy to detect the white box will be much appreciated.</p>

<p>Thanks!</p>
",,2015-09-17 09:34:56,Detect white block in image using EmguCV,<image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
35712,32860407,2015-09-30 07:34:40,,"<p>I am using Emgu-CV to identify each person in a big room.
My camera is static and in-door.
I would like to count the number of persons who visited the room, that is I want to recognize each person even if I got the images in different angles at different times in a day.</p>

<p>I am using Haar classifiers to detetct the face, heads and full body from the image and then I am comparing this with the already detected image portions using template matching so that I can recognize the person. But I am getting very poor results. 
Is this the right approach for this problem ? can anyone suggest a better approach ?</p>

<p>Or is there any better libraries available which can solve this problem ?</p>
",,2015-10-01 09:05:58,Human recognition using Template matching,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
35754,32782945,2015-09-25 13:07:34,,"<p>I have an <code>EmguCV.Image&lt;Brg, Byte&gt;()</code> instance and another 3rd party API, that requires <code>Stream</code> that represents the image data.</p>

<p>I was able to convert the EmguCV image to the stream and pass it to the 3rd party API using <code>System.Drawing.Bitmap.Save</code> but that is not very efficient.</p>

<p><strong>How to get the stream as afficietnly as possible?</strong></p>

<p>This code works:</p>

<pre><code>var image = new Image&lt;Rgb, byte&gt;(""photo.jpg"");
var bitmap = image.Bitmap// System.Drawing - this takes 108ms!
using (var ms = new MemoryStream())
{
   bitmap.Save(ms, ImageFormat.Bmp); //not very efficient neither
   ms.Position = 0;
   return ImageUtils.load(ms); //the 3rd party API
}
</code></pre>

<p>I have tried to create <code>UnmanagedMemoryStream</code> directly from the image:</p>

<pre><code>byte* pointer = (byte*)image.Ptr.ToPointer();
int length = image.Height*image.Width*3;
var unmanagedMemoryStream = new UnmanagedMemoryStream(pointer, length);
</code></pre>

<p>but when i try to read from it, it throws an <code>AccessViolationException</code>: Attempted to read or write protected memory.</p>

<pre><code>for (int i = 0; i &lt; length; i++)
{
   //throw AccessViolationException at random interation, e.g i==82240, 79936, etc
   unmanagedMemoryStream.ReadByte();     
}
</code></pre>

<p>the length is 90419328 in this case and it shoudl be correct, because it has the same value as image.ManagedArray.Length;</p>

<p>How to get the stream without copying the data?</p>
",,2015-09-25 14:52:44,How to efficiently get stream from EmguCV (OpenCV) image,<opencv><pointers><stream><unmanaged><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
35811,32868642,2015-09-30 14:24:00,,"<p>I'm using the <a href=""http://www.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow noreferrer"">EMGU CV .NET</a> library. I noticed that when I take pictures of anything with color, the colors usually get ""washed out"" if the background is dark(ish). General rule of thumb I've found is that, the darker the background is, the more washed out the colors are.</p>

<p>Here is how I'm retrieving the image from the camera with EMGU.</p>

<pre><code>Dim imgFeed As Bitmap = mCamera.RetrieveBgrFrame.ToBitmap
</code></pre>

<p>In the images below (cropped out some of the background on both), the left image is on dry white cement and the right image is on wet white cement. You can see the ""washed out"" color especially on the first tag, which is bright orange duct tape.</p>

<p><a href=""https://i.stack.imgur.com/MX8hF.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MX8hF.jpg"" alt=""Colors on dry white cement""></a>
<a href=""https://i.stack.imgur.com/5wWeJ.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5wWeJ.jpg"" alt=""Colors on wet white cement""></a></p>

<p>Here is another image, taken on black pavement in the sun, which in reality is much darker than the white cement, but appears similar in color to the background in the wet cement image above.</p>

<p><a href=""https://i.stack.imgur.com/43zWj.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/43zWj.jpg"" alt=""Gold on pavement""></a></p>

<p>Is there some sort of auto-balancing that's occurring in the EMGU library? If so, can I stop this from happening? I need to see the colors more clearly than the background. I've read about <code>_EqualizeHist()</code> and I implemented it, but that did not help me see the colors any more clearly; adding contrast to the image didn't really help because the colors were already close to white.</p>

<h2>Update</h2>

<p>After reading Spark's answer, I found the <code>SetCaptureProperty()</code> method. I see that you can disable the auto exposure property by setting the value to 0 as shown below.</p>

<pre><code>mCamera.SetCaptureProperty(CvEnum.CAP_PROP.CV_CAP_PROP_AUTO_EXPOSURE, 0.0)
</code></pre>

<p>Sadly though, with the particular camera I'm using, it looks like the driver does not support changing this property.</p>
",2015-10-01 15:23:23,2015-10-01 15:23:23,"Images appear ""washed out"" based on background color, using EMGU Camera library",<vb.net><image><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
35859,32754951,2015-09-24 06:42:38,,"<p>I am using the below code to capture the face <a href=""http://www.codeproject.com/Articles/239849/Multiple-face-detection-and-recognition-in-real"" rel=""nofollow noreferrer"">http://www.codeproject.com/Articles/239849/Multiple-face-detection-and-recognition-in-real</a>. its working as i expected. but i wanted to increase height and weight of detected area.</p>

<p><a href=""https://i.stack.imgur.com/P5Tzb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/P5Tzb.png"" alt=""enter image description here""></a></p>

<p>The below is sample code:</p>

<pre><code>public partial class FrmPrincipal : Form
{
    //Declararation of all variables, vectors and haarcascades
    Image&lt;Bgr, Byte&gt; currentFrame;
    Capture grabber;
    HaarCascade face;
    HaarCascade eye;
    MCvFont font = new MCvFont(FONT.CV_FONT_HERSHEY_TRIPLEX, 0.5d, 0.5d);
    Image&lt;Gray, byte&gt; result, TrainedFace = null;
    Image&lt;Gray, byte&gt; gray = null;
    List&lt;Image&lt;Gray, byte&gt;&gt; trainingImages = new List&lt;Image&lt;Gray, byte&gt;&gt;();
    List&lt;string&gt; labels= new List&lt;string&gt;();
    List&lt;string&gt; NamePersons = new List&lt;string&gt;();
    int ContTrain, NumLabels, t;
    string name, names = null;


    public FrmPrincipal()
    {
        InitializeComponent();
        //Load haarcascades for face detection
        face = new HaarCascade(""haarcascade_frontalface_default.xml"");
        //eye = new HaarCascade(""haarcascade_eye.xml"");
        try
        {
            //Load of previus trainned faces and labels for each image
            string Labelsinfo = File.ReadAllText(Application.StartupPath + ""/TrainedFaces/TrainedLabels.txt"");
            string[] Labels = Labelsinfo.Split('%');
            NumLabels = Convert.ToInt16(Labels[0]);
            ContTrain = NumLabels;
            string LoadFaces;

            for (int tf = 1; tf &lt; NumLabels+1; tf++)
            {
                LoadFaces = ""face"" + tf + "".bmp"";
                trainingImages.Add(new Image&lt;Gray, byte&gt;(Application.StartupPath + ""/TrainedFaces/"" + LoadFaces));
                labels.Add(Labels[tf]);
            }

        }
        catch(Exception e)
        {
            //MessageBox.Show(e.ToString());
            MessageBox.Show(""Nothing in binary database, please add at least a face(Simply train the prototype with the Add Face Button)."", ""Triained faces load"", MessageBoxButtons.OK, MessageBoxIcon.Exclamation);
        }

    }


    private void button1_Click(object sender, EventArgs e)
    {
        //Initialize the capture device
        grabber = new Capture();
        grabber.QueryFrame();
        //Initialize the FrameGraber event
        Application.Idle += new EventHandler(FrameGrabber);
        button1.Enabled = false;
    }


    private void button2_Click(object sender, System.EventArgs e)
    {
        try
        {
            //Trained face counter
            ContTrain = ContTrain + 1;

            //Get a gray frame from capture device
            gray = grabber.QueryGrayFrame().Resize(320, 240, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

            //Face Detector
            MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
            face,
            1.2,
            10,
            Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
            new Size(20, 20));

            //Action for each element detected
            foreach (MCvAvgComp f in facesDetected[0])
            {
                TrainedFace = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;();
                break;
            }

            //resize face detected image for force to compare the same size with the 
            //test image with cubic interpolation type method
            TrainedFace = result.Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
            trainingImages.Add(TrainedFace);
            labels.Add(textBox1.Text);

            //Show face added in gray scale
            imageBox1.Image = TrainedFace;

            //Write the number of triained faces in a file text for further load
            File.WriteAllText(Application.StartupPath + ""/TrainedFaces/TrainedLabels.txt"", trainingImages.ToArray().Length.ToString() + ""%"");

            //Write the labels of triained faces in a file text for further load
            for (int i = 1; i &lt; trainingImages.ToArray().Length + 1; i++)
            {
                trainingImages.ToArray()[i - 1].Save(Application.StartupPath + ""/TrainedFaces/face"" + i + "".bmp"");
                File.AppendAllText(Application.StartupPath + ""/TrainedFaces/TrainedLabels.txt"", labels.ToArray()[i - 1] + ""%"");
            }

            MessageBox.Show(textBox1.Text + ""´s face detected and added :)"", ""Training OK"", MessageBoxButtons.OK, MessageBoxIcon.Information);
        }
        catch
        {
            MessageBox.Show(""Enable the face detection first"", ""Training Fail"", MessageBoxButtons.OK, MessageBoxIcon.Exclamation);
        }
    }


    void FrameGrabber(object sender, EventArgs e)
    {
        label3.Text = ""0"";
        //label4.Text = """";
        NamePersons.Add("""");


        //Get the current frame form capture device
        currentFrame = grabber.QueryFrame().Resize(320, 240, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);

                //Convert it to Grayscale
                gray = currentFrame.Convert&lt;Gray, Byte&gt;();

                //Face Detector
                MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
              face,
              1.4,
              10,
              Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
              new Size(20, 20));

                //Action for each element detected
                foreach (MCvAvgComp f in facesDetected[0])
                {
                    t = t + 1;
                    result = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
                    //draw the face detected in the 0th (gray) channel with blue color
                    currentFrame.Draw(f.rect, new Bgr(Color.Red), 2);


                    if (trainingImages.ToArray().Length != 0)
                    {
                        //TermCriteria for face recognition with numbers of trained images like maxIteration
                    MCvTermCriteria termCrit = new MCvTermCriteria(ContTrain, 0.001);

                    //Eigen face recognizer
                    EigenObjectRecognizer recognizer = new EigenObjectRecognizer(
                       trainingImages.ToArray(),
                       labels.ToArray(),
                       3000,
                       ref termCrit);

                    name = recognizer.Recognize(result);

                        //Draw the label for each face detected and recognized
                    currentFrame.Draw(name, ref font, new Point(f.rect.X - 2, f.rect.Y - 2), new Bgr(Color.LightGreen));

                    }

                        NamePersons[t-1] = name;
                        NamePersons.Add("""");


                    //Set the number of faces detected on the scene
                    label3.Text = facesDetected[0].Length.ToString();

                    /*
                    //Set the region of interest on the faces

                    gray.ROI = f.rect;
                    MCvAvgComp[][] eyesDetected = gray.DetectHaarCascade(
                       eye,
                       1.1,
                       10,
                       Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                       new Size(20, 20));
                    gray.ROI = Rectangle.Empty;

                    foreach (MCvAvgComp ey in eyesDetected[0])
                    {
                        Rectangle eyeRect = ey.rect;
                        eyeRect.Offset(f.rect.X, f.rect.Y);
                        currentFrame.Draw(eyeRect, new Bgr(Color.Blue), 2);
                    }
                     */

                }
                    t = 0;

                    //Names concatenation of persons recognized
                for (int nnn = 0; nnn &lt; facesDetected[0].Length; nnn++)
                {
                    names = names + NamePersons[nnn] + "", "";
                }
                //Show the faces procesed and recognized
                imageBoxFrameGrabber.Image = currentFrame;
                label4.Text = names;
                names = """";
                //Clear the list(vector) of names
                NamePersons.Clear();

            }

    private void button3_Click(object sender, EventArgs e)
    {
        Process.Start(""Donate.html"");
    }
</code></pre>

<p>Suggest me for the best solution. If not What is the other way to do it?
Thanks in Advance!</p>
",,2015-09-26 03:09:10,Is there any way to incease emgu haarcascade square size while detecting face?,<c#><emgucv><windows-applications><face-detection><haar-classifier>,,,CC BY-SA 3.0,False,False,True,False,False
35899,32646180,2015-09-18 07:24:28,,"<p>How can i count unique colors of image ROI.
I try to use Histogram but i don't know how to handle Bin values. Here is my code so far using EMguCV:</p>

<pre><code>image.ROI= new Rectangle(10,10,300,500);
Image&lt;Gray, Byte&gt;[] gray = image.Split(); 
DenseHistogram hist = new DenseHistogram(256, new RangeF(0f, 256f));
hist.Calculate(new Image&lt;Gray, byte&gt;[] { gray[0] }, false, null);
float[] r = hist.GetBinValues();
hist.Calculate(new Image&lt;Gray, byte&gt;[] { gray[1] }, false, null);
float[] g = hist.GetBinValues();
hist.Calculate(new Image&lt;Gray, byte&gt;[] { gray[2] }, false, null);
float[] b = hist.GetBinValues();
</code></pre>

<p>How can calculate r,g,b values to get the number of used colors? </p>
",2015-09-18 08:49:17,2015-09-21 12:22:57,Count unique colors of RGB Image using OpenCV/EmguCV,<opencv><colors><histogram><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
35991,32887661,2015-10-01 12:30:22,,"<blockquote>
  <p><em>Note</em>
  This is not an exact code question its about algorithm writing and
  before people close it down, stack overflow is also about algorithms,
  coding them (and their problems) only comes next. And finding faster or
  optimal code, happens later.. this Q is really about the earliest
  phase of writing code.</p>
</blockquote>

<p>I try to understand how image ""blob"" detection works. 
I am looking for some code explanations, preferable in c#. 
There are several methods I read about. The most simple one might be a binary kinda filter working on black and white images.
As explained here (<a href=""https://en.wikipedia.org/wiki/Connected-component_labeling"" rel=""nofollow"">https://en.wikipedia.org/wiki/Connected-component_labeling</a></p>

<p>However that doesn't solve it for me. 
My images are not black and white, they contain more variations (which i cannt split in 2). And I need to apply some rules at blob detection level that some colours belong to the same group only if they match some logic (based upon color info in that blob), despite being visual complete distinct. </p>

<p>I've looked at Aforge (and tested it) EmguCV, OpenCV, and I've seen examples of Matlab (but I don't have Matlab). However since my image data isn't that good for those filters, as I would later like to add even more extra visual logic / future detecting / color rules etc. </p>

<p>So then I red about people sometimes write their own blob filters and this is what I am now interested in. However besides the Wikipedia article I couldnt find some readable programmers material about this subject. I did find things for mathlab, and some heavy mathematical articles about blob / future detecting. What i am looking for are some ""other"" methods like the Wikipedia article showing some different approaches to blob detection, explained in code. So that i based on such knowledge can create one too.</p>

<p>If someone could point me to some article(s) where people describe  different filter method(s), and isnt about existing aforge/opencv etc. Then i gladly like to learn it.</p>
",,2015-10-01 22:22:11,image blob detection algorithms,<c#><image-processing><aforge>,,,CC BY-SA 3.0,True,True,True,False,False
36094,32817851,2015-09-28 07:36:40,,"<p>I have to use 3rd party native API that takes pointer to <a href=""https://msdn.microsoft.com/en-us/library/windows/desktop/dd183376(v=vs.85).aspx"" rel=""nofollow"">BITMAPINFOHEADER</a> structure and pointer to bitmap data as parameters.</p>

<blockquote>
  <p><code>static Image load ( IntPtr bi, IntPtr img, string name )</code></p>
  
  <p>constructs a image representation from the specified bitmap image in
  memory. The bi pointer points to a BITMAPINFOHEARER followed by an
  optional color table. The existence of a colortable depends on the
  image type. The Byte pointer has to point to bitmap data as described
  by the bitmap information.</p>
</blockquote>

<p><strong>How do I get pointer to the structure representing uncompressed 24bit RGB bitmap with specified size in C#?</strong></p>

<p>I have downloaded the BITMAPINFOHEADER stucture C# decalaration from here: <a href=""http://www.pinvoke.net/default.aspx/Structures/BITMAPINFOHEADER.html"" rel=""nofollow"">http://www.pinvoke.net/default.aspx/Structures/BITMAPINFOHEADER.html</a></p>

<p>I'm actually working with EmguCV image class and I tried to get the BITMAPINFOHEARER describing the image from <a href=""http://www.emgu.com/wiki/files/2.0.0.0/html/a8929aab-99c5-79cf-385c-dcec7769fea1.htm"" rel=""nofollow""><code>Image&lt;Rgb, byte&gt;</code></a>.</p>

<pre><code>var image = new Image&lt;Rgb, byte&gt;(@""myImage.bmp"");

//1. create BITMAPINFOHEADER instance
var bitmapInfoHeader = new BITMAPINFOHEADER
{
    biSize = (uint)Marshal.SizeOf(typeof(BITMAPINFOHEADER)), //40
    biWidth = image.Width, //4096
    biHeight = image.Height, //4096
    biPlanes = 1,
    biBitCount =24,
    biCompression = BitmapCompressionMode.BI_RGB,
    biSizeImage = (uint)image.Bytes.Length,
};

//2. get pointer to the data
IntPtr ptrData;
fixed (byte* pData = image.Data)
    ptrData = (IntPtr)pData;

//3. get pointer to the BitmapInfoHeader:
int iSizeOfBih = Marshal.SizeOf(typeof(BITMAPINFOHEADER));
IntPtr ptrBih = Marshal.AllocHGlobal(iSizeOfBih);
Marshal.StructureToPtr(bih, ptrBih, false);

fixed (byte* pData = image.Bytes)
{
   var frImage = Bmp.load(pBitmapInfoHeader, (IntPtr)pData, ""Frame"");
   var faces = faceTracker.processFrame(frImage);
}
</code></pre>

<p>Although this compiles and runs without exception, it does not load the image correctly (i'm not able to process is later using facetracker.When I used another method to load image from file the facetracker worked)</p>

<p>What am I doing wrong?</p>
",2015-09-29 07:37:07,2015-09-29 08:22:15,How to get BITMAPINFOHEADER from OpenCV image?,<c#><winapi><bitmap><marshalling><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
36159,32938370,2015-10-04 21:01:27,,"<p>I'm Using Emgu.cv for face recognition application. which stores faces images in database and tell the name of picture after recognition. My problem is that it does not tell about unknown person but it automatically match the most relevant face from database and tells the wrong name.</p>

<p>I want to display ""unknown"" string for unknown persons. I used the following code:</p>

<pre><code>  public String Recognize(Image&lt;Gray, Byte&gt; image)
  {
     int index;
     float eigenDistance;
     String label;
     FindMostSimilarObject(image, out index, out eigenDistance, out label);

     return (_eigenDistanceThreshold &lt;= 0 || eigenDistance &lt; _eigenDistanceThreshold )  ? _labels[index] : String.Empty;
  }


  public EigenObjectRecognizer(Image&lt;Gray, Byte&gt;[] images, String[] labels, double eigenDistanceThreshold, ref MCvTermCriteria termCrit)
  {
     Debug.Assert(images.Length == labels.Length, ""The number of images should equals the number of labels"");
     Debug.Assert(eigenDistanceThreshold &gt;= 0.0, ""Eigen-distance threshold should always &gt;= 0.0"");

     CalcEigenObjects(images, ref termCrit, out _eigenImages, out _avgImage);

     /*
     _avgImage.SerializationCompressionRatio = 9;

     foreach (Image&lt;Gray, Single&gt; img in _eigenImages)
         //Set the compression ration to best compression. The serialized object can therefore save spaces
         img.SerializationCompressionRatio = 9;
     */

     _eigenValues = Array.ConvertAll&lt;Image&lt;Gray, Byte&gt;, Matrix&lt;float&gt;&gt;(images,
         delegate(Image&lt;Gray, Byte&gt; img)
         {
            return new Matrix&lt;float&gt;(EigenDecomposite(img, _eigenImages, _avgImage));
         });

     _labels = labels;

     _eigenDistanceThreshold = eigenDistanceThreshold;
  }
</code></pre>
",2015-10-17 08:58:27,2016-08-03 13:40:29,How to use Emgu.cv for Unknown Person?,<c#><emgucv><face-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
36169,33073097,2015-10-12 04:05:26,,"<p>I have this program and at some point, it takes the square root of an image. The program calls CvInvoke.cvSqrt(A.Img.Ptr, Dest.Ptr); where a.img and dest are both cv images.</p>

<p>When the program gets to this line, it throws a dllnotfound exception saying it cant find cvextern. I know that cvextern points to most other cv dlls and so I think that its because of cvinvoke that I am having this problem. The rest of the emgucv stuff works so far, its only cvinvoke that doesnt seem to exist.</p>

<p>I am using ubuntu 14.04 and emgucv version 2.4.9 and monodevelop 3.12</p>

<p>Any help would be appreciated.</p>
",,2015-10-12 04:05:26,cvinvoke dllnotfoundexception using emgucv on ubuntu,<c#><ubuntu-14.04><monodevelop><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
36175,32858601,2015-09-30 05:42:23,,"<p>I want to annotate the camera feed. I am currently using these APIs</p>

<pre><code>Image&lt;Bgr, byte&gt;.Draw();
</code></pre>

<p>However depending on lighting the text is not readable. So I would like to draw the text with a black border and white fill. How do I do this using Emgu?</p>
",,2015-09-30 07:29:37,outline drawing of text using Emgu,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
36265,32966792,2015-10-06 09:45:58,,"<p>I am working with image processing using emgu cv with c#.I want to store my streaming web cam video in a file.I also want to store 20 frames/sec in a file.How can i do this ?Here is my code.</p>

<pre><code>   namespace CamApp
{
    public partial class Form1 : Form
    {
        public Form1()
        {
            InitializeComponent();
        }

        QuBIC.MachineConsciousness.OPCCA.OPCCR occprWnd;//=null;
        Capture capture;// = default(Capture);

        private void button1_Click(object sender, EventArgs e)
        {

            capture = new Capture(0);
            Control.CheckForIllegalCrossThreadCalls = false;
            System.Threading.Thread t = new System.Threading.Thread(Grab);
            t.Start();
            }

        private void Grab() 
        {
            Bitmap bmp,bmp1;
            do 
            {
                bmp = capture.QueryFrame().ToBitmap();
                bmp1 = bmp;
                pictureBox1.Image = bmp;

                int i = 0;


                occprWnd.SetCamImage((Bitmap)bmp.Clone());
                bmp.Save(@""E:\Project\Myapp\CamApp\images\img"" + i + "".jpg"");
                i++;

            }
            while (true);
        }
        private void button2_Click(object sender, EventArgs e)
        {
            occprWnd = new QuBIC.MachineConsciousness.OPCCA.OPCCR();
            occprWnd.Show(this);
        }
    }
}
</code></pre>
",,2015-10-06 09:45:58,Save video from webcam Emgucv with c#,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
36267,32967587,2015-10-06 10:24:46,,"<p>I've installed the EMGU OpenCV library for C#. But when I try to use it, I get a <code>System.IO.FileNotFoundException</code> </p>

<blockquote>
  <p>Additional information: Could not load file or assembly 'Emgu.CV, Version = 2.4.2.1777, Culture = neutral, PublicKeyToken = <code>7281126722ab4438</code>' or one of its dependencies. The system cannot find the file specified.</p>
</blockquote>

<p>Clearly the package installed successfully because if I try to reinstall the package using the NuGet package manager console it says</p>

<pre><code>PM&gt; Install-Package VVVV.EmguCV
'VVVV.EmguCV 2.4.2.1' already installed.
CAIT already has a reference to 'VVVV.EmguCV 2.4.2.1'.
</code></pre>

<p>I don't see the problem here...</p>

<p>EDIT: Oh before you ask, the dll files are in place</p>
",2015-10-06 16:29:47,2015-10-18 22:01:19,Using NuGet Package Manager Console to install EMGU OpenCV for C#,<c#><visual-studio><opencv>,,,CC BY-SA 3.0,True,False,True,False,False
36338,33127581,2015-10-14 14:05:51,,"<p>The goal of a camera calibration is to find the intrinsic and extrinsic parameters:</p>

<ol>
<li>The intrinsic ones are those that describe the camera itself (focal
length, distortion, etc.) I get values for those, no problem.</li>
<li>The extrinsic parameters are basically the position of the camera. When I try to access those I get an <code>AccessViolationException</code>.</li>
</ol>

<p>One way to perform such calibration is to </p>

<ol>
<li>take an image of a calibration target with known corners</li>
<li>find those corners in the image</li>
<li>from the correspondence between 3D and 2D points, find the matrix that transforms one into the other</li>
<li>that matrix consists of the intrinsic and extrinsic parameters.</li>
</ol>

<p>The call to the <a href=""https://i.stack.imgur.com/e6Tvf.png"" rel=""nofollow noreferrer"">calibration function</a> looks like this:</p>

<pre><code>Mat[] rotationVectors = new Mat[1];
Mat[] translationVectors = new Mat[1];

double error = CvInvoke.CalibrateCamera(realCorners,
                                        detectedCorners,
                                        calibrationImages[0].Image.Size,
                                        cameraMatrix,
                                        distortionCoefficients,
                                        0,
                                        new MCvTermCriteria(30, 0.1),
                                        out rotationVectors,
                                        out translationVectors);

Console.WriteLine(rotationVectors[0].Size); // AccessViolationException
</code></pre>

<ul>
<li>I only use one image here, but I have the same problem when using more images (30) Different calibration images would yield different results for <code>translation</code>-/<code>rotationVector</code> anyway, which makes me doubt that using only 1 image is a problem.</li>
<li>The detection of points works and drawing them into the original image gives reasonabel results.</li>
<li>Both <code>cameraMatrix</code> and <code>distortionCoefficients</code> can be accessed and contain values. (I tried to only post the relevant parts of the code)</li>
<li>I use emgu version 3.0.0.2157</li>
</ul>

<p><strong>Why do I get an <code>AccessViolationException</code> on the <code>rotationVectors</code> and  <code>translationVectors</code>?</strong></p>

<p>I placed a breakpoint and found that the internal <code>Data</code> property is <code>null</code>. See screenshot of VS debugger:</p>

<p><a href=""https://i.stack.imgur.com/e6Tvf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/e6Tvf.png"" alt=""enter image description here""></a></p>

<p>That explains why I cannot access it. But <strong>why is it <code>null</code></strong> in the first place?</p>
",2015-10-15 11:43:44,2015-10-16 02:22:06,How do I access the rotation and translation vectors after camera calibration in emgu CV?,<c#><opencv><computer-vision><emgucv><camera-calibration>,,,CC BY-SA 3.0,True,True,True,False,False
36495,33099101,2015-10-13 09:33:33,,"<p>How can I implement image processing with opening and closing using new emgu version?</p>

<p>i found this one:
<a href=""http://www.stackoverflow.com/questions/11567350/opening-and-closing-using-opencv/"">www.stackoverflow.com/questions/11567350/opening-and-closing-using-opencv/</a></p>

<p>but i cant use ""StructuringElementEx"" anymore and the new ""image.MorphologyEx()"" method needs a little more values. </p>

<p>I also tried it with .dilate and .erode but this is only possible with a 3x3 rectangular shape which wasn't quite successful.</p>

<p>An ""updated"" example would be great!</p>
",2015-10-15 10:07:15,2017-01-13 16:38:25,"Image processing with opening and closing using emgu 3.0, MorphologyEx, c#",<c#><opencv><emgucv><background-subtraction>,,,CC BY-SA 3.0,True,False,True,False,False
36596,33107252,2015-10-13 15:54:12,,"<p>Here is the code I am working with currently</p>

<pre><code>Image&lt;Hsv, byte&gt; hsvImage = tempImage.Convert&lt;Hsv, byte&gt;();
Image&lt;Gray, byte&gt;[] channels = hsvImage.Split();
Image&lt;Gray, byte&gt; hue = channels[0];

DenseHistogram hist = new DenseHistogram(255, new RangeF(0, 255));

hist.Calculate&lt;byte&gt;(new Image&lt;Gray, Byte&gt;[] { hue }, true, null);

double[] minV, maxV;
Point[] minL, maxL;
hist.MinMax(out minV, out maxV, out minL, out maxL); //only gets lowest and highest, not most popular
</code></pre>

<p>Now I use the maxL[0].Y and I have some ranges set up to find out what color it is, but these arent numbers I can just pull out of the image directly.  My question is, is there a way to find the most used color with a histogram or will I have to convert the image to black and white and look for the colors I want?</p>
",,2015-10-13 15:54:12,Determine most popular Hue of an image with HSV Histogram Emgu CV 3.0.0.2158,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
36670,33233707,2015-10-20 10:04:58,,"<p>I am trying to remove regions in a black an white image that have number of pixels less  than a threshold.</p>

<p>I found online a solution over here: <a href=""http://www.codeproject.com/Questions/263077/bwareaopen-Matlab-equivelent-in-EMGU"" rel=""nofollow"">http://www.codeproject.com/Questions/263077/bwareaopen-Matlab-equivelent-in-EMGU</a></p>

<p>However in emgu version 3.0 I cannot use this solution because the <strong>Emgu.CV.MemStorage()</strong>  does not exist in EMGU 3.0, and also <strong><em>Contour_&lt;_Point_>_</em></strong> does not exist either.</p>

<p>One solution is to run EMGU 2.4 however is it possible to run this code with EMGU 3.0??</p>

<p>In addition is there any other alternative method to remove white regions of pixel number less than a threshold?</p>

<p>Thank you!</p>
",,2015-10-20 10:04:58,EMGU: remove regions in Black & White Images,<c#><emgucv><contour>,,,CC BY-SA 3.0,False,True,True,False,False
36721,33371729,2015-10-27 15:15:33,,"<p>I'm an EMGU/CV noob using using EMGU3.0 (emgucv-windows-universal 3.0.0.2157), Visual Studio 2013, and a target platform of ""Any CPU"". I'm trying the C# ""hello world"" app at <a href=""http://www.emgu.com/wiki/index.php/Hello_World_in_CSharp#Hello_World_-_Version_2"" rel=""nofollow noreferrer"">http://www.emgu.com/wiki/index.php/Hello_World_in_CSharp#Hello_World_-_Version_2</a> which looks like this:</p>

<pre><code>using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Structure;
using Emgu.CV.UI;
using System.Drawing;

...

//Create a 3 channel image of 400x200
using (Mat img = new Mat(200, 400, DepthType.Cv8U, 3)) 
{
   img.SetTo(new Bgr(255, 0, 0).MCvScalar); // set it to Blue color

   //Draw ""Hello, world."" on the image using the specific font
   CvInvoke.PutText(
      img, 
      ""Hello, world"", 
      new System.Drawing.Point(10, 80), 
      FontFace.HersheyComplex, 
      1.0, 
      new Bgr(0, 255, 0).MCvScalar);

   //Show the image using ImageViewer from Emgu.CV.UI
   ImageViewer.Show(img, ""Test Window"");

}
</code></pre>

<p>It builds OK. But when I ran it I got ""The type initializer for 'Emgu.CV.MatInvoke' threw an exception."" . . . at the line . . .</p>

<pre><code>using (Mat img = new Mat(200, 400, DepthType.Cv8U, 3))
</code></pre>

<p>Also, in the output window there's another clue. Just before the exception there's a message about unmanaged modules . . .</p>

<blockquote>
<pre><code>No suitable directory found to load unmanaged modules

A first chance exception of type 'System.TypeInitializationException'
occurred in Emgu.CV.dll
</code></pre>
</blockquote>

<p>Any idea what's happening here or how to debug it?</p>

<p><strong>Note:</strong> There's a question on SO <a href=""https://stackoverflow.com/questions/10930610/opencv-unmanaged-dlls-not-found-asp-net"">OpenCV Unmanaged DLLs not found asp.net</a> that involves a different error message - ""System.DllNotFoundException"" under different circumstances, (it also has no accepted answers).   That error message is produced by the system but I think the one I'm getting is produced by EMGU itself.   But if any ENGU experts see how that applies to mine I'd appreciate it.  </p>
",2017-05-23 10:27:26,2016-01-07 08:22:58,"What does ""No suitable directory found to load unmanaged modules"" mean in EMGU?",<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
36756,33276963,2015-10-22 08:51:52,,"<p>Is it possible to overlay a scale bar into an image been displayed in WPF using EMGU like in the following picture?</p>

<p><a href=""https://i.stack.imgur.com/tnYfO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tnYfO.png"" alt=""enter image description here""></a></p>

<p>Or like in Bing Maps.</p>

<p>I have images that are 1024x600 size, and I want to display on the image the scale of scale bar (I know the pixel size).</p>

<p>For example in the above image I would like to overlay to my image a green line and say that this line is 5cm. </p>

<p>I know how to do the calculations that relate the length of the line to the actual dimensions, however I don't know how to create that scale bar and overlay it on top of the image.</p>

<p>Any information about what approach I shall follow would be welcome! </p>

<p>Thank you.</p>
",,2015-10-22 18:14:47,Scale Bar in C# WPF with EMGU,<c#><wpf><image><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
36772,33532732,2015-11-04 21:51:01,,"<p>I am using Emgucv 3.0, and include all references and opencv.dll file correctly, but don not know why i can not retrieve frames using Capture object. following screen shot will illustrate my problem. if anyone know how to solve it.<a href=""http://i.stack.imgur.com/z5O88.png"" rel=""nofollow"">Problem screenshot image</a> </p>
",2015-11-05 05:07:27,2015-11-26 09:05:24,Emgu.CV.Capture does not contain definition of RetriveBrgFrame,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
36858,33540142,2015-11-05 08:53:38,,"<p>I have ROI of the image and I need to create new image that would be subpart of image. How can I do that? (I want to make pieces an array of images, not rectangles.)</p>

<pre><code>Image&lt;Bgr, byte&gt; img = frame.Copy();
pieces = new List&lt;System.Drawing.Rectangle&gt;();

int input_cell_width = img.Width / Cols;
int input_cell_height = img.Height / Rows;

System.Drawing.Rectangle old_roi = img.ROI;

for (int row = 0; row &lt; Rows; ++row)
{
    for (int col = 0; col &lt; Cols; ++col)
    {
        // Get template
        img.ROI = gridOuput.GetCellItemRect(row, col, new System.Drawing.Point(0, 0));
        pieces.Add(img.ROI);
    } 
}
</code></pre>

<p>Thanks.</p>
",2015-11-05 09:45:39,2015-11-09 15:00:01,Crop Image in Emgu.CV,<c#><video-processing><emgucv><roi>,,,CC BY-SA 3.0,False,False,True,False,False
36881,33308817,2015-10-23 18:07:18,,"<p>I am trying to figure out how to recognize if a person's arm is swinging/moving towards or away from the Kinect. I'm thinking it is much like a hit or punch towards the sensor.</p>

<p>The depth changes as the arm is going toward or away from the sensor, <strong><em>but how can this gesture be recognized</em></strong>?</p>

<p>I'm using the Kinect for Windows (older version) and SDK 1.8. I have also looked at EMGU (C# wrapper for OpenCV).</p>

<p>Any help answering this question would be greatly appriciated.</p>
",,2015-10-23 18:38:59,Recognize if an arm is swinging/moving towards Kinect sensor or away from it,<c#><opencv><kinect><emgucv><gesture-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
36980,33360027,2015-10-27 04:35:10,,"<p>I am Trying to create a social website. If anyone posted an image the it will detect all the faces in the image and draw a square in the face. Then i want to display the image. My problem is how to preview the image without saving it into a folder. Here is My code</p>

<pre><code>using System;
using System.Collections.Generic;
using System.Linq;
using System.Web;
using System.Web.UI;
using System.Web.UI.WebControls;
using System.IO;
using System.Drawing;

using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.CV.CvEnum;

public partial class User_AddPhoto : System.Web.UI.Page
{
    private HaarCascade haar;

    string base64String;
    Stream fs;
    protected void Page_Load(object sender, EventArgs e)
    {
        string location = Server.MapPath(""~/Bin/"") + ""haarcascade_frontalface_default.xml"";
        haar = new HaarCascade(location);

    }
    protected void Button1_Click(object sender, EventArgs e)
    {
        /*Image Preview */

        //Session[""Image""] = FileUpload1.PostedFile;
        //fs = FileUpload1.PostedFile.InputStream;
        //BinaryReader br = new BinaryReader(fs);
        //byte[] bytes = br.ReadBytes((Int32)fs.Length);
        //base64String = Convert.ToBase64String(bytes, 0, bytes.Length);
        //Image1.ImageUrl = ""data:image/png;base64,"" + base64String;

        /***/

        ////////////////////////////*Detect Face*///////////////////////////
        //DetectFaces();
        Bitmap bmpImage = new Bitmap(fs);
        Image&lt;Bgr, byte&gt; InputFrame = new Image&lt;Bgr, byte&gt;(bmpImage);
        Image&lt;Gray, byte&gt; grayFrame = (InputFrame).Convert&lt;Gray, byte&gt;();

        MCvAvgComp[][] faces = grayFrame.DetectHaarCascade(
            haar,
            1.4,
            8,
            HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
            new Size(20, 20)
            );
        foreach (MCvAvgComp face in faces[0])
        {
            InputFrame.Draw(face.rect, new Bgr(Color.Red), 3);
        }
        Bitmap Display = InputFrame.ToBitmap();
        //Display.Save(Server.MapPath(""~/Images/aaa.jpg""));

        //////////////////////////////////**/////////////////////////////////

        /* Photo Inserting Into Folder and Into Database*/
        BLUser blUser = new BLUser();
        string UserId=Session[""UserId""].ToString();
        string date = DateTime.Now.ToString(""mm-dd_hh_mm_ss"");
        if (FileUpload1.HasFile)
        {
            string Extension = Path.GetExtension(FileUpload1.FileName);
            string ImageName = date;
            string PhotoUrl=""~/Images/Posts/"" + ImageName + Extension;
            FileUpload1.SaveAs(Server.MapPath(""~/Images/Posts/"" + ImageName + Extension));
            blUser.PostImage(PhotoUrl,UserId);
        }
        /**/
    }
}
</code></pre>

<p>But i am in stuck to preview the image. Please Help me someone. Thanks In advance :)</p>
",,2015-10-27 04:59:21,how to preview an image without saving into folder,<c#><asp.net><.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37048,33657853,2015-11-11 18:58:32,,"<p>I'm currently modifying EmguCV's (Ver 3.0.0.2157) SurfFeature example (<a href=""https://github.com/neutmute/emgucv/blob/master/Emgu.CV.Example/SURFFeature/DrawMatches.cs#L33"" rel=""nofollow noreferrer"">Seen here</a>).</p>

<p>I'm trying to determine the amount of matched pairs of points in order to calculate a percentage of similarity between the inputted images.</p>

<p>From what I understand, this information is stored in the <code>mask</code> variable, but I don't know how to access it?</p>

<p>(This question has been asked before <a href=""https://stackoverflow.com/questions/14374423/use-surf-to-match-images-in-opencv-emgucv"">here</a>, but the example source code being referenced is using an older version of EmguCV)</p>

<p>Thanks in advance!</p>
",2017-05-23 12:15:32,2015-12-22 08:09:55,EmguCV SURF - Determine matched pairs of points,<c#><image-processing><emgucv><surf>,,,CC BY-SA 3.0,False,False,True,False,False
37060,33617237,2015-11-09 19:59:02,,"<p>I've been trying to re-scale an Emgu.CV.Mat with depth 32F and value range [0,1] (a grayscale image) to range [0,255] in order to visualize it in a ImageBox object contained in a Visual Basic form, using the code line</p>

<pre><code>ibSuave.Image = imgSuave * 255
</code></pre>

<p>However, Emgu.Cv.Mat doesn't have a Multiply method nor a defined * operator. I'd like to avoid converting the matrix to an Image. How else can I do it?</p>
",2015-11-10 15:48:24,2020-01-23 11:14:56,How to multiply a Mat and a scalar with EmguCV in Visual Basic?,<vb.net><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
37093,33441455,2015-10-30 17:15:25,,"<p><strong>I used this code :</strong></p>
<p><code>rect = faces.DetectMultiScale(src.Clone(), 1.1, 3, new Size(80, 80));</code></p>
<p><strong>instead of :</strong></p>
<p><code>MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(face,1.2,10,Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,new Size(20, 20));</code></p>
<p><strong>and then I want use this code:</strong></p>
<p><code>foreach (MCvAvgComp f in facesDetected[0])</code></p>
<p><strong>How can I convert foreach to my new code style when I use rect ?</strong></p>
",2020-06-20 09:12:55,2015-10-30 17:37:20,converting foreach(MCvAvgComp ...) to foreach for rect,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37094,33442169,2015-10-30 17:58:13,,"<p>I'm getting error in EmguCV is there anyone knows the problem here is my code:</p>

<pre><code>        Image&lt;Bgr, byte&gt; source = new Image&lt;Bgr, byte&gt;(@""D:\work\htdocs\coc\public\Barracks\b6.bmp""); // Image B
        Image&lt;Bgr, byte&gt; template = new Image&lt;Bgr, byte&gt;(@""D:\work\htdocs\coc\public\Barracks\Cropped\b6-1.bmp""); // Image A
        Image&lt;Bgr, byte&gt; imageToShow = source.Copy();

        using (Image&lt;Gray, float&gt; result = source.MatchTemplate(template, Emgu.CV.CvEnum.TM_TYPE.CV_TM_CCOEFF_NORMED))
        {
            double[] minValues, maxValues;
            Point[] minLocations, maxLocations;
            result.MinMax(out minValues, out maxValues, out minLocations, out maxLocations);

            // You can try different values of the threshold. I guess somewhere between 0.75 and 0.95 would be good.
            if (maxValues[0] &gt; 0.9)
            {
                // This is a match. Do something with it, for example draw a rectangle around it.
                Rectangle match = new Rectangle(maxLocations[0], template.Size);
                imageToShow.Draw(match, new Bgr(Color.Red), 3);
            }
        }

        // Show imageToShow in an ImageBox (here assumed to be called imageBox1)
        imageBox1.Image = imageToShow;
</code></pre>

<p>The problem I'm getting is:</p>

<p>Severity    Code    Description Project File    Line
Error   CS0234  The type or namespace name 'TM_TYPE' does not exist in the namespace 'Emgu.CV.CvEnum' (are you missing an assembly reference?)  </p>
",2015-10-31 08:56:03,2015-10-31 08:56:03,Type or namespace TM_TYPE does not exists in Emgu.CV.CvEnum in EmguCV 3.0,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37120,33484981,2015-11-02 19:04:09,,"<p>I have copied a webcam image capture tutorial from the web. It works OK. I want to watch a changing scene and save a captured image to disk when I push a button on the form. The button push is detected, but I am unable to save an image. Here is the main code. I have tried two save methods but neither works. What am I missing?</p>

<pre><code>Sub ProcessFrameAndUpdateGUI(sender As Object, arg As EventArgs)
    imgOriginal = capWebcam.QueryFrame()            'get the next frame from the webcam
    If (imgOriginal Is Nothing) Then                'if we didn't get a frame
        Return
    End If

    If btnStackPressed = True Then                      'is button pressed?
        btnStackPressed = False                         'clear the button
        imgOriginal = capWebcam.QueryFrame()            'get the next frame from the webcam
    End If

    ibOriginal.Image = imgOriginal                      'display the current image in the imagebox
    cvSaveImage(""C:\imagesaved.bmp"", imgOriginal)       'save current image as bmp
    imgOriginal.Save(""C:/MyPic.jpg"")                    'save current image as jpg

End Sub
</code></pre>
",2015-11-03 04:34:35,2015-11-03 23:50:17,emgu cv save image to file in vb,<vb.net><image><save><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37135,33735362,2015-11-16 12:25:47,,"<p>I have error in Image Emgu CV. It Rises after set ROT of Image. Application don't crash and work normally but image data becomes incorrect. It's look like Diagonal distortion<a href=""https://i.stack.imgur.com/2zGfC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2zGfC.png"" alt=""left - correct image, right - diagonal distortion""></a></p>

<p>pic 1. left - correct image, right - diagonal distortion.</p>

<p>Note: it occurs only in certain proportions of ROI (but I have not found explicit pattern)</p>

<p>Code</p>

<pre><code>private void Process(Bitmap newColorFrame)    {
GFrame = new GestureFrame(newColorFrame.Width, newColorFrame.Height);
GFrame.OriginalFrame = newColorFrame;
Emgu.CV.Image&lt;Bgr, Byte&gt; workFrameEmguCV = new Emgu.CV.Image&lt;Bgr, byte&gt;(newColorFrame);
workFrameEmguCV.ROI = GestureSystem.Property.WorkArea;
workFrameEmguCV = workFrameEmguCV.Copy();
CvInvoke.cvResetImageROI(workFrameEmguCV);
Emgu.CV.Image&lt;Gray, Byte&gt; motionFrameEmguCV = MotionDrctr.Tracking(workFrameEmguCV);
GFrame.MotionFrame = motionFrameEmguCV;
}
</code></pre>

<p>what is it?</p>
",2015-11-16 12:50:33,2015-11-16 12:50:33,Diagonal distortion after set ROI EMGU CV,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
37178,33668244,2015-11-12 09:34:43,,"<p>I need to calculate angle of following cropped image.
<a href=""http://i.stack.imgur.com/As7k4.png"" rel=""nofollow"">Image</a> </p>

<p>So I developed C#(emguCV &amp; openCV)  code for calculate angle.</p>

<p>It is here,</p>

<p><strong>For Select pixels of the line,</strong></p>

<pre><code>public ArrayList getLinepixels()
{
   //bi.RotateFlip(RotateFlipType.Rotate90FlipXY);
    testPicBox.Image = bi;
    Color pixelColor;
    ArrayList list = new ArrayList();
    for (int y=0; y &lt;bi.Height; y++)
    {
        int count=0;
        for (int x = 0; x &lt; bi.Width; x++)
        {

            pixelColor = bi.GetPixel(x, y);
            if (pixelColor.R == 255 &amp;&amp; pixelColor.G == 255 &amp;&amp; pixelColor.B == 255)
            {
                count++;
                if (count == 1)
                {
                    Point p1 = new Point(x, y);
                    list.Add(p1);
                    drawPoint(x, y);
                    break;
                }
            }
        }
        int a = list.Count;
       // label2.Text = a.ToString();
    }
</code></pre>

<p><strong>For select appropriate pixel cordinates</strong></p>

<pre><code>public ArrayList minimizePixels(ArrayList minimizeArL)
{
    mlist = new ArrayList();
    int minimizeArlCount = minimizeArL.Count;

    for (int i = 2; i &lt; minimizeArlCount; i++)
    {
        if (i == 2)
        {
            mlist.Add(minimizeArL[i]);
        }
        else if (i == minimizeArlCount - 2)
        {
            mlist.Add(minimizeArL[i]);
        }
        else if (i == (minimizeArlCount / 2) / 2)
        {
            mlist.Add(minimizeArL[i]);
        }
        else if (i == (minimizeArlCount / 2) + ((minimizeArlCount / 2) / 2))
        {
            mlist.Add(minimizeArL[i]);
        }
    }
</code></pre>

<p><strong>Code used for calculating angles</strong></p>

<pre><code>public void calculateAngle(ArrayList angleList)
{
    minimizePixels(getLinepixels());

    int firstRowX = ((Point)mlist[0]).X;
    int firstRowY = ((Point)mlist[0]).Y;

    int secondRowX = ((Point)mlist[1]).X;
    int secondRowY = ((Point)mlist[1]).Y;

    int thirdRowX = ((Point)mlist[2]).X;
    int thirdRowY = ((Point)mlist[2]).Y;

    int fourthRowX = ((Point)mlist[3]).X;
    int fourthRowY = ((Point)mlist[3]).Y;

    double tanTheta;
    double tanAlfa;
    double ang;

    tanTheta = Math.Atan2((Math.Abs(secondRowY - firstRowY)), (Math.Abs(secondRowX - firstRowX)));
    tanAlfa = Math.Atan2((Math.Abs(fourthRowY - thirdRowY)), (Math.Abs(fourthRowX - thirdRowX)));
    ang = (tanTheta + tanAlfa) * (180 / Math.PI);

    metroLabel1_angle.Text = Convert.ToString(ang);
}
</code></pre>

<p>After implementing above codes program shows some value for angle value but each time it runs it is giving different answers and some times incorrect answers. please help me to find a solution for this problem.</p>
",2015-11-15 07:00:40,2015-11-15 07:00:40,calculate angle of objects in a binary image c#,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
37201,33607886,2015-11-09 11:12:39,,"<p>We're making a sign language translator using kinect 1.0 device for my undergrad final year project.
So far we have achieved recognizing gestures in 2D using the skeleton api's in kinect sdk and applied DTW algorithm on it.
We also tracked fingers and distinguished between how many fingers are shown in the frame using contouring and applying convex hull on the contour. We used C# and Emgucv to achieve this.</p>

<p>Now we're stuck at how to transform the data into 3d coordniates. What I don't get is that:</p>

<ol>
<li><p>How the 3d visualization will look like? I mean for now we just use the depth stream and apply a skin classifier on it to show only the skin parts as white pixels and the rest of the objects as black pixels, and we show the contoured and convex hulled area in the color stream. For 3d we'll use the same depth and color stream? If yes then how we'll transform the data and coordinates into 3d?</p></li>
<li><p>For gestures that involve touching of fingers on nose, how will I isolate the contoured area not to include all of the face and just to tell which finger touches which side of nose? Is this where 3d will come in?</p></li>
<li><p>Which api's and libraries are there that can help us in c#?</p>

<p><a href=""http://i.stack.imgur.com/YT74Q.png"" rel=""nofollow"">Extracted Fingers after Contouring and Convex Hull</a></p></li>
</ol>
",2015-11-09 11:20:14,2015-11-09 11:28:00,Recognizing Sign Language in 3D Kinect,<c#><3d><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37202,33608687,2015-11-09 12:03:13,,"<p>I have a 12 bit gray-scale camera and I want to use EMGU to process the image.</p>

<p>My problem is that I want to process the image at ""UInt16""  TDepth and not the usual ""Byte""</p>

<p>So initially I create an empty 2D image:</p>

<pre><code>Image&lt;Gray, UInt16&gt; OnImage = new Image&lt;Gray, UInt16&gt;(960, 1280); 
</code></pre>

<p>then I  create a for loop to transfer my Image from 1D vector form to a 2D image:</p>

<pre><code> for (int i=1; i&lt; 960; i++)
    {
        for (int j = 1; j &lt; 1280; j++)
        {
            OnImage[i, j] = MyImageVector[Counter];
            Counter++;
        }
    } 
</code></pre>

<p>where:</p>

<pre><code>int[] MyImageVector = new int[1228800];
</code></pre>

<p>The problem is at the line :</p>

<pre><code>OnImage[i, j] = MyImageVector[Counter];
</code></pre>

<p>where i get the following error message:</p>

<blockquote>
  <p>Cannot Implicitly convert type ""int"" to ""EMGU.CV.Structure.Gray""</p>
</blockquote>

<p>Why this is happening?</p>

<p>Do you know any way that i can store Int values to an Emgu Image object???</p>

<p>Any alternative workaround would be also helpful.</p>

<p>Thank you</p>
",,2015-11-11 11:43:59,EMGU Gray TColor with UInt16 depth,<c#><arrays><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37204,33739799,2015-11-16 16:12:15,,"<p>I am trying to compute the distance of images in Emgu.CV using the <code>float[] GetEigenDistances(Image&lt;Gray, Byte&gt; image)</code> method.</p>

<p>However I keep getting null values in the distance array. This is the code I have so far:</p>

<pre><code>float[] dist = GetEigenDistances(image);///function call all images are of same sizes

public float[] GetEigenDistances(Image&lt;Gray, Byte&gt; image)
{
    using (Matrix&lt;float&gt; eigenValue = new Matrix&lt;float&gt;(EigenDecomposite(image, _eigenImages, _avgImage)))
        return Array.ConvertAll&lt;Matrix&lt;float&gt;, float&gt;(_eigenValues,
            delegate (Matrix&lt;float&gt; eigenValueI)
            {
                return (float)CvInvoke.cvNorm(eigenValue.Ptr, eigenValueI.Ptr, Emgu.CV.CvEnum.NORM_TYPE.CV_L2, IntPtr.Zero);
            }); 
}
</code></pre>
",2015-11-16 16:30:34,2015-11-16 16:30:34,Getting null values from GetEigenDistances Function,<c#><image><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37218,33815999,2015-11-19 23:03:28,,"<p>I'm trying to get some numbers from an image using EmguCV C#, and to make things easier I'm filtering the numbers and converting them into a black/white image (Im doing that, because after some tests I saw its a lot more precise like that).</p>

<p>Images its failing to recognize:</p>

<p><a href=""https://i.stack.imgur.com/2ooE5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2ooE5.png"" alt=""First image""></a></p>

<p>and</p>

<p><a href=""https://i.stack.imgur.com/WmkRz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WmkRz.png"" alt=""enter image description here""></a></p>

<p>Both images are not been recognized, and its numbers are really clear, not sure, but it shouldn't be a problem for the OCR recognize them, since its recognizing a lot harder images than those.</p>

<p>Here is the code I'm using:</p>

<pre><code>Tesseract ocr = new Tesseract(Application.StartupPath + ""\\tessdata"", ""eng"", OcrEngineMode.Default);
            ocr.SetVariable(""tessedit_char_whitelist"", ""0123456789"");
            ocr.PageSegMode = PageSegMode.SingleLine; //Tested with others types

            Bitmap img = (Bitmap)Bitmap.FromFile(Application.StartupPath + ""\\debug.png"");

            Image&lt;Bgr, Byte&gt; imgg = new Image&lt;Bgr, byte&gt;(img);

            ocr.Recognize(imgg);

            string test = ocr.GetText();

            MessageBox.Show(test);
</code></pre>

<p>Not sure if there is a way to improve the OCR performance on Emgu, or if I just need to be lucky. Any hint or help will be great, Thank you.</p>
",,2019-12-27 15:19:29,EmguCv Ocr failing on easy images,<c#><image><ocr><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37233,33816616,2015-11-19 23:57:32,,"<p>I have a problem to specify the type of variables for ConvexityDefects in EmguCv 3.0 .</p>

<p>I can't find a replacement for Vec4i to declare ""defects"".</p>

<p><code>VectorOfVectorOfInt defects = new VectorOfVectorOfInt()</code> -> This is just another attempt to find the appropriate type.</p>

<p>Every time I have a fatal error:</p>

<p>Exception thrown: 'System.ArgumentException' in mscorlib.dll
No suitable directory found to load unmanaged modules
Exception thrown: 'Emgu.CV.Util.CvException' in Emgu.CV.dll</p>

<p>and the program moves me here, to line with CvException: </p>

<pre><code>
      private static int CvErrorHandler(
         int status,
         IntPtr funcName,
         IntPtr errMsg,
         IntPtr fileName,
         int line,
         IntPtr userData)
      {
         try
         {
            SetErrStatus(Emgu.CV.CvEnum.ErrorCodes.StsOk); //clear the error status
            return 0; //signal the process to continue
         }
         finally
         {
            String funcNameStr = Marshal.PtrToStringAnsi(funcName);
            String errMsgStr = Marshal.PtrToStringAnsi(errMsg);
            String fileNameStr = Marshal.PtrToStringAnsi(fileName);
            throw new CvException(status, funcNameStr, errMsgStr, fileNameStr, line);
         }
      }
</code></pre>

<p>I will be grateful for your help.</p>

<p>Part of my code:</p>

<p><pre><code>using (VectorOfVectorOfPoint contours = new VectorOfVectorOfPoint())
                        {</p>

                        CvInvoke.FindContours(grayImg, contours, null, RetrType.List, ChainApproxMethod.ChainApproxSimple);
                        int count = contours.Size;
                        for (int i = 0; i &lt; count; i++)
                        {
                            using (VectorOfPoint contour = contours[i])
                            using (VectorOfVectorOfInt defects = new VectorOfVectorOfInt())
                            using (VectorOfPoint approxContour = new VectorOfPoint())
                            using (VectorOfPoint hull = new VectorOfPoint())
                            { 
                                CvInvoke.ApproxPolyDP(contour, approxContour, 50, true);
                                CvInvoke.ConvexHull(contour, hull, false);
                                CvInvoke.Polylines(openCvImg, hull, true, new MCvScalar(0, 255, 0), 1, LineType.AntiAlias);
                                CvInvoke.ConvexityDefects(contour, hull, defects);
                            }
                            largest_contour_index = i;
                        }
                        CvInvoke.DrawContours(openCvImg, contours, largest_contour_index, new MCvScalar(0, 0, 255), 1, LineType.EightConnected);
                    }
</code></pre>
",,2016-01-11 21:48:43,CvInvoke.ConvexityDefects() in EmguCV 3.0,<c#><c++><opencv><emgucv><opencv3.0>,,,CC BY-SA 3.0,True,False,True,False,False
37276,33857100,2015-11-22 16:23:05,,"<p>I'm trying to grab all frames from my video in WPF and using emguCV 3.0.</p>

<p>But the Retrive(frame, 0) always returns frame which has null Bitmap? </p>

<p>I guess that the problem occurs in the Capture(string filename) but I don't know why it is.</p>

<p>Can any one explain to me and give me some solutions?
thanks.</p>

<p>Here is my code</p>

<pre><code>Capture _capture;
    private void btnCut_Click(object sender, RoutedEventArgs e)
            {
                _capture = new Capture(@""H:\VisualC\HK5\LT Win\ForTesting\TestCutVideo\bin\Debug\Hay.mp4"");
                _capture.Start();
                //bool isReading = true;
                while (/*isReading*/_capture.Grab())
                {
                    Mat frame = new Mat();
                    _capture.Retrieve(frame, 0);
                    if (frame != null)
                    {
                        imageArray.Add(frame);
                    }

                }

                //to Cut list of frames from video.
                int start = 1, end = 10;
                start = start * (int)_capture.GetCaptureProperty(Emgu.CV.CvEnum.CapProp.Fps);
                end = end * (int)_capture.GetCaptureProperty(Emgu.CV.CvEnum.CapProp.Fps);
                VideoWriter vw = new VideoWriter(""test.mp4"", 15, new System.Drawing.Size(400, 400), true);
                for (int i = start; i &lt;= end; i++)
                {
                    vw.Write(imageArray[i]);
                }
            }
</code></pre>
",2015-11-23 12:32:48,2015-11-27 09:00:26,Wpf - Can't grab frames from a video?,<wpf><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
37290,33635094,2015-11-10 16:42:19,,"<p>I'm using Emgu CV to find an isosceles triangle in an image, from this triangle that's been detected I'm attempting to determine the orientation (front, left, right, and back side) and what the rotation of the triangle is (ex: -30 degrees). </p>

<p><a href=""https://i.stack.imgur.com/mbcpg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mbcpg.png"" alt=""Triangle orientation""></a></p>

<p>I'm able to detect where this triangle is and what each of the three coordinates are, I'm just not sure how to continue on finding orientation and angle of rotation. Would this be a function of Emgu CV, or just simple math; and how would I go about it? </p>
",,2015-11-10 16:46:02,How to determine the orientation / rotation of a triangle?,<c#><coordinates><orientation><emgucv><euler-angles>,,,CC BY-SA 3.0,False,False,True,False,False
37328,33783988,2015-11-18 15:26:59,,"<p>Simply put...Phone is in a static location meaning it is leaned up against the wall on a night stand.</p>

<p>I ultimately want to take two pictures:</p>

<p>Picture A - Background
Picture B - Someone walks into frame and stands there</p>

<p>Problem: When someone walks into frame, the lighting/white balance/ISO takes over and the background dims.</p>

<p>I've tried:</p>

<p>setAutoExposureLock
setWhiteBalanceLock</p>

<p>They ""kind of"" work for the REAR facing camera.</p>

<p>Front facing?  Not at all.  </p>

<p>What am I trying to accomplish?</p>

<p>I'm trying to do background subtraction in EMGUCV using AbsDiff where Picture A is the Background and Picture B is the overlay.</p>

<p>Thanks...I'd add code, but this is more of a ""Can you do this"" type of question.</p>
",2015-11-22 18:49:11,2015-11-22 18:49:11,"With Android camera API, is it possible to get consistent lighting and exposure across images",<android><image-processing><android-camera><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37364,33640938,2015-11-10 22:33:39,,"<p>Here's the problem. We currently allocate managed memory as a byte[]. Using GCAlloc we pin this array down. As part of this we have to align the pointer we pass to a device driVer on a 4K boundary. The device driver reads the data and deposits into this array. We then process from there. I want to use some of the EmguCV SDK as this is a WPF application.</p>

<p>What I cannot figure out is how to get this data into a Mat or CvArray or other object where I can access it. Could anyone give me an idea how to get this pinned data into an EmguCV/OpenCV object for further processing?</p>

<p>Thanks,
Doug</p>
",,2015-11-11 16:58:29,Need an EmguCV structure,<opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
37370,33752888,2015-11-17 09:05:49,,"<p>Currently I am doing my academic Project (Social Media Website). My intention is when a user post an image the system should recognize the face and label it with her name.</p>

<p>As prior work I created 5 users.
For training Images, when a user set her profile photo the system will detect it using EmguCv (DetectHaarCascade) and save the image as a bitmap in a folder. The label of that face will be the User Id of the User, and the label is saved in a text file within the folder.
As training images I uploaded and labeled 10 images for each user.</p>

<p>The next part is when a user post a photo. The system should recognize the face and label it with her name. I am using SVM for recognition and classification.</p>

<p>My detection code:</p>

<pre><code>    //Face Detection
    MCvAvgComp[][] facesDetected = gray.DetectHaarCascade(
                      haar,
                      1.2,
                      4,
                      HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                      new Size(20, 20));
    foreach (MCvAvgComp f in facesDetected[0])
    {
     result = currentFrame.Copy(f.rect).Convert&lt;Gray, byte&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
     // at the beginning i am added all the existing images to an List&lt;Image&lt;Gray, byte&gt;&gt; trainingImages and labels to List&lt;string&gt; labels 
     trainingImages.Add(result );
     labels.Add(Session[""UserId""].ToString())
     File.WriteAllText((Server.MapPath(""~/TrainedFaces/TrainedLabels.txt"")), trainingImages.ToArray().Length.ToString() + ""%"");

       for (int i = 1; i &lt; trainingImages.ToArray().Length + 1; i++)
       {
        //saving the trained images and labells
        trainingImages.ToArray()[i - 1].Save(Server.MapPath(""~/TrainedFaces/"") + ""face"" + i + "".bmp"");
        File.AppendAllText(Server.MapPath(""~/TrainedFaces/TrainedLabels.txt""), labels.ToArray()[i - 1] + ""%"");
       }
   }
</code></pre>

<p>My SVM training code:</p>

<pre><code>/*
1. Loaded all the images to trainingImages
2.Loaded all the labels to labels
*/

// Converting My labesl and images to Matrix for preparing training data and training label    

     Matrix&lt;float&gt; TrainindData = new Matrix&lt;float&gt;(trainingImages.Count, 100 * 100);
        int ii = 0;

        foreach (Image&lt;Gray, float&gt; img in trainingImages)
        {
            int jj = 0;
            Matrix&lt;float&gt; Imagemtrx = new Matrix&lt;float&gt;(img.Width, img.Height);
            img.CopyTo(Imagemtrx);
            for (int k = 0; k &lt; Imagemtrx.Rows; k++)
            {
                for (int j = 0; j &lt; Imagemtrx.Cols; j++)
                {
                    TrainindData.Data[ii, jj] = Imagemtrx[k, j];
                    jj++;
                }
            }
            ii++;
        }
        Matrix&lt;float&gt; TrainedLabels = new Matrix&lt;float&gt;(labels.Count, 1);
        int kk = 0;
        foreach (int lab in labels)
        {
            TrainedLabels[kk, 0] = lab;
            kk++;
        }

     SVM model = new SVM();

     SVMParams p = new SVMParams();
        p.KernelType = Emgu.CV.ML.MlEnum.SVM_KERNEL_TYPE.LINEAR;
        //p.SVMType = Emgu.CV.ML.MlEnum.SVM_TYPE.ONE_CLASS;
        p.SVMType = Emgu.CV.ML.MlEnum.SVM_TYPE.C_SVC;
        p.C = 1;
        p.TermCrit = new MCvTermCriteria(100, 0.00001);

        bool trained = model.Train(TrainindData, TrainedLabels, null, null, p);
</code></pre>

<p>My recognition and classification code:</p>

<pre><code>MCvAvgComp[][] faces=grayFrame.DetectHaarCascade(haar,1.2,10,HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,new Size(20, 20));
foreach (MCvAvgComp face in faces[0])
        {
            InputFrame.Draw(face.rect, new Bgr(Color.Red), 1);
            t = t + 1;
            Image&lt;Gray, float&gt; result = InputFrame.Copy(face.rect).Convert&lt;Gray, float&gt;().Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
            //result._EqualizeHist();
            Matrix&lt;float&gt; TestImageMatix = new Matrix&lt;float&gt;(result.Width, result.Height);
            result.CopyTo(TestImageMatix);
            Matrix&lt;float&gt; TestData = new Matrix&lt;float&gt;(1, result.Width * result.Height);
            int z = 0;
            for (int k = 0; k &lt; TestImageMatix.Rows; k++)
            {
                for (int j = 0; j &lt; TestImageMatix.Cols; j++)
                {
                    TestData.Data[0, z] = TestImageMatix[k, j];
                    z++;
                }
            }
            //Here I will Get the UserId as class label. I can find name from database using this Id
            float result1 = model.Predict(TestData);
</code></pre>

<p>Now the problem is that when I upload an image that belongs to any of existing class, it will correctly recognize and identify the person. But when I post a different photo (of a person that is not there in social media), then it's assigned to one of the existing class label. </p>

<p>My questions are:</p>

<ol>
<li><p>I Want to identify only the right person. Remaining can be labeled as Unknown or something else (I dont Know whether any other method needed or not)</p></li>
<li><p>I read about One Vs One and One Vs All Strategies. Which one is used in my code?</p></li>
<li><p>If no one is used then how to implement them?.</p></li>
<li><p>Emgu CV already includes SVM. Which type is used in It?</p></li>
</ol>
",2015-11-17 10:14:30,2015-11-17 10:14:30,Which strategy is used in EmguCv for SVM Classification?,<c#><opencv><svm><emgucv><face-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
37396,33715981,2015-11-15 03:10:06,,"<p>Using the findContours method I'm ultimately able to outline the human figure.</p>

<p>My sample pictures were used from the creator AForge.Net's website.  Using an absdiff along with findContours I'm able to use CvInvoke.cvDrawContours to actually draw the contours themselves to the screen.</p>

<p>What I would like, however, is access to the points that are being used to draw those contours.</p>

<p>In reference to the image below I want to get those points making up the blue contours.  There has to be some way to get to those no?</p>

<p>This is the relevant code:</p>

<pre><code>    Image&lt;Gray, byte&gt; grayImage = new Image&lt;Gray, byte&gt;(colorImage);
    Image&lt;Bgr, byte&gt; color = new Image&lt;Bgr, byte&gt;(colorImage);

    Image&lt;Bgr, byte&gt; whiteconverter = new Image&lt;Bgr, byte&gt;(blankImage);

    grayImage = grayImage.ThresholdBinary(new Gray(60), new Gray(255));

    grayImage._Not();

    using (MemStorage storage = new MemStorage())
    {
        //add points to listbox
        using (var p2 = new Pen(Color.Yellow, 2))
        {
            var grp = Graphics.FromImage(pictureBox3.Image);

            for (Contour&lt;Point&gt; contours = grayImage.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST, storage); contours != null; contours = contours.HNext)
            {

                Contour&lt;Point&gt; currentContour = contours.ApproxPoly(contours.Perimeter * 0.015, storage);
                CvInvoke.cvDrawContours(whiteconverter, contours, new MCvScalar(255), new MCvScalar(255), -1, 2, Emgu.CV.CvEnum.LINE_TYPE.EIGHT_CONNECTED, new Point(0, 0));

                pictureBox3.Image = whiteconverter.Bitmap;
            }
        }
    }
</code></pre>

<p><a href=""https://i.stack.imgur.com/A1S5B.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/A1S5B.png"" alt=""enter image description here""></a></p>
",,2017-10-05 13:28:15,EMGUCV findContours how to get the points themselves?,<c#><image-processing><emgucv><edge-detection>,,,CC BY-SA 3.0,False,False,True,False,False
37425,33687291,2015-11-13 06:49:33,,"<p>I have a problem which is related to EmguCV to capture the camera view.
My code is below :</p>

<pre><code>Public _capture As Capture
Dim wr As Double
Public _capture As Capture
Dim wr As Double
Dim hr As Double
Dim rtg As Rectangle
Dim _IsOpen As Boolean

Public Sub OpenCamera(selcetCamNum As Integer)
    Try
        If _capture Is Nothing Then
            selectNum = selcetCamNum
            Me._capture = New Capture(selcetCamNum)
            wr = 1
            hr = 1
            rtg = New Rectangle(CInt(105 * wr), CInt(155 * hr), CInt(110 * wr), CInt(50 * hr))
            AddHandler Me._capture.ImageGrabbed, AddressOf ProcessFrame
            Me._IsOpen = True
        End If
    Catch ex As Exception
        MessageBox.Show(""OpenCamera"" &amp; ex.Message)
    End Try
End Sub

Public Sub CameraStart()
    If Me._capture IsNot Nothing Then
        If Me._IsStart = False Then
            'start the capture
            Me._capture.Start()
            Me._IsStart = True
        End If
    End If
End Sub
</code></pre>

<p>I use the usb webcam,and it can be executed successfully, but when I use video capture card(UPMOST-UPG301PB V), it can not be executed successfully, And I insert the break point inside the code, there's no any errors in it. The version of emgu is 2.4.10. Could anybody answer me how to solve the problem??  </p>
",2015-11-13 07:08:08,2015-11-13 07:08:08,How to capture the camera View with video capture card?,<video><camera><webcam><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37438,33720270,2015-11-15 13:33:53,,"<p>i have another question. Idk what is happening buti tried to make Canny edge detector. Problem is that when i want to detect edges on simple shape like square, the program is able to detect it. But when i want to detect shapes on not very simple image program just gives me image filled by only black color. Do you guys have an idea what is going on?</p>

<p>I use this code below:</p>

<pre><code> public Bitmap CannyEdge(Bitmap bmp)
    {
        Image&lt;Gray, Byte&gt; Cannybmp;
        Image&lt;Gray, Byte&gt; GrayBmp;
        Image&lt;Bgr, Byte&gt; orig = new Image&lt;Bgr, Byte&gt;(bmp);
        Image&lt;Bgr, Byte&gt; imgSmooth;
        Bitmap output;

        imgSmooth = orig.PyrDown().PyrUp();
        imgSmooth._SmoothGaussian(3);
        GrayBmp = imgSmooth.Convert&lt;Gray, byte&gt;();

        Gray grayCannyThreshold = new Gray(160.0);
        Gray grayThreshLinking = new Gray(80.0);

        Cannybmp = GrayBmp.Canny(grayCannyThreshold.Intensity, grayThreshLinking.Intensity);
        output = Cannybmp.ToBitmap();

        //int a = 5;
        return output;

    }

private void button1_Click(object sender, EventArgs e)
    {
        Bitmap bmp = new Bitmap(pictureBox1.Image);
        pictureBox2.Image = CannyEdge(bmp);
    }
</code></pre>
",,2015-11-18 08:24:55,EmguCV Canny black window,<c#><emgucv><edge-detection>,,,CC BY-SA 3.0,False,False,True,False,False
37539,33838322,2015-11-21 00:37:05,,"<p>What I am doing is attempting to using EMGU to perform and AbsDiff of two images.</p>

<p>Given the following conditions:</p>

<ol>
<li>User starts their webcam and with the webcam stationary takes a picture.</li>
<li>User moves into the frame and takes another picture (WebCam has NOT moved).</li>
</ol>

<p>AbsDiff works well but what I'm finding is that the ISO adjustments and White Balance adjustments made by certain cameras (even on Android and iPhone) are uncontrollable to a degree.</p>

<p>Therefore instead of fighting a losing battle I'd like to attempt some image post processing to see if I can equalize the two.</p>

<p>I found the following thread but it's not helping me much: <a href=""https://stackoverflow.com/questions/10561222/how-do-i-equalize-contrast-brightness-of-images-using-opencv"">How do I equalize contrast &amp; brightness of images using opencv?</a></p>

<p>Can anyone offer specific details of what functions/methods/approach to take using EMGUCV?</p>

<p>I've tried using things like _EqualizeHist().  This yields very poor results.</p>

<p>Instead of equalizing the histograms for each image individually, I'd like to compare the brightness/contrast values and come up with an average that gets applied to both.</p>

<p>I'm not looking for someone to do the work for me (although code example would CERTAINLY be appreciated).  I'm looking for either exact guidance or some way to point the ship in the right direction.</p>

<p>Thanks for your time.</p>
",2017-05-23 12:15:13,2015-11-21 00:37:05,"How to equalize brightness, contrast, histrograms between two images using EMGUCV",<android><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
37541,33840353,2015-11-21 06:16:38,,"<p>I am using visual Studio 2015. 
I have an Windows Forms Application in Visual C# with lots of code using <a href=""http://www.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow"">EmguCv</a>. 3.0.0.  I am having trouble debugging me code do to the following problem:</p>

<p>When I run this code(With an error)</p>

<pre><code>        string theFileName = @""C:\temp\lena.jpeg"";
        Rectangle theROI = new Rectangle(-1, 0, 42, 42); //&lt;-Error.
        Mat theImage = new Mat(theFileName, Emgu.CV.CvEnum.LoadImageType.Unchanged);
        Mat theExc = new Mat(theImage, theROI);//&lt;-Here the program just stops with no error.
</code></pre>

<p>The program just stops. I do not get any indication where there is an error.</p>

<p>Sometimes i get an Emgu.Cv.Util has throw on excpetion. But no hints what line of code gave the problem. I don´t want to debug Emgu I want to find errors in my own code.</p>

<p>I have used both setting on ""Enable Just My Code""</p>

<p>The Output window just writes:
The program '[25312] VisionBox.exe' has exited with code 0 (0x0).</p>

<p>I am using </p>

<p>Microsoft Visual Studio Community 2015</p>

<p>Version 14.0.23107.0 D14REL</p>

<p>Microsoft .NET Framework</p>

<p>Version 4.6.01038</p>

<p>I have used Both:
Debug...Any CPU and
Debug..x64 
With the same result.
Also tried:</p>

<pre><code>            try
        {
            string theFileName = @""C:\temp\lena.jpeg"";
            Rectangle theROI = new Rectangle(-1, 0, 42, 42); //&lt;-Error.
            Mat theImage = new Mat(theFileName, Emgu.CV.CvEnum.LoadImageType.Unchanged);
            Mat theExc = new Mat(theImage, theROI);//&lt;-Here the program just stops with no error.
        }
        catch (Exception ee)
        {

            var theMessage = ee.Message;
        }
</code></pre>

<p>Does not work. I never get the Exception.</p>

<p>I also tried:
1. Create a new Windows Form Application. File->New->Project. Selecting ""Windows Form Application"" Ok.</p>

<ol start=""2"">
<li><p>Add Reference Emgu.CV.dll and Emgu.Util.dll.</p></li>
<li><p>Copying the x64 and x86 folder from the Emgu folder to the folder of the exe file from the project.</p></li>
<li><p>Add button to form and copying the code from above to the button1_Click function</p></li>
<li><p>Adding using Emgu.CV to Form1.cs</p></li>
<li><p>F5. ->  press button</p></li>
</ol>

<p>Result: The program stops and the output windows writes:""Exception thrown: 'Emgu.CV.Util.CvException' in Emgu.CV.dll
The program '[21552] WindowsFormsApplication2.vshost.exe' has exited with code 0 (0x0).
""</p>

<p>What is working is if I follow the steps above but using Visual Studio 2012</p>
",2015-11-21 09:11:00,2015-11-21 09:11:00,Visual studio debugging dll not stopping,<c#><debugging><visual-studio-2015><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
37620,34020299,2015-12-01 12:18:49,,"<p>Basically, what I'm trying to do is to create a window with list of images and large image view box. If user points at one of the images in the list, imagebox should display it, otherwise it should display live feed from a webcam.</p>

<p>I'm trying to achieve that by using ImageGrabbed event of EmguCV.Capture, and a field that stores index of the currently viewed image. Camera feed works alright, however, when I move the mouse over listbox, image view merely stops updating. It stays stuck at the last frame it saw, and doesn't display the image I'm pointing at. I've checked that the list has images in it, that index is correct, and that image coming from the camera is different from ones saved in the list. Also, same behavior happens when I use vanila PictureBox.</p>

<p>See the code (stripped of extra parts) below.</p>

<p>Initialization:</p>

<pre><code>int ViewedFrame = -1;
var Frames = new List&lt;Image&lt;Rgb, byte&gt;&gt;();
// This list will have some images added to it along the way.
// They will be displayed in a custom drawn ListBox bound to the list.
Camera = new Emgu.CV.Capture(cameraid);
Camera.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, width);
Camera.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, height);
Camera.ImageGrabbed += UpdateCamera;
Camera.Start();
</code></pre>

<p>Frame capture:</p>

<pre><code>private void UpdateCamera(object sender, System.EventArgs ev)
{
    if (ViewedFrame == -1)
        Preview.Image = Camera.RetrieveBgrFrame();
    else
        // !!! this line has no apparent effect, image in the ImageBox is still the same
        Preview.Image = Frames[ViewedFrame]; 
}
</code></pre>

<p>Mouse handling:</p>

<pre><code>private void FrameList_MouseMove(object sender, MouseEventArgs e)
{
    int index = FrameList.IndexFromPoint(e.Location);
    if (index == ListBox.NoMatches)
       ViewedFrame = -1;
    else if (index != ViewedFrame)
    {
        ViewedFrame = index;
    }
}

private void FrameList_MouseLeave(object sender, EventArgs e)
{
    ViewedFrame = -1;
}
</code></pre>

<p>UPD: I tried adding <code>Preview.Update()</code> and <code>Preview.Refresh()</code> into the same branch as Frames[ViewedFrame], and after the conditional operator. In first case it doesn't have any effect. In second case nothing is shown at all. In case the ImageBox can't keep up updating itself, I enabled doublebuffering, but that didn't help either. Moreover, after I hover the mouse over an image in the list, the camera stream breaks too. The code above is the only one that's somewhat working.</p>
",2015-12-02 10:54:17,2015-12-02 10:54:17,Problems with creating combined image view / camera view window using EmguCV & Windows Forms,<c#><.net><winforms><c#-4.0><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37661,33944902,2015-11-26 18:16:16,,"<p>I have a C# WPF MVVM application that needs to record and take pictures. The camera is an industrial camera <a href=""http://www.sentechamerica.com/En/Cameras/USB/STC-MCA5MUSB3"" rel=""nofollow"">STC-MCA5MUSB3</a>.</p>

<p>The only experience I have with image manipulation is with OpenCV in C++, so I am thinking about using <a href=""http://www.emgu.com/wiki/index.php/Main_Page"" rel=""nofollow"">Emgu</a>, which is just OpenCV for C#, but I feel like this might be too much.</p>

<p>My program has to show a preview of the image in a 400x300 pixels and be able to take 5MP pictures and record Full HD 1920x1080 movies. </p>

<p>The algorithm I have in my mind is:</p>

<ol>
<li><p>Receive a 5MP frame from the camera.</p></li>
<li><p>If the user pressed the ""Take Picture"" button, save this frame on the pictures folder.</p></li>
<li><p>Scale down the frame to Full HD and pass it to a library that will add this frame to a movie, like a pipeline, and recorded it in real time in the computer's HDD.</p></li>
<li><p>Scale down the frame to 400x300px and show it in the preview area in the screen.</p></li>
</ol>

<p>I am afraid this might be too much for the computer to process, specially in C#, so I am open to suggestion on the algorithm and on libraries.  </p>
",,2015-11-26 18:16:16,How to record a video with C#,<c#><image-processing><video-capture><emgucv><video-encoding>,,,CC BY-SA 3.0,True,False,True,False,False
37709,33988147,2015-11-29 21:08:37,,"<p>For a current medical project I want to filter vaskularisation images to only show red and blue color. If possible I would also like to only show colored blobs over a certain size. In the following Images I have an example for one of these pictures I would like to analyse:
<a href=""http://i.stack.imgur.com/qtXLL.png"" rel=""nofollow"">Vaskularisation</a>. 
I managed to filter it sofar that most of the noise is gone:
<a href=""http://i.stack.imgur.com/xr1RD.png"" rel=""nofollow"">Filtered Image</a>
. Now I would like to count the <strong>colored</strong> blobs in this image and display all which are bigger that a custom defined threshold. I am using EmguCV in C# for the image editing, but I have not found a way to select only the colored blobs. I would be grateful for any suggestions!</p>
",,2015-11-29 21:08:37,EmguCV filter image for certain colors,<c#><image><filtering><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37768,34030786,2015-12-01 21:45:03,,"<p>Can anyone tell me which USB camera they have had success with when using the Capture functions of OpenCV/EmguCV 3.0? I have tried my Trust Webcam 1080p and Gearhead WC8500HD 1080p cameras and neither one works. </p>

<p>I know the capture capabilities of OpenCV/EmguCV work but it seems identifying the correct camera is not so easy. Maybe a 1080p HD camera is the problem? I have USB2 and USB3 so I don't think that's the problem. It cannot even connect to my integrated camera on my laptop!All the cameras work with AMCAP.</p>

<p>I am using Windows 7 x64 Professional, OpenCV/EmguCV 3.0 Visual Studio 13 C#</p>

<p>TIA,
Doug</p>
",,2015-12-02 01:31:28,What webcam works with OpenCV/EmguCV,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
37805,34033718,2015-12-02 02:10:06,,"<p>Granted I am learning OpenCV/EmguCV and actually prefer EmguCV as the wrapper is quite nice. </p>

<p>But, lots of the examples/tutorials found out on the web are for version 2.X and do not compile under version 3.0. Things like Contour is not supported in version 3. Is there a document/web site that anyone can point me to so I spend less time porting and more time actually learning and doing?</p>
",2016-01-12 19:20:21,2017-01-14 11:12:24,OpenCV/EmguCV Version 2 to OpenCV/EmguCV Version 3 conversion,<emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
37813,34190594,2015-12-09 22:56:15,,"<p>I'm currently using EmguCV to run shape detection on an image of a shooting range target: <a href=""https://i.stack.imgur.com/LKLOd.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LKLOd.gif"" alt=""enter image description here""></a> </p>

<p>But no matter my settings in the code (below):</p>

<p><code>double cannyThreshold = 180;
double circleAccumulatorThreshold = 170;
CircleF[] circles = CvInvoke.HoughCircles(uimage, HoughType.Gradient, 2.0, 1.0, cannyThreshold, circleAccumulatorThreshold, 5);</code></p>

<p>I can only seem to find three circles, of which one is wrong.
<a href=""https://i.stack.imgur.com/NUN34.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NUN34.png"" alt=""enter image description here""></a></p>

<p>Am I going about this incorrectly? I'm using the default example for shape detection included with <a href=""http://www.emgu.com/wiki/index.php/Shape_(Triangle,_Rectangle,_Circle,_Line)_Detection_in_CSharp"" rel=""nofollow noreferrer"">Rev3.0 EmguCV</a>. </p>
",,2015-12-10 05:48:54,Detecting Circles within an image,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
37903,34004864,2015-11-30 17:52:47,,"<p>guys, recentlty I am doing a C# project with the SURF algorithm of emgucv.</p>

<p>I met a problem with this sentence:</p>

<pre><code>BruteForceMatcher&lt;float&gt; matcher = new BruteForceMatcher&lt;float(DistanceType.L2);
</code></pre>

<p>Error is:</p>

<blockquote>
  <p><strong>The non-generic type 'Emgu.CV.Features2D.BruteForceMatcher' cannot be used with type arguments</strong></p>
</blockquote>

<p>The example of emgucv is written like this, I just copy this sentence, and I try to check the definition of bruteForeceMatcher, it is non-generic, but how can the example run?</p>

<p><em>I guess there is maybe new version of Opencv? This method duplicated? Can somebody help me?</em>
Thank you !</p>
",,2015-11-30 18:29:40,(emgucv) Error BruteForceMatcher is non-generic?,<c#><opencv><emgucv><surf>,,,CC BY-SA 3.0,True,False,True,False,False
37935,34120260,2015-12-06 17:13:36,,"<p>I'm attempting to translate the following OpenCV C++ code into Emgu CV 3:</p>

<pre><code>std::vector&lt;std::vector&lt;cv::Point&gt; &gt; contours;
std::vector&lt;cv::Vec4i&gt; v4iHierarchy;

cv::findContours(imgThreshCopy, contours, v4iHierarchy, cv::RETR_TREE, cv::CHAIN_APPROX_SIMPLE);
</code></pre>

<p>I can find some Emgu CV 3 examples that use null for the 3rd parameter to findContours, for example doing it that way here would be a Visual Basic translation:</p>

<pre><code>Dim contours As New VectorOfVectorOfPoint()

CvInvoke.FindContours(imgThreshCopy, contours, Nothing, RetrType.Tree, ChainApproxMethod.ChainApproxSimple)
</code></pre>

<p>Which works if the hierarchy parameter is not needed, but what if it is?  I can't seem to figure the Emgu CV 3 syntax equivalent for the C++ line</p>

<pre><code>std::vector&lt;cv::Vec4i&gt; v4iHierarchy;
</code></pre>

<p>Anybody else gotten this to work?  Any help would be appreciated.</p>
",,2017-06-14 16:22:12,Emgu CV 3 findContours and hierarchy parameter of type Vec4i equivalent?,<emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
37945,34162695,2015-12-08 17:53:58,,"<p>I am working on a Project where I want an User to be able to import a Video. Every time, when I choose the video I want to import, <code>public class CvString : UnmanagedObject</code> is throwing me a <code>System.TypeInitializationException</code> Error. This does not depend on the Data Type, it doesn't work for pics, like <code>.jpeg</code> or <code>.png</code>, nor does it work for any videoformat I have tried (<code>.avi``.mp4``.wmp</code>)</p>

<p>This is the snippet where I want to load and display the video (own written code)</p>

<pre><code>OpenFileDialog ofd = new OpenFileDialog();
Capture _capture;
Timer My_Time = new Timer();
int FPS = 30;
public Form1()
{
    InitializeComponent();
    //Frame Rate
    My_Time.Interval = 1000 / FPS;
    My_Time.Tick += new EventHandler(timer1_Tick);
    My_Time.Start();

    _capture = new Capture(""20151102_110553.mp4"");

}

private void timer1_Tick(object sender, EventArgs e)
{
    imageBox1.Image = _capture.QueryFrame();
}


private void openFileDialog1_FileOk(object sender, CancelEventArgs e)
{
    _capture = new Capture(openFileDialog1.FileName.ToString());
}

private void button2_Click(object sender, EventArgs e)//Import-Button
{
     openFileDialog1.ShowDialog();
}
</code></pre>

<p>And here is the Method where the Exception is thrown (code from Emgu.CV)</p>

<pre><code>namespace Emgu.CV
{
   public class CvString : UnmanagedObject
   { 
        private bool _needDispose;

        internal CvString(IntPtr ptr, bool needDispose)
        {
             _ptr = ptr;
             _needDispose = needDispose;
        }

        public CvString(String s)
        {
        if (s == null)
            {
                _ptr = CvInvoke.cveStringCreate();
            }
        else
        {
            byte[] bytes = Encoding.UTF8.GetBytes(s);
            Array.Resize(ref bytes, bytes.Length + 1);
            bytes[bytes.Length - 1] = 0; //The end of string '\0' character
            GCHandle handle = GCHandle.Alloc(bytes, GCHandleType.Pinned);
            _ptr =CvInvoke.cveStringCreateFromStr(handle.AddrOfPinnedObject());
            // ^ Exception is thrown ^
            handle.Free();
        }

        _needDispose = true;
    }
</code></pre>

<p>I have already tried importing the videos or pictures into my project, importing it directly while starting the project, or by using an <code>OpenFileDialog</code> to choose the file while running, but with the same results. As soon as I choose a file and want to load it into my project, the Exception is thrown.</p>

<p><strong>EDIT : Stack Trace added</strong></p>

<p>Stack Trace</p>

<pre><code>No suitable directory found to load unmanaged modules
Exception thrown : ""System.DllNotFoundException"" in Emgu.CV.dll
Exception thrown : ""System.TypeInitializationException"" in Emgu.CV.dll
Thread 0xa64 ended with Code 0 (0x0).
Exception thrown : ""System.TypeInitializationException"" in Emgu.CV.dll
Exception thrown : ""System.TypeInitializationException"" in Emgu.CV.dll
Exception thrown : ""System.TypeInitializationException"" in Emgu.CV.dll
</code></pre>
",2015-12-08 18:54:28,2015-12-09 11:39:35,TypeInitializationException trown while importing Video with EmguCV,<c#><exception><video><exception-handling><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
37957,34240349,2015-12-12 13:27:22,,"<p>I am writing a program with EmguCv and C# to detect some pattern from a video stream. At first I am trying to import the video into the project, but after a few seconds, the program freezes and doesn't load any further. </p>

<p>I really don't know, but I <strong>think</strong> that it <em>might</em> be because I do something wrong while importing the video, most of all because the program uses 2 GB of RAM after 14 seconds</p>

<p><a href=""https://i.stack.imgur.com/f1ntB.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/f1ntB.jpg"" alt=""enter image description here""></a></p>

<p>To import the video and display it to the GUI, I am using this code:</p>

<pre><code>private void timer1_Tick(object sender, EventArgs e) 
{
     Orginal.Image = _capture.QueryFrame();         
}

private void openFileDialog1_FileOk(object sender, CancelEventArgs e)
{
    _capture = new Capture(openFileDialog1.FileName.ToString());
}

private void button2_Click(object sender, EventArgs e)//Import-Button
{
    openFileDialog1.ShowDialog();
    string _FilePath = openFileDialog1.FileName.ToString();
    textBox1.Text = _FilePath;
}

private void button1_Click(object sender, EventArgs e) //Start-Button
{
    My_Time.Interval = 1000 / FPS;
    My_Time.Tick += new EventHandler(timer1_Tick);
    My_Time.Start();
    _capture = new Capture(openFileDialog1.FileName.ToString());
}
</code></pre>

<p>Is this the right way to import a video, or is there a better way?</p>

<p>The exception with it thrown reads the following :</p>

<blockquote>
  <p>Emgu.CV.Util.CvException in Emgu.CV.dll(""OpenCV: Failed to allocate
  6220800 bytes"")</p>
</blockquote>
",2015-12-12 16:03:43,2015-12-13 16:16:28,Can't allocate enough memory while importing video to project,<c#><memory-management><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
37998,34127755,2015-12-07 06:34:20,,"<p>I want to write an Image Processing App for <strong>Windows Phone</strong> in any of the below framework:</p>

<ul>
<li>*Windows Phone 8.0/8.1 Silverlight </li>
<li>Windows Phone 8.1 (Runtime) </li>
<li>Windows Universal 8.1*</li>
</ul>

<p>Languages I know are <strong>C#</strong> and <strong>XAML</strong></p>

<p>I downloaded OpenCv,EmguCv but all are in C++. Now I got OpenCV for WindowsUniversal but its in c++. Then I got OpenCV for windows in C# but it has forms and cannot be used to write Windows Store App.</p>

<p>I am confused like hell. From where to start. Kindly guide.</p>
",,2015-12-07 11:45:21,Image Processing App for Windows Phone,<c#><opencv><windows-phone-8.1><windows-phone><emgucv>,2015-12-07 13:19:07,,CC BY-SA 3.0,True,False,True,False,False
38011,33975201,2015-11-28 18:57:01,,"<p>I am trying to stitch together very large mosaic images in C#. I've tried using the EmguCV C# libraries but there is a serious problem in that apparently (?) you cannot disable 'wave correction' from C# which causes memory overload (related post/discussion <a href=""https://stackoverflow.com/questions/19978108/opencv-emgucv-big-image-stitching"">here</a>). </p>

<p>Questions:</p>

<ol>
<li>Basically, is there any way to turn off the wave correction (set the option to 'false') from C# ?? </li>
<li>Can anyone point me to working C# stitching code for very large mosaicing? My application is very simple it's just scanning so there is no distortion, equal overlaps, etc., but it has to be pretty close to pixel-accurate. I've looked all over the net and can't find anything for larger mosaics.</li>
</ol>

<p>More comments:</p>

<ol>
<li>I've tried using Accord.NET but it appears to be only 32 bit code thus won't work for large images. Must be 64bit. I'm really kind of shocked that Accord.NET is not 64bit unless hopefully i'm missing something...</li>
<li>I've tried using openCV directly using C++ but can't mix it with my year-long development of my main code in C#. I tried making a dll in C++ but I'm no good at C++ and couldn't seem to even get it close to working.</li>
<li>I would like to be able to stitch 10x10, 3000x2000 pixel images. I've got plenty of ram, up to 32Gb if needed.</li>
</ol>

<p>Thanks very much for any info. </p>
",2017-05-23 12:01:05,2018-10-03 19:24:39,Image stitching 6x6 images,<c#><opencv><image-processing><emgucv><accord.net>,,,CC BY-SA 3.0,True,False,True,False,False
38085,34270248,2015-12-14 15:05:05,,"<p>I want to store every frame from my video in a generic List, to process it later on. I have the list declared as followed: <code>List&lt;Image&lt;Bgr, Byte&gt;&gt; Stream_to_Images = new List&lt;Image&lt;Bgr, Byte&gt;&gt;();</code>. </p>

<p>To import it I have created a timer which ticks every 33 milliseconds, in oder to get every frame. The event which is triggering should import the frame to the list. Therefore I have tried the following lines:</p>

<p>Either just a simple .Add()</p>

<pre><code>Stream_to_Images.Add(_capture.QueryFrame());
</code></pre>

<p>Or a counter for every frame, and adressing every Position itself.</p>

<pre><code>Stream_to_Images[StreamPosition] = _capture.QueryFrame();
StreamPosition++;
</code></pre>

<p>Using the first, my whole list contains only one frame, not the last one but one from the very end of the video, the second option results in an <code>ArgumentOutOfRangeException</code>. I am running out of ideas, are there any other ways to store every frame from my video in a list? </p>

<p>** <strong><em>UPDATE</em></strong> **</p>

<p>I have tried to change from a List to an Array, by using this</p>

<pre><code>imageBox1.Image = _capture.QueryFrame();
image_array.Add(_capture.QueryFrame());
</code></pre>

<p>But still, if I try to interate the array and display the video, I only get a picture of the last frame.</p>
",2015-12-23 10:39:49,2016-01-15 16:08:43,What is the best way to convert a video to a List in EmguCV,<c#><list><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
38095,34310124,2015-12-16 10:55:00,,"<p>I'm stuck in a phase in my Final Year Project where I require to calculate the coordinates of fingers on different facial features (nose, eyes or chin) of the user performing the gesture(s). </p>

<p>I've been able to extract the fingers and the recognition works good. I'm using Emgucv .Net wrapper for Open Cv to apply contouring and convex hull on the hands and fingers. The program works well when I just have hands and fingers in the threshold range but whenever I place the fingers near the face or include the face in the threshold area then the contoured area also includes the face and the finger tip points become invalid.</p>

<p>Is there anyway that I can just segment the fingers and hands in the desired threshold even though the face is present in the zone?
Or should I lose contouring technique completely and use something else?</p>
",2015-12-16 16:27:11,2015-12-16 16:27:11,Kinect Finger Detection and Tracking With Face Involved,<c#><kinect><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
38120,34312534,2015-12-16 12:48:59,,"<p><strong>Development Environment</strong></p>

<pre><code>Development OS : Windows 8.1 Pro
VS : 2013
App: Winform &amp; WPF
MSSQL : 2012
EF : 6.0
EMGU.CV : 3.0.0
ffmpeg, Nreco, office.interop and several other plugins installed with app.
</code></pre>

<p>We have developed a vehicle tracking system with the help of emgu.cv for image processing. we are using capture method to grab images from the input video file and process images. Any way, the application is almost done. To test the application, we are trying it in several machines. Like with different cores / different OS (w7/w8/w8.1/w10) etc. </p>

<p>we are installing MSSQL express 2012, .net fw 4.5, 4.5.1, before using the app in pc's where vs is not installed.</p>

<p>in most of the case, our test pc has VS 2013, and in those pc, there are no problem running this application.</p>

<p>Some pc have adobe products but not VS. But they are running the application too.</p>

<p>But those pc, just have installed or dont have any adobe product or VS, they are crashing at the same point( in 5 pc).</p>

<pre><code>    Application: VehicleTrackingSystem.exe
Framework Version: v4.0.30319
Description: The process was terminated due to an unhandled exception.
Exception Info: System.TypeInitializationException
Stack:
   at Emgu.CV.CvInvoke.cvReleaseCapture(IntPtr ByRef)
   at Emgu.CV.Capture.DisposeObject()
   at Emgu.Util.DisposableObject.Dispose(Boolean)
   at Emgu.Util.DisposableObject.Finalize()
</code></pre>

<p>Same solution is running in several pc as mentioned before. But in some cases, it shows (basically in win 7) <code>System.dllnotfoundexception</code>.</p>

<p>Its assumed that, some dlls are mismatching, may be because of VS installation or adobe product installation. I have tried <strong>Dependency Walker</strong> but in Positive PC and negetive PC all dll is similar. But the dll's file version is not same though.</p>

<p>how to solve this?</p>
",,2015-12-16 12:48:59,DLL dependency in different system or OS,<c#><.net><winforms><dll><emgucv>,,,CC BY-SA 3.0,False,False,True,False,True
38159,34180519,2015-12-09 13:53:08,,"<p>I have an x64 application using latest EmguCV 3 and after calling <code>DetectAndCompute</code> on <code>FastDetector</code> i get an Exception but unfortunately i don't know what Exception it was because as sun as Exception occurs Visual Studio (VS 2015 Community) exits debug (although i can see Excpetion Details window appearing for a brief fraction of a second before it exits.) All that is in the output window after it exits is: <code>The program has exited with code 0 (0x0).</code> In Exception settings I have checked all <code>Common Language Runtime Exceptions</code>. How can I retrieve information about this exception ?</p>
",,2016-04-29 10:07:47,Visual Studio exits debug on exception,<c#><debugging><visual-studio-2015><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
38320,34365239,2015-12-18 23:02:48,,"<p>Im using emgu surf demo</p>

<pre><code>using (Mat modelImage = CvInvoke.Imread(""img_1.jpg"", LoadImageType.Grayscale))
         using (Mat observedImage = CvInvoke.Imread(""f.tif"", LoadImageType.Grayscale))
         {
             Mat result = DrawMatches.Draw(modelImage, observedImage, out matchTime, out matchpercent);
             ImageViewer.Show(result, String.Format(""Matched using {0} in {1} milliseconds"", CudaInvoke.HasCuda ? ""GPU"" : ""CPU"", matchTime));
         }
</code></pre>

<p><br /></p>

<p>An the exception:
    An unhandled exception of type 'System.AccessViolationException' occurred in Emgu.CV.dll</p>

<p>What can i do to read .tif images properly?</p>
",,2015-12-18 23:02:48,Emgu CV error opening .tif image,<opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
38355,34483874,2015-12-27 19:12:10,,"<p>I am trying to apply Sobel filter on my picture to  detect edges as you can see here :</p>

<pre><code>Image&lt;Gray, Byte&gt; imgProcessed1;
private void Form1_Load(object sender, EventArgs e)
{



    Image&lt;Bgr, Byte&gt; imgProcessed=new Image&lt;Bgr, byte&gt;(@""C:\Users\Public\Pictures\Sample Pictures\1.jpg"");

    imgProcessed1 = imgProcessed.Convert&lt;Gray, byte&gt;();
    Image&lt;Gray, Single&gt; img_final = (imgProcessed1.Sobel(1, 0, 5));
    pictureBox1.Image = img_final.ToBitmap();
}
</code></pre>

<p>but the result is very unusual ,i am so new in opencv.</p>

<p>my output</p>

<p><a href=""https://i.stack.imgur.com/64qin.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/64qin.png"" alt=""enter image description here""></a></p>

<p>I need this result.</p>

<p><a href=""https://i.stack.imgur.com/aER4p.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aER4p.jpg"" alt=""enter image description here""></a></p>

<p>i just need to apply this filter </p>

<p><a href=""https://i.stack.imgur.com/5hhYt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5hhYt.png"" alt=""enter image description here""></a></p>
",2015-12-27 19:53:38,2015-12-27 20:24:57,Apply sobel filter for edge detection in emgucv,<c#><c++><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
38451,34568865,2016-01-02 17:50:46,,"<p>I have a group of PDFs that each have images embedded within them. These images usually consist of multiple elements like graphs and sub-images (biological cell and microscopic samples) with the sub-images clearly separated from one another by low entropy white space. </p>

<p>I have been able to extract the images stored within the PDFs but I now need to further segment these images into separate files based on viable points of interest within them (points of interest would be the rectangular sub-images and <strong>not</strong> the charts/graphs). An example of some of these PDF images can be seen <a href=""http://www.ncbi.nlm.nih.gov/pubmed/22284765"" rel=""nofollow"">here</a> under ""Images from this publication"".</p>

<p>I understand that libraries like emguCV and aForge.net that offer watershedding and k-means clustering may be able to assist in my endeavour, but as my image processing knowledge is limited I do not know exactly where to start. Also the majority of the examples I've seen online only overlay a segmented mask onto the original image instead of physically splitting the file.</p>

<p>Any guidance or pointers to achieving this would be greatly appreciated.</p>
",2016-01-02 19:06:00,2016-01-02 19:06:00,C# Image Segmentation,<c#><image><emgucv><image-segmentation><aforge>,2016-01-05 05:18:52,,CC BY-SA 3.0,False,False,True,False,False
38622,34544591,2015-12-31 09:58:46,,"<p>I'm trying to learn OCR processing. I have decided to create a .net project which use EmguCv wrapper to use OpenCV library.</p>

<p>I have wrote a little piece of code (most of lines come from <a href=""https://stackoverflow.com/questions/16406958/emgu-finding-image-a-in-image-b"">here</a>) :</p>

<pre><code>    public static Image&lt;Bgr, byte&gt; FindImage(string Imgtemplate, string Imgsource, float coeff)
    {
        Image&lt;Bgr, byte&gt; source = new Image&lt;Bgr, byte&gt;(Imgsource); // Image B
        Image&lt;Bgr, byte&gt; template = new Image&lt;Bgr, byte&gt;(Imgtemplate); // Image A
        Image&lt;Bgr, byte&gt; imageToShow = source.Copy();

        using (Image&lt;Gray, float&gt; result = source.MatchTemplate(template, Emgu.CV.CvEnum.TemplateMatchingType.CcoeffNormed))
        {
            double[] minValues, maxValues;
            //double minValues = 0, maxValues = 0;
            Point[] minLocations, maxLocations;
            //Point minLocations = new Point(), maxLocations = new Point();
            //CvInvoke.Normalize(result, result, 0, 1, Emgu.CV.CvEnum.NormType.MinMax, Emgu.CV.CvEnum.DepthType.Default, new Mat());
            //CvInvoke.MinMaxLoc(result, ref minValues, ref maxValues, ref minLocations, ref maxLocations, new Mat());
            result.MinMax(out minValues, out maxValues, out minLocations, out maxLocations);

            // You can try different values of the threshold. I guess somewhere between 0.75 and 0.95 would be good.
            if (maxValues[0] &gt; coeff)
            {
                // This is a match. Do something with it, for example draw a rectangle around it.
                Rectangle match = new Rectangle(maxLocations[0], template.Size);
                //Rectangle match = new Rectangle(maxLocations, template.Size);
                imageToShow.Draw(match, new Bgr(Color.Green), 1);
            }
        }

        // Show imageToShow in an ImageBox (here assumed to be called imageBox1)
        //imageBox1.Image = imageToShow;
        return imageToShow;

    }
</code></pre>

<p>The source image is : </p>

<p><a href=""https://i.stack.imgur.com/6yYyT.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6yYyT.jpg"" alt=""""></a></p>

<p>The template image is :</p>

<p><a href=""https://i.stack.imgur.com/Mn9R4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Mn9R4.png"" alt=""""></a></p>

<p>Both images are jpg. The result (with 100 % match) of the method is :</p>

<p><a href=""https://i.stack.imgur.com/IAykc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/IAykc.png"" alt=""""></a></p>

<p>As you can see the result isn't the good one :/. However, when i run my method with the example given on OpenCV site I have a good result (67 % match) :</p>

<p><a href=""https://i.stack.imgur.com/pmXxr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pmXxr.png"" alt=""""></a></p>

<p>Anyone have an idea about my problem ?
For the OpenCV example result is there any way to improve the matches percent ? Which option/parameter is the best ?</p>
",2017-05-23 10:28:21,2016-01-05 15:06:40,OpenCV (emgu) don't detect the good form,<c#><.net><winforms><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
38643,34507346,2015-12-29 08:32:15,,"<p>I want to import a video into my project and store it to this list :</p>

<pre><code>List&lt;Image&lt;Bgr, Byte&gt;&gt; MyVideo = new List&lt;Image&lt;Bgr, Byte&gt;&gt;();
</code></pre>

<p>I am doing this with a timer, which captures a frame every 33 ms with </p>

<pre><code>MyVideo.Add(_capture.QueryFrame());
</code></pre>

<p>If I display the currend catched frame with <code>ImageBox.Image = _capture.QueryFrame()</code> , everything is fine and I can see every single frame. But if I try to watch the Frames in my List, it shows only the last Frame from the video, the whole time. Like every Frame in the video was replaced by the last Frame. Any Ideas how to solve this?</p>
",,2015-12-29 09:35:53,OpenCV's Queryframe() returns only one frame,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
38676,34684988,2016-01-08 19:51:46,,"<p>I got a kinect mount in the ceiling pointing down to a table (that is roughly 2 to 3 meters of the kinect) and my objective is using the kinect depth stream, locate the objects and get their position to late send to unity. So for that i am using c sharp and opencv (emgu wrapper), i first use canny to get the edges and then use BoundingRect to create a box around the object. </p>

<p>The result is the as follows:</p>

<p><a href=""https://i.stack.imgur.com/BVf2c.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BVf2c.jpg"" alt=""enter image description here""></a></p>

<p>Original:</p>

<p><a href=""https://i.stack.imgur.com/iNUTf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/iNUTf.png"" alt=""enter image description here""></a></p>

<p>As you can see the stationary objects are no problem but the box around the hands (the first was a flyer on it) is to big and sometimes is even worse. Is there any other way (using opencv ) of getting the positions of the objects?</p>

<p>The objective is then to send the position and dimension (of the object) to unity (trough tcp/ip), so preferably the shapes have to squares or rectangles to easy manipulation on unity.</p>

<p>The code I have so far is:</p>

<pre><code>    Image&lt;Bgr, Byte&gt; grayImage = new Image&lt;Bgr, Byte&gt;(""C:\\Users\\Pedro\\Desktop\\imgRva\\KinectSnapshot-03-48-01.png"");
    Image&lt;Gray, Byte&gt; gray = grayImage.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();
    CvInvoke.cvShowImage(""texto"", gray);
    CvInvoke.cvWaitKey(0);
    Image&lt;Gray, Byte&gt; bin = gray.ThresholdBinary(new Gray(40), new Gray(255));
    Image&lt;Gray, Byte&gt; cannyEdges = bin.Canny(300, 300);
    CvInvoke.cvShowImage(""texto"", cannyEdges);
    CvInvoke.cvWaitKey(0);

    Image&lt;Gray, Byte&gt; canny = new Image&lt;Gray, byte&gt;(cannyEdges.Size);
    using (MemStorage storage = new MemStorage())

        for (Contour&lt;Point&gt; contours = cannyEdges.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_NONE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_TREE, storage); contours != null; contours = contours.HNext)
        {
            CvInvoke.cvDrawContours(canny, contours, new MCvScalar(255), new MCvScalar(255), -1, 1, Emgu.CV.CvEnum.LINE_TYPE.EIGHT_CONNECTED, new Point(0, 0));
        }

    using (MemStorage store = new MemStorage())
        for (Contour&lt;Point&gt; contours1 = cannyEdges.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_NONE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_TREE, store); contours1 != null; contours1 = contours1.HNext)
        {
            Rectangle r = CvInvoke.cvBoundingRect(contours1, 1);
            canny.Draw(r, new Gray(255), 1);
            Debug.WriteLine(r.Location + "" x "" + r.Width + "" y "" + r.Height);
        }
    CvInvoke.cvShowImage(""texto"", canny);
    CvInvoke.cvWaitKey(0);
</code></pre>

<p>Ty</p>
",2016-01-08 21:47:16,2016-01-08 21:47:16,Get position of objects using kinect and C#,<c#><opencv><unity3d><kinect><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
38720,34589633,2016-01-04 11:01:25,,"<p>I have used <code>cvGrabCut()</code> method from emgu cv in c# to extract foreground image. The result is satisfactory and I can extract foreground image with black background. But now I have to change the obtained black color background image to some different color. How can I do that? I have used the following code for foreground extraction:</p>

<pre><code>mask1.Draw(rect, new Gray(3), 0);
//the models (internally used)
Matrix&lt;double&gt; bgModel = new Matrix&lt;double&gt;(1, 13 * 5);
Matrix&lt;double&gt; fgModel = new Matrix&lt;double&gt;(1, 13 * 5);
//initialization with mask
CvInvoke.CvGrabCut(image.Ptr, mask1.Ptr, ref rect, bgModel.Ptr, fgModel.Ptr, 10, Emgu.CV.CvEnum.GRABCUT_INIT_TYPE.INIT_WITH_MASK);
//GrabCut segmentation
CvInvoke.CvGrabCut(image.Ptr, mask1.Ptr, ref rect, bgModel.Ptr, fgModel.Ptr, 15, Emgu.CV.CvEnum.GRABCUT_INIT_TYPE.EVAL);
//Get the pixels marked as likely foreground
mask1 = mask1.And(new Gray(1));
Image&lt;Bgr, Byte&gt; result = image.Copy(mask1);
result.Save(""foreground.jpg"");
</code></pre>
",2016-01-04 11:45:43,2016-07-29 12:05:23,Changing background color of foreground image obtained by cvGrabCut() c#,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
38753,34554798,2016-01-01 08:54:34,,"<p>I'm new to programming with <em>EMGU CV</em> and <em>OpenCV</em> so I may have made some silly mistakes. I'm writing a program to detect a specific logo of a company of a set of boxes with different logos in a warehouse. The camera will be top down orientated. I have started off simple with the example provided in the <em>EMGU CV</em> wiki and I am trying to use a BRIEF descriptor with a FAST Extractor since SURF is too slow. I am getting two errors. The first one is this.</p>
<blockquote>
<p>An unhandled exception of type 'System.AccessViolationException' occurred in Emgu.CV.dll</p>
<p>Additional information: Attempted to read or write protected memory. This is often an indication that other memory is corrupt.</p>
</blockquote>
<p>It occurs in this line of code</p>
<pre><code>        observerframe  = capture.QueryGrayFrame();
</code></pre>
<p>The next error is this</p>
<blockquote>
<p>An unhandled exception of type 'System.Runtime.InteropServices.SEHException' occurred in Emgu.CV.dll</p>
<p>Additional information: External component has thrown an exception.</p>
</blockquote>
<p>and it occurs in this line of code</p>
<pre><code>    nonZeroCount = Features2DToolbox.VoteForSizeAndOrientation(ObjectKeypoints, SceneKeypoints, indices, mask, 1.5, 20);
</code></pre>
<p>My full code is provided below</p>
<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using System.Windows;


using Emgu.CV;
using Emgu.Util;
using Emgu.CV.Structure;
using Emgu.CV.Features2D;
using Emgu.CV.Util;
namespace train
{
    public partial class Detectingwindow : Form
    {
        public Bitmap testobject;
        public Capture capture;
        public Image&lt;Gray, Byte&gt; observerframe;
        bool captureinprogress;
        bool detect = false;
        
        public Detectingwindow()
        {
            InitializeComponent();

        }

        private void matcher_Load(object sender, EventArgs e)
        {
        }

        private void camcapture(object sender, EventArgs e)
        {
            capture = new Capture(); 
            observerframe  = capture.QueryGrayFrame();

            if (observerframe != null)
            {
                Image&lt;Gray, Byte&gt; objectbnw = new Image&lt;Gray, byte&gt;(testobject);
                Image&lt;Bgr, Byte&gt; output = Draw(objectbnw, observerframe);
                imageBox1.Image = output;
            }
            return;
        }

        private void button1_Click(object sender, EventArgs e)
        {
            #region if capture is not created, create it now
            if (capture == null)
            {
                try
                {
                    capture = new Capture();
                }
                catch (NullReferenceException excpt)
                {
                    MessageBox.Show(excpt.Message);
                }
            }
            #endregion

            if (capture != null)
            {
                if (captureinprogress)
                {  //if camera is getting frames then stop the capture and set button Text
                    // &quot;Start&quot; for resuming capture
                    button1.Text = &quot;Restart&quot;; 
                    Application.Idle -= camcapture;
                }
                else
                {
                    //if camera is NOT getting frames then start the capture and set button
                    // Text to &quot;Stop&quot; for pausing capture
                    button1.Text = &quot;Pause&quot;;
                    Application.Idle += camcapture;
                    
                    
                }

                captureinprogress = !captureinprogress;
            }
        }
        public static Image&lt;Bgr, Byte&gt; Draw(Image&lt;Gray, Byte&gt; testobject, Image&lt;Gray, byte&gt; scene)
        {
            
                Image&lt;Bgr, Byte&gt; Draw;
                HomographyMatrix H = null;
                FastDetector detector = new FastDetector(10, true);
                VectorOfKeyPoint ObjectKeypoints, SceneKeypoints;
                Matrix&lt;int&gt; indices;
               // Freak extractor = new Freak(true, true, 22.0f, 4);
               BriefDescriptorExtractor extractor = new BriefDescriptorExtractor();
                Matrix&lt;byte&gt; mask;


                ObjectKeypoints = detector.DetectKeyPointsRaw(testobject, null);
                Matrix&lt;Byte&gt; ObjectDescriptors = extractor.ComputeDescriptorsRaw(testobject, null, ObjectKeypoints);

                SceneKeypoints = detector.DetectKeyPointsRaw(scene, null);
                Matrix&lt;Byte&gt; SceneDescriptors = extractor.ComputeDescriptorsRaw(scene, null, SceneKeypoints);

                BruteForceMatcher&lt;Byte&gt; matcher = new BruteForceMatcher&lt;byte&gt;(DistanceType.Hamming);
                matcher.Add(SceneDescriptors);

                indices = new Matrix&lt;int&gt;(SceneDescriptors.Rows, 2);
                using (Matrix&lt;float&gt; dist = new Matrix&lt;float&gt;(SceneDescriptors.Rows, 2))
                {
                    matcher.KnnMatch(SceneDescriptors, indices, dist, 2, null);
                    mask = new Matrix&lt;byte&gt;(dist.Rows, 1);
                    mask.SetValue(255);
                    Features2DToolbox.VoteForUniqueness(dist, 0.8, mask);
                }

                int nonZeroCount = CvInvoke.cvCountNonZero(mask);

                if (nonZeroCount &gt;= 4)
                {
                    nonZeroCount = Features2DToolbox.VoteForSizeAndOrientation(ObjectKeypoints, SceneKeypoints, indices, mask, 1.5, 20);
                    if (nonZeroCount &lt;= 4)
                    {
                        H = Features2DToolbox.GetHomographyMatrixFromMatchedFeatures(ObjectKeypoints, SceneKeypoints, indices, mask, 2);
                    }
                }

                Draw = Features2DToolbox.DrawMatches(testobject, ObjectKeypoints, scene, SceneKeypoints, indices, new Bgr(255, 255, 255), new Bgr(255, 255, 255), mask, Features2DToolbox.KeypointDrawType.NOT_DRAW_SINGLE_POINTS);
                if (H != null)
                {
                    Rectangle rect = testobject.ROI;
                    PointF[] pts = new PointF[] {
         new PointF(rect.Left, rect.Bottom),
         new PointF(rect.Right, rect.Bottom),
         new PointF(rect.Right, rect.Top),
         new PointF(rect.Left, rect.Top)};
                    H.ProjectPoints(pts);
                    Draw.DrawPolyline(Array.ConvertAll&lt;PointF, Point&gt;(pts, Point.Round), true, new Bgr(Color.Red), 5);
                }
                return Draw;
           
            
        }

        private void timer1_Tick(object sender, EventArgs e)
        {
            
        }

        private void button2_Click(object sender, EventArgs e)
        {

        }
    }
}
</code></pre>
<p>Sorry about not properly correcting indentations etc. or commenting. Would really appreciate any help.</p>
<p>Thanks</p>
",2020-06-20 09:12:55,2016-01-01 09:52:23,Error in VoteforSizeandOrientation and Cam capture EMGUCV C#,<c#><.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
38802,34653907,2016-01-07 11:23:50,,"<p>Im checking the size of image files and if the files are large then im re-sizing it so that the processing is faster. But when I use the resize code I always get a null reference exception pointing to <code>image</code>.I tried debugging-> the resized Bitmap that is returned is not null but the converted image >  <strong><em>image = new Image(x);</em></strong> is null.The code works fine if I remove the resize function. </p>

<pre><code>Image&lt;Bgr, byte&gt; image = null;

foreach (string s in mylist)
{
    Bitmap x = new Bitmap(Bitmap.FromFile(s));
    if (x.Width &gt; 1000 || x.Height &gt; 1000)
    {
        x = ResizekeepAspectRatio(x, 1000, 1000);
        image = new Image&lt;Bgr, byte&gt;(x);

    }
    else
    {
        image = new Image&lt;Bgr, byte&gt;(x);
    }

    work(image, x, s);
}

----------------------------------------------------------------------

Bitmap ResizekeepAspectRatio(Bitmap imgPhoto, int Width, int Height)
{
    int sourceWidth = imgPhoto.Width;
    int sourceHeight = imgPhoto.Height;
    int sourceX = 0;
    int sourceY = 0;
    int destX = 0;
    int destY = 0;

    float nPercent = 0;
    float nPercentW = 0;
    float nPercentH = 0;

    nPercentW = ((float)Width / (float)sourceWidth);
    nPercentH = ((float)Height / (float)sourceHeight);
    if (nPercentH &lt; nPercentW)
    {
        nPercent = nPercentH;
        destX = System.Convert.ToInt16((Width -
                      (sourceWidth * nPercent)) / 2);
    }
    else
    {
        nPercent = nPercentW;
        destY = System.Convert.ToInt16((Height -
                      (sourceHeight * nPercent)) / 2);
    }

    int destWidth = (int)(sourceWidth * nPercent);
    int destHeight = (int)(sourceHeight * nPercent);

    Bitmap bmPhoto = new Bitmap(Width, Height,
                      PixelFormat.Format24bppRgb);
    bmPhoto.SetResolution(imgPhoto.HorizontalResolution,
                     imgPhoto.VerticalResolution);

    Graphics grPhoto = Graphics.FromImage(bmPhoto);
    grPhoto.Clear(Color.Red);
    grPhoto.InterpolationMode =
            InterpolationMode.HighQualityBicubic;

    grPhoto.DrawImage(imgPhoto,
        new Rectangle(destX, destY, destWidth, destHeight),
        new Rectangle(sourceX, sourceY, sourceWidth, sourceHeight),
        GraphicsUnit.Pixel);

    grPhoto.Dispose();
    return bmPhoto;
}
</code></pre>
",2016-01-07 11:31:14,2016-01-07 19:15:28,"Image<Bgr, byte> Always returning Null",<c#><.net><emgucv><gdk>,,,CC BY-SA 3.0,False,False,True,False,False
38825,34771252,2016-01-13 15:57:26,,"<p>I have a university work in C#: to make a 3D approximation from a single scenery photo, at least a crude one, and I am not allowed to use libraries for image segmentation.</p>

<p>At this point, I have a function that segments image into colored segments and assigns color of the segment's root to all points in the segment for better distinction, like so: <a href=""http://puu.sh/mub8k.png"" rel=""nofollow"">badly segmented image on puush</a></p>

<p>Given such segmented image, is it possible to find contour points for these colored segments using EmguCV ?
My current aim is to try and use EmguCV to find segment contour points, assign them to lists and then use resulting polygons in SharpGL to make 3D scene.</p>
",,2016-01-13 15:57:26,Finding contours of colored segment in EmguCV,<c#><image-processing><emgucv><contour>,,,CC BY-SA 3.0,False,False,True,False,False
38845,34657429,2016-01-07 14:19:40,,"<p>I want to read from and write to individual elements of a <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/1f5ec683-8143-18ed-815e-1f2812ff960a.htm"" rel=""nofollow""><code>VectorOfFloat</code></a>. The problem is that there's no setter defined, which makes the brackets + index way of accessing the elements read only.</p>

<pre><code>VectorOfFloat vector = new VectorOfFloat(5);
// vector[2] = 2.5F; // does not work
</code></pre>

<p>There's a workaround:</p>

<ol>
<li>convert to array with <code>ToArray()</code></li>
<li>modify array as desired</li>
<li>write array back with <code>Clear()</code> and <code>Push()</code></li>
</ol>



<pre><code>float[] array = vector.ToArray();
array[2] = 2.5F;
vector.Clear();
vector.Push(array); // does work but is retarded

Console.WriteLine(vector[2]);
</code></pre>

<p>This seems to be very cumbersome just to write one element <strong>Is there a more direct approach to this?</strong>
Also, what is the missing setter worth if I can work around it?</p>
",2016-01-07 15:27:00,2016-01-07 16:30:32,How can I modify individual elements of a vector?,<c#><arrays><vector><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
38966,34741272,2016-01-12 10:33:10,,"<p>I know that you can blur out a whole picture by using Emgu's functions like <code>SmoothBlur</code> or <code>GaussianBlur</code>. </p>

<p>What I am interested in, is to know if it is possible to apply this filter only to a certain region of an image, for example the return-value of the function <code>DetectHaarCascade</code>, to blur out all recognized objects(faces, hands, bananas,...) inside an Image by using Emgu? I have managed to draw a rectangle around the detected region so far, therefore I thought it should be possible to apply a filter to this region?</p>

<p>I have tried a solution similar to <a href=""https://stackoverflow.com/questions/24195138/gaussian-blurring-with-opencv-only-blurring-a-subregion-of-an-image"">this answer</a>, but I can't pass the parameter returned from the <code>DetectHaarCascade</code>-Function to the Rectangle.</p>

<p>Does anyone know a better solution to that?</p>
",2017-05-23 12:15:23,2016-01-12 10:54:24,Blur only a part of a picture in EmguCV by using the return value from DetectHaarCascade,<c#><opencv><computer-vision><emgucv><blur>,,,CC BY-SA 3.0,True,False,True,False,False
38988,34635024,2016-01-06 14:02:45,,"<p>I want to undistort some points in EmguCV, but I get a <code>CVException</code> during execution, because the following assertion fails:</p>

<pre><code>OpenCV: src.isContinuous() &amp;&amp; (src.depth() == CV_32F || src.depth() == CV_64F) &amp;&amp; ((src.rows == 1 &amp;&amp; src.channels() == 2) || src.cols*src.channels() == 2)
</code></pre>

<p>Here's how I call the function:</p>

<pre><code>                                                      //fx fy,  cx,  cy, k1, k2, p1, p2
IntrinsicParameters intrinsic = new IntrinsicParameters( 1, 1, 100, 100,  0,  0,  0,  0);

VectorOfPoint points = new VectorOfPoint(new Point[] { new Point(0, 0), new Point(255, 255) });
VectorOfPoint pointsUndistorted = new VectorOfPoint(points.Size);

CvInvoke.UndistortPoints(points, pointsUndistorted, intrinsic.CameraMatrix, intrinsic.DistorionCoefficients); 
</code></pre>

<p>explanation:</p>

<ol>
<li><code>IntrinsicParameters</code> is a custom class that wraps all intrinsic parameters, which I used default values for). I added a comment above to denote what parameter is which</li>
<li>I create a <code>VectorOfPoint</code> called <code>points</code> that I want to distort.</li>
<li>I create another <code>VectorOfPoint</code> to hold the result</li>
<li><strong>The program hangs on the last line</strong> in the snippet provided. When I click pause in VisualStudio the debugger says the mentioned assertion failed.</li>
</ol>

<p>I tried to find some explanation of what this all means but <a href=""https://github.com/Itseez/opencv/blob/master/modules/imgproc/src/undistort.cpp#L422"" rel=""nofollow noreferrer"">there's no comment whatsoever in the openCV source code</a>.</p>

<p>What am I doing wrong here? Am I not supposed to use <code>undistortPoints()</code> with this type of points? But then why can I pass them to the function?</p>

<h2>Update using <code>Mat</code></h2>

<p>I tried to use <code>Mat</code> instead, which is a bit of a pain to use. <a href=""https://stackoverflow.com/questions/32255440/how-can-i-get-and-set-pixel-values-of-an-emgucv-mat-image"">I found this question explaining how to set the elements of a <code>Mat</code></a> and came up with this code:</p>

<pre><code>int n = 2;
Mat mat = new Mat(new Size(1, n), Emgu.CV.CvEnum.DepthType.Cv32F, 2);
Mat matDistorted = new Mat(new Size(1, n), Emgu.CV.CvEnum.DepthType.Cv32F, 2);

Matrix&lt;float&gt; yetAnotherMatrixOr_YAM_forShort = new Matrix&lt;float&gt;(new float[,]{{0, 0}, {255, 255}});

mat.SetTo(yetAnotherMatrixOr_YAM_forShort);

CvInvoke.UndistortPoints(mat, matDistorted, intrinsic.CameraMatrix, intrinsic.DistorionCoefficients);
</code></pre>

<p>The exception I get now comes from a different assertion (hurray?):</p>

<pre><code>OpenCV: checkScalar(value, type(), _value.kind(), _InputArray::MAT )
</code></pre>

<p>It looks like this happens when calling <code>mat.SetTo()</code>. I'm not sure why this is so complicated.</p>
",2017-05-23 10:28:22,2016-01-06 16:00:34,Why does UndistortPoints() fail for these input points?,<c#><opencv><emgucv><distortion>,,,CC BY-SA 3.0,True,True,True,False,False
39003,34827125,2016-01-16 12:47:11,,"<p>I have a problem. I have a database that contains URLs of IP Cameras. My program will read all of the URLs from that database. But additionally, I would like to exclude all URLs of cameras that are inactive. If my program connects to URL of inactive camera, it hangs. I use Emgu CV to do image processing. These are what I have done.</p>

<pre><code>string koneksi = @""Provider=Microsoft.ACE.OLEDB.12.0; Data Source=D:\Dokumen\Alfon\TA Alfon\CobaFitur\SistemParkir.accdb; 
                                     Persist Security Info=False"";

private void ProsesSemuaKamera()
{
  OleDbConnection kon = new OleDbConnection(koneksi);
  OleDbCommand commandurl = kon.CreateCommand();
  kon.Open();
  string selectsemuaurl = ""select * from datakamera"";
  commandurl.CommandText = selectsemuaurl;
  OleDbDataReader prosessemuaurl = commandurl.ExecuteReader();

  while (prosessemuaurl.Read())
  {
    CaptureSemuaKamera = new Capture(prosessemuaurl[""urlkamera""].ToString()); //(352x288)
    Application.Idle += ProcessFrameSemuaKamera;
    ProsesCapture = !ProsesCapture;
  }
  kon.Close();
}
</code></pre>
",2016-01-18 14:18:10,2016-01-18 14:18:10,Skipping Read URL data of IP Camera in MS Access Which is not Active C#,<c#><ms-access><camera><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
39006,34712480,2016-01-11 00:32:59,,"<p>I'm just starting to learn about computer vision and am working on a simple project to find basic icons in a still image.</p>

<p>I have a template image:
<a href=""https://i.stack.imgur.com/WkbNp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WkbNp.png"" alt=""enter image description here""></a> </p>

<p>and two test images:</p>

<p><a href=""https://i.stack.imgur.com/qSME9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qSME9.png"" alt=""enter image description here""></a>
 and <a href=""https://i.stack.imgur.com/0oCUf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0oCUf.png"" alt=""enter image description here""></a></p>

<p>I used template matching (using AForge.net, but I think it is the same algorthym 
that OpenCV and Emgu use.  I could be wrong, I'm new at CV) and discovered that with a threshold of .80563 that I would find exact one match in both of the above, and get no matches in images I tried that the icon was not in.</p>

<p>I thought I was getting somewhere until I looked at what was returned as the match in each image:  (The blue highlighted squares are where the image was matched.)</p>

<p><a href=""https://i.stack.imgur.com/nr91Z.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nr91Z.png"" alt=""enter image description here""></a> (Correct) and <a href=""https://i.stack.imgur.com/UlYR4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UlYR4.png"" alt=""enter image description here""></a> (Completely wrong)</p>

<p>I realize that the issue is any or all of:</p>

<ul>
<li>Icons I am looking for will be <em>similar</em> in size, color and shade, but no guarantee they will be identical in any of the above.  (Note: Angular orientation and proportions should be consistent.  I wouldn't want a circle with a ""+"" in it to match the template.  Nor would I want a huge circle with a tiny ""X"" to match.)</li>
<li>My template isn't a square, and I'm just guessing that the transparent pixels will not be included in the match.</li>
<li>Template matching may be the wrong approach given the 2 issues above.  Maybe I need to use something else to do this?</li>
</ul>

<p>Ultimately, I need some basic help on what is going wrong with my matching so that I can at least get back moving in the correct direction.  Is template matching the right approach, but I need to change something? Or do I need to look at one of the other capabilities in these libraries?  For this simple task, is there much functional difference between OpenCV (and EMGU) functionality and AForge.net functionality?</p>
",,2016-01-14 06:11:06,Finding an icon in an image,<opencv><computer-vision><emgucv><aforge>,,,CC BY-SA 3.0,True,False,True,False,False
39082,34870859,2016-01-19 07:28:33,,"<p>I started from EMGU Example (Emgu.CV v2.4.10.1939):
<a href=""http://www.emgu.com/wiki/index.php/CompareImages_-_Difference"" rel=""nofollow noreferrer"">http://www.emgu.com/wiki/index.php/CompareImages_-_Difference</a></p>

<p>Instead of comparing previous video frame and the next one I am dealing with a screen capture of the primary screen at time1 and another screen capture at time2. Second screen capture brings a minimal difference, especially in one part of the captured image and that is: an outline (closed polygon of n vertices). I applied ThresholdBinary method and this code:</p>

<pre><code>Contour&lt;Point&gt; currentContour = contours.ApproxPoly(contours.Perimeter * 0.05, storage);
</code></pre>

<p>to get the shape of the difference (which for me is a white polygon)</p>

<p>I then cropped that polygon to avoid processing unnecessary parts of the image.
<a href=""https://i.stack.imgur.com/WHdcw.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WHdcw.jpg"" alt=""enter image description here""></a>
In the attached images on the right I tried to depict what I want and don't want based on processing left input image.
I want to find x,y coordinates (in pixels) of all intersections of vertices of the polygon for the cropped image. </p>

<p>When I would later redraw the polygon I would expect to as close match as possible to this input polygon. I would like to have a reasonable number of straight lines detected so the final shape faithfully resembles input shape on the left.</p>

<p>This is a similar question that didn't have a solution.
<a href=""https://stackoverflow.com/questions/10297713/find-contour-of-the-set-of-points-in-opencv"">Find contour of the set of points in OpenCV</a></p>
",2017-05-23 12:31:24,2016-01-19 08:30:36,OpenCV/Emgu.CV: Finding contour point coordinates of a filled polygon using C#.net,<c#><image><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
39112,35008249,2016-01-26 06:41:28,,"<p>I need to get the content of an Image which is surrounded by a Rectangle. I am using emguCV DetectMultiScale function which returns an Array of Rectangle that contains the location or area of detected Image which I need to get the content. Thanks!</p>

<pre><code>results = FindPeople.Find(frameImage, tryUseCuda, tryuseOpenCL, out processingTime, out peopleCount);
foreach (Rectangle rect in results)
{
    CvInvoke.Rectangle(frameImage, rect, new Bgr(Color.Red).MCvScalar);
    //Get content of the Rectangle here, frameImage = image
}
</code></pre>
",2016-01-26 06:42:37,2016-01-26 07:11:20,How to get the content of an Image inside a Rectangle?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
39124,35009589,2016-01-26 08:27:58,,"<p><a href=""https://i.stack.imgur.com/arwQI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/arwQI.png"" alt=""enter image description here""></a>Can anyone please help me out in continuously refreshing the histogram in histogram box in real-time from webcamera using EmguCv C#..  </p>

<pre><code>HistogramBox hb = new HistogramBox();
Form frm = new Form();

hb.GenerateHistograms(img, 256);// show 256 shades
hb.Enabled = true;

hb.Size = new System.Drawing.Size(255, 255);// change to your preferred size 
frm.Controls.Add(hb);
hb.Refresh();   

frm.ShowDialog();
</code></pre>

<p>This is snippet i got but when i include in webcamera capture method the dialogbox refreshes such that it goes blank rather than updating.</p>

<hr>

<pre><code>using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Structure;
using Emgu.CV.UI;
namespace Redcolor_tracker_GUI
{
    public partial class Form1 : Form
    {
        Capture capWebcam = null;
        bool inProcess = false;
        Image&lt;Bgr, Byte&gt; img;
        Image&lt;Gray, Byte&gt; imgout;
        HistogramBox hb = new HistogramBox();
        bool toggle = false;
        Form frm = new Form();

        public Form1()
        {
            InitializeComponent();


        }



        private void Form1_Load(object sender, EventArgs e)
        {
            try
            {
                capWebcam = new Capture();
            }
            catch (NullReferenceException except)
            {
                txtXYRadius.Text = except.Message;
                return;
            }
            Application.Idle += processFrameGUI;
            inProcess = true;


        }
        private void Form1_FormClosed(object sender, FormClosedEventArgs e)
        {
            if (capWebcam != null)
            {
                capWebcam.Dispose();
            }
        }
        void processFrameGUI(object sender,EventArgs srg)
        {
            img=capWebcam.QueryFrame();
            if(img==null) return;
            imgout=img.InRange(new Bgr(0,0,0),new Bgr(0,0,0));
            imgout=imgout.SmoothGaussian(9);
            if (toggle)
            {

              hb.GenerateHistograms(img, 256);
              hb.Refresh();// show 256 shades
              hb.Enabled = true;

             }
            ibOriginal.Image=img;
            ibProcessed.Image=imgout;
         }

        private void btnPauseOResume_Click(object sender, EventArgs e)
        {
            if (inProcess == true)
            {
                Application.Idle -= processFrameGUI;
                inProcess = false;
                btnPauseOrResume.Text = ""resume"";
            }
            else
            {
                Application.Idle += processFrameGUI;
                inProcess = true;
                btnPauseOrResume.Text = ""resume"";
            }
        }

        private void button1_Click(object sender, EventArgs e)
        {
            if (toggle == false)
            {
                toggle = true;
            }
            else
            {
                toggle = false;
            }

            hb.Size = new System.Drawing.Size(400, 400);

            frm.Controls.Add(hb);
            frm.ShowDialog();  
        }

    }
}
</code></pre>

<p>ENTIRE CODE******************</p>

<p>Thank you</p>
",2016-02-06 06:23:49,2016-02-09 13:31:23,How to refresh the histogram for webcamera in real-time in EmguCV C#?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
39129,34970926,2016-01-24 00:48:48,,"<p>I have two IP cameras. I want to run both of them simultaneously. I am using Emgu CV to process images. So here, when I click Start button, my program will check which my cameras are active (get their IP addresses). After getting their IP addresses, my program will use those IPs to get data from database. The condition that I get, my program will be very slow and there is delay for several seconds when capture process is running. Can anyone help me what I must do to solve this problem ? Here what I have done</p>

<pre><code>    private void Tombol_Start_Click(object sender, EventArgs e)
    {
      ProsesSemuaKamera();
    }

    private void ProsesSemuaKamera()
    {
       Ping ping = new Ping();
       PingReply pingreply;

       OleDbConnection kon = new OleDbConnection(koneksi);
       OleDbCommand command = kon.CreateCommand();
       kon.Open();
       string selecturl = ""select * from datakamera"";
       command.CommandText = selecturl;
       OleDbDataReader bacadata = command.ExecuteReader();

       while (bacadata.Read())
       {
         int counturl = 0;
         pingreply = ping.Send(bacadata[""ipadd""].ToString());

         if (pingreply.Status == IPStatus.Success)
         {
           listBox1.Items.Add(bacadata[""namakamera""].ToString());
           CaptureSemuaKamera = new Capture(bacadata[""urlkamera""].ToString());
           Application.Idle += new EventHandler(ProcessFrameSemuaKamera);    

         }
         else if (pingreply.Status != IPStatus.Success)
         {
          textBox3.Text += bacadata[""namakamera""].ToString() + Environment.NewLine;
          }
      }
    kon.Close();
 }

    private void ProcessFrameSemuaKamera(object sender, EventArgs e)
    {
      Image&lt;Bgr, Byte&gt; sourceImage = CaptureSemuaKamera.QueryFrame();
      SourceBox.Image = sourceImage.Bitmap;
      ProsesKameraSemua();
    }

        private string BuildWhereClause(ListBox lb)
        {
            string WHEREclause = string.Empty;

            foreach (string itm in lb.Items)
            {
                if (WHEREclause == string.Empty)
                {
                    WHEREclause += "" where namakamera = '"" + itm + ""' "";
                }
                else
                {
                    WHEREclause += "" OR namakamera = '"" + itm + ""' "";
                }
            }
            return WHEREclause;
        }

 private void ProsesKameraSemua()
        {
            Image&lt;Bgr, Byte&gt; sourceImage = CaptureSemuaKamera.QueryFrame();
            SourceBox.Image = sourceImage.Bitmap;

            OleDbConnection kon = new OleDbConnection(koneksi);
            OleDbCommand commandkoord = kon.CreateCommand();
            OleDbCommand commandkoordgaris = kon.CreateCommand();

            kon.Open();
                string selectsemuakoord = ""select * from koordinatkotak "" + BuildWhereClause(listBox1);
                string selectsemuakoordgaris = ""select * from koordinatgaris "" + BuildWhereClause(listBox1);

                commandkoord.CommandText = selectsemuakoord;
                commandkoordgaris.CommandText = selectsemuakoordgaris;
                OleDbDataReader bacakoord = commandkoord.ExecuteReader();
                OleDbDataReader bacakoordgaris = commandkoordgaris.ExecuteReader();

                while (bacakoord.Read() &amp;&amp; bacakoordgaris.Read())
                {
                    #region Perspective projection

                    PointF[] srcs = new PointF[4];
                    srcs[0] = new PointF(int.Parse(bacakoord[""x1source""].ToString()), int.Parse(bacakoord[""y1source""].ToString())); //119, 187
                    srcs[1] = new PointF(int.Parse(bacakoord[""x2source""].ToString()), int.Parse(bacakoord[""y2source""].ToString())); //242, 181
                    srcs[2] = new PointF(int.Parse(bacakoord[""x3source""].ToString()), int.Parse(bacakoord[""y3source""].ToString())); //253, 225
                    srcs[3] = new PointF(int.Parse(bacakoord[""x4source""].ToString()), int.Parse(bacakoord[""y4source""].ToString())); //112, 231

                    PointF[] dsts = new PointF[4];
                    dsts[0] = new PointF(int.Parse(bacakoord[""x1proj""].ToString()), int.Parse(bacakoord[""y1proj""].ToString()));
                    dsts[1] = new PointF(int.Parse(bacakoord[""x2proj""].ToString()), int.Parse(bacakoord[""y2proj""].ToString()));
                    dsts[2] = new PointF(int.Parse(bacakoord[""x3proj""].ToString()), int.Parse(bacakoord[""y3proj""].ToString()));
                    dsts[3] = new PointF(int.Parse(bacakoord[""x4proj""].ToString()), int.Parse(bacakoord[""y4proj""].ToString()));


                    HomographyMatrix mywarpmat = CameraCalibration.GetPerspectiveTransform(srcs, dsts);
                    Image&lt;Bgr, Byte&gt; newImage = sourceImage.WarpPerspective(mywarpmat, 355, 288, Emgu.CV.CvEnum.INTER.CV_INTER_LINEAR, Emgu.CV.CvEnum.WARP.CV_WARP_FILL_OUTLIERS, new Bgr(0, 0, 0));
                    Image&lt;Gray, Byte&gt; newImageGray = newImage.Convert&lt;Gray, Byte&gt;();

                    Image&lt;Bgr, Byte&gt; imageToShow = newImage.Copy();
                    Image&lt;Bgr, Byte&gt; imageToShowGaris = newImage.Copy();

                    ProjectionBox.Image = newImage.Bitmap;

                    #endregion
  }
}
</code></pre>
",,2016-01-24 00:48:48,Running Two Cameras Simultaneously using Emgu CV C#,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
39139,34935053,2016-01-21 21:53:55,,"<p>I integrated my project on Visual Studio 2010 with Emgu 3.0 and I'm working on detection object project , but when I'm using MCvFont like the following line I get error because the library is missing , This library is removed from the last version of Emgu or what ?</p>

<pre><code> MCvFont f2 = new MCvFont(Emgu.CV.CvEnum.FONT.CV_FONT_HERSHEY_TRIPLEX, 1.0, 1.0);
</code></pre>
",,2017-02-02 23:39:19,MCvFont library is missing at Emgu 3.0,<c#><visual-studio><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
39172,34914417,2016-01-21 02:34:31,,"<p>I need to convert a Mat to an Image in Emgu CV.  Trying to cast a Mat to an image produces an exception: <code>Cannot implicitly convert type 'Emgu.CV.Mat' to 'Emgu.CV.Image</code></p>

<pre><code>Image&lt;Bgr, Byte&gt; imgeOrigenal;

Capture capWebcam = null;

imgeOrigenal = capWebcam.QueryFrame();//error line
</code></pre>

<p>How can I convert the Mat to an Image?</p>
",2018-10-04 09:08:49,2019-01-08 13:00:28,how to convert mat to image,<c#><emgucv>,,,CC BY-SA 4.0,False,True,True,False,False
39250,34842404,2016-01-17 19:05:20,,"<p>I'm using EmguCV on a Windows Forms Application with C#. Looking through the YouTube videos and online tutorials, I could not find anything that works for me or that I was able to make work for me. I believe this is because I am using the latest version of EmguCV, while these videos and tutorials are using 2.x.x.</p>

<p>I am making a science fair project with a Raspberry PI 2 running IoT Core (Microsoft Internet of Things), so I will be deploying code to the PI directly from Visual Studio. My science fair project involves traffic sign detection and speed limit detection.</p>

<p>Should I just downgrade EmguCV? Does anyone have any ideas on how I could go about detecting different traffic signs?</p>
",2016-03-12 14:07:09,2016-03-12 14:07:09,C# OpenCV: Detecting a Stop Sign,<c#><.net><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
39287,34924389,2016-01-21 12:53:14,,"<p>I am developing a windows service which processes video input and sends results of interest to a separate platform. I do not need to display the frames in this context. I am having a problem getting the correct camera input.</p>

<p>I want to save a Bitmap resulting retrieved from am EMGU capture object. To make sure that the capture is actually reading the video stream, I save the bitmap to a file, as follows:</p>

<pre><code>Mat frame = mCapture.QueryFrame();
Template = frame.Bitmap;
Template.Save(""frozen.jpg"");
</code></pre>

<p>The capture is initialized as follows:</p>

<pre><code>CvInvoke.UseOpenCL = false;
int index = int.Parse(ConfigurationManager.AppSettings[""Index""]);
mCapture = new Capture(index);
</code></pre>

<p>One test platform is a Lenovo laptop running 64-bit Windows 10, with a built-in camera and a second camera attached through a USB port. The input of interest is the second camera. However, whatever index I use to open the Capture object, the input comes from the built-in camera.</p>

<p>The other platform is a Meego Pad, running 32-bit Windows 10, with the same camera attached. In this case, I simply get blank frames as video input.  For both platforms, running the camera application shows the video input as expected. What is the problem with my initialization of the Capture object?</p>

<p><strong>Further Investigation Shows...</strong></p>

<p>First, I was using the wrong index to create the capture, so that created some of the confusion. But more confusion follows.</p>

<p>When I call the QueryFrame() method in an event delegate, as shown in <a href=""http://www.emgu.com/wiki/index.php/Camera_Capture_in_7_lines_of_code"" rel=""nofollow"">this simple example</a> I successfully retrieve the frame from the camera. Example code looks like this:</p>

<pre><code>Application.Idle += new EventHandler(delegate(object sender, EventArgs e)
{  //run this until application closed (close button click on image viewer)
   viewer.Image = capture.QueryFrame(); //draw the image obtained from camera
});
viewer.ShowDialog(); //show the image viewer
</code></pre>

<p>When I call the same method in a different thread (in response to a communication event) I get an empty image. On the gripping hand, when I call the method in a timer callback, I get the correct image.</p>

<p>I won't call this closed, because I would still like to know why QueryFrame() acts correctly in some threads, but not in others. However, I can work with this, so the question is now mostly academic.</p>
",2016-01-21 15:28:26,2016-01-21 15:28:26,Blank or Wrong Picture from EMGU capture,<c#><video><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
39307,34987108,2016-01-25 07:22:39,,"<p>I have an array of rectangle that consists of images, now I need to display it in a pop up form. How can I output the Rectangles to a ImageBox or PictureBox? Thanks!</p>

<pre><code> results = FindPeople.Find(frameImage, tryUseCuda, tryuseOpenCL, out processingTime, out peopleCount);

if (captureFrame)
      {
       popUpForm popUp = new popUpForm(results);
       popUp.Show();
       captureFrame = false;
      }
</code></pre>

<p>Pop up form</p>

<pre><code>public popUpForm(Rectangle[] images)
    {


        foreach (Rectangle rect in images)
       {



       }

    }
</code></pre>
",,2016-01-25 07:41:47,How to output a Rectangle[] to a ImageBox or PictureBox?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
39326,34948499,2016-01-22 13:59:54,,"<p>I need to have the image of my (Emgu CV version 3) <code>ImageBox</code> in an image variable, how should I do this?</p>

<p>I tried this without luck:</p>

<pre><code> Image&lt;Bgr, Byte&gt; imgeOrigenal;
 imgeOrigenal = ImageBoxbOrigenal.Image; //error line
</code></pre>

<p>Results in:</p>

<blockquote>
  <p>Cannot implicitly convert type 'Emgu.CV.IImage' to 'Emgu.CV.Image'. An explicit conversion exists </p>
</blockquote>
",2016-01-22 14:16:01,2016-01-22 14:16:01,"How to convert ImageBox.Image to Image<Bgr, Byte>",<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
39327,34949253,2016-01-22 14:39:31,,"<p>I'm developing an application to control mouse via webcam, starting from this <a href=""http://www.codeproject.com/Articles/498193/Mouse-Control-via-Webcam"" rel=""nofollow"">application</a></p>

<p>It simply tracks the hand using skin color segmentation, some noise filtering e contour analyzing, then calculate the centroid and assign it to the mouse cursor. 
Of course in this way the coordinates you get for the centroid of the hand tracked refers to the image frame captured by the webcam and don't correspond to the real screen coordinates, so there will be areas in the screen that you can not reach. Unless you have the same resolution for webcam frame and screen, how could I reach every point in the screen?</p>

<p><strong>EDIT</strong></p>

<p>Was simpler than I was thinking, here solution as proposed in the answer:</p>

<pre><code>            Rectangle resolution = Screen.PrimaryScreen.Bounds;

            int real_X = (int)((Convert.ToDouble(current_X) / frame.Width)*resolution.Width);
            int real_Y = (int)((Convert.ToDouble(current_Y) / frame.Height)*resolution.Height);
</code></pre>
",2016-01-22 16:13:38,2016-01-22 16:13:38,How to project Webcam captured frame coordinates to screen coordinates,<c#><opencv><mouse><emgucv>,2016-01-22 17:03:39,,CC BY-SA 3.0,True,False,True,False,False
39363,35106812,2016-01-30 20:35:52,,"<p>I am trying to find biggest object in my binary image. I used to code <a href=""https://channel9.msdn.com/coding4fun/blog/Contour-Analysis-for-Image-Recognition-in-C"" rel=""nofollow noreferrer"">here</a> in line 52 but I got the error on <code>FindContours</code> shown below.</p>

<p>What is wrong in my code? and Is there an other way to find the object has biggest area in binary image?</p>

<p><a href=""https://i.stack.imgur.com/nWyq1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nWyq1.png"" alt=""enter image description here""></a></p>
",,2017-01-14 11:07:36,Can not use 'FindContours' with EmguCV in C#,<c#><image-processing><emgucv><opencv-contour>,,,CC BY-SA 3.0,True,False,True,False,False
39383,35143851,2016-02-02 02:06:38,,"<p>I have two sets of images which have the same size and pixels. Now I have to compare selectedFrame which is the 1st image to backImageFrame which is the 2nd image. I need to get the difference in the images and extract it so I can output it in a ImageBox. Now, I am using AbsDiff function of EmguCV </p>

<pre><code> selectedFrame.ROI = recArray[random];
 backImageFrame.ROI = recArray[random];
 // backImageFrame = selectedFrame.AbsDiff(backImageFrame);
 CvInvoke.AbsDiff(selectedFrame, backImageFrame, backImageFrame)
 imgTry.Image = backImageFrame;
 imageBox1.Image = selectedFrame;
</code></pre>

<p>The imgTry ImageBox doesn't have any value in it</p>
",,2020-08-05 06:27:29,How to compare two images and extract its difference?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
39575,35007132,2016-01-26 04:36:28,,"<p>I'm using an Open CV wrapper, Emgu CV, to find try and find a target that is a non basic shape (see picture below). I've tried using HoughCircle detection  to find these shapes but it doesn't quite fully detect it (see picture below). Is there a better way to detect these shapes?  </p>

<p><a href=""https://i.stack.imgur.com/AloYd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AloYd.png"" alt=""target""></a></p>
",,2016-01-26 11:48:15,Open CV non-basic shape detection,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
39610,35163344,2016-02-02 20:37:43,,"<p>i have two images taken by two cameras, i want to use surf algorithm or any algorithm in Emgu to get just matched features locations in two images to calculates (estimate) real distance from cameras and this features (objects), i found example to use surf algorithm in Emgu examples, but its draw lines between matched features i want to get x and y for any begin and end of each line.
<a href=""http://i.stack.imgur.com/poT1u.jpg"" rel=""nofollow"">features matched by surf algorithm sample image</a></p>

<p>i try to add some code in surf algorithm example but not work as expected in Draw method</p>

<pre><code>long num_matches = matches.Size;
float lower = matches[0][0].Distance;
List&lt;PointF&gt; matched_points1= new List&lt;PointF&gt;();
List&lt;PointF&gt; matched_points2=new List&lt;PointF&gt;();

for (int i = 0; i &lt; num_matches; i++)
{
    if (matches[i][0].Distance &lt; 0.095)
    { 
        int idx1 = matches[i][0].TrainIdx;
        int idx2 = matches[i][0].QueryIdx;
        matched_points1.Add(observedKeyPoints[idx1].Point);
        matched_points2.Add(observedKeyPoints[idx2].Point);
        CvInvoke.Circle(result, new Point((int)observedKeyPoints[idx2].Point.X , (int)observedKeyPoints[idx2].Point.Y), 1, new MCvScalar(255, 0, 0));
        CvInvoke.Circle(result, new Point((int)modelKeyPoints[idx1].Point.X + modelImage.Width, (int)modelKeyPoints[idx1].Point.Y), 1, new MCvScalar(255, 0, 0));
    }

    if (lower &gt; matches[i][0].Distance)
        lower = matches[i][0].Distance;
}
</code></pre>
",2016-02-02 21:16:33,2016-05-17 13:30:22,"get location(x,y) of matched features in two images using emgu",<algorithm><emgucv><surf>,,,CC BY-SA 3.0,False,False,True,False,False
39676,35381238,2016-02-13 14:42:56,,"<p>I know how to draw text on image in Emgu CV:</p>

<pre><code>CvFont f = new MCvFont(Emgu.CV.CvEnum.FONT.CV_FONT_HERSHEY_COMPLEX_SMALL, 1, 1);
image.Draw(""something"", ref f, new Point(0, 0), new Rgb(0, 0, 0));
</code></pre>

<p>but I don't know how to use other fonts instead of CV_FONT_HARSHEY*</p>

<p><strong>UPDATE:</strong></p>

<p>This is complete solution:</p>

<pre><code>var b = image.Bitmap;
Graphics g = Graphics.FromImage(b);
Font drawFont = new Font(""Arial"", 16);
SolidBrush drawBrush = new SolidBrush(Color.Black);
PointF drawPoint = new PointF(0,0);
g.DrawString(""something,"", drawFont, drawBrush, drawPoint);

/// after drawing etc.

image.Bitmap = b;
</code></pre>
",2016-02-14 08:10:58,2016-02-14 08:10:58,How to use custom fonts in emgucv?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
39697,35308096,2016-02-10 06:12:23,,"<p>Code :</p>
<pre><code>Image&lt;Bgr, Byte&gt; inputImage = new Image&lt;Bgr, Byte&gt;(&quot;pic.jpg&quot;);
imageBox1.Image = inputImage;
Image&lt;Hsv, byte&gt; imageHsv = inputImage.Convert&lt;Hsv, byte&gt;();
imageBox2.Image = imageHsv;
</code></pre>
<p>Output:</p>
<p><img src=""https://i.stack.imgur.com/MXuSK.jpg"" alt=""MY OUTPUT"" /></p>
",2020-07-10 09:30:57,2020-07-10 09:30:57,What happened convert rgb to hsv,<emgucv>,,,CC BY-SA 4.0,False,False,True,False,False
39708,35383948,2016-02-13 18:50:32,,"<p>I'm trying to perform super-resolution in EMGU.
I have a microscope USB camera where I can acquire sequential frames to files (or memory).
I'm pretty new to C# but have reasonable working knowledge. I <strong>do</strong> have Emgu working well in VS .Net where I'm acquiring and saving images.  </p>

<p>I want to perform super-resolution but can't find any decent example code or just examples. There's one example <a href=""https://github.com/neutmute/emgucv/blob/master/Emgu.CV.Superres/SuperResolution.cs"" rel=""nofollow""><strong>here</strong></a>, but I'm using VS .Net and I'm having a hard time understanding. </p>

<p>Please any help is GREATLY appreciated.</p>
",,2016-02-13 18:50:32,Looking for an example EMGU super resolution,<c#><image><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
39718,35250994,2016-02-07 07:39:00,,"<p>I need to find the coordinates of three black squares in the test form. I took the example code from the site emgu.com and slightly changed it, but he does not find what I need. The size of image is A4, and the size of the test form is A5. I am hope for your help :)
I nearly forgot, the size of squares 30 pixels.</p>

<pre><code>private void DetectRectangles(Image&lt;Gray, byte&gt; img)
    {
                        var size = new Size(3, 3);
            CvInvoke.GaussianBlur(img, img, size, 0);
            CvInvoke.AdaptiveThreshold(img, img, 255, AdaptiveThresholdType.MeanC, ThresholdType.Binary, 75, 100);
            UMat cannyEdges = new UMat();
            CvInvoke.Canny(img, cannyEdges, 180, 120);
            var boxList = new List&lt;RotatedRect&gt;();

            using (VectorOfVectorOfPoint contours = new VectorOfVectorOfPoint())
            {
                CvInvoke.FindContours(cannyEdges, contours, null, RetrType.Tree, ChainApproxMethod.ChainApproxSimple);
                int count = contours.Size;
                for (int i = 0; i &lt; count; i++)
                {
                    using (VectorOfPoint contour = contours[i])
                    using (VectorOfPoint approxContour = new VectorOfPoint())
                    {
                        CvInvoke.ApproxPolyDP(contour, approxContour, CvInvoke.ArcLength(contour, true) * 0.05, true);
                        var area = CvInvoke.ContourArea(approxContour);
                        if (area &gt; 800 &amp;&amp; area &lt; 1000)
                        {
                            if (approxContour.Size == 4)
                            {
                                bool isRectangle = true;
                                Point[] pts = approxContour.ToArray();
                                LineSegment2D[] edges = PointCollection.PolyLine(pts, true);

                                for (int j = 0; j &lt; edges.Length; j++)
                                {
                                    double angle = Math.Abs(edges[(j + 1) % edges.Length].GetExteriorAngleDegree(edges[j]));
                                    if (angle &lt; 75 || angle &gt; 94)
                                    {
                                        isRectangle = false;
                                        break;
                                    }
                                }

                                if (isRectangle)
                                    boxList.Add(CvInvoke.MinAreaRect(approxContour));
                            }
                        }
                    }
                }
            }
            var resultimg = new Image&lt;Bgr,byte&gt;(img.Width, img.Height);
            CvInvoke.CvtColor(img, resultimg, ColorConversion.Gray2Bgr);
            foreach (RotatedRect box in boxList)
            {
                CvInvoke.Polylines(resultimg, Array.ConvertAll(box.GetVertices(), Point.Round), true, new Bgr(Color.Red).MCvScalar, 2);
            }
            imageBox1.Image = resultimg;
            resultimg.Save(""result_img.jpg"");       }
</code></pre>

<p>Input image:</p>

<p><img src=""https://i.stack.imgur.com/I1Qaa.jpg"" alt=""""></p>
",2016-02-08 16:08:14,2016-02-08 16:08:14,How to find a black square with any angle of rotation in the image using emgu cv,<c#><.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
39755,35427409,2016-02-16 08:29:33,,"<p>I need to get a background image from a video. I am thinking about running the video for about a minute or so to get it's background. Upon playing the video, the program will check what pixels changed every frame, then from that I think I can build a background from the video.</p>

<p>[Here is the screenshot of the video]</p>

<p><a href=""https://i.stack.imgur.com/n3479.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/n3479.jpg"" alt=""http://postimg.org/image/vxzt8smxh/""></a></p>

<p>And I edited it manually to get something like [this]</p>

<p><a href=""https://i.stack.imgur.com/kFf21.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kFf21.jpg"" alt=""http://postimg.org/image/88adk3ok5/""></a></p>

<p>Is there any way on how can I get the background automatically? Thanks!</p>
",2016-02-16 09:06:05,2016-02-16 09:38:24,How to get a background from a video?,<c#><video><background><video-streaming><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
39794,35355994,2016-02-12 06:13:36,,"<p>I am trying to calibrate my camera using Emgu CV 3.0.0 with Visual Studio 2012.</p>

<p>I want to find out the information like extrinsic, intrinsic and distortion parameters for the camera through 20 different angles of chessboard images so that I can use the camera to find other points on other images image and convert them into a world coordinates.</p>

<p>I can only find some examples from older version of EmguCV. May I have some codes or some links where can I find learn or perform the task that I need?</p>
",2016-02-14 06:47:26,2016-02-14 06:47:26,Emgu CV Camera Calibration,<c#><emgucv><camera-calibration>,,,CC BY-SA 3.0,False,False,True,False,False
39820,35394522,2016-02-14 17:03:43,,"<p>I'm new to OpenCV/EmguCV in C#. 
I tried a tutorial (<a href=""http://fewtutorials.bravesites.com/entries/emgu-cv-c/level-3---live-face-detection"" rel=""nofollow"">http://fewtutorials.bravesites.com/entries/emgu-cv-c/level-3---live-face-detection</a>) and the video captureing with the webcam was easy. Now my problem:
The tutorial was written for EmguCV 2.x. I'm using EmguCV 3.1 (I like to use the newest). Therefor I used the class <code>Mat</code> instead of the class <code>Image&lt;&gt;</code>. The class <code>Image&lt;&gt;</code> hasn't worked with <code>capture.QueryFrame();</code> 
But when I come to face detection, the tutorial says I should use the classes <code>CascadeClassifier</code> and <code>DetectHaarCascade</code>. <code>CascadeClassifier</code> is accepted but <code>DetectHaarCascade</code> is not known. 
In my 5-hour!! search I just found out, that DetectHaarCascade is obsolete but didn't find any methods replacing it exept <code>HaarCascade.Detect()</code> which is also not known.</p>

<p>I have following assamblies:</p>

<pre><code>using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.Util;
using Emgu.CV.CvEnum;
</code></pre>

<p>So, please help me: What is the replacement for DetectHaarCascade and how do I use it? Is there any tutorial for EmguCV 3.1? </p>

<p>Thanks!!</p>
",,2019-07-05 00:43:21,emguCV 3.1 - face detection,<c#><opencv><emgucv><face-detection>,,,CC BY-SA 3.0,True,False,True,False,False
39851,35362009,2016-02-12 11:55:07,,"<p>So I'm working on a little app to recognize faces as people walk into my room in order to shout things at them (Mature, I know).</p>

<p>Problem is, I have the face recognition recognizing faces, but drawing it to the screen is being problematic. Strictly speaking, it does not need to draw anything to the screen, but I just want to see it working.</p>

<p>Form1.cs</p>

<pre><code>using System;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.UI;
using Emgu.CV.Structure;
using System.Threading;
using System.Drawing;

namespace OpenCVApp1 {
    public partial class Form1 : Form {
        ImageViewer viewer = new ImageViewer(); //create an image viewer
        private Capture cap = new Capture(0);
        private CascadeClassifier cascade = new CascadeClassifier(""..\\..\\Resources\\haarcascade_frontalface_alt2.xml"");
        Thread camWorker;

        public Form1() {
            InitializeComponent();
            Application.ApplicationExit += Application_ApplicationExit;

            cap = new Capture(0);
            camWorker = new Thread(() =&gt; {
                while (true) {
                    Image&lt;Bgr, byte&gt; frame = cap.QueryFrame().ToImage&lt;Bgr, byte&gt;();
                    Image&lt;Gray, byte&gt; grayFrame = frame.Convert&lt;Gray, byte&gt;();
                    Rectangle[] faces = cascade.DetectMultiScale(grayFrame, 1.1, 10);
                    foreach (Rectangle face in faces) {
                        frame.Draw(face, new Bgr(Color.Red), 2);
                    }
                    imgCamUser.Image = frame;
                    Thread.Sleep(100);
                }
            });

            camWorker.Start();
        }

        private void Application_ApplicationExit(object sender, EventArgs e) {
            camWorker.Abort();
        }
    }
}
</code></pre>

<p>It works for a few frames, correctly draws a box around faces, and then just throws a:</p>

<pre><code>An unhandled exception of type 'Emgu.CV.Util.CvException' occurred in System.Windows.Forms.dll

Additional information: OpenCV: index is out of range
</code></pre>

<p>And that's it. I'm using OpenCV 3.10, and Emgu for the .NET wrapper.</p>

<p><a href=""https://i.stack.imgur.com/JWUjW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JWUjW.png"" alt=""Some info removed""></a></p>
",,2016-09-08 10:09:21,OpenCV Face Recognition: Index Out Of Range updating Emgu.CV.UI.ImageBox.Image,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
39867,35437664,2016-02-16 16:19:56,,"<p>How I can use OpenCV on Windows Phone 8.1 Universal in C#? I saw EmguCV but he has only commercial license for Windows Phone. Is possible other way to use OpenCV in C# on Windows Phone 8.1?</p>
",,2016-02-16 16:40:41,OpenCV on Windows Phone 8.1,<c#><opencv><windows-phone>,,,CC BY-SA 3.0,True,False,True,False,False
39884,35285355,2016-02-09 06:31:15,,"<p>I am using <code>EmguCV</code>(I don't know the exact Version) and <code>C#</code>. </p>

<p>I have created my own haarcascade along to the many tutorials found online, But when it comes to using it inside my own code, I fail. I am using the cascade with this code, but somehow the program just ends itself without any errormsg when it comes to exact that line. </p>

<pre><code>HaarCascade LicencePlate = new HaarCascade(Cascade);
MCvAvgComp[] Positives = LicencePlate.Detect(grayFrame);     // The Line it crashes
if (Positives.Length &gt; 0)
{
    foreach (var _positive in Positives)
    {
         Image&lt;Bgr, Byte&gt; tmp = frame.Copy();
         frame.ROI = _positive.rect;
         frame.Draw(_positive.rect, new Bgr(Color.Red), 0);
    }
}
</code></pre>

<p>Also, in case it might help, here are the params of my classifer</p>

<pre><code>&lt;?xml version=""1.0""?&gt; 
&lt;opencv_storage&gt; 
&lt;cascade&gt;   
&lt;stageType&gt;BOOST&lt;/stageType&gt;     
&lt;featureType&gt;HAAR&lt;/featureType&gt;   
&lt;height&gt;21&lt;/height&gt;   
&lt;width&gt;100&lt;/width&gt;   
&lt;stageParams&gt;
&lt;boostType&gt;GAB&lt;/boostType
&lt;minHitRate&gt;9.9900001287460327e-001&lt;/minHitRate&gt;
&lt;maxFalseAlarm&gt;1.0000000149011612e-001&lt;/maxFalseAlarm&gt;
&lt;weightTrimRate&gt;9.4999999999999996e-001&lt;/weightTrimRate&gt;
&lt;maxDepth&gt;1&lt;/maxDepth&gt;
&lt;maxWeakCount&gt;100&lt;/maxWeakCount&gt;&lt;/stageParams&gt; &lt;featureParams&gt;
&lt;maxCatCount&gt;0&lt;/maxCatCount&gt;
&lt;featSize&gt;1&lt;/featSize&gt;
&lt;mode&gt;ALL&lt;/mode&gt;
&lt;/featureParams&gt;  
&lt;stageNum&gt;10&lt;/stageNum&gt;
</code></pre>
",,2016-02-09 06:31:15,Programmcrash after importing the haarcascade,<c#><emgucv><haar-classifier>,,,CC BY-SA 3.0,False,False,True,False,False
39906,35365419,2016-02-12 14:46:47,,"<p>In this thread <a href=""https://stackoverflow.com/questions/35323687/x64-allows-less-threads-per-block-than-win32/35353563?noredirect=1#comment58424618_35353563"">x64 allows less threads per block than Win32?</a> there was a questions about running out of registers. I was under the impression the Nvidia has dropped support for x86 in CUDA 7.5 and beyond. This may be a foolish question but does that mean that all pointers are going to require two registers going forward? And that potentially less threads/block will be the way things work going forward?</p>
",2017-05-23 12:31:08,2016-02-21 18:43:01,x64 vs x86 for CUDA,<c++><cuda><emgucv><managed-cuda>,,,CC BY-SA 3.0,False,False,True,False,False
39916,35401971,2016-02-15 05:19:42,,"<p>I want to add a set of images to a ZIP file in C#. I use EmguCV to save the images. Currently I save the image locally first and then add to ZIP as follows. </p>

<p><strong><em>Is there anyway to add the images to ZIP file directly on the fly without saving locally?</em></strong></p>

<p>Sorry if this is a duplicate, I could not locate a clear answer for days.</p>

<pre><code>using (FileStream zipToOpen = new FileStream(this.path, FileMode.Create))
{
  using (ZipArchive zipArchive = new ZipArchive(zipToOpen, ZipArchiveMode.Update))
  {
    for (int i = 0; i &lt; clouds.Count; i++)
    {
      string imageCname = kinectId + ""_"" + dateTimes[i] + "".jpg"";
      imageCt = imageCs[i];
      imageCt.Save(""imageCt.jpg"");
      zipArchive.CreateEntryFromFile(@""imageCt.jpg"", imageCname);
      Console.WriteLine(""Flushing rgb "" + i + "" of "" + clouds.Count);
    }
  }
}
</code></pre>

<p><strong>Update 1:</strong></p>

<p>As suggested by #CarbineCoder I edited the code as follows. It saves a file. But cannot open as an image. I guess, it just save only the Byte steam. What else may I do to save it as a jpeg image.</p>

<pre><code>string imageCname = kinectId + ""_"" + dateTimes[i] + "".jpg"";
imageCt = imageCs[i];
ZipArchiveEntry zipEntryC = zipArchive.CreateEntry(imageCname);

using (var originalFileStream = new MemoryStream(imageCt.Bytes))
{
  using (var zipEntryStream = zipEntryC.Open())
  {
    originalFileStream.CopyTo(zipEntryStream);
  }
}
</code></pre>
",2016-02-15 08:22:04,2016-02-15 09:07:05,C# and EmguCV: ZIP image from memory,<c#><windows><zip><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
40021,35524538,2016-02-20 14:22:25,,"<p>I am struggling to covert Capture into Image using Emgu libraries in C#. I know that there are examples of code on Emgu website, but these don't involve camera capture. I want to get some processing done to the frames from camera.</p>

<p>This is what I have so far:</p>

<pre><code>Capture capture = null;
capture = new Capture(); //create a camera capture
capture.SetCaptureProperty(Emgu.CV.CvEnum.CapProp.Fps, 30);
capture.SetCaptureProperty(Emgu.CV.CvEnum.CapProp.FrameHeight, 240);
capture.SetCaptureProperty(Emgu.CV.CvEnum.CapProp.FrameWidth, 320); 
viewer.Image = capture.QueryFrame()
viewer.ShowDialog();
</code></pre>

<p>I would like to be able to use capture in the following line:</p>

<pre><code>Image&lt;Gray, Byte&gt; gray = capture.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp();
</code></pre>

<p>Thank you</p>
",,2016-02-22 22:19:21,"How to convert Capture to Image<Bgr,Byte> using Emgu library",<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
40051,35376717,2016-02-13 06:07:19,,"<p>I am a beginning programmer in vb.net and c#, working on a slightly advanced project.
Within a class library used for image processing, I have defined a class for fast pixel access that converts 4 channels bitmap into a byte array of bitmap.width * bitmap.height * 4 size (class is reproduced in code section #1 bellow).
Then I take action on the byte array to change some pixel value (code section #2 bellow is a sample of it). That code is very repetitive but I am yet to find a way to make it more concise and systematic. I am thinking re-usability here. It is very fast though and I would like as much as possible not to change the approach. Emgu.CV.Image set pixel method and image.data method are both much slower for the same purpose. Also no filters in Emgu library can give me as much control over the change I want to effect.
Thanks for your time and ideas</p>

<p>Section1: Class definition</p>

<pre><code> Private Class BitmapBytesRGB32
            Public ImageBytes() As Byte
            Public RowSizeBytes As Integer
            Public Const bytesPerPixel As Integer = 4
            Private m_Bitmap As Bitmap ' Creates a new private bitmap for future operation
            Private m_BitmapData As BitmapData ' and a private bitmapData class
            Public total_size As Integer

            Public Sub New(ByVal bm As Bitmap) ' passes the bitmap ref inside our BitmapBytesRGB32 class
                m_Bitmap = bm
            End Sub
            Public Sub LockBitmap() ' Lock the bitmap's data.
                Dim bounds As Rectangle = New Rectangle(0, 0, m_Bitmap.Width, m_Bitmap.Height)
                m_BitmapData = m_Bitmap.LockBits(bounds, Imaging.ImageLockMode.ReadWrite, Imaging.PixelFormat.Format32bppArgb)
                RowSizeBytes = m_BitmapData.Stride
                total_size = m_BitmapData.Stride * m_BitmapData.Height ' Allocate room for the data.
                ReDim ImageBytes(total_size)
                Marshal.Copy(m_BitmapData.Scan0, ImageBytes, 0, total_size) ' Copy the data into the ImageBytes array.
            End Sub
            Public Sub UnlockBitmap() ' Copy the data back into the bitmap
                Dim total_size As Integer = m_BitmapData.Stride * m_BitmapData.Height
                Marshal.Copy(ImageBytes, 0, m_BitmapData.Scan0, total_size)
                m_Bitmap.UnlockBits(m_BitmapData) ' Unlock the bitmap.
                ImageBytes = Nothing ' Release resources.
                m_BitmapData = Nothing ' Release resources.
            End Sub
        End Class
</code></pre>

<p>Section2: Sub method</p>

<pre><code> Private Sub PixelBasedCorrections(ByRef m_bitmap As Bitmap)
            Dim bm_bytes As New BitmapBytesRGB32(m_bitmap)

            '1
            bm_bytes.LockBitmap()
            For Xcount = 1 To m_bitmap.Width - 2
                For Ycount = 0 To m_bitmap.Height - 1
                    Dim pixPosition1 As Integer = (Ycount * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition2 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount - 1) * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition3 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount + 1) * BitmapBytesRGB32.bytesPerPixel)
                    Dim color1 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition1 + 2), bm_bytes.ImageBytes(pixPosition1 + 1), bm_bytes.ImageBytes(pixPosition1))
                    Dim color2 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition2 + 2), bm_bytes.ImageBytes(pixPosition2 + 1), bm_bytes.ImageBytes(pixPosition2))
                    Dim color3 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition3 + 2), bm_bytes.ImageBytes(pixPosition3 + 1), bm_bytes.ImageBytes(pixPosition3))
                    If color1.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color1.ToArgb &lt;&gt; color2.ToArgb AndAlso
                        color2.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color3.ToArgb = Color.Black.ToArgb Then
                        bm_bytes.ImageBytes(pixPosition1) = bm_bytes.ImageBytes(pixPosition2)
                        bm_bytes.ImageBytes(pixPosition1 + 1) = bm_bytes.ImageBytes(pixPosition2 + 1)
                        bm_bytes.ImageBytes(pixPosition1 + 2) = bm_bytes.ImageBytes(pixPosition2 + 2)
                    End If
                Next
            Next

            '2
            For Xcount = 2 To m_bitmap.Width - 3
                For Ycount = 0 To m_bitmap.Height - 1
                    Dim pixPosition1 As Integer = (Ycount * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition2 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount - 1) * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition3 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount + 2) * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition4 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount - 2) * BitmapBytesRGB32.bytesPerPixel)
                    Dim color1 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition1 + 2), bm_bytes.ImageBytes(pixPosition1 + 1), bm_bytes.ImageBytes(pixPosition1))
                    Dim color2 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition2 + 2), bm_bytes.ImageBytes(pixPosition2 + 1), bm_bytes.ImageBytes(pixPosition2))
                    Dim color3 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition3 + 2), bm_bytes.ImageBytes(pixPosition3 + 1), bm_bytes.ImageBytes(pixPosition3))
                    Dim color4 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition4 + 2), bm_bytes.ImageBytes(pixPosition4 + 1), bm_bytes.ImageBytes(pixPosition4))
                    If color1.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color1.ToArgb &lt;&gt; color2.ToArgb AndAlso
                        color2.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color3.ToArgb = Color.Black.ToArgb AndAlso
                        color4.ToArgb &lt;&gt; Color.Black.ToArgb Then 'xx
                        bm_bytes.ImageBytes(pixPosition1) = bm_bytes.ImageBytes(pixPosition4)
                        bm_bytes.ImageBytes(pixPosition1 + 1) = bm_bytes.ImageBytes(pixPosition4 + 1)
                        bm_bytes.ImageBytes(pixPosition1 + 2) = bm_bytes.ImageBytes(pixPosition4 + 2)
                    End If
                Next
            Next

            '3
            For Xcount = 1 To m_bitmap.Width - 2
                For Ycount = 0 To m_bitmap.Height - 1
                    Dim pixPosition1 As Integer = (Ycount * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition2 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount + 1) * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition3 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount - 1) * BitmapBytesRGB32.bytesPerPixel)
                    Dim color1 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition1 + 2), bm_bytes.ImageBytes(pixPosition1 + 1), bm_bytes.ImageBytes(pixPosition1))
                    Dim color2 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition2 + 2), bm_bytes.ImageBytes(pixPosition2 + 1), bm_bytes.ImageBytes(pixPosition2))
                    Dim color3 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition3 + 2), bm_bytes.ImageBytes(pixPosition3 + 1), bm_bytes.ImageBytes(pixPosition3))
                    If color1.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color1.ToArgb &lt;&gt; color2.ToArgb AndAlso
                        color2.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color3.ToArgb = Color.Black.ToArgb Then
                        bm_bytes.ImageBytes(pixPosition1) = bm_bytes.ImageBytes(pixPosition2)
                        bm_bytes.ImageBytes(pixPosition1 + 1) = bm_bytes.ImageBytes(pixPosition2 + 1)
                        bm_bytes.ImageBytes(pixPosition1 + 2) = bm_bytes.ImageBytes(pixPosition2 + 2)
                    End If
                Next
            Next

            '4
            For Xcount = 2 To m_bitmap.Width - 3
                For Ycount = 0 To m_bitmap.Height - 1
                    Dim pixPosition1 As Integer = (Ycount * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition2 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount + 1) * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition3 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount - 2) * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition4 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount + 2) * BitmapBytesRGB32.bytesPerPixel)
                    Dim color1 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition1 + 2), bm_bytes.ImageBytes(pixPosition1 + 1), bm_bytes.ImageBytes(pixPosition1))
                    Dim color2 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition2 + 2), bm_bytes.ImageBytes(pixPosition2 + 1), bm_bytes.ImageBytes(pixPosition2))
                    Dim color3 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition3 + 2), bm_bytes.ImageBytes(pixPosition3 + 1), bm_bytes.ImageBytes(pixPosition3))
                    Dim color4 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition4 + 2), bm_bytes.ImageBytes(pixPosition4 + 1), bm_bytes.ImageBytes(pixPosition4))
                    If color1.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color1.ToArgb &lt;&gt; color2.ToArgb AndAlso
                        color2.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color3.ToArgb = Color.Black.ToArgb AndAlso
                        color4.ToArgb &lt;&gt; Color.Black.ToArgb Then 'xx
                        bm_bytes.ImageBytes(pixPosition1) = bm_bytes.ImageBytes(pixPosition4)
                        bm_bytes.ImageBytes(pixPosition1 + 1) = bm_bytes.ImageBytes(pixPosition4 + 1)
                        bm_bytes.ImageBytes(pixPosition1 + 2) = bm_bytes.ImageBytes(pixPosition4 + 2)
                    End If
                Next
            Next

            '5
            For Xcount = 1 To m_bitmap.Width - 2
                For Ycount = 0 To m_bitmap.Height - 1
                    Dim pixPosition1 As Integer = (Ycount * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition2 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount + 1) * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition3 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount - 1) * BitmapBytesRGB32.bytesPerPixel)
                    Dim color1 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition1 + 2), bm_bytes.ImageBytes(pixPosition1 + 1), bm_bytes.ImageBytes(pixPosition1))
                    Dim color2 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition2 + 2), bm_bytes.ImageBytes(pixPosition2 + 1), bm_bytes.ImageBytes(pixPosition2))
                    Dim color3 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition3 + 2), bm_bytes.ImageBytes(pixPosition3 + 1), bm_bytes.ImageBytes(pixPosition3))
                    If color1.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color1.ToArgb &lt;&gt; color2.ToArgb AndAlso
                        color2.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color3.ToArgb = Color.Black.ToArgb Then
                        bm_bytes.ImageBytes(pixPosition1) = bm_bytes.ImageBytes(pixPosition2)
                        bm_bytes.ImageBytes(pixPosition1 + 1) = bm_bytes.ImageBytes(pixPosition2 + 1)
                        bm_bytes.ImageBytes(pixPosition1 + 2) = bm_bytes.ImageBytes(pixPosition2 + 2)
                    End If
                Next
            Next

            '6
            For Xcount = 0 To m_bitmap.Width - 1
                For Ycount = 1 To m_bitmap.Height - 2
                    Dim pixPosition1 As Integer = (Ycount * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition2 As Integer = ((Ycount - 1) * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition3 As Integer = ((Ycount + 1) * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim color1 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition1 + 2), bm_bytes.ImageBytes(pixPosition1 + 1), bm_bytes.ImageBytes(pixPosition1))
                    Dim color2 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition2 + 2), bm_bytes.ImageBytes(pixPosition2 + 1), bm_bytes.ImageBytes(pixPosition2))
                    Dim color3 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition3 + 2), bm_bytes.ImageBytes(pixPosition3 + 1), bm_bytes.ImageBytes(pixPosition3))
                    If color1.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color1.ToArgb &lt;&gt; color2.ToArgb AndAlso
                        color2.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color3.ToArgb = Color.Black.ToArgb Then
                        bm_bytes.ImageBytes(pixPosition1) = bm_bytes.ImageBytes(pixPosition2)
                        bm_bytes.ImageBytes(pixPosition1 + 1) = bm_bytes.ImageBytes(pixPosition2 + 1)
                        bm_bytes.ImageBytes(pixPosition1 + 2) = bm_bytes.ImageBytes(pixPosition2 + 2)
                    End If
                Next
            Next

            '7
            For Xcount = 0 To m_bitmap.Width - 1
                For Ycount = 1 To m_bitmap.Height - 2
                    Dim pixPosition1 As Integer = (Ycount * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition2 As Integer = ((Ycount + 1) * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition3 As Integer = ((Ycount - 1) * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim color1 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition1 + 2), bm_bytes.ImageBytes(pixPosition1 + 1), bm_bytes.ImageBytes(pixPosition1))
                    Dim color2 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition2 + 2), bm_bytes.ImageBytes(pixPosition2 + 1), bm_bytes.ImageBytes(pixPosition2))
                    Dim color3 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition3 + 2), bm_bytes.ImageBytes(pixPosition3 + 1), bm_bytes.ImageBytes(pixPosition3))
                    If color1.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color1.ToArgb &lt;&gt; color2.ToArgb AndAlso
                        color2.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color3.ToArgb = Color.Black.ToArgb Then
                        bm_bytes.ImageBytes(pixPosition1) = bm_bytes.ImageBytes(pixPosition2)
                        bm_bytes.ImageBytes(pixPosition1 + 1) = bm_bytes.ImageBytes(pixPosition2 + 1)
                        bm_bytes.ImageBytes(pixPosition1 + 2) = bm_bytes.ImageBytes(pixPosition2 + 2)
                    End If
                Next
            Next

            '8
            For Xcount = 2 To m_bitmap.Width - 3
                For Ycount = 0 To m_bitmap.Height - 1
                    Dim pixPosition1 As Integer = (Ycount * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition2 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount + 1) * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition3 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount - 1) * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition4 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount + 2) * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition5 As Integer = (Ycount * bm_bytes.RowSizeBytes) + ((Xcount - 2) * BitmapBytesRGB32.bytesPerPixel)
                    Dim color1 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition1 + 2), bm_bytes.ImageBytes(pixPosition1 + 1), bm_bytes.ImageBytes(pixPosition1))
                    Dim color2 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition2 + 2), bm_bytes.ImageBytes(pixPosition2 + 1), bm_bytes.ImageBytes(pixPosition2))
                    Dim color3 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition3 + 2), bm_bytes.ImageBytes(pixPosition3 + 1), bm_bytes.ImageBytes(pixPosition3))
                    Dim color4 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition4 + 2), bm_bytes.ImageBytes(pixPosition4 + 1), bm_bytes.ImageBytes(pixPosition4))
                    Dim color5 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition5 + 2), bm_bytes.ImageBytes(pixPosition5 + 1), bm_bytes.ImageBytes(pixPosition5))
                    If color1.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color1.ToArgb &lt;&gt; color2.ToArgb AndAlso
                        color2.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color2.ToArgb = color3.ToArgb AndAlso
                        color4.ToArgb = color3.ToArgb AndAlso color5.ToArgb = color3.ToArgb Then
                        bm_bytes.ImageBytes(pixPosition1) = bm_bytes.ImageBytes(pixPosition3)
                        bm_bytes.ImageBytes(pixPosition1 + 1) = bm_bytes.ImageBytes(pixPosition3 + 1)
                        bm_bytes.ImageBytes(pixPosition1 + 2) = bm_bytes.ImageBytes(pixPosition3 + 2)
                    End If
                Next
            Next

            '9
            For Xcount = 0 To m_bitmap.Width - 1
                For Ycount = 2 To m_bitmap.Height - 3
                    Dim pixPosition1 As Integer = (Ycount * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition2 As Integer = ((Ycount + 1) * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition3 As Integer = ((Ycount - 1) * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition4 As Integer = ((Ycount + 2) * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim pixPosition5 As Integer = ((Ycount - 2) * bm_bytes.RowSizeBytes) + (Xcount * BitmapBytesRGB32.bytesPerPixel)
                    Dim color1 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition1 + 2), bm_bytes.ImageBytes(pixPosition1 + 1), bm_bytes.ImageBytes(pixPosition1))
                    Dim color2 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition2 + 2), bm_bytes.ImageBytes(pixPosition2 + 1), bm_bytes.ImageBytes(pixPosition2))
                    Dim color3 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition3 + 2), bm_bytes.ImageBytes(pixPosition3 + 1), bm_bytes.ImageBytes(pixPosition3))
                    Dim color4 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition4 + 2), bm_bytes.ImageBytes(pixPosition4 + 1), bm_bytes.ImageBytes(pixPosition4))
                    Dim color5 As Color = Color.FromArgb(255, bm_bytes.ImageBytes(pixPosition5 + 2), bm_bytes.ImageBytes(pixPosition5 + 1), bm_bytes.ImageBytes(pixPosition5))
                    If color1.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color1.ToArgb &lt;&gt; color2.ToArgb AndAlso
                        color2.ToArgb &lt;&gt; Color.Black.ToArgb AndAlso color2.ToArgb = color3.ToArgb AndAlso
                        color4.ToArgb = color3.ToArgb AndAlso color5.ToArgb = color3.ToArgb Then
                        bm_bytes.ImageBytes(pixPosition1) = bm_bytes.ImageBytes(pixPosition3)
                        bm_bytes.ImageBytes(pixPosition1 + 1) = bm_bytes.ImageBytes(pixPosition3 + 1)
                        bm_bytes.ImageBytes(pixPosition1 + 2) = bm_bytes.ImageBytes(pixPosition3 + 2)
                    End If
                Next
            Next

' MORE CODE IN THE SAME VEIN.......

 bm_bytes.UnlockBitmap()
</code></pre>
",,2016-02-14 23:36:46,Vb.net refactoring code re. locking/unlocking bitmapdata & repetitive pixel access,<vb.net><bitmap><emgucv><bitmapdata>,,,CC BY-SA 3.0,False,False,True,False,False
40101,35592247,2016-02-24 02:39:10,,"<p>I am having some issues with detecting specific ""blobs"" in a set of images.  Not all images are the same, but I suppose the same parameters would be used to detect anyways.
<img src=""https://i.imgur.com/ue8tDPU.jpg"" alt=""Image1""></p>

<p>If you zoom in, you will see small, yellow aphids on the leaf.  My goal is to single these out and count them.  I don't really need to do much to the image, just obtain a count of them.  </p>

<p>Right now, I have this:</p>

<pre><code>using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using Emgu.CV;
using Emgu.CV.Features2D;
using Emgu.CV.Structure;
using Emgu.CV.Util;

namespace AphidCounter
{
    class Program
    {
        static void Main(string[] args)
        {
            // Read image
            Mat im_in = CvInvoke.Imread(""myimage1.jpg"", Emgu.CV.CvEnum.LoadImageType.Grayscale);
            //Mat im_in = CvInvoke.Imread(""myimage2.png"", Emgu.CV.CvEnum.LoadImageType.Color);
            Mat im = im_in;
            CvInvoke.Threshold(im_in, im, 40, 255, Emgu.CV.CvEnum.ThresholdType.BinaryInv);  // 60, 255, 1

            //CvInvoke.NamedWindow(""Blob Detector"", Emgu.CV.CvEnum.NamedWindowType.AutoSize);

            DetectBlobs(im, 0);

            CvInvoke.WaitKey(0);
        }

        static void DetectBlobs(Mat im, int c)
        {

            int maxT = 50;
            int minA = 125; // Minimum area in pixels
            int maxA = 550; // Maximum area in pixels

            SimpleBlobDetectorParams EMparams = new SimpleBlobDetectorParams();
            SimpleBlobDetector detector;

            EMparams.MinThreshold = 0;
            EMparams.MaxThreshold = 100;

            if (minA &lt; 1) minA = 1;
            EMparams.FilterByArea = true;
            EMparams.MinArea = minA;
            EMparams.MaxArea = maxA;

            if (maxT &lt; 1) maxT = 1;
            EMparams.MinConvexity = (float)maxT / 1000.0F; // 0.67

            EMparams.FilterByInertia = true;
            EMparams.MinInertiaRatio = 0.01F;

            EMparams.FilterByColor = true;
            EMparams.blobColor = 0;

            VectorOfKeyPoint keyPoints = new VectorOfKeyPoint();

            detector = new SimpleBlobDetector(EMparams);
            detector.DetectRaw(im, keyPoints);

            Mat im_with_keypoints = new Mat();
            Bgr color = new Bgr(0, 0, 255);
            Features2DToolbox.DrawKeypoints(im, keyPoints, im_with_keypoints, color, Features2DToolbox.KeypointDrawType.DrawRichKeypoints);

            // Show blobs
            CvInvoke.Imwrite(""keypoints1.jpg"", im_with_keypoints);
            CvInvoke.Imshow(""Blob Detector "" + keyPoints.Size, im_with_keypoints);

            System.Console.WriteLine(""Number of keypoints: "" + keyPoints.Size);

        }
    }
}
</code></pre>

<p>However, this is the result:
<img src=""https://i.imgur.com/S6dpEUX.jpg"" alt=""Image2""></p>

<p>Am I not getting the parameters right?  Or is there something else that I'm missing? </p>
",,2016-02-26 00:56:32,Blob Detection with light-colored blobs,<opencv><image-processing><emgucv><opencv3.0>,,,CC BY-SA 3.0,True,True,True,False,False
40110,35455629,2016-02-17 11:37:14,,"<p>I am developing a simple application on face recognition using EmguCv and c#. i am using ms access data to store sample data base. whenever in compile the code i get error <strong><em>""OpenCV: Different sizes of objects""</em></strong> Here is my code.... thanks in ADVANCE.</p>

<pre><code>public partial class Facerecognition : Form
{
    EigenObjectRecognizer Recognizer;
    private Capture cam;
    Image&lt;Bgr, Byte&gt; frame;
    Image&lt;Gray, Byte&gt; frame2;
    private HaarCascade Haar;
    MCvFont font = new MCvFont(FONT.CV_FONT_HERSHEY_TRIPLEX, 0.5d, 0.5d);

    OleDbConnection Connection = new OleDbConnection();
    OleDbDataAdapter Adapter;
    DataTable Table = new DataTable();

    List&lt;string&gt; FaceName = new List&lt;string&gt;();
    List&lt;Image&lt;Gray, byte&gt;&gt; FaceImg = new List&lt;Image&lt;Gray, byte&gt;&gt;();
    int ConTrain;
    string name;
    Image result;

    public Facerecognition()
    {
        InitializeComponent();
        Haar = new HaarCascade(""haarcascade_frontalface_default.xml"");
        ConnectDatabase();
    }

    private void button3_Click(object sender, EventArgs e)
    {
        Traningset t = new Traningset();
        t.Show();
    }

    public void Process(object sender, EventArgs e)
    {
        frame = cam.QueryFrame();
        LoadRecognizer();
        pictureBox1.Image = frame.ToBitmap();
        pictureBox1.SizeMode = PictureBoxSizeMode.StretchImage;
    }

    private void button2_Click(object sender, EventArgs e)
    {
        cam = new Capture();
        Application.Idle += Process;
    }

    /*public void FaceDetection()
    {
        frame2 = frame.Convert&lt;Gray, Byte&gt;();
        var faces = frame.DetectHaarCascade(Haar, 1.2, 3, HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(25, 25))[0];

        foreach (var face in faces)
        {
            frame.Draw(face.rect, new Bgr(Color.Black), 3);
            // MessageBox.Show(""Face detected "" + faces.Length.ToString());
        }

    }*/

    public void ConnectDatabase()
    {
        Connection.ConnectionString = @""Provider=Microsoft.Jet.OLEDB.4.0;Data Source=facedatabase.mdb.mdb"";
        Adapter = new OleDbDataAdapter(""Select facename, faceimg from traningset"", Connection);
        OleDbCommandBuilder CommandBuilder = new OleDbCommandBuilder(Adapter);
        Adapter.Fill(Table);
        Connection.Open();
        if (Table.Rows.Count != 0)
        {
            int numofrows = Table.Rows.Count;
        }
        Connection.Close();
    }

    public Image GetFaceFromDB()
    {
            Image Fetehedimg;
            byte[] fetechedimgbytes = (byte[])Table.Rows[0][""faceimg""];
            MemoryStream stream = new MemoryStream(fetechedimgbytes);
            Fetehedimg = Image.FromStream(stream);
            return Fetehedimg;
    }
    public void LoadRecognizer()
    {
        /////////////////////////////////////////////// FACE DETECTER /////////////////////////////////////////////////////
        frame2 = frame.Convert&lt;Gray, Byte&gt;();
        var faces = frame.DetectHaarCascade(Haar, 1.2, 3, HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(25, 25))[0];

        foreach (var face in faces)
        {
            frame.Draw(face.rect, new Bgr(Color.Black), 3);
            // MessageBox.Show(""Face detected "" + faces.Length.ToString());
        }
        ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////

        ConnectDatabase();
        Bitmap bitimage;
        Image img;
        img = new Bitmap(100, 100);
        int numofrows=0;
        if(Table.Rows.Count!=0)
        {
             numofrows=Table.Rows.Count;
        }
        for (int i = 0; i &lt; numofrows; i++)
        {
            byte[] fetchedBytes = (byte[])Table.Rows[i][""faceimg""];
            MemoryStream stream = new MemoryStream(fetchedBytes);
            bitimage = new Bitmap(stream);
            //bitimage = bitimage.Resize(100, 100, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC);
            FaceImg.Add(new Emgu.CV.Image&lt;Gray, Byte&gt;(bitimage));

            String faceName = (String)Table.Rows[i][""facename""];
            FaceName.Add(faceName);
        }
        if (FaceImg.ToArray().Length != 0)
        {

            MCvTermCriteria termCrit = new MCvTermCriteria(4, 0.001);

            Recognizer = new EigenObjectRecognizer(
                FaceImg.ToArray(),
                FaceName.ToArray(),
                3000,
                ref termCrit);

           MessageBox.Show(""face recognized"");
           // frame.Draw(name, ref font, new Point(faces.rect.X - 2, faces.rect.Y - 2), new Bgr(Color.LightGreen));
        }

    }

}
</code></pre>

<p>}</p>
",,2016-02-18 12:24:35,I need help C# and Emgu cv,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
40112,35456073,2016-02-17 11:57:22,,"<p>I'm working emgucv project, But I have problem.</p>

<p>I want as a result of this image</p>

<p><a href=""https://i.stack.imgur.com/ioUMi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ioUMi.png"" alt=""enter image description here""></a></p>

<p>I accept the four input coordinates and want to Perspective with a new image.</p>

<p>But my code is impossible...</p>

<p>This is my code:</p>

<pre><code>namespace WindowsFormsApplication1
{
    public partial class Form1 : Form
    {
        Image&lt;Bgr, byte&gt; image = new Image&lt;Bgr, byte&gt;(@""C:\Users4.jpg"");
        Bitmap bitImage;
        ImageConverter im = new ImageConverter();
        int w, h;   

        int count = 4;
        int a = 0;

        HomographyMatrix homography;

        PointF[] spoint = new PointF[4];
        PointF[] dpoint = new PointF[4];

        public Form1()
        {
            InitializeComponent();
        }

        private void Form1_Shown(object sender, EventArgs e)
        {
            bitImage = new Bitmap(@""C:\Users4.jpg"");

            w = bitImage.Width;
            h = bitImage.Height;

            this.Size = new System.Drawing.Size(w, h);

            ibCanvas.BackgroundImage = bitImage;
        }

        /*
         When taking the mouse coordinates being the X and Y axes to the coordinates stored in the Point array.
         */
        private void ibCanvas_MouseDown(object sender, MouseEventArgs e)
        {
            if (count != 0)
            {
                spoint[a] = new PointF(e.X, e.Y);
                a++;
                count -= 1;
            }

            if (count == 0)
            {
                count = 4;
                a = 0;

                PointF[] pts1 = new PointF[4];
                PointF[] pts2 = new PointF[4];

                label1.Text = spoint[0].ToString();
                label2.Text = spoint[1].ToString();
                label3.Text = spoint[2].ToString();
                label4.Text = spoint[3].ToString();

                double w1 = Math.Sqrt(Math.Pow(spoint[3].X - spoint[0].X, 2)
                                    + Math.Pow(spoint[3].X - spoint[0].X, 2));
                double w2 = Math.Sqrt(Math.Pow(spoint[2].X - spoint[1].X, 2)
                                    + Math.Pow(spoint[2].X - spoint[1].X, 2));

                double h1 = Math.Sqrt(Math.Pow(spoint[3].Y - spoint[2].Y, 2)
                                    + Math.Pow(spoint[3].Y - spoint[2].Y, 2));
                double h2 = Math.Sqrt(Math.Pow(spoint[0].Y - spoint[1].Y, 2)
                                    + Math.Pow(spoint[0].Y - spoint[1].Y, 2));



                double maxWidth = (w1 &lt; w2) ? w1 : w2;
                double maxHeight = (h1 &lt; h2) ? h1 : h2;

                dpoint[0].X = 0;
                dpoint[0].Y = 0;

                dpoint[1].X = 0;
                dpoint[1].Y = ((float)maxHeight-1);

                dpoint[2].X = ((float)maxWidth - 1); ;
                dpoint[2].Y = ((float)maxHeight - 1); ;

                dpoint[3].X = ((float)maxWidth - 1); ;
                dpoint[3].Y = 0;

                homography = CameraCalibration.GetPerspectiveTransform(spoint, dpoint);
                Image&lt;Bgr, byte&gt; newImage = image.WarpPerspective(homography, Emgu.CV.CvEnum.INTER.CV_INTER_CUBIC, Emgu.CV.CvEnum.WARP.CV_WARP_DEFAULT, new Bgr(0, 0, 0));

                CvInvoke.cvShowImage(""new Image"", newImage);
            }
        }
    }
}
</code></pre>

<p>I want really solve this problem</p>

<p>Please Help me!</p>
",2016-02-17 13:37:44,2016-02-17 13:37:44,Emgu cv Perspective Transform,<c#><emgucv><perspective><opencvsharp>,,,CC BY-SA 3.0,False,False,True,False,False
40138,35458017,2016-02-17 13:26:56,,"<p>I am creating an application which takes video from a camera hosted on the web, runs it through a computer vision algorithm to detect humans (written in C# using EmguCV's OpenCV wrapper) and streams the processed video to an ASP.NET client. </p>

<p>The process I believed would work was to have Azure Media Services create a live stream channel for the video, and somewhere in the process inject my code to process the video. The algorithm uses a SQL database for much of its decision making, and so I thought to put it in a WebJob and have it process video as it is put in storage. I would much rather process it somewhere in the Azure Media Services process, instead of using a WebJob.  </p>

<p>My question is: is there a way to process the video as it is coming in, so what is seen in storage is the processed video with boxes around the people (boxes placed by my algorithm which takes a frame as input and outputs a frame)? If so, where can I put my logic to do this, in the encoder setup? </p>

<p>Also, if you have another way of doing it please let me know! I am open to ideas! I plan on scaling this app to use more than one camera as input, and the client should be able to switch between feeds. This is off topic from my question but is a consideration. I know it is possible to have a WebJob take the video out of storage, process it, and put it back, but the app loses the ""Live"" aspect then. </p>

<p>Technology Stack:
Azure SQL DB created
Azure Website created
Azure Media Services and Storage created
Possible Azure WebJob to handle algorithm? </p>

<p>Thank you so much in advance for any help! </p>
",2016-02-19 21:41:05,2016-02-19 21:41:05,How to perform processing of Azure Media Service Live Stream video as it's being streamed?,<c#><asp.net-mvc><opencv><video><azure-media-services>,,,CC BY-SA 3.0,True,False,True,False,False
40189,35460986,2016-02-17 15:31:07,,"<p>I am currently doing a project in which I am trying to identify humans based on hands vascular pattern in C# using Emgu CV.
The gray-scale image of the hand was first processed using the Adaptive Threshold function.
Now I want to create a mask of the image using the morphological operations.
The purpose is to remove the noise from the image.
This is the adaptive-thresholded image:</p>

<p><img src=""https://i.stack.imgur.com/t1r9P.jpg"" alt=""""></p>

<p>Kindly guide me which function should I use and how to use.</p>
",2016-02-17 15:34:55,2016-02-17 16:49:01,Morphological Operations On Image,<c#><opencv><image-processing><emgucv><image-morphology>,,,CC BY-SA 3.0,True,False,True,False,False
40245,35682281,2016-02-28 12:03:55,,"<p>I have implemented detection using HoughCircles on to a still image, The method automatically detects the radius of circles to enable drawing them. Currently I am only able to display the radius of circles one by one by into a text box each as follows:</p>

<p>txtDetect.Text = circles[0].Radius.ToString();</p>

<p>txtDetect1.Text = circles[1].Radius.ToString();</p>

<p>and when I try to convert it to a list it gives the following error:</p>

<p>Cannot implicitly convert type 'Emgu.CV.Structure.CircleF[]' to 'System.Collections.Generic.List'</p>

<p>The related code is as follows:</p>

<pre><code>        #region circle detection
        Stopwatch watch = Stopwatch.StartNew();
        double cannyThreshold = 100.0;
        double circleAccumulatorThreshold = 80;
        CircleF[] circles = CvInvoke.HoughCircles(uimage, HoughType.Gradient, 2.0, 20.0, cannyThreshold, circleAccumulatorThreshold, 5);

        watch.Stop();
        msgBuilder.Append(String.Format(""Hough circles - {0} ms; "", watch.ElapsedMilliseconds));
        #endregion

        imgOriginal.Image = img;
        this.Text = msgBuilder.ToString();

        #region draw circles
        Image&lt;Bgr, Byte&gt; circleImage = img.CopyBlank();

        foreach (CircleF circle in circles)
        {
            circleImage.Draw(circle, new Bgr(Color.Brown), 2);
        }
        imgDetect.Image = circleImage;
</code></pre>

<p>Thank you kindly for your help.</p>
",2016-02-28 23:46:47,2016-03-03 15:24:21,EMGU CV in C# Displaying item properties from a list into a list box,<c#><opencv><emgucv><hough-transform>,,,CC BY-SA 3.0,True,False,True,False,False
40289,35544806,2016-02-22 02:18:41,,"<p>I need to get the shape of the person given a pattern that came from the absolute difference of the two pictures, then converting it to bitmap to remove all the black pixels. How can I get the person's original body given these images</p>

<p>Original image, Absolute difference image, Removed black pixel(Bitmap)</p>

<p><a href=""https://i.stack.imgur.com/OEzvy.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OEzvy.jpg"" alt=""Original image""></a>     <a href=""https://i.stack.imgur.com/6VfQU.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6VfQU.jpg"" alt=""Absolute difference output""></a> <a href=""https://i.stack.imgur.com/wA5Ny.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wA5Ny.png"" alt=""Bitmap""></a></p>
",,2016-02-23 14:45:51,How to get content of an image from a pattern?,<c#><image-processing><imagemagick><emgucv><mask>,,,CC BY-SA 3.0,False,False,True,False,False
40290,35544864,2016-02-22 02:28:41,,"<p>I am a newbie of programming. I am using emgucv for my project and now I am going to detect the movement of an edge. I may want to use this vector for further operation. However, I only find a lot of documentation on tracking the movement of features points. How can I do it on an edge?</p>

<p>Thx a lot.</p>
",,2016-02-22 02:28:41,How to get the movement of a edge by Emgucv,<c#><line><emgucv><opticalflow>,,,CC BY-SA 3.0,False,False,True,False,False
40327,35648079,2016-02-26 09:35:35,,"<p>There are many functions in Emgu CV which need InputArray. For example:</p>

<pre><code>var r = new Mat();
var t = new Mat();
CvInvoke.SolvePnP(b3D, b2D, _cM, _dC, r, t);
</code></pre>

<p>What types of <strong><em>r</em></strong> and <strong><em>t</em></strong> can I use instead of Mat?</p>

<p>For example, in C++ OpenCV it is possible to use std::vector where InputArray is needed</p>

<pre><code>std::vector&lt;Point2f&gt; vec;
// points or a circle, somegow fill it
cv::transform(vec, vec, cv::Matx23f(0.707, -0.707, 10, 0.707, 0.707, 20));
</code></pre>
",,2016-03-04 08:26:10,InputArray as parameter in Emgu CV,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
40391,35693063,2016-02-29 06:17:01,,"<p>I have 2 images, the 1st image is the original image and the 2nd image is the mask.
<a href=""https://i.stack.imgur.com/i4AJV.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/i4AJV.jpg"" alt=""Original image""></a>
<a href=""https://i.stack.imgur.com/SKlce.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/SKlce.jpg"" alt=""Mask""></a></p>

<p>How can I apply the mask as the opacity or alpha channel for the first image using EmguCV in C#?</p>
",,2016-02-29 06:17:01,Copying image from a mask,<c#><image-processing><emgucv><mask>,,,CC BY-SA 3.0,False,False,True,False,False
40457,35732489,2016-03-01 20:10:53,,"<p>I am somewhat new to SVMs and object recognition, and am currently attempting to train an SVM using Emgu CV 3.0, save it to a file, and then load it (for use in HOGDescriptor.SetSVMDetector).</p>

<p>However, among other problems, I cannot find a way to load the SVM after I have saved it.</p>

<p>So far, my code basically does the following:</p>

<pre><code>SVM myFirstSVM = new SVM();

// do some stuff, set some parameters...

myFirstSVM.Train(someParameters);

myFirstSVM.Save(""filePath"");
</code></pre>

<p>From here, the problem lies with <strong>reloading</strong> the SVM after being saved. I have checked several help topics and pages, and the only related things I could find pertained to OpenCV, which used the following method:</p>

<pre><code>SVM mySecondSVM;

mySecondSVM.load(""filePath"");
</code></pre>

<p>However, I could find no method "".load()"" in Emgu 3.0, although it appeared to be present in previous versions.  Is there an equivalent of this OpenCV method in Emgu 3.0?  I would assume there is, and I am sure it is fairly simple, but I cannot for the life of me find it.</p>
",2016-03-01 23:39:42,2016-07-22 14:15:31,Load Trained SVM – Emgu CV,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
40466,35735557,2016-03-01 23:17:03,,"<p>I'm working on an tool for image processing (C#, using a EmguCV)
I need to get best performance on single operations on pixels.</p>

<p>I have read a lot of threads about <code>LockBit()</code> and copying a values from pointer to array of byte as a BEST method (when performance is priority) to get/set pixel value.</p>

<p>I found some implementations like this:
<a href=""http://www.codeproject.com/Tips/240428/Work-with-bitmap-faster-with-Csharp"" rel=""nofollow"">http://www.codeproject.com/Tips/240428/Work-with-bitmap-faster-with-Csharp</a></p>

<p>And I have compared it to much simpler method:</p>

<pre><code>Image&lt;Bgr, byte&gt; image = new Image&lt;Bgr, byte&gt;(Bitmap);
byte[,,] data = image.Data;

//And then get r channel like:
byte rChannel = data[y,x,0];

//And set r channel like:
data[y,x,0] = color.R;
</code></pre>

<p>So, I have used a implementation from link above but i cut out a creating <code>Color</code> like <code>Color.FromArgb(r, g, b);</code> and assume that image depth = 24, just to optimilize performance (I'm returning a 1D array of byte as a color)</p>

<p>My results (Image 2048x2048 - 4194304 operations of comparing color of pixel with <code>Color.White</code> - done 3 times):</p>

<pre><code>Via `LockBit()` and pointer method:
00:00:00.7971876
00:00:00.7569262
00:00:00.7693977

Via `Image&lt;,&gt;.Data` method:
00:00:00.7957318
00:00:00.8136698
00:00:00.8010817
</code></pre>

<p>I dont see any significant performance difference between a unsafe <code>LockBits()</code> and pointer method and pretty clear and easy <code>Image&lt;,&gt;.Data</code> one. </p>

<p>Can someone explain me why the <code>LockBits()/Pointer</code> method is called a super fast? Maybe I'm missing something (as I said - i have used a implementation from link above).</p>
",2016-03-02 07:35:01,2016-03-02 07:35:01,"BitmapData vs Image<,>.Data when accessing to pixel value - performance",<c#><image><performance><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
40606,35824267,2016-03-06 07:26:46,,"<p>Here's my code on C# code with the EmguCV wrapper. I don't know how to convert it to useable code on iOS for use with OpenCV. Anyone OpenCV experts out there?</p>

<pre><code>public Matrix&lt;float&gt; ComputeSingleDescriptors(string imagePath)
{
     private SURFDetector detector = new SURFDetector(surfHessianThresh, surfExtendedFlag);
     Matrix&lt;float&gt; descs;

     using (Image&lt;Gray, Byte&gt; img = new Image&lt;Gray, byte&gt;(imagePath))
     {
         VectorOfKeyPoint keyPoints = detector.DetectKeyPointsRaw(img, null);
         descs = detector.ComputeDescriptorsRaw(img, null, keyPoints);
     }

     return descs;
}
</code></pre>
",,2016-03-17 12:37:23,How do I do this EmguCV C# code (that uses SURF) on iOS with OpenCV?,<c#><c++><ios><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
40607,35824300,2016-03-06 07:31:13,,"<p>Here's the code. See the commented line for where possible optimization could be (at the <code>foreach</code>). Anyone have suggestions on improving the speed here?</p>

<pre><code>public void FindMatches(Matrix&lt;float&gt; dbDescriptors, Matrix&lt;float&gt; queryDescriptors, ref IList&lt;IndecesMapping&gt; imap)
    {
        var indices = new Matrix&lt;int&gt;(queryDescriptors.Rows, 2); // matrix that will contain indices of the 2-nearest neighbors found
        var dists = new Matrix&lt;float&gt;(queryDescriptors.Rows, 2); // matrix that will contain distances to the 2-nearest neighbors found

        // create FLANN index with 4 kd-trees and perform KNN search over it look for 2 nearest neighbours
        var flannIndex = new Index(dbDescriptors, 4);
        flannIndex.KnnSearch(queryDescriptors, indices, dists, 2, 24);

        for (int i = 0; i &lt; indices.Rows; i++)
        {
            // filter out all inadequate pairs based on distance between pairs
            if (dists.Data[i, 0] &lt; (0.5 * dists.Data[i, 1]))
            {
                // find image from the db to which current descriptor range belongs and increment similarity value.
                // in the actual implementation this should be done differently as it's not very efficient for large image collections.
                foreach (var img in imap)
                {
                    if (img.IndexStart &lt;= indices[i, 0] &amp;&amp; img.IndexEnd &gt;= indices[i, 0])
                    {
                        img.Similarity++;
                        break;
                    }
                }
            }
        }
    }
</code></pre>
",,2016-09-30 19:14:49,How can I speed up this image matching code in EmguCV C# code?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
40611,35860273,2016-03-08 06:12:10,,"<p>I want to capture video stream from an ip. I've seen this but the type name cvCreateFileCapture does not exist on cvInvoke in Emgu 3.0 is there any way I can capture video from an ip?</p>

<p>I've tried using this, it didn't work but the message box shows which means capture is not null. imageCamera is empty</p>

<pre><code> _capture = new Capture(""http://uname:pass@10.16.33.158/axis-cgi/mjpg/video.cgi"");here
 if (_capture != null) //if camera capture has been successfully created
        {
            MessageBox.Show(""Capture success"");
            _capture.ImageGrabbed += ProcessFrame;
            _capture.Start();
        }

 _capture.Retrieve(frame, 0);
 Image&lt;Bgra, Byte&gt; newFrame = new Image&lt;Bgra, Byte&gt;(frame.Bitmap);
 imageCamera.Image = newFrame;
</code></pre>

<p>I entered this <a href=""http://uname:pass@10.16.33.158/axis-cgi/mjpg/video.cgi"" rel=""nofollow noreferrer"">http://uname:pass@10.16.33.158/axis-cgi/mjpg/video.cgi</a> in my browser and the video stream is there.</p>

<p>I've seen I've seen <a href=""https://stackoverflow.com/questions/10144527/how-to-get-video-from-ip-camera-using-emgucv/10148816#10148816"">this</a>  but the type name cvCreateFileCapture does not exist on cvInvoke in Emgu 3.0 is there any way I can capture video from an ip?</p>

<p>Tried entering <a href=""http://uname:pass@10.16.33.158/axis-cgi/mjpg/video.cgi"" rel=""nofollow noreferrer"">http://uname:pass@10.16.33.158/axis-cgi/mjpg/video.cgi</a> into VLC -> Media -> Network stream, it works perfectly. But why I can't see it on my capture?</p>
",2017-05-23 12:31:11,2016-03-09 13:35:12,IP Camera integration in Emgu Capture,<c#><video><emgucv><capture><ip-camera>,,,CC BY-SA 3.0,False,False,True,False,False
40644,36004585,2016-03-15 07:02:27,,"<p>I'm using <a href=""https://github.com/artemisvision/emgu_openCV"" rel=""nofollow"">Emgu.CV</a> .net Wrapper for <a href=""http://opencv.org"" rel=""nofollow"">OpenCV</a> to accomplish this. I got the following data from <code>FindMatch</code> Method.</p>

<pre><code>FindMatch(modelImage, observedImage, out matchTime, out modelKeyPoints, out observedKeyPoints, matches,
               out mask, out homography);
</code></pre>

<p>How can I calculate similarity from <code>mask</code>,<code>matches</code> or <code>homography</code>?</p>

<p>I want to identify the images of the same object taken. (Photo will be taken in same angle and orientation)</p>
",2016-03-16 05:09:48,2016-03-16 05:09:48,How can I get Image similarity in percentage from Homography matrix?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
40662,35864267,2016-03-08 10:01:00,,"<p>I'm trying to wrap a <code>C++</code> class which uses <code>OpenCv</code> so that I can use it in <code>C#</code>.</p>

<p>I have the <code>C++</code> function:</p>

<pre><code>void ImageBrightener::BrightenImage(const cv::Mat&amp; sourceImage, cv::Mat&amp; targetImage, int maxTarget)
{
    double scaleFactor;
    double shiftFactor = 0;
    double minVal = DBL_MAX, minValTemp;
    double maxVal = -DBL_MAX, maxValTemp;
    auto numPixels = 0;
    const auto RANGE_TOP_EXTEND = 10;
    const auto RANGE_BOTTOM_EXTEND = 7;

    assert(sourceImage.type() == CV_8UC1);
    assert(sourceImage.channels() == 1);

    cv::minMaxIdx(sourceImage, &amp;minValTemp, &amp;maxValTemp);
    if (minValTemp &lt; minVal)
    minVal = minValTemp;
    if (maxValTemp&gt;maxVal)
        maxVal = maxValTemp;

    numPixels += sourceImage.cols * sourceImage.rows;

    if (maxVal == minVal)
    {
        sourceImage.convertTo(targetImage, CV_8UC1, 1, shiftFactor);
        return;
    }

    // Account for prev/curr ROI differences - add a bit to the range
    maxVal += RANGE_TOP_EXTEND;
    minVal -= RANGE_BOTTOM_EXTEND;
    minVal = std::max(minVal, 0.);

    if ((maxVal - minVal) &lt; maxTarget)
    {
        scaleFactor = maxTarget / (maxVal - minVal);
        shiftFactor = -1 * scaleFactor * minVal;

        sourceImage.convertTo(targetImage, CV_8UC1, scaleFactor, shiftFactor);
        return;
    }

    auto fltMinVal = static_cast&lt;float&gt;(minVal) - 1;
    auto fltMaxVal = static_cast&lt;float&gt;(maxVal) + 1;

    // Check histogram
    const unsigned int *currval;

    #define BINS   (100)
    #define CUTOFF (0.00003)
    #define RESCUTOFF (0.2)

    int hist[BINS] = { 0 };
    int bin;

    numPixels += sourceImage.cols * sourceImage.rows;
    for (auto rowIndex = 0; rowIndex &lt; sourceImage.rows; rowIndex++)
    {
        currval = sourceImage.ptr&lt;unsigned&gt;(rowIndex, 0);
        for (auto colIndex = 0; colIndex &lt; sourceImage.cols; colIndex++)
        {
            bin = static_cast&lt;int&gt;((BINS - 1) * ((*currval - fltMinVal) / (fltMaxVal - fltMinVal)));
            assert(bin &gt;= 0 &amp;&amp; bin &lt; BINS);
            hist[bin]++;
            ++currval;
        }
    }

    double ratio;
    auto sum = 0;
    int i;
    for (i = BINS - 1; i &gt;= 0; i--)
    {
        sum += hist[i];
        ratio = static_cast&lt;double&gt;(sum) / static_cast&lt;double&gt;(numPixels);
        if (ratio &gt; CUTOFF)
            break;
    }
    if (static_cast&lt;double&gt;(BINS - i) / static_cast&lt;double&gt;(BINS) &gt; RESCUTOFF)
        fltMaxVal = fltMinVal + ((i + 2)*(fltMaxVal - fltMinVal)) / BINS;

    // Account for prev/curr ROI differences - add a bit to the range
    fltMaxVal += RANGE_TOP_EXTEND;
    fltMinVal -= RANGE_BOTTOM_EXTEND;
    fltMinVal = std::max(fltMinVal, 0.f);

    scaleFactor = maxTarget / (fltMaxVal - fltMinVal);
    shiftFactor = -1 * scaleFactor * fltMinVal;

    sourceImage.convertTo(targetImage, CV_8UC1, scaleFactor, shiftFactor);
}
</code></pre>

<p>When I test this code using the following <code>C++</code> code:</p>

<pre><code>int main()
{
    auto* m_imageBrightener = new ImageBrightener();
    auto inputImage = cv::imread(""E:\\ttt.png"", CV_LOAD_IMAGE_UNCHANGED);

    cv::Mat outputImage;

    m_imageBrightener-&gt;BrightenImage(inputImage, outputImage, 2000);
    cv::imwrite(""E:\\new_ttt.png"", outputImage);
}
</code></pre>

<p>Everything works, the code does what it should, which is to get a dark 8bit image, and brighten it (I tried replacing 200 with 500 - it works fine). The <code>new_ttt.png</code> image is brightened as expected.</p>

<p>On the other hand, I have the following <code>/Clr</code> code, which wraps the <code>C++</code> code and creates a <code>DLL</code> from it:</p>

<pre><code>array&lt;System::Byte&gt;^ ImageProcessing::ImageBrightenerWrapper::BrightenImage(array&lt;System::Byte&gt;^ sourceImage, int imageWidth, int imageHeight, int maxTarget)
{
    array&lt;System::Byte&gt;^ targetImage = (array&lt;System::Byte&gt;^)sourceImage-&gt;Clone();

    pin_ptr&lt;System::Byte&gt; sourcePointer = &amp;sourceImage[0];
    pin_ptr&lt;System::Byte&gt; targetPointer = &amp;targetImage[0];

    cv::Mat sourceMat(imageHeight, imageWidth, CV_8UC1, (unsigned short*)sourcePointer);
    cv::Mat targetMat(imageHeight, imageWidth, CV_8UC1, (unsigned short*)targetPointer);

    targetMat.setTo(0);
    m_imageBrightener-&gt;BrightenImage(sourceMat, targetMat, maxTarget);

    uchar* tempPointer;
    for (auto rowIndex = 0; rowIndex &lt; imageHeight; ++rowIndex)
    {
        tempPointer = targetMat.ptr&lt;uchar&gt;(rowIndex);
        for (auto colIndex = 0; colIndex &lt; imageWidth; ++colIndex)
            targetImage[rowIndex + colIndex] = tempPointer[colIndex];
    }

    return targetImage;
}
</code></pre>

<p>With it, I also have a <code>WPF</code> application which has a slider which controls the <code>maxTarget</code> parameter.</p>

<p>This is what I'm facing:</p>

<p>1) On the one hand, any value between 0 and 960 for <code>maxTarget</code> brightens the row index which matches <code>maxTarget / 2</code> - Meaning, that when I slide the slider to the right, for greater values, I get part of the image bright and the rest is as the original. (Example: if <code>maxTarget</code> is 300, then all of the rows between row #0 and row #150 will be brighter and the rest will be like the original).</p>

<p>2) On the other hand, if I cross the value if 960 for <code>maxTarget</code> then the application crashes with the following error (even though the code is surrounded with <code>try/catch</code>): </p>

<p><strong>""An exception of type: 'System.AccessViolationException' occurred in ImageBrightenerWrapper.dll but was not handled in user code. Additional information: Attempted to read or write protected memory. This is pften an indication that other memory is corrupt.""</strong></p>

<p>What am I doing wrong here?</p>
",,2016-03-08 13:48:14,Wrapping OpenCv C++ code for use in C#,<c#><c++><opencv><clr><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
40692,36006490,2016-03-15 08:54:50,,"<p>I have been trying to use the EMGU Example SURFFeature to determine if an image is in a collection of images. But I am having problems understanding how to determine if a match was found.</p>

<p>.........Original image ..............................Scene_1 (match).........................Scene_2 (no match)</p>

<p><img src=""https://i.stack.imgur.com/VJX5e.jpg"" alt=""enter image description here"">...................
<img src=""https://i.stack.imgur.com/8Uz7m.jpg"" alt=""enter image description here"">...................
<img src=""https://i.stack.imgur.com/6tPzG.jpg"" alt=""enter image description here""></p>

<p>I have been looking at the documentation and spent hours looking for a possible solution, on how to determine if the images are the same.
As you can see in the following pics, a match is found for both.</p>

<p><img src=""https://i.stack.imgur.com/U0SeG.png"" alt=""enter image description here""> <img src=""https://i.stack.imgur.com/H6XDC.png"" alt=""enter image description here""></p>

<p>Its clear that the one I'm trying to find gets more matches (lines connecting) but how do I check this in the code? </p>

<p><strong>Question: How do I filter out the good match?</strong></p>

<p>My goal is to be able to compare an input Image (capture from webcam) with a collection of images in a database. but before I can save all images to the DB I need to know what Values I can compare the input to. (e.g. save the objectKeypoints in the DB)</p>

<p>Here is my sample code (the matching part):</p>

<pre><code>private void match_test()
{
    long matchTime;
    using (Mat modelImage = CvInvoke.Imread(@""images\input.jpg"", LoadImageType.Grayscale))
    using (Mat observedImage = CvInvoke.Imread(@""images\2.jpg"", LoadImageType.Grayscale))
    {
        Mat result = DrawMatches.Draw(modelImage, observedImage, out matchTime);
        //ImageViewer.Show(result, String.Format(""Matched using {0} in {1} milliseconds"", CudaInvoke.HasCuda ? ""GPU"" : ""CPU"", matchTime));
        ib_output.Image = result;
        label7.Text = String.Format(""Matched using {0} in {1} milliseconds"", CudaInvoke.HasCuda ? ""GPU"" : ""CPU"", matchTime);
     }
}

public static void FindMatch(Mat modelImage, Mat observedImage, out long matchTime, out VectorOfKeyPoint modelKeyPoints, out VectorOfKeyPoint observedKeyPoints, VectorOfVectorOfDMatch matches, out Mat mask, out Mat homography)
{
    int k = 2;
    double uniquenessThreshold = 0.9;
    double hessianThresh = 800;

    Stopwatch watch;
    homography = null;

    modelKeyPoints = new VectorOfKeyPoint();
    observedKeyPoints = new VectorOfKeyPoint();

    using (UMat uModelImage = modelImage.ToUMat(AccessType.Read))
    using (UMat uObservedImage = observedImage.ToUMat(AccessType.Read))
    {
        SURF surfCPU = new SURF(hessianThresh);
        //extract features from the object image
        UMat modelDescriptors = new UMat();
        surfCPU.DetectAndCompute(uModelImage, null, modelKeyPoints, modelDescriptors, false);

        watch = Stopwatch.StartNew();

        // extract features from the observed image
        UMat observedDescriptors = new UMat();
        surfCPU.DetectAndCompute(uObservedImage, null, observedKeyPoints, observedDescriptors, false);

        //Match the two SURF descriptors
        BFMatcher matcher = new BFMatcher(DistanceType.L2);
        matcher.Add(modelDescriptors);

        matcher.KnnMatch(observedDescriptors, matches, k, null);

        mask = new Mat(matches.Size, 1, DepthType.Cv8U, 1);
        mask.SetTo(new MCvScalar(255));

        Features2DToolbox.VoteForUniqueness(matches, uniquenessThreshold, mask);
        int nonZeroCount = CvInvoke.CountNonZero(mask);

        if (nonZeroCount &gt;= 4)
        {
            nonZeroCount = Features2DToolbox.VoteForSizeAndOrientation(modelKeyPoints, observedKeyPoints,
               matches, mask, 1.5, 20);

            if (nonZeroCount &gt;= 4)
                homography = Features2DToolbox.GetHomographyMatrixFromMatchedFeatures(modelKeyPoints,
                   observedKeyPoints, matches, mask, 2);
        }

        watch.Stop();
    }

    matchTime = watch.ElapsedMilliseconds;
}
</code></pre>

<p>I really have the feeling I'm not far from the solution.. hope someone can help me out</p>
",2016-03-28 13:01:15,2016-03-28 13:01:15,Matching image and determine best match using SURF,<c#><image><opencv><emgucv><surf>,,,CC BY-SA 3.0,True,True,True,False,False
40790,36015806,2016-03-15 15:39:41,,"<p>i am trying to rotate and shift a mat at the same time. 
My first matrix comes from the following instruction:</p>

<p>CvInvoke.GetRotationMatrix2D(new Point(0, 0), ia.getAngle(), 1.0, rotation);</p>

<p>My second matric comes from the following instructions:</p>

<pre><code> Mat translation = CvInvoke.GetAffineTransform(t1, t2);
</code></pre>

<p>where t1 and t2 are vertices of two triangles
I do not want tu use Matrix. I want to perform the operation with Mat.</p>

<p>How can I multiply these two matrices in order to get the final one that I will use to apply the <strong>CvInvoke.WarpAffine</strong> method. </p>

<p>I tried: 
<code>cvInvoke.Multiply</code>, 
it does not transform the image.
I am currently trying
 <code>CvInvoke.Gemm(rotation, translation, 1.0, null, 0.0, final);</code> 
but an exception occurs:</p>

<blockquote>
  <p>(An unhandled exception of type 'Emgu.CV.Util.CvException' occurred
  in Emgu.CV.World.dll Additional information: OpenCV: a_size.width ==
  len)</p>
</blockquote>

<p>Any help would be greatly appreciated.</p>
",2016-03-15 16:31:03,2016-03-18 08:59:23,How can I perform a composition of Mats with emgu (c#)?,<c#><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
40802,35937375,2016-03-11 10:12:15,,"<p>Here is the code i'm currently using in C# and EmguCV included:</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.Util;

namespace CameraCapture
{
 public partial class CameraCapture : Form
{
    //declaring global variables
    private Capture capture;        //takes images from camera as image frames
    private bool captureInProgress; // checks if capture is executing

    public CameraCapture()
    {
        InitializeComponent();
    }

    private void ProcessFrame(object sender, EventArgs arg)
    {
        Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
        Image&lt;Bgr, Byte&gt; template = new Image&lt;Bgr, byte&gt;(@""D:\yugiCards\kuriboh.jpg"");
        Image&lt;Bgr, Byte&gt; imageToShow = ImageFrame.Copy();


        using (Image&lt;Gray, float&gt; result = imageToShow.MatchTemplate(template, Emgu.CV.CvEnum.TM_TYPE.CV_TM_CCOEFF_NORMED))
        {
            double[] minValues, maxValues;
            Point[] minLocations, maxLocations;
            result.MinMax(out minValues, out maxValues, out minLocations, out maxLocations);

            // You can try different values of the threshold. I guess somewhere between 0.75 and 0.95 would be good.
            if (maxValues[0] &gt; 0.9)
            {
                // This is a match. Do something with it, for example draw a rectangle around it.
                Rectangle match = new Rectangle(maxLocations[0], template.Size);
                imageToShow.Draw(match, new Bgr(Color.Red), 3);
            }
        }

        CamImageBox.Image = imageToShow; 
        //ImageFrame.Save(@""E:\MyPic.jpg"");  //saves to location
    }

    private void CameraOutput_Load(object sender, EventArgs e)
    {

    }

    private void btnStart_Click(object sender, EventArgs e)
    {
        #region if capture is not created, create it now
        if (capture == null)
        {
            try
            {
                capture = new Capture();
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(excpt.Message);
            }
        }
        #endregion

        if (capture != null)
        {
            if (captureInProgress)
            {  //if camera is getting frames then stop the capture and set button Text
                // ""Start"" for resuming capture
                btnStart.Text = ""Start!""; //
                Application.Idle -= ProcessFrame;
            }
            else
            {
                //if camera is NOT getting frames then start the capture and set button
                // Text to ""Stop"" for pausing capture
                btnStart.Text = ""Stop"";
                Application.Idle += ProcessFrame;
            }

            captureInProgress = !captureInProgress;
        }
    }

    private void ReleaseData()
    {
        if (capture != null)
            capture.Dispose();
    }

}
}
</code></pre>

<p>I am trying to find a template in the camera capture, however, when I run the program and start camera capture my camera LED lights up and then the program becomes not responding when it's trying to capture. Maybe it has to do with the placement of the match template function or the types of variables used but I'm not really sure since I'm not that experienced so I wanted some input on the problem with my code. </p>

<p>I do realize the imageToShow variable isn't needed but I decided to leave it be until I can get the thing working then I can mess around with it more myself.</p>

<p>Code for detecting the template was found here
<a href=""https://stackoverflow.com/questions/16406958/emgu-finding-image-a-in-image-b"">emgu finding image a in image b</a></p>

<p>It was mainly for detecting template between 2 static images though, but I edited the source to be from the webcam. </p>

<p>The webcam is working normally when I remove the using match template segment from the code. </p>

<p>Any input would be appreciated, thanks and sorry if it is an obvious error I'm still new to this kind of thing.</p>

<p>EDIT: Forgot to mention it gives this error when debugging The program </p>

<pre><code> '[6164] CameraCapture.vshost.exe' has exited with code -1073741819 (0xc0000005) 'Access violation'.
</code></pre>
",2017-05-23 12:31:31,2016-03-11 22:57:40,Access violation/Program not responding when Matching template from Camera capture. (C# EmguCV),<c#><camera><emgucv><capture><matchtemplate>,,,CC BY-SA 3.0,False,False,True,False,False
40831,35979962,2016-03-14 05:11:20,,"<p>I am trying to implement <code>emgu cv</code> in my windows application. I have downloaded <a href=""http://liquidtelecom.dl.sourceforge.net/project/emgucv/emgucv/2.2.1/libemgucv-windows-x86-2.2.1.1150.exe"" rel=""nofollow"">emgu cv version 2.2.1.1150</a>, added all necessary references in project. I have also copied all the opencv dlls in project output folder. As I run project I get exception <code>OpenCV: The node does not represent a user object (unknown type?)</code></p>

<p>At this line
<code>haar = new HaarCascade(""haarcascade_frontalface_alt_tree.xml"");</code></p>

<p>I searched a lot almost all the examples I have found is using the same code even official emgu cv tutorial on <a href=""http://www.emgu.com/wiki/index.php/Face_detection"" rel=""nofollow"">face detection</a> uses the same way to initialize <code>HaarCascade</code>.</p>

<p>Where I am doing wrong? </p>
",2016-03-14 05:49:36,2018-05-10 04:14:45,The node does not represent a user object (unknown type?),<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
40848,36095424,2016-03-18 22:40:35,,"<p>Here is part of the code where I am getting the error;</p>

<pre><code>private static void Main(string[] args)
    {
        #region Extract Model Face Detections From Video Clips

        var modelVideos = Directory.GetFiles(@""ModelsVideos\"", ""*.MOV"");

        foreach (var modelVideo in modelVideos)
        {
            var capture = new Capture(modelVideo);

            var framesQueue = new Queue&lt;Image&lt;Gray, byte&gt;&gt;();

            capture.ImageGrabbed += (sender, eventArgs) =&gt;
            {
                var currentFrame = capture.RetrieveGrayFrame();
                framesQueue.Enqueue(currentFrame);
            };
</code></pre>

<p>I tried many different formats and codecs, such as .mov, .avi, .mp4.
I also tried updating emgucv to version 3.0.
It won't even work when I try to read an image file. I also made sure I have all my binaries and .dll files. I saw all the solutions with opencv_ffmpeg300.dll and I made sure I have that as well. </p>

<p>This is the full error I am getting;</p>

<pre><code>An unhandled exception of type 'System.NullReferenceException' occurred in Emgu.CV.dll Additional information: Unable to create capture from ModelsVideos\video.MOV
</code></pre>

<p>Any help would be appreciated!</p>
",,2016-04-07 20:22:46,"emgucv won't read video/image files, getting an System.NullReferenceException error",<video><emgucv>,,,CC BY-SA 3.0,True,False,True,False,True
40862,35941173,2016-03-11 13:13:04,,"<p>I am using emgu CV for computer vision tasks and need to manipulate the images on the fly and display the results. I couldn't find a way to convert Mat type to something compatible with ImageSource so that I can display it on the WPF Image control. The examples are all for 2.x and I am using 3.1. A lot of things don't work for 3.x. I searched for a few hours but couldn't find an effective solution. Is there a simple solution to that? Thanks.</p>
",,2020-01-15 14:20:08,How to convert emgu CV Mat type to something that can be used as ImageSource?,<.net><wpf><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
40901,35943889,2016-03-11 15:22:22,,"<p>I am a newbie at EmguCV image processing and trying different methods of background subtraction. I came across at the method absdiff and gave it a try but after a bunch of processing, some part of the object seems to be transparent and the background behind it can be seen,<a href=""http://i.stack.imgur.com/JpLKJ.png"" rel=""nofollow"">Background subtraction sample</a></p>

<p>here is the part of my code that processes the image</p>

<pre><code>            img = _capture.QueryFrame().ToImage&lt;Bgr, Byte&gt;();
            Mat smoothedFrame = new Mat();
            CvInvoke.GaussianBlur(img, smoothedFrame, new Size(3, 3), 1);
            img3 = img2gray.AbsDiff(smoothedFrame.ToImage&lt;Gray, Byte&gt;());//.Convert&lt;Gray, Byte&gt;());
            img3 = img3.ThresholdBinary(new Gray(60), new Gray(255));
            IbOriginal.Image = img;
            IbProcessed.Image = img3;
</code></pre>

<p>How can i remove those ""blank or hollow"" space in the image above. Any help would be much appreciated</p>
",2016-03-18 16:30:24,2016-06-06 05:19:34,Some Background remain after Background Subtraction EMGU CV,<c#><opencv><background><emgucv><subtraction>,,,CC BY-SA 3.0,True,True,True,False,False
40984,36028941,2016-03-16 07:12:42,,"<pre><code>&lt;CM1 type_id=""opencv-matrix""&gt;
  &lt;rows&gt;3&lt;/rows&gt;
  &lt;cols&gt;3&lt;/cols&gt;
  &lt;dt&gt;d&lt;/dt&gt;
  &lt;data&gt;
    5.1385274254160595e+002 0. 3.2910027190134770e+002 0.
    5.1238136591053387e+002 2.5289438862525913e+002 0. 0. 1.&lt;/data&gt;&lt;/CM1&gt;
</code></pre>

<p>I have an xml file that contains a matrix.</p>

<p>In c++, we can use this:</p>

<pre><code>FileStorage fs(""camera parameters.xml"", FileStorage::READ);
Mat CM1;
fs[""CM1""] &gt;&gt; CM1;
</code></pre>

<p>to get the matrix object.</p>

<p>How can I do this in C#?</p>

<pre><code>FileStorage fs = new FileStorage(""camera parameters.xml"", FileStorage.Mode.Read);
Mat CM1;
CM1 = new Mat(fs[""CM1""]); //doesn't work, stuck here
</code></pre>
",,2016-08-14 20:08:51,Emgucv How to convert FileNode to Matrix?,<c#><c++><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
41039,35955105,2016-03-12 07:45:18,,"<p>I am trying to run the example of LicensePlateRecognition in EmguCV 3.1. But I always get the error System.DllNotFoundException and the message is that ""cvextern.dll cannot be loaded"". I am running Windows 7 with Visual Studio 2013 (the computer is provided by my company).</p>

<p>I copied the said dll and some other dlls in the folder to the debug folder (the profile is set to debug mode, and I tried both x86 and x64 versions). After getting the error again and again I started to suspect that it's because of my video card driver (some Google results suggested so). I updated that and the error persisted.</p>

<p>After some more Googling, I found the Dependency Walker. One file ""IEShims.dll"" is missing. I downloaded that and put it into the debug folder with no luck.</p>

<p>Some output I think might be relevant.</p>

<blockquote>
  <p>Loading open cv binary from C:\Emgu\emgucv-windesktop 3.1.0.2282\bin\x64</p>
  
  <p>LoadLibraryEx C:\Emgu\emgucv-windesktop 3.1.0.2282\bin\x64\opencv_ffmpeg310_64.dll failed with error code 87: The parameter is incorrect.</p>
  
  <p>File C:\Emgu\emgucv-windesktop 3.1.0.2282\bin\x64\opencv_ffmpeg310_64.dll cannot be loaded.</p>
  
  <p>LoadLibraryEx C:\Emgu\emgucv-windesktop 3.1.0.2282\bin\x64\cvextern.dll failed with error code 87: The parameter is incorrect.</p>
  
  <p>File C:\Emgu\emgucv-windesktop 3.1.0.2282\bin\x64\cvextern.dll cannot be loaded.</p>
</blockquote>

<p>Does anyone know what's wrong with that?</p>

<p>The error seems to be stemmed from</p>

<pre><code>#if !UNITY_IPHONE
     //Use the custom error handler
     RedirectError(CvErrorHandlerThrowException, IntPtr.Zero, IntPtr.Zero);
#endif
</code></pre>

<p>Which is in the method</p>

<pre><code>  /// &lt;summary&gt;
  /// Attempts to load opencv modules from the specific location
  /// &lt;/summary&gt;
  /// &lt;param name=""modules""&gt;The names of opencv modules. e.g. ""opencv_cxcore.dll"" on windows.&lt;/param&gt;
  /// &lt;returns&gt;True if all the modules has been loaded successfully&lt;/returns&gt;
  public static bool DefaultLoadUnmanagedModules(String[] modules)
</code></pre>

<p>I tried a whole day to find the solution but I really don't know what I can do now. Any help is appreciated.</p>

<p>EDIT: I also tried TlbImp with no luck.</p>

<blockquote>
  <p>TlbImp : error TI1002 : The input file 'D:\Resources\cvextern.dll' is not a valid type library.</p>
</blockquote>
",2016-03-12 07:56:11,2018-03-08 15:08:45,EmguCV cvextern System.DllNotFoundException,<.net><dll><emgucv>,,,CC BY-SA 3.0,True,False,True,False,True
41157,36077051,2016-03-18 05:48:26,,"<p>I have an image of a ""windows control"" lets say a Text-box and I want to get background color of the text written within the text box by finding max color occurred in that picture by pixel color comparison.
I searched in google and I found that every one is talking about histogram and also some code is given to find out histogram of an image but no one described the procedure after finding histogram.</p>

<p>the code I found on some sites is like</p>

<pre><code>        // Create a grayscale image
        Image&lt;Gray, Byte&gt; img = new Image&lt;Gray, byte&gt;(bmp);
        // Fill image with random values
        img.SetRandUniform(new MCvScalar(), new MCvScalar(255));
        // Create and initialize histogram
        DenseHistogram hist = new DenseHistogram(256, new RangeF(0.0f, 255.0f));
        // Histogram Computing
        hist.Calculate&lt;Byte&gt;(new Image&lt;Gray, byte&gt;[] { img }, true, null);
</code></pre>

<p>Currently I have used the code which takes a line segment from the image and finds the max color but which is not the right way to do it.
the currently used code is as follows</p>

<pre><code>        Image&lt;Bgr, byte&gt; image = new Image&lt;Bgr, byte&gt;(temp);
        int height = temp.Height / 2;
        Dictionary&lt;Bgr, int&gt; colors = new Dictionary&lt;Bgr, int&gt;();
        for (int i = 0; i &lt; (image.Width); i++)
        {
            Bgr pixel = new Bgr();
            pixel = image[height, i];
            if (colors.ContainsKey(pixel))
                colors[pixel] += 1;
            else
                colors.Add(pixel, 1);                
        }
        Bgr result = colors.FirstOrDefault(x =&gt; x.Value == colors.Values.Max()).Key;
</code></pre>

<p>please help me if any one knows how to get it.                                                                                                                              Take this image as input ==> <a href=""https://i.stack.imgur.com/2POEM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2POEM.png"" alt=""White Text Box""></a></p>
",2016-03-30 06:38:17,2016-03-30 07:35:54,How to find the max occurred color in the picture using EMGU CV in C#?,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
41299,36422996,2016-04-05 09:55:43,,"<p>Is there a way to convert EmguCV IImage to EmguCV structure?</p>

<pre><code>Image&lt;Bgr, Byte&gt; Frame;           // current frame from camera
Image&lt;Bgr, Byte&gt; Previous_Frame;  // previous frame aquired
Image&lt;Bgr, Byte&gt; Difference;      // difference between the two frames

double ContourThresh = 0.003; //stores alpha for thread access
int Threshold = 60; //stores threshold for thread access

private void ProcessFrame(object sender, EventArgs arg)
{
    if (Frame == null) 
    {
        Frame = imageBox1.Image; //error
        Previous_Frame = imageBox2.Image; //error
    }
    else
    {
        Frame = imageBox1.Image;//error
        Previous_Frame = imageBox2.Image;//error

        Difference = Previous_Frame.AbsDiff(Frame); 
        Difference = Difference.ThresholdBinary(new Bgr(Threshold, Threshold, Threshold), new Bgr(255, 255, 255)); //if value &gt; 60 set to 255, 0 otherwise 

        Previous_Frame = imageBox2.Image;
    }
}
</code></pre>

<p>I'm getting:</p>

<blockquote>
  <p>Error 14  Cannot implicitly convert type <code>Emgu.CV.IImage</code> to <code>Emgu.CV.Image&lt;Emgu.CV.Structure.Bgr,byte&gt;</code>. An explicit conversion exists (are you missing a cast?) d:\ece design project\aslt software\aslt software\seatplan.cs   917 25  ASLT Software</p>
</blockquote>

<p>I am trying to get the difference between two image boxes, <code>imageBox1</code> and <code>imageBox2</code>.</p>

<ul>
<li><code>imageBox1</code> is a processed image from the image captured by the camera while * <code>imageBox2</code> is an image from imageBox1 which are saved to the ms access database..</li>
</ul>

<p>What I'm trying to do is to find an image in the database that matches to the imagebox1.. is what im doing here correct or you guys have a better option than using absdiff?</p>
",2016-04-05 15:05:36,2016-04-05 15:05:36,Convert IImage to Structure,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
41304,36246402,2016-03-27 10:38:22,,"<p>I'm trying to create a motion detection application using different libraries.</p>

<p>I have already implemented AForge library, now i'm a little stuck on EmguCV.</p>

<p>I'm having difficulties in understanding how to set up all the things.</p>

<p>If i understood correctly, in order to use EmguCV i must install OpenCV.</p>

<p>So i opened Nuget Package Manager in VS, found EmguCV ( first one in the list ) and installed. Version 3.0.0</p>

<p><strong>So my question is, which OpenCV version should i install?</strong> Because EmguCV project page doesn't has no information on it, but OpenCV has many versions.</p>

<p>And additionaly, if someone knows some more computer vision libraries for C#, please write them.</p>
",,2020-09-14 18:32:10,Using EmguCV in WPF,<c#><wpf><opencv>,,,CC BY-SA 3.0,True,False,True,False,False
41325,36269038,2016-03-28 18:53:41,,"<p>I'm using Emgu CV's SURF feauture to recognize similar objects in images.</p>

<p>The image is drawn right, showing all the key points found, in both images, the <em>similar</em> points (<strong>which is what I want</strong>) and a rectangle (usually rectangle, sometimes just a line) that covers the similar points.</p>

<p>The problem is that the <em>similar points</em> are seen in the image, but they are not saved in the format I want, in fact, they're stored in a <strong>VectorOfKeyPoint</strong> object, which just stores a pointer, and other memory data, where the points are stored in memory (that's what I think). Meaning, I can't get the <em>similar points</em> in pairs like:</p>

<p><strong>((img1X, img1Y), (img2X, img2Y))</strong></p>

<p>This would be what I'm looking for, so that I can use the points later one.
Right now, I can just see the points in the resulted image, but I can't get
them in pairs.</p>

<p>The code that I'm using is the example from Emgu CV.</p>

<pre><code>//----------------------------------------------------------------------------
//  Copyright (C) 2004-2016 by EMGU Corporation. All rights reserved.       
//----------------------------------------------------------------------------
using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Drawing;
using System.Runtime.InteropServices;
using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Features2D;
using Emgu.CV.Structure;
using Emgu.CV.Util;
#if !__IOS__
using Emgu.CV.Cuda;
#endif
using Emgu.CV.XFeatures2D;

namespace FirstEmgu
{

    public static class DrawMatches
    {
  // --------------------------------
  // ORIGINAL FUNCTION FROM EXAMPLE
  // --------------------------------
        private static void FindMatch(Mat modelImage, Mat observedImage, out long matchTime, out VectorOfKeyPoint modelKeyPoints, out VectorOfKeyPoint observedKeyPoints, VectorOfVectorOfDMatch matches, out Mat mask, out Mat homography)
        {
            int k = 2;
            double uniquenessThreshold = 0.8;
            double hessianThresh = 300;

            Stopwatch watch;
            homography = null;

            modelKeyPoints = new VectorOfKeyPoint();
            observedKeyPoints = new VectorOfKeyPoint();

#if !__IOS__
            if (CudaInvoke.HasCuda)
            {
                CudaSURF surfCuda = new CudaSURF((float)hessianThresh);
                using (GpuMat gpuModelImage = new GpuMat(modelImage))
                //extract features from the object image
                using (GpuMat gpuModelKeyPoints = surfCuda.DetectKeyPointsRaw(gpuModelImage, null))
                using (GpuMat gpuModelDescriptors = surfCuda.ComputeDescriptorsRaw(gpuModelImage, null, gpuModelKeyPoints))
                using (CudaBFMatcher matcher = new CudaBFMatcher(DistanceType.L2))
                {
                    surfCuda.DownloadKeypoints(gpuModelKeyPoints, modelKeyPoints);
                    watch = Stopwatch.StartNew();

                    // extract features from the observed image
                    using (GpuMat gpuObservedImage = new GpuMat(observedImage))
                    using (GpuMat gpuObservedKeyPoints = surfCuda.DetectKeyPointsRaw(gpuObservedImage, null))
                    using (GpuMat gpuObservedDescriptors = surfCuda.ComputeDescriptorsRaw(gpuObservedImage, null, gpuObservedKeyPoints))
                    //using (GpuMat tmp = new GpuMat())
                    //using (Stream stream = new Stream())
                    {
                        matcher.KnnMatch(gpuObservedDescriptors, gpuModelDescriptors, matches, k);

                        surfCuda.DownloadKeypoints(gpuObservedKeyPoints, observedKeyPoints);

                        mask = new Mat(matches.Size, 1, DepthType.Cv8U, 1);
                        mask.SetTo(new MCvScalar(255));
                        Features2DToolbox.VoteForUniqueness(matches, uniquenessThreshold, mask);

                        int nonZeroCount = CvInvoke.CountNonZero(mask);
                        if (nonZeroCount &gt;= 4)
                        {
                            nonZeroCount = Features2DToolbox.VoteForSizeAndOrientation(modelKeyPoints, observedKeyPoints,
                               matches, mask, 1.5, 20);
                            if (nonZeroCount &gt;= 4)
                                homography = Features2DToolbox.GetHomographyMatrixFromMatchedFeatures(modelKeyPoints,
                                   observedKeyPoints, matches, mask, 2);
                        }
                    }
                    watch.Stop();
                }
            }
            else
#endif
            {
                using (UMat uModelImage = modelImage.ToUMat(AccessType.Read))
                using (UMat uObservedImage = observedImage.ToUMat(AccessType.Read))
                {
                    SURF surfCPU = new SURF(hessianThresh);
                    //extract features from the object image
                    UMat modelDescriptors = new UMat();
                    surfCPU.DetectAndCompute(uModelImage, null, modelKeyPoints, modelDescriptors, false);

                    watch = Stopwatch.StartNew();

                    // extract features from the observed image
                    UMat observedDescriptors = new UMat();
                    surfCPU.DetectAndCompute(uObservedImage, null, observedKeyPoints, observedDescriptors, false);
                    BFMatcher matcher = new BFMatcher(DistanceType.L2);
                    matcher.Add(modelDescriptors);

                    matcher.KnnMatch(observedDescriptors, matches, k, null);
                    mask = new Mat(matches.Size, 1, DepthType.Cv8U, 1);
                    mask.SetTo(new MCvScalar(255));
                    Features2DToolbox.VoteForUniqueness(matches, uniquenessThreshold, mask);

                    int nonZeroCount = CvInvoke.CountNonZero(mask);
                    if (nonZeroCount &gt;= 4)
                    {
                        nonZeroCount = Features2DToolbox.VoteForSizeAndOrientation(modelKeyPoints, observedKeyPoints,
                           matches, mask, 1.5, 20);
                        if (nonZeroCount &gt;= 4)
                            homography = Features2DToolbox.GetHomographyMatrixFromMatchedFeatures(modelKeyPoints,
                               observedKeyPoints, matches, mask, 2);
                    }

                    watch.Stop();
                }
            }
            matchTime = watch.ElapsedMilliseconds;
        }
        // --------------------------------
        // ORIGINAL FUNCTION FROM EXAMPLE
        // --------------------------------
        /// &lt;summary&gt;
        /// Draw the model image and observed image, the matched features and homography projection.
        /// &lt;/summary&gt;
        /// &lt;param name=""modelImage""&gt;The model image&lt;/param&gt;
        /// &lt;param name=""observedImage""&gt;The observed image&lt;/param&gt;
        /// &lt;param name=""matchTime""&gt;The output total time for computing the homography matrix.&lt;/param&gt;
        /// &lt;returns&gt;The model image and observed image, the matched features and homography projection.&lt;/returns&gt;
        public static Mat Draw(Mat modelImage, Mat observedImage, out long matchTime)
        {
            Mat homography;
            VectorOfKeyPoint modelKeyPoints;
            VectorOfKeyPoint observedKeyPoints;
            using (VectorOfVectorOfDMatch matches = new VectorOfVectorOfDMatch())
            {
                Mat mask;
                FindMatch(modelImage, observedImage, out matchTime, out modelKeyPoints, out observedKeyPoints, matches,
                   out mask, out homography);

                //Draw the matched keypoints
                Mat result = new Mat();
                Features2DToolbox.DrawMatches(modelImage, modelKeyPoints, observedImage, observedKeyPoints,
                   matches, result, new MCvScalar(255, 255, 255), new MCvScalar(255, 255, 255), mask);

                #region draw the projected region on the image

                if (homography != null)
                {
                    //draw a rectangle along the projected model
                    Rectangle rect = new Rectangle(Point.Empty, modelImage.Size);
                    PointF[] pts = new PointF[]
               {
                  new PointF(rect.Left, rect.Bottom),
                  new PointF(rect.Right, rect.Bottom),
                  new PointF(rect.Right, rect.Top),
                  new PointF(rect.Left, rect.Top)
               };
                    pts = CvInvoke.PerspectiveTransform(pts, homography);

                    Point[] points = Array.ConvertAll&lt;PointF, Point&gt;(pts, Point.Round);
                    using (VectorOfPoint vp = new VectorOfPoint(points))
                    {
                        CvInvoke.Polylines(result, vp, true, new MCvScalar(255, 0, 0, 255), 5);
                    }

                }

                #endregion

                return result;

            }
        }

        // ----------------------------------
        // WRITTEN BY MYSELF
        // ----------------------------------
        // Returns 4 points (usually rectangle) of similar points
        // but can't be used, since sometimes this is a line (negative 
        // points)
        public static Point[] FindPoints(Mat modelImage, Mat observedImage, out long matchTime)
        {
            Mat homography;
            VectorOfKeyPoint modelKeyPoints;
            VectorOfKeyPoint observedKeyPoints;
            using (VectorOfVectorOfDMatch matches = new VectorOfVectorOfDMatch())
            {
                Mat mask;
                FindMatch(modelImage, observedImage, out matchTime, out modelKeyPoints, out observedKeyPoints, matches,
                   out mask, out homography);

                //Draw the matched keypoints
                Mat result = new Mat();
                Features2DToolbox.DrawMatches(modelImage, modelKeyPoints, observedImage, observedKeyPoints,
                   matches, result, new MCvScalar(255, 255, 255), new MCvScalar(255, 255, 255), mask);

                Point[] points = null;
                if (homography != null)
                {
                    //draw a rectangle along the projected model
                    Rectangle rect = new Rectangle(Point.Empty, modelImage.Size);
                    PointF[] pts = new PointF[]
               {
                  new PointF(rect.Left, rect.Bottom),
                  new PointF(rect.Right, rect.Bottom),
                  new PointF(rect.Right, rect.Top),
                  new PointF(rect.Left, rect.Top)
               };
                    pts = CvInvoke.PerspectiveTransform(pts, homography);

                    points = Array.ConvertAll&lt;PointF, Point&gt;(pts, Point.Round);

                }

                return points;
            }
        }
    }
}
</code></pre>

<p><strong>EDIT</strong></p>

<p>I've managed to get some points out of the matches objects like this:</p>

<pre><code>Features2DToolbox.DrawMatches(modelImage, modelKeyPoints, observedImage, observedKeyPoints,
                   matches, result, new MCvScalar(255, 255, 255), new MCvScalar(255, 255, 255), mask);

                for (int i = 0; i &lt; matches.Size; i++)
                {
                    var a = matches[i].ToArray();
                    foreach (var e in a)
                    {
                        Point p = new Point(e.TrainIdx, e.QueryIdx);
                        Console.WriteLine(string.Format(""Point: {0}"", p));
                    }
                    Console.WriteLine(""-----------------------"");
                }
</code></pre>

<p>I think this should get me the points. I managed to get it working in python, and the code is not very different. Problem is that there are too many points that are returned. In fact, this returns me all the points on Y. </p>

<p><strong>Example</strong></p>

<p>(45, 1), (67, 1)</p>

<p>(656, 2), (77, 2)</p>

<p>...</p>

<p>It doesn't get me the points I want, even though I might be close. Any suggestions are appreciated.</p>

<p><strong>EDIT 2</strong>
This question: <a href=""https://stackoverflow.com/questions/23637916/find-interest-point-in-surf-detector-algorithm"">Find interest point in surf Detector Algorithm</a> is something very similar to what I need. There is only one answer, but it doesn't tell how to get the matched points coordinates. That's what I need, if there is an object in both images, get the coordinates of the objects points, from both images.</p>
",2017-05-23 11:53:28,2019-06-30 22:22:10,Emgu CV SURF get matched points coordinates,<c#><image><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
41344,36426324,2016-04-05 12:25:02,,"<p>I found a similar question 
<a href=""https://stackoverflow.com/questions/12193642/emgu-calculate-histogram-with-matrices"">emgu Calculate histogram with matrices</a> ... but i'm missing some steps !</p>

<p>Emgu 3 / c# / Sql Server 2014</p>

<p>I'm trying to compare one Image with several Images stored in a varbinary(max) in SQL Server. </p>

<p>My first step of many, is to compare Histograms because some images (objects) may be the similar but with different colors, so in my comparison algorithm I also want to consider the color of the objects to compare. </p>

<p>I've manged to put some code together based on other posts here, and I'm able to successfully doing it, if I calculate the histograms based on the Images:</p>

<pre><code>histBlueSource.Calculate(new Image&lt;Gray, byte&gt;[] { imgBlueSource }, true, null);
histBlueTarget.Calculate(new Image&lt;Gray, byte&gt;[] { imgBlueTarget }, true, null);

double cBlue = CvInvoke.CompareHist(histBlueSource, histBlueTarget, HistogramCompMethod.Correl);
</code></pre>

<p>Because of performance issues from loading the images from Database, I thought of extracting the BinValues from the histograms and just save them in the SQL SERVER database to later upload them back in a DenseHistogram.</p>

<p>I successfully extract the binvalues with: </p>

<pre><code>//** problem may be here - dont know if i should SAVE/LOAD bin value to a 1d FLOAT[256]
float[] BlueHist = new float[256];
BlueHist = histBlue.GetBinValues(); 
</code></pre>

<p>I serialize, save to sql server. I can the read from sql server, deserialize and get back to a float[256] with my bin values, exactly as the extracted ones.</p>

<p>To load the data back to a Densehistogram I'm doing this:</p>

<pre><code>DenseHistogram histBlue = new DenseHistogram(256, new RangeF(0.0f, 255.0f));
BlueHist = (float[])bformatterBlue.Deserialize(memStreamBlue);
//**Other problem may be here
Matrix&lt;float&gt; mtx = new Matrix&lt;float&gt;(BlueHist);
</code></pre>

<p>I find weird that Matrix data is {float[256,1]}. The values from the binvalues are then loaded from [0,0] to [255,0].</p>

<p>When I do the final step </p>

<pre><code>histBlue.Calculate(new Matrix&lt;float&gt;[] { mtx }, false, null);
</code></pre>

<p>The problem is the histogram binvalues are not correctly loaded, only the [0] has a value of 135 and the others [255] are 0.</p>

<p>Can someone help me please with this or other suggestion to make the same?</p>
",2017-05-23 11:59:37,2016-04-14 07:18:06,Load bin values to densehistogram from float array,<c#><histogram><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
41503,36555336,2016-04-11 17:29:09,,"<p>I am trying to create simple application using emgu cv 3.1.0.2282 for reading video file. I used following code to capture video from file. Capturing from webcam works fine.</p>

<pre><code>Capture _capture = new Capture(""D:\\test.avi"");
</code></pre>

<p>after this code is executed, the _capture variable will be assigned with some value (not null), but the height and width properties is 0.
But when I use that code in Emgu.CV.Example project, it works fine</p>
",,2016-04-12 02:05:21,Unable to capture video file in Emgu,<c#><video><emgucv><capture>,,,CC BY-SA 3.0,False,False,True,False,False
41515,36361680,2016-04-01 16:47:31,,"<p>I am doing face detection using <code>Emgu CV</code> in c#. It's a windows form application <code>WFP</code>.The code doesn't have any compile errors but doesn't detect any faces in the image and there is a <code>Null reference exception</code> thrown by a <code>DetectHaarCascade</code> function at run time.
The below is the code snippet</p>

<pre><code>    private void button1_Click(object sender, EventArgs e)
    {
        OpenFileDialog open = new OpenFileDialog();
        if (open.ShowDialog() == System.Windows.Forms.DialogResult.OK)
        {
            Image img = Image.FromFile(open.FileName);
           pictureBox1.Image = img;
            Image&lt;Bgr, byte&gt; ImageFrame = new Image&lt;Bgr, byte&gt;(new Bitmap(img));
           pictureBox1.Image = ImageFrame.ToBitmap();
              if (ImageFrame != null)
              {
                  Image&lt;Gray, byte&gt; grayframe = ImageFrame.Convert&lt;Gray, byte&gt;();
                  try
                  {
                      MCvAvgComp[][] faces = grayframe.DetectHaarCascade(haar, 1.4, 4, HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(ImageFrame.Width / 8, ImageFrame.Height / 8));


                      foreach (MCvAvgComp face in faces[0])
                      {
                          ImageFrame.Draw(face.rect, new Bgr(Color.Green), 3);
                      }
</code></pre>

<p>I have also added all the references required of Emgu dll files,and also added all the openCV dll files to the debug folder of the project.
I am using <code>visual studio 2010</code>and
            <code>Emgu CV 2.4</code>.
Thanks in advance.</p>
",2016-04-01 18:30:16,2016-05-19 09:26:04,Face detection using EMGU CV in c#,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
41528,36399526,2016-04-04 09:56:25,,"<p>I trained a haar cascade which is able to detect speed limit traffic signs. Now I am wondering how to recognize numbers from the images detected.
 Here are few examples of detected images: <a href=""https://i.stack.imgur.com/4RynE.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4RynE.jpg"" alt=""enter image description here""></a> <a href=""https://i.stack.imgur.com/yKUgq.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yKUgq.jpg"" alt=""enter image description here""></a></p>

<p>I've got an algorithm which can recognize numbers only in case if they are in the center of the detected image. But this condition is not always the case. OCR is also not very accurate...</p>

<p>Which specific algorithm provides numbers recognition with a high accuracy in less than 2s in my case?</p>
",,2016-04-06 00:31:13,How to recognize numbers from the images detected by haar classifier,<opencv><image-processing><emgucv><haar-classifier><object-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
41553,36284269,2016-03-29 12:26:45,,"<p>I want to convert between Matrix and Image in EmguCV 3.0.0. </p>

<p>I saw in this video (<a href=""https://www.youtube.com/watch?v=DfTS5a9xmwo"" rel=""nofollow"">https://www.youtube.com/watch?v=DfTS5a9xmwo</a>) that you can do this with the CvInvoke.cvConvert method. But it seems this method doesn't exist anymore in EmguCV 3.0.0. I did find the method CVInvoke.ConvertMaps , but this method requires two input and two output arrays. Is this method equivalent if I use empty arrays as the second arrays?</p>
",,2016-05-30 08:53:41,EmguCV 3.0.0 - CvInvoke.cvConvert equivalent,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
41577,36403619,2016-04-04 13:09:38,,"<p>Currently I'm working with a fingerletter recognition using visual studio 2013 C# along with emguCV. i already have a database using ms access and a program which allow me to add images(in graysacle already) to it. </p>

<ul>
<li>I've got 2 imageBox (imageBox0, imageBox1, imageBox2).., imageBox0 displays the live streaming of my camera., imageBox1 displays the processed image of imageBox0 (contour of my hand, grayscale, rectangle) and imageBox2 displays a selected image from the ms access database. </li>
</ul>

<p>What I needed is a way to recognize an image from imageBox1 that is similar to imageBox2 or (in the whole images inside the database)</p>

<p>Here are snapshots of what I am doing:</p>

<p><a href=""https://i.stack.imgur.com/dqiz4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dqiz4.png"" alt=""enter image description here""></a></p>

<p>I am using EmguCV version 2.</p>

<pre><code>private Image GetImgFromDB() 
{   
    if (rowNumber &gt;= 0)
    {   
        byte[] FetchedImgBytes = (byte[])LocalDataTable.Rows[rowNumber][""alphaImage""];
        MemoryStream stream = new MemoryStream(FetchedImgBytes);
        FetchedImg = Image.FromStream(stream);
        txtAlphaName.Text = (string)LocalDataTable.Rows[rowNumber][""AlphaName""];

         Bitmap FetchedImgCV = (Bitmap)FetchedImg;
         normalizedMasterImage = new Image&lt;Gray, Byte&gt;(FetchedImgCV);

        return FetchedImg; 
    }
    else
    {
        MessageBox.Show(""There are no images in the dataase yet. add some Please"");
        //return null;
    }
    return null; 
} `
</code></pre>
",2016-04-05 15:22:26,2016-04-05 15:22:26,Matching two imageBox controls (EmguCV),<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
41689,36572304,2016-04-12 11:43:15,,"<p>Non-maxima suppression seems to be a built in component of some openCV functions used for corner detection (like cornerHarris, goodFeaturesToTrack etc.). But, I would like to apply non-maxima suppression directly (on its own) to an image. Is there to achieve this in OpenCV (Emgu CV is what I'm using)?  </p>
",2016-04-14 10:19:23,2016-04-14 10:19:23,Non-maxima suppression in OpenCV / EmguCV,<opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
41716,36573001,2016-04-12 12:16:46,,"<p>I'm looking for a method which finds the ridges (local maxima) in an image and returns them as an array of ridges ( where a ridge is a vector of points defining the ridge). That is, a method which behaves exactly like findContours (which finds contours and returns them as an array of vectors defining the contours), except for ridges. </p>

<p>Does this exist, and if not how would I acheive this effect? (I'm using the Emgu CV wrapper for OpenCV) </p>

<p>I have this image (it's a bit faint, sorry), obtained using the distance transform from a binary image of a system of roads:</p>

<p><a href=""https://i.stack.imgur.com/UhJ3B.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UhJ3B.png"" alt=""Distance transform of binary image of a road system""></a></p>

<p>I can easily use findContours on the original binary image to get the <strong>road outlines</strong> as vectors of points. However I am interested in the <strong>road centerline</strong>. The road centerline is represented by the local maxima the image above. </p>

<p>Obviously, using findContours on this image gives me the road outlines again. I was planning to use non-maxima suppression to take away everything but the centerline, and use findContours on that, but I don't know how to do non-maxima suppression either, hence my question <a href=""https://stackoverflow.com/questions/36572304/non-maxima-suppression-in-opencv-emgucv"">here</a></p>
",2017-05-23 12:22:56,2016-08-11 13:38:46,Follow ridges with OpenCV - return array of 'ridges',<opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
41736,36455342,2016-04-06 15:15:50,,"<p>Can someone please throw some light on the difference between <a href=""https://www.nuget.org/packages/VVVV.EmguCV/"" rel=""nofollow"">VVVV.EmguCV</a> and <a href=""https://www.nuget.org/packages/EmguCV.221.x64/"" rel=""nofollow"">EmguCV.221.x64</a>. I am new to image processing itself.</p>

<p>Do they serve different purposes. As I understand they both are EmguCv wrappers to OpenCv. Is there any thing else to note?</p>
",,2016-04-12 07:04:39,Difference between VVVV.EmguCV and EmguCV.221.x64,<emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
41763,36497274,2016-04-08 10:26:00,,"<p>ORB detector using Emgucv is creating a lot of false matches even after performing homography. I have used the example provided for SURF in Emgucv and replaced surf detector with ORB. Here is the result I got:</p>

<p><a href=""https://i.stack.imgur.com/dHLNp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dHLNp.png"" alt=""enter image description here""></a></p>

<p>ORB in the left and SURF in the right side.How to reduce the mismatch? Any help is highly appreciated.</p>
",2016-04-08 13:12:10,2016-04-08 13:12:10,ORB giving lot of false matches in emgucv,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
41770,36458129,2016-04-06 17:23:52,,"<p>I would like to use a 3rd party wrapper dll in an asp.net core project. (Emgucv)
The Problem is: The .net Wrapper expects several DLLS in \x86 or \x64 folder in a traditional .net \bin directory. </p>

<p>I tried packing the two folders in a nugetpackage and adding that to my project, but that does not seem to help.</p>

<p>I have no clue how this could work out in asp.net core.... or if there even is a way? </p>

<p>Will it work to create an additional (""oldschool"") net dll, handling my 3rd party stuff?</p>
",2016-06-05 10:49:02,2016-06-05 10:49:02,3rd Party DLLs with asp.net core,<asp.net-core><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
41791,36419500,2016-04-05 07:13:02,,"<p>I have a system with two cameras.I have two VideoSource objects, one of which is displayed in a VideoSourcePlayer control. I want to alternate between them using the following code:</p>

<pre><code>videoSourcePlayer.SignalToStop
videoSourcePlayer.WaitForStop();
if (videoSourcePlayer.VideoSource == videoSource1)
{
     videoSourcePlayer.VideoSource = videoSource2;
}
else
{
     videoSourcePlayer.VideoSource = videoSource1;
}
videoSourcePlayer.Start();
</code></pre>

<p>When I first press the toggle button, I get the ""connecting..."" message in the videoSourcePlayer control. This didn't happen when I called videoSourcePlayer.Stop(), which simply threw an exception and then went on. After toggling again, the problem goes away. In other words, I can toggle between the two cameras without any problems.
Can anyone explain this, and tell me how to avoid the issue?</p>

<p><strong>Clarification</strong></p>

<p>I initialize the videoSource objects and Player as follows:</p>

<pre><code>videoSource1 = new VideoCaptureDevice(videoDevices[iiiVideoIndex].MonikerString);
...
videoSource1.NewFrame += iiiFrameHandler.SaveFrame;
videoSourcePlayer.VideoSource = videoSource1;
videoSourcePlayer.NewFrame += PlayerNewFrame;
...
videoSource1.Start();
...
System.Threading.Thread.Sleep(500);
videoSource2 = new VideoCaptureDevice(videoDevices[jjjVideoIndex].MonikerString);
...
videoSource2.NewFrame += jjjFrameHandler.SaveFrame;
videoSource2.Start();
</code></pre>

<p>I have three newFrameHandlers because there are some things I want to do through the user interface, and some that I want to do, in a certain state, for each frame from each camera.</p>
",2016-04-07 07:36:00,2016-04-20 12:05:11,"Toggle between cameras, sticks on VideoSourcePlayer.Start()",<.net><video><emgucv><aforge>,,,CC BY-SA 3.0,False,False,True,False,False
41812,36598261,2016-04-13 12:23:25,,"<p>I could generate Haar cascade classifier detecting traffic signs. When I use it with frames from webcam (1.3MP) it works pretty well in real time, but when I try to detect signs from video of mp4 format taken to phone camera (8MP), function DetectMultiScale(grayframe, 1.3, 10, Size.Empty) works way too slower (it detects though) causing huge delays, so original frame rate is not followed. My final goal is to recognize signs from Android phone camera in real time, but first I wanna create a desktop app.</p>

<p>I tried to change format of the videos to .wmv, .avi, .mpg, but result is the same. Probably, the reason is a resolution of the video, but I cannot resize it, otherwise it's impossible to find an object in resized frame (too small).</p>

<p>Here is my piece of code of C# with Emgu Cv library</p>

<pre><code>     _capture = new Capture(@""videos\testing.mp4"");
     Mat frame = _capture.QueryFrame();
     if (frame != null)
        {
            _cascadeClassifier = new     CascadeClassifier(Application.StartupPath + ""/cascade.xml"");

            var cpimg = frame.ToImage&lt;Bgr, byte&gt;();
            Image&lt;Gray, Byte&gt; grayframe = cpimg.Convert&lt;Gray, Byte&gt;();

            try {
                var signs = _cascadeClassifier.DetectMultiScale(grayframe, 1.3, 6, Size.Empty);

                foreach (var sign in signs)
                {
                    cpimg.Draw(sign, new Bgr(Color.Blue), 3);
                }
            }
            catch(Exception ex)
            { 
                MessageBox.Show(ex.Message);
            }
           pictureBox1.Image = cpimg.Bitmap;
        }
</code></pre>

<p>I changed parameteres of the function, but still it is not enough. Is there any other way to accelerate DetectMultiScale() to work in real time with the given video or any other solution?</p>
",2016-04-13 13:02:29,2016-04-13 13:02:29,Accelerate DetectMultiScale fucnction to detect objects from loaded videos in real time,<opencv><image-processing><emgucv><haar-classifier><object-recognition>,,,CC BY-SA 3.0,True,True,True,False,False
41842,36501788,2016-04-08 14:09:04,,"<p>Using Emgu CV I have extracted a set of closed polygons from the contours in an image of a road network. The polygons represent road outlines. The result is shown below, plotted over an OpenStreetMaps map (the polygons in 'pixel' form from Emgu CV have been converted to latitude/longitude form to be plotted). </p>

<p>Set of polygons representing road outlines:</p>

<p><a href=""https://i.stack.imgur.com/9AWBw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9AWBw.png"" alt=""enter image description here""></a></p>

<p>I would now like to compute the Voronoi diagram of this <strong>set of polygons</strong>, which will help me find the centerline of the road. But in Emgu CV I can only find a way to get the Voronoi diagram of a <strong>set of points</strong>. This is done by finding the Delaunay triangulation of the set of points (using the Subdiv2D class) and then computing the voronoi facets with GetVoronoiFacets. </p>

<p>I have tried computing the Voronoi diagram of the <strong>points</strong> defined by all the polygons in the set (each polygon is a list of points), but this gives me an extremely complicated Voronoi diagram, as one might expect:</p>

<p>Voronoi diagram of set of points:</p>

<p><a href=""https://i.stack.imgur.com/Ydqff.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Ydqff.png"" alt=""enter image description here""></a></p>

<p>This image shows a smaller portion of the first picture (for clarity, since it is so convoluted). Indeed some of the lines in the diagram seem to represent the road centerline, but there are so many other lines, it will be tough to find a criterion to extract the ""good"" lines. </p>

<p>Another potential problem that I am facing is that, as you should be able to tell from the first picture, some polygons are in the interior of others, so we are not in the standard situation of a set of <strong>disjoint</strong> closed polygons. That is, sometimes the road is between the outer boundary of one polygon and the inner boundary of another. </p>

<p>I'm looking for suggestions as to how to compute the Voronoi graph of the set of polygons using Emgu CV (or Open CV), hopefully overcoming this second problem I've outlined as well. I'm also open to other suggestions for how to acheive this without using Emgu CV.    </p>
",2016-04-08 15:57:37,2018-01-24 09:50:19,Voronoi graph from set of polygons in Emgu CV (or OpenCV),<opencv><emgucv><polygons><voronoi>,,,CC BY-SA 3.0,True,False,True,False,False
41929,36607668,2016-04-13 19:19:28,,"<p>I am using visual Studio Ultimate 2010 &amp; Emgu cv 3.0.0.2157.
I Compiled Emgu cv ""Shape Detection"" example witch found below:
<a href=""http://www.emgu.com/wiki/index.php/Shape_(Triangle,_Rectangle,_Circle,_Line)_Detection_in_CSharp"" rel=""nofollow"">Shape Detection Example</a>
I want draw lines that surround founded circle in image.(like a rectangle surround a circle).
regards</p>
",2016-04-13 19:26:07,2016-04-16 09:52:01,Draw lines that surround the circles that found from hough transform(emgu cv),<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
41941,36803713,2016-04-22 21:39:34,,"<p>I have to use OpenCV in both managed and unmanaged code in C++/CLI.</p>

<p>I'm trying Emgu CV in the managed code to wrap around the OpenCV objects but I'm having trouble doing the conversions.</p>

<p>How do I do something like this:</p>

<pre><code>Emgu::CV::Mat convert = Function_That_Returns_OpenCV_CV_Mat();
</code></pre>

<p>or this:</p>

<pre><code>Function_That_Takes_OpenCV_CV_Mat(Emgu_CV_Mat_variable);
</code></pre>

<p>?</p>
",,2018-10-08 02:52:48,How do I convert Emgu::CV::Mat to OpenCV cv::Mat and vice versa?,<opencv><image-processing><c++-cli><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
41948,36547524,2016-04-11 11:32:32,,"<p>I am working on the <strong>face recognition</strong> project for tracking the people who come across the gate. It will keep log of the people who passes through the door. 
 I am using <strong>EmguCV</strong>, in <strong>C#</strong> language. And I am using here <strong>Haarcascade xml</strong> file for face detection. But I think it is not enough good. So kindly suggest me another way to detect faces efficiently using C# language.</p>
",2016-04-11 11:39:23,2016-04-11 12:06:44,Need help in Face Detection using C# language,<c#><image-processing><emgucv><face-detection><face-recognition>,2016-04-11 12:40:46,,CC BY-SA 3.0,False,False,True,False,False
41989,36685915,2016-04-18 05:15:55,,"<p>When i try to run the VideoSurveilance Application on Raspberry Pi2.The Application hang's,I followed the steps From this Link<a href=""http://www.emgu.com/wiki/index.php/Download_And_Installation#Raspbian_.28Raspberry_Pi_2.29"" rel=""nofollow"">EmguCv Download and Installation Steps</a></p>

<p>are there any dll's i have been missing other example's are running fine.</p>

<p>Here is my code For blob tracking </p>

<pre><code>using (CvTracks tracks = new CvTracks())
using (ImageViewer viewer = new ImageViewer())
using (Capture capture = new Capture())
using (Mat fgMask = new Mat())
 {
   //BGStatModel&lt;Bgr&gt; bgModel = new BGStatModel&lt;Bgr&gt;(capture.QueryFrame(), Emgu.CV.CvEnum.BG_STAT_TYPE.GAUSSIAN_BG_MODEL);
    BackgroundSubtractorMOG2 bgModel = new BackgroundSubtractorMOG2(0, 0, true);
   //BackgroundSubstractorMOG bgModel = new BackgroundSubstractorMOG(0, 0, 0, 0);

    capture.ImageGrabbed += delegate(object sender, EventArgs e)
     {
       Mat frame = new Mat();
       capture.Retrieve(frame);
        bgModel.Apply(frame, fgMask);

         using (CvBlobDetector detector = new CvBlobDetector())
         using (CvBlobs blobs = new CvBlobs())
          {
              detector.Detect(fgMask.ToImage&lt;Gray, Byte&gt;(), blobs);
              blobs.FilterByArea(100, int.MaxValue);

              tracks.Update(blobs, 20.0, 10, 0);

              Image&lt;Bgr, Byte&gt; result = new Image&lt;Bgr, byte&gt;(frame.Size);

               using (Image&lt;Gray, Byte&gt; blobMask = detector.DrawBlobsMask(blobs))
                {
                  frame.CopyTo(result, blobMask);
                }
                //CvInvoke.cvCopy(frame, result, blobMask);

                foreach (KeyValuePair&lt;uint, CvTrack&gt; pair in tracks)
                 {
                   if (pair.Value.Inactive == 0) //only draw the active tracks.
                   {
                     CvBlob b = blobs[pair.Value.BlobLabel];
                     Bgr color = detector.MeanColor(b, frame.ToImage&lt;Bgr, Byte&gt;());
                      result.Draw(pair.Key.ToString(), pair.Value.BoundingBox.Location, Emgu.CV.CvEnum.FontFace.HersheySimplex, 0.5, color);
                        result.Draw(pair.Value.BoundingBox, color, 2);
                        Point[] contour = b.GetContour();
                        result.Draw(contour, new Bgr(0, 0, 255), 1);
                      }
                }

             viewer.Image = frame.ToImage&lt;Bgr, Byte&gt;().ConcateVertical(fgMask.ToImage&lt;Bgr, Byte&gt;().ConcateHorizontal(result));
             }
         };
         capture.Start();
         viewer.ShowDialog();
     }
</code></pre>
",2016-04-28 14:19:38,2016-04-28 14:19:38,VideoSurveilance Application whichs was provided by Emgucv bundle Hangs on Raspberry Pi2,<.net><mono><monodevelop><emgucv><raspberry-pi2>,,,CC BY-SA 3.0,False,True,True,False,False
42033,36615189,2016-04-14 06:20:06,,"<p>Earlier i was using Emgucv 2.4.10 version now i wanted to upgrade it to the 3.1 so that it can support in Raspberry Pi</p>

<p>What i found is there are some Classes are missing such as</p>

<pre><code>#region Blob Variables
BlobTrackerAutoParam&lt;Bgr&gt; param = new BlobTrackerAutoParam&lt;Bgr&gt;();
FGDetector&lt;Bgr&gt; FgDetector = new FGDetector&lt;Bgr&gt;(Emgu.CV.CvEnum.FORGROUND_DETECTOR_TYPE.FGD);
BlobDetector blobDetector = new BlobDetector(Emgu.CV.CvEnum.BLOB_DETECTOR_TYPE.Simple);
BlobTracker blobTracker = new BlobTracker(Emgu.CV.CvEnum.BLOBTRACKER_TYPE.CC);
BlobTrackPostProc btpp = new BlobTrackPostProc(Emgu.CV.CvEnum.BLOB_POST_PROCESS_TYPE.Kalman);
BlobTrackerAuto&lt;Bgr&gt; tracker;
Image&lt;Gray, Byte&gt; ProcessedImage;
#endregion
</code></pre>

<p>Had they changed the classe name in 3.1 update are they any alternative that i can make us to full fill my requirments.</p>
",,2017-01-12 06:36:51,Classes Missing in Emgcv 3.1 when compared with Emgucv 2.4.10,<c#><.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
42053,36811712,2016-04-23 13:55:22,,"<p>i would like to some assistance in a code that i am doing on Xamarin studio with emgu CV wrapper. i am developing an android app using opencv(emgucv) with C#.</p>

<ol>
<li>In my code header area it gives error of namespace of emgucv (namespace using Emgu.CV;)</li>
<li>it work fine if i change it to - using Emgu.CV; .</li>
<li>After this i get some assembly error when i try to build the project, screenshot of the error list is attached on this link-> <a href=""http://imgur.com/ZDjBPpW"" rel=""nofollow"">http://imgur.com/ZDjBPpW</a></li>
<li>Another screen shot of the error is on this link -> <a href=""http://imgur.com/PYsq4NP"" rel=""nofollow"">http://imgur.com/PYsq4NP</a></li>
<li>the error text is ""C:\Program Files (x86)\MSBuild\Xamarin\Android\Xamarin.Android.Common.targets(2,2): Error: Exception while loading assemblies: System.IO.FileNotFoundException: Could not load assembly 'System.Drawing, Version=2.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a'. Perhaps it doesn't exist in the Mono for Android profile?
File name: 'System.Drawing.dll'
at Xamarin.Android.Tuner.DirectoryAssemblyResolver.Resolve(AssemblyNameReference reference, ReaderParameters parameters)
at Xamarin.Android.Tasks.ResolveAssemblies.AddAssemblyReferences(ICollection`1 assemblies, AssemblyDefinition assembly, Boolean topLevel)
at Xamarin.Android.Tasks.ResolveAssemblies.Execute() (assad)""

<ol start=""6"">
<li>I have tried the project by removing the Visual Studio dll files for emgucv but it gives the same error</li>
</ol></li>
</ol>
",2016-05-05 05:22:49,2016-05-05 05:22:49,EmguCV issue with Android Xamarin Studio,<c#><android><opencv><xamarin><xamarin.android>,,,CC BY-SA 3.0,True,False,True,False,False
42055,36813006,2016-04-23 15:54:16,,"<p>surf algorithm is included in Emgu CV 3.1 or not? if included then how i can use it. please Explain in detail am new in Emgu CV. Am trying to implement surf algorithm using c# but can't understand how to implement it.</p>
",,2016-05-19 21:11:58,surf algorithm is included in emgu cv 3.1 or not? if included then how i can use it.... please Explain in detail am new in Emgu cv,<c#><emgucv><surf>,,,CC BY-SA 3.0,False,False,True,False,False
42062,36890103,2016-04-27 12:39:56,,"<p>I have a question, how can I display the stream from my webcam in a Image container in WPF ? I already get the stream with Emgu and converted it to an BitmapSource, but now I don't understand how to bind an Image from my webcam to WPF, with caliburn (MVVM) , every X ms .... </p>

<pre><code> &lt;Image x:Name=""imageWebcam"" /&gt;
</code></pre>
",,2020-06-19 07:40:48,Displaying a videostream from my webcam in WPF?,<c#><wpf><mvvm><caliburn.micro><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
42160,36777936,2016-04-21 18:41:51,,"<p>I've got to test in C# some new C++/CLI managed components in a Visual Studio 2013 Unit Test so that it's visible in the Test Explorer.  One of those components uses OpenCV cv::Mat.</p>

<p>It's been recommended that I use Emgu CV for unit tests.  I've installed Emgu CV for Windows x64.</p>

<p>How do I install Emgu in the unit test project?</p>
",,2016-04-21 21:23:20,How do I set up Emgu CV on Visual Studio 2013 for Unit Tests?,<visual-studio><unit-testing><opencv><emgucv><test-explorer>,,,CC BY-SA 3.0,True,True,True,False,False
42230,36666585,2016-04-16 16:16:41,,"<p>I Have two images( left and right )
I want to measure the real distance on image?
When I click on the image, ı ll get real distance to clicked point to camera.</p>

<p>Left Image:</p>

<p><a href=""https://i.stack.imgur.com/OkaNG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OkaNG.png"" alt=""enter image description here""></a></p>

<p>Right Image:</p>

<p><a href=""https://i.stack.imgur.com/0cO4z.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0cO4z.png"" alt=""enter image description here""></a></p>

<p>I have calibrated the two images. I want to use EmguCV to get distance from image.</p>

<p>Is this possible ?</p>
",2016-04-16 17:36:21,2016-04-17 20:01:31,How can I measure distances in stereo images?,<c#><opencv><computer-vision><emgucv><disparity-mapping>,,,CC BY-SA 3.0,True,False,True,False,False
42257,36628563,2016-04-14 16:15:28,,"<p>I'm trying to create program which display video from IP Camera.</p>

<p>This is my code :</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using Emgu.CV;                  //
using Emgu.CV.CvEnum;           // usual Emgu Cv imports
using Emgu.CV.Structure;        //
using Emgu.CV.UI;
using System.IO;
using System.Reflection;
using System.Windows;
using System.Runtime.InteropServices;
using Emgu.Util;
using System.Net;


namespace WindowsFormsApplication1
{
    public partial class Main : Form
    {
        public Main()
        {
            InitializeComponent();
        }

        public Capture _capture;
        public Mat imgOriginal;

        private void imageBox2_Click(object sender, EventArgs e)
        {
        }

        private void label1_Click(object sender, EventArgs e)
        {
        }

        public void button1_Click(object sender, EventArgs e)
        {
            _capture = new Capture(""http://192.168.1.148:8080/video"");
            _capture.ImageGrabbed += ProcessFrame;
            _capture.Start();
        }

        public void ProcessFrame(object sender, EventArgs arg)
        {
            imgOriginal= _capture.QueryFrame();
            ibOriginal.Image = imgOriginal;
        }
    }
}
</code></pre>

<p>It's getting stuck on this step (without expectation):</p>

<pre><code>imgOriginal= _capture.QueryFrame();
</code></pre>

<p>Maybe i should you invoke method but i don't know how.
Im using Emgu 3.1.0 <a href=""http://file.emgu.com/wiki/files/3.0.0/document/html/18b6eba7-f18b-fa87-8bf2-2acff68988cb.htm"" rel=""nofollow"">Link to Doc</a> </p>
",2016-04-14 16:28:07,2016-04-14 17:44:58,Displaying feed from ip camera using OpenCV(Emgu),<c#><video><emgucv><invoke><opencv3.0>,,,CC BY-SA 3.0,True,True,True,False,False
42294,36748137,2016-04-20 15:14:11,,"<p>I am doing a project that takes a photo when you smile, but I am not doing smile detection <em>per se</em>.</p>

<p>(My project is taking a photo when you smile)</p>

<p>How do I do smile detection so that I can take the photo?</p>

<p>This is my project source code:</p>

<pre><code>public partial class Form1 : Form
{
    private Capture capture;        
    private bool captureInProgress;
    private HaarCascade haar;
    private HaarCascade mouth;

    public Form1()
    {
        InitializeComponent();
    }

    private void Form1_Load(object sender, EventArgs e)
    {
        haar = new HaarCascade(""haarcascade_frontalface_alt_tree.xml"");
        mouth = new HaarCascade(""haarcascade_mcs_mouth.xml"");

    }
    private void ProcessFrame(object sender, EventArgs arg)
    {
        Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();

        if (ImageFrame !=null)
        {
            Image&lt;Gray, byte&gt; grayFrame = ImageFrame.Convert&lt;Gray, byte&gt;();
            Image&lt;Gray, Byte&gt; gray = ImageFrame.Convert&lt;Gray, Byte&gt;();
            var faces = grayFrame.DetectHaarCascade(haar, 1.4, 4, HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(25, 25))[0];
            foreach (var face in faces)
            {
                ImageFrame.Draw(face.rect, new Bgr(Color.Green), 3);

                MCvAvgComp[][] mouthsDetected = gray.DetectHaarCascade(mouth, 1.1, 10, Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(20, 20));
                gray.ROI = Rectangle.Empty;

                foreach (MCvAvgComp e in mouthsDetected[0])
                {
                    Rectangle mouthRect = e.rect;
                    mouthRect.Offset(face.rect.X, face.rect.Y);
                    ImageFrame.Draw(mouthRect, new Bgr(Color.Red), 2);
                }
            }

        }

        CamImageBox.Image = ImageFrame;       

    }

    private void btnstart_Click(object sender, EventArgs e)
    {
        #region if capture is not created, create it now
        if (capture == null)
        {
            try
            {
                capture = new Capture();
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(excpt.Message);
            }
        }
        #endregion

        if (capture != null)
        {
            if (captureInProgress)
            {  //if camera is getting frames then stop the capture and set button Text
                // ""Start"" for resuming capture
                btnStart.Text = ""Başlat""; //
                Application.Idle -= ProcessFrame;
            }
            else
            {
                //if camera is NOT getting frames then start the capture and set button
                // Text to ""Stop"" for pausing capture
                btnStart.Text = ""Durdur"";
                Application.Idle += ProcessFrame;
            }

            captureInProgress = !captureInProgress;
        }
    }
    private void ReleaseData()
    {
        if (capture != null)
            capture.Dispose();
    }  
  }
}
</code></pre>
",2016-04-20 16:43:41,2016-04-21 14:50:12,Emgu CV smile detection,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
42363,36970181,2016-05-01 18:11:51,,"<p>My thesis's goal is to detect vehicles stopping at non permissible zones using a camera and issuing a violation to that particular vehicle by getting his vehicle identification and sending the data to a database. (Maybe through RFID)</p>

<p>I've gone through youtube and saw some 'zone' concept:
<a href=""https://www.youtube.com/watch?v=w6gs10P2e1k"" rel=""nofollow"">https://www.youtube.com/watch?v=w6gs10P2e1k</a></p>

<p>I've decided that:</p>

<ul>
<li>Violation Detecton: OpenCV</li>
<li>Gathering Vehicle Identification: not sure if RFID(still researching for other options with the hope that there are easier ones) </li>
</ul>

<p><strong>Question 1:</strong> In the link above, he stated he used C++ for developing it. Is that kind of concept possible with c++ only? Can I apply those same concepts with Java, VB.NET, C#?</p>

<p><strong>Question 2:</strong> For openCV, is the camera to be used up to me   or am I stuck with my laptop's webcam? Of course I need a clearer camera so there will be no 'camera constraints' for my program.</p>

<p><strong>Question 3:</strong> Are there any technologies/techniques(better if easier) other than RFID to get some vehicle identification once a violator is detected?  </p>

<p><strong>Question 4:</strong> If I was going to use RFID, I need to manipulate RFID and OpenCV with their 1 common programming language to get them communicating (the condition of triggering the RFID to get the vehicle identification once there is a violation detected by the camera).</p>

<ul>
<li><p>OpenCV has C++, C, Python and Java interfaces and made possible to C# and       VB.NET through EmguCV.</p></li>
<li><p>RFIDs can be manipulated using VB.NET, C, C++, C#, Java</p></li>
</ul>

<p>Which do you recommend is the best 'common' language of the two that would suit my objectives? </p>

<p><strong>Question 4:</strong> Do you think 6 months of average 2-3hrs per day of programming will be enough to finish this level of thesis project? I can't go all out on programming everyday because I still have other classes other than my thesis to attend to for the next 6 months.</p>

<p>Sorry, I know this a LONG question as a whole to answer so I'm asking for your kind patience to help me. :) Also you can answer minimum 1 of those 4 questions if you only know an answer to one of them. </p>

<p>Your help would much much much be appreciated! :)</p>

<p>UPDATE: 
I forgot to mention this is targeting public vehicles. I know private vehicles complain about having RFID for security reasons but public utility vehicles doesn't have a choice when the government enforces it. Here in the Philippines, the main concern of traffic are traffic obstruction caused by these public uitility vehicles who load/unload passengers anywhere they want w/o following the proper zones to do those things.  </p>
",2016-05-03 01:12:43,2016-05-03 01:12:43,Need advice with OpenCV and RFID (Thesis),<java><c#><c++><opencv><rfid>,2016-05-03 14:43:37,,CC BY-SA 3.0,True,False,True,False,False
42478,36716003,2016-04-19 10:42:05,,"<p>I tried Image stitching using EmguCv 3.0. But it is showing the following errors:"" cannot convert from 'Emgu.CV.Image[]' to 'Emgu.CV.IInputArray'"". And my code is: </p>

<pre><code>Image&lt;Bgr, byte&gt;[] src = new Image&lt;Bgr, byte&gt;[3];
        Image&lt;Bgr, byte&gt;res = new Image&lt;Bgr, byte&gt;(1000,750);
        src[0] = new Image&lt;Bgr,byte&gt;(""D:/New folder/images/Fit01.jpg"");
        src[1] = new Image&lt;Bgr,byte&gt;(""D:/New folder/images/Fit02.jpg"");
        src[2] = new Image&lt;Bgr,byte&gt;(""D:/New folder/images/Fit03.jpg"");

        Stitcher stitcher = new Stitcher(false);
        stitcher.Stitch(src,res);//here showing error 
</code></pre>

<p>Please help...</p>
",,2016-04-19 12:13:14,Image Stiching using EmguCv 3.0,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
42527,37091453,2016-05-07 17:16:09,,"<p>I have thresholding image :</p>

<p><img src=""https://i.stack.imgur.com/WtV61.png""/></p>

<p>I want to know, can i detect ""white zones"" and draw rectangle around them (save data also wanted)<br>
Or can i draw parallelepiped (polygon) and ""say"" area inside it is white?<br>
Thanks.</p>
",2016-05-07 17:58:53,2016-05-08 19:47:49,Detecting threshold area(s),<c#><wpf><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
42528,37092550,2016-05-07 19:00:57,,"<p>with this simple c# code I am trying to just open camera</p>

<pre><code>ImageViewer viewer = new ImageViewer(); //create an image viewer
Capture capture = new Capture(); //create a camera captue
Application.Idle += new EventHandler(delegate(object sender, EventArgs e)
    {  
        //run this until application closed (close button click on image viewer)
        viewer.Image = capture.QueryFrame(); //draw the image obtained from camera
    });
viewer.ShowDialog(); //show the image viewer
</code></pre>

<p>the result:</p>

<p><a href=""https://i.stack.imgur.com/lgnmW.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lgnmW.jpg"" alt=""enter image description here""></a></p>

<p>so what is the problem ?</p>
",2016-05-07 19:29:17,2016-05-10 13:06:12,EmguCV does not load images from camera,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
42658,37060295,2016-05-05 21:07:33,,"<p>I am using emgucv 3.10 and I want to extract 3D information from stereo images.
So, I take a left and right image and after that get a disparity map.</p>

<p>But my disparity map is black?
how can I fix it ?
can you help me solve this issue ?</p>

<p>After I get my disparity image, I want to measure real distances between the points in the image? is this possible ? ( like in this video <a href=""https://www.youtube.com/watch?v=cX3eUwHunZM"" rel=""nofollow noreferrer"">YouTube: Measure distance with web cams from depth map using OpenCV full source code</a> )</p>

<pre><code>using System;using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;using System.Text;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Structure;
using System.Diagnostics;
using Emgu.CV.UI;

namespaceEmguCv_Stereo_Image_Calismasi_02mayıs{
    public partial class Form1 : Form    {
        private Mat _sol;
        private Mat _sag;



        public Form1()
        {
            InitializeComponent();
        }

        private void button1_Click(object sender, EventArgs e)
        {
            _sol = CvInvoke.Imread(@""imL.png"", LoadImageType.Color);
            UMat solGri = new UMat();
            CvInvoke.CvtColor(_sol, solGri, ColorConversion.Bgr2Gray);
            _sag = CvInvoke.Imread(@""imR.png"", LoadImageType.Color);
            UMat sagGri = new UMat();
            CvInvoke.CvtColor(_sag, sagGri, ColorConversion.Bgr2Gray);

            ımageBox1.Image = _sol;
            ımageBox2.Image = solGri;
            ımageBox3.Image = _sag;
            ımageBox4.Image = sagGri;


        }
        private int GetSliderValue(TrackBar Control)
        {
            if (Control.InvokeRequired)
            {
                try
                {
                    return (int)Control.Invoke(new Func&lt;int&gt;(() =&gt; GetSliderValue(Control)));
                }
                catch (Exception ex)
                {
                    return 0;
                }
            }
            else
            {
                return Control.Value;
            }
        }
        private void button2_Click(object sender, EventArgs e)
        {
            Mat disparityMap = new Mat();
            _sol = CvInvoke.Imread(@""imL.png"", LoadImageType.Color);
            UMat solGri = new UMat();
            CvInvoke.CvtColor(_sol, solGri, ColorConversion.Bgr2Gray);
            _sag = CvInvoke.Imread(@""imR.png"", LoadImageType.Color);
            UMat sagGri = new UMat();
            CvInvoke.CvtColor(_sag, sagGri, ColorConversion.Bgr2Gray);

            // StereoSGBM sgbm = new StereoSGBM(1, 48, 11, 242, 605, -1, 63,10, 0, 32,0);
             //  sgbm.Compute(solGri, sagGri, disparityMap);


            int numDisparities = GetSliderValue(Num_Disparities);
            int minDispatities = GetSliderValue(Min_Disparities);
            int SAD = GetSliderValue(SAD_Window);
            int P1 = 8 * 1 * SAD * SAD;//GetSliderValue(P1_Slider);
            int P2 = 32 * 1 * SAD * SAD;//GetSliderValue(P2_Slider);
            int disp12MaxDiff = GetSliderValue(Disp12MaxDiff);
            int PreFilterCap = GetSliderValue(pre_filter_cap);
            int UniquenessRatio = GetSliderValue(uniquenessRatio);
            int Speckle = GetSliderValue(Speckle_Window);
            int SpeckleRange = GetSliderValue(specklerange);

            label3.Text = minDispatities.ToString();
            label14.Text = numDisparities.ToString();
            label15.Text = SAD.ToString();
            label16.Text = disp12MaxDiff.ToString();
            label17.Text = PreFilterCap.ToString();
            label18.Text = UniquenessRatio.ToString();
            label19.Text = Speckle.ToString();
            label20.Text = SpeckleRange.ToString();

            StereoSGBM sgbm = new StereoSGBM(
              minDispatities,
              numDisparities,
              SAD, 
              P1, 
              P2,
              disp12MaxDiff,
              PreFilterCap,
              UniquenessRatio,
              Speckle,
              SpeckleRange, 
              0
              );
            sgbm.Compute(solGri, sagGri, disparityMap);
            ımageBox5.Image = disparityMap;

        }
    }
}
</code></pre>

<p><a href=""https://i.stack.imgur.com/Dc1Wz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Dc1Wz.png"" alt=""enter image description here""></a><a href=""https://i.stack.imgur.com/Qss0H.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Qss0H.png"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/YNo1q.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YNo1q.gif"" alt=""enter image description here""></a></p>
",2016-05-06 00:25:08,2020-05-16 21:06:40,my 'Disparity map' result is black?,<c#><opencv><emgucv><opencv3.0>,,,CC BY-SA 3.0,True,True,True,False,False
42770,37109058,2016-05-09 06:27:49,,"<p>If matchTemplate finds a match ,the result is displayed using a rectangle around it. But what to do if MatchTemplate does not finds an accurate result?
How to handle the minmax values? </p>

<p>Sample query image:</p>

<p><a href=""https://i.stack.imgur.com/mpY23.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mpY23.png"" alt=""enter image description here""></a></p>

<p>Relevant code snippet:</p>

<pre><code> if ((minValues[0] &gt;= 0.95) || (minValues[0] &lt;= 0.3))
            //if ((maxValues[0] &gt;= 0.95))
            {
                Rectangle rect = new Rectangle(new Point(minLocations[0].X, minLocations[0].Y), new Size(imgTemplate.Width, imgTemplate.Height));
                imgSource.Draw(rect, new Bgr(0, 0, 255), 1);
                isFoundMatch = true;
                ImageViewer.Show(imgSource);
                if (isFoundMatch == true)
                {
                    imgSource.Save(""C:/Misc/MatchFound/warning.png"");
                }
            }
</code></pre>

<p>Edit: I've checked for a template which is not present in the  image. But its giving false match.</p>
",2016-05-12 15:50:44,2016-05-12 15:50:44,How to avoid false matches in match template,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
42780,37028423,2016-05-04 12:52:59,,"<p>I searched the web a lot and couldn't find any simple solution.</p>
<p>I'm trying to create a people detector, for this project i chose the Emgu library.</p>
<p>For now i'm able to detect persons but with no good percentage of success.</p>
<p>I'm trying to train my SVM, i saw on this post: <a href=""https://stackoverflow.com/questions/10769519/svm-classifier-based-on-hog-features-for-object-detection-in-opencv"">SVM classifier based on HOG features for “object detection” in OpenCV</a> the process i need for training:</p>
<blockquote>
<p>Step 1) Prepare some training images of the objects you want to detect (positive samples). Also you will need to prepare some images with no objects of interest (negative samples).</p>
<p>Step 2) Detect HOG features of the training sample and use this features to train an SVM classifier (also provided in OpenCV).</p>
<p>Step 3) Use the coefficients of the trained SVM classifier in HOGDescriptor::setSVMDetector() method.</p>
</blockquote>
<p>I have some training images and i'm using this lines of code to extract HOG features:</p>
<pre><code>public static Image&lt;Bgr, Byte&gt; Resize(Image&lt;Bgr, Byte&gt; im)
    {
        return im.Resize(64, 128,   Inter.Linear);
    }
    public static float[] GetVector(Image&lt;Bgr, Byte&gt; im)
    {
        HOGDescriptor hog = new HOGDescriptor();    // with defaults values
        Image&lt;Bgr, Byte&gt; imageOfInterest = Resize(im);
        Point[] p = new Point[imageOfInterest.Width * imageOfInterest.Height];
        int k = 0;
        for (int i = 0; i &lt; imageOfInterest.Width; i++)
        {
            for (int j = 0; j &lt; imageOfInterest.Height; j++)
            {
                Point p1 = new Point(i, j);
                p[k++] = p1;
            }
        }

        return hog.Compute(imageOfInterest, new Size(8, 8), new Size(0, 0), p);
    }
</code></pre>
<p>But i couldn't find how could i train my SVM (step 2 on the steps above).</p>
",2020-06-20 09:12:55,2016-05-15 08:22:28,Emgu Train SVM for people detection - C#,<c#><opencv><image-processing><svm><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
42804,37188645,2016-05-12 13:38:28,,"<p>I have two successive images which I want to stabilize using EmguCv in c#.</p>

<p>I found much information on how to perform image stabilization, however I could not find any detailed explanation on how to use Emgu to stabilize two successive frames (Actual code expmples).</p>

<p>In general I understand that I have to do the following:</p>

<ol>
<li>Calculate the good features on the first frame by using the GFTTDetector() and get the Good feature points of the first Image (GFP1).</li>
<li>Then I need to compute the Optical flow using the CvInvoke.CalcOpticalFlowPyrLK() to get the good feature points of the second image (GFP2).</li>
<li>With the GFP1 &amp; GFP2 I can calculate the Homography matrix with the CvInvoke.cvFindHomography() function.</li>
<li>Finally I have to use the  CvInvoke.cvWarpPerspective() to stabilize the frame.</li>
</ol>

<p>So based on the above I tried to perform Image stabilization.</p>

<p>I have the two successive frames :</p>

<pre><code>Image&lt;Gray, ushort&gt; FirstImage = new Image&lt;Gray, ushort&gt;(Width, Height);
Image&lt;Gray, ushort&gt; SecondImage= new Image&lt;Gray, ushort&gt;(Width, Height);
</code></pre>

<p>The  I tried to calculate the good features:</p>

<pre><code>Emgu.CV.Features2D.GFTTDetector _GFTTdetector = new Emgu.CV.Features2D.GFTTDetector(500,0.05);
var GFP1 = _GFTTdetector.Detect(FirstImage);
</code></pre>

<p>However when I call the .Detect I get an OpenCV exception and I cannot proceed:</p>

<blockquote>
  <p>$exception    {""OpenCV: scn == 3 || scn == 4""}    Emgu.CV.Util.CvException</p>
</blockquote>

<p>Does anybody knows why I get this exception?</p>

<p>In addition I would appreciate if someone could post a sample code of how to use the following functions because I am not sure about what input arguments I shall use:</p>

<ul>
<li>CvInvoke.CalcOpticalFlowPyrLK()</li>
<li>CvInvoke.cvFindHomography()</li>
<li>CvInvoke.cvWarpPerspective()</li>
</ul>

<p>Lastly  _GFTTdetector.Detect() returns a KeyPoint[] type, however the CvInvoke.CalcOpticalFlowPyrLK() accepts only PointF[] arguments for the good points, so how I can convert the KeyPoint[] to PointF[]?</p>
",2016-05-12 14:07:09,2016-05-12 14:07:09,Emgucv C# Image Stabilization,<c#><image-processing><emgucv><image-stabilization>,,,CC BY-SA 3.0,True,False,True,False,False
42883,36965976,2016-05-01 11:10:30,,"<p>I use <code>findcontours()</code> in emgu, but I want to know what is the theory. I know <code>findcontours()</code>'s parameter and how to use. So is the 
algorithm <code>convexhull</code>? Or where can I find the related knowledge?</p>
",2016-05-01 11:23:24,2016-05-01 11:23:24,What the findcontour() theory in opencv?,<c#><opencv><emgucv><contour>,2016-05-01 17:28:17,,CC BY-SA 3.0,True,False,True,False,False
42991,37085408,2016-05-07 06:44:43,,"<p>I am developing an application which can identify basic shapes and their colors. Identifying shape part is done Now I want to identify the color of that shapes.I am using EmguCV libraries. Is there any one help me?</p>
",2016-05-07 07:13:05,2016-05-18 18:23:34,How to identify the color of a shape using EmguCV,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
43042,37382896,2016-05-23 04:57:29,,"<p>I'm doing a project to identify basic geometric shapes using emgucv. I'm using following code to identify pentagon shapes. but when I execute it, it shows pentagons and circles also. I want only pentagons as the output. I have already done identifying circles,rectangles and triangles. How to display only pentagons using this code?<br>
Thank you!</p>

<pre><code>    public Image&lt;Bgr, Byte&gt; My_Image;
    public Image&lt;Gray, Byte&gt; grayImage;
    public Image&lt;Gray, Byte&gt; cannyEdges;      

    grayImage = My_Image.Convert&lt;Gray, byte&gt;();



public void CannyEdgeDetection()
         {
            try
            {
                double cannyThresholdLinking = 120.0;
                cannyEdges = grayImage.Canny(cannyThreshold, cannyThresholdLinking);
                lines = cannyEdges.HoughLinesBinary(
                    1, //Distance resolution in pixel-related units
                    Math.PI / 45.0, //Angle resolution measured in radians.
                    20, //threshold
                    10, //min Line width
                    10 //gap between lines
                    )[0]; //Get the lines from the first channel
            }
            catch (Exception ex)
            {

                throw ex;
            }

         }

    public void DetectPentagons()
            {

                try
                {

                    CannyEdgeDetection();

                    using (MemStorage storage = new MemStorage())
                        for (
                          Contour&lt;Point&gt; contours = cannyEdges.FindContours(
                              Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
                              Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_EXTERNAL,
                              storage);
                           contours != null;
                           contours = contours.HNext)
                        {
                            Contour&lt;Point&gt; currentContour = contours.ApproxPoly(contours.Perimeter * 0.05, storage);

                            if (currentContour.Area &gt; 100)
                            {
                                if (currentContour.Total == 5) 
                                {

                                    grayImage.Draw(contours, new Bgr(Color.Red), 10);
                                    pictureBox2.Image = obj.grayImage.Bitmap;
                                }
                            }
                        }

                }

                catch (Exception ex)
                {
                    throw ex;
                }

            } 
</code></pre>
",,2016-05-30 08:33:07,How to detect Pentagons and Hexagons in EmguCv,<c#><winforms><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
43057,37270146,2016-05-17 07:47:41,,"<p>I am developing a system just like Camera mouse or other face control mouse, I have implemented all the functionality, the mouse pointer is also moving well, but I want to create the movement smooth just like the mouse control the pointer. the code I am using is:</p>

<pre><code>        if (startButton == true)
        {
            try
            {
                cap = new Capture();
                pictureBox1.Image = cap.QueryFrame().ToImage&lt;Bgr, Byte&gt;().Bitmap;
            }
            catch (Exception exp)
            {
                MessageBox.Show(""Error:"" + exp);
            }
            _cascadeClassifier = new CascadeClassifier(Application.StartupPath + ""/haarcascade_frontalface_default.xml"");
            eye_cascadeClassifier = new CascadeClassifier(Application.StartupPath + ""/haarcascade_eye.xml"");

            timer1.Start();
        }

    private void timer1_Tick(object sender, EventArgs e)
    {
        using (var imageFrame = cap.QueryFrame().ToImage&lt;Bgr, Byte&gt;().Flip(FlipType.Horizontal))
        {
            if (imageFrame != null)
            {
                var grayframe = imageFrame.Convert&lt;Gray, byte&gt;();

                var faces = _cascadeClassifier.DetectMultiScale(grayframe, 1.1, 10, Size.Empty); //the actual face detection happens here

                foreach (var face in faces)
                {
                    if(Configure.FaceBoxCheck==true)
                    imageFrame.Draw(face, new Bgr(Color.LightGreen), 2); //the detected face(s) is highlighted here using a box that is drawn around it/them
                    Int32 yCoordStartSearchEyes = face.Top + (face.Height * 3 / 11);
                    Point startingPointSearchEyes = new Point(face.X, yCoordStartSearchEyes);
                    Size searchEyesAreaSize = new Size(face.Width, (face.Height * 3 / 11));
                    Rectangle possibleROI_eyes = new Rectangle(startingPointSearchEyes, searchEyesAreaSize);

                    int widthNav = (imageFrame.Width / 11 * 3);
                    int heightNav = (imageFrame.Height / 11 * 3);
                    Rectangle nav = new Rectangle(new Point(imageFrame.Width / 2 - widthNav / 2, imageFrame.Height / 2 - heightNav / 2), new Size(widthNav, heightNav));
                    imageFrame.Draw(nav, new Bgr(Color.Lavender), 3);
                    Point cursor = new Point(face.X + searchEyesAreaSize.Width / 2, yCoordStartSearchEyes + searchEyesAreaSize.Height / 2);
                    grayframe.ROI = possibleROI_eyes;
                    var eyes = eye_cascadeClassifier.DetectMultiScale(grayframe, 2.15, 3, Size.Empty);

                    foreach (var eye in eyes)
                    {
                      //imageFrame.Draw(eye, new Bgr(Color.Red), 2);
                        if(Configure.EyeBoxCheck==true)
                        imageFrame.Draw(possibleROI_eyes, new Bgr(Color.DarkGreen), 2);
                        if (nav.Left &lt; cursor.X &amp;&amp; cursor.X &lt; (nav.Left + nav.Width) &amp;&amp; nav.Top &lt; cursor.Y &amp;&amp; cursor.Y &lt; nav.Top + nav.Height)
                        {
                            LineSegment2D CursorDraw = new LineSegment2D(cursor, new Point(cursor.X, cursor.Y + 1));

                            imageFrame.Draw(CursorDraw, new Bgr(Color.White), 3);
                            //we compute new cursor coordinate using a simple scale based on frame width and height
                            int xCoord = (imageFrame.Width * (cursor.X - nav.Left)) / nav.Width;
                            int yCoord = (imageFrame.Height * (cursor.Y - nav.Top)) / nav.Height;
                            //We set our new cursor position
                            Cursor.Position = new Point(xCoord * 2, yCoord *2);
                    }
                }
            }
</code></pre>
",2016-05-17 07:53:28,2016-05-17 08:57:56,how to control mouse pointer with head movement using emguCV C#?,<c#><mouse><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
43108,37272526,2016-05-17 09:41:24,,"<p>I am wondering if anyone has applied a contrast based autofocus technique using AForge or EmguCV. I have a Nikon D5300 DSLR which I am going to connect to a lead screw and servo and bring the camera forwards and backwards to try and find the appropriate points along the Z axis which have some 'focus' or 'contrast' information.</p>

<p>The issue is that since I am doing high magnification work, the depth of field is fairly shallow which means that there may actually be more than one focus point.</p>

<p>The idea was to use a live view image, and to move through the Z axis from a start to finish point, recording the Z position and then measure if any of the image is in focus. If this is the case then it would 'remember' those positions for later.</p>

<p>Once I have the positions, I would turn off the live view, move to each position and capture a high resolution image which I would then focus stack into one image.</p>

<p>So I am curious if anyone has done something similar where they are trying to determine if there is detail in any part of the image which should be captured to be included in the final focus stacked image.</p>

<p>Thanks</p>
",,2016-05-17 09:41:24,AForge.net or EmguCV AutoFocus,<vb.net><emgucv><aforge>,,,CC BY-SA 3.0,False,False,True,False,False
43109,37272993,2016-05-17 10:03:33,,"<p>Im Making an Image Processing Cross platform mobile application using Xamarin in Visual Studio 2015.When I import the dll files which are relevant to emgucv an error shows up saying  </p>

<pre><code>DllImport attempting to load: 'opencv_core220'.
DllImport error loading library '/storage/emulated/0/Android/data/App1.Droid/files/.__override__/libopencv_core220': 'dlopen failed: library ""/data/app-lib/App1.Droid-1//storage/emulated/0/Android/data/App1.Droid/files/.__override__/libopencv_core220"" not found'.
</code></pre>

<p>What can I do to fix this Error.</p>
",,2016-05-17 10:03:33,Missing DLL file in emgucv in Visual Studio 2015,<c#><image-processing><xamarin><cross-platform><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
43147,37213383,2016-05-13 15:01:09,,"<p>I've been assigned to read text from captcha images.
Input images training images are given.
The part where I'm stuck is I've to train SVM (with that given training sample data). AFter a hell lot of search and headache, I still don't know how to start SVM training.I've install openCV from NuGet, EMGU CV and accord.net but still fruitless.
Any help would be really appreciated.
<a href=""http://i.stack.imgur.com/e8yl3.jpg"" rel=""nofollow"">Captcha Images are like this.</a>
This is what my instructor step by step told:
1.  There is Captcha data in the test folders. Divide the test data into two parts, training data (60%) and test data (40%)
2.  Figure out a way to segment out the 4 letters in each image of training data.
3.  Figure out a way to store them automatically in Class folders
(all As in folder named “A” etc)
4.  Train a SVM on the segmented data to get a training file. 
5.  Use the Test data with the trained file to read the captchas. 
6.  Report accuracy automatically.
I'm badly stuck at step 4.</p>
",,2016-12-23 15:02:11,SVM Training C#,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
43161,37472667,2016-05-26 23:36:05,,"<p>I would like to detect all the angles in a given binary image ,
the image contains a handwriting character (black on white bg),
is there a way that i can get the angles at the lines junctions with 100% accuracy?</p>

<p>My current solution (below) do find the angles but sometimes it finds unwanted angles - that is angles near the junction and not exectly on it (ther's an example below).
In this implementation i use Magick.net,</p>

<p>because i cant post more than two links ill post the input letter image that suppose to be a binary image with blue marks that are the lcations of the angles i want to detect - to get  the input binary image they will need to be deleted (sorry).
<a href=""http://i.stack.imgur.com/DytIR.jpg"" rel=""nofollow"">letter A</a></p>

<p>My code:</p>

<pre><code>    var image = new MagickImage(@""xImg.jpg"");
    const int Radius = 3;//angle points surrounding circle radius
    image.Grayscale(PixelIntensityMethod.Average); //redundent
    var lineJunctionsImage = image.Clone(); // an image that will contain only the lines junctions points - angle points

    //detect all lines junctions points (black pixels points) in the image
    //with morphology method HAM + lineJunction kernel
    lineJunctionsImage.Negate();
    lineJunctionsImage.Morphology(MorphologyMethod.HitAndMiss, Kernel.LineJunctions);
    lineJunctionsImage.Negate();
</code></pre>

<p><a href=""http://i.stack.imgur.com/hYhfo.jpg"" rel=""nofollow"">resulting image</a></p>

<p>The resulting points are supposed to be the points on the middle of the junctions,
but some are not accurate and its critical for me as i want to draw a circle that surrounds each of them and then take the angle between the point and the two points that intercects the circle, now, the next code is doing it but its to complicated and long so ill just write the algorithm here:</p>

<p>for each junction point p do:
     detect all black pixels bi(0 >= i) that intersects a circle 
     with the above radius (3) that surrounds p,
     for each bi pairs calculate the angle between p and the pair
 print the angles found with the following protocol:
 {point1} {angle point} {point 2}
angle</p>

<p>The angles found (the angle points (middle junctions points) marked):</p>

<p>{11,19} <strong>{8,17}</strong> {5,19} 112.619</p>

<p>{11,19} <strong>{8,17}</strong> {9,14} 105.255</p>

<p>{5,19} <strong>{8,17}</strong> {9,14} 142.12</p>

<p>{24,17} <strong>{21,20}</strong> {18,19} 116.56</p>

<p>{24,17} <strong>{21,20}</strong> {20,23} 90</p>

<p>{21,1} <strong>{24,0}</strong> {27,2} 127.87</p>

<p>{24,0} <strong>{27,2}</strong> {27,5} 123.7</p>

<p>{26,12} <strong>{27,9}</strong> {27,6} 161.56</p>

<p>I think the main problem is that the angle points are sometimes not the correct points but a close neighbor.</p>

<p>Maybe someone have a better more accurate idea that will find the correct angles.</p>
",2016-05-28 11:37:52,2016-05-28 11:37:52,Detect junctions angles in a given binary image in c#,<c#><opencv><image-processing><emgucv><magick.net>,,,CC BY-SA 3.0,True,False,True,False,False
43258,37439228,2016-05-25 13:50:06,,"<p>I'm working on computer screen detection using emgucv (a c# opencv wrapper ).
I want to detect my computer screnn and draw a rectangle on it. 
<br>To help in this process, I used 3 Infrared Leds on the screen of the computer which I detect firtsly and after the detection, I could find the screen areas below those 3 leds.
Here is the results after the detection of the 3 leds.</p>

<p>The 3 red boxes are the detected leds.<br>
<a href=""https://i.stack.imgur.com/OMI9G.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OMI9G.png"" alt=""Here is the image and description""></a>.
<br> And in general I have something like this<br><br>
<a href=""https://i.stack.imgur.com/EXMtG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EXMtG.png"" alt=""General case""></a></p>

<p>Does anyone have an idea about how I can proceed to detect the whole screan area ?</p>
",2016-05-25 13:50:57,2020-05-25 09:56:49,Screen detection using opencv / Emgucv,<opencv><image-processing><emgucv><image-recognition><pattern-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
43366,37408481,2016-05-24 08:44:30,,"<p>This must be simple for C++ developers using OpenCV directly. However what I'm using is Emgu (an OpenCV wrapper for .NET) and in the latest version we have the method <code>CvInvoke.FindContours</code> returning void, the output result is passed by parameter reference and is of type <code>VectorOfVectorOfPoint</code>.</p>

<p>Here is a simple call:</p>

<pre><code>//outputResult is a VectorOfVectorOfPoint
CvInvoke.FindContours(inputImage, outputResult, null, RetrType.Tree, 
                      ChainApproxMethod.ChainApproxSimple);
</code></pre>

<p>For <code>RetrType.List</code> mode, we can just convert the result to some array of arrays and loop through all the contours easily. However here I would like to navigate through all the contours in a tree. I guess we must do something with native (unsafe) C++ code here with pointer (accessed via the <code>Ptr</code> property of the output result). But I wonder if there is a more .NET-friendly solution for this. And if even using pointer is the only solution, I still don't know how to delve into that <code>Ptr</code> to navigate through the contours tree.</p>

<p>The sample codes accompanied with the Emgu installation have a snippet using <code>CvInvoke.FindContourTree</code> instead (and that returns a <code>int[,]</code>).</p>
",2016-05-24 09:54:42,2016-05-26 21:03:20,Navigate through hierarchy of contours found by FindContours method?,<c#><opencv><emgucv><contour><opencv-contour>,,,CC BY-SA 3.0,True,False,True,False,False
43373,37335774,2016-05-19 23:43:15,,"<p>I want to copy a center part (Rectangle) of my image to a completely white <code>Mat</code> (to the same position).</p>

<p>Code:</p>

<pre><code>        Mat src = Image.Mat;
        Mat dst = new Mat(src.Height, src.Width, DepthType.Cv8U, 3);
        dst.SetTo(new Bgr(255, 255, 255).MCvScalar);

        Rectangle roi = new Rectangle((int)(0.1 * src.Width), (int)(0.1 * src.Height), (int)(0.8 * src.Width), (int)(0.8 * src.Height));

        Mat srcROI = new Mat(src, roi);

        Mat dstROI = new Mat(dst, roi);

        srcROI.CopyTo(dstROI);

        //I have dstROI filled well. CopyTo method is doing well. 
        //However I have no changes in my dst file.
</code></pre>

<p>However I'm getting only white image as a result - <code>dst</code>. Nothing inside. </p>

<p>What i'm doing wrong?</p>

<p>using EmguCV 3.1</p>

<p><strong>EDIT</strong></p>

<p>I have a <code>dstROI</code> Mat filled well. But there is a problem how to apply changes to original <code>dst</code> Mat now.</p>

<p>Changing <code>CopyTo</code> like this:</p>

<pre><code>  srcROI.CopyTo(dst);
</code></pre>

<p>causes that dst is filled now with my part of src image but not in the centre like i wanted</p>

<p><strong>EDIT 2</strong></p>

<pre><code> src.Depth = Cv8U
</code></pre>

<p>As you suggested I check a value of <code>IsSubmatrix</code> property.</p>

<pre><code>   Console.WriteLine(dstROI.IsSubmatrix);         
   srcROI.CopyTo(dstROI);
   Console.WriteLine(dstROI.IsSubmatrix);
</code></pre>

<p>gives output:</p>

<pre><code>   true
   false
</code></pre>

<p>What can be wrong then?</p>
",2016-05-21 07:31:34,2020-02-26 01:32:49,Copy part of image to another image with EmguCV,<opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
43379,37564117,2016-06-01 09:05:19,,"<p>I have been trying to use EmguCV v3.0 on Visual Studio 2012 and C# to Covert Image Format from IplImage to Bitmap. When I debug project, the VS throw a following exception:</p>

<blockquote>
  <p>Could not load file or Assembly “Emgu.CV, Version=2.4.10.1939,
  Culture=neutral, PublicKeyToken=7281126722ab4438”....</p>
</blockquote>

<p>I have checked the system environment path and Project's References and using in project, there are correct. Then I have also tried to change Platform target to AnyCPU, failed!
I don't know what's wrong with my project, please help, Thanks!
 <a href=""https://i.stack.imgur.com/zmSPz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zmSPz.png"" alt=""enter image description here""></a></p>

<blockquote>
<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using Emgu.CV;
using Emgu.Util;
using Emgu.CV.UI;
using Emgu.CV.Structure;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Data;
using System.Drawing;
using System.Drawing.Imaging;
using Cognex.VisionPro;
using Cognex.VisionPro.Display;
using Cognex.VisionPro.ImageFile;
using Cognex.VisionPro.OCRMax;
using System.Xml;
using System.Runtime.InteropServices;
using System.Diagnostics;
</code></pre>
</blockquote>

<pre><code>namespace dfadvocrkernel {
     public class dfadvocrdecode
     { 
         public unsafe Int32 DF_ADVOCRDecode(void* inBMP, void* inPara, void* pResult)
             {
                 IntPtr inputBmp = new IntPtr((IntPtr *)inBMP);
                 Image&lt;Gray, byte&gt; dest = new Image&lt;Gray, byte&gt;(CvInvoke.cvGetSize(inputBmp));
                 CvInvoke.cvCopy(inputBmp, dest, IntPtr.Zero);
                 Bitmap bmp = dest.ToBitmap();
                  ....
              }
          }
      }
</code></pre>
",2016-06-01 09:53:23,2016-06-01 09:53:23,"How to solve ""FileNotFoundException was unhandled""?",<c#><.net><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
43393,37449753,2016-05-26 00:35:48,,"<p>Goal:
Show picture of the inside of the mobile rectangle in another Picturebox.</p>

<p>That is, have two Picturebox (PB) A and B Forms different . I want to move the rectangle in the PBA I want the image of its interior appears in PBB .</p>

<p>Possible solution:</p>

<p>Cut image and display the cutout in another picturebox</p>

<p>To make the cut:</p>

<pre><code> Mat A = new mat ( img , rect ) ; // Being img input Mat and rect rectangle
</code></pre>

<p>It works as long as the rectangle is not busy . That is very little busy .</p>

<p>Then it returns the error</p>

<pre><code>Error: OpenCV : 0 &lt; = roi.x &amp;&amp; 0 &lt; = roi.width &amp;&amp; roi.x + roi.width &lt; = m.cols &amp;&amp; &lt; = roi.y &amp;&amp; 0 &lt; = roi.height &lt; = m.rows
</code></pre>

<p>Thanks in advance! Thank you!</p>

<p>Code to create and move the rectangle :</p>

<pre><code> private void pb_imageRecorte_Paint(object sender, PaintEventArgs e)
    {
        if (rect.X &lt; 0) rect.X = 0;
        if (rect.Y &lt; 0) rect.Y = 0;
        if (rect.X + rect.Width &gt; pb_imageRecorte.Width) rect.X = pb_imageRecorte.Width - rect.Width;
        if (rect.Y + rect.Height &gt; pb_imageRecorte.Height) rect.Y = pb_imageRecorte.Height - rect.Height;

        using (Pen pen = new Pen(Color.LimeGreen, 1))
        {
            e.Graphics.DrawRectangle(pen, rect);
        }
    }

    private void pb_imageRecorte_MouseDown(object sender, MouseEventArgs e)
    {
        start_X = e.X;
        start_Y = e.Y;

        if (rect.Contains(e.Location))
        {
            pb_imageRecorte.MouseMove -= pb_imageRecorte_MouseMove_NotDown;
            pb_imageRecorte.MouseMove += pb_imageRecorte_MouseMove_MovingSegment;
            pb_imageRecorte.MouseUp += pb_imageRecorte_MouseUp_MovingSegment; 

            OffsetX = rect.X - e.X;
            OffsetY = rect.Y - e.Y;
        }
        else
        {
            pb_imageRecorte.MouseMove += pb_imageRecorte_MouseMove_NotDown;
        }
    }

    private void pb_imageRecorte_MouseMove_NotDown(object sender, MouseEventArgs e)
    {
        Cursor new_cursor = Cursors.Arrow;
        if (rect.Contains(e.Location))
            new_cursor = Cursors.Hand;
        if (pb_imageRecorte.Cursor != new_cursor)
            pb_imageRecorte.Cursor = new_cursor;
    }
    private void pb_imageRecorte_MouseMove_MovingSegment(object sender, MouseEventArgs e)
    {
        int new_x1 = e.X + OffsetX;
        int new_y1 = e.Y + OffsetY;

        int dx = new_x1 - rect.X;
        int dy = new_y1 - rect.Y;

        if (dx == 0 &amp;&amp; dy == 0) return;

        rect = new Rectangle(rect.X + dx, rect.Y + dy, 50, 50);

        // Redraw.
        pb_imageRecorte.Invalidate();
    }
    private void pb_imageRecorte_MouseUp_MovingSegment(object sender, MouseEventArgs e)
    {
        pb_imageRecorte.MouseMove += pb_imageRecorte_MouseMove_NotDown;
        pb_imageRecorte.MouseMove -= pb_imageRecorte_MouseMove_MovingSegment;
        pb_imageRecorte.MouseUp -= pb_imageRecorte_MouseUp_MovingSegment;

        pb_imageRecorte.Invalidate();
    }
</code></pre>

<p>for crop:</p>

<pre><code>        private void cropMat(Mat input)
    {
        Mat output = new Mat(input.Height, input.Width, Emgu.CV.CvEnum.DepthType.Cv8U, input.NumberOfChannels);
        Mat inputROI = new Mat(input, rect);
        Mat outputROI = new Mat(output, rect);
        inputROI.CopyTo(outputROI);
        delPassData arquivo = new delPassData(Z.RecebeIMG);
        arquivo(inputROI);
    }
</code></pre>
",2016-05-26 03:52:53,2016-05-26 03:52:53,Cut the Image to Move Runtime Rectangle - EmguCV - OpenCV - C#,<c#><opencv><emgucv><rect>,,,CC BY-SA 3.0,True,True,True,False,False
43399,37567494,2016-06-01 11:34:31,,"<p>What is the difference between OpenCV.NET, OpenCVSharp and EmguCV?</p>

<p>They are derived from OpenCV.</p>

<p>So, what is the difference in their design, implementation and application philosophies?</p>
",2016-06-07 13:22:21,2018-04-09 09:07:44,"What is the difference between OpenCV.NET, OpenCVSharp and EmguCV?",<opencv><image-processing><emgucv><opencv3.0><opencvsharp>,,,CC BY-SA 3.0,True,False,True,False,False
43499,37638759,2016-06-05 05:27:21,,"<p>imgOriginal = New Mat(ofdOpenFile.FileName, LoadImageType.Color)</p>

<p>this is where exception throw</p>
",,2017-01-11 12:37:58,Emgu CV 3.1.0 - error: The type initializer for 'Emgu.CV.MatInvoke' threw an exception. help me out,<opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
43525,37640406,2016-06-05 09:33:06,,"<p>I have a requirement of making the black color background of a image as transparent. Any ideas on how to do this using EmguCV ? </p>

<p>Below is the image which I'm using for this process.</p>

<p><a href=""https://i.stack.imgur.com/sB0lC.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/sB0lC.jpg"" alt=""image""></a></p>
",,2016-10-13 14:40:15,How to make transparency in emgu cv?,<c#><opencv><transparency><emgucv><alpha>,,,CC BY-SA 3.0,True,False,True,False,False
43584,37602572,2016-06-02 21:39:24,,"<p>I recently tried upgrading my Emgu libraries from 2.4.2 to 3.0.0. So there have been significant changes in the version, and I am having a bit of trouble modifying the code to make it work.</p>

<p>The 2.4.2 version of Emgu had a Contour Class: <a href=""http://www.emgu.com/wiki/files/2.4.2/do"" rel=""nofollow"">http://www.emgu.com/wiki/files/2.4.2/do</a> ... Index.html</p>

<p>My code uses that, and sometimes I remove points using the RemoveAt method or add points using the Insert method.  My initial contour could contain points that are outliers (due to various criteria, such as curvature, distance between adjacent points, etc.)</p>

<p>What I tried to do in the new version of Emgu was use the VectorOfPoint class. It works for much of my code, but it still does not have (as far as I can tell) any equivalent of RemoveAt method. It seems to have something similar to the Insert method (Push method: <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/9f6838b0-d946-adc6-e14e-8f223079f5e3.htm"" rel=""nofollow"">http://www.emgu.com/wiki/files/3.0.0/document/html/9f6838b0-d946-adc6-e14e-8f223079f5e3.htm</a>) though I am not sure that it is exactly what I want.</p>

<p>I looked into the matter a bit further, and saw that the Mat class has a <strong>PushBack</strong> and <strong>PopBack</strong> method, which allows you to add and remove an element at the end of a sequence.  However, as I had the code before, I was removing elements at certain places (the <strong>RemoveAt</strong> method allows you to input the index i of the element to be removed).</p>

<p>As an example, this is how I used the RemoveAt method before:</p>

<pre><code>for (int i = nPoints - 1; i &gt;= 0; i--)
                {
                    if (!goodPoint[i])
                    {
                        shapeContour.RemoveAt(i);
                        continue;
                    }
                }
</code></pre>

<p>I do not see a direct function I can use in the new version of Emgu.  Am I mistaken?</p>

<p>I would appreciate any help. Thanks in advance.</p>
",2016-06-07 22:16:15,2016-06-07 22:16:15,EMGU 3.0.0 OpenCV Insert and Remove Contour Points,<c#><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
43620,37464879,2016-05-26 15:16:12,,"<p>I am hoping to achieve something similar to what is shown in this <a href=""https://youtu.be/Mp1_TM_IRdA"" rel=""nofollow noreferrer"">video</a>.</p>
<p>I have been able to detect face in image, and then cropping a rectangle containing the face using haar cascade classifier. But, because faces are not completely rectangle, some of the background are still shown in the cropped image.</p>
<p>I am trying to achieve what was shown in the video so I can remove the background part of the cropped image.</p>
<p>Is there any way to do it using Emgucv?</p>
<p>Thank you!</p>
",2020-06-20 09:12:55,2016-05-26 15:37:43,Segmenting only Face in an Image in EmguCV,<c#><opencv><emgucv><image-segmentation>,,,CC BY-SA 3.0,True,False,True,False,False
43696,37765188,2016-06-11 15:05:01,,"<p>I have a C# (Emgu CV) application where I capture mutliple images of the same scene at varying focal lengths. Now I want to create a multifocus image simular like described in this article <a href=""http://blog.patdavid.net/2013/01/focus-stacking-macro-photos-enfuse.html"" rel=""nofollow"">http://blog.patdavid.net/2013/01/focus-stacking-macro-photos-enfuse.html</a></p>

<p>I could not find any approach doing it with OpenCV.
I was able to create  sharpness maps for my images with this code</p>

<pre><code>private Image&lt;Gray, float&gt; GetFocusMask(string imgfile)
    {
        var img = new Image&lt;Bgra,byte&gt;(imgfile);

        Image&lt;Gray, byte&gt; imgGray = img.Convert&lt;Gray, byte&gt;();
        Image&lt;Gray, float&gt; roughSharpness = imgGray.Laplace(5);
        roughSharpness = roughSharpness.Dilate(2);
        roughSharpness._SmoothGaussian(3);

        return roughSharpness;
    }
</code></pre>

<p>Unfortunately I am stuck now and don’t know how to use this masks to calculate a single Depth of Field image of the original focus image collection.</p>
",,2018-01-08 10:48:52,Focus-stacking using OpenCV / Emgu CV,<c#><.net><opencv><focus><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
43705,37767085,2016-06-11 18:14:42,,"<p>I'm new to opencv and using EMGU as wrapper in C#. I'm trying to get the best similar image for a query image from images database.</p>

<p>I followed up the example as show <a href=""http://romovs.github.io/blog/2013/07/05/matching-image-to-a-set-of-images-with-emgu-cv/"" rel=""nofollow"">here</a> to do the work.</p>

<p>it uses SURF detector to detect image features and then it combines all database images descriptors in one Super descriptors matrix for matching.</p>

<p>Then it uses the Flann Index to find the nearest neighbors of the query image.</p>

<p>The problem is that the distance matrix ""dists"" always contains ""0"" values.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>flannIndex.KnnSearch(queryDescriptors, indices, dists, 2, 24);</code></pre>
</div>
</div>
</p>
",,2016-08-11 15:37:49,Opencv Surf and FlannIndex to find image in images database,<c#><opencv><emgucv><surf><flann>,,,CC BY-SA 3.0,True,False,True,False,False
43714,37728986,2016-06-09 14:37:17,,"<p>I'm trying to detect the corners of the image using emguCv. To do that I used Harris Corner detection method in emguCv. but output result is blurred and using that method I cannot get the number of the corners in the image. When I searching I found a code in OpenCvSharp to detect corners and It will give output as my wish. 
I tried to convert that OpenCvSharp code to EmguCv and I stuck in here. When converting 'Cv.GoodFeaturesToTrack()' method to EmguCv. In EmguCv structure it requires 11 parameters and for last 4 parameters what should I pass? Can someone help me?</p>

<p>OpencvSharp code as follows:</p>

<pre><code>IplImage src;
IplImage gray;
IplImage eigImg;

        public void Grascale()
        {
            gray = Cv.CreateImage(src.Size, BitDepth.U8, 1);
            Cv.CvtColor(src, gray, ColorConversion.RgbToGray);
            Cv.SaveImage(""grayimg.jpg"", src);
        }

        public void DetectCorners()
        {
            Grascale();
            int cornerCount = 15000000;


            using (src)
            using (gray)
            using (IplImage eigImg = new IplImage(gray.GetSize(), BitDepth.F32, 1))
            using (IplImage tempImg = new IplImage(gray.GetSize(), BitDepth.F32, 1))

            {
                CvPoint2D32f[] corners;
                Cv.GoodFeaturesToTrack(gray, eigImg, tempImg, out corners, ref cornerCount, 0.1, 15);
                Cv.FindCornerSubPix(gray, corners, cornerCount, new CvSize(3, 3), new CvSize(-1, -1), new CvTermCriteria(20, 0.03));

                for (int i = 0; i &lt; cornerCount; i++)
                    Cv.Circle(src, corners[i], 3, new CvColor(0, 0, 255), 2);

                Cv.SaveImage(""result_img.jpg"", src);

            }
        }
</code></pre>
",2016-06-09 16:12:08,2017-03-07 05:36:26,Corner detection using EmguCv,<emgucv><opencvsharp>,,,CC BY-SA 3.0,False,False,True,False,False
43784,37773390,2016-06-12 10:53:58,,"<p>Currently I'm trying to write a small programm detecting faces.</p>

<p>I want to cut the grayframe for detection into pieces of the size of the rectangles of the detected faces. </p>

<p>This is my method for the operation:</p>

<pre><code>public List&lt;PreviewImage&gt; GetDetectedSnippets(Capture capture, ProcessType processType)
{
    var mat = capture?.QueryFrame();

    var imageList = new List&lt;PreviewImage&gt;();
    if (mat == null)
        return imageList;

    var imageframe = mat.ToImage&lt;Bgr, byte&gt;();
    var grayframe = imageframe.Convert&lt;Gray, byte&gt;();

    Rectangle[] faces = null;

    try
    {
        switch (processType)
        {
            case ProcessType.Front:
                {
                    faces = _cascadeFrontDefault.DetectMultiScale(grayframe, 1.25, 10, Size.Empty);

                }
                break;

            case ProcessType.Profile:
                {
                    faces = _cascadeProfileFace.DetectMultiScale(grayframe, 1.25, 10, Size.Empty);
                }
                break;

            default:
                {
                    return imageList;
                }
        }
    }
    catch (Exception ex)
    {
        Debug.WriteLine(""Could not process snapshot: "" + ex);
        return imageList;
    }


    foreach (var face in faces)
    {
        var detectedImage = imageframe.Clone();
        detectedImage.Draw(face, new Bgr(Color.BlueViolet), 4);


        var detectedGrayframe = grayframe.GrabCut(face, 1); // This isn't working. Here should the grayframe be cutted into a smaller piece.

        imageList.Add(new PreviewImage(detectedImage, detectedGrayframe));
    }

    return imageList;
}
</code></pre>

<p>And this is the previewImage class:</p>

<pre><code>public class PreviewImage
{
    public Image&lt;Bgr, byte&gt; Original { get; }
    public Image&lt;Gray, byte&gt; Grayframe { get; }

    public PreviewImage(Image&lt;Bgr, byte&gt; original, Image&lt;Gray, byte&gt; grayframe)
    {
        Original = original;
        Grayframe = grayframe;
    }
}
</code></pre>

<p>How can I cut the grayframe into a piece with the size of the given rectangle?</p>
",2016-06-12 11:12:15,2016-06-12 11:23:47,Cut image EmguCV,<c#><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
43997,37786181,2016-06-13 09:29:21,,"<p>I have a requirement to find out the passport and its details from the give image using Emgu.CV. </p>

<p>Can somebody help me to give direction regarding how to start with this. If somebody can show me the steps or ways to go for the solution would be really helpful.</p>

<p>Thanks in advance.</p>

<p>Parthiv</p>
",,2016-06-13 09:29:21,Need to find out Passport from the image using EMGUCV,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
44046,37791125,2016-06-13 13:31:13,,"<p>From a video, i want to capture images of all the updated frames .
The video is in windows media format (wmv), and what i am looking forward is to <strong>capture all the images from it whenever the video updates the visuals in it</strong>.</p>

<p>The video plays slowly , so i need to capture the screenshot of it whenever the frames updates or whenever the visuals in the video changes.</p>

<p>Using emgucv, I think we can add the frames like this.</p>

<pre><code>Image&lt;Bgr, Byte&gt; imgframe = video.QueryFrame();
image_array.Add(imgframe.Copy());
</code></pre>

<p>As i am a beginner, i need a helping hand. </p>
",2016-06-14 05:07:29,2016-06-14 05:22:28,EmguCV- Capture screenshot from a video whenever the video gets updated,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
44072,37910755,2016-06-19 18:59:47,,"<p>I am new to OpenCV.</p>

<p>I am using Emgu CV 3.1 Library in C# and Visual Studio 2015.</p>

<p>I am facing a problem in reading a live video from a WebCam. I don't know why the exception occurred by Capture() Constructor. I wasted my 2 days upon it.</p>

<p>Plzzz help me and provide me a solution in Emgu CV 3.1 on Visual Studio 2015. I got TypeInitializationException. I aslo upload the picture of exception.
<a href=""http://i.stack.imgur.com/sSTqx.png"" rel=""nofollow"">TypeInitializationException Is here</a></p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;

using Emgu.CV;
using Emgu.CV.Structure;

namespace FaceRecognition_3._0
{
    public partial class Form1 : Form
    {
        private Capture _capture;
        private CascadeClassifier _cascadeClassifier;


        public Form1()
        {
            InitializeComponent();

            _capture = new Capture();
            imgCamUser.Image = _capture.QueryFrame();
            startProcess();
        }

        public void startProcess()
        {
            _cascadeClassifier = new CascadeClassifier(Application.StartupPath + ""/haarcascade_frontalface_alt_tree.xml"");

            using (var imageFrame = _capture.QueryFrame().ToImage&lt;Bgr, Byte&gt;())
            {
                if (imageFrame != null)
                {
                    var grayframe = imageFrame.Convert&lt;Gray, byte&gt;();
                    var faces = _cascadeClassifier.DetectMultiScale(grayframe, 1.1, 10, Size.Empty); //the actual face detection happens here
                    foreach (var face in faces)
                    {
                        imageFrame.Draw(face, new Bgr(Color.BurlyWood), 3); //the detected face(s) is highlighted here using a box that is drawn around it/them

                    }
                }

                imgCamUser.Image = imageFrame;
            }
        }
    }
}
</code></pre>

<p>`</p>
",2016-06-19 19:04:15,2016-10-12 13:51:14,Exception In C# Code In Capturing Video From WebCam using Emgu CV 3.1 In Visual Studio 2015,<c#><visual-studio-2015><webcam><emgucv><live-video>,,,CC BY-SA 3.0,True,False,True,False,False
44206,37801393,2016-06-14 01:01:20,,"<p>If there is , is it a significant difference? </p>

<p>Is the difference derived by the different languages (c# vs c++)? </p>

<p>The libraries implementations?</p>

<p>Both?</p>

<p>That is for all operations , 
and especially image pixels iteration.</p>
",,2016-06-14 01:01:20,Is there a difference in performance between opencv and emgucv?,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
44207,37801986,2016-06-14 02:21:34,,"<p>I am new to OpenCV. I have a project to detect wall, floor and roof in a room picture and apply color or texture according to the selection. I searched alot in the Internet, but couldn't find a good one. </p>

<p>I also tried a pixel method to color the background, but then it doesn't give the feel of a room. Please can someone help me in this regard or share me the code if you don't mind. Thanks in Advance.</p>
",,2016-06-14 05:59:50,Select a region in a room picture either wall or roof or floor and apply a solid Color or a texture,<c#><opencv><emgucv><detection>,,,CC BY-SA 3.0,True,False,True,False,False
44230,38014883,2016-06-24 13:41:53,,"<p>New to EmguCV, so need an opinion on this scenario.  I have a video which shows - 3 Pages , </p>

<p>(i.e) first it shows Page1 then after 10 seconds it will update to Page2 and finally after a few seconds - Page3 .</p>

<p>I am looking to get these 3 frames as images . Whenever the Page in the video updates i need to take capture of that screen and save it as an image.</p>
",2016-06-27 10:29:27,2016-07-04 16:10:19,EmguCV - Process a video and capture frames as images,<c#><video-processing><emgucv><image-capture>,,,CC BY-SA 3.0,False,False,True,False,False
44247,38136447,2016-07-01 03:13:21,,"<p>I'm developing a vision processing application using WPF and EmguCV 3.0. My issue is that the element isn't positioned correctly on-screen. I have viewed what the padding is, and it returns all sides as 0. The ImageBox element from Emgu, which is what I am using to display the images, is encapsulated in a Windows Forms Host control. I have two other ImageBox elements, which display properly. Each of the ImageBox elements are within their own tab in a TabControl. On startup, I set the width and height properties of all the ImageBoxes and their canvases.</p>

<p>An additional thing to note is that the other two ImageBoxes also overflow out of their boundaries, but are reset back into the boundaries after switching back and forth between the tabs. This only happens once.</p>

<p>Here is a link to screenshots of what the UI looks like. <a href=""http://imgur.com/a/RwG17"" rel=""nofollow"">http://imgur.com/a/RwG17</a></p>

<p>Additionally, here is the XAML and C# code for the ImageBoxes.</p>

<pre><code>&lt;TabItem x:Name=""ImageTabControlHSV""&gt;
    &lt;TabItem.Header&gt;
        &lt;StackPanel Orientation=""Horizontal""&gt;
            &lt;TextBlock Text=""HSV"" /&gt;
        &lt;/StackPanel&gt;
    &lt;/TabItem.Header&gt;
    &lt;Canvas x:Name=""HSVImageCanvas""&gt;
        &lt;WindowsFormsHost&gt;
            &lt;emui:ImageBox x:Name=""HSVImageBox""/&gt;
        &lt;/WindowsFormsHost&gt;
    &lt;/Canvas&gt;
&lt;/TabItem&gt;

//Width and height properties are gotten from camera image.
HSVImageBox.Width = ratioWidth;
HSVImageBox.Height = ratioHeight;
HSVImageCanvas.Width = width;
HSVImageCanvas.Height = height;
HSVImageCanvas.MaxHeight = height;
HSVImageCanvas.MaxWidth = width;
</code></pre>

<p>Any help or suggestions would be greatly appreciated.</p>

<p><strong>UPDATE:</strong> Putting a counter for how many times the problematic ImageBox has been selected and using Canvas.SetTop() and Canvas.SetLeft() seems to be a workaround. I would still like to know why the canvas is changing its position.</p>
",2016-07-01 16:49:00,2016-07-05 04:38:46,C# WPF element position not in correct place,<c#><wpf><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
44268,37926001,2016-06-20 15:12:55,,"<p>I am making a program in c# that must detect and scan Qr-codes from a tag (using security cameras) that people glue to their chest, and as a second layer of security must also capture their faces and match them in a database. Now, i was able of dealing with the face recognition just fine, but the program fails to read more than one Qr-code at a time. How could i deal with this? I am using ZXing's library aswell as Emgu.cv. Are there better options?
My code for QR-Reading is:</p>

<pre><code>        bitmap = frame.Bitmap;
        txtQreader.Text = Qrreader(bitmap); //it's inside an if, not that it matters :p


    private string Qrreader(Bitmap x)
{
    BarcodeReader reader = new BarcodeReader { AutoRotate = true, TryHarder = true };
    Result result = reader.Decode(x);
    string decoded = result.ToString().Trim();
    return decoded;
}
</code></pre>
",2016-06-21 08:11:47,2019-11-20 15:43:54,Multiple QRCode detection from video stream,<c#><opencv><computer-vision><zxing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
44269,37927166,2016-06-20 16:10:46,,"<p>I have created a windows form application that is a face recogniser using EMGU CV. I also have a website which is locally hosted on my laptop, made using ASP.NET MVC4. I want a link on my website which ,upon clicking, opens the facial recognition software. Is it possible to do it? Do I have to create a setup of application and install it to do this or is there any other way? </p>
",,2016-06-20 16:39:39,Open windows form application from a link in locally hosted website,<c#><asp.net><asp.net-mvc-4><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
44371,38107768,2016-06-29 18:45:42,,"<p>I currently use a NDA-library (non commercial) which has zero documentation and uses EMGU.
Here is a example for my Question:</p>

<pre><code>public void example()
{
     Image&lt;Gray,byte&gt; exp = new Image&lt;Gray,byte&gt;(128,128);
     foo(exp);
     exp.Dispose();
}

public bool foo(Image&lt;Gray,byte&gt; bar)
{
     //magic here
     //bar.Dispose() ??
     return true;
}
</code></pre>

<p>When I pass an EMGU-Image from one function to another, do i have to call <code>.Dispose()</code> in the called function, too? Or is it sufficient to call it in the callee?</p>
",2016-06-29 18:46:42,2016-06-29 18:48:27,Do i have to dispose a parameter in C#?,<c#><memory-management><memory-leaks><emgucv>,2016-06-29 18:48:14,,CC BY-SA 3.0,False,False,True,False,False
44445,38031836,2016-06-25 18:47:04,,"<p>How to call CvInvoke.HoughLines with EmguCv in C#? Thus not the HoughLinesP method. The trouble I am experiencing is the type to use for the second parameter, which is of IOutputArray. </p>
",,2016-06-25 18:47:04,How to use OpenCv 3.0 CvInvoke.HoughLines method with EmguCv,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
44485,38076620,2016-06-28 12:43:53,,"<p>I'm implementing a Pedestrian detection system using emgu cv library. The find method Returns number of results that detecting through the method. </p>

<pre><code>public static Rectangle[] findPedestrian(Image&lt;Bgr, Byte&gt; image)
{
    Stopwatch stopwatch;
    Rectangle[] regions;
    if (CudaInvoke.HasCuda)
    {
        using (CudaHOG des = new CudaHOG(new Size(64, 128), new Size(16, 16), new Size(8, 8), new Size(8, 8)))
        {
            des.SetSVMDetector(des.GetDefaultPeopleDetector());
            stopwatch = Stopwatch.StartNew();
            using (GpuMat cudaBgr = new GpuMat(image))
            using (GpuMat cudaBgra = new GpuMat())
            using (VectorOfRect vr = new VectorOfRect())
            {
                CudaInvoke.CvtColor(cudaBgr, cudaBgra, ColorConversion.Bgr2Bgra);
                des.DetectMultiScale(cudaBgra, vr);
                regions = vr.ToArray();
            }
        }
    }
    else
    {
        using (HOGDescriptor des = new HOGDescriptor())
        {
            des.SetSVMDetector(HOGDescriptor.GetDefaultPeopleDetector());
            stopwatch = Stopwatch.StartNew();
            MCvObjectDetection[] results = des.DetectMultiScale(image);
            regions = new Rectangle[results.Length];
            for (int i = 0; i &lt; results.Length; i++)
                regions[i] = results[i].Rect;
            stopwatch.Stop();
        }
    }
    //processingTime = stopwatch.ElapsedMilliseconds;
    return regions;
}
</code></pre>

<p>And here it's generating the rectangles according to the results that sending through the process. What i want is to count the number of results that returning through the method. I thought to get it from the number of iterations of this foreach loop. </p>

<pre><code>private Image&lt;Bgr, Byte&gt; imagingPedestrian(Image&lt;Bgr, Byte&gt; image)
{
    System.Drawing.Rectangle[] results = pedestrianDetection.findPedestrian(image);
    foreach (Rectangle rect in results)
    {
        CvInvoke.Rectangle(image, rect, new Bgr(Color.Red).MCvScalar);
    }
    return image;
}
</code></pre>

<p>Can i know a way to get that result. Thanks in advance.</p>
",2016-06-28 13:13:55,2016-11-15 14:54:27,How to get the number of Results that returns through Find method in EMGU CV Pedestrian Detection C#,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
44561,38261510,2016-07-08 07:49:56,,"<p>I have GeForce GTX 960 with installed 353.90 NVidia driver and 7.5.18 CUDA driver. I'm using the latest version of Emgu CV, but it doesn't detect CUDA on the system (even in Emgu samples), <code>Emgu.CV.Cuda.CudaInvoke.HasCuda</code> is always <code>false</code>. At the same time other programs, like Xillisoft Video Converter can use CUDA without problems. How do I enable CUDA for Emgu CV?</p>
",2016-07-22 07:27:47,2017-03-26 05:21:24,Emgu CV does not detect CUDA,<c#><opencv><nvidia><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
44589,38083170,2016-06-28 17:58:28,,"<p>I am kind new with emgucv and optical flow. I am trying to recognize object in motion on video and draw around them circle or rectangle or some other shape. I must use opticalflow.HS and opticalflow.LK. That is the first thing I want to do. I am using emgu cv 2.4.9.I have some code, but it is just some thinking. I red previous frame and current frame and sent it to opticalflow.HS but I don't know what to do after that and I can't find any example using HS, so I would really appreciate same example what to do next after opticalflow.HS and also some advice.</p>

<pre><code>  private void ProcessFrame(object sender, EventArgs e)
  {
      bool firstFrame = true;
      bool keepProcessing = true;

      Image&lt;Gray, Byte&gt; nextFrame = new Image&lt;Gray, byte&gt;(160, 640);
      Image&lt;Gray, Byte&gt; previousFrame = null;

      while (keepProcessing)
      {
          // ****** Change - Save previous frame before getting next one
          // Only do this if the first frame has passed
          if (!firstFrame)
              previousFrame = nextFrame.Clone();

          // grab the next frame from video source
         // _capture.Grab();

          // decode and return the grabbed video frame
          nextFrame = _capture.RetrieveGrayFrame();

          // if the frame is valid (not end of video for example)
          if (!(nextFrame==null))
          {
              // **** Change - If we are on the first frame, only show that and
              // set the flag to false
              if (firstFrame)
              {
                  firstFrame = false;

              }
              else
              {
                  Image&lt;Gray, float&gt; velx = new Image&lt;Gray, float&gt;(previousFrame.Size);
                  Image&lt;Gray, float&gt; vely = new Image&lt;Gray, float&gt;(nextFrame.Size);
                  OpticalFlow.HS(previousFrame, nextFrame, true, velx, vely, 0.1d, new MCvTermCriteria(100));
                  //capturedImageBox.Image = nextFrame;

              }
          }
          else
          {
              keepProcessing = false;
          }
      }
</code></pre>
",2016-06-28 18:08:38,2016-06-28 18:24:56,Motion detection using C# and EmguCV,<c#><emgucv><motion><motion-detection><opticalflow>,,,CC BY-SA 3.0,False,False,True,False,False
44611,38165908,2016-07-03 01:22:00,,"<p>The method below processing rectangles for the objects identified in findPedestrian() method. I have assigned 'rectCount' variable to show the rectangle count on every each frame. And 'maxCount' variable shows the maximum number of rectangles the count while the process.</p>

<pre><code>private Image&lt;Bgr, Byte&gt; imagingPedestrian(Image&lt;Bgr, Byte&gt; image)
    { 
        System.Drawing.Rectangle[] results = pedestrianDetection.findPedestrian(image);
        //System.Drawing.Rectangle[] results2 = vehicleDetection.findVehicle(image);
        foreach (Rectangle rect in results)
        {
            CvInvoke.Rectangle(image, rect, new Bgr(Color.Red).MCvScalar);
            rectCount = results.Count();
            label1.Text = rectCount.ToString();
            if(rectCount &gt; maxCount1)
            {
                maxCount1 = rectCount;
                label8.Text = maxCount1.ToString();
            }
            else
            {
                label8.Text = maxCount1.ToString();
            }
        }
        return image;
    }
</code></pre>

<p>In this question what i want to get is get the rectangle count for every 10 seconds. After 10 seconds the maxCount variable should get reset. Then it should show the maximum rectangle count within next 10 seconds. Like wise it should run iterately within every 10 seconds. Is there anyway to implement it..</p>

<p>Thanks in Advance..</p>
",,2016-07-03 01:37:18,How to set an Integer Variable to set Reset within a number of seconds,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
44620,38202802,2016-07-05 11:54:13,,"<p>I'm using Emgu CV's SURF feature to recognize similar objects in images. 
The image is drawn, showing all the key points found, in both images. The problem  is that the similar points are seen in the image.</p>

<p>How can I save those match points in a database?</p>
",,2016-07-15 12:47:01,How to save interest point in SURF feature?,<emgucv><similarity><surf>,,,CC BY-SA 3.0,False,False,True,False,False
44730,38389841,2016-07-15 07:05:01,,"<p>I have a problem looking forward to people to help when i detect and face recognition using Emgu Library,before  face detection i draw a rectangle on the picturebox, the purpose is i want to face detection and recognition are located inside this rectangle if the face is outside the rectangle will not detect and identification, how can I do this?Please help me.
My email : giangnamnam@gmail.com,thank you very much.</p>

<p>Descriptions:</p>

<p>Step 1:
<a href=""http://i.stack.imgur.com/KPnp4.jpg"" rel=""nofollow"">Detection and recognition</a></p>

<p>Step 2:
<a href=""http://i.stack.imgur.com/a8bO4.jpg"" rel=""nofollow"">I want the result will look like this</a></p>

<p>Here's my code:</p>

<ul>
<li><p>Draw rectangle on picturebox :</p>

<pre><code> private void pictureBox1_Paint(object sender, PaintEventArgs e)
{
   Rectangle rect = new Rectangle(90, 80, 160, 160);
    using (Pen pen = new Pen(Color.Red, 2))
    {
        e.Graphics.DrawRectangle(pen, rect);
    }
}
</code></pre>

<ul>
<li><p>Code for face detection :</p>

<pre><code>private void btn_FaceDetection_Click(object sender, EventArgs e)
{

    Image&lt;Bgr, byte&gt;   imgOriginal = new Image&lt;Bgr, byte&gt;(new Bitmap(pictureBox1.Image));
    Image&lt;Gray, Byte&gt; grayFrame = imgOriginal.Convert&lt;Gray, Byte&gt;();
    Rectangle[] facesDetected = haar.DetectMultiScale(grayFrame, 1.2, 5, new Size(50, 50), Size.Empty);

    if (facesDetected.Length &gt; 0)
    {
        for (int i = 0; i &lt; facesDetected.Length; i++)
        {
            facesDetected[i].X += (int)(facesDetected[i].Height * 0.1);
            facesDetected[i].Y += (int)(facesDetected[i].Width * 0.15);
            facesDetected[i].Height -= (int)(facesDetected[i].Height * 0.2);
            facesDetected[i].Width -= (int)(facesDetected[i].Width * 0.2);

            // print face to view
            Image&lt;Gray, Byte&gt; result = grayFrame.Copy(facesDetected[i]).Convert&lt;Gray, Byte&gt;().Resize(150, 150, INTER.CV_INTER_CUBIC);
            result._EqualizeHist();
            picb_ViewFace.Image = result.ToBitmap();

            // draw rectangle for face
            imgOriginal.Draw(facesDetected[i], new Bgr(Color.Green), 2);
        }
    }

    pictureBox1.Image = imgOriginal.ToBitmap();

}
</code></pre></li>
</ul></li>
</ul>
",2016-07-15 08:05:14,2016-07-15 08:05:14,How can I check if a rectangle is inside another rectangle Emgu C#,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
44742,38279632,2016-07-09 07:53:24,,"<p>I have an algorithm <a href=""http://docs.opencv.org/master/d7/d8b/tutorial_py_face_detection.html#gsc.tab=0"" rel=""nofollow noreferrer"">Viola-Jones</a> in <code>Python</code>. I'm using <code>haarcascade</code> xml, which I load from <code>openCV</code> root file. But there wasn't any xml file for mouth and nose in <code>openCV</code>, so I downloaded these files from <a href=""https://sourceforge.net/p/emgucv/opencv/ci/d58cd9851fdb592a395488fc5721d11c7436a99c/tree/data/haarcascades/"" rel=""nofollow noreferrer"">EmguCV</a>. Result for detection of face is OK, but detection of eye isn't good and nose with mouth is very bad. I tried to change parameters in <code>face_cascade.detectMultiScale</code>, but it didn't help at all.</p>

<hr>

<p><strong>My code:</strong></p>

<pre><code>import cv2
import sys

def facedet(img):
    face_cascade = cv2.CascadeClassifier('/home/kattynka/opencv/data/haarcascades/haarcascade_frontalface_default.xml')
    eye_cascade = cv2.CascadeClassifier('/home/kattynka/opencv/data/haarcascades/haarcascade_eye.xml')
    mouth_cascade = cv2.CascadeClassifier('/home/kattynka/opencv/data/haarcascades/haarcascade_mcs_mouth.xml')
    nose_cascade = cv2.CascadeClassifier('/home/kattynka/opencv/data/haarcascades/haarcascade_mcs_nose.xml')

    img = cv2.imread(img)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    faces = face_cascade.detectMultiScale(gray, 1.3, 5)

    for (x,y,w,h) in faces:
        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)
        roi_gray = gray[y:y+h, x:x+w]
        roi_color = img[y:y+h, x:x+w]
        eyes = eye_cascade.detectMultiScale(roi_gray)
        nose =  nose_cascade.detectMultiScale(roi_gray)
        mouth = mouth_cascade.detectMultiScale(roi_gray)

        for (ex,ey,ew,eh) in eyes:
            cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0,255,0), 2)
        for (nx, ny, nw, nh) in nose:
            cv2.rectangle(roi_color, (nx, ny), (nx + nw, ny + nh), (0, 0, 255), 2)
        for (mx, my, mw, mh) in mouth:
            cv2.rectangle(roi_color, (mx, my), (mx + mw, my + mh), (0, 0, 0), 2)

    cv2.namedWindow('image', cv2.WINDOW_NORMAL)
    cv2.imshow('image',img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()


if __name__ == '__main__':
    #img = sys.argv[1]
    facedet(img)
</code></pre>

<hr>

<p><strong>My question</strong></p>

<p>What am I doing wrong? Is there any simple solution, which will give me a better result? </p>

<hr>

<p><strong>Output:</strong></p>

<p><a href=""https://i.stack.imgur.com/VOdIj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VOdIj.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/G2MBq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/G2MBq.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/PjSX5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PjSX5.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/zye32.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zye32.png"" alt=""enter image description here""></a></p>
",,2019-12-11 19:58:46,"Viola-Jones in Python with openCV, detection mouth and nose",<python><xml><opencv><face-detection><viola-jones>,,,CC BY-SA 3.0,True,False,True,False,False
44775,38351702,2016-07-13 12:25:51,,"<p>The error happens in this line:</p>

<pre><code>Dim imageMatrix = New Emgu.CV.Matrix(Of Double)(100, 120)
</code></pre>

<blockquote>
  <p>An unhandled exception of type 'System.TypeInitializationException' occurred in Emgu.CV.World.dll</p>
</blockquote>

<pre><code>CvInvoke.cvInitMatHeader(_ptr, _array.GetLength(0), _array.GetLength(1), CvInvoke.MakeType( CvInvoke.GetDepthType(typeof(TDepth)), 1), _dataHandle.AddrOfPinnedObject(), 0x7fffffff);
</code></pre>

<p>Is this a declaration or library error?</p>

<p>Thanks for your help</p>
",2016-07-13 13:03:17,2016-07-14 04:53:51,Error creating Matrix in EMGU CV,<vb.net><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
44893,38360698,2016-07-13 20:01:12,,"<p>I am doing project in Emgu cv in C#.</p>

<p>I have stuck in this first step. I calculated opticalflow.HS and LK and I don't know how to add velx and vely to draw them in frame as points and show them in ImageBox.</p>

<pre><code> OpticalFlow.HS(prev, frame1, true, velx, vely, 0.1d, new MCvTermCriteria(100));
</code></pre>

<p>Does anyone can describe me what to do or even better some code example will be a lot of help? I don't want to show color of direction, only motion as points in frame.</p>
",,2016-07-14 19:13:49,velX and velY in optical flow (how to add them),<c#><opencv><computer-vision><emgucv><opticalflow>,,,CC BY-SA 3.0,True,False,True,False,False
44924,38523886,2016-07-22 10:16:07,,"<p>I have a very strange problem when using Emgu CV's gaussian blur functionality. Blurring an image works fine when I use a kernel size of 1-3, but when I use a larger size, my application exits with the following message:</p>

<p><code>Exception thrown: 'Emgu.CV.Util.CvException' in Emgu.CV.World.dll</code></p>

<p>I'm working in Visual Studio, and it doesn't even give me the standard exception popup. It just exits and throws me back to the editor.</p>

<p>This is the code I've tried:</p>

<p><code>CvInvoke.GaussianBlur(image, image, new Size(4, 4), 0, 0);</code></p>

<p><code>image._SmoothGaussian(4);</code></p>

<p>Both examples give the same results.</p>
",,2017-01-06 01:21:04,"Emgu CV ""Emgu.CV.Util.CvException"" when using GaussianBlur with size>3",<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
45015,38243881,2016-07-07 11:05:08,,"<p>I'm using <code>Image</code> class and it's <code>MatchTemplate</code> method in Emgu CV to detect pattern in pictures. So, my pictures are black-white (with 256 gray variants) and I have to search for white templates, but how do I store them? If I'm using .png with only 2 colors: white for pattern and black for background - then <code>MatchTemplate</code> method considers the background part of template (and that's ruining the results). What color I have to use for background in patterns?</p>

<p>UPD: Images added.</p>

<p>Pattern (only white triangle needed):</p>

<p><a href=""https://i.stack.imgur.com/ijlpS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ijlpS.png"" alt=""Pattern""></a></p>

<p>Image example (a simple one):</p>

<p><a href=""https://i.stack.imgur.com/fuuAj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fuuAj.png"" alt=""Image""></a></p>

<p>Detection (white square is what I get, red one - what I need):
<a href=""https://i.stack.imgur.com/NJrzT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NJrzT.png"" alt=""Detection""></a></p>
",2018-03-07 06:33:37,2020-06-25 23:49:55,Emgu CV - ignore a color while matching template,<c#><opencv><image-processing><pattern-matching><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
45044,38369572,2016-07-14 08:47:59,,"<p>I am using Emgu CV (v2.4) with C#. In the following class. I need to modify the data type of the used column in the table to  array. </p>

<pre><code>public void  FindSURF(Image&lt;Gray, Byte&gt; modelImage)
{
    VectorOfKeyPoint modelKeyPoints;

    SURFDetector surfCPU = new SURFDetector(500, false);

    //extract features from the object image
    modelKeyPoints = new VectorOfKeyPoint();
    Matrix&lt;float&gt; modelDescriptors = surfCPU.DetectAndCompute(modelImage, null, modelKeyPoints);

}  
</code></pre>

<p>the SURF feature extract and store in <code>Matrix&lt;float&gt; modelDescriptors</code> how can I modify this datatype to array?</p>
",2016-07-14 14:37:24,2016-07-14 14:37:24,How to modify datatype of Matrix<float> to array?,<c#><arrays><emgucv><type-conversion><surf>,,,CC BY-SA 3.0,False,False,True,False,False
45247,38640640,2016-07-28 15:25:24,,"<p>I need to find the coordinates of the most popular simple shapes (usually - rectangles) in the picture. I used the approach that has been described here (<a href=""https://stackoverflow.com/a/35251367/5341912"">Simple approach for finding rectangles</a> ). But I've faced with the situation shown in the picture. Some boxes have a torn border and I cannot detect them with standard approach. These rectangles circled in red.
<a href=""https://i.stack.imgur.com/lMrqp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lMrqp.png"" alt=""Objects have torn contours""></a> What solution would you suggest?</p>

<p>UPDATE:</p>

<p>Using dilation/erosion before binarization:</p>

<ol>
<li>Dilation</li>
</ol>

<p><a href=""https://i.stack.imgur.com/7NpqN.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7NpqN.png"" alt=""Dilate image before binarization""></a></p>

<ol start=""2"">
<li>Erosion</li>
</ol>

<p><a href=""https://i.stack.imgur.com/bMMIr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bMMIr.png"" alt=""Erode image before binarization""></a></p>
",2017-05-23 12:08:32,2016-08-25 10:03:19,"How to detect simple shapes (using emgu cv), when a contour can be torn?",<c#><opencv><image-processing><emgucv><opencv-contour>,,,CC BY-SA 3.0,True,False,True,False,False
45301,38611298,2016-07-27 11:10:39,,"<p>I just started to learn Emgu and OpenCV. So it might be a stupid question. When I look at Emgu documentation (see link <a href=""https://stackoverflow.com/questions/24970577/finding-contour-points-in-emgucv"">http://www.emgu.com/wiki/files/3.1.0/document/html/cb24a129-d9ce-57f3-19ad-0eaa27a77317.htm</a> ), I cannot find an example. But I suppose you used it in the form of</p>

<pre><code>CvInvoke.FindContours(...)
</code></pre>

<p>But when I searched stackoverflow, I found this person just used the following form in the middle-bottom section of his code <a href=""https://stackoverflow.com/questions/24970577/finding-contour-points-in-emgucv"">enter link description here</a></p>

<pre><code>grayImage.FindContours()
</code></pre>

<p>However, when I tried the later, Visual studio simply doesn't accept it. (ie, when I typed in grayImage.F the pop up simply doesn't have FindContours function). </p>

<p>I am using the latest opencv and emgu. Any ideas?</p>
",2017-05-23 12:13:44,2016-11-08 09:19:11,"Emgu, what's the difference between .FindContours() and CvInvoke.FindContours()",<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
45436,38700086,2016-08-01 13:23:34,,"<p>I try to convert from bitmap to Image (ImageBox) of EmguCV but it shows me the problem Cannot implicitly convert type 'System.Drawing.Bitmap' to 'Emgu.CV.IImage' with <code>this.captureImageBox.Image = val;</code>
I am using EmguCV V3</p>

<pre><code>void SetPic(Bitmap val)
        {
            if (val != null)
            {

                this.captureImageBox.Image = val;
            }
        }
</code></pre>

<blockquote>
  <p>Severity  Code    Description Project File    Line    Suppression State
  Error   CS0029  Cannot implicitly convert type 'System.Drawing.Bitmap' to 'Emgu.CV.IImage'  </p>
</blockquote>
",,2016-08-01 13:39:10,convert type 'System.Drawing.Bitmap' to 'Emgu.CV.IImage',<c#><winforms><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
45523,38890357,2016-08-11 07:48:51,,"<p>I am working on Image processing and i have made an application in c# using EmguCV wrapper version 2.4 beta and now i want to covert it in to vb.Net so which version would be compatible for vb.Net i want to use these dll files.</p>

<pre><code>Imports Emgu.CV.UI
Imports Emgu.CV
Imports Emgu.CV.Structure
Imports Emgu.CV.CvEnum
</code></pre>

<p>Help me to resolve this problem how can i use EmguCV in vb.Net..</p>
",,2016-08-11 07:56:48,EmguCV compatible version for VB.NET,<vb.net><image-processing><dll><emgucv><face-recognition>,,,CC BY-SA 3.0,False,False,True,False,False
45551,38705960,2016-08-01 18:44:57,,"<p>I have two images, I need to get a return that's a bool match. Everything I'm finding is ""getting the difference image"" which is not what I want. </p>

<pre><code>        Image&lt;Gray, Byte&gt; img1 = new Image&lt;Gray, Byte&gt;(imageURL);
        Image&lt;Gray, Byte&gt; img2 = new Image&lt;Gray, Byte&gt;(imageURL2);
        Image&lt;Gray, Byte&gt; img3 = img2 - img1;
</code></pre>

<p>I'd also take some sort of percent match return. </p>
",,2016-08-01 19:07:30,Do two images match? Using Emgu CV C#,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
45568,38792117,2016-08-05 14:49:41,,"<p>I am working on a face recognition program using emguCV.</p>

<p>Right now, I am writing a program to write the test results in an excel worksheet.</p>

<p>Here are the code that I used to paste the test result:</p>

<pre><code>Image a = imageBoxTesting.Image.Bitmap;                    
Image b = imageBoxTraining.Image.Bitmap;

                Clipboard.SetImage(a);
                cellRngImg = (Range)ws.Cells[rowCount, 1];
                ws.Paste(cellRngImg, a);

                ws.Cells[2][rowCount] = testingLabel;

                Clipboard.SetImage(b);
                cellRngImg2 = (Range)ws.Cells[rowCount, 3];
                ws.Paste(cellRngImg2, b);

                Clipboard.Clear();
                cellRngImg.Clear();
                cellRngImg2.Clear();

                ws.Cells[4][rowCount] = predictionLabel;
                ws.Cells[5][rowCount] = ed;
                ws.Cells[6][rowCount] = valid;
                ws.Cells[7][rowCount] = maxDistance;
rowCount++;
</code></pre>

<p>The code above  is put in a loop until every available testing images are tested.</p>

<p>The error seems to occur on either of this line:</p>

<pre><code>ws.Paste(cellRngImg, a);
ws.Paste(cellRngImg2, b);
</code></pre>

<p>And the error occurs randomly, never at the same iterations. On one run, it could occur at the 3rd iteration, on another run it could occur at the 17th iteration.</p>

<p>I have tried running VS as administrator, but it doesn't seem to affect anything.</p>

<p>Please help!
Thank you!</p>

<p>EDIT
The error message:
    An unhandled exception of type 'System.Runtime.InteropServices.COMException' occured in Eigenface.exe
    Additional information: Exception from HRESULT: 0x800A03EC</p>
",2016-08-05 15:17:26,2016-08-05 15:17:26,Error While Pasting Image to Worksheet Cells,<c#><excel><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
45641,38878457,2016-08-10 16:04:11,,"<p>Here I am trying to display a live image stream in imagebox through the laptop webcam for which i have used <code>emgucv-windows-x86 2.2.1.1150</code>. (Note: I am using windows 64bit).</p>

<p>I have used a button whose text is <code>Start!</code> initially. What we want is that when the <code>Start!</code> button is pressed, the camera should start working and the image stream should be visible in our <code>ImageBox</code>. If the stream is on, then the start button should display <code>Pause</code> and pressing it should pause the stream and vice versa.</p>

<p>The problem is that when I press the <code>Start!</code> button, even if there is no error at all, instead of showing live stream image it shows nothing in the ImageBox even though webcam is working.</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.Util;
namespace CameraCapture
{
  public partial class cameracapture : Form
  {
    //declaring global variables
    private Capture capture;        //takes images from camera as image frames
    private bool captureInProgress; // checks if capture is executing

    public cameracapture()
    {
      InitializeComponent();
    }
    //------------------------------------------------------------------------------//
    //Process Frame() below is our user defined function in which we will create an EmguCv 
    //type image called ImageFrame. capture a frame from camera and allocate it to our 
    //ImageFrame. then show this image in ourEmguCV imageBox
    //------------------------------------------------------------------------------//

    private void ProcessFrame(object sender, EventArgs arg)
    {
      Image&lt;Bgr, Byte&gt; ImageFrame = capture.QueryFrame();
      CamImageBox.Image = ImageFrame;
    }
    private void cameracapture_Load(object sender, EventArgs e)
    {

    }

    private void btnStart_Click(object sender, EventArgs e)
    {
      #region if capture is not created, create it now
      if (capture == null)
      {
        try
        {
            capture = new Capture();
        }
        catch (NullReferenceException excpt)
        {
            MessageBox.Show(excpt.Message);
        }
      }
      #endregion

      if (capture != null)
      {
        if (captureInProgress)
        {  //if camera is getting frames then stop the capture and set button Text
            // ""Start"" for resuming capture
            btnStart.Text = ""Start!""; //
            Application.Idle -= ProcessFrame;
        }
        else
        {
            //if camera is NOT getting frames then start the capture and set button
            // Text to ""Stop"" for pausing capture
            btnStart.Text = ""Stop"";
            Application.Idle += ProcessFrame;
        }

        captureInProgress = !captureInProgress;
    }

    }
    private void ReleaseData()
    {
      if (capture != null)
        capture.Dispose();
    }
  }
}
</code></pre>
",2017-09-03 05:13:25,2020-06-26 01:43:11,How to Display Image in Emgucv,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
45655,38973023,2016-08-16 10:54:41,,"<p>I'm currently using the EmguCV library along with Kinect to create a simple hit test using WPF. I'm able to succesfully find the chessboard corners and store them in a list of rectangles as 4 corners of rectangles, then I'm trying to use a LeftMouseButtonUp event to get the mouse position and check whether it lies in the boundary any of the rectangles.</p>

<p>The problem is that I suspect that the coordinates returned by EmguCV as chessboard corners and the ones return from the mouse click event arent aligned, therefore it cannot detect a hit (i.e. a mouse click within a rectangle). How to get these two coordinates aligned together? Am I missing something?</p>

<p>XAML:</p>

<pre><code>&lt;Window x:Class=""EmguMotionTest.MainWindow""
        xmlns=""http://schemas.microsoft.com/winfx/2006/xaml/presentation""
        xmlns:x=""http://schemas.microsoft.com/winfx/2006/xaml""
        Title=""MainWindow"" Height=""350"" Width=""525"" KeyDown=""Window_KeyDown"" &gt;
    &lt;Grid&gt;
        &lt;Image Name=""rgbImage"" Stretch=""Fill"" MouseLeftButtonUp=""rgbImage_MouseLeftButtonUp""/&gt;
        &lt;Line Name=""line"" Stroke=""Red"" StrokeThickness=""1"" Visibility=""Visible"" /&gt;
    &lt;/Grid&gt;
&lt;/Window&gt;
</code></pre>

<p>C#:</p>

<pre><code>public partial class MainWindow : Window
{
    /*Kinect Initialization*/
    KinectSensor _kinectSensor;

    /*Getting the Chessboard corners*/
    PointF[] corners = new PointF[] { };
    PointF[] points = new PointF[4];
    List&lt;PointF&gt; cornerPts = new List&lt;PointF&gt;();
    List&lt;List&lt;PointF&gt;&gt; rectangle = new List&lt;List&lt;PointF&gt;&gt;();
    /*Defining the Chessboard parameters */
    const int width = 4;
    const int height = 4;
    Drawing.Size boardSize = new Drawing.Size(width, height);

    public MainWindow()
    {
        InitializeComponent();

        this.Unloaded += delegate
        {
            _kinectSensor.ColorStream.Disable();
        };

        this.Loaded += delegate
        {
            _kinectSensor = KinectSensor.KinectSensors[0];

            _kinectSensor.ColorStream.Enable();
            _kinectSensor.Start();

            BackgroundWorker bw = new BackgroundWorker();
            bw.DoWork += (a, b) =&gt; Pulse();
            bw.RunWorkerCompleted += (c, d) =&gt; bw.RunWorkerAsync();
            bw.RunWorkerAsync();
        };
    }

    /*Polling event to retrieve Data from Kinect*/
    private void Pulse()
    {
        using (ColorImageFrame imageFrame = _kinectSensor.ColorStream.OpenNextFrame(200))
        {
            if (imageFrame == null)
                return;

            //Converting a Kinect Color Frame to EmguCV Image
            Image&lt;Bgr, Byte&gt; imageCap = imageFrame.ToOpenCVImage&lt;Bgr, Byte&gt;();

            Image&lt;Gray, Byte&gt; gray = imageCap.Convert&lt;Gray, Byte&gt;();

            corners = CameraCalibration.FindChessboardCorners(gray, boardSize, Emgu.CV.CvEnum.CALIB_CB_TYPE.ADAPTIVE_THRESH | Emgu.CV.CvEnum.CALIB_CB_TYPE.FILTER_QUADS);

            if (corners != null)
            {
                CvInvoke.cvFindCornerSubPix(gray, corners, corners.Length, new Drawing.Size(11, 11), new Drawing.Size(-1, -1), new MCvTermCriteria(30, 0.1));
                CameraCalibration.DrawChessboardCorners(gray, boardSize, corners);

                //Displaying the result in WPF
                this.Dispatcher.Invoke(
                       new Action(() =&gt; rgbImage.Source = gray.ToBitmapSource())
                       );
            }
            else
            {
                //Displaying the result in WPF
                this.Dispatcher.Invoke(
                       new Action(() =&gt; rgbImage.Source = gray.ToBitmapSource())
                       );
            }

        }
    }

    private void Window_KeyDown(object sender, KeyEventArgs e)
    {
        if (e.Key == Key.Space)
        {
            //Clear out the List of points 
            if (cornerPts != null)
            {
                cornerPts.Clear();
            }

            //Enter all the found corners into an array stored as polygons
            for (int i = 0; i &lt; boardSize.Height - 1; i++)
            {
                for (int j = 0; j &lt; boardSize.Width - 1; j++)
                {
                    //Getting the corners of the squares (Square 1, 2, 3)..
                    int p1 = (i * boardSize.Width) + j;
                    int p2 = (i * boardSize.Width) + j + 1;
                    int p3 = ((i + 1) * boardSize.Width) + j;
                    int p4 = ((i + 1) * boardSize.Width) + j + 1;

                    //Add range method

                    points[0] = corners[p1];
                    points[1] = corners[p2];
                    points[2] = corners[p3];
                    points[3] = corners[p4];

                    cornerPts.AddRange(points);
                    rectangle.Add(new List&lt;PointF&gt;() { points[0], points[1], points[2], points[3] });
                }
            }
        }

        /*To test the corners points are being added correctly */
        if (e.Key == Key.D)
        {
            Console.WriteLine(""D button press registered"");

            ///*Test Square */
            for (int c = 0; c &lt; rectangle.Count; c++)
            {
                for (int n = 0; n &lt; 4; n++)
                {
                    Console.WriteLine(""Triangle no: "" + c + "","" + n + rectangle[c][n]);
                }
            }
        }
    }

    private void rgbImage_MouseLeftButtonUp(object sender, MouseButtonEventArgs e)
    {
        System.Windows.Point p = Mouse.GetPosition(rgbImage);
        Console.WriteLine(""MouseX: "" + p.X + "","" + ""MouseY: "" + p.Y);

        Console.WriteLine(""-------------Hit Test---------------"");
        /*Test Square */
        for (int c = 0; c &lt; rectangle.Count; c++)
        {
            for (int n = 0; n &lt; 4; n++)
            {
                //Console.WriteLine(""Triangle no: "" + c + "","" + n + rectangle[c][n]);

                if ((p.X &gt; rectangle[c][0].X &amp;&amp; p.X &lt; rectangle[c][1].X) &amp;&amp; (p.Y &gt; rectangle[c][0].Y &amp;&amp; p.Y &lt; rectangle[c][2].Y))
                {
                    Console.WriteLine(""Triangle HIT is triangle no: "" + c);
                }

            }
        }
    }
}
</code></pre>
",2016-08-16 11:07:56,2016-08-19 11:21:57,Mouse click event coordinates are not matching or aligned with the found chessboard corner coordinates - EmguCV / WPF,<c#><wpf><opencv><kinect><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
45730,39053940,2016-08-20 12:06:13,,"<p>I am trying to stitch multiple images to single(panorama) image.</p>

<p>Following code working fine in EMGU-2.4 but in EMGU-3.1 I have a problem in passing parameters in stitch method.</p>

<pre><code>  // Collect all images
            List&lt;Image&lt;Bgr, Byte&gt;&gt; sourceImages = new List&lt;Image&lt;Bgr, Byte&gt;&gt;(); 

            for (int i = 1; i &lt;7 ; i++)
            {
                string fileN = fl1 + ""n ("" + i.ToString() + "").jpg"";
                sourceImages.Add(new Image&lt;Bgr, Byte&gt;(fileN));
            }

            try
            {
                using (Stitcher stitcher = new Stitcher(false))
                {
                    // Stitch images
                    Image&lt;Bgr, Byte&gt; result = stitcher.Stitch(sourceImages.ToArray());
                    Bitmap bm = result.ToBitmap();
                    bm.Save(fl1 + ""resul.jpeg"", ImageFormat.Jpeg);
                }
            }
            finally
            {

            }
</code></pre>

<h2>EMGU-3.1 documentation : stitch method contains new parameters like below</h2>

<pre><code>  //
        // Summary:
        //     Compute the panoramic images given the images
        //
        // Parameters:
        //   images:
        //     The input images. This can be, for example, a VectorOfMat
        //
        //   pano:
        //     The panoramic image
        //
        // Returns:
        //     true if successful
        public bool Stitch(IInputArray images, IOutputArray pano);
</code></pre>

<p>How to pass this two parameters in my existing code and what is this parameters for?</p>

<p>Please I am pretty new to EMGU</p>
",,2017-12-13 11:57:07,C# EMGU 3.1 Image stitching method parameters,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
45762,38913645,2016-08-12 08:43:00,,"<p>I make screenshot of a window in a infinite loop
it works good.
But I hope it can be improved.
When i run my project, it has a litter delay to copy ""Myscreen"" from ""PictureBox"".</p>

<p>Anyone have a idea?
Or did you know any other solutions?</p>

<p>I just want to get Screen's BITMAP constantly.(faster..)</p>

<p>Below source is screen capture function.</p>

<pre><code>public static Bitmap ScreenCapture_B(System.Windows.Forms.Screen MyScreen)
    {

        try
        {
            Rectangle rect = MyScreen.Bounds;
            // 2nd screen = Screen.AllScreens[1]
            int bitsPerPixel = MyScreen.BitsPerPixel;
            PixelFormat pixelFormat = PixelFormat.Format32bppArgb;
            if (bitsPerPixel &lt;= 16)
            {
                pixelFormat = PixelFormat.Format16bppRgb565;
            }
            if (bitsPerPixel == 24)
            {
                pixelFormat = PixelFormat.Format24bppRgb;
            }
            else
            {
                pixelFormat = PixelFormat.Format24bppRgb;
            }
            Bitmap bmp = new Bitmap(rect.Width, rect.Height, pixelFormat);
            using (Graphics gr = Graphics.FromImage(bmp))
            {
                // 화면을 그대로 카피해서 Bitmap 메모리에 저장
                gr.CopyFromScreen(rect.Left, rect.Top, 0, 0, rect.Size);
            }
            return bmp;
        }
        catch(Exception)
        {
            throw;
        }
    }
</code></pre>

<p>Bellow source is Thread.</p>

<pre><code>public void ThreadLoop()
    {
        try
        {
            //infinite loop
            while (true)
            {
                bm = null;
                Screen MyScreen = Screen.PrimaryScreen;
                bm = ScreenCapture_B(MyScreen);
                setImage(bm, pictureEdit1);                    
                Bitmap btimage = new Bitmap(pictureEdit1.Image);
                ProcessImage_new(btimage);
            }

        }
        catch (Exception ex)
        {
            throw;
        }
    }
</code></pre>
",2016-08-12 09:05:15,2016-08-12 09:05:15,c# Capturing and taking a screenshot of a window in a infinite loop,<c#><screenshot><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
45834,39184895,2016-08-27 19:23:39,,"<p>Please help me understand how to interpret histograms and calculate bins to be put in generating histograms. First of all, I am still a student and I am confused on the things I have read from my research. I have read that to calculate a bin, you need  to know the range of the data(dataset?). My problem is that I do not know how to get the data and the range of data in my image. </p>

<p><strong>The DenseHistogram asks for these parameters....</strong></p>

<pre><code>DenseHistogram x = new DenseHistogram(int binSize, RangeF range);
</code></pre>

<p><strong>My code is below</strong> and I just copied this from another person here so I can try it and I really want to understand <strong>how he got 256 for binSize and 0-256 for range</strong></p>

<pre><code>DenseHistogram hist = new DenseHistogram(256, new RangeF(0, 256)); 
</code></pre>

<p>and</p>

<p>my problem here Ma'am/Sir, is that my histogram looks different from other histograms I have seen on the internet and, again, the binSize.
the histogram looks like <a href=""http://i.stack.imgur.com/gCAtT.png"" rel=""nofollow"">click here to view histogram</a> and this is the image used for <strong>generateHistograms</strong> <a href=""http://i.stack.imgur.com/r6Xoa.jpg"" rel=""nofollow"">click here to view image</a> , it is different from others and I have noticed that if I changed the number of bins, the lines also change. This is why I want to know how many bins I should put in....</p>

<pre><code>histogramBox.generateHistograms(IImage image, int numberOfBins);
</code></pre>

<p><strong>Please help me understand and can you please explain why the histogram looked like that?</strong> <strong>THANK YOU SO MUCH FOR YOUR HELP!!!</strong></p>
",,2016-08-27 19:23:39,how to calculate bins for densehistogram and for histogrambox.generateHistogram in c#?,<c#><image-processing><visual-studio-2015><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
45884,39189169,2016-08-28 08:01:01,,"<p>I have been trying to stitch images using the sample program, but it continually runs out of memory .</p>

<p>There appears to be a successful fix for this by turning off the ""wave correction"". While this can apparently be easily done in openCV, I cannot figure out how to do it in EMGU C#.</p>

<p>below is my snippet C#.</p>

<pre><code>// Collect all images
            List&lt;Image&lt;Bgr, Byte&gt;&gt; sourceImages = new List&lt;Image&lt;Bgr, Byte&gt;&gt;(); 

            for (int i = 1; i &lt;7 ; i++)
            {
                string fileN = fl1 + ""n ("" + i.ToString() + "").jpg"";
                sourceImages.Add(new Image&lt;Bgr, Byte&gt;(fileN));
            }

            try
            {
                using (Stitcher stitcher = new Stitcher(false))
                {
                    // Stitch images
                    Image&lt;Bgr, Byte&gt; result = stitcher.Stitch(sourceImages.ToArray());
                    Bitmap bm = result.ToBitmap();
                    bm.Save(fl1 + ""resul.jpeg"", ImageFormat.Jpeg);
                }
            }
            finally
            {

            }
</code></pre>

<p>Answer any version  2.4 or 3.1 is welcome</p>
",,2018-11-20 10:16:36,C# Emgucv2.4 or 3.1 disable the stitching wave correction,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
45891,38926673,2016-08-12 21:26:17,,"<p>I'm programming by WPF(c#) for image processing (in emgu cv). In my application, I open a image using these codes:</p>

<pre><code>OpenFileDialog d = new OpenFileDialog();

if(d.ShowDialog() == true)
{
    Bitmap b = new Bitmap(d.FileName);
    img1.Source = Util.Convert(b);
}
</code></pre>

<p>I use codes below to convert <code>Bitmap</code> to <code>ImageSource</code> and vice versa:</p>

<pre><code>public static Bitmap ImageSourceToBitmap(ImageSource imageSource)
{
    BitmapSource bitmapSource = (BitmapSource)imageSource;

    MemoryStream mse = new MemoryStream();
    BmpBitmapEncoder encoder = new BmpBitmapEncoder();
    encoder.Frames.Add(BitmapFrame.Create(bitmapSource));
    encoder.Save(mse);

    System.Drawing.Bitmap bitmap = new System.Drawing.Bitmap(mse);

    return bitmap;
}

public static BitmapImage Convert(Bitmap src)
{
    MemoryStream ms = new MemoryStream();
    ((System.Drawing.Bitmap)src).Save(ms, System.Drawing.Imaging.ImageFormat.Png);

    BitmapImage image = new BitmapImage();
    image.BeginInit();
    ms.Seek(0, SeekOrigin.Begin);
    image.StreamSource = ms;
    image.EndInit();
    return image;
}
</code></pre>

<p>Size of image will be changed (a strange behavior is occurred on my conversion) when i use it from a button. the code event of button is:</p>

<pre><code>Image&lt;Gray, byte&gt; im = new Image&lt;Gray, byte&gt;(Util.ImageSourceToBitmap(img1.Source));
im._EqualizeHist();

img1.Source = Util.Convert(im.Bitmap);
</code></pre>

<p>I also set <code>stretch = None</code>. </p>

<p>what is the problem?</p>
",,2016-09-29 19:09:35,Unwanted Image Resizing in Bitmap to ImageSource,<image><bitmap><size><emgucv><imagesource>,,,CC BY-SA 3.0,False,False,True,False,False
45936,39112074,2016-08-23 23:11:37,,"<p>Config:
Windows 10, Visual Studio 2015, Project is Windows Forms, VB, with EmguCV's OpenCV wrappers.</p>

<p>My project has a reference to <em>emgu.cv.world</em></p>

<p>My code is pretty simple (VB):</p>

<pre><code>Imports Emgu.CV

Class Form1
    Public gStop As Boolean
    Async Function DoStuff() As Task
        Dim cap As New Capture
        Do While gStop = False
            cap.QueryFrame()
        Loop
    End Function
End Class 
</code></pre>

<p>When I run DoStuff in the debugger, memory is consumed up to 2GB, then:</p>

<p><em>Exception thrown: 'Emgu.CV.Util.CvException' in Emgu.CV.World.dll</em></p>

<p><a href=""http://i.stack.imgur.com/Sb9qA.png"" rel=""nofollow"">Graph of Memory Leak</a></p>

<p>Am I right in thinking this clearly demonstrates a memory leak? My initial code did a bit more with the captured video than the above code does but I pared it down to try to isolate the leak. All the above code does now is retrieve a frame from the webcam and discard it, indefinitely. It puzzles me because this is really basic functionality for Emgu so I don't understand why it hasn't already been fixed and wonder if I've got something wrong somewhere. I haven't coded since VB6: used to know my onions but less so now. </p>
",,2016-08-23 23:11:37,Does Emgu.CV.Capture.QueryFrame leak memory?,<vb.net><opencv><memory-leaks><visual-studio-2015><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
45977,39116108,2016-08-24 06:40:57,,"<p>I want to know the methods needed to process an image for the best results, before giving it to OCR. Also, what character set should be provided to get the best result. Currently, I am working on an Xamarin Android App. </p>

<p>Below is my image processing code. </p>

<pre><code> CvInvoke.CvtColor(img, img, ColorConversion.Bgr2Gray);
 //CvInvoke.Canny(gray, canny, 100, 50, 3, false);
 Size s = new Size(3, 3);
 CvInvoke.GaussianBlur(img, img, s, 0, 0, BorderType.Default);
 //CvInvoke.FastNlMeansDenoising(img, img, 3, 7, 21);
 CvInvoke.AdaptiveThreshold(img, img, 255, AdaptiveThresholdType.MeanC, Emgu.CV.CvEnum.ThresholdType.Binary, 5, 4);
 CvInvoke.Threshold(img, img, 0, 255,  Emgu.CV.CvEnum.ThresholdType.Otsu);
</code></pre>

<p>I am using the EmguCv library for processing, as well as Tesseract. </p>

<p>Below is my white listed character set.</p>

<pre><code>_ocr.SetVariable(""tessedit_char_whitelist"", 
    ""ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-1234567890 :$/.?,!@#%^&amp;*()_+=\'\"";{}[]+"");
</code></pre>

<p>I want to scan receipt and I am very new to this concept. Please let me know your thoughts.</p>
",2016-08-24 14:35:55,2016-08-24 14:35:55,Pre-processing image using opencv for tesseract,<opencv><xamarin><xamarin.android><ocr><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
45989,39037628,2016-08-19 11:12:10,,"<blockquote>
  <p>Attempted to read or write protected memory. This is often an
  indication that other memory is corrupt.</p>
</blockquote>

<p>This was the error after I set the Image to my PictureBox. Its working fine but later on the error just pop-out.</p>

<p>Here is my code.</p>

<pre><code>Private Sub Timer1_Tick(sender As Object, e As EventArgs) Handles Timer1.Tick
    Try
        Dim cap As New Capture() 'first line

        PictureBox1.Image = cap.QueryFrame.ToBitmap 'this line AccessViolationException
    Catch ex As Exception
        Timer1.Stop()
        MsgBox(""CAMERA ERROR "" &amp; ex.Message)
    End Try
End Sub

Private Sub MetroTile1_Click(sender As Object, e As EventArgs) Handles MetroTile1.Click
        Try
            Dim cap As New Capture() 'first line
            Select Case MetroTile1.Text
                Case ""Capture""
                    Timer1.Start()
                    MetroTile1.Text = ""OK""
                Case ""OK""
                    Timer1.Stop()
                    frmStudentAddEdit.picImage.Image = PictureBox1.Image
                    MetroTile1.Text = ""Capture""
                    Me.Close()
            End Select
        Catch ex As Exception
            Timer1.Stop()
        End Try
    End Sub
</code></pre>

<p>The <code>cap.QueryFrame.ToBitmap</code> is the <strong>AccessViolationException was unhandled</strong> error.</p>

<p><strong>How can I Fix this ? What causing this error ? Please Help.</strong></p>
",,2016-08-20 02:55:33,AccessViolationException was unhandled [VB.Net] [Emgucv],<vb.net><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
46005,39040073,2016-08-19 13:17:18,,"<p>i just dont know what to do within this method LoadFaceRecognition, 
this method load the training images smoothly when it have less than 800 training images but as soon as I add  images the loading of data stops executing and memory consumption expands. Please help me with this </p>

<p>training imgaes are the Grayscale images </p>

<p>this is LoadFaceRecognition, </p>

<pre><code>private bool LoadFaceRecognition(string Training_Folder, string TrainedFaces) { 

  if (File.Exists(Training_Folder + TrainedFaces + ""/TrainedLabels.xml""))
    {
        try
        {
            Names_List_Faces.Clear();
            trainingImages_Faces.Clear();
            FileStream filestream = File.OpenRead(Training_Folder + TrainedFaces + ""/TrainedLabels.xml"");

            long filelength = filestream.Length;
            byte[] xmlBytes = new byte[filelength];
            filestream.Read(xmlBytes, 0, (int)filelength);
            filestream.Close();

            MemoryStream xmlStream = new MemoryStream(xmlBytes);
            XmlReader xmlreader = XmlTextReader.Create(xmlStream);

            while (xmlreader.Read())
            {
                if (xmlreader.IsStartElement())
                {
                    switch (xmlreader.Name)
                    {
                        case ""NAME"":
                            if (xmlreader.Read())
                            {
                                //Names_List_ID.Add(Names_List.Count); //0, 1, 2, 3....
                                Names_List_Faces.Add(xmlreader.Value.Trim());
                                NumLabels_Faces += 1;
                            }
                            break;
                        case ""FILE"":
                            if (xmlreader.Read())
                            {
                                //PROBLEM HERE IF TRAININGG MOVED
                                trainingImages_Faces.Add(new Image&lt;Gray, byte&gt;(Training_Folder + ""/TrainedFaces//"" + xmlreader.Value.Trim()));

                            }
                            break;
                    }
                }
            }
            ContTrain_Faces = NumLabels_Faces;
            if (trainingImages_Faces.ToArray().Length != 0)
            {
                recognizer_Faces = new EORecognizer(trainingImages_Faces.ToArray(), Names_List_Faces.ToArray(), Eigen_Threshold, ref termCrit_Faces);
                return true;

            }
            else return false;
        }
        catch (Exception ex)
        {
            Error = ex.ToString();
            return false;
        }
    }
    else return false;
}
</code></pre>
",,2016-08-19 14:47:12,Emgu CV memory leaks on loading more than 1000 training images,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
46026,38966525,2016-08-16 04:09:10,,"<p>Hello when i run this code to c# with emgucv to see a live ip camera in a picturebox it show me an error
in this part:</p>

<pre><code>Mat frame = new Mat();
_capture.Retrieve(frame, 0);
captureImageBox.Image = frame;
</code></pre>

<p>the error mentions</p>

<blockquote>
  <p>Cannot convert a type emgu.cv.mat in emgu.cv.imag...</p>
</blockquote>

<p>What lines of code do i need to change to run it correctly....</p>

<p><strong>Specs</strong></p>

<ul>
<li>Visual studio 2015 <br></li>
<li><p>emgucv v3.1 x64</p>

<pre><code>public partial class Form1 : Form
{
private Capture _capture = null;
private bool _captureInProgress;
public Form1()
{
    InitializeComponent();
    CvInvoke.UseOpenCL = false;
    try
    {
        _capture = new Capture(""http://webcam.st-malo.com/axis-cgi/mjpg/video.cgi?"");
        _capture.ImageGrabbed += ProcessFrame;
    }
    catch (NullReferenceException excpt)
    {
        MessageBox.Show(excpt.Message);
    }
}

private void ProcessFrame(object sender, EventArgs arg)
{
    Mat frame = new Mat();
    _capture.Retrieve(frame, 0);

    captureImageBox.Image = frame;

}

private void captureButton_Click(object sender, EventArgs e)
{
    if (_capture != null)
    {
        if (_captureInProgress)
        {  //stop the capture
            captureButton.Text = ""Start Capture"";
            _capture.Pause();
        }
        else
        {
            //start the capture
            captureButton.Text = ""Stop"";
            _capture.Start();
        }

        _captureInProgress = !_captureInProgress;
    }
}
</code></pre>

<p>}</p></li>
</ul>
",2016-08-16 05:02:23,2017-07-20 09:25:15,stream camera ip emgucv,<c#><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
46030,39259090,2016-08-31 21:12:50,,"<p>I assume my camera calibration, performed with EmguCV library, is successful because I can apply the calibration to images and they appear to be at least somewhat corrected.  Now I want to store the calibration to disk so I can simply load it when my program runs.  IntrinsicCameraParameters has methods called writeXML() and readXML() that take XmlWriter and XmlReader as arguments, respectively.  Seems like the way to go.  I found an example where someone just instantiated a default XmlWriter and immediately used it to call WriteXml().  But when I try this I get runtime exceptions that seem to be related to the structure of the XML (i.e. only able to have one root node in the XML).  So I have adjusted the code and shared it below.  If I don't include the stupid root element then the call to ""WriteXml"" throws the exception about improperly formed XML.  So I seem to be able to write it, but I don't know how to read it back.  Perhaps the stupid root element prevents the read from succeeding.  Can't find any examples of anyone reading it back.  Does any one have an example to share?</p>

<pre><code>public void SaveCalibrationToFile(IntrinsicCameraParameters ICP)
        {
            XmlWriterSettings settings = new XmlWriterSettings();
            settings.ConformanceLevel = ConformanceLevel.Auto;

            // DISTORTION COEFFICIENTS
            XmlWriter writer = XmlWriter.Create(""C:\\Video\\Cal\\DistortionCoeff.xml"", settings);               
            writer.WriteStartDocument();
            writer.WriteStartElement(""TheStupidRootElement"");

                writer.WriteStartElement(""TheDistortionCoefficients"");
                ICP.DistortionCoeffs.WriteXml(writer);
                writer.WriteEndElement(); // end TheDistortionCoefficients

            writer.WriteEndElement(); // end TheStupidRootElement
            writer.WriteEndDocument();
            writer.Close();

            // CAMERA MATRIX
            writer = XmlWriter.Create(""C:\\Video\\Cal\\CameraMatrix.xml"", settings);                
            writer.WriteStartDocument();
            writer.WriteStartElement(""TheStupidRootElement"");

                writer.WriteStartElement(""TheCameraMatrix"");
                ICP.IntrinsicMatrix.WriteXml(writer);
                writer.WriteEndElement(); // end TheCameraMatrix

            writer.WriteEndElement(); // end TheStupidRootElement
            writer.WriteEndDocument();
            writer.Close();

            // now [just to see if it worked] try to load from the XML
            XmlReaderSettings readerSettings = new XmlReaderSettings();
            readerSettings.ConformanceLevel = ConformanceLevel.Auto;
            XmlReader reader = XmlReader.Create(""C:\\Video\\Cal\\DistortionCoeff.xml"", readerSettings);

            IntrinsicCameraParameters ICP_read = new IntrinsicCameraParameters();
            IC.DistortionCoeffs.ReadXml(reader);                
        }
</code></pre>
",,2016-09-02 02:04:56,How to store/load IntrinsicCameraParameters with XML,<c#><xml><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
46038,39160848,2016-08-26 07:36:03,,"<p>Hello I want to extract text-blocks from images and pass it to ocr for better accuracy. I have been searching on internet but not able to find suitable example for this. I am very new to this concept can anyone please help me out on the same?</p>

<p><a href=""https://i.stack.imgur.com/purxx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/purxx.png"" alt=""enter image description here""></a> </p>

<p><a href=""https://i.stack.imgur.com/UX8NQ.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UX8NQ.jpg"" alt=""enter image description here""></a></p>

<p>This is what I want to achieve. 
Note I am using EMGUCV for opencv and ocr. 
I want to scan receipt mostly.
If you can help with that it would be great. </p>
",2016-08-26 07:52:41,2016-08-26 09:16:26,Detecting text blocks in images using opencv c#,<c#><opencv><image-processing><xamarin><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
46045,39229810,2016-08-30 14:09:19,,"<p>I'm working on a project using EmguCV which requires capturing images from a camera and processing them, looking for certain things in the image. The processing takes up about ~.2 seconds, and is the biggest time-sink in the application so we're looking into making the capturing/processing different threads to speed up the overall process. </p>

<p>We've already tried the VideoCapture.ImageGrabbed event handler, and calling Retrieve, as well as setting up a threaded loop of our own calling QueryFrame and any other capturing method we can find. </p>

<p>Most of the threaded solutions end up causing empty images (not caught by the .IsEmpty property of the Mat, though, for some reason), which end up as images saved with 0 bytes. </p>

<p>After this, we tried simplifying but ran into an issue where the camera is always a few seconds behind, due to the buffer internal to the library. This leads to my question: is there a way to refresh the buffer, or clear it of memory? We cannot dispose of the capture object because of the time overhead for creating the object. Any tips about threading the capturing and processing are welcome as well, though the other suggestions I've found around this site about similar situations have not led to much success. </p>

<p>A brief example of the code we're using</p>

<pre><code>_capture.ImageGrabbed += GrabFrames;
...
public void GrabFrames()
{
    Mat image = new Mat();
    _capture.Retrieve(image);
    ProcessThread = new Thread(new ParameterizedThreadStart(StartProcess));
    ProcessThread.Start(image);
}
...
public void StartProcess(object image)
{
    Mat img = (Mat)image;
    Process(image);
    img.Dispose();
}
</code></pre>
",,2016-08-30 14:09:19,Clearing EmguCV's image buffer,<c#><multithreading><emgucv><raspberry-pi3>,,,CC BY-SA 3.0,False,True,True,False,False
46046,39230089,2016-08-30 14:21:03,,"<p>So I've got a main class which gets the frames from my webcam and multiple threads that process the frames. I've locked the part of the main class that grabs the frame from the cam, so only one thread can process the same frame. Now I'm getting an External exception and I do not know why.
My main class:</p>

<pre><code>public Image&lt;Bgr, byte&gt; GetImage()
{
    Image&lt;Bgr, byte&gt; returnable;
    Mat f = null;
    lock (locker)
    {
       do
       {
            f = capture.QueryFrame();
        } while (!capture.Grab());
        returnable = f.ToImage&lt;Bgr, byte&gt;();
    }
    return returnable;
}
</code></pre>

<p>My thread:</p>

<pre><code>Image&lt;Bgr,byte&gt; image;
image = o.GetImage(); //o is the main class
Image imag = image.ToBitmap();
string savePath = path + rofNumber + ""/Original.jpg"";
imag.Save(savePath); //Exception is on this line
toFind = o.GetNumbersFromDatabase();
labels = FindLabels(image);
</code></pre>

<p>The Exception:</p>

<pre><code>System.Runtime.InteropServices.ExternalException was unhandled
ErrorCode=-2147467259
HResult=-2147467259
Message=Er is een algemene fout opgetreden in GDI+.
Source=System.Drawing
StackTrace:
   bij System.Drawing.Image.Save(String filename, ImageCodecInfo encoder,    EncoderParameters encoderParams)
   bij OCR.Worker.Run() in C:\Users\...\Code\Visual Studio\OCR\OCR\Worker.cs:regel 178
   bij System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
   bij System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
   bij System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)
   bij System.Threading.ThreadHelper.ThreadStart()
InnerException: 
</code></pre>
",,2016-08-31 12:09:25,Trying to get multiple threads to get frames with capture.QueryFrame(),<c#><multithreading><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
46082,39044886,2016-08-19 17:40:01,,"<p>I am having some issues extracting a blob from an image using EmguCV.  Everything I see online uses the Contours object, but I guess that was removed from EmguCV3.0?  I get an exception every time I try to use it.  I haven't found many recent/relevant SO topics that aren't out of date.</p>

<p>Basically, I have a picture of a leaf.  The background might be white, green, black, etc.  I want to essentially remove the background so that I can perform operations on the leaf without interference with the background.  I'm just not sure where I'm going wrong here:</p>

<p><a href=""https://i.stack.imgur.com/rXoxE.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rXoxE.jpg"" alt=""enter image description here""></a></p>

<pre><code>        Image&lt;Bgr, Byte&gt; Original = Core.CurrentLeaf.GetImageBGR;
        Image&lt;Gray, Byte&gt; imgBinary = Original.Convert&lt;Gray, Byte&gt;();
        imgBinary.PyrDown().PyrUp(); // Smoothen a little bit
        imgBinary = imgBinary.ThresholdBinaryInv(new Gray(100), new Gray(255)); // Apply inverse suppression

        // Now, copy pixels from original image that are black in the mask, to a new Mat.  Then scan?
        Image&lt;Gray, Byte&gt; imgMask;
        imgMask = imgBinary.Copy(imgBinary);
        CvInvoke.cvCopy(Original, imgMask, imgBinary);

        VectorOfVectorOfPoint contoursDetected = new VectorOfVectorOfPoint();
        CvInvoke.FindContours(imgBinary, contoursDetected, null, Emgu.CV.CvEnum.RetrType.List, Emgu.CV.CvEnum.ChainApproxMethod.ChainApproxSimple);

        var contoursArray = new List&lt;VectorOfPoint&gt;();
        int count = contoursDetected.Size;
        for (int i = 0; i &lt; count; i++)
        {
            using (VectorOfPoint currContour = contoursDetected[i])
            {
                contoursArray.Add(currContour);
            }
        }
</code></pre>

<p>With this, I get a black image with a tiny bit of white lines.  I've racked my brain back and forth and haven't been able to come up with something.  Any pointers would be much appreciated!</p>
",,2016-08-20 19:00:06,Finding largest blob in image,<opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
46091,39010270,2016-08-18 04:56:39,,"<p>I'm programming in WPF(C#) using emgucv-windesktop 3.1.0.2282. I'm new in image processing and I want to use FFT and DFT in my image processing application. here is my code:</p>

<pre><code>Image&lt;Gray, System.Single&gt; _image = new Image&lt;Gray, System.Single&gt;(
    Util.ImageSourceToBitmap(img1.Source));

UMat DFTimage = new UMat();
UMat Original = new UMat();

CvInvoke.Dft(_image.ToUMat(), DFTimage, Emgu.CV.CvEnum.DxtType.Forward , -1);
CvInvoke.Dft(DFTimage, Original, Emgu.CV.CvEnum.DxtType.Inverse, -1);

img2.Source = Util.BitmapToImageSource(Original.Bitmap);
img3.Source = Util.BitmapToImageSource(DFTimage.Bitmap);
</code></pre>

<p>I used a human face, flower, etc but what I see in img2 and img3 (they are Image controls) is black and empty images. What is wrong in my code?</p>

<p><strong>UPDATE 1:</strong></p>

<p>Now I'm using this code:</p>

<pre><code>Bitmap bm = Util.ImageSourceToBitmap(img1.Source);

Image&lt;Gray, Single&gt; image = new Image&lt;Gray, Single&gt;(bm);
UMat DFTimage = new UMat(image.Size, Emgu.CV.CvEnum.DepthType.Cv32F, 2);
UMat Original = new UMat(image.Size, Emgu.CV.CvEnum.DepthType.Cv32F, 2);


CvInvoke.Dft(image, DFTimage, Emgu.CV.CvEnum.DxtType.Forward, image.Rows);
CvInvoke.Dft(Original, DFTimage, Emgu.CV.CvEnum.DxtType.Inverse, image.Rows);


Util.BitmapToImageSource(Original.Bitmap);
</code></pre>

<p>Now I get <code>System.Exception</code> exception in showing my inverse image:</p>

<blockquote>
  <p>An unhandled exception of type 'System.Exception' occurred in
  Emgu.CV.World.dll</p>
  
  <p>Additional information: Unknown color type</p>
</blockquote>

<p><a href=""https://i.stack.imgur.com/OuzDG.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OuzDG.jpg"" alt=""enter image description here""></a> </p>
",2016-08-19 05:33:46,2018-03-22 06:19:07,DFT in EmguCV not showing,<c#><wpf><image-processing><emgucv><dft>,,,CC BY-SA 3.0,False,False,True,False,False
46112,39301573,2016-09-02 22:47:09,,"<p>I can create a Mat object in EmguCV from a unmanaged buffer, either pinned in managed memory of created with AllocHGlobal.</p>

<p>How do I create a GpuMat, or similar object, using memory allocated on the device either by device pointer or a Cuda array.</p>
",2016-09-27 10:41:23,2016-09-27 10:41:23,Creating a OpenCV/EmguCV GpuMat from a Cuda device pointer,<opencv><cuda><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
46113,39301750,2016-09-02 23:12:13,,"<p>I am using EmguCV's CascadeClassifier to detect faces in an image using DetectMultiScale, and while detecting the first image takes a while (around 3-5 seconds), the subsequent images only take about 0.3-0.7 seconds. I initialized the classifier on load to see if that changed anything but it didn't seem to make a difference.</p>

<p>Is there any way I could speed up the time of the the first image?</p>
",,2018-01-17 08:16:47,"EmguCV cascade classifier slow at first, then fast",<c#><opencv><emgucv><face-detection>,,,CC BY-SA 3.0,True,False,True,False,False
46117,39236682,2016-08-30 20:37:12,,"<p>I'm using VS2015, EmguCV 3 and VB, and am trying to translate some C++ code.</p>

<p><strong>C++</strong></p>

<pre><code>vector&lt;vector&lt;Point&gt; &gt; contours;
vector&lt;Vec4i&gt; hierarchy;
findContours(bw, contours, hierarchy, CV_RETR_LIST, CV_CHAIN_APPROX_NONE);
for (size_t i = 0; i &lt; contours.size(); ++i)
{...}
</code></pre>

<p>I'm trying to use some object orientation code given in full <a href=""https://robospace.wordpress.com/2013/10/09/object-orientation-principal-component-analysis-opencv/"" rel=""nofollow"">here</a>. Basically the code is going to tell me the angle at which an object is oriented in an image. Unfortunately it is C++ code and VB developers' brains can explode at the sight of some C++ syntax. Any help avoiding the need to clean my screen again would be welcome. The explosive material was <code>vector&lt;vector&lt;point&gt; &gt; contours;</code> in this particular case, and my question is about how to translate it.</p>

<p>I got this far:</p>

<p><strong>VB</strong></p>

<pre><code>Imports Emgu.CV
Imports Emgu.CV.Structure
...
contours = New Mat
hierarchy = New Mat
CvInvoke.FindContours(m, contours, hierarchy, CvEnum.RetrType.List, CvEnum.ChainApproxMethod.ChainApproxNone)
</code></pre>

<p>I'm using EmguCV 3. This claims that <code>FindContours</code> takes <code>image As IInputOutputArray, contours As IOutputArray, hierarchy As IOutputArray</code>. So I figured I could provide three Mats. m is defined earlier has been successfully processed (e.g. with Threshold) so I'm happy with m. contours and hierarchy on the other hand may be problematic. When I run the code, I get an unhandled exception:</p>

<blockquote>
  <p><a href=""http://i.stack.imgur.com/0W7wy.png"" rel=""nofollow"">Emgu.CV.Util.CvException: OpenCV: (_contours.kind() == _InputArray::STD_VECTOR_VECTOR || _contours.kind() == _InputArray::STD_VECTOR_MAT || _contours.kind() == _InputArray::STD_VECTOR_UMAT)</a></p>
</blockquote>

<p>This seems to suggest I've passed the wrong types to OpenCV although I would have expected Emgu to handle that. But I have no clue. Any help?</p>
",2016-08-30 21:22:38,2016-08-30 21:40:48,Using OpenCV Mat as an Array: VB vs C++,<c++><vb.net><opencv><emgucv><mat>,,,CC BY-SA 3.0,True,True,True,False,False
46140,39127579,2016-08-24 15:36:39,,"<p>I am suing SURF algorithm, to find the similarity between a query image and a collection image that stored in a database. For better performance, I used Fast Approximate Nearest Neighbor (FLANN).
Now, I want divide this work into two steps:</p>

<p>First step:
Compute the descriptors for all images in the database, then combine all the descriptors into a big matrix, finally build FLANN.</p>

<p>Second step:
Compute the descriptors for the query image and using FLANN index to find matching between the query descriptor and all of the collection descriptors.</p>

<p>Who can help me?</p>

<p><strong>FLANN.cs</strong></p>

<pre><code>using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.IO;
using System.Windows.Forms;
using System.Diagnostics;
using System.Drawing;

using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Features2D;
using Emgu.CV.Structure;
using Emgu.CV.Util;
using Emgu.CV.GPU;
using Emgu.CV.Flann;

namespace flannconsole
{

class FLANN
{

    private static double surfHessianThresh = 300;
    private static bool surfExtendedFlag = true;
    private static SURFDetector detector = new      SURFDetector(surfHessianThresh, surfExtendedFlag);


    public class IndecesMapping
    {
        public int IndexStart { get; set; }
        public int IndexEnd { get; set; }
        public int Similarity { get; set; }
        public string fileName { get; set; }

        public override string ToString()
        {
            return fileName + "": "" + Similarity + ""%"";
        }
    }


    public static IList&lt;IndecesMapping&gt; Match(string[] dbImages, string queryImage)
    {
        IList&lt;IndecesMapping&gt; imap;

        // compute descriptors for each image
        var dbDescsList = ComputeMultipleDescriptors(dbImages, out imap);

        // concatenate all DB images descriptors into single Matrix
        Matrix&lt;float&gt; dbDescs = ConcatDescriptors(dbDescsList);

        // compute descriptors for the query image
        Matrix&lt;float&gt; queryDescriptors = ComputeSingleDescriptors(queryImage);

        FindMatches(dbDescs, queryDescriptors, ref imap);

        return imap;
    }


    public static Matrix&lt;float&gt; ComputeSingleDescriptors(string fileName)
    {
        Matrix&lt;float&gt; descs;

        using (Image&lt;Gray, Byte&gt; img = new Image&lt;Gray, Byte&gt;(fileName))
        {
            VectorOfKeyPoint keyPoints = detector.DetectKeyPointsRaw(img, null);
            descs = detector.ComputeDescriptorsRaw(img, null, keyPoints);
        }

        return descs;
    }


    public static IList&lt;Matrix&lt;float&gt;&gt; ComputeMultipleDescriptors(string[] fileNames, out IList&lt;IndecesMapping&gt; imap)
    {
        imap = new List&lt;IndecesMapping&gt;();

        IList&lt;Matrix&lt;float&gt;&gt; descs = new List&lt;Matrix&lt;float&gt;&gt;();

        int r = 0;

        for (int i = 0; i &lt; fileNames.Length; i++)
        {
            var desc = ComputeSingleDescriptors(fileNames[i]);
            descs.Add(desc);

            imap.Add(new IndecesMapping()
            {
                fileName = fileNames[i],
                IndexStart = r,
                IndexEnd = r + desc.Rows - 1
            });

            r += desc.Rows;
        }

        return descs;
    }


    public static void FindMatches(Matrix&lt;float&gt; dbDescriptors, Matrix&lt;float&gt; queryDescriptors, ref IList&lt;IndecesMapping&gt; imap)
    {
        var indices = new Matrix&lt;int&gt;(queryDescriptors.Rows, 2);
        var dists = new Matrix&lt;float&gt;(queryDescriptors.Rows, 2); 

        // create FLANN index with 4 kd-trees and perform KNN search over it look for 2 nearest neighbours
        var flannIndex = new Index(dbDescriptors, 4);
        flannIndex.KnnSearch(queryDescriptors, indices, dists, 2, 24);

        for (int i = 0; i &lt; indices.Rows; i++)
        {
            // filter out all inadequate pairs based on distance between pairs
            if (dists.Data[i, 0] &lt; (0.6 * dists.Data[i, 1]))
            {
                foreach (var img in imap)
                {
                    if (img.IndexStart &lt;= indices[i, 1] &amp;&amp; img.IndexEnd &gt;= indices[i, 1])
                    {
                        img.Similarity++;
                        break;
                    }
                }
            }
        }
    }



    public static Matrix&lt;float&gt; ConcatDescriptors(IList&lt;Matrix&lt;float&gt;&gt; descriptors)
    {
        int cols = descriptors[0].Cols;
        int rows = descriptors.Sum(a =&gt; a.Rows);

        float[,] concatedDescs = new float[rows, cols];

        int offset = 0;

        foreach (var descriptor in descriptors)
        {
            // append new descriptors
            Buffer.BlockCopy(descriptor.ManagedArray, 0, concatedDescs, offset, sizeof(float) * descriptor.ManagedArray.Length);
            offset += sizeof(float) * descriptor.ManagedArray.Length;
        }

        return new Matrix&lt;float&gt;(concatedDescs);
    }


}
}
</code></pre>

<p><strong>program.cs</strong></p>

<pre><code>using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.IO;
using System.Windows.Forms;
using System.Diagnostics;
using System.Drawing;

using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Features2D;
using Emgu.CV.Structure;
using Emgu.CV.Util;
using Emgu.CV.GPU;
using Emgu.CV.Flann;


namespace flannconsole
{
class Program
{
    static void Main(string[] args)
    {
        string[] dbImages = Directory.GetFiles(@""E:/nf/"");
        string queryImage = ""E://nf//01.jpg"";

        IList&lt;FLANN.IndecesMapping&gt; matches = FLANN.Match(dbImages, queryImage);

        foreach (FLANN.IndecesMapping match in matches)
        {
            Console.WriteLine(match.ToString());
        }

        Console.ReadLine();
    }


}
}
</code></pre>
",2017-01-02 00:16:57,2017-01-02 00:16:57,How to divide FLANN SURF into feature extraction and find similarity?,<c#><opencv><emgucv><surf><flann>,,,CC BY-SA 3.0,True,False,True,False,False
46191,39212152,2016-08-29 17:46:22,,"<p>How can I compute a DFT of an image with Emgu 3.0+ in visual basic?</p>

<p>I have some image I load in as a Mat with CvInvoke.Imread(), which I can display and alter, and I'd like to compute the forward DFT of this image, then display the magnitudes. How can I do this? I'm having trouble with inputting valid IInputArrays into CvInvoke.Dft(). My Emgu version is 3.1.0 at the moment.</p>

<p>Here's the code I'm currently using:</p>

<pre><code>    Dim imgOrig As Mat
    imgOrig = CvInvoke.Imread(ofd.FileName, LoadImageType.AnyColor)

    EmguImageBox.Image = imgOrig

    Dim imgGrayscale As New Mat()
    CvInvoke.CvtColor(imgOrig, imgGrayscale, ColorConversion.Bgr2Gray)

    EmguImageBox.Image = imgGrayscale

    Dim imgDFT As Mat
    imgDFT = New Mat(imgOrig.Rows, imgOrig.Cols, DepthType.Cv32F, 2)

    CvInvoke.Dft(imgGrayscale, imgDFT, DxtType.Forward, 0)

    EmguImageBox.Image = imgDFT
</code></pre>
",2016-08-29 21:40:06,2019-12-30 20:40:46,DFT of image in Emgu 3.0+,<vb.net><visual-studio><opencv><emgucv><dft>,,,CC BY-SA 3.0,True,True,True,False,False
46331,39439383,2016-09-11 18:35:44,,"<p>I'm trying to use <code>CvInvoke.cvConvertScale</code> to convert a Byte-depth <code>mat</code> into an Int32-depth <code>mat</code> in preparation for summing several frames together with <code>CvInvoke.Add</code>. The convert function requires a couple of <code>IntPtr</code> parameters.</p>

<p>I have my first image in a Byte-depth <code>mat</code> and I've initialised an Int32-depth <code>mat</code> ready to accept the result of the convert function.</p>

<p>But I simply cannot figure out how to pass these <code>mat</code> as parameters to the function. <code>cvarrToMat</code> always throws <code>Unknown Array Type</code>. I've tried the following approaches:</p>

<pre><code>'m is a mat with a Cv8U frame from a single channel video in it

Dim dataC(m.Cols * m.Rows) As Byte
Dim dataD(m.Cols * m.Rows) As Int32
Dim handleC As GCHandle = GCHandle.Alloc(dataC, GCHandleType.Pinned)
Dim handleD As GCHandle = GCHandle.Alloc(dataD, GCHandleType.Pinned)
Dim frametoaddC_Byte As New Mat(sizes:=New Integer() {m.Cols, m.Rows, m.NumberOfChannels}, type:=CvEnum.DepthType.Cv8U, data:=handleC.AddrOfPinnedObject)
Dim frametoaddD_Int32 As New Mat(sizes:=New Integer() {m.Cols, m.Rows, m.NumberOfChannels}, type:=CvEnum.DepthType.Cv32S, data:=handleD.AddrOfPinnedObject)

frametoaddC_Byte = vid.frame(i) 'Returns a mat of depth Cv8U from a video, same size as m, one channel.

'This doesn't work
CvInvoke.cvConvertScale(Marshal.GetIUnknownForObject(frametoaddC_Byte), Marshal.GetIUnknownForObject(frametoaddD_Int32), 1, 0)
'This doesn't work either
CvInvoke.cvConvertScale(handleC.AddrOfPinnedObject, handleD.AddrOfPinnedObject, 1, 0)
'And neither does this
CvInvoke.cvConvertScale(frametoaddC_Byte.Ptr, frametoaddD_Int32.Ptr, 1, 0)
'And finally, just in case, neither does this
CvInvoke.cvConvertScale(frametoaddC_Byte, frametoaddD_Int32, 1, 0)
</code></pre>

<p>(To my surprise those three <code>IntPtr</code> all have different values - quite widely different, actually. You'd think they'd all be close in memory but they're not. Anyway, never mind that.) </p>

<p>I've also tried replacing the Dims of the two frametoadds with this:</p>

<pre><code>Dim frametoaddC_Byte As New Mat(m.Rows, m.Cols, CvEnum.DepthType.Cv8U, 1)
Dim frametoaddD_Int32 As New Mat(m.Rows, m.Cols, CvEnum.DepthType.Cv32S, 1)
</code></pre>

<p>That would be the usual syntax rather than bothering with GCHandle.Alloc and was actually where I started. I only tried Alloc so I had the option of using AddrOfPinnedObject in my attempts to get a valid IntPtr. But to no avail.</p>

<p>All my attempts lead to the same error: <code>Unknown Array Type</code> in <code>cvarrToMat</code>. Samples seem thin on the ground. I'm using Emgu 3. Any ideas?</p>
",2016-09-11 21:36:50,2016-09-11 21:36:50,How to pass Emgu mat to Emgu function requiring IntPtr?,<vb.net><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
46432,39484274,2016-09-14 07:00:06,,"<p>I want to detect a display on an image (more precisely its corners).
I segment the image in display color and not display color:</p>

<pre><code>Image&lt;Gray, byte&gt; segmentedImage = greyImage.InRange(new Gray(180), new Gray(255));
</code></pre>

<p><a href=""https://i.stack.imgur.com/4mVnA.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4mVnA.jpg"" alt=""enter image description here""></a></p>

<p>Then I use corner Harris to find the corners:</p>

<pre><code>Emgu.CV.Image&lt;Emgu.CV.Structure.Gray, Byte&gt; harrisImage = new Image&lt;Emgu.CV.Structure.Gray, Byte&gt;(greyImage.Size);
CvInvoke.CornerHarris(segmentedImage, harrisImage, 2);
CvInvoke.Normalize(harrisImage, harrisImage, 0, 255, NormType.MinMax, DepthType.Cv32F);
</code></pre>

<p><a href=""https://i.stack.imgur.com/HAMZ3.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HAMZ3.jpg"" alt=""enter image description here""></a></p>

<p>There are now white pixels in the corners, but I cannot access them:</p>

<pre><code>for (int j = 0; j &lt; harrisImage.Rows; j++)
{
    for (int i = 0; i &lt; harrisImage.Cols; i++)
    {
        Console.WriteLine(harrisImage[j, i].Intensity);
    }
}
</code></pre>

<p>It writes only 0s. How can I access them? And if I can access them, how can I find the 4 corners of the screen in the harris image? Is there a function to find a perspectively transformed rectangle from points?</p>

<p>EDIT:<br>
On the OpenCV IRC they said FindContours is not that precise. And when I try to run it on the segmentedImage, I get this:
<a href=""https://i.stack.imgur.com/ydDHB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ydDHB.png"" alt=""enter image description here""></a>
(ran FindContours on the segmentedImage, then ApproxPolyDP and drew the found contour on the original greyscale image)<br>
I cannot get it to find the contours more precise...</p>

<p>EDIT2:
I cannot get this to work for me. Even with your code, I get the exact same result...
Here is my full Emgu code:</p>

<pre><code>Emgu.CV.Image&lt;Emgu.CV.Structure.Gray, Byte&gt; imageFrameGrey = new Image&lt;Emgu.CV.Structure.Gray, Byte&gt;(bitmap);
Image&lt;Gray, byte&gt; segmentedImage = imageFrameGrey.InRange(new Gray(180), new Gray(255));
// get rid of small objects
int morph_size = 2;
Mat element = CvInvoke.GetStructuringElement(Emgu.CV.CvEnum.ElementShape.Rectangle, new System.Drawing.Size(2 * morph_size + 1, 2 * morph_size + 1), new System.Drawing.Point(morph_size, morph_size));
CvInvoke.MorphologyEx(segmentedImage, segmentedImage, Emgu.CV.CvEnum.MorphOp.Open, element, new System.Drawing.Point(-1, -1), 1, Emgu.CV.CvEnum.BorderType.Default, new MCvScalar());

// Find edges that form rectangles
List&lt;RotatedRect&gt; boxList = new List&lt;RotatedRect&gt;();
using (VectorOfVectorOfPoint contours = new VectorOfVectorOfPoint())
{
    CvInvoke.FindContours(segmentedImage, contours, null, Emgu.CV.CvEnum.RetrType.External, ChainApproxMethod.ChainApproxSimple);
    int count = contours.Size;
    for (int i = 0; i &lt; count; i++)
    {
        using (VectorOfPoint contour = contours[i])
        using (VectorOfPoint approxContour = new VectorOfPoint())
        {
            CvInvoke.ApproxPolyDP(contour, approxContour, CvInvoke.ArcLength(contour, true) * 0.01, true);
            if (CvInvoke.ContourArea(approxContour, false) &gt; 10000)
            {
                if (approxContour.Size == 4)
                {
                    bool isRectangle = true;
                    System.Drawing.Point[] pts = approxContour.ToArray();
                    LineSegment2D[] edges = Emgu.CV.PointCollection.PolyLine(pts, true);
                    for (int j = 0; j &lt; edges.Length; j++)
                    {
                        double angle = Math.Abs(edges[(j + 1) % edges.Length].GetExteriorAngleDegree(edges[j]));
                        if (angle &lt; 80 || angle &gt; 100)
                        {
                            isRectangle = false;
                            break;
                        }
                    }

                    if (isRectangle)
                    boxList.Add(CvInvoke.MinAreaRect(approxContour));
                }
            }
        }
    }
}
</code></pre>
",2016-09-17 11:04:42,2016-09-18 13:17:32,Detect display corners with Emgu,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
46451,39371651,2016-09-07 13:46:09,,"<p>When I am trying to read image from file, then after load Mat.Data array is alway null. But when I am looking into Mat object during debug there is byte array in which are all data from image.</p>

<pre><code>Mat image1 = CvInvoke.Imread(""minion.bmp"", Emgu.CV.CvEnum.LoadImageType.AnyDepth);
</code></pre>

<p>Do you have any idea why?</p>
",2016-09-07 13:51:16,2017-07-05 15:25:01,EmguCV - Mat.Data array is always null after image loading,<opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
46500,39336747,2016-09-05 19:40:32,,"<p>When im running my application im getting this error ""EmguCV cvextern System.DllNotFoundException"". In desktop i must create the folders x86 and x64 and put the dll into then, but when im using Android (with Xamarin) what must i do?</p>

<p>PS: i'm using Demo license.</p>

<pre><code>System.TypeInitializationException: The type initializer for 'Emgu.CV.CvInvoke' threw an exception. ---&gt; System.DllNotFoundException: cvextern
  at (wrapper managed-to-native) Emgu.CV.CvInvoke:RedirectError (Emgu.CV.CvInvoke/CvErrorCallback,intptr,intptr)
  at Emgu.CV.CvInvoke..cctor () [0x0008c] in &lt;filename unknown&gt;:0 
  --- End of inner exception stack trace ---
  at Emgu.CV.Image`2[TColor,TDepth].AllocateData (Int32 rows, Int32 cols, Int32 numberOfChannels) [0x00013] in &lt;filename unknown&gt;:0 
  at Emgu.CV.Image`2[TColor,TDepth].set_Bitmap (Android.Graphics.Bitmap value) [0x0003a] in &lt;filename unknown&gt;:0 
  at Emgu.CV.Image`2[TColor,TDepth]..ctor (Android.Graphics.Bitmap bmp) [0x00006] in &lt;filename unknown&gt;:0 
  at EmguCVTeste.ImageProcessing.Process (Android.Graphics.Bitmap imageToProcess) [0x00002] in d:\TCC FUCKING SHIT\App2\App2\ImageProcessing.cs:28
</code></pre>
",2016-09-05 22:46:45,2016-09-05 22:46:45,EmguCV cvextern System.DllNotFoundException Android,<android><xamarin><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
46527,39340693,2016-09-06 04:31:42,,"<p>I am developing a face recognition application usin <strong><em>EmguCV 3.1</em></strong>. And I am using EigenFaceRecognizer as the recognition algorithm. I tried to train an image using the code below.</p>

<pre><code>    List&lt;Image&lt;Gray, byte&gt;&gt; trainingImages = new List&lt;Image&lt;Gray, byte&gt;&gt;();
    FaceRecognizer recognizer;
    List&lt;Face&gt; faceList = new List&lt;Face&gt;();
        ...
        ...
        recognizer = new EigenFaceRecognizer(80, double.PositiveInfinity);
        ...
        ...            
        Image&lt;Gray, byte&gt; image = new Image&lt;Gray, byte&gt;(imgBox2.DisplayedImage.Bitmap);
        trainingImages.Add(image);
        List&lt;int&gt; trainigLabels = new List&lt;int&gt;();
        recognizer.Train(trainingImages.ToArray(), trainigLabels.ToArray());
        recognizer.Save(""TraningData"");
        faceList.Add(new Face(image.Bytes.Length, txtName.Text));
        ...
        ...
        Image&lt;Gray, byte&gt; image = new Image&lt;Gray, byte&gt;(imgBox2.DisplayedImage.Bitmap);
            recognizer.Load(""TraningData"");
            try
            {
                var result = recognizer.Predict(image);
                MessageBox.Show(result.Label.ToString());
            }
            catch (Emgu.CV.Util.CvException ex)
            {
                Console.WriteLine(ex);
            }
</code></pre>

<p>But when this code is invoked it gives me following error. </p>

<pre><code>A first chance exception of type 'Emgu.CV.Util.CvException' occurred in Emgu.CV.World.dll
The program '[1136] IPTest.vshost.exe' has exited with code -1073741819 (0xc0000005) 'Access violation'.
The program '[1136] IPTest.vshost.exe: Program Trace' has exited with code 0 (0x0).
</code></pre>

<p>It is occurring while trying to use <code>recognizer.Train()</code>. What have I done wrong?</p>

<p><strong>UPDATE</strong><br>
After some trial and error I got to know that problem is with recognizer.Predict() method. <br>
When I used try/catch it shows the following exception</p>

<pre><code>Emgu.CV.Util.CvException: OpenCV: The matrix is not continuous, thus its number of rows can not be changed
</code></pre>
",2016-09-06 06:50:38,2018-03-15 13:49:30,'Emgu.CV.Util.CvException' occurred in 'Emgu.CV.World.dll' - When trying to Predict,<c#><opencv><emgucv><face-detection><face-recognition>,,,CC BY-SA 3.0,True,False,True,False,False
46629,39462514,2016-09-13 05:05:36,,"<p>your help is much appreciated. I am using C# and EmguCV for image processing</p>

<p>I have tried noise removal, but nothing happens. I also tried image median filter, and it only works on the first image, but it does not work on the second image. It only makes the second image blurry and the objects larger and more square-like. </p>

<p>I want to <strong>remove obviously distinct objects</strong>(green ones)  in my image below so that it would turn all black because they are obviously separated and are not grouped unlike the second image below.</p>

<p>Image 1:</p>

<p><img src=""https://i.stack.imgur.com/hJsDY.png"" alt=""It said that i need 10 reputation to post images, so this is image 1 :(""></p>

<p>At the same way, I want to do it in my image below, but <strong>remove only those objects -- (the black ones) -- that are not grouped/(lumped?)</strong> so that what remains on the image are the objects that are grouped/larger in scale?</p>

<p>Image 2:</p>

<p><img src=""https://i.stack.imgur.com/B8IJh.png"" alt=""It said that i need 10 reputation to post images, so this is image 2 :(""></p>

<p>Thank you</p>
",2016-09-13 07:16:01,2016-09-13 07:16:01,Remove separated objects in an Image C#,<c#><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
46633,39546556,2016-09-17 11:58:56,,"<p>I am trying to perform simple face detection using EMGUCV. But when I try to initialise the CascadeClassifier object it throws the exception </p>

<p>An unhandled exception of type 'System.EntryPointNotFoundException' occurred in Emgu.CV.dll</p>

<p>Additional information: Unable to find an entry point named 'CvCascadeClassifierCreate' in DLL 'cvextern'.</p>

<p>Below is my source code</p>

<p>` 
                                                                                                 private CascadeClassifier _cascadeClassifier;</p>

<pre><code>        _cascadeClassifier = new CascadeClassifier(Application.StartupPath + ""/haarcascade_frontalface_default.xml"");
        using (var imageFrame = _capture.QueryFrame().ToImage&lt;Bgr, Byte&gt;())
        {
            if (imageFrame != null)
            {
                var grayframe = imageFrame.Convert&lt;Gray, byte&gt;();
                var faces = _cascadeClassifier.DetectMultiScale(grayframe, 1.1, 10, Size.Empty); //the actual face detection happens here
                foreach (var face in faces)
                {
                    imageFrame.Draw(face, new Bgr(Color.BurlyWood), 3); //the detected face(s) is highlighted here using a box that is drawn around it/them

                }
            }
            imgCamUser.Image = imageFrame;
        }
</code></pre>

<p>`</p>

<p>Please how can I workaround this problem?.</p>
",,2016-09-18 04:38:51,EMGU CV Exception,<c#><exception><emgucv><face-detection>,,,CC BY-SA 3.0,False,False,True,False,False
46646,39644213,2016-09-22 16:24:17,,"<p>I use the library Emgu.CV.World and a set of classes x86 in web solution ASP.NET MVC5. Version EMGU: 3.1.0.2282.</p>

<p>For a while it worked, then I made a copy of the project in the same directory and changed the name of the folder, then began to appear the error:</p>

<p>An exception is thrown at 0x2AF630B1 (cvextern.dll) in iisexpress.exe: 0xC0000005: Access violation reading location 0x00000000.</p>

<p>This same functionality is implemented in the Win Forms application of the same libraries, it works without problems.
But web application all the time breaks down, on this method : CvInvoke.Threshold ().</p>

<p>Used x86, x64 catalogs, copy all the libraries in a separate directory, change the type of application to any CPU , x86 to x64 and nothing.
Tried on other systems (64-bit) is the same. Most interesting is that initially it worked, ie, the error my code is not.</p>

<p>I used, IIS Express 10, vs 2015 community.</p>

<p>I would be grateful for some advice, thanks</p>
",,2018-10-03 09:45:14,Emgu.CV.CvInvoke exception in iisexpress.exe,<c#><asp.net><iis-express><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
46720,39650757,2016-09-23 00:22:00,,"<p>i'm trying to get the birthmarks with HoughCircles.</p>

<p>My results so far:
<a href=""https://i.stack.imgur.com/exH94.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/exH94.jpg"" alt=""enter image description here""></a></p>

<p>My code:</p>

<pre><code>Mat imgDest = new Mat(imagePath, LoadImageType.Color);
CvtColor(imgDest, imgDest, ColorConversion.Bgr2Gray);
MedianBlur(imgDest, imgDest, 7);
//nice try but not so good... :(
//CvInvoke.Threshold(imgDest, imgDest, 120, 255, ThresholdType.Binary);
//CvInvoke.Canny(imgDest, imgDest, 40, 200);

var circles = CvInvoke.HoughCircles(imgDest, HoughType.Gradient, 1, imgDest.Rows/8, 60, 18);
foreach(var circle in circles)
{
   CvInvoke.Circle(imgDest, new Point((int)circle.Center.X, (int)circle.Center.Y), (int)circle.Radius, new MCvScalar(255, 255, 0), 2);
   imgDest.Save(imageName);                        
}
</code></pre>

<p>There's something there can i do for get better results?</p>
",,2016-09-23 06:01:46,EmguCV(OpenCV) trying to find a birthmarks (mole),<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
46724,39689403,2016-09-25 16:52:16,,"<p>what I'm trying to do is using an let say pre-loaded image within <a href=""http://www.emgu.com/wiki/files/3.1.0/document/html/2ec33afb-1d2b-cac1-ea60-0b4775e4574c.htm"" rel=""nofollow""><code>Emgu.CV.Mat</code></a>. It offers an constructor where its possible to specify a filename. But my image is already loaded (and manipulated) within the code, therefore it makes no sense to save the file here just to load it again.</p>

<p>I'm working within a WPF Environment and therefor have my image currently as a <code>WriteableBitmap</code>. Furthermore I found couple of hints (e.g. <a href=""https://github.com/neutmute/emgucv/blob/master/Emgu.CV/PInvoke/Windows.Store/ImageWindowsStore.cs"" rel=""nofollow"">here</a>) how to convert an <code>Mat</code> to <code>WriteableBitmap</code>. But what I'm looking for is the other way round, using a <code>WriteableBitmap</code> in order to <code>Emgu.CV</code> stuff with it.</p>

<p>According to <a href=""http://www.emgu.com/wiki/index.php/Working_with_Images#Creating_image_from_Bitmap"" rel=""nofollow"">Emgu CV 2.x it was possible</a> to use a <code>Bitmap</code> but it seams that this feature was removed in Emgu CV 3.x.</p>

<p>Any ideas how to do it in Emgu CV Version 3?</p>
",,2016-09-29 14:55:51,WriteableBitmap used in Mat.Mat constructor (Emgu.CV),<wpf><image-processing><emgucv><mat>,,,CC BY-SA 3.0,False,True,True,False,False
46737,39764844,2016-09-29 08:12:15,,"<p>I'm working on a project to recognize (similarity percentage) a image from a collection of image. I used the EmugCV 3.1.0. The codes are given below. Although the program runs, it have following issues</p>

<ol>
<li>When matches found the percentage showing always for first image. Find the attachment</li>
</ol>

<p><a href=""https://i.stack.imgur.com/tpGhI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tpGhI.png"" alt=""enter image description here""></a></p>

<ol start=""2"">
<li><p>if we put the same image in dbimage collection as twice and this same image as query image, the all matching percentage is zero. find the attachment </p>

<p>string[] dbImages = { imgPath + ""1.jpg"", imgPath + ""2.jpg"", imgPath + ""3.jpg"", imgPath + ""4.jpg"" };
 string queryImage = imgPath + ""4.jpg"";</p></li>
</ol>

<p>In these images image ""2"" and ""4"" are same</p>

<p><a href=""https://i.stack.imgur.com/QOgyE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QOgyE.png"" alt=""enter image description here""></a></p>

<p>The codes are given below</p>

<pre><code>    public partial class Form1 : Form
    {
        private static double surfHessianThresh = 300;
        private static SURF detector;
        public Form1()
        {
            InitializeComponent();
            ImageMatching();
        }

        public void ImageMatching()
        {
            string MatchString = null;
            detector = new SURF(surfHessianThresh);
            IList&lt;IndecesMapping&gt; matches = Match();
            IOrderedEnumerable&lt;IndecesMapping&gt; orderedMatches = matches.OrderByDescending(match =&gt; match.Similarity);

            foreach (IndecesMapping match in orderedMatches)
            {
                MatchString = MatchString + ""\n"" + match.ToString();
            }
            lblMatch.Text = MatchString;
            //Console.WriteLine();
            //Console.WriteLine(""MOST LIKELY MATCH: "" + orderedMatches.First());

            //Console.WriteLine(""Press enter to exit..."");
            //Console.ReadLine();
        }

        /// &lt;summary&gt;
        /// Main method.
        /// &lt;/summary&gt;
        static public IList&lt;IndecesMapping&gt; Match()
        {

            string imgPath = ""E:\\Riyas\\Projects\\Image Recognition\\Sample Projects\\EmguSample3.1.0\\EmguSample3.1.0\\"";
            string[] dbImages = { imgPath + ""1.jpg"", imgPath + ""2.jpg"", imgPath + ""3.jpg"", imgPath + ""4.jpg"" };
            string queryImage = imgPath + ""1.jpg"";

            IList&lt;IndecesMapping&gt; imap;

            // compute descriptors for each image
            var dbDescsList = ComputeMultipleDescriptors(dbImages, out imap);

            // concatenate all DB images descriptors into single Matrix
            Matrix&lt;float&gt; dbDescs = ConcatDescriptors(dbDescsList);

            // compute descriptors for the query image
            Matrix&lt;float&gt; queryDescriptors = ComputeSingleDescriptors(queryImage);

            FindMatches(dbDescs, queryDescriptors, ref imap);

            return imap;
        }

        /// &lt;summary&gt;
        /// Computes image descriptors.
        /// &lt;/summary&gt;
        /// &lt;param name=""fileName""&gt;Image filename.&lt;/param&gt;
        /// &lt;returns&gt;The descriptors for the given image.&lt;/returns&gt;
        static public Matrix&lt;float&gt; ComputeSingleDescriptors(string fileName)
        {
            Matrix&lt;float&gt; descs = null;
            using (Image&lt;Gray, Byte&gt; img = new Image&lt;Gray, byte&gt;(fileName))
            {
                MKeyPoint[] mkeyPoints = detector.Detect(img, null);
                VectorOfKeyPoint keyPoints = new VectorOfKeyPoint();
                keyPoints.Push(mkeyPoints);

                UMat observedDescriptors = new UMat();
                detector.Compute(img, keyPoints, observedDescriptors);
                descs = new Matrix&lt;float&gt;(observedDescriptors.Size);
                detector.Compute(img, keyPoints, descs);
            }

            return descs;
        }


        /// &lt;summary&gt;
        /// Convenience method for computing descriptors for multiple images.
        /// On return imap is filled with structures specifying which descriptor ranges in the concatenated matrix belong to what image.
        /// &lt;/summary&gt;
        /// &lt;param name=""fileNames""&gt;Filenames of images to process.&lt;/param&gt;
        /// &lt;param name=""imap""&gt;List of IndecesMapping to hold descriptor ranges for each image.&lt;/param&gt;
        /// &lt;returns&gt;List of descriptors for the given images.&lt;/returns&gt;
        static public IList&lt;Matrix&lt;float&gt;&gt; ComputeMultipleDescriptors(string[] fileNames, out IList&lt;IndecesMapping&gt; imap)
        {
            imap = new List&lt;IndecesMapping&gt;();

            IList&lt;Matrix&lt;float&gt;&gt; descs = new List&lt;Matrix&lt;float&gt;&gt;();

            int r = 0;

            for (int i = 0; i &lt; fileNames.Length; i++)
            {
                var desc = ComputeSingleDescriptors(fileNames[i]);
                descs.Add(desc);

                imap.Add(new IndecesMapping()
                {
                    fileName = fileNames[i],
                    IndexStart = r,
                    IndexEnd = r + desc.Rows - 1
                });

                r += desc.Rows;
            }

            return descs;
        }


        /// &lt;summary&gt;
        /// Computes 'similarity' value (IndecesMapping.Similarity) for each image in the collection against our query image.
        /// &lt;/summary&gt;
        /// &lt;param name=""dbDescriptors""&gt;Query image descriptor.&lt;/param&gt;
        /// &lt;param name=""queryDescriptors""&gt;Consolidated db images descriptors.&lt;/param&gt;
        /// &lt;param name=""images""&gt;List of IndecesMapping to hold the 'similarity' value for each image in the collection.&lt;/param&gt;
        static public void FindMatches(Matrix&lt;float&gt; dbDescriptors, Matrix&lt;float&gt; queryDescriptors, ref IList&lt;IndecesMapping&gt; imap)
        {
            var indices = new Matrix&lt;int&gt;(queryDescriptors.Rows, 2); // matrix that will contain indices of the 2-nearest neighbors found
            var dists = new Matrix&lt;float&gt;(queryDescriptors.Rows, 2); // matrix that will contain distances to the 2-nearest neighbors found

            // create FLANN index with 4 kd-trees and perform KNN search over it look for 2 nearest neighbours
            KdTreeIndexParamses kdparam = new KdTreeIndexParamses(4);

            var flannIndex = new Index(dbDescriptors, kdparam);
            flannIndex.KnnSearch(queryDescriptors, indices, dists, 2, 24);

            for (int i = 0; i &lt; indices.Rows; i++)
            {
                // filter out all inadequate pairs based on distance between pairs
                if (dists.Data[i, 0] &lt; (0.6 * dists.Data[i, 1]))
                {
                    // find image from the db to which current descriptor range belongs and increment similarity value.
                    // in the actual implementation this should be done differently as it's not very efficient for large image collections.
                    foreach (var img in imap)
                    {
                        if (img.IndexStart &lt;= i &amp;&amp; img.IndexEnd &gt;= i)
                        {
                            img.Similarity++;
                            break;
                        }
                    }
                }
            }
        }

        /// &lt;summary&gt;
        /// Concatenates descriptors from different sources (images) into single matrix.
        /// &lt;/summary&gt;
        /// &lt;param name=""descriptors""&gt;Descriptors to concatenate.&lt;/param&gt;
        /// &lt;returns&gt;Concatenated matrix.&lt;/returns&gt;
        static public Matrix&lt;float&gt; ConcatDescriptors(IList&lt;Matrix&lt;float&gt;&gt; descriptors)
        {
            int cols = descriptors[0].Cols;
            int rows = descriptors.Sum(a =&gt; a.Rows);

            float[,] concatedDescs = new float[rows, cols];

            int offset = 0;

            foreach (var descriptor in descriptors)
            {
                // append new descriptors
                Buffer.BlockCopy(descriptor.ManagedArray, 0, concatedDescs, offset, sizeof(float) * descriptor.ManagedArray.Length);
                offset += sizeof(float) * descriptor.ManagedArray.Length;
            }

            return new Matrix&lt;float&gt;(concatedDescs);
        }
    }

    public class IndecesMapping
    {
        public int IndexStart { get; set; }
        public int IndexEnd { get; set; }
        public int Similarity { get; set; }
        public string fileName { get; set; }

        public override string ToString()
        {
            return fileName + "": "" + Similarity + ""%"";
        }
    }
</code></pre>
",,2016-10-05 20:43:11,Finding matching image within a collection of images using emguCV 3.1.0,<c#><opencv><emgucv><flann>,,,CC BY-SA 3.0,True,False,True,False,False
46830,39619754,2016-09-21 14:42:51,,"<p><a href=""https://i.stack.imgur.com/5LZkq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5LZkq.png"" alt=""enter image description here""></a><br>
How can I get the position of the ""point"" from walls perspective? I know the x,y,(z) coordinates from cameras perspective, and I know the edge points of the wall.<br>
I want to calculate if the point stands in front of the wall, and on witch side of it (left, right).
My idea is to calculate a plane equation of the wall, and test if a perpendicular line from the point to the plane hits it in the boundaries of the wall.<br>
Can I do this somehow without using the z coordinate (it is very inaccurate) and the angle between wall and camera is variable.</p>
",,2016-09-21 23:11:29,Calculate perspective transformation in OpenCV,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
46889,39894559,2016-10-06 11:16:58,,"<p>There are some different between emgu cv library , documentation, sample files. emgv.cv.capture  is not supported in latest emgu cv library. I cannot access the _capture.start(), _capture.pause(), _capture.stop() functions. I want solution for this.</p>
",2016-10-06 11:30:42,2016-10-11 19:08:38,.dll file is not available,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
46904,39864464,2016-10-05 02:19:13,,"<p>I need to compare two images in a project,
The images would be two fruits of the same kind -let's say two different images of two different apples- </p>

<p>To be more clear, the database will have images of the stages which an apple takes from the day it was picked from a tree until it gets rotten..</p>

<p>The user would upload an image of the apple they have and the software should compare it to all those images in the database and retrieve the data of the matching image and tell the user at which stage is it...</p>

<p>I did compare before images using OpenCv emgu but I really don't have much knowledge if it's the best way...</p>

<p>I need an expert advise is what i said in the project even possible? or the whole database images' will match the user's image! 
And is this ""image processing"" or something else?
And is there any suggested tutorials to learn how to do this?</p>

<p>I know it seems not totally clear yet, but it's just a crazy idea that I wish I can get a way to know more how i can bring it to life!</p>

<p>N.B the project will be an android application</p>
",2016-10-13 01:01:35,2016-10-13 01:01:35,Comparing images using OpenCv or something more useful,<opencv><image-processing><emgucv><image-comparison>,,,CC BY-SA 3.0,True,False,True,False,False
46938,39743750,2016-09-28 09:45:12,,"<p>I have the following image as a test image:</p>

<p><a href=""https://i.stack.imgur.com/NFXjb.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NFXjb.gif"" alt=""enter image description here""></a></p>

<p>I attempt to find the shapes on the image (and other images). My approch right now is the following:</p>

<ol>
<li>Gaussian blur with a 3x3 kernel </li>
<li>Canny edge detection using
list (to get all shapes) </li>
<li>Morphology with MorphOp.Close to close
the edges </li>
<li>FindContours to find contours </li>
<li>Iteration of each contour: 

<ol start=""6"">
<li>Find ApproxPolyDP </li>
<li>Find ConvexHull </li>
<li>Discard if
hull size &lt; 2, approx area &lt; 200 or hull size > 50000, or arclength
of the approx &lt; 100 </li>
<li>Draw convexhull</li>
</ol></li>
</ol>

<p>This method yields the following images where the convex hulls are drawn:
<a href=""https://i.stack.imgur.com/3vsUq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3vsUq.png"" alt=""enter image description here""></a></p>

<p>This is almost perfect, but notice that the lines are seen as a contours events->suppliers and events->documents). When looking at the edge information, it becomes apparent why this is so:</p>

<p><a href=""https://i.stack.imgur.com/jvEs0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jvEs0.png"" alt=""enter image description here""></a></p>

<p>The lines are detected as a contour. How could I prepare/find the shapes so the lines are not detected? I though of some thinning algorithm, but since I also work on real life images it is difficult to find a threshold that works. Here is an example of a real life image where thinning is difficult to do because thinning typically requires the images to be monochrome in black and white.</p>

<p><a href=""https://i.stack.imgur.com/wCIuS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wCIuS.png"" alt=""enter image description here""></a></p>

<p>How would you do it? Is there some method to determine if the contour/convex hull is a line, rectangle or something like this?</p>
",,2016-10-06 08:30:23,Find shapes on white background. Thinning the lines,<opencv><emgucv><opencv-contour><canny-operator><adaptive-threshold>,,,CC BY-SA 3.0,True,False,True,False,False
46942,39828628,2016-10-03 09:40:01,,"<p>Has anyone used the packaged Xamrin version of this? <a href=""https://components.xamarin.com/view/emgucv-v3"" rel=""nofollow noreferrer"">https://components.xamarin.com/view/emgucv-v3</a></p>

<p>I have recently purchased this license and am hitting exactly the same issues as described here ( <a href=""https://stackoverflow.com/questions/14816166/rotate-camera-preview-to-portrait-android-opencv-camera/39804785#39804785"">Rotate camera preview to Portrait Android OpenCV Camera</a>). Have been using a variety of approaches.</p>

<p>Firstly rotate the screen orientation from Landscape to Portrait, but this simply displays the stream in the same rotated form (90 degrees). Landscape seems to be the only one that works as I would like.</p>

<p>I have tried to rotate the camera itself using the camera object, but this doesn't fix the issue either. i.e.</p>

<pre><code>camera.SetDisplayOrientation(90);
</code></pre>

<p>I have debuged this a huge number of times to see where execution occurs, and it seems that initially the screen is set correctly, but by the time </p>

<pre><code>protected override void OnDraw(Android.Graphics.Canvas canvas)
</code></pre>

<p>is run to add the FPS text it has flipped it back.</p>

<p>I have also tried to flip the image using Matrix, but this drops the frame rate from approx 20FPS to about 6FPS. This is too much of. a hit</p>

<p>Really struggling here as this is now the major stumbling block to building out my app.</p>

<p>I am fairly new to Xamarin, so any help is greatly appreciated.</p>

<p>P.S. Apologies. I know this has been covered by another thread (<a href=""https://stackoverflow.com/questions/14816166/rotate-camera-preview-to-portrait-android-opencv-camera/39804785#39804785"">Rotate camera preview to Portrait Android OpenCV Camera</a>), and I have tried all the options there, but this entry was deleted by Ed Cotrell (Admin) from that thread and I was told to start a new one. </p>
",2017-05-23 12:02:34,2016-10-03 12:36:13,Rotate camera preview to Portrait Android OpenCV Camera and Xamarin,<android><opencv><xamarin>,,,CC BY-SA 3.0,True,False,True,False,False
46949,39711183,2016-09-26 19:47:54,,"<p>My problem is combining nearby contours at a reasonable speed.</p>

<p>I start with a CV8U single-channel greyscale mat containing an image of a large, closed shape. Sprouting on the inside of this shape is a short curve. My mission is to get the curve only into a vector of points. </p>

<p>So I threshold my mat and call FindContours. The result is a vector of many contours. Some are noise, including bits of the large shape that I didn't quite manage to mask out. But several are parts of my curve. The problem is that the curve - continuous in the raw image - is fragmented into many contours by FindContours. To fix this, I find the largest contour, which is always a part of my curve, and search for other nearby contours. If I find any, I join them together, and repeat.</p>

<p>By the end, I have a single vector of points containing my curve. It works. But all the looping and iteration makes it stupidly slow.</p>

<p>What alternative approach would retain the output (a vector of points representing my curve) but run fast?</p>

<pre><code>Private vpcurve As VectorOfPoint
...
    GrowCurve(FindContoursOutput, inc, BiggestContourInFindContoursOutput)
...
Private Sub GrowCurve(ContoursToCheck As VectorOfVectorOfPoint, ContoursIncluded() As Boolean, StartContour As Integer)
    vpcurve.Push(ContoursToCheck(StartContour).ToArray)
    ContoursIncluded(StartContour) = True
    For j = ContoursToCheck.Size - 1 To 0 Step -1
        If Not ContoursIncluded(j) Then
            If contoursClose(ContoursToCheck, j, StartContour) Then
                GrowCurve(ContoursToCheck, ContoursIncluded, j)
            End If
        End If
    Next
End Sub

Private Function contoursClose(cnt As VectorOfVectorOfPoint, index1 As Integer, index2 As Integer) As Boolean
    For i As Integer = cnt(index1).Size - 1 To 0 Step -1
        Dim p1 As Point = cnt(index1)(i)
        For j As Integer = cnt(index2).Size - 1 To 0 Step -1
            Dim p2 As Point = cnt(index2)(j)
            If (Math.Pow(p1.X - p2.X, 2) + Math.Pow(p1.Y - p2.Y, 2)) &lt; 30 Then 'arbitrary  pixel distance
                contoursClose = True
                Exit Function
            End If
        Next
    Next
    contoursClose = False
End Function
</code></pre>
",,2016-09-26 19:47:54,How can I speed up or replace code to combine close contours?,<opencv><emgucv><opencv-contour>,,,CC BY-SA 3.0,True,True,True,False,False
46976,39927686,2016-10-08 01:09:59,,"<p>I built and referred to <code>Emgu.CV.World.dll</code> in my project. When I was trying to call the method like</p>

<pre><code>IntPtr complexImage = CvInvoke.cvCreateImage(image.Width * image.Height, Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_32F, 2);
CvInvoke.cvSetZero(complexImage); 
</code></pre>

<p>Visual studio complains that it could not find the definitions for both <code>Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_32F</code> and <code>cvSetZero()</code>. Am I still missing anything in my project?</p>
",2016-10-08 01:24:08,2016-11-07 16:34:09,CvInvoke does not contain a definition of cvSetZero,<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
47030,39835963,2016-10-03 16:12:29,,"<p>I'm trying to walk through all of the pixels in a binary EmguCV image by following the code shown here:
<a href=""https://stackoverflow.com/a/5107490/1092688"">https://stackoverflow.com/a/5107490/1092688</a></p>

<p>And make a recursive call on any white pixels found and place the contiguous object into its own binary image. There is a List which stores these binary images, and then I need to perform some operations on the list. However, I'm getting a stack overflow error in my recursive function. The code block which iterates over an image is shown here:</p>

<pre><code>    //globals:
    byte[,,] outputData;
    byte[,,] inputData;
    int count = 0;

    //iterative loop
    inputData = input.Data;
    for (int i = input.Rows - 1; i &gt;= 0; i--)
        {
            for (int j = input.Cols - 1; j &gt;= 0; j--)
            {
                if (inputData[i, j, 0] == 255)
                {
                    count = 0;
                    Image&lt;Gray, Byte&gt; temp = new Image&lt;Gray, Byte&gt;(input.Size);
                    outputData = temp.Data;

                    crawlFrom(i, j);
                    //outputData should now contain a byte[,,] representing the data of a single object to be processed.
                }
            }
        } 
</code></pre>

<p>And the recursive function is shown below (note that it uses the globals shown above):</p>

<pre><code>private void crawlFrom(int i, int j)
    {
        outputData[i, j, 0] = 255;//add pixel to output
        count++;//increment count
        inputData[i, j, 0] = 0;//blacken input image

        //recursively call on neighbors:
        if(i + 1 &lt; height)
            if (inputData[i + 1, j, 0] == 255)
                crawlFrom(i + 1, j);

        if (i - 1 &gt;= 0)
            if (inputData[i - 1, j, 0] == 255) 
                crawlFrom(i - 1, j);

        if (j + 1 &lt; width)
            if (inputData[i, j + 1, 0] == 255) 
                crawlFrom(i, j + 1);

        if (j - 1 &gt;= 0)
            if (inputData[i, j - 1, 0] == 255) 
                crawlFrom(i, j - 1);

    } 
</code></pre>

<p>I checked the color of the neighbor before recursively calling on it in an attempt to thwart the stack overflow, <em>yes</em> I have also tried it with </p>

<pre><code>if(inputData[i, j, 0] == 0) return;
</code></pre>

<p>at the start of the function.  </p>

<p>Some other info:<br>
Stack size is 1GB<br>
Image size is 1920x1080<br>
The image should have less than 10% white pixels. It does seem that the images which cause the stack overflow tend to have more white pixels (perhaps up to 30%).<br>
This is a real-time application.<br>
Objects are not always closed shapes.  </p>

<p>How can I solve this problem? I'm pretty unfamiliar with how the Image.Data property works and whether or not I'm using it properly so I hope it's something obvious. If it's not a simple bugfix, I'm open to suggestions for tweaking my existing algorithm or changing my algorithm for object detection altogether, so long as the solution fits my criteria for detection and speed.</p>

<p>Thanks for your time!</p>
",2017-05-23 12:00:40,2016-10-03 16:12:29,EmguCV Object Detection stack overflow,<c#><algorithm><opencv><recursion><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
47037,39753142,2016-09-28 16:37:38,,"<p>I try to use disparity map calculation in C# using Emgu.CV</p>

<p>I read the images from this <a href=""https://stackoverflow.com/questions/17607312/difference-between-disparity-map-and-disparity-image-in-stereo-matching"">article</a> as bitmapLeft and bitmapRight. For reference I used the example code from <a href=""http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_calib3d/py_depthmap/py_depthmap.html"" rel=""nofollow noreferrer"">here</a></p>

<p>Here is my source code:</p>

<pre><code>bitmapLeft = (Bitmap) mainForm.pictureBoxLeft.Image;
bitmapRight = (Bitmap)mainForm.pictureBoxRight.Image;

Image&lt;Gray, Byte&gt; imageLeft = new Image&lt;Gray, Byte&gt;(bitmapLeft);
Image&lt;Gray, Byte&gt; imageRight = new Image&lt;Gray, Byte&gt;(bitmapRight);
Image&lt;Gray, Byte&gt; imageDisparity = new Image&lt;Gray, Byte&gt;(bitmapLeft.Width, bitmapLeft.Height);

StereoBM stereoBM = new StereoBM(16, 15);
StereoMatcherExtensions.Compute(stereoBM, imageLeft, imageRight, imageDisparity);

Image bitmapDisparity = imageDisparity.ToBitmap();
</code></pre>

<p>However, the resulting bitmap is all black.</p>
",2017-05-23 12:33:11,2017-08-18 23:05:51,Disparity Map in Emgu.CV,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
47084,39911727,2016-10-07 07:26:42,,"<p>I'm currently working on implementing an algorithm in EmguCV in C#, meaning that I don't want to use the build in rotate function that comes with EmguCV.</p>

<p>I've already found the algorithm that I want to implement, but I'm kinda stuck as how to implement it. The main problem is, that I don't know how the specify the X and Y values of my Matrix to be able to do the intended calculations.</p>

<p>Rotation Algorithm:
<a href=""https://i.stack.imgur.com/hQMxF.jpg"" rel=""nofollow noreferrer"">http://i.stack.imgur.com/hQMxF.jpg</a></p>

<p>Right now my Code looks like this:</p>

<pre><code>static void Main(string[] args) {
        Mat image = CvInvoke.Imread(""C:\\Users\\Leon\\Desktop\\a.jpg"", LoadImageType.Grayscale);

        int height = image.Height;
        int width = image.Width;

        //Convert to Matrix
        Matrix&lt;Byte&gt; matrix = new Matrix&lt;Byte&gt;(image.Rows, image.Cols, image.NumberOfChannels);
        image.CopyTo(matrix);

        Matrix&lt;Byte&gt; newMatrix = new Matrix&lt;Byte&gt;(image.Rows, image.Cols, image.NumberOfChannels);
        image.CopyTo(newMatrix);

        for (int i = 0; i &lt; matrix.Rows-1; i++)
        {
            for (int j = 0; j &lt; matrix.Cols-1; j++)
            {

            }
        }

        CvInvoke.Imshow(""abc"", matrix);
        CvInvoke.WaitKey(0);

    }
</code></pre>

<p>But as I said, I'm in doubt of as how to implement the algorithm. My plan was to rotate the pixels in ""matrix"" and store them in ""newMatrix"" but I do not know how to specify the X and Y values of my matrix.</p>

<p>Maybe someone can help me out here.</p>

<p>EDIT:
There has been suggested that this answer here: ""<a href=""https://stackoverflow.com/questions/32255440/how-can-i-get-and-set-pixel-values-of-an-emgucv-mat-image"">How can I get and set pixel values of an EmguCV Mat image?</a>"" will be an answer to my question. But it is not. I know that I can do Math.Cos and Math.Sin but I do not know how to specify X and Y in my Matrix. I don't have problems accessing the Data in my Matrix.</p>
",2017-05-23 12:06:56,2016-10-12 08:46:27,"How do I implement a ""rotate-algorithm"" in Emgu CV?",<c#><algorithm><opencv><emgucv><image-rotation>,,,CC BY-SA 3.0,True,True,True,False,False
47150,40139078,2016-10-19 18:33:17,,"<p>I writing app for face Detection using Emgu CV.</p>

<p>It is WPF app.</p>

<p>Here is code for my xaml:</p>

<pre><code>&lt;Window x:Class=""WpfFaceDetectionTest.MainWindow""
    xmlns=""http://schemas.microsoft.com/winfx/2006/xaml/presentation""
    xmlns:x=""http://schemas.microsoft.com/winfx/2006/xaml""
    Title=""MainWindow"" Height=""600"" Width=""800"" Loaded=""Window_Loaded""&gt;
&lt;Grid&gt;
    &lt;Image Name=""image1"" Stretch=""Fill"" /&gt;
&lt;/Grid&gt;
</code></pre>

<p></p>

<p>and code for my xaml.cs</p>

<pre><code>   using System;
using System.Windows;
using System.Windows.Controls;
using System.Windows.Media.Imaging;
using System.Windows.Threading;
using Emgu.CV.Structure;
using Emgu.CV;
using System.Runtime.InteropServices;

namespace WpfFaceDetectionTest
{
    /// &lt;summary&gt;
    /// Interaction logic for MainWindow.xaml
    /// &lt;/summary&gt;
    public partial class MainWindow : Window
    {

        private Capture capture;
        private HaarCascade haarCascade;
        DispatcherTimer timer;

        public MainWindow()
        {
            InitializeComponent();
        }

        private void Window_Loaded(object sender, RoutedEventArgs e)
        {
            capture = new Capture();
            haarCascade = new HaarCascade(""C:\\Users\\nemes\\Desktop\\WpfFaceDetectionTest\\haarcascade_frontalface_alt_tree.xml"");
            timer = new DispatcherTimer();
            timer.Tick += new EventHandler(timer_Tick);
            timer.Interval = new TimeSpan(0, 0, 0, 0, 1);
            timer.Start();
        }

        void timer_Tick(object sender, EventArgs e)
        {
            Image&lt;Bgr,Byte&gt; currentFrame = capture.QueryFrame();

            if (currentFrame != null)
            {
                Image&lt;Gray, Byte&gt; grayFrame = currentFrame.Convert&lt;Gray, Byte&gt;();

                var detectedFaces = grayFrame.DetectHaarCascade(haarCascade)[0];

                foreach (var face in detectedFaces)
                    currentFrame.Draw(face.rect, new Bgr(0, double.MaxValue, 0), 3);

                image1.Source = ToBitmapSource(currentFrame);
            }

        }

        [DllImport(""gdi32"")]
        private static extern int DeleteObject(IntPtr o);

        public static BitmapSource ToBitmapSource(IImage image)
        {
            using (System.Drawing.Bitmap source = image.Bitmap)
            {
                IntPtr ptr = source.GetHbitmap(); //obtain the Hbitmap

                BitmapSource bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
                    ptr,
                    IntPtr.Zero,
                    Int32Rect.Empty,
                    System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions());

                DeleteObject(ptr); //release the HBitmap
                return bs;
            }
        }
    }
}
</code></pre>

<p>My problem is that the videostream from web camera breaks.</p>

<p>How can I fix this issue?</p>

<p>Thank's for help</p>
",2016-10-19 18:53:52,2016-10-19 18:53:52,Face Detection (Emgu CV),<c#><wpf><xaml><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
47203,39989691,2016-10-12 02:42:45,,"<p>My code works ok for built in cameras but I want to capture a stream from an IP camera. However the feed runs very slow. How can I skip frames so I am always seeing the latest frame. For what I am doing it is not important to have a perfect streaming video but rather get frames in realtime.</p>

<pre><code>        while (true)
        {
            // try to open the camera device
            if (capture == null)
            {
                try
                {
                    int index;
                    bool isNumeric = int.TryParse(ConfigurationManager.AppSettings[""CameraSource""], out index);
                    capture = isNumeric ? new Capture(index) : new Capture(ConfigurationManager.AppSettings[""CameraSource""]);
                }
                catch
                {
                    frameObservers.ForEach(a =&gt; a.frame(cameraNotConnectedBitmap, new List&lt;Person&gt;(), recognizer.isActive()));
                }
                Task.Delay(1000).Wait();
                continue;
            }

            // read a frame from the camera
            Mat matFrame = capture.QueryFrame();
            Image&lt;Bgr, byte&gt; frame = (matFrame == null) ? null : matFrame.ToImage&lt;Bgr, byte&gt;();
            if (frame == null)
            {
                frameObservers.ForEach(a =&gt; a.frame(cameraNotConnectedBitmap, new List&lt;Person&gt;(), recognizer.isActive()));
                capture = null; // force to reconnect to camera again
                Task.Delay(1000).Wait();
                continue;
            }

            frameObservers.ForEach(a =&gt; a.frame(frame, personsInCurrentFrame, recognizer.isActive()));

            Task.Delay(10).Wait();
        }
</code></pre>
",,2016-10-12 02:42:45,Emgu opencv capture RTSP/HTTP media stream too slow,<opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
47230,40063333,2016-10-15 19:27:43,,"<p>EmguCV is a wrapper library for OpenCV in C#.</p>

<p>So I'm developing a web app for my Database course which is a police database system for storing criminal records using Asp.Net MVC, Entity Framework, and SQL Server. Here I am planning to implement facial recognition by applying Open CV's eigenfaces algorithm. So the problem here is that I've looked upon some threads here on StackOverflow regarding this but the answers are too vague. The problem is that OpenCV contains all files which can't be hosted on a web server and of course can't be executed there. If I were to deploy this project in a production environment, what approach would I follow?</p>

<p>One suggestion on a thread was that to make a console application as a separate project which only processes the image using EmguCV and another project within the same solution which will be an MVC application. The web app will pass the image to the desktop application and it will process it further. But again the problem here is that I can't deploy both the console application and a desktop application on the same server.</p>

<p>What approach would I follow?</p>
",2016-10-15 21:09:59,2016-10-15 21:09:59,Using EmguCV along with ASP.NET MVC,<c#><asp.net-mvc><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
47250,40221901,2016-10-24 15:16:21,,"<p>I'm using EmguCV 2.4 in C# for edge detection and ellipse fitting of ellipsoid objects in a picture (e.g. laser spot). </p>

<p>EmguCV has implemented functions for fitting an ellipse to a point cloud using the least squares method, but the ellipses do not fit very well to the ellipsoids, depending on their angle. </p>

<p>Here's a basic code, I'm using:</p>

<pre><code>CHAIN_APPROX_METHOD approxMethod = CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_NONE;
RETR_TYPE           RetrType     = RETR_TYPE.CV_RETR_LIST;

Bitmap Bmp = new Bitmap(@""C:\Users\pernizki\Downloads\binary2.bmp"");                // read Bitmap
Image&lt;Bgr,  byte&gt; ImgIn   = new Image&lt;Bgr, byte&gt;(Bmp);                              // Convert to Image&lt;&gt;
Image&lt;Gray, byte&gt; ImgBin  = ImgIn.Convert&lt;Gray, byte&gt;();                            // convert Bgr to Gray
ImgBin = ImgBin.ThresholdBinary(new Gray(140), new Gray(120)).PyrDown().PyrUp();    // convert to binary and reduce noise
ImgBin = ImgBin.Canny(100, 120);                                                    // detect the edges from binary image
Contour&lt;Point&gt;    Contour = ImgBin.FindContours(approxMethod, RetrType);            // Get Contour from binary Image
int cntr = 0;
PointF[] ContourPts = new PointF[Contour.Total];

// Convert Contour to PointF Array
foreach(Point p in Contour)
{
    ContourPts[cntr++] = new PointF(p.X, p.Y);
}

Ellipse fittedEllipse = PointCollection.EllipseLeastSquareFitting(ContourPts);

ImgIn.Draw(Contour, new Bgr(Color.Green), 2);
ImgIn.Draw(fittedEllipse, new Bgr(Color.Tomato), 2);

CvInvoke.cvShowImage(""Fitted Ellipse"", ImgIn.Ptr);
</code></pre>

<p>When I have vertical or horizontal ellipse as an input image, the fitted ellipse is always 90° rotated to the input shape. If the angle is something between 0° and 90° the fitted ellipse is still rotated, but at different angle. </p>

<p>I understand, that this problem is fundamental to the least square method. But are there more robust algorithms to fit an ellipse, that is enclosing all of the points? 
The picture in the <a href=""http://www.emgu.com/wiki/index.php/Ellipse_Fitting_in_CSharp"" rel=""nofollow"">EmguCV tutorial</a> for fitting an ellipse seems to be exactly, what I'm looking for. Unfortunately, that's not how the function works. </p>

<p>Here's an example image, that I've used. 
(sorry for having only one, as I don't have enough reputation for more)</p>

<p><a href=""https://i.stack.imgur.com/msYh9.png"" rel=""nofollow"">rotated Ellipse</a></p>
",,2016-10-24 15:16:21,Improve a fitted Ellipse using EmguCV (2.4) in C#,<c#><ellipse><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
47265,40107310,2016-10-18 11:42:16,,"<p>I've seen examples of using EMGUCV on regular RGB images captured from the Kinect like <a href=""http://www.imaginativeuniversal.com/blog/post/2015/06/11/emgu-kinect-and-computer-vision.aspx"" rel=""nofollow noreferrer"">this</a>, but then you might as well have a webcam. I am interested in getting a Point Cloud which I can later use for triangulation.</p>

<p>I've tried 'manually' converting a DepthFrame to a point cloud file. In the depth frame you have X, Y and a depth value which I converted to XYZ points for a .ply file. The results are garbled and useless.</p>

<p>Now, I noticed that EMGUCV has <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/ae627911-05a3-99ac-c417-b0bc6152d738.htm"" rel=""nofollow noreferrer"">this method</a> which maps a point cloud into an EMGUCV Mat object.
I just don't know how the syntax is supposed to be for this as there are no examples of people asking for this or any provided examples by the people behind EMGUCV.</p>

<p>Here's what I tried, the Kinect doesn't even seem to turn on, and success always returns false.</p>

<pre><code>public void test()
{
    KinectCapture kc = new KinectCapture(KinectCapture.DeviceType.Kinect, KinectCapture.ImageGeneratorOutputMode.Vga30Hz);
    Mat m = new Mat();
    bool success = kc.RetrievePointCloudMap(m);
}
</code></pre>

<p>I also had a problem that it kept throwing an exception during the construction of the KinectCapture object, <a href=""https://stackoverflow.com/questions/15194310/emgucv-typeinitializationexception-thrown-by-emgucv-cv-cvinvoke"">this</a> was my solution.</p>
",2017-05-23 12:16:39,2016-10-24 08:34:52,Retrieving a Point Cloud using Kinect and EMGU?,<c#><opencv><kinect><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
47281,39951821,2016-10-10 05:34:48,,"<p>I'm new to emgu, and found people are using Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_32F in their implementation. In my program, I don't know why I can not use it. However, I found that I could use Emgu.CV.CvEnum.IplDepth.IplDepth32F. I'm guessing they are the same thing, but I'm using a different version of emgu from other people. I'm using emgu.cv.dll version 3.0.0.2157. I tried to find which version uses Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_32F as other people are using, but didn't get any luck. I probably referred to the wrong place. Can any one tell how to figure out such problems?</p>
",,2016-11-07 16:26:39,Emgu.CV.CvEnum.IPL_DEPTH.IPL_DEPTH_32F and Emgu.CV.CvEnum.IplDepth.IplDepth32F,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
47323,39995777,2016-10-12 09:59:27,,"<p>I want to rotate an image using OpenCV/EmguCV. I've found a rotation algorithm that I want to implement, but the outcome is not quite as I want it to be. Maybe someone can have a look.</p>

<p>My Code:</p>

<pre><code>static void Main(string[] args)
    {
        Mat image = CvInvoke.Imread(""C:\\Users\\Leon\\Downloads\\a.jpg"", LoadImageType.Grayscale);

        int height = image.Height;
        int width = image.Width;

        //Convert to Matrix
        Matrix&lt;Byte&gt; matrix = new Matrix&lt;Byte&gt;(image.Rows, image.Cols, image.NumberOfChannels);
        image.CopyTo(matrix);

        Matrix&lt;Byte&gt; newMatrix = new Matrix&lt;Byte&gt;(image.Rows, image.Cols, image.NumberOfChannels);
        image.CopyTo(newMatrix);

        for (int i = 0; i &lt; matrix.Rows - 1; i++)
        {
            for (int j = 0; j &lt; matrix.Cols - 1; j++)
            {
                newMatrix.Data[i, j] = matrix.Data[(byte)(i * Math.Cos(3) - j * Math.Sin(3)), (byte)(i * Math.Sin(3) + j * Math.Cos(3))];
            }
        }

        CvInvoke.Imshow(""abc"", newMatrix);
        CvInvoke.WaitKey(0);

    }
}
</code></pre>

<p>Original Picture:</p>

<p><a href=""https://i.stack.imgur.com/qc0qb.jpg"" rel=""nofollow""><img src=""https://i.stack.imgur.com/qc0qb.jpg"" alt=""Vladimir Putin""></a></p>

<p>My Outcome:</p>

<p><a href=""https://i.stack.imgur.com/Q8C6U.png"" rel=""nofollow""><img src=""https://i.stack.imgur.com/Q8C6U.png"" alt=""incorrectly rotated""></a></p>

<p>If someone can point out what I'm doing wrong, I'd be very thankful! :)</p>
",2016-10-12 12:09:01,2016-10-12 12:38:58,EmguCV Rotation Algorithm not working,<c#><algorithm><opencv><rotation><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
47332,40222685,2016-10-24 15:57:19,,"<p>I can play the following link in vlc media player:</p>

<pre><code>rtsp://192.168.42.1:554/live
</code></pre>

<p>But when I use the same link inside my capture initialization I can't get anything and my image box is displaying nothing.</p>

<pre><code>private void Form1_Load (object sender, EventArgs e) 
{ 
  capture = new Capture(""rtsp://192.168.42.1/live""); 
  Application.Idle += new EventHandler(ProcessFrame); 
} 

public void ProcessFrame (object sender, EventArgs arg) 
{ 
  imageBox1.Image = capture.QueryFrame(); 
}
</code></pre>
",2016-10-25 13:35:39,2016-10-25 13:35:39,How can I display the video stream of an action camera to an image box using capture of emgu cv c#?,<c#><streaming><emgucv><ip-camera>,,,CC BY-SA 3.0,False,False,True,False,False
47335,40225084,2016-10-24 18:28:42,,"<p>I'm programming in C# using EmguCV(3.1) library. In previous version of this library there is an <code>Image</code> (for example Image) instance having <code>.Copy(Rectangle r)</code> method.</p>

<p>How can I crop an <code>UMat</code> instance using a <code>Rectangle</code> instance?</p>
",,2016-10-25 00:55:35,.Copy(Rectangle r) method for UMat in EmguCV(3.1),<c#><image><image-processing><copy><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
47346,39957142,2016-10-10 11:23:43,,"<p>I want to remove the connecting points of wire with the components, The main purpose of doing this is to segment the image and detect only the resistor capacitor etc signs </p>

<p>What i have done is : erosion , dilation , etc</p>

<p>since the size of wire and component is nearly same so erosion dilation will not work</p>

<p>can anyone tell me how can i remove the point or segment the image</p>

<p>Thanks </p>

<p><a href=""https://i.stack.imgur.com/B9Az4.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/B9Az4.jpg"" alt=""enter image description here""></a></p>
",,2016-10-10 11:23:43,Break the connection of wire with components:Segmentation,<matlab><image-processing><emgucv><aforge><accord.net>,,,CC BY-SA 3.0,False,True,True,False,False
47351,40193951,2016-10-22 15:40:09,,"<p>I've got an image and I've got a mask (which isn't a rectangle) and a destination empty image with the size of the mask's bounding box. So the interested image part should fit there. How can I tell emgucv to copy the masked image to the destination without having the same number of dimensions of the destination image?</p>

<p>So something like:
img:
(3*3 image)</p>

<pre><code>3,3,3 4,4,4 5,5,5
6,6,6 7,7,7 8,8,8
9,9,9 1,1,1 2,2,2
</code></pre>

<p>mask:
I'm not interested in the top row and 1 last pixel
(3*3 gray image)</p>

<pre><code>0,0,0 0,0,0 0,0,0
1,1,1 1,1,1 1,1,1
1,1,1 1,1,1 0,0,0
</code></pre>

<p>dest (before copy):
(3*2 empty image)</p>

<pre><code>0,0,0 0,0,0 0,0,0
0,0,0 0,0,0 0,0,0
</code></pre>

<p>dest (after copy):
(3*2 image)</p>

<pre><code>6,6,6 7,7,7 8,8,8
9,9,9 1,1,1 0,0,0
</code></pre>
",,2016-10-22 15:40:09,EmguCv copy image part to dest with offset,<c#><image><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
47359,40194301,2016-10-22 16:15:50,,"<p>can viola jones recognize faces without any addition method like PCA or anything else ? how's the accurancity? and how to get rid the false negative in detecting? because there's so much false negative in viola jones detecting. if you know something please tell me. </p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Windows.Forms;
using Emgu.CV.Util;
using Emgu.CV.Features2D;
using Emgu.CV;
using Emgu.CV.GPU;
using Emgu.CV.VideoStab;
using Emgu.CV.Structure;
using Emgu.CV.CvEnum;

namespace deteksi_wajah
{
    public partial class Form1 : Form
    {
        Capture capture; // untuk koneksi ke webcam
        HaarCascade haar;



        public Form1()
        {

            InitializeComponent();


        }

        //method
        //Proses image aquisision bertipe rgb
        private void prosesFrame(object sender, EventArgs arg)
        {
            Image &lt; Bgr, byte &gt; image = capture.QueryFrame(); //hasil koneksi gambar didapat bertipe rbg
            imageBox1.Image = image; // citra yg didapat berada dalam box
               if( image != null)
               {
                    Image &lt; Gray, byte &gt; gray = image.Convert&lt;Gray,byte&gt;();
            var faces =  gray.DetectHaarCascade(haar, 1.1 , 1, 
                Emgu.CV.CvEnum.HAAR_DETECTION_TYPE.DO_CANNY_PRUNING, new Size(20,20))[0];
                   foreach (var face in faces)
                   {
                       Image&lt;Gray,byte&gt;hasil = image.Copy(face.rect).Convert&lt;Gray,byte&gt;().Resize(100, 100, INTER.CV_INTER_CUBIC);
                           image.Draw(face.rect, new Bgr(Color.Red),3);
                   }
               }

        }

        private void button1_Click(object sender, EventArgs e)
        {
            if (capture == null)
            {
                try
                {
                    capture = new Capture();
                }
                catch
                {
                }
            }
            //jika camera tidak sama dengan null
            if (capture != null)
            {
                if (btn_start.Text == ""Pause"")
                {
                    btn_start.Text = ""Resume"";
                    Application.Idle -= prosesFrame; // mengaktifkan kamera
                }
                else
                {
                    btn_start.Text = ""Pause"";
                    Application.Idle += prosesFrame;
                }


            }

        }

        private void Form1_Load(object sender, EventArgs e)
        {
            haar = new HaarCascade(""haarcascade_frontalface_default.xml"");
        }
    }
}
</code></pre>
",2016-10-22 16:28:04,2016-10-31 11:37:15,viola jones recognize faces with emgucv and C#,<c#><visual-studio-2010><image-processing><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
47366,39957681,2016-10-10 11:54:32,,"<p>I am currently trying to get the CUDA part of EMGU CV working. After the compilation, when I try to run it, I get the error ""Unable to find an entry point named 'cudaCreateLinearFilter' in DLL 'cvextern'. Where cudaCreateLinearFilter can be arbitrarily replaced by any CUDA-related function within EMGU CV. EMGU CV itself works fine tough.</p>

<p>I tried the fix described <a href=""http://www.codeproject.com/Articles/257502/Creating-Your-First-EMGU-Image-Processing-Project"" rel=""nofollow"">here</a> and copied all the mentioned dlls(like cudart64_32_16.dll and opencv_calib3d220.dll) into the Debug folder within the project. Unfortunately this did not work either. </p>

<p>I also replaced all the EMGU dlls already once with a newly downloaded version.</p>

<p>What am I doing wrong?</p>
",2016-10-10 13:52:28,2016-10-11 18:41:30,Unable to find an entry point named '' in DLL 'cvextern',<c#><opencv><dll><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
47384,40000662,2016-10-12 14:02:09,,"<pre><code>using (MemStorage storage = new MemStorage())
{    
    for(Contour&lt;Point&gt;contours=GrayImage.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST, storage);  contours != null; contours = contours.HNext)
    {                  
       CvInvoke.cvDrawContours(CurrentFrame, contours, new MCvScalar(255),newMCvScalar(128), 1, 1, Emgu.CV.CvEnum.LINE_TYPE.EIGHT_CONNECTED, new Point(0, 0));
       Rectangle Rect = CvInvoke.cvBoundingRect(contours, 1);
       currentFrame.Draw(Rect, new Gray(255), 1);
    }
    OutPutImage.Image = CurrentFrame.ToBitmap();                        
}
</code></pre>

<p>I'm new to EmguCV 2.4.0.1717 and i'm having a hard time trying to find and draw convex hull.<br>
In this code i can find and draw the contours and  Bounding Rectangle, what i want to do next is drawing convex hull around the object.</p>

<p><a href=""https://i.stack.imgur.com/m7RET.jpg"" rel=""nofollow"">what I have now</a> </p>
",2016-10-12 15:10:35,2016-10-12 15:10:35,Draw Convex Hull,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
47451,40237738,2016-10-25 10:37:01,,"<p>Is it possible to use this code in capturing a video stream from an ip camera?</p>

<p><code>Capture cap = new Capture(""rtsp://192.168.42.1:554/live"");
imageBox1.Image = cap.QueryFrame();</code></p>

<p>because my image box is displaying nothing but when i tried viewing it to VLC Media Player the ip address worked. Please help.</p>

<p>I also tried it with VLCPlugin v2 instead of using imageBox and the ip address still work..</p>

<p>I also tried it with iSpy and it worked under ffmpeg(h264), maybe the problem is there? I'm using Visual Studio Ultimate 2010, Emgu CV 3.x. and I'm using Please help. Been working on this for long now.</p>
",,2017-02-01 22:51:03,Is it possible to use Emgu CV 3.0 to open a live stream with rstp protocol with ffmpeg h264,<c#><visual-studio-2010><ffmpeg><h.264><emgucv>,,,CC BY-SA 3.0,False,False,True,False,True
47556,40086839,2016-10-17 12:49:47,,"<p>I am using <code>emgu</code> to save uncompressed video. <code>VideoWriter(""video.avi"", 0, (int)FrameRate, frameSize, true);</code> The <code>0</code> value means that the saved video will be uncompressed, see <a href=""http://www.emgu.com/wiki/index.php/Video_Files"" rel=""nofollow"">here</a>. Also, <code>FrameRate</code> aws set to 30.
The <code>Mat</code> file that is stored is:<code>var mat = new Mat(480, 640, Emgu.CV.CvEnum.DepthType.Cv8U, 3)</code>. For a stored video of <code>13994</code> frames, the property window says: <code>9.29 GB (6,449,164,288 bytes)</code>(windows). Now I am trying to verify the video size manually:</p>

<p><code>640*480*3*13994= 12,896,870,400 bytes</code>, twice that window property returns. </p>

<p>Could you please cast some light on this?</p>

<p><strong>MediaInfo information</strong>:</p>

<pre><code>General
Complete name                            : name.avi
Format                                   : AVI
Format/Info                              : Audio Video Interleave
Format profile                           : OpenDML
File size                                : 6.01 GiB
Duration                                 : 7 min 46 s
Overall bit rate                         : 111 Mb/s
Writing application                      : Lavf56.36.100

Video
ID                                       : 0
Format                                   : YUV
Codec ID                                 : I420
Codec ID/Info                            : 8 bit Y plane followed by 8 bit 2x2 subsampled U and V planes.
Duration                                 : 7 min 46 s
Bit rate                                 : 111 Mb/s
Width                                    : 640 pixels
Height                                   : 480 pixels
Display aspect ratio                     : 4:3
Frame rate                               : 30.000 FPS
Compression mode                         : Lossless
Bits/(Pixel*Frame)                       : 12.000
Stream size                              : 6.01 GiB (100%)
</code></pre>

<p>Thanks you.</p>
",2016-10-19 08:23:37,2016-10-21 14:42:32,Compute emgu video size manually,<video><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
47597,40129593,2016-10-19 11:02:25,,"<p>I downloaded Example for EmguCV.</p>

<p>I try to change image from default to my image</p>

<p>On default  it was like this</p>

<pre><code> static void Run()
  {
     var image = new Mat(""lena.jpg"", LoadImageType.Color); //Read the files as an 8-bit Bgr image  
     long detectionTime;
     List&lt;Rectangle&gt; faces = new List&lt;Rectangle&gt;();
     List&lt;Rectangle&gt; eyes = new List&lt;Rectangle&gt;();

     //The cuda cascade classifier doesn't seem to be able to load ""haarcascade_frontalface_default.xml"" file in this release
     //disabling CUDA module for now
     bool tryUseCuda = false;

     DetectFace.Detect(
       image, ""haarcascade_frontalface_default.xml"", ""haarcascade_eye.xml"", 
       faces, eyes,
       tryUseCuda,
       out detectionTime);

     foreach (Rectangle face in faces)
        CvInvoke.Rectangle(image, face, new Bgr(Color.Green).MCvScalar, 2);
     foreach (Rectangle eye in eyes)
        CvInvoke.Rectangle(image, eye, new Bgr(Color.Aquamarine).MCvScalar, 2);

     //display the image 
     ImageViewer.Show(image, String.Format(
        ""Completed face and eye detection using {0} in {1} milliseconds"", 
        (tryUseCuda &amp;&amp; CudaInvoke.HasCuda) ? ""GPU""
        : CvInvoke.UseOpenCL ? ""OpenCL"" 
        : ""CPU"",
        detectionTime));
  }
</code></pre>

<p>}
}</p>

<p>I added change ""lena.jpg"" to my image - ""oleg.jpg"".</p>

<p>I added this image to project folder</p>

<p>Via Add Existing File - oleg.jpg.</p>

<p>But when I run my program it says that 'File oleg.jpg do not exist'</p>

<p>Where is problem?</p>

<p>Thank's for help</p>
",,2017-07-07 18:42:23,Program doesn't find file (EmguCV),<c#><visual-studio><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
47629,40320554,2016-10-29 15:16:47,,"<p>what I need is an <code>Emgu.Cv.Mat</code>. Due to I have an <code>Bitmap</code> I want to pass his information to this Mat instance.</p>

<p>Here is my code:</p>

<pre><code>//the real file is not stored on the harddrive. this is for demonstration only.
Bitmap fileBmp = new Bitmap(@""C:\Users\my\Desktop\file1.PNG""); 
</code></pre>

<p>.</p>

<pre><code>//generating an Image from it works pretty fine as well. Even displaying it works great.
Image&lt;Bgr, Byte&gt; image = new Image&lt;Bgr, Byte&gt;(fileBmp);
</code></pre>

<p>.</p>

<pre><code>//But I'm not able to generate a Mat with it. Not using the Bitmap
Mat mat1 = new Mat(new int[] { fileBmp.Width, fileBmp.Height }, DepthType.Cv8S, fileBmp.GetHbitmap());

//... and not using the Image
Mat mat2 = new Mat(new int[] { fileBmp.Width, fileBmp.Height }, DepthType.Cv8S, image.Bitmap.GetHbitmap());
</code></pre>

<p>I keep getting an </p>

<blockquote>
  <p>System.AccessViolationException</p>
</blockquote>

<p>If I read either <code>mat1.Bitmap</code> property or <code>mat2.Bitmap</code> property (all other properties looking fine).<a href=""https://i.stack.imgur.com/kHD3E.png"" rel=""nofollow""><img src=""https://i.stack.imgur.com/kHD3E.png"" alt=""error""></a> What is wrong with my code?</p>

<p>Any suggestions how I can pass the ""graphic information"" to an <code>Mat</code> using <code>EmguCv</code>? </p>

<p>One again: using <code>new Mat(@""C:\Users\my\Desktop\file1.PNG"")</code> is not possible due to the bitmap is not stored on the hard drive.</p>
",,2016-11-05 13:53:07,System.AccessViolationException while construct Mat using EmguCV,<c#><emgucv><access-violation>,,,CC BY-SA 3.0,False,True,True,False,False
47687,40521505,2016-11-10 06:49:43,,"<p>I'm using EmguCv wrapper for OpenCV to capture live video from IP camera.</p>

<p>I'm trying to get the frame timestamp using the function</p>

<pre><code>Capture _Capture = new Capture(URL);
_Capture.ImageGrabbed += Capture_ImageGrabbed;

private void _Capture_ImageGrabbed(object sender, EventArgs e)
{
   Mat Frame;
   _Capture.Retrieve(Frame);
   double ts = GetCaptureProperty(CapProp.PosMsec);
}
</code></pre>

<p>the function work, but it return the position of the frame from the beggining of the capturing and not the device clock timestamp.</p>

<p>in the <a href=""http://www.emgu.com/wiki/files/2.4.10/document/index.html"" rel=""nofollow noreferrer"">manual of the EmguCV</a> and OpenCV its says:</p>

<blockquote>
  <p>GetCaptureProperty(CV_CAP_PROP_POS_MSEC) is returning the film current position in milliseconds or video capture timestamp</p>
</blockquote>

<p>Is there a way to choose if it will return the film position or the timestamp?</p>

<p>Thanks</p>
",2016-11-10 07:00:42,2016-11-10 07:00:42,Get real timestamp of frame captured using OpenCV,<c#><c++><opencv><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
47720,40398801,2016-11-03 10:10:25,,"<p>I use the imagebox to display a image(imgWidth:19200, imgHeight:260),and my code is:</p>

<pre><code>imageBox = new ImageBox();
imageBox.Size = new Size(imgWidth, imgHeight);
imageBox.Dock = DockStyle.Fill;
MainSplitContainer.Panel1.Controls.Add(imageBox);
imageBox.Image = new Image&lt;Bgr, byte&gt;(""2.bmp"");
</code></pre>

<p>But the displayed image width is only about 15000, and the right part of the image can not be displayed. How can I display the full image?</p>

<p><a href=""https://i.stack.imgur.com/kfuXs.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kfuXs.png"" alt=""enter image description here""></a></p>
",2016-11-03 10:25:46,2017-01-31 22:38:36,c# use emgu imagebox control to display a image,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
47728,40440511,2016-11-05 16:23:07,,"<p>I have two ""contours"" shapes in a array, one contourn is the square that i know his real size, and the other is the mole that i need to make the proportional measurement.
Here is the image example:</p>

<p><a href=""https://i.stack.imgur.com/c7m0A.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/c7m0A.jpg"" alt=""enter image description here""></a></p>

<p>The square has 10x10mm, how can i know the size of the other shape based on the square?</p>

<p>What i tried so far is this:</p>

<pre><code>var molePerimeter = CvInvoke.ArcLength(contours[0], false);
double moleArea = CvInvoke.ContourArea(contours[0], false);
var squarePerimeter = CvInvoke.ArcLength(squares[0], true);
double squareArea = CvInvoke.ContourArea(squares[0], false);
textBox2.AppendText(""Area: "" + squareArea / moleArea);
textBox2.AppendText(""perimeter: "" + squarePerimeter / molePerimeter);
</code></pre>

<p>But i dont thinks that is corret.</p>
",,2016-11-05 16:44:22,Measure real size of irregular shapes in picture,<opencv><math><shape><emgucv><measurement>,,,CC BY-SA 3.0,True,False,True,False,False
47737,40522966,2016-11-10 08:26:43,,"<p>I am trying to create an interactive boardgame in Unity, using hand gestures to activate mechanics. The game will be projected on a table with a camera attached next to it, which will be used to capture motion. </p>

<p>The game consists of two grids, one 30x30 hidden tile grid, with a map grid on top of it. </p>

<p><strong>My question is then:</strong> What is the smartest way to go around synchronizing the camera with the hidden tile grid, so I can see if a detected BLOB from my EmguCV is on top of set tile?</p>

<p><strong>I've considered:</strong></p>

<ul>
<li>Creating another tilemap for the camera, and check if the tile number
in both   tilemaps are equal to eachother.</li>
<li>Check if tile center position is close to blob center position, using
Unitys method Vector2.Distance</li>
</ul>
",,2016-11-10 08:26:43,Creating a connection between EmguCV and my projected gameboard,<c#><unity3d><emgucv><aforge>,,,CC BY-SA 3.0,False,False,True,False,False
47770,40288204,2016-10-27 15:08:52,,"<p>I just installed the Affectiva SDK on my Surface tablet, and I am now trying to use the SDK in an application. The camera starts, the light is on, but I do not receive any onImageCapture, or any onImageResults. Does anyone have any ideas on what to do to see why this happens?</p>

<p>Note: I used EMGU 3 library and with that, I can open the camera and see frames. So the camera works.</p>

<p>Best regards.</p>
",,2016-10-27 15:08:52,Affdex CameraDetector does not process frames,<.net><emgucv><affdex-sdk>,,,CC BY-SA 3.0,False,False,True,False,False
47777,40264730,2016-10-26 14:17:14,,"<p>Hi what I'm trying to do is assigning an <code>Emgu.CV.Mat</code> to an <code>Emgu.CV.UI.ImageBox</code> but I keep getting an <code>System.AccessViolationException</code> error within the <code>CvInvokeCore.cs</code> file (Line 2379 <code>            cveMinMaxLoc(iaArr, ref minVal, ref maxVal, ref minLoc, ref maxLoc, iaMask);</code>):</p>
<blockquote>
<p>An unhandled exception of type 'System.AccessViolationException' occurred in Emgu.CV.World.dll</p>
<p>Additional information: Attempted to read or write protected memory. This is often an indication that other memory is corrupt.</p>
</blockquote>
<p>The Code is pretty simple. I generate an Bitmap</p>
<pre><code>Bitmap tmp = mybitmap.getBitmap(); // generates my Bitmap
pictureBox1.Image = tmp; // assigning it to an Win Form picture Box works pretty fine

imageBox1.Image = ConvertBitmapToMat(tmp); // but converting the Bitmap to an Mat file 
                                           // and try to assign it to an 
                                           // Emgu.CV.UI.ImageBox throws the
                                           // error in the above mentioned file.
</code></pre>
<p>The <code>ConvertBitmapToMat()</code> code I used is:</p>
<pre><code>public Mat ConvertBitmapToMat(Bitmap bmp)
{
   // Lock the bitmap's bits.  
    Rectangle rect = new Rectangle(0, 0, bmp.Width, bmp.Height);

    System.Drawing.Imaging.BitmapData bmpData =
        bmp.LockBits(rect, System.Drawing.Imaging.ImageLockMode.ReadWrite,
            bmp.PixelFormat);

    // data = scan0 is a pointer to our memory block.
    IntPtr data = bmpData.Scan0;

    // step = stride = amount of bytes for a single line of the image
    int step = bmpData.Stride;

    // So you can try to get you Mat instance like this:
    Mat mat = new Mat(bmp.Height, bmp.Width, Emgu.CV.CvEnum.DepthType.Cv32F, 4, data, step);

    // Unlock the bits.
    bmp.UnlockBits(bmpData);

    return mat;
}
</code></pre>
<p>found at <a href=""http://avidprogrammer.blogspot.de/2016/05/emgucv-c-convert-bitmap-object-to-mat.html"" rel=""nofollow noreferrer"">http://avidprogrammer.blogspot.de/2016/05/emgucv-c-convert-bitmap-object-to-mat.html</a></p>
<p>Any suggestions on this?</p>
",2020-06-20 09:12:55,2016-10-31 06:23:36,'System.AccessViolationException' while assigning `Emgu.CV.Mat` to `Emgu.CV.UI.ImageBox` (Emgu),<c#><emgucv><access-violation><mat>,,,CC BY-SA 3.0,False,True,True,False,False
47803,40485668,2016-11-08 11:24:10,,"<p>I am using <strong>EmguCV 3.1.0</strong> library, by using this i am fetching the frames as shown below...</p>

<p><strong>_capture.SetCaptureProperty(Emgu.CV.CvEnum.CapProp.PosMsec, 17.567);</strong></p>

<p><strong>Image""&lt;""Bgr, Byte"">"" frame = captureData.QueryFrame().ToImage""&lt;""Bgr, Byte"">""();</strong></p>

<p><strong>pictureBox1.Image = frame.ToBitmap();</strong></p>

<p>in the above piece of code 17.567 is the time of the video frame. i am fetching the video frame with the help of time and we are displaying on picturebox control.
so here SetCaptureProperty function taking long time to fetch frame from the HD video. due to that the performance got reduced....</p>

<p>Please ignore the double quotes in source code...</p>

<p>can you please help in this...
thanks in advance...</p>
",,2016-11-08 11:24:10,Regarding Frame extraction from the HD Video with the help of time(in the form of seconds as shown below) of the Video position,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
47810,40290631,2016-10-27 17:16:53,,"<p>Argument 1: cannot convert from 'Emgu.CV.Matrix' to 'int'    </p>

<p>Anyone can help me?</p>

<p>i have tried to Convert.ToInt16(rsmmatrixtanimlayici) it's not working.</p>
",,2016-10-28 13:03:32,C# Emgu.Cv.Matrix<Float> to int,<c#><computer-vision><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
47887,40453139,2016-11-06 18:44:58,,"<p>I have a situation where i find some contours that result in a square, this is square is not in a 90º angle. How can i transform it for measure his Width and Height?</p>

<p>here is a example image:
<a href=""https://i.stack.imgur.com/k53ET.jpg"" rel=""nofollow noreferrer"">square detected</a></p>

<p>And here is my code that draw the Square:</p>

<pre><code>CvInvoke.Polylines(copyImg, squares[i], true, new MCvScalar(0, 255, 0), 1, LineType.FourConnected);
</code></pre>
",,2016-11-06 18:44:58,"Measure Square (width, height)",<opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
47901,40412121,2016-11-03 22:14:22,,"<p>I am using EmguCV 3.1.0.2282 and I found that when I use an image, there are times when it doesn't release its resources and eats up memory until the PC is out of resources and an out of memory exception is thrown.</p>

<p>Here is a test code I did within my application. When the button is clicked, a new local image is instantiated based on an existing bitmap in memory. It will do a manual dispose if the checkbox is checked.</p>

<pre><code>    private void button1_Click(object sender, EventArgs e)
    {
        Image&lt;Bgr, Byte&gt; TempImage = new Image&lt;Bgr, Byte&gt;(CurrentLeftBitmap);
        TempImage.ThresholdBinary(new Bgr(2.2, 3.3, 4.4), new Bgr(100.0, 100.0, 100.0));            
        if (checkBox1.Checked)
        {
            TempImage.Dispose();
            TempImage = null;
        }
    }   
</code></pre>

<p>I found each time I click on the button, memory goes down and won't be released without an application restart. Even when I do a manual dispose, memory still goes down. Funny thing is that if I commented out the ThresholdBinary step, it works fine. However, it still requires a manual dispose. I've also tried the USING statement but still the same.</p>

<p>My question is that has anyone encounter something similar? What is the proper way of implementing these image objects?</p>
",,2016-11-08 03:41:52,Images in EmguCV not releasing resources,<c#><memory-leaks><garbage-collection><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
47954,40384487,2016-11-02 16:03:16,,"<p>As titled. I am having a problem of converting System.Drawing.Image to Emgu.CV.Mat
I tried to covert it from Drawing.Image to CV.Image but keep having Exceptions. </p>

<p>Is there any other solution available? Any help render is kindly appreciated.</p>
",,2016-11-05 13:49:58,System.Drawing.Image to Emgu.CV.Mat,<c#><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
48014,40389148,2016-11-02 20:25:21,,"<p>I'm programming in C#(WindowsForm). I want to use EmguCV(3.1) to capture an .avi file. When I load a file I see this exception:</p>
<blockquote>
<p>An unhandled exception of type 'System.AccessViolationException' occurred in System.Drawing.dll</p>
<p>Additional information: Attempted to read or write protected memory. This is often an indication that other memory is corrupt.</p>
</blockquote>
<p>After this exception I see this window:</p>
<p><a href=""https://i.stack.imgur.com/JxL4t.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JxL4t.jpg"" alt=""enter image description here"" /></a></p>
<p>Here is my code to load a file:</p>
<pre><code>private void LoadVideoFromFile()
{
    OpenFileDialog d = new OpenFileDialog();
    d.ShowDialog();

    _capture = new Emgu.CV.Capture(d.FileName);
    _capture.ImageGrabbed += ProcessFrame;
}
</code></pre>
<p>And here is my code for showing avi file:</p>
<pre><code>private void ProcessFrame(object sender, EventArgs arg)
{            
    Action a = () =&gt;
        {
            UMat captured = new UMat();
            Boolean cap = _capture.Retrieve(captured);

            pictureBox1.Image = captured.Bitmap;
        };

    pictureBox1.Invoke(a);
}
</code></pre>
",2020-06-20 09:12:55,2016-11-19 01:15:39,AccessViolationException in EmguCV(3.x) while capturing,<c#><emgucv><access-violation>,,,CC BY-SA 3.0,False,False,True,False,False
48038,40605631,2016-11-15 08:57:47,,"<p>Im trying to use EmguCV to do some image processing with MonoDevelop. I can build the project but if I try to debug/run it from inside MonoDevelop, I get a <code>DllNotFoundException</code> saying it cannot find libdl.so. If I run the compiled program directly (with <code>mono emgucv_test.exe</code>) everything works fine.<br>
This is a console app, I got very similar behaviour for a Gtk# test project where it said, it couldnt find libgdiplus.so. I can find both libs however with <code>ldconfig -p |grep libgdiplus</code>.<br>
All of this leads me to believe, that this is neither a problem with missing libs, EmguCV/OpenCV nor mono but with MonoDevelop.</p>

<p>I tried setting the <code>LD_LIBRARY_PATH</code> environment variable in the projects run configuration, that didn't help. I was unable to find anything related online and don't know what else I could try. What is the problem and how can I fix this? This is just a test app, for the real project Im going to need to be able to properly debug with MonoDevelop.</p>

<p>Im running MonoDevelop 6.1.1 (flatpak version) in Lubuntu 16.10 (also tested in Ubuntu 16.04) in a VirtualBox VM and I installed the latest mono (v4.6.1).  </p>

<p><strong>Update</strong><br>
I just tested this with MonoDevelop installed with the <code>monodevelop</code> package (version 5.10). With this it works.<br>
I know nothing about flatpak, but I've read somewhere, that it is kind of a sandbox environment for apps. If this is true, could the problems I experience be due to this?</p>
",2016-11-15 15:49:37,2016-11-21 17:42:12,MonoDevelop unable to find shared libs on (L)Ubuntu,<c#><opencv><ubuntu><monodevelop><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
48150,40617224,2016-11-15 18:33:30,,"<p>I already have the code done but I think there's still improvement on my code.</p>

<p><strong>This is what I want to find:</strong></p>

<p>A square with 4 colors on each quadrant. The background is gray.</p>

<p><a href=""https://i.stack.imgur.com/CXKoQ.png"" rel=""nofollow noreferrer"">What I want to find</a></p>

<p><strong>This is my implementation:</strong></p>

<p>frame_drone is the image frame.</p>

<p>My implementation:</p>

<ul>
<li>PyrDown, PyrUp</li>
<li>SmoothGaussian(3)</li>
<li>Convert</li>
<li>Threshold Hsv -> Hsv.InRange(H,S,V)</li>
<li>Threshold HSV Dilate 3</li>
<li>Threshold HSV Erode 1</li>
<li>Threshold HSV.Canny (50,150)</li>
<li>Canny.SmoothGaussian(5)</li>
<li>Find contours of Canny</li>
<li>If CurrentContour.Area > 2500</li>
<li>If CurrentContour.Total = 4 //square</li>
<li>Find the angle of the edges.</li>
<li>If Angle is between 75 and 105 is square</li>
<li>Get the color of each quadrant.</li>
<li>Determine if it's red,blue,green or yellow using Hue <strong>//is this right or wrong??</strong></li>
</ul>

<p><strong>This is my Code (Dont look at the commented code):</strong></p>

<pre><code>       public void quadrado()
    {
        #region Encontrar Quadrados        



        //int erosao = 4;
        // int dilatacao = 1;
        increamenta_listagem_quadrados = 0;
        tamanho_imagem.X = frame_drone.Width;
        tamanho_imagem.Y = frame_drone.Height;

        // elemento_erosao = new StructuringElementEx(erosao, erosao, 1, 1, Emgu.CV.CvEnum.CV_ELEMENT_SHAPE.CV_SHAPE_RECT); //elemento kernelx,kernely,anchorx,anchory
        //elemento_dilatacao = new StructuringElementEx(dilatacao, dilatacao, 1, 1, Emgu.CV.CvEnum.CV_ELEMENT_SHAPE.CV_SHAPE_RECT); //elemento kernelx,kernely,anchorx,anchory            

        frame_drone = frame_drone.PyrDown().PyrUp();
        frame_drone = frame_drone.SmoothGaussian(3); //Filtro mediana antes da passagem para HSV
        frame_drone_hsv = frame_drone.Convert&lt;Hsv, Byte&gt;(); //Converte a imagem da camera RGB para HSV
        // CvInvoke.cvCvtColor(frame_drone_hsv, frame_drone_hsv, COLOR_CONVERSION.BGR2HSV);
        //frame_drone_hsv = frame_drone.Convert&lt;Hsv, Byte&gt;();
        frame_drone_threshold_hsv = frame_drone_hsv.InRange(new Hsv(hl.Value, sl.Value, vl.Value), new Hsv(hh.Value, sh.Value, vh.Value)); //utiliza as trackbars HSV para ver a cor pretendida 
        //frame_drone_hsv.Split();


        //frame_drone_gray = frame_drone.Convert&lt;Gray, Byte&gt;().PyrDown().PyrUp(); //Bgr para Gray
        //frame_drone_threshold_gray = frame_drone_gray.ThresholdBinary(new Gray(150), new Gray(255)); //Threshold para mostrar apenas partes escuras (quadrados)
        //frame_drone_threshold_gray = frame_drone_threshold_gray.Dilate(2);
        //Dilatacao seguida de erosao para fechar o ruido (Origina o Fecho de Buracos nas Regiões e a Eliminação de Baías nos limites da regiões)
        //CvInvoke.cvDilate(frame_drone_threshold_hsv, frame_drone_threshold_hsv, elemento_dilatacao, 1);
        //CvInvoke.cvErode(frame_drone_threshold_hsv, frame_drone_threshold_hsv, elemento_erosao, 1);

        frame_drone_threshold_hsv = frame_drone_threshold_hsv.Dilate(3);
        frame_drone_threshold_hsv =  frame_drone_threshold_hsv.Erode(1);

        //Erosao seguida de dilatacao (Retira pequenas porções ou regiões que saem dos limites)
        //CvInvoke.cvErode(frame_drone_processado, frame_drone_processado, elemento_erosao, 1);
        // CvInvoke.cvDilate(frame_drone_processado, frame_drone_processado, elemento_dilatacao, 1);

        frame_drone_gray = frame_drone.Convert&lt;Gray, Byte&gt;();
        //frame_drone_gray = frame_drone_gray.SmoothGaussian(9); //Filtro gaussiano na imagem binaria        

        frame_drone_canny = frame_drone_threshold_hsv.Canny(50,150); //Canny
        frame_drone_canny = frame_drone_canny.SmoothGaussian(5);
        // CvInvoke.cvDilate(frame_drone_canny, frame_drone_canny, elemento_dilatacao, 1); //Dilatação ao canny
        //frame_drone_threshold_hsv_circulo = frame_drone_gray.ThresholdBinaryInv(new Gray(trackBar1.Value), new Gray(255));          
        frame_drone_threshold_hsv_circulo = frame_drone_hsv.InRange(new Hsv(0, 80, 40), new Hsv(22, 248, 251)); //laranja
        //frame_drone_threshold_hsv_circulo = frame_drone_hsv.InRange(new Hsv(0, 0, 0), new Hsv(0, 0, 0));
        frame_drone_threshold_hsv_circulo = frame_drone_threshold_hsv_circulo.Dilate(6);
        frame_drone_threshold_hsv_circulo = frame_drone_threshold_hsv_circulo.Erode(6);
        frame_drone_threshold_hsv_circulo = frame_drone_threshold_hsv_circulo.SmoothGaussian(15);

        frame_drone_copia = frame_drone.Copy(); //copia a imagem original para evitar pixeis escritos na imagem

        #region Extração de contornos
        using (MemStorage storage = new MemStorage()) //aloca espaço na memoria
        {


            //detecao_circulo_em_quadrado(); //procura por circulos no quadrado

            //Procura contornos 
            for (Contour&lt;System.Drawing.Point&gt; contours = frame_drone_canny.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_TREE, storage); contours != null; contours = contours.HNext)
            {

                Contour&lt;System.Drawing.Point&gt; currentContour = contours.ApproxPoly(contours.Perimeter * 0.05, storage); //AproxContour                       
                // MCvMoments moments; //inicializacao
                 // moments = currentContour.GetMoments(); // momentos

                //Cria letra
                MCvFont f = new MCvFont(FONT.CV_FONT_HERSHEY_COMPLEX, 0.8, 0.8);

                // centroid = new System.Drawing.Point((int)(moments.m10 / moments.m00), (int)(moments.m01 / moments.m00)); //calculo do centroid

                if (currentContour.Area &gt; 2500/*currentContour.Area &gt;= area_contornos_min.Value &amp;&amp; currentContour.Area &lt;= area_contornos_max.Value*/) //se a area estiver dentro dos valores das trackbars
                {

                    if (currentContour.Total == 4) //se for retangulo/quadrado
                    {
                        // string area_contornos = contours.Area.ToString();
                        //string perimetro_contornos = contours.Perimeter.ToString();

                        bool retangular = true;

                        //frame_drone.Draw("""" + area_contornos.Substring(0,5),ref f, new Point(centroid.X, centroid.Y),new Bgr(Color.Black));
                        //frame_drone.Draw("""" + perimetro_contornos.Substring(0,5), ref f, new Point(centroid.X, centroid.Y), new Bgr(Color.Black));



                        Point[] pontos = currentContour.ToArray(); //pontos para array
                        LineSegment2D[] edges = PointCollection.PolyLine(pontos, true);

                        for (int i = 0; i &lt; edges.Length; i++)
                        {
                            double angulo = Math.Abs(edges[(i + 1) % edges.Length].GetExteriorAngleDegree(edges[i]));
                            if (angulo &lt; 75 || angulo &gt; 105) //Limitação do angulo para determinar se é quadrado ou nao
                            {
                               retangular = false; //não é quadrado
                               quadrado_detetado = 0;
                               lv_lista_quadrados.Items.Clear();
                               //increamenta_listagem_quadrados = 0;
                               posicao_atual = new PointF(0, 0);

                            }
                            if (retangular)
                            {
                                increamenta_listagem_quadrados++;                                  
                                centroid.X = (int)currentContour.GetMoments().GravityCenter.x;
                                centroid.Y = (int)currentContour.GetMoments().GravityCenter.y;


                                List&lt;Point&gt; pontos_quadrado = new List&lt;Point&gt;()
                                    {
                                        pontos[0],
                                        pontos[1],
                                        pontos[2],
                                        pontos[3]
                                    };

                                pontos_quadrado = pontos_quadrado.OrderBy(x =&gt; Math.Pow(x.X, 2) + Math.Pow(x.Y, 2)).ToList(); //reorganiza a lista de pontos por distancia a um canto da imagem


                                if (centroid.X &gt; tamanho_imagem.X || centroid.X &lt; 0 || centroid.Y &gt; tamanho_imagem.Y || centroid.Y &lt; 0)
                                {
                                    centroid.X = 0;
                                    centroid.Y = 0;
                                }


                                for (int vertices = 0; vertices &lt;= 3; vertices++) //Numero de vertices da forma (quadrado)
                                {
                                    frame_drone.Draw(new CircleF(pontos_quadrado[vertices], 1), new Bgr(Color.Yellow), 10); //Mostra os vertices a amarelo
                                    //frame_drone.Draw("""" + pontos[vertices].X + "","" + pontos[vertices].Y, ref f, pontos[vertices], new Bgr(Color.Black)); //Escrever na imagem as coordenadas dos vertices  
                                    frame_drone.Draw(""V"" +vertices, ref f, pontos_quadrado[vertices], new Bgr(Color.Black));
                                    //treeview_contornos.Nodes[0].Nodes[0].Nodes.Add("""" + vertices + "":"" + """" + pontos[vertices].X + "","" + pontos[vertices].Y); //Adiciona os vertices à treeview


                                    //Calcular os pontos médios
                                    int ponto_medio_x;
                                    int ponto_medio_y;

                                    PointF ponto_medio_circulo = new PointF(0,0);
                                    ponto_medio_circulo.X = (pontos_quadrado[vertices].X + centroid.X) / 2;
                                    ponto_medio_circulo.Y = (pontos_quadrado[vertices].Y + centroid.Y) / 2;

                                    //utiliza pontos perto do centroide do quadrado para ver as cores
                                    ponto_medio_x = ((pontos_quadrado[vertices].X - centroid.X) / 4) +centroid.X;
                                    ponto_medio_y = ((pontos_quadrado[vertices].Y - centroid.Y) / 4) + centroid.Y;

                                    array_pontos_medios[vertices] = new PointF(ponto_medio_x, ponto_medio_y);


                                    frame_drone.Draw(new CircleF(new Point(ponto_medio_x, ponto_medio_y), 1), new Bgr(Color.LightYellow), 7); //Desenha os pontos (quadrantes)
                                    frame_drone.Draw(new CircleF(new Point((int)ponto_medio_circulo.X, (int)ponto_medio_circulo.Y), 1), new Bgr(Color.Pink), 7); //Desenha os pontos médios (quadrantes)



                                    Color obter_cor_pixel = frame_drone_copia.Bitmap.GetPixel(ponto_medio_x, ponto_medio_y); //obtem cor do pixel no ponto médio
                                                                                                                             //RGB para HSV

                                    Color obter_cor_circulo = frame_drone_copia.Bitmap.GetPixel((int)ponto_medio_circulo.X, (int)ponto_medio_circulo.Y); //obtem cor do pixel no ponto médio
                                                                                                                                                         //RGB para HSV



                                    if(obter_cor_circulo.G &lt; 5 &amp;&amp; obter_cor_circulo.R &lt; 5 &amp;&amp; obter_cor_circulo.B &lt;5 )
                                    {
                                        frame_drone.Draw(""Circulo"", ref f, new System.Drawing.Point((int)ponto_medio_circulo.X, (int)ponto_medio_circulo.Y), new Bgr(Color.White));
                                        //utiliza o centroid onde encontrou o ponto preto para o centroid do circulo
                                        centroide_circulo.X = (int)ponto_medio_circulo.X;
                                        centroide_circulo.Y = (int)ponto_medio_circulo.Y;
                                    }

                                    //float huecirculo = obter_cor_circulo.GetHue();
                                    //float saturacaocirculo = obter_cor_circulo.GetSaturation();
                                    //float luminusidadecirculo = obter_cor_circulo.GetBrightness();

                                    float hue = obter_cor_pixel.GetHue();
                                    float saturacao = obter_cor_pixel.GetSaturation();
                                    float luminusidade = obter_cor_pixel.GetBrightness();


                                    //if(huecirculo &gt; 300 &amp;&amp; huecirculo &lt; 350)
                                    //{
                                    //    frame_drone.Draw(""Circulo"", ref f, new System.Drawing.Point((int)ponto_medio_circulo.X, (int)ponto_medio_circulo.Y), new Bgr(Color.White)); //Escrever na imagem a cor no ponto medio    
                                    //}

                                    if (hue &gt; 160 &amp;&amp; hue &lt; 250)
                                    {
                                        frame_drone.Draw(""Azul"", ref f, new System.Drawing.Point(ponto_medio_x, ponto_medio_y), new Bgr(Color.White)); //Escrever na imagem a cor no ponto medio                                                                                    
                                        cores_dos_pontos_medios[incrementa_ponto_medio] = ""Azul"";
                                    }
                                    else if (hue &gt; 60 &amp;&amp; hue &lt;= 160)
                                    {
                                        frame_drone.Draw(""Verde"", ref f, new System.Drawing.Point(ponto_medio_x, ponto_medio_y), new Bgr(Color.White)); //Escrever na imagem a cor no ponto medio           
                                        cores_dos_pontos_medios[incrementa_ponto_medio] = ""Verde"";
                                    }
                                    else if (hue &gt;= 0 &amp;&amp; hue &lt;= 65)
                                    {
                                        frame_drone.Draw(""Amarelo"", ref f, new System.Drawing.Point(ponto_medio_x, ponto_medio_y), new Bgr(Color.White)); //Escrever na imagem a cor no ponto medio           
                                        cores_dos_pontos_medios[incrementa_ponto_medio] = ""Amarelo"";
                                    }
                                    else if ((hue &gt;= 0 &amp;&amp; hue &lt;= 30) || (hue &gt; 330 &amp;&amp; hue &lt;= 360))
                                    {
                                        frame_drone.Draw(""Vermelho"", ref f, new System.Drawing.Point(ponto_medio_x, ponto_medio_y), new Bgr(Color.White)); //Escrever na imagem a cor no ponto medio           
                                        cores_dos_pontos_medios[incrementa_ponto_medio] = ""Vermelho"";
                                    }

                                    incrementa_ponto_medio++;
                                    if (incrementa_ponto_medio == 4)
                                    {
                                        incrementa_ponto_medio = 0;
                                    }

                                }
</code></pre>

<p><strong>This is the result:</strong></p>

<p><a href=""https://i.stack.imgur.com/7lTrG.png"" rel=""nofollow noreferrer"">Result</a></p>

<p><strong>My conclusion:</strong></p>

<p><strong>The threshold and the square finding is not ideal</strong>. It works if the illumation it PERFECT. <strong>If it's not the best but still good</strong>, it cant threshold only the square well.</p>

<p><strong><em>What can I do to improve my square finding? Is there another kind of implementation?</em></strong></p>
",,2016-11-15 18:33:30,C# EmguCV/OpenCV Find Square Implementation,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
48162,40656077,2016-11-17 13:22:45,,"<p>I am making a project where I want to re-identify person based on their soft features like cloth color. So I want to get the <strong>HSV and RGB histogram</strong> of their images and compare it later to check if it is the same person.</p>

<p><strong>Code</strong> i made so far:</p>

<pre><code>//This is small part of the project
        float[] hueHists=new float[255];
        float[] satHists = new float[255];


        DenseHistogram dh = new DenseHistogram(255, new RangeF(0, 255));
        DenseHistogram dh2 = new DenseHistogram(255,new RangeF(0, 255));
        Image&lt;Hsv, byte&gt; hsvImage = image.Convert&lt;Hsv, byte&gt;();

        for (int i = 0; i &lt; 8; i++)
        {
            hsvImage.ROI = new Rectangle(0, i * 16, 64, 16);

            Image&lt;Gray, byte&gt;[] channels = hsvImage.Copy().Split();
            Image&lt;Gray, byte&gt; hue = channels[0];  
            Image&lt;Gray, byte&gt; sat = channels[1];  


            dh.Calculate&lt;byte&gt;(new Image&lt;Gray, byte&gt;[] { hue }, true, null);
            dh2.Calculate&lt;byte&gt;(new Image&lt;Gray, byte&gt;[] { sat }, true, null);

            float[] huehist = dh.GetBinValues();
            float[] sathist = dh2.GetBinValues();

            if(i==0)
            {
                huehist.CopyTo(hueHists,0);
                sathist.CopyTo(satHists,0);
            }
            else
            {
                hueHists = hueHists.Concat&lt;float&gt;(huehist).ToArray&lt;float&gt;();
                satHists = satHists.Concat&lt;float&gt;(sathist).ToArray&lt;float&gt;();
            }

        }
</code></pre>

<p>And also should I extract HSV and RGB histogram of complete image or extract after segmentation of image.</p>

<p><strong>[Edit]</strong>
I have extracted the histogram of a personA and matched it against other people's histogram (to check if he/she is personA or not). 
<strong>Problem</strong>  the problem is with accuracy. my program can not correctly find same person. And I want to ask the better way to do it...</p>

<p>Help from opencv person is also appreciated </p>

<p><strong>Thanks</strong> in advance.</p>
",2016-11-17 14:38:16,2016-11-17 14:38:16,How to extract HSV histogram from image. [EmguCV],<c#><opencv><image-processing><emgucv><surveillance>,,,CC BY-SA 3.0,True,False,True,False,False
48174,40772274,2016-11-23 18:59:13,,"<p>I have the the following code in a normal windows form application with EmguCV 3.1</p>

<pre><code>    public Form1()
    {
        InitializeComponent();
        _capture = new Capture(""http://root:pass@192.168.1.27:80/axis-cgi/mjpg/video.cgi"");
        _capture.ImageGrabbed += ProcessFrame;
    }

    private void Form1_Load(object sender, EventArgs e)
    {
        _capture.Start();
    }

    private void ProcessFrame(object sender, EventArgs e)
    {
        Mat image = new Mat();
        _capture.Retrieve(image);
        imageBox1.BackgroundImage = image.Bitmap;

    }
</code></pre>

<p>I have tested the above link in a browser it worked, I have also tested this using iSpy it also works there but using EmguCV ProcessFrame is never reached</p>

<p>I have also tried to connect to the camera using Luxand and it worked well but Luxand is not free so I have to use EmguCV to do face detection &amp; recognition</p>
",,2016-11-30 21:33:50,EmguCV not reading camera,<c#><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
48238,40735479,2016-11-22 06:50:55,,"<p>I am using Emgu in Xamarin App.
 Xamarin dlls are 48.6 MB and Emgu dll is 62 MB. Totally
 around 110 MB. Which is more than the android play store size of 100MB. How do people submit Xamarin Android app with Emgu Integrated to Google play store. </p>
",,2016-11-22 06:54:55,Reducing the size of the Xamarin Android App with Emgu library,<xamarin><xamarin.android><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
48274,40779833,2016-11-24 06:57:58,,"<p>Does EmguCV provide any built-in function for converting a color image into RG Chromaticity (<a href=""https://en.wikipedia.org/wiki/Rg_chromaticity"" rel=""nofollow noreferrer"">see Wikipedia link</a>)   ?</p>
<p>Thanks in advance.</p>
",2020-06-20 09:12:55,2016-11-30 13:34:46,EmguCV - Convert color image to rg chromaticity,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
48306,40821708,2016-11-26 18:33:17,,"<p>i want to store uncompressed frames from a device as a video, but i need to know how to choose "" Full Frames (Uncompressed) "" as a codec for the VideoWriter (in emgu aka openCV).</p>

<p>Iam able to choose it from the dropdown menu when iam passing -1 like this</p>

<pre><code>VideoWriter myVideoWriter = new VideoWriter (""myVieoColor.avi"", -1 , 15, videoSize, true);
</code></pre>

<p>But i want to choose the Full Frames (Uncompressed) codec automatically.
For example i know i can choose the Lagarith Lossless Video Codec by </p>

<pre><code>VideoWriter myVideoWriter = new VideoWriter (""myVieoColor.avi"", Emgu.CV.VideoWriter.Fourcc('L','A','G','S') , 15, videoSize, true);
</code></pre>

<p>but iam not able to figure out which fourcc i need to use.</p>

<p>Perhaps someone can help me out please</p>
",2016-12-05 14:31:37,2017-09-05 18:58:43,How to choose Full Frames (Uncompressed) as codec for VideoWriter,<opencv><kinect><video-capture><emgucv><codec>,,,CC BY-SA 3.0,True,False,True,False,False
48321,40707844,2016-11-20 18:34:04,,"<p><strong>Hi, I'm using EmguCV 3.1 for C# and I'd like to know where is the difference between <a href=""http://www.emgu.com/wiki/files/3.1.0/document/html/1b8e2536-14cd-678d-197d-e0a4533a82b4.htm"" rel=""noreferrer"">Capture.Retrieve</a> and <a href=""http://www.emgu.com/wiki/files/3.1.0/document/html/8dfb0679-4c54-4f17-37ba-7218cbd28e67.htm"" rel=""noreferrer"">Capture.QueryFrame</a>?</strong> And why are there two methods to get the same image (since emgu is only a wrapper for opencv and in opencv VideoCapture has only retrieve to get the image (read is a combination of grab + retrieve and >> is read in other notation))</p>

<p>I've tried to find a difference using <code>Capture.ImageGrabbed</code> event and a own thread with <code>Capture.Grab</code> + <code>Capture.Retrieve</code> / Capture.QueryFrame in following combinations but it seems there is no difference at all. Same framerate, size, color depth..</p>

<ul>
<li>ImageGrabbed: Retrieve(mat,0) results in a colored image</li>
<li>ImageGrabbed: Retrieve(mat,1) results in a colored image, too</li>
<li>ImageGrabbed: QueryFrame results in a StackOverflowException (for whatever reason)</li>
<li>Thread: Grab + Retrieve results in a colored image</li>
<li>Thread: QueryFrame results in a colored image</li>
</ul>

<p>But no difference seen yet. Anyone an idea?</p>
",2017-02-22 09:15:33,2017-02-22 09:15:33,"What is the difference between Retrieve vs QueryFrame, EmguCV",<c#><image-processing><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
48371,40745276,2016-11-22 15:06:14,,"<p>I was wondering if EmguCV provides any function for detecting (just detecting, not correcting) the number of pixels with noise within an image</p>

<p>Take this picture for example : <a href=""http://www-labs.iro.umontreal.ca/~mignotte/ResearchMaterial/SIMPAR-Denoising/zelda512-NoiseV400.gif"" rel=""nofollow noreferrer"">http://www-labs.iro.umontreal.ca/~mignotte/ResearchMaterial/SIMPAR-Denoising/zelda512-NoiseV400.gif</a>  , whose size is 512x512 (or 262,144 pixels).  </p>

<p>Would it be possible to get the total number of noisy pixels ? i.e 150,321 noisy pixels out of 262,144 total pixels.</p>

<p>What approach do you suggest ?</p>

<p>Thanks in Advance.</p>
",2016-11-23 01:05:13,2016-11-23 01:05:13,How to identify pixels with noise,<c#><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
48380,40789457,2016-11-24 14:56:21,,"<p>I am working in Unity and trying to make a grid and camera sync.</p>

<p>To achieve this, I'm using the EmguCV/OpenCV method HomographyFind: <a href=""http://www.emgu.com/wiki/files/1.4.0.0/html/3906193c-e458-2cb5-7667-fbb94114d179.htm"" rel=""nofollow noreferrer"">http://www.emgu.com/wiki/files/1.4.0.0/html/3906193c-e458-2cb5-7667-fbb94114d179.htm</a></p>

<p>My calibration function looks like the following:</p>

<pre><code> Matrix&lt;float&gt; homography = new Matrix&lt;float&gt;(3, 3);
    float[,] sourcePoints;
    float[,] destPoints;
    void Calibrate()
    {
        sourcePoints = new float[,]{{Cam.greenRect[0].X, Cam.greenRect[0].Y}, {Cam.greenRect[1].X, Cam.greenRect[1].Y}, {Cam.greenRect[2].X, Cam.greenRect[2].Y}, {Cam.greenRect[3].X, Cam.greenRect[3].Y}};
        destPoints = new float[,] { { goTile[0].transform.position.x, goTile[0].transform.position.y }, { goTile[32].transform.position.x, goTile[32].transform.position.y }, { goTile[858].transform.position.x, goTile[858].transform.position.y }, { goTile[890].transform.position.x, goTile[890].transform.position.y } };
        Emgu.CV.Matrix&lt;float&gt; sourceMat = new Matrix&lt;float&gt;(sourcePoints);
        Emgu.CV.Matrix&lt;float&gt; destMat = new Matrix&lt;float&gt;(destPoints);

        CvInvoke.FindHomography(sourceMat, destMat, homography, Emgu.CV.CvEnum.HomographyMethod.Default);
        call.GetComponent&lt;Text&gt;();
        call.text = destPoints[3,0].ToString();

        calibrationComplete = true;

    }
</code></pre>

<p>Cam.greenRect and goTile values seem to fit, but all positions in my homography seems to be 0. </p>

<p>Reasoned this, my Unity translation also returns 0 (Vector2): </p>

<pre><code>Vector2 coordToUnity(Vector2 fingerPos)
    {
        float x = (fingerPos.x * homography.Data[0, 0]) + (fingerPos.y * homography[0, 1]) + (1 * homography[0, 2]);
        float y = (fingerPos.x * homography.Data[1, 0]) + (fingerPos.y * homography[1, 1]) + (1 * homography[1, 2]);
        return new Vector2(x, y);
    }   
</code></pre>

<p>I believe the issue might rely in my float[,] to matrix convertion, or my algorithm in coordToUnity.</p>

<p>Issue: coordToUnity always return 0. Where am I implementing EmguCV.HomographyFind wrong?</p>
",,2016-11-24 16:42:32,EmguCV HomographyFind - Unity always receive zero,<c#><unity3d><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
48415,40828684,2016-11-27 11:58:27,,"<p>I have following code in C# using emgu to camera capture:  </p>

<pre><code>    //video capture
    private Capture videoCapture = null;  //takes images from camera as image frames
    private Image&lt;Bgr, Byte&gt; videoCaptureImageFrame;
    private Image&lt;Bgr, Byte&gt; videoCaptureResizedFrame;
    //video capture

    private void ProcessFrame(object sender, EventArgs arg)
    {
        try
        {
            videoCaptureImageFrame = videoCapture.QueryFrame().ToImage&lt;Bgr, Byte&gt;();   

            if (videoCaptureImageFrame != null)
            {
                videoCaptureResizedFrame = videoCaptureImageFrame.Resize(960, 540, Emgu.CV.CvEnum.Inter.Cubic);                                        
                VideoCapturePictureBox.Image = videoCaptureResizedFrame.ToBitmap();                      
            }

        }
        catch (Exception ex)
        {
            MessageBox.Show(""Video capture error #1: "" + ex.Message.ToString());
        }
    }

    public void VideoCaptureReleaseData()
    {
        if (videoCapture != null)
            videoCapture.Dispose();
    }

    //video capture  
    private void MainForm_Load(object sender, EventArgs e)
    {
        //Dispose of Capture if it was created before
        if (videoCapture != null) videoCapture.Dispose();

        //video capture
        if (videoCapture == null)
        {                
            try
            {
                videoCapture = new Capture(0);
                videoCapture.SetCaptureProperty(Emgu.CV.CvEnum.CapProp.FrameWidth, 1920);
                videoCapture.SetCaptureProperty(Emgu.CV.CvEnum.CapProp.FrameHeight, 1080);
                videoCapture.SetCaptureProperty(Emgu.CV.CvEnum.CapProp.FrameCount, 25);

                Application.Idle += ProcessFrame;
            }
            catch (NullReferenceException excpt)
            {
                MessageBox.Show(""Video capture error #2: "" + excpt.Message);
            }
        }
        //video capture
    }
</code></pre>

<p>This code works fine but I can see that from time to time Visual Studio 2015 show process memory consumption of 2GB of data. 
Sometimes I got following error:<br>
""Video capture error #1: opencv: u != 0""<br>
and application stops to show any camera output.</p>

<p>I assume I have some kind of memory leak in above code.<br>
This is strange because I wrote this code according to tutorials.<br>
Could you please help me what is wrong with this code?</p>
",,2016-11-27 11:58:27,c# emgu camera capture and mem leak?,<c#><cameracapturetask><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
48528,40937039,2016-12-02 16:41:31,,"<p>my task is to convert a program for blob tracking with kinect V1 into a program for blob tracking using Kinect v2.</p>

<p>The first program is written in c++ and uses opencv. The new program must be write in c#, so I'm using the wrapper emgucv.</p>

<p>The first program at a certain point uses this instruction:</p>

<pre><code>cvCvtColor(frameVideo,hsvImg,CV_BGR2HSV);
</code></pre>

<p>frameVideo and hsvImg are defined like this:</p>

<pre><code>IplImage* frameVideo=cvCreateImage(cvSize(IMAGE_WIDTH,IMAGE_HEIGHT),8,3);

IplImage *hsvImg=cvCreateImage(cvSize(IMAGE_WIDTH,IMAGE_HEIGHT),8,3);
</code></pre>

<p>Now, I'm trying an equivalent way to do the same with C# and emgu.</p>

<p>My equivalent variables are defined like this:</p>

<pre><code>MIplImage frameVideo = (MIplImage)Marshal.PtrToStructure(CvInvoke.cvCreateImage(new System.Drawing.Size(Globals.IMAGE_WIDTH, Globals.IMAGE_HEIGHT), IplDepth.IplDepth_8U, 3), typeof(MIplImage));

MIplImage hsvImg = (MIplImage)Marshal.PtrToStructure(CvInvoke.cvCreateImage(new System.Drawing.Size(Globals.IMAGE_WIDTH, Globals.IMAGE_HEIGHT), IplDepth.IplDepth_8U, 3), typeof(MIplImage));
</code></pre>

<p>Inside emgu there's the equivalent method of cvCvtColor, that is CvInvoke.CvtColor(, ...), whose syntax is the following:</p>

<pre><code>public static void CvtColor(
    IInputArray src,
    IOutputArray dst,
    ColorConversion code,
    int dstCn = 0
)
</code></pre>

<p>Link to documentation of this method: <a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/80190679-ef98-e1ef-f6b6-4c8b9f3b7f64.htm"" rel=""nofollow noreferrer"">http://www.emgu.com/wiki/files/3.0.0/document/html/80190679-ef98-e1ef-f6b6-4c8b9f3b7f64.htm</a></p>

<p>So, my problem is that this method requires to work with IInputArray as a source and IOutputArray as destination, but i can't find a way to use my variables (that are of type MIplImage) in that method, or a way to associate frameVideo with IInputArray and hsvImg with IOutputArray.</p>

<p>I've found a way to use the method with the Image type, but in this case I've not find a way to convert from my MIplImage format to Image.</p>

<p>Can anyone help me? </p>

<p>If you have more questions or if you want more details on the code please contact me.</p>

<p>Thanks a lot!</p>
",,2017-01-31 22:27:35,c# emgucv conversion of MIplImage type image from BGR color space to HSV color space,<c#><emgucv><data-conversion><hsv><bgr>,,,CC BY-SA 3.0,True,False,True,False,False
48581,41018625,2016-12-07 13:21:27,,"<p>I wrote it like this, but the rectangular bars do not appear. How can I detect these bars?</p>

<p>I specified the problem in the picture.</p>

<p>Thank you..</p>

<pre><code>Bitmap bitmap = (Bitmap)panel1.BackgroundImage;
        BlobCounter blobCounter = new BlobCounter();
        blobCounter.FilterBlobs = true;
        blobCounter.MinHeight = 1;
        blobCounter.MinWidth = 1;
        blobCounter.ObjectsOrder = ObjectsOrder.Size;
        blobCounter.ProcessImage(bitmap);

        Pen yellowPen = new Pen(Color.Red, 6);
        Graphics g = Graphics.FromImage(bitmap);
        Blob[] blobs = blobCounter.GetObjectsInformation();

        SimpleShapeChecker shapeChecker = new SimpleShapeChecker();

        foreach (var blob in blobs)
        {
            List&lt;IntPoint&gt; edgePoints = blobCounter.GetBlobsEdgePoints(blob);
            List&lt;IntPoint&gt; cornerPoints;
            if (shapeChecker.IsQuadrilateral(edgePoints, out cornerPoints))
            {
                if (shapeChecker.CheckPolygonSubType(cornerPoints) == PolygonSubType.RectangledTriangle)
                {
                    List&lt;System.Drawing.Point&gt; Points = new List&lt;System.Drawing.Point&gt;();
                    foreach (var point in cornerPoints)
                    {
                        Points.Add(new System.Drawing.Point(point.X, point.Y));
                    }


                    g.DrawPolygon(new Pen(Color.Red, 5.0f), Points.ToArray());

                    bitmap.Save(@""C:\Users\OkanBerk\Desktop\result.png"");
                }
            }
        }

        panel1.BackgroundImage = bitmap;
        panel1.Invalidate();
</code></pre>

<p><a href=""https://i.stack.imgur.com/PM4mj.jpg"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/PM4mj.jpg</a></p>
",2016-12-07 16:19:37,2016-12-07 16:19:37,I Can Not Find Optical Form Bars (A-Forge),<c#><emgucv><image-recognition><aforge>,,,CC BY-SA 3.0,False,False,True,False,False
48594,40884040,2016-11-30 09:00:21,,"<p>Probably it is something easy but I cannot find the method. I am trying this code to draw an ARC segment with float points:</p>

<p>System.Drawing.PointF[] points = new PointF[20];</p>

<p>background.DrawPolyline(points, false, new Bgr(0, 0, 0), 1, Emgu.CV.CvEnum.LineType.FourConnected, 0);</p>

<p>According to the documentation in
<a href=""http://www.emgu.com/wiki/files/3.0.0/document/html/53068d61-8b55-789f-5d3c-6ed2288f073e.htm"" rel=""nofollow noreferrer"">http://www.emgu.com/wiki/files/3.0.0/document/html/53068d61-8b55-789f-5d3c-6ed2288f073e.htm</a></p>

<p>the DrawPolyline method can use PointF[] as input. However, I get error when I type it. I am using EmguCV 3.1. Also, I tried ""Go to definition"" and I cannot find this method in the .cs file. Someone knows why? I changed from 2.4 to 3.1 just because I though I can find this method in the new version, but I still cannot find it.</p>

<p>I hope someone can help me. If someone knows a better way to draw an arc, also welcome.
Thanks in advance</p>
",,2016-11-30 18:28:09,"EmguCV C# 3.1 - DrawPolyline(PointF[], Boolean, TColor, Int32) syntax error",<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
48630,41099422,2016-12-12 11:04:23,,"<p>I am using EmguCV in my C# project.
I have recently set the values of my usb webcam properties to some random doubles and integers to see how it works, but now my webcam seemed to remember all my unfortunate changes and the video is terrible even in a clean project.</p>

<p>The code I have used looked like this:</p>

<pre><code> capture.SetCaptureProperty(CapProp.Contrast, x);
 capture.SetCaptureProperty(CapProp.Brightness, x);
 capture.SetCaptureProperty(CapProp.AutoExposure, x);
 capture.SetCaptureProperty(CapProp.Gamma, x);
 capture.SetCaptureProperty(CapProp.Staturation, x);
 capture.SetCaptureProperty(CapProp.Sharpness, x);
</code></pre>

<p>How do I know the default values of properties listed in EmguCV CapProp Enum?
Is there a way to reset to default webcam settings?</p>
",,2017-07-26 05:00:27,EmguCV SetCaptureProperty default values,<emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
48640,40889570,2016-11-30 13:24:10,,"<p>I am currently using SURF  algorithm (on EmguCV 3.1) to test whether two images might correspond to the same location <a href=""https://i.stack.imgur.com/GKzgF.jpg"" rel=""nofollow noreferrer"">Image 1</a> and a very dark version of it, which brings me the following 2 questions:</p>

<p>1-Do you think counting the number of good matches between the two pictures is a good idea for determining the image similarity? If not , any other suggestions ?</p>

<p>2-Assuming counting the number of matches is a good approach. How to get the count of matches ? Some articles talk about <a href=""https://stackoverflow.com/questions/33657853/emgucv-surf-determine-matched-pairs-of-points?noredirect=1&amp;lq=1"">counting the number of NonZeros</a> . However, results do no seem to match like in <a href=""https://i.stack.imgur.com/Sjkjw.jpg"" rel=""nofollow noreferrer"">this picture</a> , which shows only 2 matches , yet it returns  a value of 30 (variable noZeroCount). The code I'm using is this :</p>

<pre><code>public static void FindMatch(Mat modelImage, Mat observedImage, out long matchTime, out VectorOfKeyPoint modelKeyPoints, out VectorOfKeyPoint observedKeyPoints, VectorOfVectorOfDMatch matches, out Mat mask, out Mat homography)
    {
        int k = 2;
        double uniquenessThreshold = 0.8;
        double hessianThresh = 300;

        Stopwatch watch;
        homography = null;

        modelKeyPoints = new VectorOfKeyPoint();
        observedKeyPoints = new VectorOfKeyPoint();
        using (UMat uModelImage = modelImage.ToUMat(AccessType.Read))
        using (UMat uObservedImage = observedImage.ToUMat(AccessType.Read))
        {
            SURF surfCPU = new SURF(hessianThresh, 4 , 2, true, true);

            //extract features from the object image
            UMat modelDescriptors = new UMat();
            surfCPU.DetectAndCompute(uModelImage, null, modelKeyPoints, modelDescriptors, false);

            watch = Stopwatch.StartNew();

            // extract features from the observed image
            UMat observedDescriptors = new UMat();
            surfCPU.DetectAndCompute(uObservedImage, null, observedKeyPoints, observedDescriptors, false);
            BFMatcher matcher = new BFMatcher(DistanceType.L2);
            matcher.Add(modelDescriptors);

            matcher.KnnMatch(observedDescriptors, matches, k, null);
            mask = new Mat(matches.Size, 1, DepthType.Cv8U, 1);
            mask.SetTo(new MCvScalar(255));
            Features2DToolbox.VoteForUniqueness(matches, uniquenessThreshold, mask);

            int nonZeroCount = CvInvoke.CountNonZero(mask);
            if (nonZeroCount &gt;= 4)
            {
                nonZeroCount = Features2DToolbox.VoteForSizeAndOrientation(modelKeyPoints, observedKeyPoints,
                   matches, mask, 1.5, 20);
                if (nonZeroCount &gt;= 4)
                    homography = Features2DToolbox.GetHomographyMatrixFromMatchedFeatures(modelKeyPoints,
                       observedKeyPoints, matches, mask, 2);
            }

            watch.Stop();
            matchTime = watch.ElapsedMilliseconds;
        }
    }
</code></pre>

<p>Much appreciated for any of your efforts.</p>
",2017-05-23 12:24:26,2018-03-21 09:47:37,EmguCV - Get number of matches for determining image similarity,<c#><opencv><image-processing><emgucv><surf>,,,CC BY-SA 3.0,True,True,True,False,False
48671,41104856,2016-12-12 16:07:05,,"<p><strong>Please Guide me:</strong>
I am going to make my Final year project in image processing using the concept of real time video processing.</p>

<p>Project will contain the following <strong>Task</strong>:</p>

<ul>
<li>Capture the video in real time.</li>
<li>Track the face and eyes pupal in real time.</li>
<li>If eyes are closed then alarm.
Now i confused about to which library should be used by me <strong>AForge.net or openCv?</strong>
Does <strong>AForge.net</strong> support the real time face and eyes tracking?</li>
</ul>
",2016-12-12 16:26:55,2017-01-19 14:59:26,Real Time Face and eye tracking using video processing with AForge.net,<opencv><video><image-processing><emgucv><aforge>,2018-05-04 13:02:40,,CC BY-SA 3.0,True,False,True,False,False
48722,41067634,2016-12-09 19:35:21,,"<p>I have implemented <a href=""http://www.emgu.com/wiki/index.php/SURF_feature_detector_in_CSharp"" rel=""nofollow noreferrer"">this</a> code and have detcted logo in couple of images,
I was able to get some results like this <a href=""https://i.stack.imgur.com/Gz4RV.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Gz4RV.jpg"" alt=""this"" /></a> but I need to count that how many images contain this logo,
may be something like finding all keypoints of logo inside big image or some thing else.
I can see I have foud the logo inside big image but I want to confirm it programetically, using emguCV.
Please help.</p>
<h1>-- edited</h1>
<p>this is the piece of code with homography, can you guide me a bit here, because I am totaly new to emguCV and openV please help me counting these inlier</p>
<pre><code>public static Mat Draw(Mat modelImage, Mat observedImage, out long matchTime)
    {
        Mat homography;
        VectorOfKeyPoint modelKeyPoints;
        VectorOfKeyPoint observedKeyPoints;
        using (VectorOfVectorOfDMatch matches = new VectorOfVectorOfDMatch())
        {
            Mat mask;
            FindMatch(modelImage, observedImage, out matchTime, out modelKeyPoints, out observedKeyPoints, matches,
               out mask, out homography);

            //Draw the matched keypoints
            Mat result = new Mat();// new Size(400,400), modelImage.Depth, modelImage.NumberOfChannels);
            Features2DToolbox.DrawMatches(modelImage, modelKeyPoints, observedImage, observedKeyPoints,
               matches, result, new MCvScalar(255, 255, 255), new MCvScalar(255, 255, 255), mask);

            #region draw the projected region on the image

            if (homography != null)
            {
                
                //draw a rectangle along the projected model
                Rectangle rect = new Rectangle(Point.Empty, modelImage.Size);
                PointF[] pts = new PointF[]
                {
                      new PointF(rect.Left, rect.Bottom),
                      new PointF(rect.Right, rect.Bottom),
                      new PointF(rect.Right, rect.Top),
                      new PointF(rect.Left, rect.Top)
                };
                pts = CvInvoke.PerspectiveTransform(pts, homography);

                Point[] points = Array.ConvertAll&lt;PointF, Point&gt;(pts, Point.Round);
                using (VectorOfPoint vp = new VectorOfPoint(points))
                {
                    CvInvoke.Polylines(result, vp, true, new MCvScalar(255, 0, 0, 255), 5);
                }

            }

            #endregion

            return result;

        }
    }
</code></pre>
",2020-06-20 09:12:55,2018-06-05 12:29:41,Logo recognition using emguCV,<c#><opencv><emgucv><sift>,,,CC BY-SA 3.0,True,True,True,False,False
48723,40952261,2016-12-03 20:38:38,,"<p>I'm using the code used off the tutorial on Emgu's website with the following code : </p>

<pre><code> using (Image&lt;Gray, float&gt; result = source.MatchTemplate(template, TemplateMatchingType.CcoeffNormed))
        {
            double[] minValues, maxValues;
            Point[] minLocations, maxLocations;
            result.MinMax(out minValues, out maxValues, out minLocations, out maxLocations);
            // You can try different values of the threshold. I guess somewhere between 0.75 and 0.95 would be good.
            if (maxValues[0] &gt; 0.6)
            {
                // This is a match. Do something with it, for example draw a rectangle around it.
                Rectangle match = new Rectangle(maxLocations[0], template.Size);
                imageToShow.Draw(match, new Bgr(Color.Red), 3);
            }
        }
</code></pre>

<p>It works great to identify a single sub-image inside of another image. But I was wondering how you would go about adapting this code to identify multiple instances. </p>

<p>Thanks in advance.</p>
",,2016-12-04 07:38:31,EmguCV/Open CV - Is there a way to search for a template sub- mage multiple times?,<c#><image><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
48735,41111124,2016-12-12 23:00:50,,"<p>I wish to convert the following class to C# using Emgucv 3.1.0 because I am more familiar with C# Emgucv library.</p>

<p>It is a background segmentation algorithm found <a href=""https://github.com/sagi-z/BackgroundSubtractorCNT"" rel=""nofollow noreferrer"">here</a>. </p>

<pre><code>     #include ""bgsubcnt.h""
    #include &lt;functional&gt;

namespace cv
{

namespace bgsubcnt
{

/** @brief Implementation of background subtraction based on counting.
 *  About as fast as MOG2 on a high end system (benchmarked on )
 *  More than twice faster than MOG2 on cheap hardware (benchmarked on Raspberry Pi3).
 *  Algorithm by Sagi Zeevi
 */
class BackgroundSubtractorCNTImpl: public BackgroundSubtractorCNT
{
public:
    /**
     * @brief BackgroundSubtractorCNTImpl
     * @param stability number of frames with same pixel color to consider stable
     * @param useHistory determines if we're giving a pixel credit for being stable for a long time
     * @param maxStability maximum allowed credit for a pixel in history
     * @param isParallel determines if we're parallelizing the algorithm
     */
    BackgroundSubtractorCNTImpl(int minStability,
                                bool useHistory,
                                int maxStability,
                                bool isParallel);

    // BackgroundSubtractor interface
    virtual void apply(InputArray image, OutputArray fgmask, double learningRate);
    virtual void getBackgroundImage(OutputArray backgroundImage) const;

    int getMinPixelStability() const;
    void setMinPixelStability(int value);

    int getMaxPixelStability() const;
    void setMaxPixelStability(int value);

    bool getUseHistory() const;
    void setUseHistory(bool value);

    bool getIsParallel() const;
    void setIsParallel(bool value);

private:
    int minPixelStability;
    int maxPixelStability;
    int threshold;
    bool useHistory;
    bool isParallel;
    // These 3 commented expressed in 1 'data' for faster single access
    //    Mat_&lt;int&gt; stability;        // data[0]  =&gt; Candidate for historyStability if pixel is ~same as in prevFrame
    //    Mat_&lt;int&gt; history;          // data[1]  =&gt; Color which got most hits for the past maxPixelStability frames
    //    Mat_&lt;int&gt; historyStability; // data[2]  =&gt; How many hits this pixel got for the color in history
    //    Mat_&lt;int&gt; background;       // data[3]  =&gt; Current background as detected by algorithm
    Mat_&lt;Vec4i&gt; data;
    Mat prevFrame;
    Mat fgMaskPrev;
};

BackgroundSubtractorCNTImpl::BackgroundSubtractorCNTImpl(int minStability,
                                                         bool _useHistory,
                                                         int maxStability,
                                                         bool _isParallel)
    : minPixelStability(minStability),
      maxPixelStability(maxStability),
      threshold(5),
      useHistory(_useHistory),
      isParallel(_isParallel)
{
}

void BackgroundSubtractorCNTImpl::getBackgroundImage(OutputArray _backgroundImage) const
{
    CV_Assert(! data.empty());

    _backgroundImage.create(prevFrame.size(), CV_8U); // OutputArray usage requires this step
    Mat backgroundImage = _backgroundImage.getMat();

    // mixChannels requires same types to mix,
    //  so imixing with tmp Mat and conerting
    Mat_&lt;int&gt; tmp(prevFrame.rows, prevFrame.cols);
    int from_bg_model_to_user[] = {3, 0};
    mixChannels(&amp;data, 1, &amp;tmp, 1, from_bg_model_to_user, 1);
    tmp.convertTo(backgroundImage, CV_8U);
}

int BackgroundSubtractorCNTImpl::getMinPixelStability() const
{
    return minPixelStability;
}

void BackgroundSubtractorCNTImpl::setMinPixelStability(int value)
{
    CV_Assert(value &gt; 0 &amp;&amp; value &lt; maxPixelStability);
    minPixelStability = value;
}

int BackgroundSubtractorCNTImpl::getMaxPixelStability() const
{
    return maxPixelStability;
}

void BackgroundSubtractorCNTImpl::setMaxPixelStability(int value)
{
    CV_Assert(value &gt; minPixelStability);
    maxPixelStability = value;
}

bool BackgroundSubtractorCNTImpl::getUseHistory() const
{
    return useHistory;
}

void BackgroundSubtractorCNTImpl::setUseHistory(bool value)
{
    useHistory = value;
}

bool BackgroundSubtractorCNTImpl::getIsParallel() const
{
    return isParallel;
}

void BackgroundSubtractorCNTImpl::setIsParallel(bool value)
{
    isParallel = value;
}

class CNTFunctor
{
public:
    virtual void operator()(Vec4i &amp;vec, uchar currColor, uchar prevColor, uchar &amp;fgMaskPixelRef) = 0;
};

struct BGSubtractPixel : public CNTFunctor
{
    BGSubtractPixel(int _minPixelStability, int _threshold,
                    const Mat &amp;_frame, const Mat &amp;_prevFrame, Mat &amp;_fgMask)
        : minPixelStability(_minPixelStability),
          threshold(_threshold),
          frame(_frame),
          prevFrame(_prevFrame),
          fgMask(_fgMask)
    {}

    void operator()(Vec4i &amp;vec, uchar currColor, uchar prevColor, uchar &amp;fgMaskPixelRef)
    {
        int &amp;stabilityRef = vec[0];
        int &amp;bgImgRef = vec[3];
        if (abs(currColor - prevColor) &lt; threshold)
        {
            ++stabilityRef;
            if (stabilityRef == minPixelStability)
            {   // bg
                --stabilityRef;
                bgImgRef = prevColor;
            }
            else
            {   // fg
                fgMaskPixelRef = 255;
            }
        }
        else
        {   // fg
            stabilityRef = 0;
            fgMaskPixelRef = 255;
        }
    }

    int minPixelStability;
    int threshold;
    const Mat &amp;frame;
    const Mat &amp;prevFrame;
    Mat &amp;fgMask;
};

struct BGSubtractPixelWithHistory : public CNTFunctor
{
    BGSubtractPixelWithHistory(int _minPixelStability, int _maxPixelStability, int _threshold,
                               const Mat &amp;_frame, const Mat &amp;_prevFrame, Mat &amp;_fgMask)
        : minPixelStability(_minPixelStability),
          maxPixelStability(_maxPixelStability),
          threshold(_threshold),
          thresholdHistory(30),
          frame(_frame),
          prevFrame(_prevFrame),
          fgMask(_fgMask)
    {}

    void incrStability(int &amp;histStabilityRef)
    {
        if (histStabilityRef &lt; maxPixelStability)
        {
            ++histStabilityRef;
        }
    }

    void decrStability(int &amp;histStabilityRef)
    {
        if (histStabilityRef &gt; 0)
        {
            --histStabilityRef;
        }
    }

    void operator()(Vec4i &amp;vec, uchar currColor, uchar prevColor, uchar &amp;fgMaskPixelRef)
    {
        int &amp;stabilityRef = vec[0];
        int &amp;historyColorRef = vec[1];
        int &amp;histStabilityRef = vec[2];
        int &amp;bgImgRef = vec[3];
        if (abs(currColor - historyColorRef) &lt; thresholdHistory)
        {   // No change compared to history - this is maybe a background
            stabilityRef = 0;
            incrStability(histStabilityRef);
            if (histStabilityRef &lt;= minPixelStability)
            {
                fgMaskPixelRef = 255;
            }
            else
            {
                bgImgRef = historyColorRef;
            }
        }
        else if (abs(currColor - prevColor) &lt; threshold)
        {   // No change compared to prev - this is maybe a background
            incrStability(stabilityRef);
            if (stabilityRef &gt; minPixelStability)
            {   // Stable color - this is maybe a background
                if (stabilityRef &gt;= histStabilityRef)
                {
                    historyColorRef = currColor;
                    histStabilityRef = stabilityRef;
                    bgImgRef = historyColorRef;
                }
                else
                {   // Stable but different from stable history - this is a foreground
                    decrStability(histStabilityRef);
                    fgMaskPixelRef = 255;
                }
            }
            else
            {   // This is FG.
                fgMaskPixelRef = 255;
            }
        }
        else
        {   // Color changed - this is defently a foreground
            stabilityRef = 0;
            decrStability(histStabilityRef);
            fgMaskPixelRef = 255;
        }

    }

    int minPixelStability;
    int maxPixelStability;
    int threshold;
    int thresholdHistory;
    const Mat &amp;frame;
    const Mat &amp;prevFrame;
    Mat &amp;fgMask;
};

class CNTInvoker : public ParallelLoopBody
{
public:
    CNTInvoker(Mat_&lt;Vec4i&gt; &amp;_data, Mat &amp;_img, Mat &amp;_prevFrame, Mat &amp;_fgMask, CNTFunctor &amp;_functor)
        : data(_data), img(_img), prevFrame(_prevFrame), fgMask(_fgMask), functor(_functor)
    {
    }

    // Iterate rows
    void operator()(const Range&amp; range) const
    {
        for (int r = range.start; r &lt; range.end; ++r)
        {
            Vec4i* row = data.ptr&lt;Vec4i&gt;(r);
            uchar* frameRow = img.ptr&lt;uchar&gt;(r);
            uchar* prevFrameRow = prevFrame.ptr&lt;uchar&gt;(r);
            uchar* fgMaskRow = fgMask.ptr&lt;uchar&gt;(r);
            for (int c = 0; c &lt; data.cols; ++c)
            {
                functor(row[c], frameRow[c], prevFrameRow[c], fgMaskRow[c]);
            }
        }
    }

private:
    Mat_&lt;Vec4i&gt; &amp;data;
    Mat &amp;img;
    Mat &amp;prevFrame;
    Mat &amp;fgMask;
    CNTFunctor &amp;functor;
};

void BackgroundSubtractorCNTImpl::apply(InputArray image, OutputArray _fgmask, double learningRate)
{
    CV_Assert(image.type() == CV_8UC1);

    Mat frameIn = image.getMat();
    _fgmask.create(image.size(), CV_8U); // OutputArray usage requires this step
    Mat fgMask = _fgmask.getMat();

    bool needToInitialize = data.empty() || learningRate &gt;= 1 || frameIn.size() != prevFrame.size();

    Mat frame = frameIn.clone();

    if (needToInitialize)
    {   // Usually done only once
        data = Mat_&lt;Vec4i&gt;::zeros(frame.rows, frame.cols);
        prevFrame = frame;

        // mixChannels requires same types to mix,
        //  so imixing with tmp Mat and conerting
        Mat tmp;
        prevFrame.convertTo(tmp, CV_32S);
        int from_gray_to_history_color[] = {0,1};
        mixChannels(&amp;tmp, 1, &amp;data, 1, from_gray_to_history_color, 1);
    }

    fgMask = Scalar(0);
    CNTFunctor *functor;
    if (useHistory &amp;&amp; learningRate)
    {
        double scaleMaxStability = 1.0;
        if (learningRate &gt; 0 &amp;&amp; learningRate &lt; 1.0)
        {
            scaleMaxStability = learningRate;
        }
        functor = new BGSubtractPixelWithHistory(minPixelStability, int(maxPixelStability * scaleMaxStability),
                                                 threshold, frame, prevFrame, fgMask);
    }
    else
    {
        functor = new BGSubtractPixel(minPixelStability, threshold*3, frame, prevFrame, fgMask);
    }

    if (isParallel)
    {
        parallel_for_(Range(0, frame.rows),
                      CNTInvoker(data, frame, prevFrame, fgMask, *functor));
    }
    else
    {
        for (int r = 0; r &lt; data.rows; ++r)
        {
            Vec4i* row = data.ptr&lt;Vec4i&gt;(r);
            uchar* frameRow = frame.ptr&lt;uchar&gt;(r);
            uchar* prevFrameRow = prevFrame.ptr&lt;uchar&gt;(r);
            uchar* fgMaskRow = fgMask.ptr&lt;uchar&gt;(r);
            for (int c = 0; c &lt; data.cols; ++c)
            {
                (*functor)(row[c], frameRow[c], prevFrameRow[c], fgMaskRow[c]);
            }
        }
    }

    delete functor;

    prevFrame = frame;
}

Ptr&lt;BackgroundSubtractorCNT&gt;
createBackgroundSubtractorCNT(int minPixelStability, bool useHistory, int maxStability, bool isParallel)
{
    return makePtr&lt;BackgroundSubtractorCNTImpl&gt;(minPixelStability, useHistory, maxStability, isParallel);
}

}

}
</code></pre>
",2016-12-12 23:45:15,2016-12-12 23:45:15,BackgroundSubtractorCNT Implementation in C# Emgucv,<c#><c++><opencv><emgucv><opencv3.1>,,,CC BY-SA 3.0,True,True,True,False,False
48779,41149195,2016-12-14 18:02:32,,"<p>I calculated Disparity map in c# (Emgu). The attached file<a href=""https://i.stack.imgur.com/RLeMK.png"" rel=""nofollow noreferrer"">1</a> is left and right image, and disparity map. The noise of disparity map is high. How can i decrease noise in disparity map?
Thanks.</p>
",2016-12-15 07:19:28,2017-01-12 16:28:50,Decrease noise in Disparity map,<emgucv><camera-calibration><stereo-3d><stereoscopy>,,,CC BY-SA 3.0,False,False,True,False,False
48884,41081134,2016-12-10 22:48:03,,"<p>I'm programming in C# and I use EmguCV (3.1). I use Canny edge detector from CvInvoke class. My problem is this algorithm do not find some edges. My OpenCL = true. Here is my problem:</p>

<p>The input image:<br/>
<a href=""https://i.stack.imgur.com/unFWg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/unFWg.png"" alt=""Rectangles""></a></p>

<p>And the result:
<a href=""https://i.stack.imgur.com/Zfk5n.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Zfk5n.jpg"" alt=""Edges""></a></p>

<p>As you see, rectangles that are not rotated, miss their top edges. My questions are:</p>

<p>1- Is it normal?<br/>
2- In case of <strong>NO</strong> how can I fix it?</p>

<p>HERE IS MY CODE:</p>

<pre><code>CvInvoke.UseOpenCL = true;

Bitmap bm = new Bitmap(pictureBox1.Image);

Image&lt;Gray, byte&gt; im = new Image&lt;Gray, byte&gt;(bm);
UMat u = im.ToUMat();            

CvInvoke.Canny(u, u, 150, 50);

pictureBox1.Image = u.Bitmap;
</code></pre>
",2016-12-10 23:13:35,2016-12-10 23:13:35,Canny edge detection in emgu loses edges,<c#><opencv><image-processing><canny-operator><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
48891,41004962,2016-12-06 21:09:53,,"<p>Hello How can I take a snapshot from the Webcam and save it in a variable by using C# and Emgu CV</p>
",,2016-12-06 21:14:00,Take snapshot from webcam and save it in variable by C# & Emgu CV,<c#><emgucv>,2016-12-07 00:29:41,,CC BY-SA 3.0,False,False,True,False,False
48908,40968394,2016-12-05 06:34:27,,"<p>I program my app in C# using visual studio 2013. I use EmguCV(3.1) for this purpose. I Load each image file from folder and do some process on it. My app is some thing like this:</p>
<pre><code>private void SomeProcessesOnSingleImage(String filePath)
{
    // Some Bitmap instances
    // Some Image&lt;Gray, Byte&gt; instances
    // Some Image&lt;Bgr, Byte&gt; instances
    // Some UMat instances

    // Do some processes
    // Save file
}
private void BatchProcessor()
{
    String[] filePathes = Directory.GetFiles(d.SelectedPath);
    foreach(String path in filePathes)
    {
        SomeProcessesOnSingleImage(path);
    }
}
</code></pre>
<p>After about 1 minute from running my app, it does not respond and I see this message about my graphic card:</p>
<p><a href=""https://i.stack.imgur.com/hGnRp.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hGnRp.jpg"" alt=""enter image description here"" /></a></p>
<p>Now, My questions are:</p>
<ol>
<li>Should I release <code>Image&lt; , &gt;</code> or <code>UMat</code> using <code>CvInvoke.cvReleaseImage()</code> or <code>Garbage collector</code> do it?</li>
<li>Should I use <code>using</code> for <code>Bitmap</code> and other similar instances?</li>
<li>In case of <strong>NO</strong> for questions above, how can I fix it?</li>
</ol>
<p>I note that my app do it works perfectly when I use single Image (when I just call <code>SomeProcessesOnSingleImage</code> method).</p>
<p><em>UPDATE 1: I use OpenCL (UseOpenCL = true)</em></p>
",2020-06-20 09:12:55,2016-12-05 08:00:11,CvInvoke.cvReleaseImage() usage in EmguCV (3.1),<c#><image-processing><garbage-collection><emgucv><using-statement>,,,CC BY-SA 3.0,False,False,True,False,False
48926,41165032,2016-12-15 13:11:02,,"<p>I am working with Emgu CV 3.1 in a C# Project. </p>

<p>Looking for a way to smooth images I found <a href=""http://www.emgu.com/wiki/files/2.3.0/document/html/5bdae109-2a3d-0f2f-f0f3-a973ca9498cb.htm"" rel=""nofollow noreferrer"">cvSmooth</a> which allows a selection which smoothing algorithm to use. In IDE I can see methods like <code>CvInvoke.Blur</code> or <code>CvInvoke.GaussianBlur</code> but there is no cvSmooth or a similar method. Is it simply gone with V3?</p>
",,2016-12-21 02:47:38,CvInvoke.cvSmooth gone since emgu cv 3?,<c#><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
48961,41242318,2016-12-20 12:25:05,,"<p>I have done the grabcut implementation interactive in c# but there is one problem which Iam unable to solve. How to smooth the edges. The edges looks rough after applying grabcut. I googled and found out a solution in c++ but I am unable to convert it into c#. Here What I have done so far.</p>

<pre><code>Image&lt;Bgr, Byte&gt; image = new Image&lt;Bgr, Byte&gt;(""SourceImage"");  
Image&lt;Gray, Byte&gt; mask1 = newMask;//Grabcut mask
Image&lt;Bgr, float&gt; maskF = mask1.Convert&lt;Bgr, float&gt;();
Image&lt;Bgr, float&gt; maskF2 = maskF.Mul(1 / 255);
Image&lt;Bgr, float&gt; imageF = image.Convert&lt;Bgr, float&gt;();
var img= imageF.Mul(maskF).Convert&lt;Bgr, byte&gt;();
Image&lt;Bgr, byte&gt; result3 = new Image&lt;Bgr, byte&gt;(imageSource.Width, imageSource.Height);
imageSource.Copy(result3, newMask);Pictureboxoutput.image=(result3+img).ToBitMap();
</code></pre>

<p><a href=""https://i.stack.imgur.com/ngOQY.jpg"" rel=""nofollow noreferrer"">OutputImage</a><a href=""https://i.stack.imgur.com/RNkFc.jpg"" rel=""nofollow noreferrer"">InputImage</a></p>
",2017-03-22 16:59:55,2017-03-22 16:59:55,How to get smooth edges in grabcut in Emgu c#,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
48993,41206025,2016-12-18 06:27:22,,"<p>In my code, the output is an image each pixel of which is determined using nested loops.</p>

<p>1) How can I force a window to open and show the output image as it is being constructed in the loop? (The window shows up when everything is finished. I don't want this.)</p>

<p>2) How can I have the output be displayed line by line (or even pixel by pixel) as the loop goes on. User must have the sense of getting the output in real-time.</p>

<pre><code>    outImage = new Image&lt;Hsv, Byte&gt;(numberOfColumns, numberOfRows);
    byte[,,] pixelValue = outImage.Data;
        for (int i = 0; i &lt; numberOfRows - 1; i++)
        {
            for (int j = 0; j &lt; numberOfColumns - 1; j++)
            {
                //pixelValue[i, j, k] is determined here using some other functions
                imageBox1.Image = outImage; //too slow and impossible                 
            }
        }
</code></pre>
",,2017-02-01 00:03:12,Display an image in real time as it is being created in a loop,<c#><real-time><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
48995,41206881,2016-12-18 09:03:32,,"<p>I am coding on WPF+EmguCV 3.1.0, and I am hitting some performance issue on video playback.
The input stream resolution is 1920*1800. I use EmguCV's ImageBox in order to render each frame. UI update is performed within a DispatcherTimer, which ticks every 1 ms. </p>

<p>No support of CUDA. OpenCL + OpenCL GPU working. </p>

<p>The result is an unbearable slowness in displaying each frame. It simply takes too long. The video is not a video. It's like watching a frame every 10 seconds or so. </p>

<p>Any idea of what could be the reason? </p>

<p>Regards</p>
",,2017-01-31 22:07:42,emgucv performance issue with video playback,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
49043,41096122,2016-12-12 07:38:16,,"<p>I am trying to recognize the person in video (not by his face but by his body). What I have done so far now is to find the HOG,HS and RGB histograms of a person and compare it with all other person to find him.</p>

<p>I am using EmguCV but OpenCV's help will also be appreciated.</p>

<p><strong>HOG is Calculated using</strong></p>

<pre><code>        Size imageSize = new Size(64, 16);
        Size blockSize = new Size(16, 16);
        Size blockStride = new Size(16, 8);
        Size cellSize = new Size(8, 8);

        HOGDescriptor hog = new HOGDescriptor(imageSize, blockSize, blockStride, cellSize);

        float[] hogs = hog.Compute(image);
</code></pre>

<p><strong>Code to Calculate HS Histograms (Same method is used for RGB)</strong></p>

<pre><code>        Image&lt;Gray, byte&gt;[] channels = hsvImage.Copy().Split();
        Image&lt;Gray, byte&gt; hue = channels[0];
        Image&lt;Gray, byte&gt; sat = channels[1];

        dh.Calculate&lt;byte&gt;(new Image&lt;Gray, byte&gt;[] { hue }, true, null);
        dh2.Calculate&lt;byte&gt;(new Image&lt;Gray, byte&gt;[] { sat }, true, null);

        float[] huehist = dh.GetBinValues();
        float[] sathist = dh2.GetBinValues();
</code></pre>

<p><strong>Calculating distance of 2 histograms using</strong></p>

<pre><code>        double distance = 0;
        for (int i = 0; i &lt; hist1.Length; i++)
        {
            distance += Math.Abs(hist1[i] - hist2[i]);
        }
        return distance;
</code></pre>

<p><strong>What is happening</strong></p>

<p>I am trying to track a selected person from video feed. and the person can move from camera to camera.
The body of <strong>personA</strong> is extracted from the video frame, whose HOG,HS,RGB histograms are calculated and stored... then from next frame the histograms of all detected persons are calculated and matched with the histograms of <strong>personA</strong> the most matched histogram (with minimum distance) is considered as the same person (personA)... so it is continued to track that person...</p>

<p><strong>Problem</strong></p>

<ul>
<li>Accuracy is not good (sometimes it tells 2 people, with very different colored cloths, same)</li>
</ul>

<p><strong>Suggestions</strong></p>

<ul>
<li>What should I change/remove</li>
<li>Should I calculate histograms using <strong>CvInvoke.CalcHist(...);</strong> instead of dense histograms for HS and RGB</li>
<li>Should I normalize histograms before calculating distances.</li>
<li>Is this normalization method good? (every value <strong>minus</strong> mean of array) </li>
<li>Or should I try something else.</li>
</ul>

<p><strong>Any kind of help/suggestion will be HIGHLY APPRECIATED</strong> if any more info is needed then please comment.
Thanks,</p>
",,2017-01-26 09:57:19,Body recognition in EmguCV/OpenCV (Tracking person in video),<c#><opencv><image-processing><tracking><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
49059,41385114,2016-12-29 18:15:31,,"<p>I have been working on a project which would identify diseases from a leaf. I did search and worked out a few things. However some confusions remains. </p>

<p>I believe following should be the flow (suggestions required)</p>

<ol>
<li>Crop diseased area (Manually) from leafs for building Vocabulary.</li>
<li>Use <code>SIFT</code> to get <code>keypoints</code> and <code>descriptors</code></li>
<li>Create <code>Bag of Words</code> Vocabulary and <code>Cluster</code> (K means)</li>
<li>Train <code>SVM</code> from descriptors obtained above</li>
<li>To Evaluate/Classify Take input image of entire leaf and crop it to extract diseased area using <code>HarCascade</code></li>
<li>Use <code>SIFT</code> to get <code>keypoints</code> and <code>Descriptors</code> and then use <code>SVM</code> to Predict.</li>
</ol>

<p>Questions are </p>

<ol>
<li>Is above workflow reasonable ? or i am missing something?</li>
<li>I am confused about how does SVM learns the Name of object or disease for example where does SVM get Name of object it learned or detected?</li>
<li>How does SVM outputs the Name of object it identified ?</li>
</ol>
",,2016-12-29 18:15:31,Identification/Classification using BOW and SVM,<opencv><image-processing><svm><emgucv><sift>,,,CC BY-SA 3.0,True,False,True,False,False
49100,41349572,2016-12-27 17:32:31,,"<p>I want to calibrate stereo camera in c#(in Emgu library). but the calibration accuracy is very bad<a href=""https://i.stack.imgur.com/4OxbK.png"" rel=""nofollow noreferrer"">this is an example of disparity map</a>!Please help me.
Thank you</p>
",2016-12-29 04:37:04,2016-12-31 20:28:01,How can i improve stereo calibration accuracy?,<opencv><stereo-3d><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
49123,41430385,2017-01-02 16:39:25,,"<p>i been surfing the net for a quite some time about comparing fingerprint image and i found emgu is very interesting now questions are</p>

<ol>
<li><p>is this accurate?</p></li>
<li><p>is this possible(i think)</p></li>
<li>don't know where to go(guide me please)</li>
</ol>

<p>i have found this somewhere</p>

<pre><code>private Image&lt;Bgr, byte&gt; bwareaopen(Image&lt;Bgr, byte&gt; Input_Image, int threshold)
{    
     Image&lt;Bgr, byte&gt; bwresults = Input_Image.Copy();    
     using (MemStorage storage = new MemStorage())
     {
         for (Contour&lt;Point&gt; contours = Input_Image.Convert&lt;Gray, byte&gt;().FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE, Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST, storage); contours != null; contours = contours.HNext)
         {
             Contour&lt;Point&gt; currentContour = contours.ApproxPoly(contours.Perimeter * 0.05, storage);
             if (currentContour.Area &lt; threshold)
             {
                 for (int i = currentContour.BoundingRectangle.X; i &lt; currentContour.BoundingRectangle.X + currentContour.BoundingRectangle.Width; i++)
                 {
                      for (int j = currentContour.BoundingRectangle.Y; j &lt; currentContour.BoundingRectangle.Y + currentContour.BoundingRectangle.Height; j++)
                      {
                           bwresults.Data[j, i, 0] = 0;
                           bwresults.Data[j, i, 1] = 0;
                           bwresults.Data[j, i, 2] = 0;
                      }
                 }
             }
         }
     }
     return bwresults;
}
</code></pre>

<p>but i have no idea what is it, when i try to run it it gives me an error.</p>
",2017-01-02 20:10:19,2017-03-03 19:33:10,Comparing two fingerprint image using Emgu in C#,<c#><emgucv><fingerprint>,,,CC BY-SA 3.0,False,False,True,False,False
49129,41350495,2016-12-27 18:41:50,,"<p>I want to use CvBox2D type in emgucv 3.1.0.2504, but it is not recognized!</p>

<pre><code>using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Structure;
using Emgu.CV.UI;
using Emgu.CV.Util;
using Emgu.Util;
using System;

        static CvBox2D GetROIRegion(XPointF p1, XPointF p2)
        {
             CvBox2D result = new CvBox2D();
             ...
            return result;
        }
</code></pre>

<p><a href=""https://i.stack.imgur.com/fXOGx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fXOGx.png"" alt=""enter image description here""></a></p>
",,2016-12-28 07:42:09,CvBox2D is not recognized in emgucv 3.1,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
49161,41272421,2016-12-21 21:46:17,,"<p>I am trying to find the convex hull of a contour with emgu 3.1</p>

<p>It seems to be the case that FindContours only accepts a vectorOfVectorOfPoints (not pointsF). But then, convexhull requires a vectorOfPointF. Am I wrong? If I change contours to VectorOfVectorOfPointF I get a runtime error in the call to FindContours.</p>

<p>How do you convert a VectorOfPoint to VectorOfPointF?
Is there a better way to do it?</p>

<p>Thanks!</p>

<pre><code>using (var contours = new VectorOfVectorOfPoint())
using (Mat hierachy = new Mat())
{

    CvInvoke.FindContours(img, contours, hierachy, Emgu.CV.CvEnum.RetrType.External, Emgu.CV.CvEnum.ChainApproxMethod.ChainApproxSimple, new Point());
            for (int i = 0; i &lt; contours.Size; i++)
            {
                var contour = contours[i];
                var c = new VectorOfPointF();
                CvInvoke.ConvexHull(contour, c, false, true);
            }
</code></pre>
",,2020-02-28 03:30:51,Converting from VectorOfPoint to VectorOfPointF for contours in Emgu,<c#><emgucv>,,,CC BY-SA 3.0,False,True,True,False,False
49258,41552655,2017-01-09 16:36:11,,"<p>I'm doing my final project about hand gesture recognition using EmguCV. So far I did until Convex Hull. Now, I want to draw convexity defect on it and get the defect value from it. But I am stack. I found some references codes, but most of it written in C++ code. I don't how to convert them into c# code. Anyone, Would you mind to help me by convert this code? this is the C++ code:</p>

<pre><code>for( int i = 0; i&lt; contours.size(); i++ )
{
    size_t count = contours[i].size();
    if( count &lt;300 )
    continue;

    vector&lt;Vec4i&gt;::iterator d=convdefect[i].begin();
    while(d!=convdefect[i].end()) 
    {
        Vec4i&amp; v=(*d);
        int startidx=v[0]; Point ptStart( contours[i][startidx] );
        int endidx=v[1]; Point ptEnd( contours[i][endidx] );
        int faridx=v[2]; Point ptFar( contours[i][faridx] );
        float depth = v[3] / 256;
        line( drawing, ptStart, ptEnd, Scalar(0,255,0), 1 );
        line( drawing, ptStart, ptFar, Scalar(0,255,0), 1 );
        line( drawing, ptEnd, ptFar, Scalar(0,255,0), 1 );
        circle( drawing, ptFar,   4, Scalar(0,255,0), 2 );
        d++;
    }
}
</code></pre>

<p>thanks,</p>
",2017-01-09 16:41:24,2017-01-09 16:41:24,How do I draw Convex Defects,<c#><image-processing><computer-vision><emgucv>,,,CC BY-SA 3.0,False,False,True,False,False
49307,41361851,2016-12-28 12:08:38,,"<p>I want too draw a contour in EmguCV 3.1.0.2504 but I get error: ""OpenCV: i&lt;0 .Children could not be evaluated.""</p>

<pre><code>IInputArrayOfArrays biggestCnt = GetBiggestCountour(BinaryImage);
Image&lt;Gray, byte&gt; justCountor = new Image&lt;Gray, byte&gt;(384, 284, new Gray(255));
CvInvoke.DrawContours(justCountor, biggestCnt, -1, new MCvScalar(255, 0, 0));
</code></pre>

<p><a href=""https://i.stack.imgur.com/dKCc0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dKCc0.png"" alt=""enter image description here""></a></p>
",,2017-01-07 05:54:58,Draw a contour in emgucv 3.1,<c#><opencv><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
49333,41560048,2017-01-10 02:08:36,,"<p>I am working on contour finding in a C# EmguCV project. For this project it is essential that I obtain the contour hierarchy data. I have used this method before in a C++ OpenCV project, so I understand the workings of the <code>FindContours</code> method and the <code>Hierarchy</code> information. Please find the relevant code below:</p>

<pre><code>Mat grayImage = new Mat(originalImage.Size, originalImage.Depth, 1);
Mat edges = new Mat(originalImage.Size, originalImage.Depth, 1);

CvInvoke.CvtColor(originalImage, grayImage, ColorConversion.Bgr2Gray);            
CvInvoke.Canny(grayImage, edges, 100, 200, 3);

var contours = new VectorOfVectorOfPoint();

Mat hierarchy = new Mat();
CvInvoke.FindContours(edges, contours, hierarchy, RetrType.Tree, ChainApproxMethod.ChainApproxSimple);
</code></pre>

<p>When I run this code contours are found as expected. Also the <code>Hierarchy Mat</code> object seems to get populated as expected, namely <code>1 x size of outputResult x 4</code> (see image below), yet the data in this object remains <code>null</code>:</p>

<p><a href=""https://i.stack.imgur.com/gE8Lj.png"" rel=""nofollow noreferrer"">Screenshot of hierarchy mat object</a></p>

<p>I have not been able to find an answer on how to extract the hierarchy contour (tree) data from this object. I have seen in <a href=""https://stackoverflow.com/a/37470968/7397065"">other StackOverflow posts (see also the comments)</a> that others have been struggling and/or that there may be bugs in the EmguCV 3.x library, but I have not been able to find an answer.</p>

<p>My question is thus: is it normal that the data field in the <code>Hierarchy Mat</code> object is <code>null</code>?</p>

<ul>
<li>If so: how do I extract the relevant hierarchical data from this <code>Mat</code> object?</li>
<li>If not: is there a way to circumvent this bug where the hierarchical data is <code>null</code>? Would it for example be possible to downgrade to EmguCV 2.x?</li>
</ul>
",2017-05-23 12:34:18,2020-04-02 06:41:24,C# - Emgu CV - FindContours hierarchy data always null,<c#><opencv><emgucv><contour>,,,CC BY-SA 3.0,True,True,True,False,False
49385,41294275,2016-12-23 02:03:54,,"<p>My background is C++ and I have been trying to translate one of my apps that uses OpenCV to a C# app that uses EmguCV. I have read the EmguCV documentation and Wiki as well as StackOverflow Q/As as deeply as humanly possible with no luck in solving some of the basic problems. At this point I wonder if the way I think about EmguCV is fundamentally flawed.</p>

<p>I was under the impression that when EmguCV has provided an interface to the C++ library for let's say <code>FloodFill</code> using <code>CvInvoke.FloodFill(IInputOutputArray, IInputOutputArray, ...)</code>, underneath it takes care of its own memory management to the point that the returning <code>IInputOutputArray</code>s (in my case a <code>Mat</code>) is all taken care of. In practice however, A call to <code>CvInvoke.FloodFill</code> fails with an exception from within the dll.</p>

<p>This is what I have:</p>

<pre><code>int i = ...
int j = ...
int intensity = ...
int height = img.Rows;
int width = img.Cols;
Mat outputMask = new Mat(height + 2, width + 2, DepthType.Cv8U, 1);
Rectangle dummy = new Rectangle();
CvInvoke.FloodFill(img, outputMask, new Point(i, j), new MCvScalar(255), out dummy, new MCvScalar(intensity), new MCvScalar(intensity), Connectivity.EightConnected, FloodFillType.MaskOnly);
</code></pre>

<p>But the call fails with an exception description that is not helpful. I have used <code>GCHandle</code> allocation and pinning for other methods to be able to access the raw data underneath, but I believe <code>CvInvoke.FloodFill</code> should be safe when called on some local <code>Mat</code>s.</p>

<p>My question is whether I'm completely off track with the way EmguCV is supposed to be used given my background with C++ and OpenCV. If so, what is the correct way of calling such function? </p>
",,2017-01-04 05:04:21,Correct way of memory management using Emgu CV 3.1,<c#><emgucv><flood-fill>,,,CC BY-SA 3.0,True,True,True,False,False
49500,41533809,2017-01-08 14:33:04,,"<p>I am working on a hand recognition project. At this point I'm able to detect the hand and I found the contour of the hand and convex hull points using the following code:</p>

<pre><code>Contour&lt;Point&gt; contours = imageThreshold.FindContours(Emgu.CV.CvEnum.CHAIN_APPROX_METHOD.CV_CHAIN_APPROX_SIMPLE,
   Emgu.CV.CvEnum.RETR_TYPE.CV_RETR_LIST, storage);
   Contour&lt;Point&gt; largestcontour = contours;
   while (contours != null)
   {
      if(largestcontour.Area &lt; contours.Area)
      {
         largestcontour = contours;
      }

      contours = contours.HNext;
   }
   if (largestcontour != null)
   {
      Seq&lt;Point&gt; convexHull = largestcontour.GetConvexHull(Emgu.CV.CvEnum.ORIENTATION.CV_CLOCKWISE);
      foreach (var hullPoint in convexHull)
      {
         CvInvoke.cvCircle(ColorFrame, hullPoint, 3, new MCvScalar(255), 2, Emgu.CV.CvEnum.LINE_TYPE.EIGHT_CONNECTED, 0);
      }

      CvInvoke.cvDrawContours(ColorFrame, convexHull, new MCvScalar(255),
                        new MCvScalar(128), 1, 1, Emgu.CV.CvEnum.LINE_TYPE.EIGHT_CONNECTED, new Point(0, 0));

   }
</code></pre>

<p>In the output there is more than one point on each fingertip. What I want is to get one point on each fingertip.</p>

<p>After doing some research, what I understood is that to get one point on each fingertip I need to find the farthest point from each vertex in the convex hull. </p>

<p>How do I get farthest points in convex hull?</p>
",2017-01-08 16:49:59,2017-01-12 11:21:38,Farthest points in convex hull,<c#><opencv><image-processing><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
49563,41593829,2017-01-11 14:45:16,,"<p>I am using EmguCV to create a capture from a video file stored on disk.  I set the capture property for frame position and then perform a QueryFrame.  On certain frames from the video, when I go to process the Mat further I get the error '{""OpenCV: Unrecognized or unsupported array type""}'.  This doesn't happen on all frames of the video but when I run it for the same video it happens for the same frames in the video.  If I save the Mat to disk the image looks perfectly fine and saves without error.  Here is the code for loading and processing the image:</p>

<pre><code>Capture cap = new Capture(movieLocation);
int framePos = 0;

while (reading)
{
    cap.SetCaptureProperty(CapProp.PosFrames, framePos);
    using (var frame = cap.QueryFrame())
    {
        if (frame != null)
        {
            try
            {
                var fm = Rotate(frame); // Works fine
                // Other Processing including classifier.DetectMultiScale -- Error occurs here
                frameMap.Add(framePos, r);
            }
            catch (Exception ex)
            {
                var s = """";  // Done to just see the error
            }
            framePos = framePos + 2;

        }
        else
        {
            reading = false;
        }
    }
}
</code></pre>

<p>Line of code which throws exception in further processing</p>

<pre><code>var r = _classifier.DetectMultiScale(matIn, 1.1, 2, new Size(200, 200), new Size(375, 375));
</code></pre>

<p>As I said, this does not fail for every frame of the video.</p>

<p>I'm trying to solve this because sometimes it skips 1 frame but at other times it will skip whole blocks of frames which is causing me to miss important events in the video.</p>
",2017-01-11 14:52:14,2017-01-11 17:56:52,EmguCV 3.1 Capture.QueryFrame returning error intermittantly,<opencv><emgucv><opencv3.1>,,,CC BY-SA 3.0,True,True,True,False,False
49660,41599155,2017-01-11 19:27:48,,"<p>I am currently trying to merge two separate camera images into one image as <a href=""https://de.wikipedia.org/wiki/Anaglyph_3D"" rel=""nofollow noreferrer"">Anaglyph</a>. The result should look something like <a href=""https://de.wikipedia.org/wiki/Anaglyph_3D#/media/File:Guitar3d.jpg"" rel=""nofollow noreferrer"">this image here</a>.</p>

<p>Here's my code that I wrote to capture the two camera images and converting them to black&amp;white:</p>

<pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Text;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Structure;
using Emgu.Util;

namespace CameraStereoCapture {

    public partial class CameraStereoCapture : Form {

        private bool captureInProgress;

        private VideoCapture cameraLeft = null;
        private VideoCapture cameraRight = null;

        private Mat leftRawFrame;
        private Mat rightRawFrame;

        private Mat leftGrayFrame;
        private Mat rightGrayFrame;

        private Mat stereoFrame;

        public CameraStereoCapture() {
            InitializeComponent();
            CvInvoke.UseOpenCL = false;
            try {
                cameraLeft = new VideoCapture(1);
                cameraLeft.ImageGrabbed += ProcessFrame;
                cameraRight = new VideoCapture(0);
                cameraRight.ImageGrabbed += ProcessFrame;
            } catch (NullReferenceException ex) {
                MessageBox.Show(ex.Message);
            }
            leftRawFrame = new Mat();
            rightRawFrame = new Mat();
            leftGrayFrame = new Mat();
            rightGrayFrame = new Mat();
            stereoFrame = new Mat();
        }

        private void cmdCapture_Click(object sender, EventArgs e) {
            if (cameraLeft != null) {
                if (captureInProgress) {
                    // stop the capture
                    cmdCapture.Text = ""Start Capture"";
                    cameraLeft.Pause();
                    cameraRight.Pause();
                } else {
                    // start the capture
                    cmdCapture.Text = ""Stop Capture"";
                    cameraLeft.Start();
                    cameraRight.Start();
                }
                captureInProgress = !captureInProgress;
            }
        }

        private void ProcessFrame(object sender, EventArgs arg) {
            // capture and cache image from left camera
            if (cameraLeft != null &amp;&amp; cameraLeft.Ptr != IntPtr.Zero) {
                cameraLeft.Retrieve(leftRawFrame, 0);
                imgLeft.Image = leftRawFrame;
            }
            // capture and cache image from right camera
            if (cameraRight != null &amp;&amp; cameraRight.Ptr != IntPtr.Zero) {
                cameraRight.Retrieve(rightRawFrame, 0);
                imgRight.Image = rightRawFrame;
            }
            // calculate stereo image by combining the left and right image
            if (leftRawFrame != null &amp;&amp; rightRawFrame!=null) {
                CvInvoke.CvtColor(leftRawFrame, leftGrayFrame, ColorConversion.Bgr2Gray);
                CvInvoke.CvtColor(rightRawFrame, rightGrayFrame, ColorConversion.Bgr2Gray);
                // TODO: how to convert 'leftRawImage to Cyan' ???
                // TODO: how to convert 'rightRawImage to Magenta' ???
                CvInvoke.AddWeighted(leftGrayFrame, 0.5, rightGrayFrame, 0.5, 1.0, stereoFrame);
                imgStereo.Image = stereoFrame;
            }
        }

    }

}
</code></pre>

<p>My question is, how to I convert the gray images to a <code>Cyan</code> and <code>Magenta</code> or <code>Red</code> and <code>Blue</code> (cp. lines in the code snippet that are marked as <code>TODO:</code>) ?</p>
",,2017-01-13 17:14:35,How to mix up a stereo image with EmguCV?,<opencv><emgucv><stereo-3d><stereoscopy>,,,CC BY-SA 3.0,True,True,True,False,False
49730,41604581,2017-01-12 03:23:39,,"<p>I'm doing projects using camera IP source onvif, but i can't catch exception when initialization new capture camera :
<a href=""https://i.stack.imgur.com/L8P5A.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/L8P5A.png"" alt=""enter image description here""></a></p>

<p>I'm start app debug but System Suspended by code new Capture(source ovif) , can't show exception. Thanks you.</p>
",,2017-07-07 13:13:24,unable catch exception new capture emgu CV c#,<emgucv><capture>,,,CC BY-SA 3.0,False,False,True,False,False
49747,41605375,2017-01-12 04:55:40,,"<p>I am Working Window based VB.NET Project in that we use <code>EmguCV,Opencv,Tessaract</code> techniques for Image Processing, My application gets crash and say to stop Application, It May be due to  </p>

<blockquote>
  <p><strong>ATTEMPTED READ OR WRITE PROTECTED MEMORY</strong></p>
</blockquote>

<p>this kind of error. I got the Error at Below lines</p>

<pre><code>ImageFrame2.ROI = New Rectangle(txtLeftRight3.Text, txtUpDown3.Text, txtwidth3.Text, txthight3.Text)
                       Capturez2.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, 352)
                        Capturez2.SetCaptureProperty(Emgu.CV.CvEnum.CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, 288)
</code></pre>

<p>I have searched many articles, I applied many Solutions like mention as Follows</p>

<p>Turn On DEP for all programmes, </p>

<p>untick from Visual studio 10-Suppress JIT Optimization,</p>

<p>Thread.Sleep after above code lines</p>

<p>Is there any solutions please mention these,thanks in Advance </p>
",2017-01-12 05:11:17,2017-02-07 07:22:22,"EmguCV Application Get crash when Error Occurs ""Attempted Read or Write Protected Memory. This is Often Indication that Other Memory Is Corrupt""",<vb.net><visual-studio-2010><opencv><image-processing><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
49766,41724448,2017-01-18 16:24:14,,"<p>I am trying to learn BOW object categorization. I have tried to implement the example given in the book ""<a href=""https://docs.google.com/file/d/0B5_mAdKvdKTleE5weDF0VTZvcms/edit"" rel=""nofollow noreferrer"">Practical OpenCV, Samarth Brahmbhatt</a>"" Chapter 8 (page 148)  </p>

<ul>
<li>When I save the SVM's to file on the training stage and read them on the categorization stage, the result is comletely different. (If the line
<code>svm = notFromFile[category];</code> is removed, the results are wrong; if not, it is successful with the dataset provided by the book.)</li>
<li>When I try this code with some larger datasets, I <strong>sometimes</strong> get this exception: <em>System.AccessViolationException' in Emgu.CV.World.dll</em>  for the line <code>bowDescriptorExtractor.Compute(frame_g, kp, img);</code> and the application closes. It cannot be handled.</li>
</ul>

<p>I have tried many things but could not figure them out. Any suggestions why these are happening, and how to solve, is very appreciated.</p>

<p>I am using emgucv-windesktop 3.1.0.2504</p>

<p>My implementation:</p>

<pre><code>internal class Categorizer3 : ICategorizer
    {
        public string Name
        {
            get
            {
                return ""Categorizer3"";
            }
        }

        public bool Train()
        {
            try
            {
                initDir();
                Feature2D descriptorExtractor;
                Feature2D featureDetector;
                List&lt;Mat&gt; templates;
                BOWKMeansTrainer bowtrainer;
                BOWImgDescriptorExtractor bowDescriptorExtractor;
                init(out descriptorExtractor, out featureDetector, out templates, out bowtrainer, out bowDescriptorExtractor);

                List&lt;Tuple&lt;string, Mat&gt;&gt; train_set;
                List&lt;string&gt; category_names;
                make_train_set(out train_set, out category_names);

                Mat vocab;
                build_vocab(descriptorExtractor, featureDetector, templates, bowtrainer, out vocab);

                bowDescriptorExtractor.SetVocabulary(vocab);

                Dictionary&lt;string, Mat&gt; positive_data;
                Dictionary&lt;string, Mat&gt; negative_data;
                make_pos_neg(train_set, bowDescriptorExtractor, featureDetector, category_names, out positive_data, out negative_data);

                this.train_classifiers(category_names, positive_data, negative_data);

                return true;
            }
            catch (Exception)
            {
                return false;
            }
        }
        public event TrainedEventHandler Trained;
        protected void OnTrained(string fn)
        {
            if (this.Trained != null)
                this.Trained(fn);
        }
        public Categorizer3()
        {
        }
        private Feature2D create_FeatureDetector()
        {
            return new SURF(500);
            //return new KAZE();
            //return new SIFT();
            //return new Freak();
        }
        private BOWImgDescriptorExtractor create_bowDescriptorExtractor(Feature2D descriptorExtractor)
        {
            LinearIndexParams ip = new LinearIndexParams();
            SearchParams sp = new SearchParams();
            var descriptorMatcher = new FlannBasedMatcher(ip, sp);

            return new BOWImgDescriptorExtractor(descriptorExtractor, descriptorMatcher);
        }
        private void init(out Feature2D descriptorExtractor, out Feature2D featureDetector, out List&lt;Mat&gt; templates, out BOWKMeansTrainer bowtrainer, out BOWImgDescriptorExtractor bowDescriptorExtractor)
        {
            int clusters = 1000;
            featureDetector = create_FeatureDetector();

            MCvTermCriteria term = new MCvTermCriteria(10000, 0.0001d);
            term.Type = TermCritType.Iter | TermCritType.Eps;
            bowtrainer = new BOWKMeansTrainer(clusters, term, 5, Emgu.CV.CvEnum.KMeansInitType.PPCenters);//****


            BFMatcher matcher = new BFMatcher(DistanceType.L1);//****
            descriptorExtractor = featureDetector;//******

            bowDescriptorExtractor = create_bowDescriptorExtractor(descriptorExtractor);


            templates = new List&lt;Mat&gt;();
            string TEMPLATE_FOLDER = ""C:\\Emgu\\book\\practical-opencv\\code\\src\\chapter8\\code8-5\\data\\templates"";
            //string TEMPLATE_FOLDER = ""C:\\Emgu\\book\\practical-opencv\\code\\src\\chapter8\\code8-5\\data\\train_images"";
            foreach (var filename in Directory.GetFiles(TEMPLATE_FOLDER, ""*"", SearchOption.AllDirectories))
            {
                templates.Add(GetMat(filename, true));
                this.OnTrained(filename);
            }
        }


        void make_train_set(out List&lt;Tuple&lt;string, Mat&gt;&gt; train_set, out List&lt;string&gt; category_names)
        {
            string TRAIN_FOLDER = ""C:\\Emgu\\book\\practical-opencv\\code\\src\\chapter8\\code8-5\\data\\train_images"";

            category_names = new List&lt;string&gt;();
            train_set = new List&lt;Tuple&lt;string, Mat&gt;&gt;();
            foreach (var dir in Directory.GetDirectories(TRAIN_FOLDER))
            {
                // Get category name from name of the folder
                string category = new DirectoryInfo(dir).Name;
                category_names.Add(category);
                foreach (var filename in Directory.GetFiles(dir))
                {     
                    train_set.Add(new Tuple&lt;string, Mat&gt;(category, GetMat(filename, true)));
                    this.OnTrained(filename);
                }
            }
        }

        void build_vocab(Feature2D descriptorExtractor, Feature2D featureDetector, List&lt;Mat&gt; templates, BOWKMeansTrainer bowtrainer, out Mat vocab)
        {
            Mat vocab_descriptors = new Mat();
            foreach (Mat templ in templates)
            {
                Mat desc = new Mat();
                VectorOfKeyPoint kp = new VectorOfKeyPoint(featureDetector.Detect(templ));
                descriptorExtractor.Compute(templ, kp, desc);
                vocab_descriptors.PushBack(desc);
            }

            bowtrainer.Add(vocab_descriptors);
            vocab = new Mat();
            bowtrainer.Cluster(vocab);

            string fn = getVocabularyFileName();
            using (FileStorage fs = new FileStorage(fn, FileStorage.Mode.Write))
            {
                fs.Write(vocab, ""vocab"");
                fs.ReleaseAndGetString();
            }
        }

        void make_pos_neg(List&lt;Tuple&lt;string, Mat&gt;&gt; train_set, BOWImgDescriptorExtractor bowDescriptorExtractor, Feature2D featureDetector, List&lt;string&gt; category_names,
            out Dictionary&lt;string, Mat&gt; positive_data, out Dictionary&lt;string, Mat&gt; negative_data)
        {
            positive_data = new Dictionary&lt;string, Mat&gt;();
            negative_data = new Dictionary&lt;string, Mat&gt;();

            foreach (var tu in train_set)
            {
                string category = tu.Item1;
                Mat im = tu.Item2;
                Mat feat = new Mat();

                VectorOfKeyPoint kp = new VectorOfKeyPoint(featureDetector.Detect(im));
                bowDescriptorExtractor.Compute(im, kp, feat);

                for (int cat_index = 0; cat_index &lt; category_names.Count; cat_index++)
                {
                    string check_category = category_names[cat_index];
                    if (check_category.CompareTo(category) == 0)
                    {
                        if (!positive_data.ContainsKey(check_category))
                            positive_data[check_category] = new Mat();
                        positive_data[check_category].PushBack(feat);
                    }
                    else
                    {
                        if (!negative_data.ContainsKey(check_category))
                            negative_data[check_category] = new Mat();
                        negative_data[check_category].PushBack(feat);
                    }
                }
            }
        }
        void train_classifiers(List&lt;string&gt; category_names, Dictionary&lt;string, Mat&gt; positive_data, Dictionary&lt;string, Mat&gt; negative_data)
        { 
            for (int i = 0; i &lt; category_names.Count; i++)
            {
                string category = category_names[i];

                // Postive training data has labels 1
                Mat train_data = positive_data[category];
                Mat train_labels = new Mat(train_data.Rows, 1, DepthType.Cv32S, 1);
                {
                    for (int col = 0; col &lt; train_labels.Cols; col++)
                        for (int row = 0; row &lt; train_labels.Rows; row++)
                            train_labels.SetValue(row, col, (int)1);
                    train_labels.SetTo(new MCvScalar(1));


                    // Negative training data has labels 0
                    train_data.PushBack(negative_data[category]);
                    Mat m = new Mat(negative_data[category].Rows, 1, DepthType.Cv32S, 1);
                    {
                        for (int col = 0; col &lt; m.Cols; col++)
                            for (int row = 0; row &lt; m.Rows; row++)
                                m.SetValue(row, col, (int)0);
                        m.SetTo(new MCvScalar(0));

                        train_labels.PushBack(m);
                    }

                    SVM svm = new SVM();
                    svm.C = 312.5;
                    svm.Gamma = 0.50625000000000009;
                    svm.SetKernel(SVM.SvmKernelType.Rbf);
                    svm.Type = SVM.SvmType.CSvc;

                    svm.Train(train_data, Emgu.CV.ML.MlEnum.DataLayoutType.RowSample, train_labels);

                    var fn = getSVMFileName(category);
                    svm.SaveSVMToFile(fn);

                    notFromFile[category] = svm;
                }
            }
        }
        Dictionary&lt;string, SVM&gt; notFromFile = new Dictionary&lt;string, SVM&gt;();//****


        private void initDir()
        {
            var dir = getSaveDir();
            if (Directory.Exists(dir))
                foreach (var fn in Directory.GetFiles(dir))
                    File.Delete(fn);
        }
        private string getSaveDir()
        {
            string dir = Path.Combine(Path.GetTempPath(), ""Dece"", ""SVMS"");
            if (!Directory.Exists(dir))
                Directory.CreateDirectory(dir);
            return dir;
        }
        private string getSVMFileName(string category)
        {
            return Path.Combine(getSaveDir(), category + "".svm"");
        }
        private string getVocabularyFileName()
        {
            return Path.Combine(getSaveDir(), ""vocabulary.voc"");
        }


        //[HandleProcessCorruptedStateExceptions]
        public IEnumerable&lt;ImageInfo&gt; Categorize(IEnumerable&lt;string&gt; imageFileNames)
        {   
            var featureDetector = create_FeatureDetector();
            var bowDescriptorExtractor = create_bowDescriptorExtractor(featureDetector);

            Mat vocab = new Mat();
            using (var fs = new FileStorage(getVocabularyFileName(), FileStorage.Mode.Read))
                fs[""vocab""].ReadMat(vocab);


            bowDescriptorExtractor.SetVocabulary(vocab);

            Dictionary&lt;string, string&gt; svms = new Dictionary&lt;string, string&gt;();
            foreach (var xml in Directory.GetFiles(getSaveDir(), ""*.svm""))
                svms.Add(Path.GetFileNameWithoutExtension(xml), xml);


            Dictionary&lt;string, SVM&gt; dic = new Dictionary&lt;string, SVM&gt;();

            foreach (var fn in imageFileNames)
            {
                string scoreTxt = Environment.NewLine;
                float score = float.MaxValue;
                //float score = float.MinValue;
                string cat = """";

                try
                {
                    using (Mat frame_g = GetMat(fn, false))
                    {
                        using (Mat img = new Mat())
                        {
                            VectorOfKeyPoint kp = new VectorOfKeyPoint(featureDetector.Detect(frame_g));

                            bowDescriptorExtractor.Compute(frame_g, kp, img);

                            foreach (var category in svms.Keys)
                            {
                                SVM svm = null;
                                if (!dic.ContainsKey(category))
                                {
                                    string svmFn = svms[category];
                                    svm = new SVM();
                                    svm.LoadSVMFromFile(svmFn);
                                    dic[category] = svm;
                                }
                                else
                                    svm = dic[category];
                                svm = notFromFile[category];//*************

                                float classVal = svm.Predict(img, null);
                                float scoreVal = svm.Predict(img, null, 1);
                                //float signMul = (classVal &lt; 0) == (scoreVal &lt; 0) ? 1f : -1f;
                                //float score1 = signMul * scoreVal;

                                scoreTxt += string.Format(""{0}-{1}: {2}{3}"", category, classVal.ToString(), scoreVal.ToString(""N3""), Environment.NewLine);

                                if (scoreVal &lt; score)
                                {
                                    score = scoreVal;
                                    cat = category;
                                }
                            }
                        }
                    }
                }
                catch (Exception)
                {
                    score = 0f;
                    cat = ""hata"";
                }
                if (string.IsNullOrEmpty(cat))
                    score = 0f;
                yield return new ImageInfo(fn, cat, scoreTxt);
            }
        }


        private static object matLocker = new object();
        public Mat GetMat(string fn, bool train)
        {
            lock (matLocker)
            {
                var mat = new Mat(fn, ImreadModes.Color);
                var mat2 = new Mat();
                mat.ConvertTo(mat2, DepthType.Cv8U);
                return mat2;
            }
        }
    }
</code></pre>
",2017-01-19 07:11:15,2017-01-23 06:21:13,Cannot make EmguCV-OpenCV BOW Categorization work properly,<c#><opencv><classification><svm><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
49884,41612852,2017-01-12 12:07:21,,"<p>I'm trying to get frames from a video file but while reading frames, OpenCv:u!=0 exception is being thrown. I'm using Emgu.Cv dll.
I have written the code as follows:</p>

<pre><code>private void GetVideoFrames(String Filename)
{
    try
    {
        captureFrame = new Capture(Filename);
        bool Reading = true;
        while (Reading)
        {
            using (frame = captureFrame.QueryFrame().ToImage&lt;Bgr, Byte&gt;())
            {
                if 
                if (frame != null)
                {
                    imageBox1.Image = frame;
                    frameCount++;
                }
                else
                {
                    Reading = false;
                }
            }
        }
    }
</code></pre>

<p>Could anyone please provide some help.</p>
",2017-01-12 12:40:24,2017-02-07 07:16:18,OpenCv:u!=0 Exception while reading frames from video file,<c#><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
49920,41735425,2017-01-19 06:46:02,,"<p>I have a WritableBitmap, and I would like to convert it to a EmguCV/OpenCV Mat. How would I go about doing that? I've tried several chain solutions (WritableBitmap -> Bitmap -> Map) from code online, but I haven't found anything that works. Thanks!</p>
",2017-01-19 15:27:22,2017-01-31 21:51:25,How do you convert a C# WritableBitmap to a EmguCV/OpenCV Mat?,<c#><opencv><emgucv><mat><writeablebitmap>,,,CC BY-SA 3.0,True,True,True,False,False
49937,41891192,2017-01-27 09:57:05,,"<p>I am new on this subject. What I try to do is train many SVM's for the same dataset with different parameters (different kind of signature of images in the future I hope) then predict each SVM and accept the mostly found class.</p>

<p>I tried to read many peoples' code about SVM image training, but couldn't figure out what I am doing wrong im my code. What ever I try, svm.Predict always return 0.</p>

<p>Any help or hint is very appreciated.</p>

<pre><code>    internal class SVMClassifier
    {
        Dictionary&lt;int, string&gt; classIndex_name;
        List&lt;SVM&gt; svms;

        internal void Train(string trainFolder)
        {
            this.classIndex_name = new Dictionary&lt;int, string&gt;();
            Dictionary&lt;int, List&lt;Mat&gt;&gt; class_mats = getMats(trainFolder, this.classIndex_name);
            this.svms = new List&lt;SVM&gt;();


            Mat samples; Mat responses;
            getTrainingData(class_mats, out samples, out responses);
            svms.Add(trainSVM(samples, responses));
            svms.Add(trainSVM(samples, responses, SVM.SvmType.CSvc, SVM.SvmKernelType.Linear, 0d, 0d, 10d, TermCritType.Iter | TermCritType.Eps, 1000, 0.000001d, 0d, 0d));
            svms.Add(trainSVM(samples, responses, SVM.SvmType.CSvc, SVM.SvmKernelType.Rbf, 100d, 100d, 1d, TermCritType.Iter | TermCritType.Eps, 1000, 0.000001d, 0.1d, 0.5d));

            samples.Dispose(); responses.Dispose();

            foreach (Mat mat in class_mats.Values.SelectMany((a) =&gt; a))
                mat.Dispose();
        }
        private static Dictionary&lt;int, List&lt;Mat&gt;&gt; getMats(string trainFolder, Dictionary&lt;int, string&gt; classIndex_name)
        {
            Dictionary&lt;int, List&lt;Mat&gt;&gt; class_mats = new Dictionary&lt;int, List&lt;Mat&gt;&gt;();
            DirectoryInfo diTrain = new DirectoryInfo(trainFolder);
            int i = 0;
            foreach (var di in diTrain.GetDirectories())//classes are according to the directories
            {
                var dirName = di.Name;
                classIndex_name[i] = dirName;
                var fileNames = di.GetFiles().Select((a) =&gt; a.FullName).ToList();
                fileNames.Sort(new Dece.Misc.NumericSuffixFileFullNameComparer());
                class_mats[i] = fileNames.Select((a) =&gt; getMat(a, true)).ToList();
                i++;
            }
            return class_mats;
        }

        private static SVM trainSVM(Mat samples, Mat responses,
            SVM.SvmType? svm_Type = null, SVM.SvmKernelType? svm_KernelType = null, double? gamma = null, double? degree = null, double? c = null,
            TermCritType? criteriaType = null, int? criteriaMaxCount = null, double? criteriaEps = null, double? p = null, double? nu=null)
        {
            SVM svm = new SVM();
            if (svm_Type != null) svm.Type = (SVM.SvmType)svm_Type;
            if (svm_KernelType != null) svm.SetKernel((SVM.SvmKernelType)svm_KernelType);
            if (gamma != null) svm.Gamma = (double)gamma;
            if (degree != null) svm.Degree = (double)degree;
            if (c != null) svm.C = (double)c;

            if ((criteriaType != null) || (criteriaMaxCount != null) || (criteriaEps != null))
            {
                var t = new MCvTermCriteria((int)criteriaMaxCount, (double)criteriaEps);
                if (criteriaType != null) t.Type = (TermCritType)criteriaType;
                svm.TermCriteria = t;
            }


            if (p != null) svm.P = (double)p;
            if (nu != null) svm.Nu = (double)nu;

            if (!svm.Train(samples, DataLayoutType.RowSample, responses))
                throw new Exception();
            return svm;
        }

        private static void getTrainingData(Dictionary&lt;int, List&lt;Mat&gt;&gt; class_mats, out Mat samples, out Mat responses)
        {
            samples = null;
            List&lt;int&gt; lstResp = new List&lt;int&gt;();
            foreach (int cls in class_mats.Keys)
            {
                int count = 0;
                foreach (Mat mat in class_mats[cls])
                    using (var desc = mat.Reshape(0, 1))
                    {
                        if (samples == null)
                            samples = new Mat(desc.Cols, 0, desc.Depth, 1);
                        samples.PushBack(desc);
                        count += desc.Rows;
                    }
                for (int i = 0; i &lt; count; i++)
                    lstResp.Add(cls);
            }

            //responses = new Mat(new Size(lstResp.Count, 1), DepthType.Cv32S, 1);
            //for (int i = 0; i &lt; lstResp.Count; i++)
            //    responses.SetValue(0, i, lstResp[i]);

            responses = new Mat(new Size(1, lstResp.Count), DepthType.Cv32S, 1);
            for (int i = 0; i &lt; lstResp.Count; i++)
                responses.SetValue(i, 0, lstResp[i]);

            if (samples.Depth != DepthType.Cv32F)
                samples.ConvertTo(samples, DepthType.Cv32F);

            CvInvoke.Normalize(samples, samples, -1, 1, NormType.MinMax);
        }

        internal void Detect(IEnumerable&lt;string&gt; fileNames, Action&lt;ShapeInfo&gt; detected)
        {
            foreach (var fn in fileNames)
                using (Mat mat = getMat(fn, false))
                {
                    {
                        using (var samples = mat.Reshape(0, 1))
                        {
                            if (samples.Depth != DepthType.Cv32F)
                                samples.ConvertTo(samples, DepthType.Cv32F);
                            CvInvoke.Normalize(samples, samples, -1, 1, NormType.MinMax);
                            foreach (var svm in this.svms)
                            {
                                Mat res = new Mat();
                                float p0 = svm.Predict(samples, res, 0);
                                float p1 = svm.Predict(samples, res, 1);
                                float p2 = svm.Predict(samples, res, 2);
                                float p3 = svm.Predict(samples, res, 3);
                                float p4 = svm.Predict(samples, res, 4);
                                float p = svm.Predict(samples, res);

                                foreach (var val in toIEnumerable(p0, p1, p2, p3, p4, p))
                                    if (val != 0f)
                                    {
                                        System.Windows.Forms.MessageBox.Show(""never enters here :("");
                                    }
                            }
                        }
                    }
                }
        }

        private static Mat getMat(string fn, bool train)
        {
            var mat = new Mat(fn, ImreadModes.Grayscale);
            mat.Resize(new Size(128, 128));
            return mat;
        }
        private static IEnumerable&lt;T&gt; toIEnumerable&lt;T&gt;(params T[] items)
        {
            if (items != null)
                foreach (var item in items)
                    yield return item;
        }

    }
</code></pre>

<p>Mat.SetValue extension is taken from <a href=""https://stackoverflow.com/a/32559496/1266873"">here</a>.</p>

<p>I hope asking like that is propriate for this site's format. If not this question can be closed-erased, no problem. I am trying to understand how should we train an svm with images.</p>
",2017-05-23 10:29:18,2017-01-27 12:30:48,Cannot make SVM working as I expected,<c#><opencv><svm><emgucv>,,,CC BY-SA 3.0,True,True,True,False,False
49974,41858557,2017-01-25 18:05:40,,"<p>I am attempting to identify a ""T"" shape as well as an ""L"" shape which can be reversed, as shown below. I am using EMGU in C#.</p>

<p><strong>Shape: T</strong></p>

<p><a href=""https://i.stack.imgur.com/F1Tjs.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/F1Tjs.jpg"" alt=""enter image description here""></a></p>

<p><strong>Shape: L (Regular)</strong></p>

<p><a href=""https://i.stack.imgur.com/aey4M.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aey4M.jpg"" alt=""enter image description here""></a></p>

<p><strong>Shape: L (Reversed)</strong></p>

<p><a href=""https://i.stack.imgur.com/RDbbm.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RDbbm.jpg"" alt=""enter image description here""></a></p>

<p>I am attempting to consistently detect these different shapes, and I have tried using the Contour approach as shown in <a href=""http://www.emgu.com/wiki/index.php/Shape_(Triangle,_Rectangle,_Circle,_Line)_Detection_in_CSharp"" rel=""nofollow noreferrer"">the EMGU shape detection tutorial</a>. The problem is that it does not detect the contour points correctly, or when it occasionally does, it is not reliable.</p>

<p><strong>Contour Logic Output</strong></p>

<p><a href=""https://i.stack.imgur.com/WrNJM.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WrNJM.jpg"" alt=""enter image description here""></a></p>

<p>These shapes will be mostly the same, but can be rotated or have a slightly different perspective. What would be an accurate, efficient way to detect these different shapes consistently?</p>

<p>Thanks!</p>
",,2017-02-21 17:44:06,Identify fairly simple shapes with EMGU,<c#><opencv><image-processing><computer-vision><emgucv>,,,CC BY-SA 3.0,True,False,True,False,False
