,Unnamed: 0,Id,PostTypeId,AcceptedAnswerId,ParentId,CreationDate,DeletionDate,Score,ViewCount,Body,LastEditDate,LastActivityDate,Title,Tags,AnswerCount,CommentCount,FavoriteCount,ClosedDate,CommunityOwnedDate,ContentLicense,HotScore
19773,19773,54334304,1,54409674.0,,2019-01-23 19:24:21,,31,44775,difference spacy load en core web sm spacy load en link explains different model size still clear spacy load en core web sm spacy load en differ spacy load en run fine spacy load en core web sm throw error installed go jupyter notebook run command nlp spacy load en core web sm get error oserror traceback recent call last import spacy load language library import spacy nlp spacy load en core web sm create doc object c user nikhizzz appdata local conda conda envs tensorflowspyder lib site package spacy init py load name override depr path true false none deprecation warning warning w format path depr path return util load model name override c user nikhizzz appdata local conda conda envs tensorflowspyder lib site package spacy util py load model name override elif hasattr name exists path path like model data return load model path name override raise ioerror error e format name name oserror e find model en core web sm seem shortcut link python package valid path data directory installed spacy c user nikhizzz appdata local conda conda envs tensorflowspyder c user nikhizzz conda install c conda forge spacy fetching package metadata solving package specification package plan installation environment c user nikhizzz appdata local conda conda envs tensorflowspyder following new package installed blas mkl cymem py h conda forge dill py conda forge msgpack numpy py conda forge murmurhash py h conda forge plac py conda forge preshed py h conda forge pyreadline py conda forge regex py conda forge spacy py h ac b conda forge termcolor py conda forge thinc py h ac b conda forge tqdm py conda forge ujson py hfa e cd conda forge following package updated msgpack python py py bc conda forge following package downgraded freetype vc conda forge vc proceed n blas mkl time b cymem p time mb msgpack python time mb murmurhash time mb plac py time b pyreadline time mb regex time mb termcolor time kb tqdm py time mb ujson py time mb dill p time mb msgpack numpy time b preshed time b thinc p time mb spacy p time mb c user nikhizzz appdata local conda conda envs tensorflowspyder c user nikhizzz python v python anaconda custom bit c user nikhizzz appdata local conda conda envs tensorflowspyder c user nikhizzz python spacy download en collecting en core web sm http github com explosion spacy model release download en core web sm en core web sm tar gz egg en core web sm downloading http github com explosion spacy model release download en core web sm en core web sm tar gz mb mb installing collected package en core web sm running setup py install en core web sm done successfully installed en core web sm linking successful c user nikhizzz appdata local conda conda envs tensorflowspyder lib site package en core web sm c user nikhizzz appdata local conda conda envs tensorflowspyder lib site package spacy data en load model via spacy load en c user nikhizzz appdata local conda conda envs tensorflowspyder c user nikhizzz,,2020-09-10 19:45:29,spacy find model en core web sm window python anaconda custom bit,python-3.x spacy,11,2,8.0,,,CC BY-SA 4.0,0.00011816362611570509
23335,23335,58636587,1,,,2019-10-31 03:34:11,,16,7533,know bert ha max length limit token acticle ha length much bigger token text bert used,2019-11-05 22:56:47,2020-09-02 12:11:33,use bert long text classification,nlp text-classification bert-language-model,5,0,3.0,,,CC BY-SA 4.0,9.251026761830646e-05
1166,1166,16370583,1,,,2013-05-04 04:29:21,,104,204759,difficult time using pip install almost anything new coding thought maybe something wrong opted easy install get needed done ha generally worked however trying download nltk library neither getting job done tried entering sudo pip install nltk got following response library framework python framework version bin pip run sat may downloading unpacking nltk getting page http pypi python org simple nltk could fetch url need reputation post link wa problem confirming ssl certificate skip url need reputation post link simple nltk looking download link nltk getting page need reputation post link simple could fetch url http pypi python org simple wa problem confirming ssl certificate skip url need reputation post link looking download link nltk fetch index base url need reputation post link url search version nltk need reputation post link getting page need reputation post link could fetch url need reputation post link wa problem confirming ssl certificate skip url need reputation post link looking download link nltk could find downloads satisfy requirement nltk distribution found nltk exception information traceback recent call last file library framework python framework version lib python site package pip py egg pip basecommand py line main status self run option args file library framework python framework version lib python site package pip py egg pip command install py line run requirement set prepare file finder force root egg info self bundle bundle self bundle file library framework python framework version lib python site package pip py egg pip req py line prepare file url finder find requirement req install upgrade self upgrade file library framework python framework version lib python site package pip py egg pip index py line find requirement raise distributionnotfound distribution found req distributionnotfound distribution found nltk easy install installed fragment library code ran trouble quickly upon trying run thought issue really appreciate feedback either get pip working something get around issue meantime,2017-08-08 17:11:07,2020-08-12 01:51:46,pip issue installing almost library,python pip nltk easy-install,26,1,37.0,,,CC BY-SA 3.0,9.13132166063771e-05
16650,16650,49964028,1,50342159.0,,2018-04-22 08:33:02,,42,55195,even though downloaded model load jalal goku entity sentiment analysis python scratch sjn anaconda bin python jalal goku entity sentiment analysis sudo python spacy download en sudo password jalal collecting http github com explosion spacy model release download en core web sm en core web sm tar gz downloading http github com explosion spacy model release download en core web sm en core web sm tar gz mb mb mb installing collected package en core web sm running setup py install en core web sm done successfully installed en core web sm linking successful usr lib python site package en core web sm usr lib python site package spacy data en load model via spacy load en import spacy nlp spacy load en oserror traceback recent call last import spacy nlp spacy load en scratch sjn anaconda lib python site package spacy init py load name override load example nnlp spacy load format depr path error return util load model name override scratch sjn anaconda lib python site package spacy util py load model name override elif hasattr name exists path path like model data return load model path name override raise ioerror find model name oserror find model en fix use sudo downloading en model get collecting http github com explosion spacy model release download en core web sm en core web sm tar gz downloading http github com explosion spacy model release download en core web sm en core web sm tar gz mb mb mb ta mb mb eta requirement already satisfied use upgrade upgrade en core web sm http github com explosion spacy model release download en core web sm en core web sm tar gz scratch sjn anaconda lib python site package using pip version however version available consider upgrading via pip install upgrade pip command error link model en creating symlink spacy data failed make sure required permission try running command admin use virtualenv still import model module call load method create symlink manually scratch sjn anaconda lib python site package en core web sm scratch sjn anaconda lib python site package spacy data en download successful linking failed creating shortcut link en work maybe admin permission still load model via full package name nlp spacy load en core web sm,2018-04-26 23:09:28,2020-06-19 14:55:25,spacy oserror find model en,nlp spacy,11,1,12.0,,,CC BY-SA 3.0,8.010113314449436e-05
6200,6200,26570944,1,26575754.0,,2014-10-26 07:52:51,,98,113655,code import nltk data tokenizer nltk data load nltk tokenizers punkt english pickle error message ec user ip sentiment python mapper local v py traceback recent call last file mapper local v py line tokenizer nltk data load nltk tokenizers punkt english pickle file usr lib python site package nltk data py line load opened resource open resource url file usr lib python site package nltk data py line open return find path path open file usr lib python site package nltk data py line find raise lookuperror resource found lookuperror resource u tokenizers punkt english pickle found please use nltk downloader obtain resource nltk download searched home ec user nltk data usr share nltk data usr local share nltk data usr lib nltk data usr local lib nltk data u trying run program unix machine per error message logged python shell unix machine used command import nltk nltk download downloaded available thing using loader l list option still problem persists tried best find solution internet got solution mentioned step,2014-12-09 15:03:23,2020-08-01 02:50:32,resource u tokenizers punkt english pickle found,python unix nltk,17,1,14.0,,,CC BY-SA 3.0,7.863049080250763e-05
3094,3094,17531684,1,17547860.0,,2013-07-08 16:35:31,,141,157521,looking way split text n gram normally would something like import nltk nltk import bigram string really like python pretty awesome string bigram bigram string print string bigram aware nltk offer bigram trigram way split text four gram five gram even hundred gram thanks,2015-11-09 03:42:23,2020-05-02 00:13:19,n gram python four five six gram,python string nltk n-gram,15,3,51.0,,,CC BY-SA 3.0,7.071137004888903e-05
22010,22010,57062456,1,,,2019-07-16 17:17:22,,12,17412,reimplementing text speech project facing function call stack kera scratch graph error decoder part network architecture deep voice paper using kera tf google colab code decoder kera model tf one shape def decoder name decoder decoder prenet din tf concat tf zero like hp mel hp mel key k input shape batch size name key vals k input shape batch size name vals prev max attention li tf one shape hp dlayer hp batch size dtype tf int prev max attention li k input tensor prev max attention li range hp dlayer dpout k layer dropout rate else hp dropout din fc k layer dense hp char embed activation relu dpout print print fc value fc print query pe k layer embedding hp ty hp char embed tf tile tf expand dims tf range hp ty hp r hp batch size key pe k layer embedding hp tx hp char embed tf tile tf expand dims tf range hp tx hp batch size alignment li max attention li range hp dlayer dpout k layer dropout rate fc query k layer conv hp datten size hp dfilter padding causal dilation rate dpout fc query fc tf math sqrt print print fc value fc print query fc query pe key key pe tensor alignment max attention attention name attention query key vals prev max attention li fc tensor query tf math sqrt alignment li append alignment max attention li append max attention decoder output fc dpout k layer dropout rate decoder output mel logits k layer dense hp mel hp r dpout dpout k layer dropout rate fc done output k layer dense dpout return k model input key vals output mel logits done output decoder output alignment li max attention li name name decode decoder kin tf one shape vin tf one shape print decode kin vin tf kera utils plot model decode file decoder png show shape true test data show error message going problem fc dun know pas fc output first loop second loop answer would appreciated file decoder py line decode decoder file decoder py line decoder dpout k layer dropout rate fc file user ydc dl npm lib python site package tensorflow python kera engine base layer py line call base layer utils create kera history input file user ydc dl npm lib python site package tensorflow python kera engine base layer utils py line create kera history created layer create kera history helper tensor set file user ydc dl npm lib python site package tensorflow python kera engine base layer utils py line create kera history helper layer input processed ops created layer file user ydc dl npm lib python site package tensorflow python kera engine base layer utils py line create kera history helper layer input processed ops created layer file user ydc dl npm lib python site package tensorflow python kera engine base layer utils py line create kera history helper layer input processed ops created layer file user ydc dl npm lib python site package tensorflow python kera engine base layer utils py line create kera history helper constant backend function op input file user ydc dl npm lib python site package tensorflow python kera backend py line call output self graph fn converted input file user ydc dl npm lib python site package tensorflow python eager function py line call return self call flat args file user ydc dl npm lib python site package tensorflow python eager function py line call flat output self inference function call ctx args file user ydc dl npm lib python site package tensorflow python eager function py line call ctx ctx file user ydc dl npm lib python site package tensorflow python eager execute py line quick execute six raise core status exception e code message none file line raise tensorflow python framework error impl failedpreconditionerror error reading resource variable anonymousvar container localhost could mean variable wa uninitialized found resource localhost anonymousvar n tensorflow vare doe exist node dense biasadd readvariableop defined decoder py op inference kera scratch graph function call stack kera scratch graph,2019-08-07 17:41:15,2020-08-06 09:45:12,function call stack kera scratch graph error,python tensorflow keras nlp tensorflow2.0,7,1,3.0,,,CC BY-SA 4.0,6.473421167921858e-05
1780,1780,22129943,1,22130100.0,,2014-03-02 16:04:53,,127,97838,according gensim word vec use word vec model gensim package calculate similarity word e g trained model similarity woman man however word vec model fails predict sentence similarity find lsi model sentence similarity gensim seem combined word vec model length corpus sentence long shorter word simple way achieve goal,2016-04-12 13:10:22,2020-01-08 06:38:49,calculate sentence similarity using word vec model gensim python,python gensim word2vec,13,4,77.0,,,CC BY-SA 3.0,5.9606343035252674e-05
84,84,8897593,1,8897648.0,,2012-01-17 15:51:09,,217,181701,looking working nlp project programming language though python preference want take two document determine similar,2019-02-19 17:11:44,2020-05-13 06:14:59,compute similarity two text document,nlp,10,1,179.0,,,CC BY-SA 4.0,5.614956484972162e-05
14682,14682,47295316,1,47297686.0,,2017-11-14 21:15:08,,39,53109,working codebase us spacy installed spacy using sudo pip install spacy sudo python spacy download en end last command got message linking successful home rayabhik local lib python site package en core web sm home rayabhik local lib python site package spacy data en load model via spacy load en try running code line spacy en import english give following error importerror module named spacy en looked stackexchange closest import error spacy module named en doe solve problem help would appreciated thanks edit might solved following python default sep gcc linux type help copyright credit license information import spacy spacy load en using spacy lang en import english still keeping open case answer,2018-03-28 08:05:49,2020-06-01 23:52:15,importerror module named spacy en,python spacy,10,5,8.0,,,CC BY-SA 3.0,5.5095370540910394e-05
7579,7579,34870614,1,34877590.0,,2016-01-19 07:14:40,,161,68344,tf nn embedding lookup params id partition strategy mod name none understand duty function like lookup table mean return parameter corresponding id id instance skip gram model use tf nn embedding lookup embeddings train input find correspond embedding,2018-07-13 12:19:33,2018-08-05 11:52:02,doe tf nn embedding lookup function,python tensorflow deep-learning word-embedding natural-language-processing,8,1,60.0,,,CC BY-SA 3.0,5.1850114092178725e-05
21909,21909,56927602,1,56949134.0,,2019-07-08 02:08:36,,12,8631,using spacy google colab build ner model downloaded spacy en core web lg model using import spacy cli spacy cli download en core web lg get message saying download installation successful load model via spacy load en core web lg however try load model nlp spacy load en core web lg following error printed oserror e find model en core web lg seem shortcut link python package valid path data directory could anyone help problem,2019-11-22 13:40:50,2020-08-03 19:15:36,unable load spacy model en core web lg google colab,python nlp google-colaboratory spacy,4,0,5.0,,,CC BY-SA 4.0,4.711224696097171e-05
9556,9556,38916452,1,39142816.0,,2016-08-12 11:04:22,,45,36330,get following error trying install punkt nltk nltk download punkt nltk data error loading punkt false,,2020-07-07 10:01:36,nltk download ssl certificate verify failed,ssl-certificate nltk,12,0,12.0,,,CC BY-SA 3.0,4.5801011852567116e-05
25369,25369,60492839,1,60493083.0,,2020-03-02 16:20:07,,11,3518,using huggingface transformer package access pretrained model use case need functionality english arabic using bert base multilingual cased pretrained model need able compare similarity sentence using something cosine similarity use first need get embedding vector sentence compute cosine similarity firstly best way extratc semantic embedding bert model would taking last hidden state model fed sentence suffice import torch transformer import bertmodel berttokenizer model class bertmodel tokenizer class berttokenizer pretrained weight bert base multilingual cased tokenizer tokenizer class pretrained pretrained weight model model class pretrained pretrained weight sentence test sentence input id torch tensor tokenizer encode sentence add special token true torch grad output tuple model input id last hidden state output tuple print last hidden state size last hidden state secondly sufficient way get embeddings sentence another problem embedding vector different length depending length original sentence shape output n vocab size value order compute two vector cosine similarity need length could something naive first summing across axis still work option,2020-03-02 16:25:55,2020-03-03 09:31:58,compare sentence similarity using embeddings bert,python vector nlp cosine-similarity huggingface-transformers,2,0,5.0,,,CC BY-SA 4.0,4.444430359993805e-05
24776,24776,59956670,1,59959188.0,,2020-01-28 20:39:24,,25,7694,panda dataframe one column bunch string certain travel detail goal parse string extract city origin destination city would like ultimately two new column titled origin destination data df col new york venice italy usd return flight brussels bangkok etihad los angeles guadalajara mexico usd fly australia new zealand paris return including checked bag result origin new york usa destination venice italy origin brussels bel destination bangkok thailand origin los angeles usa destination guadalajara mexico origin paris france destination australia new zealand complicated case given two country thus far tried variety nltk method ha gotten closest using nltk po tag method tag word string result list tuples word associated tag example fly nnp australia nnp cc new nnp zealand nnp paris nnp nnp return nn including vbg cd checked vbd bag nns stuck stage unsure best implement anyone point right direction please thanks,2020-01-28 20:46:16,2020-03-02 21:48:24,parsing city origin destination city string,python regex pandas nlp nltk,1,1,20.0,,,CC BY-SA 4.0,4.416630854334468e-05
251,251,13883277,1,,,2012-12-14 17:12:20,,90,94000,possible use stanford parser nltk talking stanford po,2015-12-06 05:28:44,2019-09-03 08:04:07,stanford parser nltk,python parsing nlp nltk stanford-nlp,18,4,77.0,,,CC BY-SA 3.0,4.397807927196635e-05
1407,1407,15547409,1,,,2013-03-21 12:22:07,,127,180166,starting use nltk quite understand get list word text use nltk word tokenize get list word punctuation need word instead get rid punctuation also work multiple sentence dot added last word,2013-03-21 12:45:57,2020-01-26 08:18:46,get rid punctuation using nltk tokenizer,python nlp tokenize nltk,11,8,35.0,,,CC BY-SA 3.0,4.3090613806328995e-05
17223,17223,50747947,1,,,2018-06-07 18:29:18,,39,47583,checked pytorch tutorial question similar one stackoverflow get confused doe embedding pytorch embedding make similar word closer need give sentence lookup table need code model,2019-08-29 16:34:17,2020-08-29 13:44:55,embedding pytorch,pytorch word-embedding,4,0,14.0,,,CC BY-SA 4.0,4.297356986464917e-05
10917,10917,41610543,1,,,2017-01-12 10:19:22,,47,76773,trying import nltk package python import nltk stopwords nltk corpus stopwords word english print stopwords running give following error lookuperror resource corpus stopwords found please use nltk downloader obtain resource nltk download therefore open python termin following import nltk nltk download give showing info http raw githubusercontent com nltk nltk data gh page index xml however doe seem stop running still give error thought go wrong,,2020-09-13 07:58:26,corpus stopwords found import nltk library,python nltk,8,0,4.0,,,CC BY-SA 3.0,4.27127302480732e-05
8580,8580,36952763,1,36956440.0,,2016-04-30 08:45:50,,48,93639,using anaconda python window training language model using kera exmaple print build model model sequential model add gru return sequence true input shape maxlen len char model add dropout model add gru return sequence false model add dropout model add dense len char model add activation softmax model compile loss categorical crossentropy optimizer rmsprop def sample temperature helper function sample index probability array np log temperature np exp np sum np exp return np argmax np random multinomial train model output generated text iteration iteration range print print print iteration iteration model fit x batch size nb epoch start index random randint len text maxlen diversity print print diversity diversity generated sentence text start index start index maxlen generated sentence print generating seed sentence sys stdout write generated range x np zero maxlen len char char enumerate sentence x char index char preds model predict x verbose next index sample preds diversity next char index char next index generated next char sentence sentence next char sys stdout write next char sys stdout flush print according kera documentation model fit method return history callback ha history attribute containing list successive loss metric hist model fit x validation split print hist history training model run print model history get error attributeerror sequential object ha attribute history return model history training model code update issue wa following first defined kera callback import history history history callback option called model fit x train train nb epoch batch size callback history print print history history return even though ran iteration,2017-03-10 15:21:49,2020-10-17 15:23:03,return history validation loss kera,python neural-network nlp deep-learning keras,10,2,12.0,,,CC BY-SA 3.0,4.197199211712986e-05
13947,13947,46168600,1,,,2017-09-12 05:33:26,,28,52732,trying import gensim following code import gensim model gensim model word vec load word vec format model googlenews vector negative bin binary true got following error importerror traceback recent call last import gensim model gensim model word vec load word vec format model googlenews vector negative bin binary true importerror module named gensim installed gensim python use genssim word vec,,2020-07-22 22:03:11,gensim error module named gensim,python linux gensim word2vec,10,2,1.0,,,CC BY-SA 3.0,4.1919827448630504e-05
11634,11634,42821330,1,44891281.0,,2017-03-15 21:49:19,,35,11035,restore original text kera imdb dataset want restore imdb original text kera imdb dataset first load kera imdb dataset returned sequence word index x train train x test test imdb load data x train found imdb get word index method return word index dictionary like create make converting create index word dictionary word index imdb get word index index word v k k v word index item tried restore original text like following join index word get w w x train effort still usually make finished sucking ended cbc though something know novel female slowly lot freshened connect script end deceptively good english know sentence something strange happened restore original text,2017-07-12 08:30:30,2020-10-09 02:36:06,restore original text kera imdb dataset,python machine-learning neural-network nlp keras,9,0,6.0,,,CC BY-SA 3.0,3.930853484120595e-05
16427,16427,49710537,1,49802495.0,,2018-04-07 18:21:06,,37,26061,want load pre trained word vec embedding gensim pytorch embedding layer question get embedding weight loaded gensim pytorch embedding layer thanks advance,2018-08-10 12:26:52,2020-04-03 08:18:38,pytorch gensim load pre trained word embeddings,python neural-network pytorch gensim embedding,6,0,14.0,,,CC BY-SA 3.0,3.9305197077382676e-05
1135,1135,15388831,1,15389153.0,,2013-03-13 14:59:09,,143,93742,find list possible po tag used natural language toolkit nltk,,2020-07-26 00:17:06,possible po tag nltk,python nltk,8,0,63.0,,,CC BY-SA 3.0,3.8961603929642456e-05
4333,4333,28501072,1,28501150.0,,2015-02-13 13:46:40,,104,192247,shell script checking whether package installed installed install withing shell script import nltk echo nltk version stop shell script line linux terminal tried see manner nltk give nothing thought installed way verify package installation shell script installed also install,,2020-05-01 00:14:11,check version nltk scikit learn installed,python linux shell scikit-learn nltk,7,9,18.0,,,CC BY-SA 3.0,3.7544655131133585e-05
9010,9010,37793118,1,38230349.0,,2016-06-13 15:01:18,,41,53922,downloaded pretrained glove vector file internet txt file unable load access easy load access word vector binary file using gensim know text file format thanks advance,,2020-07-03 05:05:04,load pretrained glove vector python,python-2.7 vector nlp,10,0,28.0,,,CC BY-SA 3.0,3.45701095818786e-05
5080,5080,29760935,1,,,2015-04-21 00:46:52,,75,60711,generated vector list token large document using word vec given sentence possible get vector sentence vector token sentence,,2019-12-09 15:37:08,get vector sentence word vec token sentence,word2vec,9,0,55.0,,,CC BY-SA 3.0,3.3002327293183156e-05
18116,18116,51956000,1,51956230.0,,2018-08-21 20:08:48,,69,43736,occasion circumstance require u following kera preprocessing text import tokenizer tokenizer tokenizer num word max invariably chant mantra tokenizer fit text text sequence tokenizer text sequence text le understand total effect figure one doe separately regardless much research including obviously documentation think ever seen one without doe circumstance would use either one without simply combined something like sequence tokenizer fit text sequence text apology missing something obvious pretty new,2018-12-25 11:38:07,2019-06-22 11:09:42,doe kera tokenizer method exactly,python keras nlp,3,1,23.0,,,CC BY-SA 4.0,3.150686172923832e-05
8443,8443,36610179,1,36612605.0,,2016-04-13 21:47:55,,52,31549,trying find get dependency tree spacy find anything get tree navigate tree,2018-05-14 15:16:47,2020-09-14 08:31:40,get dependency tree spacy,python spacy,7,0,23.0,,,CC BY-SA 4.0,3.14445095672212e-05
1262,1262,9647202,1,20007730.0,,2012-03-10 14:27:49,,59,48206,currently looking way replace word like first second third appropriate ordinal number representation st nd rd googling last week find useful standard tool function nltk write regular expression manually thanks advice,,2020-09-23 20:32:52,ordinal number replacement,python nlp nltk ordinals,18,1,17.0,,,CC BY-SA 3.0,3.107027875605869e-05
12094,12094,43396572,1,43399308.0,,2017-04-13 15:44:02,,61,47817,tried build cnn one layer problem indeed compilator say valueerror error checking model input expected conv input dimension got array shape code import numpy kera model import sequential kera layer convolutional import conv numpy random seed datasettraining numpy loadtxt canceradapter csv delimiter x datasettraining datasettraining datasettesting numpy loadtxt cancereevaluation csv delimiter x test datasettraining test datasettraining model sequential model add conv activation relu input shape x shape model compile loss binary crossentropy optimizer adam metric accuracy model fit x epoch batch size score model evaluate x test test print n f model metric name score,,2020-01-05 19:06:42,dimension shape conv,python keras text-classification keras-layer,5,0,29.0,,,CC BY-SA 3.0,3.060417309938013e-05
12381,12381,43727583,1,43727749.0,,2017-05-01 22:47:19,,66,216118,read multiple post regarding error still figure try loop function def fix plan location letter sub za z search non letter replace non letter space location column row search word letter lower split stop set stopwords word english meaningful word w w word w stop return join meaningful word col plan fix plan train plan num response train plan size clean plan response range num response clean plan response append fix plan train plan error traceback recent call last file c user xxxxx pycharmprojects tronc tronc py line clean plan response append fix plan train plan file c user xxxxx pycharmprojects tronc tronc py line fix plan location column row search file c user xxxxx appdata local program python python lib py line sub return compile pattern flag sub repl string count typeerror expected string byte like object,2018-12-29 08:38:01,2020-07-27 16:17:09,sub erroring expected string byte like object,python regex pandas nltk,3,10,8.0,,,CC BY-SA 4.0,2.937599006356285e-05
6053,6053,31421413,1,31575870.0,,2015-07-15 04:17:36,,115,172058,working sentiment analysis problem data look like label instance data unbalanced since labeled classification im using scikit svc problem know balance data right way order compute accurately precision recall accuracy f score multiclass case tried following approach first wclf svc kernel linear c class weight wclf fit x weighted prediction wclf predict x test print accuracy accuracy score test weighted prediction print f score f score test weighted prediction average weighted print recall recall score test weighted prediction average weighted print precision precision score test weighted prediction average weighted print n clasification report n classification report test weighted prediction print n confussion matrix n confusion matrix test weighted prediction second auto wclf svc kernel linear c class weight auto auto wclf fit x auto weighted prediction auto wclf predict x test print accuracy accuracy score test auto weighted prediction print f score f score test auto weighted prediction average weighted print recall recall score test auto weighted prediction average weighted print precision precision score test auto weighted prediction average weighted print n clasification report n classification report test auto weighted prediction print n confussion matrix n confusion matrix test auto weighted prediction third clf svc kernel linear c clf fit x prediction clf predict x test sklearn metric import precision score recall score confusion matrix classification report accuracy score f score print accuracy accuracy score test prediction print f score f score test prediction print recall recall score test prediction print precision precision score test prediction print n clasification report n classification report test prediction print n confussion matrix n confusion matrix test prediction f score usr local lib python site package sklearn metric classification py deprecationwarning default weighted averaging deprecated version use precision recall f score multiclass multilabel data po label none result exception please set explicit value average one none micro macro weighted sample cross validation use instance scoring f weighted instead scoring f sample weight sample weight usr local lib python site package sklearn metric classification py deprecationwarning default weighted averaging deprecated version use precision recall f score multiclass multilabel data po label none result exception please set explicit value average one none micro macro weighted sample cross validation use instance scoring f weighted instead scoring f sample weight sample weight usr local lib python site package sklearn metric classification py deprecationwarning default weighted averaging deprecated version use precision recall f score multiclass multilabel data po label none result exception please set explicit value average one none micro macro weighted sample cross validation use instance scoring f weighted instead scoring f sample weight sample weight however im getting warning like usr local lib python site package sklearn metric classification py deprecationwarning default weighted averaging deprecated version use precision recall f score multiclass multilabel data po label none result exception please set explicit value average one none micro macro weighted sample cross validation use instance scoring f weighted instead scoring f deal correctly unbalanced data order compute right way classifier metric,2017-03-15 20:59:13,2020-06-04 12:27:50,compute precision recall accuracy f score multiclass case scikit learn,python machine-learning nlp artificial-intelligence scikit-learn,4,2,61.0,,,CC BY-SA 3.0,2.8945081642900805e-05
12179,12179,43459437,1,43758076.0,,2017-04-17 20:56:05,,22,20337,running import spacy nlp spacy load en following printed warning model found en loading en tokenizer site package spacy data empty exception init file filepaths pointing single installation python help appreciated resolving thanks,2017-08-01 17:17:20,2020-06-19 08:42:51,spacy link error,python models spacy,10,1,4.0,,,CC BY-SA 3.0,2.7886104415405725e-05
10721,10721,41170726,1,41172279.0,,2016-12-15 18:11:49,,44,45453,best way add remove stop word spacy using token stop function would like make custom change set wa looking documentation could find anything regarding stop word thanks,2020-05-20 16:55:48,2020-05-20 16:56:12,add remove custom stop word spacy,python nlp stop-words spacy,6,1,21.0,,,CC BY-SA 4.0,2.7871636080877617e-05
1944,1944,22211525,1,,,2014-03-05 23:19:31,,51,125189,updated answer nltk work well uninstalled installed work installed nltk tried download nltk data wa follow instrution site http www nltk org data html downloaded nltk installed tried run following code import nltk nltk download gave error message like traceback recent call last file line nltk download attributeerror module object ha attribute download directory c python lib site package tried nltk download nltk downloader gave error message used help nltk pull package show following info name nltk package content align app package book ccg package chat package chunk package classify package cluster package collocation corpus package data decorator downloader draw package example package featstruct grammar help inference package internals lazyimport metric package misc package model package parse package probability sem package sourcedstring stem package tag package test package text tokenize package toolbox tree treetransforms util yamltags file c python lib site package nltk see downloader sure doe work python system window vista,2014-03-06 22:12:15,2019-09-03 01:04:06,download nltk data,python nltk,15,7,11.0,,,CC BY-SA 3.0,2.7602263773891744e-05
20445,20445,55103162,1,,,2019-03-11 13:41:05,,13,14048,wa trying install python spacy download en vector web lg wa throwing error could install package due environmenterror errno space left device may know creating error saying enogh space directory install,,2020-06-15 12:45:35,could install package due environmenterror errno space left device,python spacy,2,1,2.0,,,CC BY-SA 4.0,2.7191859428596466e-05
20673,20673,55382596,1,55416944.0,,2019-03-27 16:52:34,,32,9129,seen nlp model bert utilize wordpiece tokenization wordpiece split token like ing mentioned cover wider spectrum vocabulary oov word someone please help explain wordpiece tokenization actually done handle effectively help rare oov word,,2020-04-03 11:50:17,wordpiece tokenization helpful effectively deal rare word problem nlp,nlp word-embedding,1,0,10.0,,,CC BY-SA 4.0,2.475758802878529e-05
22783,22783,57984502,1,,,2019-09-18 03:05:58,,13,2953,want analyse text google compute server google cloud platform gcp using word vec model however un compressed word vec model http mccormickml com google pretrained word vec model python gb take time download manually upload cloud instance way access pre trained word vec model google compute server without uploading,2019-09-18 10:06:45,2019-10-16 09:10:58,access use google pre trained word vec model without manually downloading model,python google-cloud-platform nlp google-compute-engine word2vec,3,3,1.0,,,CC BY-SA 4.0,2.4335163065684792e-05
8021,8021,35861482,1,35862172.0,,2016-03-08 07:29:33,,33,74258,running python script using nltk got traceback recent call last file cpicklesave py line po nltk po tag word file usr lib python site package nltk tag init py line po tag tagger perceptrontagger file usr lib python site package nltk tag perceptron py line init ap model loc str find tagger averaged perceptron tagger pickle file usr lib python site package nltk data py line find raise lookuperror resource found lookuperror resource u tagger averaged perceptron tagger averaged perceptro n tagger pickle found please use nltk downloader obtain resource nltk download searched root nltk data usr share nltk data usr local share nltk data usr lib nltk data usr local lib nltk data anyone explain problem,2016-03-08 13:37:37,2020-09-09 15:59:13,nltk lookup error,python python-2.7 nltk,8,0,8.0,,,CC BY-SA 3.0,2.414190270176173e-05
12103,12103,43370851,1,44872209.0,,2017-04-12 13:24:09,,19,34281,trying install spacy running pip install spacy python version continuously getting error like get rid issue previously wa cl exe found error added visual studio path environment variable cl exe exists failed building wheel spacy running setup py clean spacy running setup py bdist wheel murmurhash error complete output command c user sh appdata local program python python python exe u c import setuptools tokenize file c user sh appdata local temp pip build joi voav murmurhash setup py f getattr tokenize open open file code f read replace r n n f close exec compile code file exec bdist wheel c user sh appdata local temp tmpa tzdkovpip wheel python tag cp running bdist wheel running build running build py failed building wheel murmurhash running setup py clean murmurhash running setup py bdist wheel cymem error complete output command c user sh appdata local program python python python exe u c import setuptools tokenize file c user sh appdata local temp pip build joi voav cymem setup py f getattr tokenize open open file code f read replace r n n f close exec compile code file exec bdist wheel c user sh appdata local temp tmpz p hkiwpip wheel python tag cp failed building wheel cymem running setup py clean cymem running setup py bdist wheel preshed error complete output command c user sh appdata local program python python python exe u c import setuptools tokenize file c user sh appdata local temp pip build joi voav preshed setup py f getattr tokenize open open file code f read replace r n n f close exec compile code file exec bdist wheel c user sh appdata local temp tmpwppgmyp pip wheel python tag cp failed building wheel preshed running setup py clean preshed running setup py bdist wheel thinc error failed building wheel thinc running setup py clean thinc running setup py bdist wheel ujson error failed building wheel ujson running setup py clean ujson running setup py bdist wheel cytoolz error failed building wheel cytoolz running setup py clean cytoolz failed build spacy murmurhash cymem preshed thinc ujson cytoolz installing collected package murmurhash cymem preshed wrapt tqdm toolz cytoolz plac pyreadline dill termcolor pathlib thinc ujson regex spacy running setup py install murmurhash error c program file x microsoft visual studio vc bin cl exe c nologo ox w gl dndebug md ic user sh appdata local program python python include ic user sh appdata local temp pip build joi voav murmurhash murmurhash include ic user sh appdata local program python python include ic user sh appdata local program python python include ehsc tpmurmurhash mrmr cpp fobuild temp win amd release murmurhash mrmr obj ox ehsc mrmr cpp c xx fatal error c open source file murmurhash mrmr cpp file directory error command c program file x microsoft visual studio vc bin cl exe failed exit status command c user sh appdata local program python python python exe u c import setuptools tokenize file c user sh appdata local temp pip build joi voav murmurhash setup py f getattr tokenize open open file code f read replace r n n f close exec compile code file exec install record c user sh appdata local temp pip j cxej record install record txt single version externally managed compile failed error code c user sh appdata local temp pip build joi voav murmurhash,,2020-04-29 04:48:11,failed building wheel spacy,python scipy pip python-wheel spacy,10,0,5.0,,,CC BY-SA 3.0,2.410140004278053e-05
10787,10787,41348621,1,42890688.0,,2016-12-27 16:22:49,,72,40664,trying download nltk use python mac x getting ssl error import nltk nltk download downloaded nltk pip command sudo pip install u nltk changing index nltk downloader allows downloader show nltk file one try download one get another ssl error see bottom photo relatively new computer science savvy respect ssl question simply resolve issue similar question user problem unable download nltk data decided post new question screenshots since edit question wa rejected similar question find helpful nltk download ssl certificate verify failed downloading error using nltk download,2020-06-20 09:12:55,2019-09-11 06:23:14,ssl error downloading nltk data,python macos ssl ssl-certificate nltk,4,0,31.0,,,CC BY-SA 3.0,2.3928823223745068e-05
14778,14778,47388497,1,47393191.0,,2017-11-20 09:16:27,,25,10239,difference dialogflow bot framework v rasa nlu bot framework open source framework available market nlp support,,2020-07-29 12:35:55,difference dialogflow bot framework v rasa nlu bot framework,nlp open-source chatbot dialogflow-es rasa-nlu,4,2,13.0,,,CC BY-SA 3.0,2.2198213217726088e-05
15112,15112,47818669,1,47819500.0,,2017-12-14 17:05:21,,29,5918,tried understand rasa official documentation rasa core rasa nlu able deduce much able understand rasa core used guide flow conversation rasa nlu understand process text extract information entity second thing example build chatbot rasa core well rasa nlu used build chatbot understand difference two approach follow one could please help understand better way,2019-03-05 10:10:26,2020-04-30 15:47:01,difference rasa core rasa nlu,nlp artificial-intelligence chatbot rasa-nlu rasa-core,4,0,8.0,,,CC BY-SA 4.0,2.170296282266765e-05
19045,19045,53403306,1,53403392.0,,2018-11-20 23:47:12,,11,1648,example lens want get mask torch longtensors,2018-11-20 23:58:25,2020-07-31 07:20:19,batch convert sentence length mask pytorch,nlp pytorch,3,0,4.0,,,CC BY-SA 4.0,2.134247038280103e-05
15802,15802,48962171,1,,,2018-02-24 11:10:57,,20,13060,tried follow wasted lot time ending nothing useful want train model corpus mb corpus txt file downloaded file provided link compiled using editing demo sh file changed vocab file corpus txt leave corpus text unchanged output wa cooccurrence bin cooccurrence shuf bin text corpus txt vector txt used file load model python,2020-01-27 06:21:12,2020-06-09 16:10:08,train glove algorithm corpus,nlp stanford-nlp gensim word2vec glove,4,0,6.0,,,CC BY-SA 4.0,2.126220335789639e-05
8019,8019,35857519,1,35857833.0,,2016-03-08 01:52:21,,36,28667,like count frequency word text file countinfile test txt return aaa bbb ccc target text file like test txt aaa bbb ccc bbb implemented pure python following post however found pure python way insufficient due huge file size gb think borrowing sklearn power candidate let countvectorizer count frequency line guess get word frequency summing column sound bit indirect way efficient straightforward way count word file python update slow code collection import counter def get term frequency file source file path wordcount open source file path f line f line line lower translate none string punctuation wordcount counter line split wordcount add merge two dict wordcount wordcount return wordcount def add merge two dict x return k x get k get k k set x set,2017-05-23 10:31:13,2020-01-26 09:10:46,efficiently count word frequency python,python nlp scikit-learn word-count frequency-distribution,8,3,10.0,,,CC BY-SA 3.0,2.0933535650711467e-05
7876,7876,35572000,1,,,2016-02-23 08:06:07,,90,186927,using scikit learn classification text document class use scikit learn confusion matrix method computing confusion matrix model logisticregression model model fit matrix label pred model predict test matrix cm metric confusion matrix test label pred print cm plt imshow cm cmap binary confusion matrix look like however receive clear legible plot better way,2017-11-15 06:46:56,2020-01-08 23:45:29,plot confusion matrix,python matplotlib matrix scikit-learn text-classification,3,0,31.0,2018-07-03 23:24:26,,CC BY-SA 3.0,2.0351354069965572e-05
13627,13627,45735070,1,45737582.0,,2017-08-17 12:25:32,,49,24983,trained sentiment classifier model using kera library following step broadly convert text corpus sequence using tokenizer object class build model using model fit method evaluate model scoring using model wa able save model file load file however found way save tokenizer object file without process corpus every time need score even single sentence way around,2017-12-30 13:35:34,2019-05-13 00:35:34,kera text preprocessing saving tokenizer object file scoring,machine-learning neural-network nlp deep-learning keras,4,0,12.0,,,CC BY-SA 3.0,1.967211536248635e-05
3563,3563,26693736,1,26693897.0,,2014-11-01 22:05:16,,61,95678,trying start project sentiment analysis use stop word method made research found nltk stopwords execute command error following order know word nltk use like may found http www nltk org book ch html section nltk corpus import stopwords stopwords word english press enter obtain lookuperror traceback recent call last stopwords word english c user usuario anaconda lib site package nltk corpus util pyc getattr self attr def getattr self attr self load look circular since load change class something new c user usuario anaconda lib site package nltk corpus util pyc load self except lookuperror e try root nltk data find corpus zip name except lookuperror raise e load corpus lookuperror resource corpus stopwords found please use nltk downloader obtain resource nltk download searched c user meru nltk data c nltk data nltk data e nltk data c user meru anaconda nltk data c user meru anaconda lib nltk data c user meru appdata roaming nltk data problem thing like run properly obtaining error nltk corpus import stopwords stop stopwords word english sentence foo bar sentence print sentence split stop know may problem must use word spanish recomend another method also thought using goslate package datasets english thanks reading p use ananconda,2014-11-01 22:15:29,2020-04-19 17:55:21,nltk stopwords fail lookuperror,python nltk sentiment-analysis stop-words,6,0,11.0,,,CC BY-SA 3.0,1.9460295229062043e-05
14699,14699,47350942,1,47351587.0,,2017-11-17 12:43:56,,14,19090,installed spacy python nlp project installed using verify installed spacy version using pip install u spacy command verify installed spacy version,,2020-08-05 07:37:22,verify installed spacy version,python nlp pip version spacy,5,0,2.0,,,CC BY-SA 3.0,1.9268560271565188e-05
14399,14399,46786211,1,46786277.0,,2017-10-17 08:54:32,,31,31661,table like urn firm name r x yah co big building society st james society kensington society ltd mmv oil associate ltd want count frequency word within firm name column get output like tried following code import panda pd import nltk data pd read csv x firm data csv top n word dist nltk freqdist data firm name print frequency print rslt pd dataframe word dist common top n column word frequency print rslt print however following code doe produce unique word count,2017-10-17 09:01:16,2020-04-23 20:29:35,counting frequency word panda data frame,python pandas nltk,3,0,14.0,,,CC BY-SA 3.0,1.9185167705916994e-05
10033,10033,40011896,1,,,2016-10-13 03:36:31,,26,12316,recently started use nltk toolkit creating solution using python hear lot community activity regarding using stanford nlp anyone tell difference nltk stanford nlp different library know nltk ha interface stanford nlp anyone throw light basic difference even detail stanford nlp used using python,2019-09-19 03:40:53,2020-04-16 17:18:36,nltk v stanford nlp,python nlp nltk stanford-nlp,7,3,11.0,,,CC BY-SA 3.0,1.879705197145063e-05
14359,14359,46752650,1,46755405.0,,2017-10-15 07:17:46,,26,30663,using scikit learn text classification want calculate information gain attribute respect class sparse document term matrix information gain defined h class h class attribute entropy using weka accomplished infogainattribute found measure scikit learn however ha suggested formula information gain measure mutual information match also definition wikipedia possible use specific setting mutual information scikit learn accomplish task,2020-10-14 11:01:17,2020-10-14 11:01:17,information gain calculation scikit learn,python machine-learning scikit-learn text-classification feature-selection,2,1,7.0,,,CC BY-SA 4.0,1.8430913995644846e-05
9472,9472,38763007,1,,,2016-08-04 09:04:54,,30,43527,new spacy want use lemmatizer function know use like string word return string basic form word example word word thank,2019-03-12 19:13:02,2020-08-30 09:48:49,use spacy lemmatizer get word basic form,python nltk spacy lemmatization,5,3,7.0,,,CC BY-SA 4.0,1.838351139396111e-05
10341,10341,40511562,1,40512652.0,,2016-11-09 16:20:16,,34,24884,new tensorflow running deep learning assignment udacity ipython notebook link ha error attributeerror traceback recent call last tf session graph graph session tf global variable initializer run attributeerror module object ha attribute global variable initializer please help fix thank,2016-11-10 22:21:24,2020-08-13 10:52:50,tensorflow module object ha attribute global variable initializer,python tensorflow deep-learning word2vec,4,0,5.0,,,CC BY-SA 3.0,1.8324755207053638e-05
17560,17560,51235118,1,51235358.0,,2018-07-08 18:53:29,,19,9316,currently working kera model ha embedding layer first layer order visualize relationship similarity word need function return mapping word vector every element vocabulary e g love way,2018-09-05 18:42:56,2020-09-09 11:47:20,get word vector kera embedding layer,python dictionary keras keras-layer word-embedding,1,0,6.0,,,CC BY-SA 4.0,1.8170057847797337e-05
3842,3842,27697766,1,35615151.0,,2014-12-29 23:57:13,,72,52719,five text file input countvectorizer specifying min df max df countvectorizer instance doe min max document frequency exactly mean frequency word particular text file frequency word entire overall corpus txt file different min df max df provided integer float documentation seem provide thorough explanation doe supply example demonstrate use min df max df could someone provide explanation example demonstrating min df max df,2018-03-05 20:34:34,2019-12-06 16:16:13,understanding min df max df scikit countvectorizer,python machine-learning scikit-learn nlp,5,0,40.0,,,CC BY-SA 3.0,1.810246649363119e-05
14470,14470,46977498,1,,,2017-10-27 14:32:36,,18,38930,installing nltk get error urllib httperror http error ssl required really trying install failing trying install package minimal dockerfile reproduce issue ubuntu run apt get update run apt get install python pip problem occurs without following line run pip install upgrade pip cmd pip install nltk,,2020-05-20 14:59:50,urllib httperror http error ssl required installing nltk,pip nltk,4,6,6.0,,,CC BY-SA 3.0,1.79440425898027e-05
1727,1727,19790188,1,,,2013-11-05 13:32:22,,46,30936,english language ha couple contraction instance sometimes cause headache natural language processing python library expand contraction,2018-08-23 15:37:27,2020-06-23 22:00:08,expanding english language contraction python,python nlp text-processing,9,1,19.0,,,CC BY-SA 3.0,1.7642879924354458e-05
6750,6750,32879532,1,40496870.0,,2015-10-01 04:34:36,,26,31391,want find sentiment positive negative neutral given string researching came across stanford nlp sadly java idea make work python,,2020-05-25 20:19:23,stanford nlp python,python stanford-nlp sentiment-analysis,9,2,27.0,,,CC BY-SA 3.0,1.746372124700924e-05
5277,5277,27324292,1,27329142.0,,2014-12-05 20:39:00,,63,46891,word vec site download googlenews vector negative bin gz bin file gb binary format useful tomas mikolov assures u fairly straightforward convert binary format text format though take disk space check code distance tool rather trivial read binary file unfortunately know enough c understand http word vec googlecode com svn trunk distance c supposedly gensim also tutorial found seem converting text way someone suggest modification c code instruction gensim emit text,2014-12-05 20:54:12,2017-05-04 08:30:48,convert word vec bin file text,python c gensim word2vec,10,0,27.0,,,CC BY-SA 3.0,1.7449630716613707e-05
9716,9716,39303912,1,39308809.0,,2016-09-03 06:26:03,,49,42596,using tfidfvectorizer scikit learn feature extraction text data csv file score review text pulled data dataframe run vectorizer code import panda pd import numpy np sklearn feature extraction text import tfidfvectorizer df pd read csv train new csv name score review sep x df review np nan print x csv path findnan csv sep na rep string index true print df isnull value v tfidfvectorizer decode error replace encoding utf x v fit transform df review traceback error get traceback recent call last file home pycharmprojects review src feature extraction py line x v fit transform df review file home b hw local lib python site package sklearn feature extraction text py line fit transform x super tfidfvectorizer self fit transform raw document file home b work local lib python site package sklearn feature extraction text py line fit transform self fixed vocabulary file home b work local lib python site package sklearn feature extraction text py line count vocab feature analyze doc file home b work local lib python site package sklearn feature extraction text py line tokenize preprocess self decode doc stop word file home b work local lib python site package sklearn feature extraction text py line decode raise valueerror np nan invalid document expected byte valueerror np nan invalid document expected byte unicode string checked csv file dataframe anything read nan find anything row none return true df review head look like book life saver ha bought time older son great basic wish space book perfect first time new mo postpartum stay hospital th name review dtype object,2016-11-03 10:53:06,2020-05-31 23:04:54,tfidfvectorizer scikit learn valueerror np nan invalid document,python pandas machine-learning scikit-learn tf-idf,3,4,11.0,,,CC BY-SA 3.0,1.715386713485275e-05
12698,12698,44238154,1,44239754.0,,2017-05-29 08:43:37,,21,20621,two attention used seq seq module two different attention introduced multiplicative additive attention tensorflow documentation difference,2019-12-13 04:51:31,2020-07-27 15:22:53,difference luong attention bahdanau attention,tensorflow deep-learning nlp attention-model,4,0,9.0,,,CC BY-SA 3.0,1.6927763261164608e-05
16856,16856,50240029,1,50240724.0,,2018-05-08 18:25:03,,17,9503,doe anyone know difference using nltk nothing doc string explains difference find info either documentation perhaps search right place would expected first one would get rid punctuation token like,,2020-06-12 13:59:29,nltk wordpunct tokenize v word tokenize,python nltk,2,0,5.0,,,CC BY-SA 4.0,1.6558007903404727e-05
12106,12106,43377265,1,,,2017-04-12 18:41:32,,14,28403,using nltk scikit learn text processing however within list document document english example following could true text written english text written english ce n est pa en anglais purpose analysis want sentence english removed part pre processing however good way googling find anything specific let recognize string english something offered functionality either scikit learn edit seen question like individual word document would loop every word sentence check whole sentence english using python library python would preferable switch language needed thought python would best,2017-11-29 08:27:32,2020-08-07 10:07:42,determine text english,python scikit-learn nlp nltk,6,0,4.0,,,CC BY-SA 3.0,1.6531461587521987e-05
11651,11651,42711144,1,42735403.0,,2017-03-10 05:47:27,,15,17267,pytorch installed machine whenever try following torchtext import data torchtext import datasets get following error importerror module named torchtext install torchtext,2018-08-22 12:01:32,2020-06-10 12:51:00,install torchtext,python nlp deep-learning pytorch natural-language-processing,7,0,3.0,,,CC BY-SA 3.0,1.6443788706847647e-05
531,531,12118720,1,12124981.0,,2012-08-25 02:41:26,,93,110247,wa following tutorial wa available part part unfortunately author time final section involved using cosine similarity actually find distance two document followed example article help following link stackoverflow included code mentioned link make life easier sklearn feature extraction text import countvectorizer sklearn feature extraction text import tfidftransformer nltk corpus import stopwords import numpy np import numpy linalg la train set sky blue sun bright document test set sun sky bright query stopwords stopwords word english vectorizer countvectorizer stop word stopwords print vectorizer transformer tfidftransformer print transformer trainvectorizerarray vectorizer fit transform train set toarray testvectorizerarray vectorizer transform test set toarray print fit vectorizer train set trainvectorizerarray print transform vectorizer test set testvectorizerarray transformer fit trainvectorizerarray print print transformer transform trainvectorizerarray toarray transformer fit testvectorizerarray print tfidf transformer transform testvectorizerarray print tfidf todense result code following matrix fit vectorizer train set transform vectorizer test set sure use output order calculate cosine similarity know implement cosine similarity respect two vector similar length sure identify two vector,2018-04-30 11:58:14,2019-10-29 00:00:58,python tf idf cosine find document similarity,python machine-learning nltk information-retrieval tf-idf,6,5,124.0,,,CC BY-SA 3.0,1.642957847995308e-05
12210,12210,43510778,1,48162961.0,,2017-04-20 05:17:39,,28,7978,wa recently working data set used abbreviation various word example wtrbtl water bottle bwlingbl bowling ball bsktball basketball seem consistency term convention used e sometimes used vowel sometimes trying build mapping object like one abbreviation corresponding word without complete corpus comprehensive list term e abbreviation could introduced explicitly known simplicity sake say restricted stuff would find gym could anything basically look left hand side example kind model could processing brain term relating abbreviation corresponding full text label idea stopped taking first last letter finding dictionary assign priori probability based context since large number morpheme without marker indicates end word see possible split updated also idea combine couple string metric algorithm like match rating algorithm determine set related term calculate levenshtein distance word set target abbreviation however still dark come abbreviation word master dictionary basically inferring word construction may naive bayes model could help concerned error precision caused using algorithm invalid model training process help appreciated really stuck one,2018-01-08 22:03:03,2020-04-23 12:01:14,python intuit word abbreviated text using nlp,python machine-learning nlp abbreviation,4,1,12.0,,,CC BY-SA 3.0,1.6349714523784126e-05
15454,15454,48432300,1,,,2018-01-24 21:55:23,,16,5810,currently using kera tokenizer create word index matching word index imported glove dictionary create embedding matrix however problem seems defeat one advantage using word vector embedding since using trained model prediction run new word tokenizer word index remove sequence fit tokenizer tokenizer tokenizer tokenizer fit text text word index tokenizer word index load glove embedding dict embeddings index dims glove data glove b str dims txt f open glove data line f value line split word value value np asarray value dtype float embeddings index word value f close create embedding matrix embedding matrix np zero len word index dims word word index item embedding vector embeddings index get word embedding vector none word found embedding index zero embedding matrix embedding vector dims embedding layer embedding layer embedding embedding matrix shape embedding matrix shape weight embedding matrix input length make prediction sequence tokenizer text sequence test sentence model predict sequence way still use tokenizer transform sentence array still use much word glove dictionary instead one show training text edit upon contemplation guess one option would add text text text tokenizer fit includes list key glove dictionary though might mess statistic want use tf idf either preferable way different better approach,2018-01-25 00:21:46,2020-06-19 07:44:59,using kera tokenizer new word training set,python machine-learning nlp deep-learning keras,3,4,8.0,,,CC BY-SA 3.0,1.5701892775994487e-05
18413,18413,52352522,1,52353721.0,,2018-09-16 08:52:31,,13,3912,currently developing text classification tool using kera work work fine got validation accuracy wrap head around exactly convolution layer work text data hyper parameter use following sentence input data maximum word sentence le padding added vocabulary size amount sentence training embedding vecor length many relation word ha word embeddings batch size matter question number label class simple model made complicated structure strangely work better even without using lstm model sequential model add embedding top word embedding vecor length input length max review length model add conv filter kernel size padding activation relu model add maxpooling pool size model add flatten model add dense label count activation softmax model compile loss categorical crossentropy optimizer adam metric accuracy print model summary main question hyper parameter use conv layer model add conv filter kernel size padding activation relu following input data max word count word embeddings dimension doe mean filter scan first word completely discarding rest kernel size set filter max amount word sentence example image instance input data http joxi ru krdgdbbiebypja first step convoulution layer stride http joxi ru lb c dwkor second step stride http joxi ru brrg ij ra filter layer repeat time correct get say th word sentence thus information lost,2018-09-16 11:45:52,2020-06-28 10:07:19,doe kera convolution layer work word embeddings text classification problem filter kernel size hyperparameter,python tensorflow keras conv-neural-network word-embedding,1,0,11.0,,,CC BY-SA 4.0,1.5576911494095447e-05
778,778,15173225,1,15174569.0,,2013-03-02 10:06:29,,71,97948,python tf idf cosine find document similarity possible calculate document similarity using tf idf cosine without importing external library way calculate cosine similarity string foo bar sentence sentence similar foo bar sentence string totally related two line cosine sim give high cosine similarity cosine sim give high cosine similarity value cosine sim give high cosine similarity value,2017-12-12 14:59:12,2020-03-27 23:03:38,calculate cosine similarity given sentence string,python string nlp similarity cosine-similarity,6,3,54.0,,,CC BY-SA 3.0,1.5406139090563978e-05
10370,10370,40288323,1,40288324.0,,2016-10-27 15:14:32,,36,25017,spacy tag part speech two different format one stored property stored property syntactic dependency head token stored property tag self explanatory even somebody like without linguistics background import spacy en nlp spacy load en document en nlp shot man reno watch die document shot document po verb others document tag vbd document po det document dep dobj worse official doc contain even list possible tag property meaning sometimes mention tokenization standard use claim currently entirely accurate top standard tricky track possible value property mean,2016-10-29 12:00:56,2020-01-09 23:00:01,spacy part speech dependency tag mean,python nlp spacy,4,1,21.0,,,CC BY-SA 3.0,1.535659096589815e-05
5677,5677,26394748,1,26394855.0,,2014-10-16 01:20:27,,56,68945,following instruction class homework assignment supposed look top frequently used word text file last part code fdist freqdist nsmytext vocab fdist key vocab press enter vocab line return traceback recent call last file line typeerror dict key object subscriptable suggestion fix correctly return answer,2019-03-11 20:04:41,2020-02-19 18:50:38,nltk python error typeerror dict key object subscriptable,python nltk,5,3,13.0,,,CC BY-SA 4.0,1.5010067476508207e-05
9048,9048,37889914,1,37937675.0,,2016-06-17 20:30:07,,45,10663,currently trying understand architecture behind word vec neural net learning algorithm representing word vector based context reading tomas mikolov paper came across defines projection layer even though term widely used referred word vec find precise definition actually neural net context question neural net context projection layer name given hidden layer whose link previous node share weight unit actually activation function kind another resource also refers broadly problem found tutorial also refers projection layer around page,2017-11-18 21:20:45,2020-07-16 07:00:04,projection layer context neural network,machine-learning nlp neural-network word2vec,3,2,21.0,,,CC BY-SA 3.0,1.4995253187842136e-05
320,320,13928155,1,,,2012-12-18 07:18:30,,41,118798,fairly new python nltk busy application perform spell check replaces incorrectly spelled word correct one currently using enchant library python pyenchant nltk library code class handle correction replacement nltk metric import edit distance class spellingreplacer def init self dict name en gb max dist self spell dict enchant dict dict name self max dist def replace self word self spell dict check word return word suggestion self spell dict suggest word suggestion edit distance word suggestion self max dist return suggestion else return word written function take list word executes replace word return list word spelled correctly def spell check word list checked list item word list replacer spellingreplacer r replacer replace item checked list append r return checked list word list car colour spell check word car color really like accurate looking way achieve spelling check replacement word also need something pick spelling mistake like caaaar better way perform spelling check doe google spelling suggester good suggestion,2020-08-13 06:48:56,2020-10-14 19:17:32,spell checker python,python python-2.7 nltk spell-checking pyenchant,9,0,21.0,,,CC BY-SA 4.0,1.4707456661517433e-05
1584,1584,23175809,1,,,2014-04-19 21:32:28,,54,64925,following code import nltk json csv string cpickle scipy stats import scoreatpercentile lmtzr nltk stem wordnet wordnetlemmatizer def sanitize wordlist answer word translate none string punctuation word wordlist answer lmtzr lemmatize word lower word answer return answer word filename json list word extend sanitize nltk word tokenize join tweet text tweet json load open filename read tested line separate testing py file wrote import nltk json csv string cpickle scipy stats import scoreatpercentile wordlist print wordlist wordlist word translate none string punctuation word wordlist print wordlist answer lmtzr lemmatize word lower word wordlist print answer freq nltk freqdist wordlist print freq command prompt return wanted removing punctuation however put exact code different file python return typeerror stating file foo py line tweet json load open filename read file foo py line sanitize answer word translate none string punctuation word wordlist typeerror translate take exactly one argument given json list list file path printed check list valid confused typeerror everything work perfectly fine testing different file,2018-01-02 09:45:25,2020-08-26 20:23:13,str translate give typeerror translate take one argument given worked python,python nltk typeerror,5,12,18.0,,,CC BY-SA 3.0,1.4680176051559786e-05
699,699,9294926,1,9344555.0,,2012-02-15 14:12:06,,131,24952,io email client email contains date time location text becomes hyperlink possible create appointment look map simply tapping link work email english language also love feature would like understand naive way would many regular expression run however going scale well work specific language date format etc think apple must using concept machine learning extract entity pm pm h h etc idea apple able extract entity quickly email client machine learning algorithm would apply accomplish task,2012-09-30 20:36:35,2017-07-31 21:41:03,doe apple find date time address email,machine-learning nlp information-extraction named-entity-recognition,6,2,114.0,,,CC BY-SA 3.0,1.4657817404422949e-05
3926,3926,27860652,1,27864657.0,,2015-01-09 12:31:25,,86,35613,reading paper trouble understanding concept negative sampling http arxiv org pdf v pdf anyone help please,,2020-02-14 09:22:45,word vec negative sampling layman term,machine-learning nlp word2vec,3,1,52.0,,,CC BY-SA 3.0,1.4617801401956417e-05
3825,3825,25735644,1,25736082.0,,2014-09-09 01:55:57,,25,50383,want make list sentence string print want use nltk need split period end sentence decimal abbreviation title name sentence ha com attempt regex work import text mr smith bought cheapsite com million dollar e paid lot mind adam jones jr think case true well probability sentence split r text stuff sentence print stuff example output look like mr smith bought cheapsite com million dollar e paid lot mind adam jones jr think case true well probability,2014-09-09 04:11:02,2020-06-29 22:09:00,python regex splitting text sentence sentence tokenizing,python regex nlp tokenize,10,9,14.0,2019-03-05 08:37:13,,CC BY-SA 3.0,1.4538734336266495e-05
1429,1429,15586721,1,15590384.0,,2013-03-23 12:23:54,,61,61456,wanted use wordnet lemmatizer python learnt default po tag noun doe output correct lemma verb unless po tag explicitly specified verb question best shot inorder perform lemmatization accurately po tagging using nltk po tag lost integrating tree bank po tag wordnet compatible po tag please help nltk stem wordnet import wordnetlemmatizer lmtzr wordnetlemmatizer tagged nltk po tag token get output tag nn jj vb rb change wordnet compatible tag also train nltk po tag tagged corpus use directly data evaluate,,2019-10-20 10:01:13,wordnet lemmatization po tagging python,python nltk wordnet lemmatization,7,0,29.0,,,CC BY-SA 3.0,1.4314080784879399e-05
17034,17034,50466643,1,,,2018-05-22 11:32:20,,12,6926,trained word vec model gensim trying load model spacy first need save disk try load init model spacy unable figure exactly gensimmodel import spacy spacy load gensimmodel oserror e find model word vec vocab size alpha seem shortcut link python package valid path data directory,,2020-05-07 09:09:20,spacy use word vec model created gensim,model word2vec gensim spacy,2,1,2.0,,,CC BY-SA 4.0,1.4230725444983452e-05
16958,16958,50492676,1,50499090.0,,2018-05-23 15:50:18,,11,5025,seen question ask none answer yet thought might well try using gensim word vec model create vector exported text tried importing tensorflow live model embedding projector one problem work told tensor improperly formatted beginner thought would ask people experience possible solution equivalent code import gensim corpus word sentence one word sentence two model gensim model word vec iter size model build vocab corpus save memory vector model wv del model vector save word vec format vect txt binary false creates model save vector print result nice pretty tab delimited file value dimension understand figure wrong way put tensorflow documentation regarding pretty scarce far tell one idea ha presented implementing appropriate tensorflow code know code import file live demo edit new problem object vector non iterable gensim apparently decided make data structure non compatible trying ok done thanks help,2018-05-24 19:06:32,2020-03-11 14:31:33,visualize gensim word vec embeddings tensorboard projector,python tensorflow gensim tensorboard word-embedding,3,3,5.0,,,CC BY-SA 4.0,1.3984124942701073e-05
1221,1221,9637278,1,,,2012-03-09 16:10:20,,32,46971,trying use tm package r perform text analysis tied following require tm dataset corpus dirsource tmp dataset tm map dataset tolower error fun x l invalid input rt noxforu erneut riesiger alt lteppich im golf von mexiko pic vom freitag http bit ly bw hvu http bit ly r jcf oilspill bp utf towcs problem character valid like exclude invalid character analysis either within r importing file processing tried using iconv convert file utf exclude anything converted follows find type f exec iconv utf c tmpconverted pointed batch convert latin file utf using iconv still get error appreciate help,2017-05-23 11:47:22,2020-06-06 10:11:23,r tm package invalid input utf towcs,r utf-8 iconv text-mining,14,0,16.0,,,CC BY-SA 3.0,1.3829433638905313e-05
8892,8892,37593293,1,,,2016-06-02 13:28:33,,33,32632,want calculate tf idf document using python panda import panda pd df pd dataframe docid sent first sentence second sentence third sentence first thought would need get word count row wrote simple function def word count sent word cnt dict word sent split word word cnt word cnt word else word cnt word return word cnt applied row df word count df sent apply word count lost know easy method calculate tf idf use graphlab want stick open source option sklearn gensim look overwhelming simplest solution get tf idf,2020-09-20 18:19:29,2020-09-20 18:19:29,get tfidf panda dataframe,python pandas scikit-learn tf-idf gensim,3,0,9.0,,,CC BY-SA 4.0,1.3789594267705067e-05
3385,3385,21844546,1,21844800.0,,2014-02-18 04:41:47,,25,66237,list sentence text cant railway station citadel hotel police stn need form bigram pair store variable problem get pair sentence instead word text word word line split line text bigram nltk bigram text print bigram yield cant railway station citadel hotel citadel hotel police stn railway station citadel hotel form one bigram want cant railway railway station citadel hotel last word first sentence merge first word second sentence make work,2016-04-29 21:23:23,2020-08-27 15:45:32,forming bigram word list sentence python,python list list-comprehension nltk collocation,10,0,11.0,,,CC BY-SA 3.0,1.3388309792550394e-05
14353,14353,46889727,1,48320687.0,,2017-10-23 12:44:40,,12,10946,working recurrent language model learn word embeddings used initialize language model using gensim word vec model training word vec model hold two vector word vocabulary word embedding row input hidden matrix context embedding column hidden output matrix outlined post least three common way combine two embedding vector summing context word vector word summing averaging concatenating context word vector however find proper paper report best strategy question common solution whether sum average concatenate vector doe best way depend entirely task question strategy best word level language model combine vector use original word embeddings word e contained weight matrix input hidden neuron related unanswered question word vec summing concatenate inside outside vector use input hidden weight matrix word vector instead hidden output weight matrix,2017-10-24 07:38:32,2020-04-10 02:42:38,word vec best add concatenate average word vector,python word2vec gensim word-embedding language-model,4,5,7.0,,,CC BY-SA 3.0,1.3382395378444924e-05
3906,3906,24647400,1,24648116.0,,2014-07-09 07:12:45,,40,53657,tried nltk method stemming give weird result word example often cut end word poodle poodl article articl stem good easily easy stemmed word leaf grows fairly stemmed know stemming libs python good dictionary thank,2014-07-09 07:19:29,2020-05-27 06:54:38,best stemming method python,python nltk stemming,6,3,16.0,,,CC BY-SA 3.0,1.3319542320822296e-05
18655,18655,52856057,1,,,2018-10-17 13:26:19,,11,2547,way ner model spacy extract metric precision recall f score per entity type something look like precision recall f score support b loc loc b misc misc b org org b per per avg total taken http www davidsbatista net blog named entity evaluation thank,2018-10-17 13:55:39,2019-10-15 16:25:06,way spacy ner calculate metric per entity type,python entity metrics spacy ner,3,0,6.0,,,CC BY-SA 4.0,1.3193545840200818e-05
8487,8487,36800654,1,,,2016-04-22 18:09:42,,29,57275,trying get word distinctive certain document using tfidfvectorizer class scikit learn creates tfidf matrix word score document seems count common word well code running vectorizer tfidfvectorizer tfidf matrix vectorizer fit transform content feature name vectorizer get feature name dense tfidf matrix todense denselist dense tolist df pd dataframe denselist column feature name index character pd series df loc adam sort value ascending false expected return list distinctive word document adam doe return list common word might understand perfectly understand tf idf supposed find word distinctive one document corpus finding word appear frequently one document document appears frequently document know returning high value complete code using generate jupyter notebook compute tf idf semi manually using nltk computing score word get appropriate result adam document fresh prime bone relate blame enough look right since word appear adam document much document corpus complete code used generate jupyter notebook something wrong scikit code another way initialize class return right result course ignore stopwords passing stop word english really solve problem since common word sort high score,,2019-11-21 14:32:15,tfidfvectorizer scikit learn supposed work,python nlp scikit-learn,5,0,12.0,,,CC BY-SA 3.0,1.3127585785369525e-05
15052,15052,47856247,1,47949327.0,,2017-12-17 14:46:53,,16,8273,using spacy noun chunk extraction using doc noun chunk property provided spacy could extract verb phrase input text using spacy library form verb adv verb,,2020-06-02 02:30:10,extract verb phrase using spacy,python spacy,2,0,10.0,,,CC BY-SA 3.0,1.3076291943808023e-05
14796,14796,47485216,1,53470422.0,,2017-11-25 11:03:49,,21,7820,thought mask zero true output input value following layer could skip computation something doe work example data np array data shape model x input shape e embedding mask zero true x model input x output e p predict data print p shape print p actual output number random however thought output,2018-11-25 18:13:23,2020-04-08 13:50:35,doe mask zero kera embedding layer work,python machine-learning keras word-embedding,2,3,8.0,,,CC BY-SA 4.0,1.292423495154226e-05
11732,11732,42986405,1,43067907.0,,2017-03-23 20:30:58,,24,20259,building chatbot need vectorize user input using word vec using pre trained model million word google googlenews vector negative load model using gensim import gensim model gensim model keyedvectors load word vec format googlenews vector negative bin binary true problem take minute load model let user wait long speed load time thought putting million word corresponding vector mongodb database would certainly speed thing intuition tell good idea,2017-03-29 18:42:16,2019-10-17 10:36:30,speed gensim word vec model load time,deep-learning gensim word2vec,4,0,14.0,,,CC BY-SA 3.0,1.273990540507963e-05
6015,6015,31321209,1,,,2015-07-09 14:57:45,,55,67222,get document vector two text document using doc vec new would helpful someone could point right direction help tutorial using gensim doc sentence another sentence document doc strip split doc doc model doc vec doc vec document size window min count worker get attributeerror list object ha attribute word whenever run,2018-12-15 19:33:57,2019-06-04 10:17:50,doc vec get document vector,python gensim word2vec,4,0,24.0,,,CC BY-SA 4.0,1.2659201897586344e-05
14167,14167,46433778,1,55622285.0,,2017-09-26 18:51:02,,18,26544,working code using gensim tough time troubleshooting valueerror within code finally wa able zip googlenews vector negative bin gz file could implement model also tried gzip result unsuccessful error code occurs last line would like know done fix error workarounds finally website could reference thank respectfully assistance import gensim kera import backend kera layer import dense input lambda lstm timedistributed kera layer merge import concatenate kera layer embeddings import embedding kera model import mode pretrained embeddings path googlenews vector negative bin word vec gensim model keyedvectors load word vec format pretrained embeddings path binary true valueerror traceback recent call last pretrained embeddings path googlenews vector negative bin word vec gensim model keyedvectors load word vec format pretrained embeddings path binary true c user green anaconda envs py lib site package gensim model keyedvectors py load word vec format cl fname fvocab binary encoding unicode error limit datatype word append ch word utils unicode b join word encoding encoding error unicode error weight fromstring fin read binary len dtype real add word word weight else valueerror string size must multiple element size,,2019-12-02 11:05:08,import googlenews vector negative bin,python gensim,3,4,1.0,,,CC BY-SA 3.0,1.2469028947760776e-05
13445,13445,45394949,1,,,2017-07-29 23:24:19,,11,11188,want understand meant dimensionality word embeddings embed word form matrix nlp task role doe dimensionality play visual example help understand concept,2018-01-03 01:32:13,2019-12-30 13:06:24,dimensionality word embeddings,nlp terminology dimensionality-reduction word-embedding,6,1,6.0,,,CC BY-SA 3.0,1.246277623725445e-05
9168,9168,38045290,1,39190391.0,,2016-06-27 03:02:43,,32,16521,result two different summary system sys sys reference summary evaluated bleu rouge problem rouge score sys wa higher sys rouge rouge rouge rouge rouge l rouge su bleu score sys wa le bleu score sys quite much question rouge bleu based n gram measure similar summary system summary human difference result evaluation like main different rouge v bleu explain issue,2020-06-24 09:31:49,2020-06-24 09:31:49,text summarization evaluation bleu v rouge,nlp text-processing rouge bleu,3,0,10.0,,,CC BY-SA 4.0,1.2407075883009403e-05
15786,15786,48941648,1,,,2018-02-23 05:26:07,,16,3952,given model e g gensim model word vec import word vec document human machine interface lab abc computer application survey user opinion computer system response time eps user interface management system system human system engineering testing eps relation user perceived response time error measurement generation random binary unordered tree intersection graph path tree graph minor iv width tree well quasi ordering graph minor survey text lower split document w v model word vec text size window min count worker possible remove word w v vocabulary e g originally print w v model graph print w v model wv vocab graph vocab count index sample int find similar word print w v model similar graph binary unordered perceived iv error machine quasi relation tree delete dictionary del w v model wv vocab graph print w v model graph keyerror word graph vocabulary similarity word deleting see word popping e g w v model similar binary unordered ordering perceived error graph generation computer testing tree remove word completely word vec model gensim updated answer vumaasha comment could give detail want delete word let say universe word word corpus learn dense relation word want generate similar word come subset domain specific word possible generate enough similar filter word let say space specific domain small might looking word ranked th similar inefficient would better word totally removed word vector similar word return word outside specific domain,2018-02-23 06:17:40,2019-08-14 03:55:22,remove word completely word vec model gensim,python dictionary word2vec gensim del,4,4,2.0,,,CC BY-SA 3.0,1.2396172321003876e-05
2612,2612,20290870,1,24119115.0,,2013-11-29 17:33:07,,41,65062,trying extract human name text doe anyone method would recommend tried code using find everything marked person generating list nnp part person skipping person one nnp avoids grabbing lone surname getting decent result wa wondering better way go solving problem code import nltk nameparser parser import humanname def get human name text token nltk tokenize word tokenize text po nltk po tag token sentt nltk ne chunk po binary false person list person name subtree sentt subtrees filter lambda node person leaf subtree leaf person append leaf len person avoid grabbing lone surname part person name part name person list person list append name name person return person list text economist responded positively bitcoin including francois r velde senior economist federal reserve chicago described elegant solution problem creating digital currency november richard branson announced virgin galactic would accept bitcoin payment saying invested bitcoin found fascinating whole new global currency ha created encouraging others also invest bitcoin economist commenting bitcoin critical economist paul krugman ha suggested structure currency incentivizes hoarding value derives expectation others accept payment economist larry summer ha expressed wait see attitude come bitcoin nick cola market strategist convergex group ha remarked effect increasing use bitcoin restricted supply noting incremental adoption meet relatively fixed supply surprise price go exactly happening btc price name get human name text print last first name name last first humanname name last humanname name first print last first output last first velde francois branson richard galactic virgin krugman paul summer larry cola nick apart virgin galactic valid output course knowing virgin galactic human name context article hard maybe impossible part,2019-09-15 17:22:53,2020-01-02 22:45:42,improving extraction human name nltk,python nlp nltk,7,4,28.0,2019-09-16 14:07:54,,CC BY-SA 3.0,1.2370318285373652e-05
7049,7049,33587667,1,33588238.0,,2015-11-07 20:54:18,,16,44451,efficient way code read text file extract noun import nltk file open filename open file line file read read line sentence nltk sent tokenize line tokenize sentence noun empty array hold noun sentence sentence word po nltk po tag nltk word tokenize str sentence po nn po nnp po nns po nnps noun append word reduce time complexity code way avoid using nested loop thanks advance,2015-11-07 21:10:45,2020-08-26 08:22:02,extracting noun text file using nltk,python nltk,7,1,7.0,,,CC BY-SA 3.0,1.22250138186022e-05
