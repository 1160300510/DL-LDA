{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0       Id  PostTypeId  AcceptedAnswerId  ParentId  \\\n0           0  8707624           1         8790222.0       NaN   \n1           1  8720410           1         8780172.0       NaN   \n2           2  8721488           1               NaN       NaN   \n3           3  8748870           1         8749344.0       NaN   \n4           4  8751071           1               NaN       NaN   \n\n          CreationDate  DeletionDate  Score  ViewCount  \\\n0  2012-01-03 03:33:13           NaN      5       1252   \n1  2012-01-04 00:02:18           NaN      2       1095   \n2  2012-01-04 02:55:43           NaN     -2        883   \n3  2012-01-05 19:56:04           NaN      2       1010   \n4  2012-01-05 22:53:26           NaN      5       3085   \n\n                                                Body  ...  \\\n0  came across term called explicit semantic anal...  ...   \n1  wa kicking around idea breaking large group te...  ...   \n2  compare two document find degree similarity ne...  ...   \n3  using python nltk written regex find word star...  ...   \n4  latent dirichlet analysis research keep runnin...  ...   \n\n          LastEditDate     LastActivityDate  \\\n0                  NaN  2012-01-09 14:50:17   \n1                  NaN  2012-01-08 18:43:09   \n2                  NaN  2013-01-23 21:18:21   \n3  2012-01-05 19:59:49  2012-01-05 21:16:54   \n4  2013-02-25 09:09:24  2018-05-16 04:13:38   \n\n                                               Title  \\\n0                         explicit semantic analysis   \n1            compressing text using recursive n gram   \n2                                  degree similarity   \n3  change findall regex text nltk text findall regex   \n4  convert one document per line blei lda c dtm f...   \n\n                              Tags AnswerCount CommentCount FavoriteCount  \\\n0      text similarity text-mining           1            0           1.0   \n1  text compression storage n-gram           2            0           1.0   \n2      text similarity text-mining           2            3           1.0   \n3                python regex nltk           1            0           3.0   \n4                 nlp dataform lda           4            3           3.0   \n\n  ClosedDate  CommunityOwnedDate  ContentLicense  \n0        NaN                 NaN    CC BY-SA 3.0  \n1        NaN                 NaN    CC BY-SA 3.0  \n2        NaN                 NaN    CC BY-SA 3.0  \n3        NaN                 NaN    CC BY-SA 3.0  \n4        NaN                 NaN    CC BY-SA 3.0  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Id</th>\n      <th>PostTypeId</th>\n      <th>AcceptedAnswerId</th>\n      <th>ParentId</th>\n      <th>CreationDate</th>\n      <th>DeletionDate</th>\n      <th>Score</th>\n      <th>ViewCount</th>\n      <th>Body</th>\n      <th>...</th>\n      <th>LastEditDate</th>\n      <th>LastActivityDate</th>\n      <th>Title</th>\n      <th>Tags</th>\n      <th>AnswerCount</th>\n      <th>CommentCount</th>\n      <th>FavoriteCount</th>\n      <th>ClosedDate</th>\n      <th>CommunityOwnedDate</th>\n      <th>ContentLicense</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>8707624</td>\n      <td>1</td>\n      <td>8790222.0</td>\n      <td>NaN</td>\n      <td>2012-01-03 03:33:13</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1252</td>\n      <td>came across term called explicit semantic anal...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2012-01-09 14:50:17</td>\n      <td>explicit semantic analysis</td>\n      <td>text similarity text-mining</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>8720410</td>\n      <td>1</td>\n      <td>8780172.0</td>\n      <td>NaN</td>\n      <td>2012-01-04 00:02:18</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1095</td>\n      <td>wa kicking around idea breaking large group te...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2012-01-08 18:43:09</td>\n      <td>compressing text using recursive n gram</td>\n      <td>text compression storage n-gram</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>8721488</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2012-01-04 02:55:43</td>\n      <td>NaN</td>\n      <td>-2</td>\n      <td>883</td>\n      <td>compare two document find degree similarity ne...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2013-01-23 21:18:21</td>\n      <td>degree similarity</td>\n      <td>text similarity text-mining</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>8748870</td>\n      <td>1</td>\n      <td>8749344.0</td>\n      <td>NaN</td>\n      <td>2012-01-05 19:56:04</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1010</td>\n      <td>using python nltk written regex find word star...</td>\n      <td>...</td>\n      <td>2012-01-05 19:59:49</td>\n      <td>2012-01-05 21:16:54</td>\n      <td>change findall regex text nltk text findall regex</td>\n      <td>python regex nltk</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>8751071</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2012-01-05 22:53:26</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>3085</td>\n      <td>latent dirichlet analysis research keep runnin...</td>\n      <td>...</td>\n      <td>2013-02-25 09:09:24</td>\n      <td>2018-05-16 04:13:38</td>\n      <td>convert one document per line blei lda c dtm f...</td>\n      <td>nlp dataform lda</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nlp = pd.read_csv('preprocess/nlp-process.csv')\n",
    "nlp.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "nlp.drop(['OwnerUserId', 'OwnerDisplayName','LastEditorUserId', 'LastEditorDisplayName'],axis=1,inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import time, math\n",
    "#计算热门问题\n",
    "def hot (Qviews, Qanswers, Qscore, Ascore, date_ask, date_active):\n",
    "    date_compute = time.mktime(time.strptime('2020-10-22 00:00:00', '%Y-%m-%d %H:%M:%S'))\n",
    "    Qage = round((date_compute - date_ask) / 3600)\n",
    "    Qupdated = round((date_compute - date_active) / 3600)\n",
    "    return (math.log10(Qviews) * 4 + Qanswers * Qscore / 5 + Ascore )/(pow((Qage + 1) - (Qage - Qupdated) / 2,1.5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "nlp_score = nlp[nlp['PostTypeId'] == 1]\n",
    "nlp_answer = nlp[nlp['PostTypeId'] == 2]\n",
    "answerScore = {}\n",
    "for index, row in nlp_answer.iterrows():\n",
    "    parentId = row['ParentId']\n",
    "    score = answerScore.get(parentId, 0) + row['Score']\n",
    "    answerScore[parentId] = score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-8efc94b73a87>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out.sort_values(by='HotScore', ascending=False, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Unnamed: 0        Id  PostTypeId  AcceptedAnswerId  ParentId  \\\n19773       19773  54334304           1        54409674.0       NaN   \n23335       23335  58636587           1               NaN       NaN   \n1166         1166  16370583           1               NaN       NaN   \n16650       16650  49964028           1        50342159.0       NaN   \n6200         6200  26570944           1        26575754.0       NaN   \n...           ...       ...         ...               ...       ...   \n13445       13445  45394949           1               NaN       NaN   \n9168         9168  38045290           1        39190391.0       NaN   \n15786       15786  48941648           1               NaN       NaN   \n2612         2612  20290870           1        24119115.0       NaN   \n7049         7049  33587667           1        33588238.0       NaN   \n\n              CreationDate  DeletionDate  Score  ViewCount  \\\n19773  2019-01-23 19:24:21           NaN     31      44775   \n23335  2019-10-31 03:34:11           NaN     16       7533   \n1166   2013-05-04 04:29:21           NaN    104     204759   \n16650  2018-04-22 08:33:02           NaN     42      55195   \n6200   2014-10-26 07:52:51           NaN     98     113655   \n...                    ...           ...    ...        ...   \n13445  2017-07-29 23:24:19           NaN     11      11188   \n9168   2016-06-27 03:02:43           NaN     32      16521   \n15786  2018-02-23 05:26:07           NaN     16       3952   \n2612   2013-11-29 17:33:07           NaN     41      65062   \n7049   2015-11-07 20:54:18           NaN     16      44451   \n\n                                                    Body  ...  \\\n19773  difference spacy load en core web sm spacy loa...  ...   \n23335  know bert ha max length limit token acticle ha...  ...   \n1166   difficult time using pip install almost anythi...  ...   \n16650  even though downloaded model load jalal goku e...  ...   \n6200   code import nltk data tokenizer nltk data load...  ...   \n...                                                  ...  ...   \n13445  want understand meant dimensionality word embe...  ...   \n9168   result two different summary system sys sys re...  ...   \n15786  given model e g gensim model word vec import w...  ...   \n2612   trying extract human name text doe anyone meth...  ...   \n7049   efficient way code read text file extract noun...  ...   \n\n          LastActivityDate                                              Title  \\\n19773  2020-09-10 19:45:29  spacy find model en core web sm window python ...   \n23335  2020-09-02 12:11:33                  use bert long text classification   \n1166   2020-08-12 01:51:46                pip issue installing almost library   \n16650  2020-06-19 14:55:25                        spacy oserror find model en   \n6200   2020-08-01 02:50:32   resource u tokenizers punkt english pickle found   \n...                    ...                                                ...   \n13445  2019-12-30 13:06:24                     dimensionality word embeddings   \n9168   2020-06-24 09:31:49         text summarization evaluation bleu v rouge   \n15786  2019-08-14 03:55:22       remove word completely word vec model gensim   \n2612   2020-01-02 22:45:42               improving extraction human name nltk   \n7049   2020-08-26 08:22:02               extracting noun text file using nltk   \n\n                                                    Tags AnswerCount  \\\n19773                                   python-3.x spacy          11   \n23335        nlp text-classification bert-language-model           5   \n1166                        python pip nltk easy-install          26   \n16650                                          nlp spacy          11   \n6200                                    python unix nltk          17   \n...                                                  ...         ...   \n13445  nlp terminology dimensionality-reduction word-...           6   \n9168                      nlp text-processing rouge bleu           3   \n15786              python dictionary word2vec gensim del           4   \n2612                                     python nlp nltk           7   \n7049                                         python nltk           7   \n\n       CommentCount  FavoriteCount           ClosedDate CommunityOwnedDate  \\\n19773             2            8.0                  NaN                NaN   \n23335             0            3.0                  NaN                NaN   \n1166              1           37.0                  NaN                NaN   \n16650             1           12.0                  NaN                NaN   \n6200              1           14.0                  NaN                NaN   \n...             ...            ...                  ...                ...   \n13445             1            6.0                  NaN                NaN   \n9168              0           10.0                  NaN                NaN   \n15786             4            2.0                  NaN                NaN   \n2612              4           28.0  2019-09-16 14:07:54                NaN   \n7049              1            7.0                  NaN                NaN   \n\n      ContentLicense     HotScore  \n19773   CC BY-SA 4.0  0.000118164  \n23335   CC BY-SA 4.0  9.25103e-05  \n1166    CC BY-SA 3.0  9.13132e-05  \n16650   CC BY-SA 3.0  8.01011e-05  \n6200    CC BY-SA 3.0  7.86305e-05  \n...              ...          ...  \n13445   CC BY-SA 3.0  1.24628e-05  \n9168    CC BY-SA 4.0  1.24071e-05  \n15786   CC BY-SA 3.0  1.23962e-05  \n2612    CC BY-SA 3.0  1.23703e-05  \n7049    CC BY-SA 3.0   1.2225e-05  \n\n[100 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Id</th>\n      <th>PostTypeId</th>\n      <th>AcceptedAnswerId</th>\n      <th>ParentId</th>\n      <th>CreationDate</th>\n      <th>DeletionDate</th>\n      <th>Score</th>\n      <th>ViewCount</th>\n      <th>Body</th>\n      <th>...</th>\n      <th>LastActivityDate</th>\n      <th>Title</th>\n      <th>Tags</th>\n      <th>AnswerCount</th>\n      <th>CommentCount</th>\n      <th>FavoriteCount</th>\n      <th>ClosedDate</th>\n      <th>CommunityOwnedDate</th>\n      <th>ContentLicense</th>\n      <th>HotScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19773</th>\n      <td>19773</td>\n      <td>54334304</td>\n      <td>1</td>\n      <td>54409674.0</td>\n      <td>NaN</td>\n      <td>2019-01-23 19:24:21</td>\n      <td>NaN</td>\n      <td>31</td>\n      <td>44775</td>\n      <td>difference spacy load en core web sm spacy loa...</td>\n      <td>...</td>\n      <td>2020-09-10 19:45:29</td>\n      <td>spacy find model en core web sm window python ...</td>\n      <td>python-3.x spacy</td>\n      <td>11</td>\n      <td>2</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 4.0</td>\n      <td>0.000118164</td>\n    </tr>\n    <tr>\n      <th>23335</th>\n      <td>23335</td>\n      <td>58636587</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2019-10-31 03:34:11</td>\n      <td>NaN</td>\n      <td>16</td>\n      <td>7533</td>\n      <td>know bert ha max length limit token acticle ha...</td>\n      <td>...</td>\n      <td>2020-09-02 12:11:33</td>\n      <td>use bert long text classification</td>\n      <td>nlp text-classification bert-language-model</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 4.0</td>\n      <td>9.25103e-05</td>\n    </tr>\n    <tr>\n      <th>1166</th>\n      <td>1166</td>\n      <td>16370583</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2013-05-04 04:29:21</td>\n      <td>NaN</td>\n      <td>104</td>\n      <td>204759</td>\n      <td>difficult time using pip install almost anythi...</td>\n      <td>...</td>\n      <td>2020-08-12 01:51:46</td>\n      <td>pip issue installing almost library</td>\n      <td>python pip nltk easy-install</td>\n      <td>26</td>\n      <td>1</td>\n      <td>37.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n      <td>9.13132e-05</td>\n    </tr>\n    <tr>\n      <th>16650</th>\n      <td>16650</td>\n      <td>49964028</td>\n      <td>1</td>\n      <td>50342159.0</td>\n      <td>NaN</td>\n      <td>2018-04-22 08:33:02</td>\n      <td>NaN</td>\n      <td>42</td>\n      <td>55195</td>\n      <td>even though downloaded model load jalal goku e...</td>\n      <td>...</td>\n      <td>2020-06-19 14:55:25</td>\n      <td>spacy oserror find model en</td>\n      <td>nlp spacy</td>\n      <td>11</td>\n      <td>1</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n      <td>8.01011e-05</td>\n    </tr>\n    <tr>\n      <th>6200</th>\n      <td>6200</td>\n      <td>26570944</td>\n      <td>1</td>\n      <td>26575754.0</td>\n      <td>NaN</td>\n      <td>2014-10-26 07:52:51</td>\n      <td>NaN</td>\n      <td>98</td>\n      <td>113655</td>\n      <td>code import nltk data tokenizer nltk data load...</td>\n      <td>...</td>\n      <td>2020-08-01 02:50:32</td>\n      <td>resource u tokenizers punkt english pickle found</td>\n      <td>python unix nltk</td>\n      <td>17</td>\n      <td>1</td>\n      <td>14.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n      <td>7.86305e-05</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13445</th>\n      <td>13445</td>\n      <td>45394949</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017-07-29 23:24:19</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>11188</td>\n      <td>want understand meant dimensionality word embe...</td>\n      <td>...</td>\n      <td>2019-12-30 13:06:24</td>\n      <td>dimensionality word embeddings</td>\n      <td>nlp terminology dimensionality-reduction word-...</td>\n      <td>6</td>\n      <td>1</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n      <td>1.24628e-05</td>\n    </tr>\n    <tr>\n      <th>9168</th>\n      <td>9168</td>\n      <td>38045290</td>\n      <td>1</td>\n      <td>39190391.0</td>\n      <td>NaN</td>\n      <td>2016-06-27 03:02:43</td>\n      <td>NaN</td>\n      <td>32</td>\n      <td>16521</td>\n      <td>result two different summary system sys sys re...</td>\n      <td>...</td>\n      <td>2020-06-24 09:31:49</td>\n      <td>text summarization evaluation bleu v rouge</td>\n      <td>nlp text-processing rouge bleu</td>\n      <td>3</td>\n      <td>0</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 4.0</td>\n      <td>1.24071e-05</td>\n    </tr>\n    <tr>\n      <th>15786</th>\n      <td>15786</td>\n      <td>48941648</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2018-02-23 05:26:07</td>\n      <td>NaN</td>\n      <td>16</td>\n      <td>3952</td>\n      <td>given model e g gensim model word vec import w...</td>\n      <td>...</td>\n      <td>2019-08-14 03:55:22</td>\n      <td>remove word completely word vec model gensim</td>\n      <td>python dictionary word2vec gensim del</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n      <td>1.23962e-05</td>\n    </tr>\n    <tr>\n      <th>2612</th>\n      <td>2612</td>\n      <td>20290870</td>\n      <td>1</td>\n      <td>24119115.0</td>\n      <td>NaN</td>\n      <td>2013-11-29 17:33:07</td>\n      <td>NaN</td>\n      <td>41</td>\n      <td>65062</td>\n      <td>trying extract human name text doe anyone meth...</td>\n      <td>...</td>\n      <td>2020-01-02 22:45:42</td>\n      <td>improving extraction human name nltk</td>\n      <td>python nlp nltk</td>\n      <td>7</td>\n      <td>4</td>\n      <td>28.0</td>\n      <td>2019-09-16 14:07:54</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n      <td>1.23703e-05</td>\n    </tr>\n    <tr>\n      <th>7049</th>\n      <td>7049</td>\n      <td>33587667</td>\n      <td>1</td>\n      <td>33588238.0</td>\n      <td>NaN</td>\n      <td>2015-11-07 20:54:18</td>\n      <td>NaN</td>\n      <td>16</td>\n      <td>44451</td>\n      <td>efficient way code read text file extract noun...</td>\n      <td>...</td>\n      <td>2020-08-26 08:22:02</td>\n      <td>extracting noun text file using nltk</td>\n      <td>python nltk</td>\n      <td>7</td>\n      <td>1</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CC BY-SA 3.0</td>\n      <td>1.2225e-05</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_score = nlp[nlp['PostTypeId'] == 1]\n",
    "nlp_score['HotScore']='0'\n",
    "# nlp_score['CreationDate'] = pd.to_datetime(nlp_score['CreationDate'])\n",
    "# nlp_score['LastActivityDate'] = pd.to_datetime(nlp_score['LastActivityDate'])\n",
    "nlp_score['ViewCount'].fillna(0, inplace=True)\n",
    "nlp_score['AnswerCount'].fillna(0, inplace=True)\n",
    "nlp_score['Score'].fillna(0, inplace=True)\n",
    "\n",
    "import time\n",
    "for index, row in nlp_score.iterrows():\n",
    "    Qviews = row['ViewCount']\n",
    "    Qanswers = row['AnswerCount']\n",
    "    Qscore = row['Score']\n",
    "    if (row['Id'] in answerScore):\n",
    "        Ascore = answerScore[row['Id']]\n",
    "    else:\n",
    "        Ascore = 0\n",
    "    date_ask = time.mktime(time.strptime(row['CreationDate'], '%Y-%m-%d %H:%M:%S'))\n",
    "    date_active = time.mktime(time.strptime(row['LastActivityDate'], '%Y-%m-%d %H:%M:%S'))\n",
    "    hotscore = hot(Qviews, Qanswers, Qscore, Ascore, date_ask, date_active)\n",
    "    nlp_score.loc[index,'HotScore'] = hotscore\n",
    "# 进行筛选，条件score>10,viewcount>1000,answercount>0\n",
    "out = nlp_score[(nlp_score['Score']>10) & (nlp_score['ViewCount']>1000) &(nlp_score['AnswerCount']>0)]\n",
    "# 进行降序排序\n",
    "out.sort_values(by='HotScore', ascending=False, inplace=True)\n",
    "out[0:100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "out[0:100].to_csv('hotquestion/nlp-hotquestion.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\lda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning: Columns (22) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "<ipython-input-28-468bc15a41fa>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cvout.sort_values(by='HotScore', ascending=False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "cv = pd.read_csv('preprocess/cv-process.csv')\n",
    "cv.drop(['OwnerUserId', 'OwnerDisplayName','LastEditorUserId', 'LastEditorDisplayName'],axis=1,inplace=True)\n",
    "cv_score = cv[cv['PostTypeId'] == 1]\n",
    "cv_answer = cv[cv['PostTypeId'] == 2]\n",
    "answerScore = {}\n",
    "for index, row in cv_answer.iterrows():\n",
    "    parentId = row['ParentId']\n",
    "    score = answerScore.get(parentId, 0) + row['Score']\n",
    "    answerScore[parentId] = score\n",
    "\n",
    "cv_score['HotScore']='0'\n",
    "cv_score['ViewCount'].fillna(0, inplace=True)\n",
    "cv_score['AnswerCount'].fillna(0, inplace=True)\n",
    "cv_score['Score'].fillna(0, inplace=True)\n",
    "\n",
    "import time\n",
    "for index, row in cv_score.iterrows():\n",
    "    Qviews = row['ViewCount']\n",
    "    Qanswers = row['AnswerCount']\n",
    "    Qscore = row['Score']\n",
    "    if (row['Id'] in answerScore):\n",
    "        Ascore = answerScore[row['Id']]\n",
    "    else:\n",
    "        Ascore = 0\n",
    "    date_ask = time.mktime(time.strptime(row['CreationDate'], '%Y-%m-%d %H:%M:%S'))\n",
    "    date_active = time.mktime(time.strptime(row['LastActivityDate'], '%Y-%m-%d %H:%M:%S'))\n",
    "    hotscore = hot(Qviews, Qanswers, Qscore, Ascore, date_ask, date_active)\n",
    "    cv_score.loc[index,'HotScore'] = hotscore\n",
    "# 进行筛选，条件score>10,viewcount>1000,answercount>0\n",
    "cvout = cv_score[(cv_score['Score']>10) & (cv_score['ViewCount']>1000) &(cv_score['AnswerCount']>0)]\n",
    "# 进行降序排序\n",
    "cvout.sort_values(by='HotScore', ascending=False, inplace=True)\n",
    "cvout[0:100].to_csv('hotquestion/cv-hotquestion.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-3c41836f8b09>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  speechout.sort_values(by='HotScore', ascending=False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "speech = pd.read_csv('preprocess/speech-process.csv')\n",
    "speech.drop(['OwnerUserId', 'OwnerDisplayName','LastEditorUserId', 'LastEditorDisplayName'],axis=1,inplace=True)\n",
    "speech_score = speech[speech['PostTypeId'] == 1]\n",
    "speech_answer = speech[speech['PostTypeId'] == 2]\n",
    "answerScore = {}\n",
    "for index, row in speech_answer.iterrows():\n",
    "    parentId = row['ParentId']\n",
    "    score = answerScore.get(parentId, 0) + row['Score']\n",
    "    answerScore[parentId] = score\n",
    "\n",
    "speech_score['HotScore']='0'\n",
    "speech_score['ViewCount'].fillna(0, inplace=True)\n",
    "speech_score['AnswerCount'].fillna(0, inplace=True)\n",
    "speech_score['Score'].fillna(0, inplace=True)\n",
    "\n",
    "import time\n",
    "for index, row in speech_score.iterrows():\n",
    "    Qviews = row['ViewCount']\n",
    "    Qanswers = row['AnswerCount']\n",
    "    Qscore = row['Score']\n",
    "    if (row['Id'] in answerScore):\n",
    "        Ascore = answerScore[row['Id']]\n",
    "    else:\n",
    "        Ascore = 0\n",
    "    date_ask = time.mktime(time.strptime(row['CreationDate'], '%Y-%m-%d %H:%M:%S'))\n",
    "    date_active = time.mktime(time.strptime(row['LastActivityDate'], '%Y-%m-%d %H:%M:%S'))\n",
    "    hotscore = hot(Qviews, Qanswers, Qscore, Ascore, date_ask, date_active)\n",
    "    speech_score.loc[index,'HotScore'] = hotscore\n",
    "# 进行筛选，条件score>10,viewcount>1000,answercount>0\n",
    "speechout = speech_score[(speech_score['Score']>10) & (speech_score['ViewCount']>1000) &(speech_score['AnswerCount']>0)]\n",
    "# 进行降序排序\n",
    "speechout.sort_values(by='HotScore', ascending=False, inplace=True)\n",
    "speechout[0:100].to_csv('hotquestion/speech-hotquestion.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-fb4d7dd3",
   "language": "python",
   "display_name": "PyCharm (DL-LDA)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}